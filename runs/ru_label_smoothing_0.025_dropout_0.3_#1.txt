Sender: LSF System <lsfadmin@eu-g2-07>
Subject: Job 208068411: <ru_label_smoothing_0.025_dropout_0.3_#1> in cluster <euler> Done

Job <ru_label_smoothing_0.025_dropout_0.3_#1> was submitted from host <eu-login-45> by user <andriusb> in cluster <euler> at Sun Mar 13 12:01:18 2022
Job was executed on host(s) <eu-g2-07>, in queue <gpu.120h>, as user <andriusb> in cluster <euler> at Sun Mar 13 12:01:43 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar 13 12:01:43 2022
Terminated at Mon Mar 14 08:04:47 2022
Results reported at Mon Mar 14 08:04:47 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/ru --save-dir /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.3 --criterion label_smoothed_cross_entropy --label-smoothing 0.025 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --patience 3 --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   76426.95 sec.
    Max Memory :                                 3731 MB
    Average Memory :                             2881.51 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               16269.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72184 sec.
    Turnaround time :                            72209 sec.

The output (if any) follows:

2022-03-13 12:01:51 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.3, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/ru', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.025, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-13 12:01:51 | INFO | fairseq.tasks.language_modeling | dictionary: 35920 types
2022-03-13 12:01:52 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(35920, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=35920, bias=False)
  )
)
2022-03-13 12:01:52 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-13 12:01:52 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-13 12:01:52 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-13 12:01:52 | INFO | fairseq_cli.train | num. shared model params: 37,305,344 (num. trained: 37,305,344)
2022-03-13 12:01:52 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-13 12:01:52 | INFO | fairseq.data.data_utils | loaded 2,558 examples from: data-bin/ru/valid
2022-03-13 12:01:55 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-13 12:01:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-13 12:01:55 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-13 12:01:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-13 12:01:55 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-13 12:01:55 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-13 12:01:55 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 12:01:55 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 12:01:55 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-13 12:01:55 | INFO | fairseq.data.data_utils | loaded 53,136 examples from: data-bin/ru/train
2022-03-13 12:01:56 | INFO | fairseq.trainer | begin training epoch 1
2022-03-13 12:01:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:02:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-13 12:02:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:02:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 12:02:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 12:05:53 | INFO | train_inner | epoch 001:    104 / 407 loss=14.841, nll_loss=14.814, ppl=28801.3, wps=29883.4, ups=0.46, wpb=65536, bsz=128, num_updates=100, lr=1.25975e-05, gnorm=2.189, loss_scale=8, train_wall=213, gb_free=9.7, wall=238
2022-03-13 12:09:32 | INFO | train_inner | epoch 001:    204 / 407 loss=13.382, nll_loss=13.319, ppl=10215.9, wps=30008.6, ups=0.46, wpb=65536, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=0.645, loss_scale=16, train_wall=195, gb_free=9.7, wall=457
2022-03-13 12:13:11 | INFO | train_inner | epoch 001:    304 / 407 loss=12.515, nll_loss=12.424, ppl=5495.25, wps=29859.2, ups=0.46, wpb=65536, bsz=128, num_updates=300, lr=3.75925e-05, gnorm=0.402, loss_scale=32, train_wall=196, gb_free=9.7, wall=676
2022-03-13 12:16:52 | INFO | train_inner | epoch 001:    404 / 407 loss=12.075, nll_loss=11.96, ppl=3984.99, wps=29626.8, ups=0.45, wpb=65534.2, bsz=128, num_updates=400, lr=5.009e-05, gnorm=0.394, loss_scale=64, train_wall=198, gb_free=9.7, wall=897
2022-03-13 12:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:17:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.893 | nll_loss 11.766 | ppl 3482.99 | wps 52034.3 | wpb 511.9 | bsz 1 | num_updates 403
2022-03-13 12:17:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 403 updates
2022-03-13 12:17:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:17:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 1 @ 403 updates, score 11.893) (writing took 2.494288559013512 seconds)
2022-03-13 12:17:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-13 12:17:27 | INFO | train | epoch 001 | loss 13.195 | nll_loss 13.121 | ppl 8906.38 | wps 28913.5 | ups 0.44 | wpb 65492.3 | bsz 127.9 | num_updates 403 | lr 5.04649e-05 | gnorm 0.904 | loss_scale 64 | train_wall 807 | gb_free 9.7 | wall 932
2022-03-13 12:17:27 | INFO | fairseq.trainer | begin training epoch 2
2022-03-13 12:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:19:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:21:03 | INFO | train_inner | epoch 002:     98 / 407 loss=11.886, nll_loss=11.759, ppl=3465.32, wps=26024.1, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=500, lr=6.25875e-05, gnorm=0.411, loss_scale=32, train_wall=199, gb_free=9.7, wall=1149
2022-03-13 12:24:45 | INFO | train_inner | epoch 002:    198 / 407 loss=11.654, nll_loss=11.517, ppl=2930.53, wps=29582.8, ups=0.45, wpb=65536, bsz=128, num_updates=600, lr=7.5085e-05, gnorm=0.451, loss_scale=64, train_wall=198, gb_free=9.7, wall=1370
2022-03-13 12:27:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:28:29 | INFO | train_inner | epoch 002:    299 / 407 loss=11.356, nll_loss=11.207, ppl=2364.02, wps=29321.6, ups=0.45, wpb=65536, bsz=128, num_updates=700, lr=8.75825e-05, gnorm=0.452, loss_scale=32, train_wall=200, gb_free=9.7, wall=1594
2022-03-13 12:32:08 | INFO | train_inner | epoch 002:    399 / 407 loss=11.008, nll_loss=10.847, ppl=1841.75, wps=29805.4, ups=0.45, wpb=65536, bsz=128, num_updates=800, lr=0.00010008, gnorm=0.521, loss_scale=64, train_wall=196, gb_free=9.7, wall=1813
2022-03-13 12:32:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:32:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:32:51 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.604 | nll_loss 10.423 | ppl 1373.33 | wps 52291.6 | wpb 511.9 | bsz 1 | num_updates 807 | best_loss 10.604
2022-03-13 12:32:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 807 updates
2022-03-13 12:32:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:32:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 2 @ 807 updates, score 10.604) (writing took 2.5650990860303864 seconds)
2022-03-13 12:32:54 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-13 12:32:54 | INFO | train | epoch 002 | loss 11.461 | nll_loss 11.317 | ppl 2551.21 | wps 28538.4 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 807 | lr 0.000100955 | gnorm 0.46 | loss_scale 32 | train_wall 803 | gb_free 9.7 | wall 1859
2022-03-13 12:32:54 | INFO | fairseq.trainer | begin training epoch 3
2022-03-13 12:32:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:36:18 | INFO | train_inner | epoch 003:     93 / 407 loss=10.654, nll_loss=10.478, ppl=1425.94, wps=26162.5, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=900, lr=0.000112578, gnorm=0.538, loss_scale=32, train_wall=198, gb_free=9.7, wall=2063
2022-03-13 12:37:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:39:59 | INFO | train_inner | epoch 003:    194 / 407 loss=10.392, nll_loss=10.203, ppl=1179.06, wps=29638.7, ups=0.45, wpb=65536, bsz=128, num_updates=1000, lr=0.000125075, gnorm=0.533, loss_scale=32, train_wall=197, gb_free=9.7, wall=2284
2022-03-13 12:42:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:43:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 12:43:44 | INFO | train_inner | epoch 003:    296 / 407 loss=10.167, nll_loss=9.967, ppl=1000.9, wps=29204.4, ups=0.45, wpb=65536, bsz=128, num_updates=1100, lr=0.000137573, gnorm=0.597, loss_scale=16, train_wall=200, gb_free=9.7, wall=2509
2022-03-13 12:47:24 | INFO | train_inner | epoch 003:    396 / 407 loss=9.958, nll_loss=9.748, ppl=859.75, wps=29817.7, ups=0.45, wpb=65536, bsz=128, num_updates=1200, lr=0.00015007, gnorm=0.598, loss_scale=16, train_wall=196, gb_free=9.7, wall=2729
2022-03-13 12:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:48:12 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.634 | nll_loss 9.403 | ppl 677.06 | wps 52217.2 | wpb 511.9 | bsz 1 | num_updates 1211 | best_loss 9.634
2022-03-13 12:48:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1211 updates
2022-03-13 12:48:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:48:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:48:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 3 @ 1211 updates, score 9.634) (writing took 3.145600132003892 seconds)
2022-03-13 12:48:16 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-13 12:48:16 | INFO | train | epoch 003 | loss 10.271 | nll_loss 10.076 | ppl 1079.76 | wps 28704.1 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 1211 | lr 0.000151445 | gnorm 0.568 | loss_scale 32 | train_wall 797 | gb_free 9.7 | wall 2781
2022-03-13 12:48:16 | INFO | fairseq.trainer | begin training epoch 4
2022-03-13 12:48:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:51:32 | INFO | train_inner | epoch 004:     89 / 407 loss=9.746, nll_loss=9.525, ppl=736.97, wps=26299.3, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=1300, lr=0.000162568, gnorm=0.656, loss_scale=32, train_wall=196, gb_free=9.7, wall=2977
2022-03-13 12:53:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:55:13 | INFO | train_inner | epoch 004:    190 / 407 loss=9.557, nll_loss=9.327, ppl=642.33, wps=29627.9, ups=0.45, wpb=65536, bsz=128, num_updates=1400, lr=0.000175065, gnorm=0.696, loss_scale=32, train_wall=197, gb_free=9.7, wall=3198
2022-03-13 12:58:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:58:55 | INFO | train_inner | epoch 004:    291 / 407 loss=9.369, nll_loss=9.131, ppl=560.53, wps=29588.2, ups=0.45, wpb=65536, bsz=128, num_updates=1500, lr=0.000187563, gnorm=0.683, loss_scale=32, train_wall=198, gb_free=9.7, wall=3420
2022-03-13 13:02:35 | INFO | train_inner | epoch 004:    391 / 407 loss=9.191, nll_loss=8.944, ppl=492.41, wps=29804.5, ups=0.45, wpb=65536, bsz=128, num_updates=1600, lr=0.00020006, gnorm=0.701, loss_scale=32, train_wall=196, gb_free=9.7, wall=3640
2022-03-13 13:03:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:03:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:03:34 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 8.866 | nll_loss 8.595 | ppl 386.65 | wps 52560.7 | wpb 511.9 | bsz 1 | num_updates 1615 | best_loss 8.866
2022-03-13 13:03:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 1615 updates
2022-03-13 13:03:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:03:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:03:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 4 @ 1615 updates, score 8.866) (writing took 3.1868255420122296 seconds)
2022-03-13 13:03:37 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-13 13:03:37 | INFO | train | epoch 004 | loss 9.443 | nll_loss 9.208 | ppl 591.29 | wps 28712 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 1615 | lr 0.000201935 | gnorm 0.687 | loss_scale 32 | train_wall 797 | gb_free 9.7 | wall 3702
2022-03-13 13:03:37 | INFO | fairseq.trainer | begin training epoch 5
2022-03-13 13:03:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:06:45 | INFO | train_inner | epoch 005:     85 / 407 loss=9.016, nll_loss=8.76, ppl=433.39, wps=26145.3, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=1700, lr=0.000212558, gnorm=0.701, loss_scale=32, train_wall=197, gb_free=9.7, wall=3890
2022-03-13 13:08:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:10:25 | INFO | train_inner | epoch 005:    186 / 407 loss=8.859, nll_loss=8.595, ppl=386.63, wps=29751.7, ups=0.45, wpb=65536, bsz=128, num_updates=1800, lr=0.000225055, gnorm=0.739, loss_scale=32, train_wall=196, gb_free=9.7, wall=4110
2022-03-13 13:13:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:14:07 | INFO | train_inner | epoch 005:    287 / 407 loss=8.71, nll_loss=8.439, ppl=346.94, wps=29469.4, ups=0.45, wpb=65534.2, bsz=128, num_updates=1900, lr=0.000237553, gnorm=0.73, loss_scale=32, train_wall=199, gb_free=9.7, wall=4332
2022-03-13 13:17:47 | INFO | train_inner | epoch 005:    387 / 407 loss=8.586, nll_loss=8.308, ppl=316.96, wps=29883.3, ups=0.46, wpb=65536, bsz=128, num_updates=2000, lr=0.00025005, gnorm=0.732, loss_scale=32, train_wall=196, gb_free=9.7, wall=4552
2022-03-13 13:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:18:55 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 8.273 | nll_loss 7.965 | ppl 249.93 | wps 53114.6 | wpb 511.9 | bsz 1 | num_updates 2020 | best_loss 8.273
2022-03-13 13:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 2020 updates
2022-03-13 13:18:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:18:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:18:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 5 @ 2020 updates, score 8.273) (writing took 2.615621429984458 seconds)
2022-03-13 13:18:58 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-13 13:18:58 | INFO | train | epoch 005 | loss 8.767 | nll_loss 8.498 | ppl 361.59 | wps 28813.8 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 2020 | lr 0.00025255 | gnorm 0.728 | loss_scale 64 | train_wall 796 | gb_free 9.7 | wall 4623
2022-03-13 13:18:58 | INFO | fairseq.trainer | begin training epoch 6
2022-03-13 13:18:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:19:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:21:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:21:57 | INFO | train_inner | epoch 006:     82 / 407 loss=8.438, nll_loss=8.152, ppl=284.5, wps=26096.3, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=2100, lr=0.000262548, gnorm=0.738, loss_scale=16, train_wall=199, gb_free=9.7, wall=4802
2022-03-13 13:25:36 | INFO | train_inner | epoch 006:    182 / 407 loss=8.307, nll_loss=8.015, ppl=258.62, wps=29880.8, ups=0.46, wpb=65536, bsz=128, num_updates=2200, lr=0.000275045, gnorm=0.701, loss_scale=16, train_wall=196, gb_free=9.7, wall=5021
2022-03-13 13:29:16 | INFO | train_inner | epoch 006:    282 / 407 loss=8.208, nll_loss=7.911, ppl=240.66, wps=29856.4, ups=0.46, wpb=65536, bsz=128, num_updates=2300, lr=0.000287543, gnorm=0.722, loss_scale=32, train_wall=196, gb_free=9.7, wall=5241
2022-03-13 13:30:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:30:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:33:00 | INFO | train_inner | epoch 006:    384 / 407 loss=8.107, nll_loss=7.805, ppl=223.6, wps=29189.1, ups=0.45, wpb=65536, bsz=128, num_updates=2400, lr=0.00030004, gnorm=0.696, loss_scale=16, train_wall=201, gb_free=9.7, wall=5465
2022-03-13 13:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:34:17 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.836 | nll_loss 7.506 | ppl 181.77 | wps 51940.9 | wpb 511.9 | bsz 1 | num_updates 2423 | best_loss 7.836
2022-03-13 13:34:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 2423 updates
2022-03-13 13:34:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:34:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:34:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 6 @ 2423 updates, score 7.836) (writing took 2.576045912981499 seconds)
2022-03-13 13:34:19 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-13 13:34:19 | INFO | train | epoch 006 | loss 8.242 | nll_loss 7.947 | ppl 246.72 | wps 28638.5 | ups 0.44 | wpb 65492.3 | bsz 127.9 | num_updates 2423 | lr 0.000302914 | gnorm 0.709 | loss_scale 16 | train_wall 798 | gb_free 9.7 | wall 5544
2022-03-13 13:34:19 | INFO | fairseq.trainer | begin training epoch 7
2022-03-13 13:34:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:37:09 | INFO | train_inner | epoch 007:     77 / 407 loss=7.981, nll_loss=7.673, ppl=204.09, wps=26266, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=2500, lr=0.000312538, gnorm=0.68, loss_scale=32, train_wall=197, gb_free=9.7, wall=5714
2022-03-13 13:40:49 | INFO | train_inner | epoch 007:    177 / 407 loss=7.909, nll_loss=7.596, ppl=193.53, wps=29871.2, ups=0.46, wpb=65536, bsz=128, num_updates=2600, lr=0.000325035, gnorm=0.7, loss_scale=64, train_wall=196, gb_free=9.7, wall=5934
2022-03-13 13:41:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:44:32 | INFO | train_inner | epoch 007:    278 / 407 loss=7.833, nll_loss=7.516, ppl=183.06, wps=29401.7, ups=0.45, wpb=65536, bsz=128, num_updates=2700, lr=0.000337533, gnorm=0.666, loss_scale=32, train_wall=199, gb_free=9.7, wall=6157
2022-03-13 13:46:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:48:15 | INFO | train_inner | epoch 007:    379 / 407 loss=7.756, nll_loss=7.435, ppl=173.09, wps=29281.7, ups=0.45, wpb=65536, bsz=128, num_updates=2800, lr=0.00035003, gnorm=0.664, loss_scale=32, train_wall=200, gb_free=9.7, wall=6380
2022-03-13 13:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:49:42 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.512 | nll_loss 7.162 | ppl 143.19 | wps 52783.4 | wpb 511.9 | bsz 1 | num_updates 2828 | best_loss 7.512
2022-03-13 13:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 2828 updates
2022-03-13 13:49:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:49:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:49:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 7 @ 2828 updates, score 7.512) (writing took 2.8067131930147298 seconds)
2022-03-13 13:49:45 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-13 13:49:45 | INFO | train | epoch 007 | loss 7.848 | nll_loss 7.532 | ppl 185.14 | wps 28648.9 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 2828 | lr 0.000353529 | gnorm 0.675 | loss_scale 32 | train_wall 801 | gb_free 9.7 | wall 6470
2022-03-13 13:49:45 | INFO | fairseq.trainer | begin training epoch 8
2022-03-13 13:49:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:51:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:52:26 | INFO | train_inner | epoch 008:     73 / 407 loss=7.65, nll_loss=7.325, ppl=160.34, wps=26030.6, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=2900, lr=0.000362528, gnorm=0.636, loss_scale=32, train_wall=199, gb_free=9.7, wall=6632
2022-03-13 13:56:05 | INFO | train_inner | epoch 008:    173 / 407 loss=7.587, nll_loss=7.259, ppl=153.22, wps=29939.2, ups=0.46, wpb=65534.2, bsz=128, num_updates=3000, lr=0.000375025, gnorm=0.624, loss_scale=32, train_wall=195, gb_free=9.7, wall=6850
2022-03-13 13:56:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:59:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:59:49 | INFO | train_inner | epoch 008:    275 / 407 loss=7.535, nll_loss=7.205, ppl=147.53, wps=29256.3, ups=0.45, wpb=65536, bsz=128, num_updates=3100, lr=0.000387523, gnorm=0.626, loss_scale=16, train_wall=200, gb_free=9.7, wall=7074
2022-03-13 14:03:28 | INFO | train_inner | epoch 008:    375 / 407 loss=7.48, nll_loss=7.147, ppl=141.76, wps=29914, ups=0.46, wpb=65536, bsz=128, num_updates=3200, lr=0.00040002, gnorm=0.606, loss_scale=16, train_wall=195, gb_free=9.7, wall=7294
2022-03-13 14:04:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:04:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:05:03 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 7.252 | nll_loss 6.889 | ppl 118.53 | wps 51885.4 | wpb 511.9 | bsz 1 | num_updates 3231 | best_loss 7.252
2022-03-13 14:05:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 3231 updates
2022-03-13 14:05:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:05:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 8 @ 3231 updates, score 7.252) (writing took 2.711326858960092 seconds)
2022-03-13 14:05:06 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-13 14:05:06 | INFO | train | epoch 008 | loss 7.542 | nll_loss 7.212 | ppl 148.31 | wps 28658.9 | ups 0.44 | wpb 65492.3 | bsz 127.9 | num_updates 3231 | lr 0.000403894 | gnorm 0.625 | loss_scale 16 | train_wall 796 | gb_free 9.7 | wall 7391
2022-03-13 14:05:06 | INFO | fairseq.trainer | begin training epoch 9
2022-03-13 14:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:07:38 | INFO | train_inner | epoch 009:     69 / 407 loss=7.38, nll_loss=7.044, ppl=131.92, wps=26140, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=3300, lr=0.000412518, gnorm=0.617, loss_scale=16, train_wall=198, gb_free=9.7, wall=7544
2022-03-13 14:11:18 | INFO | train_inner | epoch 009:    169 / 407 loss=7.321, nll_loss=6.981, ppl=126.35, wps=29847.1, ups=0.46, wpb=65536, bsz=128, num_updates=3400, lr=0.000425015, gnorm=0.596, loss_scale=32, train_wall=196, gb_free=9.7, wall=7763
2022-03-13 14:11:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:15:00 | INFO | train_inner | epoch 009:    270 / 407 loss=7.275, nll_loss=6.933, ppl=122.21, wps=29540.2, ups=0.45, wpb=65536, bsz=128, num_updates=3500, lr=0.000437513, gnorm=0.59, loss_scale=16, train_wall=198, gb_free=9.7, wall=7985
2022-03-13 14:18:39 | INFO | train_inner | epoch 009:    370 / 407 loss=7.225, nll_loss=6.881, ppl=117.88, wps=29940.4, ups=0.46, wpb=65536, bsz=128, num_updates=3600, lr=0.00045001, gnorm=0.584, loss_scale=32, train_wall=195, gb_free=9.7, wall=8204
2022-03-13 14:18:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:20:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:20:25 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.997 | nll_loss 6.623 | ppl 98.56 | wps 51935.2 | wpb 511.9 | bsz 1 | num_updates 3636 | best_loss 6.997
2022-03-13 14:20:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 3636 updates
2022-03-13 14:20:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:20:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 9 @ 3636 updates, score 6.997) (writing took 2.621989630977623 seconds)
2022-03-13 14:20:28 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-13 14:20:28 | INFO | train | epoch 009 | loss 7.281 | nll_loss 6.939 | ppl 122.71 | wps 28768.3 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 3636 | lr 0.000454509 | gnorm 0.591 | loss_scale 16 | train_wall 797 | gb_free 9.7 | wall 8313
2022-03-13 14:20:28 | INFO | fairseq.trainer | begin training epoch 10
2022-03-13 14:20:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:22:48 | INFO | train_inner | epoch 010:     64 / 407 loss=7.131, nll_loss=6.783, ppl=110.15, wps=26179.2, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=3700, lr=0.000462508, gnorm=0.577, loss_scale=16, train_wall=197, gb_free=9.7, wall=8454
2022-03-13 14:26:28 | INFO | train_inner | epoch 010:    164 / 407 loss=7.081, nll_loss=6.731, ppl=106.22, wps=29904.9, ups=0.46, wpb=65536, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.569, loss_scale=32, train_wall=196, gb_free=9.7, wall=8673
2022-03-13 14:26:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:30:11 | INFO | train_inner | epoch 010:    265 / 407 loss=7.044, nll_loss=6.693, ppl=103.43, wps=29364.3, ups=0.45, wpb=65536, bsz=128, num_updates=3900, lr=0.000487503, gnorm=0.561, loss_scale=16, train_wall=199, gb_free=9.7, wall=8896
2022-03-13 14:31:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:33:55 | INFO | train_inner | epoch 010:    366 / 407 loss=7.001, nll_loss=6.648, ppl=100.29, wps=29259.8, ups=0.45, wpb=65534.2, bsz=128, num_updates=4000, lr=0.0005, gnorm=0.555, loss_scale=16, train_wall=200, gb_free=9.7, wall=9120
2022-03-13 14:35:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:35:49 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.786 | nll_loss 6.401 | ppl 84.52 | wps 51982.6 | wpb 511.9 | bsz 1 | num_updates 4041 | best_loss 6.786
2022-03-13 14:35:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 4041 updates
2022-03-13 14:35:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:35:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:35:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 10 @ 4041 updates, score 6.786) (writing took 2.9809211940155365 seconds)
2022-03-13 14:35:52 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-13 14:35:52 | INFO | train | epoch 010 | loss 7.044 | nll_loss 6.693 | ppl 103.45 | wps 28705.6 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 4041 | lr 0.000497457 | gnorm 0.563 | loss_scale 16 | train_wall 799 | gb_free 9.7 | wall 9237
2022-03-13 14:35:52 | INFO | fairseq.trainer | begin training epoch 11
2022-03-13 14:35:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:37:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:38:03 | INFO | train_inner | epoch 011:     60 / 407 loss=6.914, nll_loss=6.558, ppl=94.2, wps=26364.9, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=4100, lr=0.000493865, gnorm=0.553, loss_scale=16, train_wall=195, gb_free=9.7, wall=9368
2022-03-13 14:41:42 | INFO | train_inner | epoch 011:    160 / 407 loss=6.865, nll_loss=6.505, ppl=90.84, wps=29937.4, ups=0.46, wpb=65536, bsz=128, num_updates=4200, lr=0.00048795, gnorm=0.534, loss_scale=16, train_wall=195, gb_free=9.7, wall=9587
2022-03-13 14:42:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:45:22 | INFO | train_inner | epoch 011:    261 / 407 loss=6.821, nll_loss=6.46, ppl=88.04, wps=29736.3, ups=0.45, wpb=65536, bsz=128, num_updates=4300, lr=0.000482243, gnorm=0.54, loss_scale=16, train_wall=197, gb_free=9.7, wall=9807
2022-03-13 14:48:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:49:07 | INFO | train_inner | epoch 011:    362 / 407 loss=6.799, nll_loss=6.438, ppl=86.69, wps=29130.9, ups=0.44, wpb=65534.2, bsz=128, num_updates=4400, lr=0.000476731, gnorm=0.532, loss_scale=16, train_wall=201, gb_free=9.7, wall=10032
2022-03-13 14:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:51:13 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.611 | nll_loss 6.216 | ppl 74.35 | wps 51699.4 | wpb 511.9 | bsz 1 | num_updates 4445 | best_loss 6.611
2022-03-13 14:51:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 4445 updates
2022-03-13 14:51:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:51:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 11 @ 4445 updates, score 6.611) (writing took 2.8398429700173438 seconds)
2022-03-13 14:51:16 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-13 14:51:16 | INFO | train | epoch 011 | loss 6.83 | nll_loss 6.469 | ppl 88.59 | wps 28638.1 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 4445 | lr 0.000474312 | gnorm 0.536 | loss_scale 16 | train_wall 799 | gb_free 9.7 | wall 10161
2022-03-13 14:51:16 | INFO | fairseq.trainer | begin training epoch 12
2022-03-13 14:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:53:17 | INFO | train_inner | epoch 012:     55 / 407 loss=6.723, nll_loss=6.358, ppl=82.04, wps=26170.8, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=4500, lr=0.000471405, gnorm=0.514, loss_scale=16, train_wall=197, gb_free=9.7, wall=10282
2022-03-13 14:54:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:56:58 | INFO | train_inner | epoch 012:    156 / 407 loss=6.672, nll_loss=6.304, ppl=79.03, wps=29653.8, ups=0.45, wpb=65534.2, bsz=128, num_updates=4600, lr=0.000466252, gnorm=0.51, loss_scale=16, train_wall=197, gb_free=9.7, wall=10503
2022-03-13 14:59:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:00:38 | INFO | train_inner | epoch 012:    257 / 407 loss=6.665, nll_loss=6.297, ppl=78.64, wps=29713.5, ups=0.45, wpb=65536, bsz=128, num_updates=4700, lr=0.000461266, gnorm=0.514, loss_scale=16, train_wall=197, gb_free=9.7, wall=10723
2022-03-13 15:04:17 | INFO | train_inner | epoch 012:    357 / 407 loss=6.642, nll_loss=6.273, ppl=77.36, wps=29964.6, ups=0.46, wpb=65536, bsz=128, num_updates=4800, lr=0.000456435, gnorm=0.503, loss_scale=32, train_wall=195, gb_free=9.7, wall=10942
2022-03-13 15:05:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:06:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:06:31 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.499 | nll_loss 6.098 | ppl 68.51 | wps 53217.7 | wpb 511.9 | bsz 1 | num_updates 4849 | best_loss 6.499
2022-03-13 15:06:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 4849 updates
2022-03-13 15:06:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:06:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 12 @ 4849 updates, score 6.499) (writing took 2.7514457009965554 seconds)
2022-03-13 15:06:34 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-13 15:06:34 | INFO | train | epoch 012 | loss 6.66 | nll_loss 6.292 | ppl 78.35 | wps 28826.8 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 4849 | lr 0.000454123 | gnorm 0.51 | loss_scale 16 | train_wall 794 | gb_free 9.7 | wall 11079
2022-03-13 15:06:34 | INFO | fairseq.trainer | begin training epoch 13
2022-03-13 15:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:08:27 | INFO | train_inner | epoch 013:     51 / 407 loss=6.585, nll_loss=6.214, ppl=74.24, wps=26186.6, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=4900, lr=0.000451754, gnorm=0.5, loss_scale=16, train_wall=198, gb_free=9.7, wall=11192
2022-03-13 15:11:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:12:08 | INFO | train_inner | epoch 013:    152 / 407 loss=6.538, nll_loss=6.165, ppl=71.76, wps=29637.4, ups=0.45, wpb=65534.2, bsz=128, num_updates=5000, lr=0.000447214, gnorm=0.49, loss_scale=16, train_wall=197, gb_free=9.7, wall=11413
2022-03-13 15:15:48 | INFO | train_inner | epoch 013:    252 / 407 loss=6.539, nll_loss=6.166, ppl=71.8, wps=29773.4, ups=0.45, wpb=65536, bsz=128, num_updates=5100, lr=0.000442807, gnorm=0.488, loss_scale=32, train_wall=197, gb_free=9.7, wall=11633
2022-03-13 15:19:26 | INFO | train_inner | epoch 013:    352 / 407 loss=6.52, nll_loss=6.147, ppl=70.84, wps=29986.5, ups=0.46, wpb=65536, bsz=128, num_updates=5200, lr=0.000438529, gnorm=0.491, loss_scale=32, train_wall=195, gb_free=9.7, wall=11851
2022-03-13 15:20:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:21:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:21:53 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.404 | nll_loss 5.999 | ppl 63.98 | wps 51976 | wpb 511.9 | bsz 1 | num_updates 5254 | best_loss 6.404
2022-03-13 15:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 5254 updates
2022-03-13 15:21:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:21:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:21:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 13 @ 5254 updates, score 6.404) (writing took 2.94999482302228 seconds)
2022-03-13 15:21:56 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-13 15:21:56 | INFO | train | epoch 013 | loss 6.53 | nll_loss 6.157 | ppl 71.34 | wps 28757.3 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 5254 | lr 0.00043627 | gnorm 0.489 | loss_scale 32 | train_wall 798 | gb_free 9.7 | wall 12001
2022-03-13 15:21:56 | INFO | fairseq.trainer | begin training epoch 14
2022-03-13 15:21:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:22:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:23:39 | INFO | train_inner | epoch 014:     47 / 407 loss=6.466, nll_loss=6.09, ppl=68.13, wps=25863.7, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=5300, lr=0.000434372, gnorm=0.486, loss_scale=16, train_wall=200, gb_free=9.7, wall=12104
2022-03-13 15:27:22 | INFO | train_inner | epoch 014:    147 / 407 loss=6.431, nll_loss=6.053, ppl=66.42, wps=29439.1, ups=0.45, wpb=65536, bsz=128, num_updates=5400, lr=0.000430331, gnorm=0.493, loss_scale=32, train_wall=199, gb_free=9.7, wall=12327
2022-03-13 15:31:02 | INFO | train_inner | epoch 014:    247 / 407 loss=6.43, nll_loss=6.053, ppl=66.39, wps=29694.8, ups=0.45, wpb=65536, bsz=128, num_updates=5500, lr=0.000426401, gnorm=0.483, loss_scale=32, train_wall=197, gb_free=9.7, wall=12547
2022-03-13 15:31:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:32:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:34:45 | INFO | train_inner | epoch 014:    349 / 407 loss=6.425, nll_loss=6.048, ppl=66.15, wps=29486.2, ups=0.45, wpb=65536, bsz=128, num_updates=5600, lr=0.000422577, gnorm=0.483, loss_scale=16, train_wall=198, gb_free=9.7, wall=12770
2022-03-13 15:36:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:37:17 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.334 | nll_loss 5.926 | ppl 60.79 | wps 52674.6 | wpb 511.9 | bsz 1 | num_updates 5658 | best_loss 6.334
2022-03-13 15:37:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 5658 updates
2022-03-13 15:37:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:37:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:37:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 14 @ 5658 updates, score 6.334) (writing took 2.449286632996518 seconds)
2022-03-13 15:37:19 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-13 15:37:19 | INFO | train | epoch 014 | loss 6.425 | nll_loss 6.048 | ppl 66.16 | wps 28667.2 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 5658 | lr 0.000420406 | gnorm 0.486 | loss_scale 16 | train_wall 799 | gb_free 9.7 | wall 12924
2022-03-13 15:37:19 | INFO | fairseq.trainer | begin training epoch 15
2022-03-13 15:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:38:52 | INFO | train_inner | epoch 015:     42 / 407 loss=6.384, nll_loss=6.005, ppl=64.24, wps=26404.7, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=5700, lr=0.000418854, gnorm=0.482, loss_scale=32, train_wall=196, gb_free=9.7, wall=13017
2022-03-13 15:39:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:42:36 | INFO | train_inner | epoch 015:    143 / 407 loss=6.352, nll_loss=5.971, ppl=62.74, wps=29262.3, ups=0.45, wpb=65536, bsz=128, num_updates=5800, lr=0.000415227, gnorm=0.485, loss_scale=16, train_wall=200, gb_free=9.7, wall=13241
2022-03-13 15:44:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:46:18 | INFO | train_inner | epoch 015:    244 / 407 loss=6.342, nll_loss=5.961, ppl=62.31, wps=29560, ups=0.45, wpb=65536, bsz=128, num_updates=5900, lr=0.000411693, gnorm=0.481, loss_scale=16, train_wall=198, gb_free=9.7, wall=13463
2022-03-13 15:49:56 | INFO | train_inner | epoch 015:    344 / 407 loss=6.337, nll_loss=5.956, ppl=62.06, wps=30105, ups=0.46, wpb=65534.2, bsz=128, num_updates=6000, lr=0.000408248, gnorm=0.478, loss_scale=32, train_wall=194, gb_free=9.7, wall=13681
2022-03-13 15:50:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:52:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:52:38 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.27 | nll_loss 5.858 | ppl 58 | wps 52118.2 | wpb 511.9 | bsz 1 | num_updates 6062 | best_loss 6.27
2022-03-13 15:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 6062 updates
2022-03-13 15:52:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:52:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 15 @ 6062 updates, score 6.27) (writing took 2.4827797379693948 seconds)
2022-03-13 15:52:41 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-13 15:52:41 | INFO | train | epoch 015 | loss 6.341 | nll_loss 5.96 | ppl 62.24 | wps 28708 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 6062 | lr 0.000406155 | gnorm 0.482 | loss_scale 16 | train_wall 797 | gb_free 9.7 | wall 13846
2022-03-13 15:52:41 | INFO | fairseq.trainer | begin training epoch 16
2022-03-13 15:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:54:03 | INFO | train_inner | epoch 016:     38 / 407 loss=6.298, nll_loss=5.915, ppl=60.33, wps=26376.9, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=6100, lr=0.000404888, gnorm=0.482, loss_scale=16, train_wall=196, gb_free=9.7, wall=13928
2022-03-13 15:57:42 | INFO | train_inner | epoch 016:    138 / 407 loss=6.271, nll_loss=5.887, ppl=59.18, wps=29982.3, ups=0.46, wpb=65534.2, bsz=128, num_updates=6200, lr=0.00040161, gnorm=0.483, loss_scale=32, train_wall=195, gb_free=9.7, wall=14147
2022-03-13 16:00:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:01:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:01:26 | INFO | train_inner | epoch 016:    240 / 407 loss=6.275, nll_loss=5.891, ppl=59.33, wps=29307.1, ups=0.45, wpb=65536, bsz=128, num_updates=6300, lr=0.00039841, gnorm=0.477, loss_scale=16, train_wall=200, gb_free=9.7, wall=14371
2022-03-13 16:05:04 | INFO | train_inner | epoch 016:    340 / 407 loss=6.264, nll_loss=5.879, ppl=58.86, wps=30043.1, ups=0.46, wpb=65536, bsz=128, num_updates=6400, lr=0.000395285, gnorm=0.476, loss_scale=16, train_wall=195, gb_free=9.7, wall=14589
2022-03-13 16:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:07:55 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.217 | nll_loss 5.803 | ppl 55.83 | wps 52186 | wpb 511.9 | bsz 1 | num_updates 6467 | best_loss 6.217
2022-03-13 16:07:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 6467 updates
2022-03-13 16:07:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:07:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:07:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 16 @ 6467 updates, score 6.217) (writing took 2.456484703987371 seconds)
2022-03-13 16:07:57 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-13 16:07:57 | INFO | train | epoch 016 | loss 6.267 | nll_loss 5.883 | ppl 59.02 | wps 28952.2 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 6467 | lr 0.000393232 | gnorm 0.478 | loss_scale 32 | train_wall 792 | gb_free 9.7 | wall 14762
2022-03-13 16:07:57 | INFO | fairseq.trainer | begin training epoch 17
2022-03-13 16:07:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:09:10 | INFO | train_inner | epoch 017:     33 / 407 loss=6.245, nll_loss=5.86, ppl=58.08, wps=26521.6, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=6500, lr=0.000392232, gnorm=0.473, loss_scale=32, train_wall=195, gb_free=9.7, wall=14835
2022-03-13 16:11:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:12:50 | INFO | train_inner | epoch 017:    134 / 407 loss=6.2, nll_loss=5.813, ppl=56.21, wps=29818.6, ups=0.46, wpb=65534.2, bsz=128, num_updates=6600, lr=0.000389249, gnorm=0.475, loss_scale=32, train_wall=196, gb_free=9.7, wall=15055
2022-03-13 16:15:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:16:30 | INFO | train_inner | epoch 017:    235 / 407 loss=6.205, nll_loss=5.818, ppl=56.41, wps=29735.6, ups=0.45, wpb=65536, bsz=128, num_updates=6700, lr=0.000386334, gnorm=0.485, loss_scale=16, train_wall=197, gb_free=9.7, wall=15275
2022-03-13 16:20:12 | INFO | train_inner | epoch 017:    335 / 407 loss=6.206, nll_loss=5.819, ppl=56.46, wps=29580.7, ups=0.45, wpb=65536, bsz=128, num_updates=6800, lr=0.000383482, gnorm=0.484, loss_scale=16, train_wall=198, gb_free=9.7, wall=15497
2022-03-13 16:21:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:22:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:23:15 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.172 | nll_loss 5.755 | ppl 54.02 | wps 51856.4 | wpb 511.9 | bsz 1 | num_updates 6871 | best_loss 6.172
2022-03-13 16:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 6871 updates
2022-03-13 16:23:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:23:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 17 @ 6871 updates, score 6.172) (writing took 2.659529470023699 seconds)
2022-03-13 16:23:18 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-13 16:23:18 | INFO | train | epoch 017 | loss 6.205 | nll_loss 5.818 | ppl 56.42 | wps 28729.8 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 6871 | lr 0.000381496 | gnorm 0.481 | loss_scale 16 | train_wall 796 | gb_free 9.7 | wall 15683
2022-03-13 16:23:18 | INFO | fairseq.trainer | begin training epoch 18
2022-03-13 16:23:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:24:22 | INFO | train_inner | epoch 018:     29 / 407 loss=6.188, nll_loss=5.8, ppl=55.72, wps=26085.6, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=6900, lr=0.000380693, gnorm=0.483, loss_scale=16, train_wall=198, gb_free=9.7, wall=15747
2022-03-13 16:28:01 | INFO | train_inner | epoch 018:    129 / 407 loss=6.14, nll_loss=5.75, ppl=53.82, wps=30000.2, ups=0.46, wpb=65534.2, bsz=128, num_updates=7000, lr=0.000377964, gnorm=0.469, loss_scale=32, train_wall=195, gb_free=9.7, wall=15966
2022-03-13 16:31:38 | INFO | train_inner | epoch 018:    229 / 407 loss=6.154, nll_loss=5.765, ppl=54.39, wps=30118.4, ups=0.46, wpb=65536, bsz=128, num_updates=7100, lr=0.000375293, gnorm=0.473, loss_scale=32, train_wall=194, gb_free=9.7, wall=16184
2022-03-13 16:31:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:32:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:35:24 | INFO | train_inner | epoch 018:    331 / 407 loss=6.154, nll_loss=5.765, ppl=54.37, wps=29083.3, ups=0.44, wpb=65536, bsz=128, num_updates=7200, lr=0.000372678, gnorm=0.478, loss_scale=16, train_wall=201, gb_free=9.7, wall=16409
2022-03-13 16:38:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:38:38 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.136 | nll_loss 5.719 | ppl 52.66 | wps 51760.6 | wpb 511.9 | bsz 1 | num_updates 7276 | best_loss 6.136
2022-03-13 16:38:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 7276 updates
2022-03-13 16:38:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:38:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 18 @ 7276 updates, score 6.136) (writing took 2.938756939023733 seconds)
2022-03-13 16:38:41 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-13 16:38:41 | INFO | train | epoch 018 | loss 6.151 | nll_loss 5.761 | ppl 54.24 | wps 28735.2 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 7276 | lr 0.000370727 | gnorm 0.477 | loss_scale 32 | train_wall 798 | gb_free 9.7 | wall 16606
2022-03-13 16:38:41 | INFO | fairseq.trainer | begin training epoch 19
2022-03-13 16:38:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:39:34 | INFO | train_inner | epoch 019:     24 / 407 loss=6.148, nll_loss=5.758, ppl=54.13, wps=26102.8, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=7300, lr=0.000370117, gnorm=0.486, loss_scale=32, train_wall=198, gb_free=9.7, wall=16659
2022-03-13 16:42:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:42:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:43:19 | INFO | train_inner | epoch 019:    126 / 407 loss=6.092, nll_loss=5.7, ppl=51.99, wps=29179.9, ups=0.45, wpb=65536, bsz=128, num_updates=7400, lr=0.000367607, gnorm=0.481, loss_scale=16, train_wall=200, gb_free=9.7, wall=16884
2022-03-13 16:46:58 | INFO | train_inner | epoch 019:    226 / 407 loss=6.097, nll_loss=5.705, ppl=52.17, wps=29914, ups=0.46, wpb=65534.2, bsz=128, num_updates=7500, lr=0.000365148, gnorm=0.473, loss_scale=16, train_wall=196, gb_free=9.7, wall=17103
2022-03-13 16:47:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:50:38 | INFO | train_inner | epoch 019:    327 / 407 loss=6.11, nll_loss=5.719, ppl=52.67, wps=29799, ups=0.45, wpb=65536, bsz=128, num_updates=7600, lr=0.000362738, gnorm=0.475, loss_scale=16, train_wall=196, gb_free=9.7, wall=17323
2022-03-13 16:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:53:58 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.105 | nll_loss 5.684 | ppl 51.43 | wps 52256.6 | wpb 511.9 | bsz 1 | num_updates 7680 | best_loss 6.105
2022-03-13 16:53:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 7680 updates
2022-03-13 16:53:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:53:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:54:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 19 @ 7680 updates, score 6.105) (writing took 2.5806870100204833 seconds)
2022-03-13 16:54:01 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-13 16:54:01 | INFO | train | epoch 019 | loss 6.102 | nll_loss 5.711 | ppl 52.36 | wps 28777.2 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 7680 | lr 0.000360844 | gnorm 0.476 | loss_scale 32 | train_wall 795 | gb_free 9.7 | wall 17526
2022-03-13 16:54:01 | INFO | fairseq.trainer | begin training epoch 20
2022-03-13 16:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:54:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:54:46 | INFO | train_inner | epoch 020:     21 / 407 loss=6.098, nll_loss=5.707, ppl=52.22, wps=26329.8, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=7700, lr=0.000360375, gnorm=0.474, loss_scale=16, train_wall=196, gb_free=9.7, wall=17571
2022-03-13 16:58:25 | INFO | train_inner | epoch 020:    121 / 407 loss=6.042, nll_loss=5.648, ppl=50.14, wps=29924.9, ups=0.46, wpb=65534.2, bsz=128, num_updates=7800, lr=0.000358057, gnorm=0.475, loss_scale=16, train_wall=195, gb_free=9.7, wall=17790
2022-03-13 17:02:02 | INFO | train_inner | epoch 020:    221 / 407 loss=6.066, nll_loss=5.673, ppl=51.03, wps=30170.9, ups=0.46, wpb=65536, bsz=128, num_updates=7900, lr=0.000355784, gnorm=0.475, loss_scale=32, train_wall=194, gb_free=9.7, wall=18007
2022-03-13 17:02:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:05:43 | INFO | train_inner | epoch 020:    322 / 407 loss=6.065, nll_loss=5.672, ppl=50.98, wps=29679.5, ups=0.45, wpb=65536, bsz=128, num_updates=8000, lr=0.000353553, gnorm=0.475, loss_scale=16, train_wall=197, gb_free=9.7, wall=18228
2022-03-13 17:08:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:09:14 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.076 | nll_loss 5.655 | ppl 50.4 | wps 51893.5 | wpb 511.9 | bsz 1 | num_updates 8085 | best_loss 6.076
2022-03-13 17:09:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 8085 updates
2022-03-13 17:09:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:09:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:09:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 20 @ 8085 updates, score 6.076) (writing took 2.6793551290174946 seconds)
2022-03-13 17:09:17 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-13 17:09:17 | INFO | train | epoch 020 | loss 6.059 | nll_loss 5.666 | ppl 50.77 | wps 28941.8 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 8085 | lr 0.00035169 | gnorm 0.476 | loss_scale 32 | train_wall 792 | gb_free 9.7 | wall 18442
2022-03-13 17:09:17 | INFO | fairseq.trainer | begin training epoch 21
2022-03-13 17:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:09:51 | INFO | train_inner | epoch 021:     15 / 407 loss=6.057, nll_loss=5.664, ppl=50.71, wps=26406.4, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=8100, lr=0.000351364, gnorm=0.478, loss_scale=32, train_wall=196, gb_free=9.7, wall=18476
2022-03-13 17:11:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:13:35 | INFO | train_inner | epoch 021:    116 / 407 loss=6.002, nll_loss=5.606, ppl=48.72, wps=29198, ups=0.45, wpb=65536, bsz=128, num_updates=8200, lr=0.000349215, gnorm=0.478, loss_scale=16, train_wall=201, gb_free=9.7, wall=18700
2022-03-13 17:17:17 | INFO | train_inner | epoch 021:    216 / 407 loss=6.025, nll_loss=5.63, ppl=49.52, wps=29591.8, ups=0.45, wpb=65536, bsz=128, num_updates=8300, lr=0.000347105, gnorm=0.476, loss_scale=32, train_wall=198, gb_free=9.7, wall=18922
2022-03-13 17:20:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:20:54 | INFO | train_inner | epoch 021:    317 / 407 loss=6.026, nll_loss=5.631, ppl=49.56, wps=30156.7, ups=0.46, wpb=65536, bsz=128, num_updates=8400, lr=0.000345033, gnorm=0.478, loss_scale=32, train_wall=194, gb_free=9.7, wall=19139
2022-03-13 17:23:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:24:31 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 6.045 | nll_loss 5.623 | ppl 49.27 | wps 53575.6 | wpb 511.9 | bsz 1 | num_updates 8489 | best_loss 6.045
2022-03-13 17:24:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 8489 updates
2022-03-13 17:24:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:24:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 21 @ 8489 updates, score 6.045) (writing took 2.6419103739899583 seconds)
2022-03-13 17:24:34 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-13 17:24:34 | INFO | train | epoch 021 | loss 6.021 | nll_loss 5.626 | ppl 49.37 | wps 28854.6 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 8489 | lr 0.000343219 | gnorm 0.477 | loss_scale 16 | train_wall 794 | gb_free 9.7 | wall 19359
2022-03-13 17:24:34 | INFO | fairseq.trainer | begin training epoch 22
2022-03-13 17:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:24:58 | INFO | train_inner | epoch 022:     11 / 407 loss=6.029, nll_loss=5.635, ppl=49.69, wps=26814.6, ups=0.41, wpb=65360.1, bsz=127.7, num_updates=8500, lr=0.000342997, gnorm=0.478, loss_scale=16, train_wall=192, gb_free=9.7, wall=19383
2022-03-13 17:28:31 | INFO | train_inner | epoch 022:    111 / 407 loss=5.969, nll_loss=5.572, ppl=47.57, wps=30678.3, ups=0.47, wpb=65536, bsz=128, num_updates=8600, lr=0.000340997, gnorm=0.484, loss_scale=16, train_wall=190, gb_free=9.7, wall=19596
2022-03-13 17:28:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:32:08 | INFO | train_inner | epoch 022:    212 / 407 loss=5.981, nll_loss=5.584, ppl=47.95, wps=30198.7, ups=0.46, wpb=65534.2, bsz=128, num_updates=8700, lr=0.000339032, gnorm=0.48, loss_scale=16, train_wall=193, gb_free=9.7, wall=19813
2022-03-13 17:35:44 | INFO | train_inner | epoch 022:    312 / 407 loss=5.997, nll_loss=5.601, ppl=48.53, wps=30442, ups=0.46, wpb=65536, bsz=128, num_updates=8800, lr=0.0003371, gnorm=0.481, loss_scale=32, train_wall=192, gb_free=9.7, wall=20029
2022-03-13 17:38:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:39:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:39:32 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 6.027 | nll_loss 5.604 | ppl 48.64 | wps 53305.3 | wpb 511.9 | bsz 1 | num_updates 8894 | best_loss 6.027
2022-03-13 17:39:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 8894 updates
2022-03-13 17:39:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:39:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:39:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 22 @ 8894 updates, score 6.027) (writing took 2.7504149840096943 seconds)
2022-03-13 17:39:35 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-13 17:39:35 | INFO | train | epoch 022 | loss 5.985 | nll_loss 5.589 | ppl 48.12 | wps 29434.8 | ups 0.45 | wpb 65492.6 | bsz 127.9 | num_updates 8894 | lr 0.000335314 | gnorm 0.481 | loss_scale 32 | train_wall 778 | gb_free 9.7 | wall 20260
2022-03-13 17:39:35 | INFO | fairseq.trainer | begin training epoch 23
2022-03-13 17:39:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:39:48 | INFO | train_inner | epoch 023:      6 / 407 loss=5.995, nll_loss=5.599, ppl=48.47, wps=26746.2, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=8900, lr=0.000335201, gnorm=0.477, loss_scale=32, train_wall=193, gb_free=9.7, wall=20273
2022-03-13 17:41:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:43:26 | INFO | train_inner | epoch 023:    107 / 407 loss=5.93, nll_loss=5.531, ppl=46.23, wps=29994, ups=0.46, wpb=65536, bsz=128, num_updates=9000, lr=0.000333333, gnorm=0.478, loss_scale=16, train_wall=195, gb_free=9.7, wall=20491
2022-03-13 17:46:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:47:04 | INFO | train_inner | epoch 023:    208 / 407 loss=5.948, nll_loss=5.549, ppl=46.83, wps=30140, ups=0.46, wpb=65536, bsz=128, num_updates=9100, lr=0.000331497, gnorm=0.482, loss_scale=16, train_wall=194, gb_free=9.7, wall=20709
2022-03-13 17:50:40 | INFO | train_inner | epoch 023:    308 / 407 loss=5.974, nll_loss=5.577, ppl=47.73, wps=30344.3, ups=0.46, wpb=65534.2, bsz=128, num_updates=9200, lr=0.00032969, gnorm=0.477, loss_scale=16, train_wall=193, gb_free=9.7, wall=20925
2022-03-13 17:54:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:54:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:54:39 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 6.009 | nll_loss 5.585 | ppl 48.01 | wps 53040.4 | wpb 511.9 | bsz 1 | num_updates 9298 | best_loss 6.009
2022-03-13 17:54:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 9298 updates
2022-03-13 17:54:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:54:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:54:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 23 @ 9298 updates, score 6.009) (writing took 2.2875203620060347 seconds)
2022-03-13 17:54:41 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-13 17:54:41 | INFO | train | epoch 023 | loss 5.954 | nll_loss 5.556 | ppl 47.03 | wps 29211.6 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 9298 | lr 0.000327948 | gnorm 0.478 | loss_scale 16 | train_wall 783 | gb_free 9.7 | wall 21166
2022-03-13 17:54:41 | INFO | fairseq.trainer | begin training epoch 24
2022-03-13 17:54:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:54:45 | INFO | train_inner | epoch 024:      2 / 407 loss=5.961, nll_loss=5.564, ppl=47.31, wps=26622, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=9300, lr=0.000327913, gnorm=0.474, loss_scale=16, train_wall=194, gb_free=9.7, wall=21170
2022-03-13 17:58:19 | INFO | train_inner | epoch 024:    102 / 407 loss=5.901, nll_loss=5.5, ppl=45.27, wps=30739.9, ups=0.47, wpb=65534.2, bsz=128, num_updates=9400, lr=0.000326164, gnorm=0.483, loss_scale=16, train_wall=190, gb_free=9.7, wall=21384
2022-03-13 18:01:54 | INFO | train_inner | epoch 024:    202 / 407 loss=5.921, nll_loss=5.522, ppl=45.94, wps=30402.5, ups=0.46, wpb=65536, bsz=128, num_updates=9500, lr=0.000324443, gnorm=0.48, loss_scale=32, train_wall=192, gb_free=9.7, wall=21599
2022-03-13 18:03:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:03:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:05:33 | INFO | train_inner | epoch 024:    304 / 407 loss=5.93, nll_loss=5.531, ppl=46.24, wps=29962.6, ups=0.46, wpb=65536, bsz=128, num_updates=9600, lr=0.000322749, gnorm=0.478, loss_scale=16, train_wall=195, gb_free=9.7, wall=21818
2022-03-13 18:09:09 | INFO | train_inner | epoch 024:    404 / 407 loss=5.944, nll_loss=5.546, ppl=46.72, wps=30302.9, ups=0.46, wpb=65536, bsz=128, num_updates=9700, lr=0.000321081, gnorm=0.477, loss_scale=32, train_wall=193, gb_free=9.7, wall=22034
2022-03-13 18:09:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:09:40 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 5.988 | nll_loss 5.563 | ppl 47.29 | wps 52933.5 | wpb 511.9 | bsz 1 | num_updates 9703 | best_loss 5.988
2022-03-13 18:09:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 9703 updates
2022-03-13 18:09:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:09:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:09:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 24 @ 9703 updates, score 5.988) (writing took 2.3962172060273588 seconds)
2022-03-13 18:09:43 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-13 18:09:43 | INFO | train | epoch 024 | loss 5.924 | nll_loss 5.525 | ppl 46.05 | wps 29413 | ups 0.45 | wpb 65492.6 | bsz 127.9 | num_updates 9703 | lr 0.000321031 | gnorm 0.48 | loss_scale 32 | train_wall 779 | gb_free 9.7 | wall 22068
2022-03-13 18:09:43 | INFO | fairseq.trainer | begin training epoch 25
2022-03-13 18:09:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:11:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:13:14 | INFO | train_inner | epoch 025:     98 / 407 loss=5.879, nll_loss=5.477, ppl=44.54, wps=26688.2, ups=0.41, wpb=65360.1, bsz=127.7, num_updates=9800, lr=0.000319438, gnorm=0.485, loss_scale=16, train_wall=193, gb_free=9.7, wall=22279
2022-03-13 18:16:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:17:11 | INFO | train_inner | epoch 025:    199 / 407 loss=5.886, nll_loss=5.485, ppl=44.77, wps=27660.1, ups=0.42, wpb=65536, bsz=128, num_updates=9900, lr=0.000317821, gnorm=0.48, loss_scale=16, train_wall=213, gb_free=9.7, wall=22516
2022-03-13 18:21:03 | INFO | train_inner | epoch 025:    299 / 407 loss=5.916, nll_loss=5.516, ppl=45.77, wps=28242.7, ups=0.43, wpb=65536, bsz=128, num_updates=10000, lr=0.000316228, gnorm=0.482, loss_scale=16, train_wall=208, gb_free=9.7, wall=22748
2022-03-13 18:21:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:24:58 | INFO | train_inner | epoch 025:    400 / 407 loss=5.912, nll_loss=5.512, ppl=45.65, wps=27840.3, ups=0.42, wpb=65536, bsz=128, num_updates=10100, lr=0.000314658, gnorm=0.482, loss_scale=16, train_wall=212, gb_free=9.7, wall=22983
2022-03-13 18:25:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:25:41 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 5.967 | nll_loss 5.54 | ppl 46.52 | wps 49707.1 | wpb 511.9 | bsz 1 | num_updates 10107 | best_loss 5.967
2022-03-13 18:25:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 10107 updates
2022-03-13 18:25:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:25:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:25:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 25 @ 10107 updates, score 5.967) (writing took 2.2687503800261766 seconds)
2022-03-13 18:25:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-13 18:25:44 | INFO | train | epoch 025 | loss 5.898 | nll_loss 5.497 | ppl 45.16 | wps 27535.3 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 10107 | lr 0.000314549 | gnorm 0.482 | loss_scale 16 | train_wall 836 | gb_free 9.7 | wall 23029
2022-03-13 18:25:44 | INFO | fairseq.trainer | begin training epoch 26
2022-03-13 18:25:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:29:20 | INFO | train_inner | epoch 026:     93 / 407 loss=5.855, nll_loss=5.452, ppl=43.77, wps=24958.1, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=10200, lr=0.000313112, gnorm=0.481, loss_scale=32, train_wall=209, gb_free=9.7, wall=23245
2022-03-13 18:32:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:33:18 | INFO | train_inner | epoch 026:    194 / 407 loss=5.869, nll_loss=5.467, ppl=44.22, wps=27611.4, ups=0.42, wpb=65536, bsz=128, num_updates=10300, lr=0.000311588, gnorm=0.48, loss_scale=32, train_wall=214, gb_free=9.7, wall=23483
2022-03-13 18:34:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:37:14 | INFO | train_inner | epoch 026:    295 / 407 loss=5.87, nll_loss=5.468, ppl=44.27, wps=27768.1, ups=0.42, wpb=65534.2, bsz=128, num_updates=10400, lr=0.000310087, gnorm=0.484, loss_scale=16, train_wall=212, gb_free=9.7, wall=23719
2022-03-13 18:41:07 | INFO | train_inner | epoch 026:    395 / 407 loss=5.893, nll_loss=5.493, ppl=45.02, wps=28114.4, ups=0.43, wpb=65536, bsz=128, num_updates=10500, lr=0.000308607, gnorm=0.48, loss_scale=32, train_wall=210, gb_free=9.7, wall=23952
2022-03-13 18:41:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:42:00 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 5.96 | nll_loss 5.533 | ppl 46.31 | wps 51640.4 | wpb 511.9 | bsz 1 | num_updates 10512 | best_loss 5.96
2022-03-13 18:42:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 10512 updates
2022-03-13 18:42:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:42:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:42:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 26 @ 10512 updates, score 5.96) (writing took 2.289015294983983 seconds)
2022-03-13 18:42:02 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-13 18:42:02 | INFO | train | epoch 026 | loss 5.872 | nll_loss 5.47 | ppl 44.34 | wps 27105.9 | ups 0.41 | wpb 65492.6 | bsz 127.9 | num_updates 10512 | lr 0.000308431 | gnorm 0.481 | loss_scale 32 | train_wall 855 | gb_free 9.7 | wall 24007
2022-03-13 18:42:02 | INFO | fairseq.trainer | begin training epoch 27
2022-03-13 18:42:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:45:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:45:29 | INFO | train_inner | epoch 027:     89 / 407 loss=5.836, nll_loss=5.432, ppl=43.18, wps=24904.1, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=10600, lr=0.000307148, gnorm=0.486, loss_scale=32, train_wall=210, gb_free=9.7, wall=24214
2022-03-13 18:48:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:49:23 | INFO | train_inner | epoch 027:    190 / 407 loss=5.849, nll_loss=5.446, ppl=43.59, wps=27992.1, ups=0.43, wpb=65536, bsz=128, num_updates=10700, lr=0.000305709, gnorm=0.485, loss_scale=16, train_wall=210, gb_free=9.7, wall=24448
2022-03-13 18:53:13 | INFO | train_inner | epoch 027:    290 / 407 loss=5.849, nll_loss=5.446, ppl=43.59, wps=28491.7, ups=0.43, wpb=65536, bsz=128, num_updates=10800, lr=0.00030429, gnorm=0.488, loss_scale=32, train_wall=206, gb_free=9.7, wall=24678
2022-03-13 18:53:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:57:08 | INFO | train_inner | epoch 027:    391 / 407 loss=5.871, nll_loss=5.469, ppl=44.3, wps=27955.9, ups=0.43, wpb=65536, bsz=128, num_updates=10900, lr=0.000302891, gnorm=0.479, loss_scale=16, train_wall=211, gb_free=9.7, wall=24913
2022-03-13 18:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:58:10 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 5.936 | nll_loss 5.508 | ppl 45.52 | wps 50558.1 | wpb 511.9 | bsz 1 | num_updates 10916 | best_loss 5.936
2022-03-13 18:58:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 10916 updates
2022-03-13 18:58:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:58:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:58:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 27 @ 10916 updates, score 5.936) (writing took 2.239053398021497 seconds)
2022-03-13 18:58:13 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-13 18:58:13 | INFO | train | epoch 027 | loss 5.849 | nll_loss 5.447 | ppl 43.61 | wps 27261.3 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 10916 | lr 0.000302669 | gnorm 0.485 | loss_scale 16 | train_wall 846 | gb_free 9.7 | wall 24978
2022-03-13 18:58:13 | INFO | fairseq.trainer | begin training epoch 28
2022-03-13 18:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:01:28 | INFO | train_inner | epoch 028:     84 / 407 loss=5.803, nll_loss=5.398, ppl=42.17, wps=25155.7, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=11000, lr=0.000301511, gnorm=0.487, loss_scale=32, train_wall=207, gb_free=9.7, wall=25173
2022-03-13 19:01:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:05:22 | INFO | train_inner | epoch 028:    185 / 407 loss=5.817, nll_loss=5.412, ppl=42.58, wps=27957.9, ups=0.43, wpb=65536, bsz=128, num_updates=11100, lr=0.00030015, gnorm=0.487, loss_scale=16, train_wall=211, gb_free=9.7, wall=25407
2022-03-13 19:09:16 | INFO | train_inner | epoch 028:    285 / 407 loss=5.843, nll_loss=5.44, ppl=43.4, wps=28051.8, ups=0.43, wpb=65536, bsz=128, num_updates=11200, lr=0.000298807, gnorm=0.481, loss_scale=32, train_wall=210, gb_free=9.7, wall=25641
2022-03-13 19:11:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:13:12 | INFO | train_inner | epoch 028:    386 / 407 loss=5.845, nll_loss=5.442, ppl=43.46, wps=27680.5, ups=0.42, wpb=65536, bsz=128, num_updates=11300, lr=0.000297482, gnorm=0.484, loss_scale=32, train_wall=213, gb_free=9.7, wall=25877
2022-03-13 19:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:14:27 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 5.926 | nll_loss 5.498 | ppl 45.18 | wps 51866.4 | wpb 511.9 | bsz 1 | num_updates 11321 | best_loss 5.926
2022-03-13 19:14:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 11321 updates
2022-03-13 19:14:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:14:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:14:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 28 @ 11321 updates, score 5.926) (writing took 2.367811302014161 seconds)
2022-03-13 19:14:30 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-13 19:14:30 | INFO | train | epoch 028 | loss 5.828 | nll_loss 5.424 | ppl 42.92 | wps 27147.2 | ups 0.41 | wpb 65492.6 | bsz 127.9 | num_updates 11321 | lr 0.000297206 | gnorm 0.484 | loss_scale 32 | train_wall 853 | gb_free 9.7 | wall 25955
2022-03-13 19:14:30 | INFO | fairseq.trainer | begin training epoch 29
2022-03-13 19:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:15:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:17:36 | INFO | train_inner | epoch 029:     80 / 407 loss=5.799, nll_loss=5.393, ppl=42.03, wps=24812.8, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=11400, lr=0.000296174, gnorm=0.48, loss_scale=16, train_wall=211, gb_free=9.7, wall=26141
2022-03-13 19:21:29 | INFO | train_inner | epoch 029:    180 / 407 loss=5.812, nll_loss=5.408, ppl=42.45, wps=28123.9, ups=0.43, wpb=65534.2, bsz=128, num_updates=11500, lr=0.000294884, gnorm=0.484, loss_scale=32, train_wall=209, gb_free=9.7, wall=26374
2022-03-13 19:25:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:25:26 | INFO | train_inner | epoch 029:    281 / 407 loss=5.8, nll_loss=5.395, ppl=42.09, wps=27587.5, ups=0.42, wpb=65536, bsz=128, num_updates=11600, lr=0.00029361, gnorm=0.485, loss_scale=32, train_wall=214, gb_free=9.7, wall=26611
2022-03-13 19:28:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:29:24 | INFO | train_inner | epoch 029:    382 / 407 loss=5.823, nll_loss=5.419, ppl=42.77, wps=27518.1, ups=0.42, wpb=65536, bsz=128, num_updates=11700, lr=0.000292353, gnorm=0.483, loss_scale=16, train_wall=214, gb_free=9.7, wall=26850
2022-03-13 19:30:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:30:49 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 5.915 | nll_loss 5.485 | ppl 44.79 | wps 51144.9 | wpb 511.9 | bsz 1 | num_updates 11725 | best_loss 5.915
2022-03-13 19:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 11725 updates
2022-03-13 19:30:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:30:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:30:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 29 @ 11725 updates, score 5.915) (writing took 2.49503457400715 seconds)
2022-03-13 19:30:51 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-13 19:30:51 | INFO | train | epoch 029 | loss 5.808 | nll_loss 5.403 | ppl 42.31 | wps 26962.6 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 11725 | lr 0.000292041 | gnorm 0.484 | loss_scale 16 | train_wall 856 | gb_free 9.7 | wall 26936
2022-03-13 19:30:51 | INFO | fairseq.trainer | begin training epoch 30
2022-03-13 19:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:33:47 | INFO | train_inner | epoch 030:     75 / 407 loss=5.785, nll_loss=5.379, ppl=41.61, wps=24941.6, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=11800, lr=0.000291111, gnorm=0.485, loss_scale=16, train_wall=210, gb_free=9.7, wall=27112
2022-03-13 19:34:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:37:39 | INFO | train_inner | epoch 030:    176 / 407 loss=5.775, nll_loss=5.368, ppl=41.3, wps=28211, ups=0.43, wpb=65536, bsz=128, num_updates=11900, lr=0.000289886, gnorm=0.489, loss_scale=16, train_wall=208, gb_free=9.7, wall=27344
2022-03-13 19:41:27 | INFO | train_inner | epoch 030:    276 / 407 loss=5.795, nll_loss=5.39, ppl=41.93, wps=28668.2, ups=0.44, wpb=65536, bsz=128, num_updates=12000, lr=0.000288675, gnorm=0.482, loss_scale=32, train_wall=205, gb_free=9.7, wall=27573
2022-03-13 19:44:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:45:29 | INFO | train_inner | epoch 030:    377 / 407 loss=5.805, nll_loss=5.4, ppl=42.22, wps=27087.9, ups=0.41, wpb=65536, bsz=128, num_updates=12100, lr=0.00028748, gnorm=0.491, loss_scale=32, train_wall=218, gb_free=9.7, wall=27814
2022-03-13 19:45:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:46:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:47:05 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 5.905 | nll_loss 5.476 | ppl 44.52 | wps 49774.1 | wpb 511.9 | bsz 1 | num_updates 12129 | best_loss 5.905
2022-03-13 19:47:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 12129 updates
2022-03-13 19:47:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:47:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:47:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 30 @ 12129 updates, score 5.905) (writing took 2.3482775110169314 seconds)
2022-03-13 19:47:07 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-13 19:47:07 | INFO | train | epoch 030 | loss 5.789 | nll_loss 5.383 | ppl 41.73 | wps 27110.4 | ups 0.41 | wpb 65492.9 | bsz 127.9 | num_updates 12129 | lr 0.000287136 | gnorm 0.487 | loss_scale 16 | train_wall 850 | gb_free 9.7 | wall 27912
2022-03-13 19:47:07 | INFO | fairseq.trainer | begin training epoch 31
2022-03-13 19:47:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:49:54 | INFO | train_inner | epoch 031:     71 / 407 loss=5.753, nll_loss=5.346, ppl=40.67, wps=24697.7, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=12200, lr=0.000286299, gnorm=0.489, loss_scale=16, train_wall=211, gb_free=9.7, wall=28079
2022-03-13 19:53:48 | INFO | train_inner | epoch 031:    171 / 407 loss=5.764, nll_loss=5.357, ppl=40.97, wps=28041.6, ups=0.43, wpb=65536, bsz=128, num_updates=12300, lr=0.000285133, gnorm=0.489, loss_scale=32, train_wall=210, gb_free=9.7, wall=28313
2022-03-13 19:56:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:57:46 | INFO | train_inner | epoch 031:    272 / 407 loss=5.778, nll_loss=5.371, ppl=41.39, wps=27533.8, ups=0.42, wpb=65536, bsz=128, num_updates=12400, lr=0.000283981, gnorm=0.487, loss_scale=32, train_wall=214, gb_free=9.7, wall=28551
2022-03-13 20:01:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:01:39 | INFO | train_inner | epoch 031:    373 / 407 loss=5.797, nll_loss=5.392, ppl=41.98, wps=28073.3, ups=0.43, wpb=65536, bsz=128, num_updates=12500, lr=0.000282843, gnorm=0.487, loss_scale=32, train_wall=210, gb_free=9.7, wall=28784
2022-03-13 20:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:03:25 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 5.894 | nll_loss 5.464 | ppl 44.12 | wps 50587.5 | wpb 511.9 | bsz 1 | num_updates 12534 | best_loss 5.894
2022-03-13 20:03:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 12534 updates
2022-03-13 20:03:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:03:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:03:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 31 @ 12534 updates, score 5.894) (writing took 2.601790108019486 seconds)
2022-03-13 20:03:28 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-13 20:03:28 | INFO | train | epoch 031 | loss 5.771 | nll_loss 5.365 | ppl 41.21 | wps 27041.8 | ups 0.41 | wpb 65492.6 | bsz 127.9 | num_updates 12534 | lr 0.000282459 | gnorm 0.489 | loss_scale 32 | train_wall 855 | gb_free 9.7 | wall 28893
2022-03-13 20:03:28 | INFO | fairseq.trainer | begin training epoch 32
2022-03-13 20:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:04:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:06:07 | INFO | train_inner | epoch 032:     67 / 407 loss=5.745, nll_loss=5.337, ppl=40.42, wps=24431.3, ups=0.37, wpb=65361.9, bsz=127.7, num_updates=12600, lr=0.000281718, gnorm=0.491, loss_scale=16, train_wall=215, gb_free=9.7, wall=29052
2022-03-13 20:10:00 | INFO | train_inner | epoch 032:    167 / 407 loss=5.742, nll_loss=5.334, ppl=40.32, wps=28087.6, ups=0.43, wpb=65536, bsz=128, num_updates=12700, lr=0.000280607, gnorm=0.489, loss_scale=32, train_wall=210, gb_free=9.7, wall=29285
2022-03-13 20:12:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:13:56 | INFO | train_inner | epoch 032:    268 / 407 loss=5.759, nll_loss=5.352, ppl=40.85, wps=27805.6, ups=0.42, wpb=65534.2, bsz=128, num_updates=12800, lr=0.000279508, gnorm=0.485, loss_scale=16, train_wall=212, gb_free=9.7, wall=29521
2022-03-13 20:17:45 | INFO | train_inner | epoch 032:    368 / 407 loss=5.771, nll_loss=5.365, ppl=41.21, wps=28527.8, ups=0.44, wpb=65536, bsz=128, num_updates=12900, lr=0.000278423, gnorm=0.486, loss_scale=32, train_wall=206, gb_free=9.7, wall=29751
2022-03-13 20:19:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:19:38 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 5.881 | nll_loss 5.451 | ppl 43.74 | wps 52797.2 | wpb 511.9 | bsz 1 | num_updates 12939 | best_loss 5.881
2022-03-13 20:19:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 12939 updates
2022-03-13 20:19:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:19:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 32 @ 12939 updates, score 5.881) (writing took 2.276642607001122 seconds)
2022-03-13 20:19:40 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-13 20:19:40 | INFO | train | epoch 032 | loss 5.753 | nll_loss 5.346 | ppl 40.67 | wps 27288.4 | ups 0.42 | wpb 65492.6 | bsz 127.9 | num_updates 12939 | lr 0.000278003 | gnorm 0.488 | loss_scale 32 | train_wall 848 | gb_free 9.7 | wall 29865
2022-03-13 20:19:40 | INFO | fairseq.trainer | begin training epoch 33
2022-03-13 20:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:21:59 | INFO | train_inner | epoch 033:     61 / 407 loss=5.732, nll_loss=5.323, ppl=40.04, wps=25826.1, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=13000, lr=0.00027735, gnorm=0.495, loss_scale=32, train_wall=202, gb_free=9.7, wall=30004
2022-03-13 20:22:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:24:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:25:53 | INFO | train_inner | epoch 033:    163 / 407 loss=5.729, nll_loss=5.32, ppl=39.96, wps=27955.9, ups=0.43, wpb=65534.2, bsz=128, num_updates=13100, lr=0.000276289, gnorm=0.499, loss_scale=16, train_wall=210, gb_free=9.7, wall=30238
2022-03-13 20:29:38 | INFO | train_inner | epoch 033:    263 / 407 loss=5.745, nll_loss=5.337, ppl=40.42, wps=29155.8, ups=0.44, wpb=65536, bsz=128, num_updates=13200, lr=0.000275241, gnorm=0.488, loss_scale=32, train_wall=201, gb_free=9.7, wall=30463
2022-03-13 20:33:24 | INFO | train_inner | epoch 033:    363 / 407 loss=5.75, nll_loss=5.342, ppl=40.56, wps=28940.3, ups=0.44, wpb=65536, bsz=128, num_updates=13300, lr=0.000274204, gnorm=0.489, loss_scale=32, train_wall=203, gb_free=9.7, wall=30689
2022-03-13 20:33:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:35:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:35:31 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 5.876 | nll_loss 5.445 | ppl 43.56 | wps 49521 | wpb 511.9 | bsz 1 | num_updates 13343 | best_loss 5.876
2022-03-13 20:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 13343 updates
2022-03-13 20:35:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:35:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:35:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 33 @ 13343 updates, score 5.876) (writing took 2.124564294994343 seconds)
2022-03-13 20:35:33 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-13 20:35:33 | INFO | train | epoch 033 | loss 5.738 | nll_loss 5.33 | ppl 40.22 | wps 27764 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 13343 | lr 0.000273762 | gnorm 0.492 | loss_scale 32 | train_wall 828 | gb_free 9.7 | wall 30818
2022-03-13 20:35:33 | INFO | fairseq.trainer | begin training epoch 34
2022-03-13 20:35:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:37:45 | INFO | train_inner | epoch 034:     57 / 407 loss=5.719, nll_loss=5.31, ppl=39.67, wps=25067.8, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=13400, lr=0.000273179, gnorm=0.497, loss_scale=32, train_wall=208, gb_free=9.7, wall=30950
2022-03-13 20:39:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:41:42 | INFO | train_inner | epoch 034:    158 / 407 loss=5.706, nll_loss=5.296, ppl=39.29, wps=27620.2, ups=0.42, wpb=65534.2, bsz=128, num_updates=13500, lr=0.000272166, gnorm=0.49, loss_scale=32, train_wall=213, gb_free=9.7, wall=31187
2022-03-13 20:41:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:45:33 | INFO | train_inner | epoch 034:    259 / 407 loss=5.73, nll_loss=5.322, ppl=39.99, wps=28395.6, ups=0.43, wpb=65536, bsz=128, num_updates=13600, lr=0.000271163, gnorm=0.488, loss_scale=16, train_wall=207, gb_free=9.7, wall=31418
2022-03-13 20:49:22 | INFO | train_inner | epoch 034:    359 / 407 loss=5.742, nll_loss=5.334, ppl=40.33, wps=28576.7, ups=0.44, wpb=65536, bsz=128, num_updates=13700, lr=0.000270172, gnorm=0.483, loss_scale=32, train_wall=206, gb_free=9.7, wall=31647
2022-03-13 20:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:51:40 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 5.87 | nll_loss 5.437 | ppl 43.32 | wps 49516.1 | wpb 511.9 | bsz 1 | num_updates 13748 | best_loss 5.87
2022-03-13 20:51:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 13748 updates
2022-03-13 20:51:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:51:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:51:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 34 @ 13748 updates, score 5.87) (writing took 2.191602126986254 seconds)
2022-03-13 20:51:42 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-13 20:51:42 | INFO | train | epoch 034 | loss 5.722 | nll_loss 5.313 | ppl 39.76 | wps 27358.7 | ups 0.42 | wpb 65492.6 | bsz 127.9 | num_updates 13748 | lr 0.0002697 | gnorm 0.49 | loss_scale 32 | train_wall 845 | gb_free 9.7 | wall 31787
2022-03-13 20:51:42 | INFO | fairseq.trainer | begin training epoch 35
2022-03-13 20:51:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:51:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:53:47 | INFO | train_inner | epoch 035:     53 / 407 loss=5.704, nll_loss=5.295, ppl=39.25, wps=24656.9, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=13800, lr=0.000269191, gnorm=0.492, loss_scale=16, train_wall=212, gb_free=9.7, wall=31913
2022-03-13 20:57:38 | INFO | train_inner | epoch 035:    153 / 407 loss=5.696, nll_loss=5.285, ppl=39, wps=28483.2, ups=0.43, wpb=65534.2, bsz=128, num_updates=13900, lr=0.000268221, gnorm=0.49, loss_scale=32, train_wall=206, gb_free=9.7, wall=32143
2022-03-13 21:01:24 | INFO | train_inner | epoch 035:    253 / 407 loss=5.717, nll_loss=5.308, ppl=39.61, wps=28913.5, ups=0.44, wpb=65536, bsz=128, num_updates=14000, lr=0.000267261, gnorm=0.488, loss_scale=32, train_wall=203, gb_free=9.7, wall=32369
2022-03-13 21:01:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:05:16 | INFO | train_inner | epoch 035:    354 / 407 loss=5.724, nll_loss=5.315, ppl=39.81, wps=28288.1, ups=0.43, wpb=65536, bsz=128, num_updates=14100, lr=0.000266312, gnorm=0.487, loss_scale=32, train_wall=208, gb_free=9.7, wall=32601
2022-03-13 21:06:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:07:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:07:39 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 5.859 | nll_loss 5.426 | ppl 43 | wps 51529.4 | wpb 511.9 | bsz 1 | num_updates 14152 | best_loss 5.859
2022-03-13 21:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 14152 updates
2022-03-13 21:07:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:07:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:07:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 35 @ 14152 updates, score 5.859) (writing took 2.2502264649956487 seconds)
2022-03-13 21:07:42 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-13 21:07:42 | INFO | train | epoch 035 | loss 5.709 | nll_loss 5.299 | ppl 39.37 | wps 27580.7 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 14152 | lr 0.000265822 | gnorm 0.49 | loss_scale 32 | train_wall 835 | gb_free 9.7 | wall 32747
2022-03-13 21:07:42 | INFO | fairseq.trainer | begin training epoch 36
2022-03-13 21:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:09:35 | INFO | train_inner | epoch 036:     48 / 407 loss=5.701, nll_loss=5.291, ppl=39.15, wps=25233.5, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=14200, lr=0.000265372, gnorm=0.499, loss_scale=32, train_wall=207, gb_free=9.7, wall=32860
2022-03-13 21:11:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:13:18 | INFO | train_inner | epoch 036:    149 / 407 loss=5.686, nll_loss=5.275, ppl=38.73, wps=29323.9, ups=0.45, wpb=65534.2, bsz=128, num_updates=14300, lr=0.000264443, gnorm=0.494, loss_scale=32, train_wall=200, gb_free=9.7, wall=33083
2022-03-13 21:16:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 21:17:11 | INFO | train_inner | epoch 036:    250 / 407 loss=5.692, nll_loss=5.282, ppl=38.9, wps=28192.6, ups=0.43, wpb=65536, bsz=128, num_updates=14400, lr=0.000263523, gnorm=0.493, loss_scale=16, train_wall=209, gb_free=9.7, wall=33316
2022-03-13 21:21:04 | INFO | train_inner | epoch 036:    350 / 407 loss=5.708, nll_loss=5.299, ppl=39.36, wps=28069.1, ups=0.43, wpb=65536, bsz=128, num_updates=14500, lr=0.000262613, gnorm=0.488, loss_scale=16, train_wall=210, gb_free=9.7, wall=33549
2022-03-13 21:23:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:23:43 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 5.847 | nll_loss 5.415 | ppl 42.65 | wps 49553.8 | wpb 511.9 | bsz 1 | num_updates 14557 | best_loss 5.847
2022-03-13 21:23:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 14557 updates
2022-03-13 21:23:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:23:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:23:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 36 @ 14557 updates, score 5.847) (writing took 2.2005900949588977 seconds)
2022-03-13 21:23:45 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-13 21:23:45 | INFO | train | epoch 036 | loss 5.695 | nll_loss 5.285 | ppl 38.98 | wps 27541.6 | ups 0.42 | wpb 65492.6 | bsz 127.9 | num_updates 14557 | lr 0.000262098 | gnorm 0.494 | loss_scale 32 | train_wall 838 | gb_free 9.7 | wall 33710
2022-03-13 21:23:45 | INFO | fairseq.trainer | begin training epoch 37
2022-03-13 21:23:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:23:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 21:25:26 | INFO | train_inner | epoch 037:     44 / 407 loss=5.678, nll_loss=5.267, ppl=38.51, wps=24996.3, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=14600, lr=0.000261712, gnorm=0.495, loss_scale=16, train_wall=208, gb_free=9.7, wall=33811
2022-03-13 21:29:18 | INFO | train_inner | epoch 037:    144 / 407 loss=5.668, nll_loss=5.256, ppl=38.21, wps=28273.9, ups=0.43, wpb=65536, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.49, loss_scale=32, train_wall=208, gb_free=9.7, wall=34043
2022-03-13 21:33:10 | INFO | train_inner | epoch 037:    244 / 407 loss=5.687, nll_loss=5.276, ppl=38.74, wps=28170.4, ups=0.43, wpb=65536, bsz=128, num_updates=14800, lr=0.000259938, gnorm=0.492, loss_scale=32, train_wall=209, gb_free=9.7, wall=34275
2022-03-13 21:33:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:36:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 21:37:10 | INFO | train_inner | epoch 037:    346 / 407 loss=5.701, nll_loss=5.29, ppl=39.13, wps=27328.1, ups=0.42, wpb=65534.2, bsz=128, num_updates=14900, lr=0.000259064, gnorm=0.489, loss_scale=16, train_wall=216, gb_free=9.7, wall=34515
2022-03-13 21:39:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:39:54 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 5.843 | nll_loss 5.411 | ppl 42.55 | wps 52563 | wpb 511.9 | bsz 1 | num_updates 14961 | best_loss 5.843
2022-03-13 21:39:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 14961 updates
2022-03-13 21:39:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:39:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:39:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 37 @ 14961 updates, score 5.843) (writing took 2.2360059329657815 seconds)
2022-03-13 21:39:57 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-13 21:39:57 | INFO | train | epoch 037 | loss 5.682 | nll_loss 5.271 | ppl 38.61 | wps 27226.2 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 14961 | lr 0.000258535 | gnorm 0.491 | loss_scale 16 | train_wall 849 | gb_free 9.7 | wall 34682
2022-03-13 21:39:57 | INFO | fairseq.trainer | begin training epoch 38
2022-03-13 21:39:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:41:24 | INFO | train_inner | epoch 038:     39 / 407 loss=5.676, nll_loss=5.264, ppl=38.44, wps=25704.6, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=15000, lr=0.000258199, gnorm=0.495, loss_scale=16, train_wall=203, gb_free=9.7, wall=34769
2022-03-13 21:45:17 | INFO | train_inner | epoch 038:    139 / 407 loss=5.641, nll_loss=5.228, ppl=37.48, wps=28199.7, ups=0.43, wpb=65536, bsz=128, num_updates=15100, lr=0.000257343, gnorm=0.499, loss_scale=32, train_wall=209, gb_free=9.7, wall=35002
2022-03-13 21:47:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:49:10 | INFO | train_inner | epoch 038:    240 / 407 loss=5.683, nll_loss=5.272, ppl=38.63, wps=28112.4, ups=0.43, wpb=65536, bsz=128, num_updates=15200, lr=0.000256495, gnorm=0.491, loss_scale=32, train_wall=209, gb_free=9.7, wall=35235
2022-03-13 21:52:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:53:04 | INFO | train_inner | epoch 038:    341 / 407 loss=5.681, nll_loss=5.27, ppl=38.6, wps=27977.2, ups=0.43, wpb=65534.2, bsz=128, num_updates=15300, lr=0.000255655, gnorm=0.496, loss_scale=32, train_wall=211, gb_free=9.7, wall=35469
2022-03-13 21:55:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 21:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:56:01 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 5.833 | nll_loss 5.4 | ppl 42.22 | wps 51899.6 | wpb 511.9 | bsz 1 | num_updates 15365 | best_loss 5.833
2022-03-13 21:56:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 15365 updates
2022-03-13 21:56:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:56:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:56:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 38 @ 15365 updates, score 5.833) (writing took 2.232607915007975 seconds)
2022-03-13 21:56:03 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-13 21:56:03 | INFO | train | epoch 038 | loss 5.669 | nll_loss 5.258 | ppl 38.26 | wps 27371.7 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 15365 | lr 0.000255114 | gnorm 0.495 | loss_scale 16 | train_wall 843 | gb_free 9.7 | wall 35648
2022-03-13 21:56:03 | INFO | fairseq.trainer | begin training epoch 39
2022-03-13 21:56:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:57:24 | INFO | train_inner | epoch 039:     35 / 407 loss=5.671, nll_loss=5.259, ppl=38.3, wps=25132, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=15400, lr=0.000254824, gnorm=0.498, loss_scale=16, train_wall=208, gb_free=9.7, wall=35729
2022-03-13 22:01:08 | INFO | train_inner | epoch 039:    135 / 407 loss=5.645, nll_loss=5.232, ppl=37.59, wps=29339, ups=0.45, wpb=65534.2, bsz=128, num_updates=15500, lr=0.000254, gnorm=0.499, loss_scale=32, train_wall=200, gb_free=9.7, wall=35953
2022-03-13 22:04:50 | INFO | train_inner | epoch 039:    235 / 407 loss=5.658, nll_loss=5.246, ppl=37.94, wps=29418.1, ups=0.45, wpb=65536, bsz=128, num_updates=15600, lr=0.000253185, gnorm=0.491, loss_scale=32, train_wall=199, gb_free=9.7, wall=36175
2022-03-13 22:04:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:08:31 | INFO | train_inner | epoch 039:    336 / 407 loss=5.672, nll_loss=5.261, ppl=38.34, wps=29705, ups=0.45, wpb=65536, bsz=128, num_updates=15700, lr=0.000252377, gnorm=0.501, loss_scale=16, train_wall=197, gb_free=9.7, wall=36396
2022-03-13 22:09:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:11:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:11:31 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 5.835 | nll_loss 5.401 | ppl 42.25 | wps 52070 | wpb 511.9 | bsz 1 | num_updates 15770 | best_loss 5.833
2022-03-13 22:11:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 15770 updates
2022-03-13 22:11:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 22:11:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 22:11:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 39 @ 15770 updates, score 5.835) (writing took 1.3839574260055088 seconds)
2022-03-13 22:11:33 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-13 22:11:33 | INFO | train | epoch 039 | loss 5.658 | nll_loss 5.246 | ppl 37.94 | wps 28544.3 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 15770 | lr 0.000251816 | gnorm 0.497 | loss_scale 16 | train_wall 806 | gb_free 9.7 | wall 36578
2022-03-13 22:11:33 | INFO | fairseq.trainer | begin training epoch 40
2022-03-13 22:11:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:12:38 | INFO | train_inner | epoch 040:     30 / 407 loss=5.657, nll_loss=5.245, ppl=37.92, wps=26477.7, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=15800, lr=0.000251577, gnorm=0.498, loss_scale=16, train_wall=196, gb_free=9.7, wall=36643
2022-03-13 22:15:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:16:18 | INFO | train_inner | epoch 040:    131 / 407 loss=5.622, nll_loss=5.208, ppl=36.96, wps=29702.9, ups=0.45, wpb=65536, bsz=128, num_updates=15900, lr=0.000250785, gnorm=0.493, loss_scale=16, train_wall=197, gb_free=9.7, wall=36864
2022-03-13 22:19:56 | INFO | train_inner | epoch 040:    231 / 407 loss=5.642, nll_loss=5.229, ppl=37.5, wps=30140.3, ups=0.46, wpb=65534.2, bsz=128, num_updates=16000, lr=0.00025, gnorm=0.493, loss_scale=16, train_wall=194, gb_free=9.7, wall=37081
2022-03-13 22:23:34 | INFO | train_inner | epoch 040:    331 / 407 loss=5.663, nll_loss=5.251, ppl=38.07, wps=30017.3, ups=0.46, wpb=65536, bsz=128, num_updates=16100, lr=0.000249222, gnorm=0.495, loss_scale=32, train_wall=195, gb_free=9.7, wall=37299
2022-03-13 22:24:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:25:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:26:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:26:44 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 5.821 | nll_loss 5.387 | ppl 41.84 | wps 53522.5 | wpb 511.9 | bsz 1 | num_updates 16174 | best_loss 5.821
2022-03-13 22:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 16174 updates
2022-03-13 22:26:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:26:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 40 @ 16174 updates, score 5.821) (writing took 2.1905769190052524 seconds)
2022-03-13 22:26:46 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-13 22:26:46 | INFO | train | epoch 040 | loss 5.646 | nll_loss 5.233 | ppl 37.62 | wps 28974.5 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 16174 | lr 0.000248652 | gnorm 0.495 | loss_scale 16 | train_wall 791 | gb_free 9.7 | wall 37491
2022-03-13 22:26:46 | INFO | fairseq.trainer | begin training epoch 41
2022-03-13 22:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:27:42 | INFO | train_inner | epoch 041:     26 / 407 loss=5.65, nll_loss=5.237, ppl=37.71, wps=26352.4, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=16200, lr=0.000248452, gnorm=0.494, loss_scale=16, train_wall=197, gb_free=9.7, wall=37547
2022-03-13 22:31:22 | INFO | train_inner | epoch 041:    126 / 407 loss=5.622, nll_loss=5.207, ppl=36.95, wps=29835.2, ups=0.46, wpb=65534.2, bsz=128, num_updates=16300, lr=0.000247689, gnorm=0.504, loss_scale=32, train_wall=196, gb_free=9.7, wall=37767
2022-03-13 22:33:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:35:01 | INFO | train_inner | epoch 041:    227 / 407 loss=5.637, nll_loss=5.224, ppl=37.36, wps=29893.5, ups=0.46, wpb=65536, bsz=128, num_updates=16400, lr=0.000246932, gnorm=0.497, loss_scale=16, train_wall=196, gb_free=9.7, wall=37986
2022-03-13 22:38:37 | INFO | train_inner | epoch 041:    327 / 407 loss=5.644, nll_loss=5.231, ppl=37.56, wps=30352, ups=0.46, wpb=65536, bsz=128, num_updates=16500, lr=0.000246183, gnorm=0.501, loss_scale=32, train_wall=193, gb_free=9.7, wall=38202
2022-03-13 22:41:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:41:56 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 5.822 | nll_loss 5.388 | ppl 41.88 | wps 52874 | wpb 511.9 | bsz 1 | num_updates 16579 | best_loss 5.821
2022-03-13 22:41:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 16579 updates
2022-03-13 22:41:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 22:41:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 22:41:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 41 @ 16579 updates, score 5.822) (writing took 1.2155875880271196 seconds)
2022-03-13 22:41:57 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-13 22:41:57 | INFO | train | epoch 041 | loss 5.636 | nll_loss 5.222 | ppl 37.33 | wps 29108.6 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 16579 | lr 0.000245596 | gnorm 0.499 | loss_scale 16 | train_wall 789 | gb_free 9.7 | wall 38402
2022-03-13 22:41:57 | INFO | fairseq.trainer | begin training epoch 42
2022-03-13 22:41:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:42:43 | INFO | train_inner | epoch 042:     21 / 407 loss=5.644, nll_loss=5.231, ppl=37.56, wps=26628.6, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=16600, lr=0.00024544, gnorm=0.498, loss_scale=16, train_wall=195, gb_free=9.7, wall=38448
2022-03-13 22:46:19 | INFO | train_inner | epoch 042:    121 / 407 loss=5.603, nll_loss=5.188, ppl=36.45, wps=30301, ups=0.46, wpb=65536, bsz=128, num_updates=16700, lr=0.000244704, gnorm=0.498, loss_scale=32, train_wall=193, gb_free=9.7, wall=38664
2022-03-13 22:46:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:49:58 | INFO | train_inner | epoch 042:    222 / 407 loss=5.621, nll_loss=5.206, ppl=36.92, wps=29859.9, ups=0.46, wpb=65536, bsz=128, num_updates=16800, lr=0.000243975, gnorm=0.495, loss_scale=16, train_wall=196, gb_free=9.7, wall=38883
2022-03-13 22:52:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:53:38 | INFO | train_inner | epoch 042:    323 / 407 loss=5.646, nll_loss=5.233, ppl=37.62, wps=29831.4, ups=0.46, wpb=65534.2, bsz=128, num_updates=16900, lr=0.000243252, gnorm=0.501, loss_scale=16, train_wall=196, gb_free=9.7, wall=39103
2022-03-13 22:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:57:06 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 5.812 | nll_loss 5.379 | ppl 41.61 | wps 52952.6 | wpb 511.9 | bsz 1 | num_updates 16984 | best_loss 5.812
2022-03-13 22:57:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 16984 updates
2022-03-13 22:57:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:57:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:57:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 42 @ 16984 updates, score 5.812) (writing took 2.2014384630019777 seconds)
2022-03-13 22:57:08 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-13 22:57:08 | INFO | train | epoch 042 | loss 5.625 | nll_loss 5.211 | ppl 37.05 | wps 29120.1 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 16984 | lr 0.00024265 | gnorm 0.499 | loss_scale 16 | train_wall 788 | gb_free 9.7 | wall 39313
2022-03-13 22:57:08 | INFO | fairseq.trainer | begin training epoch 43
2022-03-13 22:57:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:57:43 | INFO | train_inner | epoch 043:     16 / 407 loss=5.631, nll_loss=5.218, ppl=37.21, wps=26661.2, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=17000, lr=0.000242536, gnorm=0.502, loss_scale=32, train_wall=194, gb_free=9.7, wall=39348
2022-03-13 22:58:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:01:25 | INFO | train_inner | epoch 043:    117 / 407 loss=5.594, nll_loss=5.178, ppl=36.19, wps=29600.9, ups=0.45, wpb=65536, bsz=128, num_updates=17100, lr=0.000241825, gnorm=0.501, loss_scale=16, train_wall=198, gb_free=9.7, wall=39570
2022-03-13 23:05:02 | INFO | train_inner | epoch 043:    217 / 407 loss=5.619, nll_loss=5.205, ppl=36.88, wps=30167, ups=0.46, wpb=65536, bsz=128, num_updates=17200, lr=0.000241121, gnorm=0.496, loss_scale=32, train_wall=194, gb_free=9.7, wall=39787
2022-03-13 23:08:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:08:41 | INFO | train_inner | epoch 043:    318 / 407 loss=5.626, nll_loss=5.212, ppl=37.06, wps=29919, ups=0.46, wpb=65536, bsz=128, num_updates=17300, lr=0.000240424, gnorm=0.501, loss_scale=32, train_wall=195, gb_free=9.7, wall=40006
2022-03-13 23:11:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:12:20 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 5.808 | nll_loss 5.374 | ppl 41.48 | wps 53097.3 | wpb 511.9 | bsz 1 | num_updates 17389 | best_loss 5.808
2022-03-13 23:12:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 17389 updates
2022-03-13 23:12:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:12:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 43 @ 17389 updates, score 5.808) (writing took 2.1829484709887765 seconds)
2022-03-13 23:12:22 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-13 23:12:22 | INFO | train | epoch 043 | loss 5.615 | nll_loss 5.201 | ppl 36.77 | wps 29008.1 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 17389 | lr 0.000239807 | gnorm 0.5 | loss_scale 32 | train_wall 791 | gb_free 9.7 | wall 40227
2022-03-13 23:12:22 | INFO | fairseq.trainer | begin training epoch 44
2022-03-13 23:12:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:12:46 | INFO | train_inner | epoch 044:     11 / 407 loss=5.623, nll_loss=5.209, ppl=36.99, wps=26633.6, ups=0.41, wpb=65360.1, bsz=127.7, num_updates=17400, lr=0.000239732, gnorm=0.5, loss_scale=32, train_wall=194, gb_free=9.7, wall=40251
2022-03-13 23:13:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:16:27 | INFO | train_inner | epoch 044:    112 / 407 loss=5.584, nll_loss=5.168, ppl=35.94, wps=29691, ups=0.45, wpb=65536, bsz=128, num_updates=17500, lr=0.000239046, gnorm=0.496, loss_scale=32, train_wall=197, gb_free=9.7, wall=40472
2022-03-13 23:18:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:20:07 | INFO | train_inner | epoch 044:    213 / 407 loss=5.605, nll_loss=5.189, ppl=36.49, wps=29801.3, ups=0.45, wpb=65536, bsz=128, num_updates=17600, lr=0.000238366, gnorm=0.5, loss_scale=32, train_wall=196, gb_free=9.7, wall=40692
2022-03-13 23:22:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:23:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:23:48 | INFO | train_inner | epoch 044:    315 / 407 loss=5.62, nll_loss=5.206, ppl=36.9, wps=29615.9, ups=0.45, wpb=65536, bsz=128, num_updates=17700, lr=0.000237691, gnorm=0.497, loss_scale=16, train_wall=197, gb_free=9.7, wall=40913
2022-03-13 23:27:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:27:34 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 5.802 | nll_loss 5.368 | ppl 41.28 | wps 53122.5 | wpb 511.9 | bsz 1 | num_updates 17792 | best_loss 5.802
2022-03-13 23:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 17792 updates
2022-03-13 23:27:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:27:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:27:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 44 @ 17792 updates, score 5.802) (writing took 2.2191184289986268 seconds)
2022-03-13 23:27:36 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-13 23:27:36 | INFO | train | epoch 044 | loss 5.606 | nll_loss 5.19 | ppl 36.51 | wps 28884.9 | ups 0.44 | wpb 65492.3 | bsz 127.9 | num_updates 17792 | lr 0.000237076 | gnorm 0.498 | loss_scale 16 | train_wall 791 | gb_free 9.7 | wall 41141
2022-03-13 23:27:36 | INFO | fairseq.trainer | begin training epoch 45
2022-03-13 23:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:27:53 | INFO | train_inner | epoch 045:      8 / 407 loss=5.614, nll_loss=5.2, ppl=36.75, wps=26649.2, ups=0.41, wpb=65360.1, bsz=127.7, num_updates=17800, lr=0.000237023, gnorm=0.501, loss_scale=16, train_wall=194, gb_free=9.7, wall=41158
2022-03-13 23:29:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:31:37 | INFO | train_inner | epoch 045:    109 / 407 loss=5.567, nll_loss=5.15, ppl=35.5, wps=29332.7, ups=0.45, wpb=65536, bsz=128, num_updates=17900, lr=0.00023636, gnorm=0.506, loss_scale=16, train_wall=200, gb_free=9.7, wall=41382
2022-03-13 23:34:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:35:28 | INFO | train_inner | epoch 045:    210 / 407 loss=5.586, nll_loss=5.17, ppl=36, wps=28310.9, ups=0.43, wpb=65536, bsz=128, num_updates=18000, lr=0.000235702, gnorm=0.498, loss_scale=16, train_wall=208, gb_free=9.7, wall=41613
2022-03-13 23:39:17 | INFO | train_inner | epoch 045:    310 / 407 loss=5.616, nll_loss=5.201, ppl=36.79, wps=28632.8, ups=0.44, wpb=65534.2, bsz=128, num_updates=18100, lr=0.00023505, gnorm=0.501, loss_scale=16, train_wall=205, gb_free=9.7, wall=41842
2022-03-13 23:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:43:28 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 5.802 | nll_loss 5.366 | ppl 41.23 | wps 49439.4 | wpb 511.9 | bsz 1 | num_updates 18197 | best_loss 5.802
2022-03-13 23:43:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 18197 updates
2022-03-13 23:43:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:43:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:43:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 45 @ 18197 updates, score 5.802) (writing took 2.0817929699551314 seconds)
2022-03-13 23:43:30 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-13 23:43:30 | INFO | train | epoch 045 | loss 5.597 | nll_loss 5.181 | ppl 36.28 | wps 27787.2 | ups 0.42 | wpb 65492.6 | bsz 127.9 | num_updates 18197 | lr 0.000234423 | gnorm 0.503 | loss_scale 32 | train_wall 830 | gb_free 9.7 | wall 42096
2022-03-13 23:43:31 | INFO | fairseq.trainer | begin training epoch 46
2022-03-13 23:43:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:43:38 | INFO | train_inner | epoch 046:      3 / 407 loss=5.62, nll_loss=5.205, ppl=36.9, wps=25101.8, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=18200, lr=0.000234404, gnorm=0.503, loss_scale=32, train_wall=208, gb_free=9.7, wall=42103
2022-03-13 23:45:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:46:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:47:36 | INFO | train_inner | epoch 046:    105 / 407 loss=5.559, nll_loss=5.141, ppl=35.29, wps=27518, ups=0.42, wpb=65534.2, bsz=128, num_updates=18300, lr=0.000233762, gnorm=0.508, loss_scale=16, train_wall=214, gb_free=9.7, wall=42341
2022-03-13 23:51:23 | INFO | train_inner | epoch 046:    205 / 407 loss=5.589, nll_loss=5.173, ppl=36.07, wps=28839.3, ups=0.44, wpb=65536, bsz=128, num_updates=18400, lr=0.000233126, gnorm=0.496, loss_scale=16, train_wall=204, gb_free=9.7, wall=42568
2022-03-13 23:52:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:55:20 | INFO | train_inner | epoch 046:    306 / 407 loss=5.6, nll_loss=5.185, ppl=36.37, wps=27607.7, ups=0.42, wpb=65536, bsz=128, num_updates=18500, lr=0.000232495, gnorm=0.508, loss_scale=16, train_wall=214, gb_free=9.7, wall=42805
2022-03-13 23:59:12 | INFO | train_inner | epoch 046:    406 / 407 loss=5.604, nll_loss=5.188, ppl=36.47, wps=28259.9, ups=0.43, wpb=65536, bsz=128, num_updates=18600, lr=0.000231869, gnorm=0.497, loss_scale=32, train_wall=208, gb_free=9.7, wall=43037
2022-03-13 23:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:59:41 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 5.79 | nll_loss 5.355 | ppl 40.93 | wps 49565.4 | wpb 511.9 | bsz 1 | num_updates 18601 | best_loss 5.79
2022-03-13 23:59:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 18601 updates
2022-03-13 23:59:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:59:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:59:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 46 @ 18601 updates, score 5.79) (writing took 2.0969250630005263 seconds)
2022-03-13 23:59:43 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-13 23:59:43 | INFO | train | epoch 046 | loss 5.588 | nll_loss 5.171 | ppl 36.04 | wps 27204.6 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 18601 | lr 0.000231863 | gnorm 0.503 | loss_scale 32 | train_wall 848 | gb_free 9.7 | wall 43068
2022-03-13 23:59:43 | INFO | fairseq.trainer | begin training epoch 47
2022-03-13 23:59:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:02:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:02:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 00:03:37 | INFO | train_inner | epoch 047:    101 / 407 loss=5.552, nll_loss=5.134, ppl=35.13, wps=24701.4, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=18700, lr=0.000231249, gnorm=0.504, loss_scale=16, train_wall=211, gb_free=9.7, wall=43302
2022-03-14 00:07:24 | INFO | train_inner | epoch 047:    201 / 407 loss=5.562, nll_loss=5.144, ppl=35.37, wps=28853.1, ups=0.44, wpb=65534.2, bsz=128, num_updates=18800, lr=0.000230633, gnorm=0.507, loss_scale=16, train_wall=204, gb_free=9.7, wall=43529
2022-03-14 00:11:17 | INFO | train_inner | epoch 047:    301 / 407 loss=5.599, nll_loss=5.183, ppl=36.33, wps=28131.3, ups=0.43, wpb=65536, bsz=128, num_updates=18900, lr=0.000230022, gnorm=0.507, loss_scale=32, train_wall=209, gb_free=9.7, wall=43762
2022-03-14 00:12:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:15:13 | INFO | train_inner | epoch 047:    402 / 407 loss=5.6, nll_loss=5.185, ppl=36.37, wps=27761.5, ups=0.42, wpb=65536, bsz=128, num_updates=19000, lr=0.000229416, gnorm=0.497, loss_scale=32, train_wall=212, gb_free=9.7, wall=43998
2022-03-14 00:15:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:15:51 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 5.788 | nll_loss 5.352 | ppl 40.83 | wps 49825 | wpb 511.9 | bsz 1 | num_updates 19005 | best_loss 5.788
2022-03-14 00:15:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 19005 updates
2022-03-14 00:15:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:15:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:15:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 47 @ 19005 updates, score 5.788) (writing took 2.1828773420420475 seconds)
2022-03-14 00:15:53 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-14 00:15:53 | INFO | train | epoch 047 | loss 5.579 | nll_loss 5.162 | ppl 35.81 | wps 27285.1 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 19005 | lr 0.000229386 | gnorm 0.504 | loss_scale 32 | train_wall 845 | gb_free 9.7 | wall 44038
2022-03-14 00:15:53 | INFO | fairseq.trainer | begin training epoch 48
2022-03-14 00:15:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:18:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:19:37 | INFO | train_inner | epoch 048:     96 / 407 loss=5.556, nll_loss=5.139, ppl=35.23, wps=24736.6, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=19100, lr=0.000228814, gnorm=0.506, loss_scale=32, train_wall=211, gb_free=9.7, wall=44262
2022-03-14 00:23:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:23:31 | INFO | train_inner | epoch 048:    197 / 407 loss=5.561, nll_loss=5.143, ppl=35.34, wps=28056.7, ups=0.43, wpb=65534.2, bsz=128, num_updates=19200, lr=0.000228218, gnorm=0.505, loss_scale=32, train_wall=210, gb_free=9.7, wall=44496
2022-03-14 00:27:22 | INFO | train_inner | epoch 048:    297 / 407 loss=5.582, nll_loss=5.165, ppl=35.89, wps=28314, ups=0.43, wpb=65536, bsz=128, num_updates=19300, lr=0.000227626, gnorm=0.504, loss_scale=32, train_wall=208, gb_free=9.7, wall=44727
2022-03-14 00:28:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:30:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 00:31:18 | INFO | train_inner | epoch 048:    399 / 407 loss=5.587, nll_loss=5.17, ppl=36.01, wps=27838.8, ups=0.42, wpb=65536, bsz=128, num_updates=19400, lr=0.000227038, gnorm=0.497, loss_scale=16, train_wall=211, gb_free=9.7, wall=44963
2022-03-14 00:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:32:00 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 5.783 | nll_loss 5.347 | ppl 40.7 | wps 52742.8 | wpb 511.9 | bsz 1 | num_updates 19408 | best_loss 5.783
2022-03-14 00:32:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 19408 updates
2022-03-14 00:32:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:32:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:32:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 48 @ 19408 updates, score 5.783) (writing took 2.2047042549820617 seconds)
2022-03-14 00:32:02 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-14 00:32:02 | INFO | train | epoch 048 | loss 5.571 | nll_loss 5.154 | ppl 35.6 | wps 27219.7 | ups 0.42 | wpb 65492.3 | bsz 127.9 | num_updates 19408 | lr 0.000226992 | gnorm 0.503 | loss_scale 16 | train_wall 846 | gb_free 9.7 | wall 45008
2022-03-14 00:32:02 | INFO | fairseq.trainer | begin training epoch 49
2022-03-14 00:32:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:35:37 | INFO | train_inner | epoch 049:     92 / 407 loss=5.538, nll_loss=5.119, ppl=34.76, wps=25162.8, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=19500, lr=0.000226455, gnorm=0.505, loss_scale=32, train_wall=209, gb_free=9.7, wall=45223
2022-03-14 00:39:30 | INFO | train_inner | epoch 049:    192 / 407 loss=5.565, nll_loss=5.148, ppl=35.45, wps=28221.7, ups=0.43, wpb=65534.2, bsz=128, num_updates=19600, lr=0.000225877, gnorm=0.503, loss_scale=32, train_wall=209, gb_free=9.7, wall=45455
2022-03-14 00:40:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:43:15 | INFO | train_inner | epoch 049:    293 / 407 loss=5.57, nll_loss=5.153, ppl=35.58, wps=29024.2, ups=0.44, wpb=65536, bsz=128, num_updates=19700, lr=0.000225303, gnorm=0.507, loss_scale=32, train_wall=202, gb_free=9.7, wall=45681
2022-03-14 00:45:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:47:07 | INFO | train_inner | epoch 049:    394 / 407 loss=5.577, nll_loss=5.16, ppl=35.76, wps=28262.6, ups=0.43, wpb=65536, bsz=128, num_updates=19800, lr=0.000224733, gnorm=0.504, loss_scale=32, train_wall=208, gb_free=9.7, wall=45912
2022-03-14 00:47:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:48:02 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 5.783 | nll_loss 5.346 | ppl 40.67 | wps 53159.7 | wpb 511.9 | bsz 1 | num_updates 19813 | best_loss 5.783
2022-03-14 00:48:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 19813 updates
2022-03-14 00:48:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:48:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:48:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 49 @ 19813 updates, score 5.783) (writing took 2.12795879796613 seconds)
2022-03-14 00:48:04 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-14 00:48:04 | INFO | train | epoch 049 | loss 5.563 | nll_loss 5.146 | ppl 35.4 | wps 27585.8 | ups 0.42 | wpb 65492.6 | bsz 127.9 | num_updates 19813 | lr 0.00022466 | gnorm 0.505 | loss_scale 32 | train_wall 838 | gb_free 9.7 | wall 45969
2022-03-14 00:48:04 | INFO | fairseq.trainer | begin training epoch 50
2022-03-14 00:48:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:49:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 00:51:31 | INFO | train_inner | epoch 050:     88 / 407 loss=5.534, nll_loss=5.115, ppl=34.66, wps=24812.9, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=19900, lr=0.000224168, gnorm=0.502, loss_scale=16, train_wall=212, gb_free=9.7, wall=46176
2022-03-14 00:55:21 | INFO | train_inner | epoch 050:    188 / 407 loss=5.55, nll_loss=5.132, ppl=35.06, wps=28435.8, ups=0.43, wpb=65534.2, bsz=128, num_updates=20000, lr=0.000223607, gnorm=0.505, loss_scale=32, train_wall=207, gb_free=9.7, wall=46406
2022-03-14 00:58:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 00:59:17 | INFO | train_inner | epoch 050:    289 / 407 loss=5.557, nll_loss=5.139, ppl=35.23, wps=27830, ups=0.42, wpb=65536, bsz=128, num_updates=20100, lr=0.00022305, gnorm=0.505, loss_scale=16, train_wall=212, gb_free=9.7, wall=46642
2022-03-14 01:03:02 | INFO | train_inner | epoch 050:    389 / 407 loss=5.578, nll_loss=5.162, ppl=35.79, wps=29107.5, ups=0.44, wpb=65536, bsz=128, num_updates=20200, lr=0.000222497, gnorm=0.507, loss_scale=32, train_wall=202, gb_free=9.7, wall=46867
2022-03-14 01:03:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 01:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:04:11 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 5.773 | nll_loss 5.338 | ppl 40.44 | wps 49567.1 | wpb 511.9 | bsz 1 | num_updates 20217 | best_loss 5.773
2022-03-14 01:04:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 20217 updates
2022-03-14 01:04:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:04:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:04:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 50 @ 20217 updates, score 5.773) (writing took 2.153421424969565 seconds)
2022-03-14 01:04:13 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-14 01:04:13 | INFO | train | epoch 050 | loss 5.555 | nll_loss 5.137 | ppl 35.19 | wps 27305.3 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 20217 | lr 0.000222404 | gnorm 0.505 | loss_scale 16 | train_wall 844 | gb_free 9.7 | wall 46938
2022-03-14 01:04:13 | INFO | fairseq.trainer | begin training epoch 51
2022-03-14 01:04:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:07:22 | INFO | train_inner | epoch 051:     83 / 407 loss=5.53, nll_loss=5.11, ppl=34.54, wps=25168.4, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=20300, lr=0.000221948, gnorm=0.512, loss_scale=16, train_wall=207, gb_free=9.7, wall=47127
2022-03-14 01:11:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 01:11:14 | INFO | train_inner | epoch 051:    184 / 407 loss=5.538, nll_loss=5.119, ppl=34.76, wps=28150.8, ups=0.43, wpb=65536, bsz=128, num_updates=20400, lr=0.000221404, gnorm=0.501, loss_scale=16, train_wall=209, gb_free=9.7, wall=47359
2022-03-14 01:15:04 | INFO | train_inner | epoch 051:    284 / 407 loss=5.557, nll_loss=5.139, ppl=35.23, wps=28514.7, ups=0.44, wpb=65536, bsz=128, num_updates=20500, lr=0.000220863, gnorm=0.512, loss_scale=16, train_wall=206, gb_free=9.7, wall=47589
2022-03-14 01:18:53 | INFO | train_inner | epoch 051:    384 / 407 loss=5.57, nll_loss=5.153, ppl=35.58, wps=28667.3, ups=0.44, wpb=65534.2, bsz=128, num_updates=20600, lr=0.000220326, gnorm=0.503, loss_scale=32, train_wall=205, gb_free=9.7, wall=47818
2022-03-14 01:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:20:14 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 5.771 | nll_loss 5.335 | ppl 40.36 | wps 49483.5 | wpb 511.9 | bsz 1 | num_updates 20623 | best_loss 5.771
2022-03-14 01:20:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 20623 updates
2022-03-14 01:20:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:20:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 51 @ 20623 updates, score 5.771) (writing took 2.1961329220212065 seconds)
2022-03-14 01:20:16 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-14 01:20:16 | INFO | train | epoch 051 | loss 5.548 | nll_loss 5.129 | ppl 35 | wps 27617.8 | ups 0.42 | wpb 65492.7 | bsz 127.9 | num_updates 20623 | lr 0.000220203 | gnorm 0.507 | loss_scale 32 | train_wall 838 | gb_free 9.7 | wall 47901
2022-03-14 01:20:16 | INFO | fairseq.trainer | begin training epoch 52
2022-03-14 01:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:21:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:23:17 | INFO | train_inner | epoch 052:     78 / 407 loss=5.525, nll_loss=5.106, ppl=34.43, wps=24772.5, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=20700, lr=0.000219793, gnorm=0.509, loss_scale=32, train_wall=211, gb_free=9.7, wall=48082
2022-03-14 01:23:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 01:27:04 | INFO | train_inner | epoch 052:    179 / 407 loss=5.539, nll_loss=5.12, ppl=34.77, wps=28770.3, ups=0.44, wpb=65536, bsz=128, num_updates=20800, lr=0.000219265, gnorm=0.509, loss_scale=16, train_wall=204, gb_free=9.7, wall=48310
2022-03-14 01:31:21 | INFO | train_inner | epoch 052:    279 / 407 loss=5.548, nll_loss=5.13, ppl=35.01, wps=25554.7, ups=0.39, wpb=65536, bsz=128, num_updates=20900, lr=0.000218739, gnorm=0.507, loss_scale=32, train_wall=232, gb_free=9.7, wall=48566
2022-03-14 01:34:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:35:42 | INFO | train_inner | epoch 052:    380 / 407 loss=5.551, nll_loss=5.133, ppl=35.09, wps=25117.6, ups=0.38, wpb=65536, bsz=128, num_updates=21000, lr=0.000218218, gnorm=0.514, loss_scale=32, train_wall=236, gb_free=9.7, wall=48827
2022-03-14 01:35:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 01:36:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:37:20 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 5.77 | nll_loss 5.334 | ppl 40.33 | wps 46618.2 | wpb 511.9 | bsz 1 | num_updates 21026 | best_loss 5.77
2022-03-14 01:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 21026 updates
2022-03-14 01:37:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:37:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:37:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 52 @ 21026 updates, score 5.77) (writing took 2.2699791279737838 seconds)
2022-03-14 01:37:22 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-14 01:37:22 | INFO | train | epoch 052 | loss 5.541 | nll_loss 5.122 | ppl 34.82 | wps 25712.2 | ups 0.39 | wpb 65492.3 | bsz 127.9 | num_updates 21026 | lr 0.000218083 | gnorm 0.509 | loss_scale 16 | train_wall 898 | gb_free 9.7 | wall 48927
2022-03-14 01:37:22 | INFO | fairseq.trainer | begin training epoch 53
2022-03-14 01:37:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:40:34 | INFO | train_inner | epoch 053:     74 / 407 loss=5.516, nll_loss=5.096, ppl=34.2, wps=22391.9, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=21100, lr=0.0002177, gnorm=0.511, loss_scale=16, train_wall=236, gb_free=9.7, wall=49119
2022-03-14 01:44:54 | INFO | train_inner | epoch 053:    174 / 407 loss=5.52, nll_loss=5.1, ppl=34.29, wps=25184.8, ups=0.38, wpb=65536, bsz=128, num_updates=21200, lr=0.000217186, gnorm=0.505, loss_scale=32, train_wall=236, gb_free=9.7, wall=49379
2022-03-14 01:47:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:49:15 | INFO | train_inner | epoch 053:    275 / 407 loss=5.553, nll_loss=5.135, ppl=35.14, wps=25116.5, ups=0.38, wpb=65534.2, bsz=128, num_updates=21300, lr=0.000216676, gnorm=0.506, loss_scale=32, train_wall=236, gb_free=9.7, wall=49640
2022-03-14 01:52:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:53:34 | INFO | train_inner | epoch 053:    376 / 407 loss=5.552, nll_loss=5.134, ppl=35.11, wps=25293.6, ups=0.39, wpb=65536, bsz=128, num_updates=21400, lr=0.000216169, gnorm=0.505, loss_scale=32, train_wall=234, gb_free=9.7, wall=49899
2022-03-14 01:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:55:22 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 5.771 | nll_loss 5.334 | ppl 40.33 | wps 46377 | wpb 511.9 | bsz 1 | num_updates 21431 | best_loss 5.77
2022-03-14 01:55:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 21431 updates
2022-03-14 01:55:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 01:55:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 01:55:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 53 @ 21431 updates, score 5.771) (writing took 1.2358751310384832 seconds)
2022-03-14 01:55:23 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-14 01:55:23 | INFO | train | epoch 053 | loss 5.533 | nll_loss 5.114 | ppl 34.64 | wps 24548.2 | ups 0.37 | wpb 65492.6 | bsz 127.9 | num_updates 21431 | lr 0.000216012 | gnorm 0.507 | loss_scale 32 | train_wall 951 | gb_free 9.7 | wall 50008
2022-03-14 01:55:23 | INFO | fairseq.trainer | begin training epoch 54
2022-03-14 01:55:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:58:22 | INFO | train_inner | epoch 054:     69 / 407 loss=5.496, nll_loss=5.075, ppl=33.71, wps=22695.5, ups=0.35, wpb=65360.1, bsz=127.7, num_updates=21500, lr=0.000215666, gnorm=0.502, loss_scale=32, train_wall=233, gb_free=9.7, wall=50187
2022-03-14 01:58:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:02:43 | INFO | train_inner | epoch 054:    170 / 407 loss=5.52, nll_loss=5.1, ppl=34.3, wps=25070.4, ups=0.38, wpb=65536, bsz=128, num_updates=21600, lr=0.000215166, gnorm=0.508, loss_scale=32, train_wall=237, gb_free=9.7, wall=50448
2022-03-14 02:04:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:06:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 02:07:05 | INFO | train_inner | epoch 054:    272 / 407 loss=5.538, nll_loss=5.119, ppl=34.74, wps=25030.7, ups=0.38, wpb=65536, bsz=128, num_updates=21700, lr=0.000214669, gnorm=0.502, loss_scale=16, train_wall=237, gb_free=9.7, wall=50710
2022-03-14 02:11:23 | INFO | train_inner | epoch 054:    372 / 407 loss=5.549, nll_loss=5.13, ppl=35.02, wps=25426.7, ups=0.39, wpb=65536, bsz=128, num_updates=21800, lr=0.000214176, gnorm=0.509, loss_scale=16, train_wall=233, gb_free=9.7, wall=50968
2022-03-14 02:12:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:13:21 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 5.769 | nll_loss 5.331 | ppl 40.24 | wps 45903 | wpb 511.9 | bsz 1 | num_updates 21835 | best_loss 5.769
2022-03-14 02:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 21835 updates
2022-03-14 02:13:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:13:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:13:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 54 @ 21835 updates, score 5.769) (writing took 2.326225424942095 seconds)
2022-03-14 02:13:24 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-14 02:13:24 | INFO | train | epoch 054 | loss 5.527 | nll_loss 5.108 | ppl 34.48 | wps 24480.5 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 21835 | lr 0.000214005 | gnorm 0.506 | loss_scale 32 | train_wall 950 | gb_free 9.7 | wall 51089
2022-03-14 02:13:24 | INFO | fairseq.trainer | begin training epoch 55
2022-03-14 02:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:14:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 02:16:14 | INFO | train_inner | epoch 055:     66 / 407 loss=5.52, nll_loss=5.1, ppl=34.29, wps=22467.2, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=21900, lr=0.000213687, gnorm=0.516, loss_scale=16, train_wall=235, gb_free=9.7, wall=51259
2022-03-14 02:20:32 | INFO | train_inner | epoch 055:    166 / 407 loss=5.512, nll_loss=5.092, ppl=34.1, wps=25369.5, ups=0.39, wpb=65536, bsz=128, num_updates=22000, lr=0.000213201, gnorm=0.506, loss_scale=32, train_wall=234, gb_free=9.7, wall=51517
2022-03-14 02:24:50 | INFO | train_inner | epoch 055:    266 / 407 loss=5.515, nll_loss=5.095, ppl=34.18, wps=25413, ups=0.39, wpb=65536, bsz=128, num_updates=22100, lr=0.000212718, gnorm=0.507, loss_scale=32, train_wall=233, gb_free=9.7, wall=51775
2022-03-14 02:25:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:29:10 | INFO | train_inner | epoch 055:    367 / 407 loss=5.532, nll_loss=5.113, ppl=34.6, wps=25200, ups=0.38, wpb=65534.2, bsz=128, num_updates=22200, lr=0.000212238, gnorm=0.505, loss_scale=32, train_wall=235, gb_free=9.7, wall=52035
2022-03-14 02:30:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:31:22 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 5.76 | nll_loss 5.323 | ppl 40.02 | wps 46055.9 | wpb 511.9 | bsz 1 | num_updates 22240 | best_loss 5.76
2022-03-14 02:31:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 22240 updates
2022-03-14 02:31:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:31:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:31:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 55 @ 22240 updates, score 5.76) (writing took 2.2905011129914783 seconds)
2022-03-14 02:31:24 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-14 02:31:24 | INFO | train | epoch 055 | loss 5.52 | nll_loss 5.1 | ppl 34.3 | wps 24549.8 | ups 0.37 | wpb 65492.6 | bsz 127.9 | num_updates 22240 | lr 0.000212047 | gnorm 0.509 | loss_scale 32 | train_wall 949 | gb_free 9.7 | wall 52169
2022-03-14 02:31:24 | INFO | fairseq.trainer | begin training epoch 56
2022-03-14 02:31:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:31:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 02:34:01 | INFO | train_inner | epoch 056:     61 / 407 loss=5.512, nll_loss=5.092, ppl=34.1, wps=22443.6, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=22300, lr=0.000211762, gnorm=0.517, loss_scale=16, train_wall=235, gb_free=9.7, wall=52326
2022-03-14 02:38:21 | INFO | train_inner | epoch 056:    161 / 407 loss=5.499, nll_loss=5.078, ppl=33.78, wps=25287.5, ups=0.39, wpb=65536, bsz=128, num_updates=22400, lr=0.000211289, gnorm=0.51, loss_scale=32, train_wall=234, gb_free=9.7, wall=52586
2022-03-14 02:39:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 02:42:41 | INFO | train_inner | epoch 056:    262 / 407 loss=5.519, nll_loss=5.1, ppl=34.29, wps=25122.7, ups=0.38, wpb=65536, bsz=128, num_updates=22500, lr=0.000210819, gnorm=0.507, loss_scale=16, train_wall=236, gb_free=9.7, wall=52846
2022-03-14 02:46:59 | INFO | train_inner | epoch 056:    362 / 407 loss=5.531, nll_loss=5.112, ppl=34.58, wps=25431.7, ups=0.39, wpb=65534.2, bsz=128, num_updates=22600, lr=0.000210352, gnorm=0.51, loss_scale=32, train_wall=233, gb_free=9.7, wall=53104
2022-03-14 02:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:49:23 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 5.754 | nll_loss 5.317 | ppl 39.87 | wps 46649.4 | wpb 511.9 | bsz 1 | num_updates 22645 | best_loss 5.754
2022-03-14 02:49:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 22645 updates
2022-03-14 02:49:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:49:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:49:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 56 @ 22645 updates, score 5.754) (writing took 2.2181076040142216 seconds)
2022-03-14 02:49:25 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-14 02:49:25 | INFO | train | epoch 056 | loss 5.514 | nll_loss 5.094 | ppl 34.15 | wps 24541.3 | ups 0.37 | wpb 65492.6 | bsz 127.9 | num_updates 22645 | lr 0.000210142 | gnorm 0.51 | loss_scale 32 | train_wall 950 | gb_free 9.7 | wall 53250
2022-03-14 02:49:25 | INFO | fairseq.trainer | begin training epoch 57
2022-03-14 02:49:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:50:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:51:50 | INFO | train_inner | epoch 057:     56 / 407 loss=5.504, nll_loss=5.083, ppl=33.89, wps=22455.1, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=22700, lr=0.000209888, gnorm=0.508, loss_scale=32, train_wall=235, gb_free=9.7, wall=53395
2022-03-14 02:53:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 02:56:11 | INFO | train_inner | epoch 057:    157 / 407 loss=5.49, nll_loss=5.069, ppl=33.56, wps=25134.6, ups=0.38, wpb=65536, bsz=128, num_updates=22800, lr=0.000209427, gnorm=0.509, loss_scale=16, train_wall=236, gb_free=9.7, wall=53656
2022-03-14 03:00:30 | INFO | train_inner | epoch 057:    257 / 407 loss=5.51, nll_loss=5.089, ppl=34.04, wps=25249.8, ups=0.39, wpb=65534.2, bsz=128, num_updates=22900, lr=0.000208969, gnorm=0.514, loss_scale=32, train_wall=235, gb_free=9.7, wall=53916
2022-03-14 03:01:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 03:04:51 | INFO | train_inner | epoch 057:    358 / 407 loss=5.528, nll_loss=5.109, ppl=34.5, wps=25164.4, ups=0.38, wpb=65536, bsz=128, num_updates=23000, lr=0.000208514, gnorm=0.51, loss_scale=16, train_wall=236, gb_free=9.7, wall=54176
2022-03-14 03:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:07:25 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 5.759 | nll_loss 5.32 | ppl 39.94 | wps 46246.8 | wpb 511.9 | bsz 1 | num_updates 23049 | best_loss 5.754
2022-03-14 03:07:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 23049 updates
2022-03-14 03:07:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 03:07:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 03:07:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 57 @ 23049 updates, score 5.759) (writing took 1.2509032089728862 seconds)
2022-03-14 03:07:26 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-14 03:07:26 | INFO | train | epoch 057 | loss 5.508 | nll_loss 5.087 | ppl 33.99 | wps 24476.9 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 23049 | lr 0.000208293 | gnorm 0.51 | loss_scale 16 | train_wall 951 | gb_free 9.7 | wall 54331
2022-03-14 03:07:26 | INFO | fairseq.trainer | begin training epoch 58
2022-03-14 03:07:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:09:38 | INFO | train_inner | epoch 058:     51 / 407 loss=5.5, nll_loss=5.079, ppl=33.81, wps=22755, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=23100, lr=0.000208063, gnorm=0.511, loss_scale=32, train_wall=232, gb_free=9.7, wall=54463
2022-03-14 03:11:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 03:13:59 | INFO | train_inner | epoch 058:    152 / 407 loss=5.487, nll_loss=5.065, ppl=33.47, wps=25110.2, ups=0.38, wpb=65536, bsz=128, num_updates=23200, lr=0.000207614, gnorm=0.513, loss_scale=16, train_wall=236, gb_free=9.7, wall=54724
2022-03-14 03:17:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 03:18:22 | INFO | train_inner | epoch 058:    253 / 407 loss=5.499, nll_loss=5.078, ppl=33.77, wps=24929.3, ups=0.38, wpb=65534.2, bsz=128, num_updates=23300, lr=0.000207168, gnorm=0.511, loss_scale=16, train_wall=238, gb_free=9.7, wall=54987
2022-03-14 03:22:38 | INFO | train_inner | epoch 058:    353 / 407 loss=5.521, nll_loss=5.101, ppl=34.33, wps=25563.8, ups=0.39, wpb=65536, bsz=128, num_updates=23400, lr=0.000206725, gnorm=0.508, loss_scale=16, train_wall=232, gb_free=9.7, wall=55243
2022-03-14 03:24:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:25:25 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 5.759 | nll_loss 5.321 | ppl 39.97 | wps 46364.2 | wpb 511.9 | bsz 1 | num_updates 23454 | best_loss 5.754
2022-03-14 03:25:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 23454 updates
2022-03-14 03:25:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 03:25:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 03:25:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 58 @ 23454 updates, score 5.759) (writing took 1.2932065069908276 seconds)
2022-03-14 03:25:26 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-14 03:25:26 | INFO | train | epoch 058 | loss 5.501 | nll_loss 5.081 | ppl 33.84 | wps 24546.8 | ups 0.37 | wpb 65492.6 | bsz 127.9 | num_updates 23454 | lr 0.000206486 | gnorm 0.511 | loss_scale 32 | train_wall 950 | gb_free 9.7 | wall 55411
2022-03-14 03:25:26 | INFO | fairseq.trainer | begin training epoch 59
2022-03-14 03:25:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:25:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 03:27:27 | INFO | train_inner | epoch 059:     47 / 407 loss=5.5, nll_loss=5.079, ppl=33.8, wps=22643.6, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=23500, lr=0.000206284, gnorm=0.508, loss_scale=16, train_wall=234, gb_free=9.7, wall=55532
2022-03-14 03:31:43 | INFO | train_inner | epoch 059:    147 / 407 loss=5.475, nll_loss=5.053, ppl=33.19, wps=25585.4, ups=0.39, wpb=65534.2, bsz=128, num_updates=23600, lr=0.000205847, gnorm=0.512, loss_scale=32, train_wall=232, gb_free=9.7, wall=55788
2022-03-14 03:32:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 03:36:02 | INFO | train_inner | epoch 059:    248 / 407 loss=5.5, nll_loss=5.079, ppl=33.8, wps=25279.2, ups=0.39, wpb=65536, bsz=128, num_updates=23700, lr=0.000205412, gnorm=0.515, loss_scale=16, train_wall=235, gb_free=9.7, wall=56047
2022-03-14 03:40:19 | INFO | train_inner | epoch 059:    348 / 407 loss=5.506, nll_loss=5.085, ppl=33.95, wps=25531.9, ups=0.39, wpb=65536, bsz=128, num_updates=23800, lr=0.00020498, gnorm=0.513, loss_scale=32, train_wall=232, gb_free=9.7, wall=56304
2022-03-14 03:42:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 03:42:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:43:18 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 5.752 | nll_loss 5.313 | ppl 39.75 | wps 46599.2 | wpb 511.9 | bsz 1 | num_updates 23858 | best_loss 5.752
2022-03-14 03:43:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 23858 updates
2022-03-14 03:43:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:43:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 59 @ 23858 updates, score 5.752) (writing took 2.223800143052358 seconds)
2022-03-14 03:43:20 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-14 03:43:20 | INFO | train | epoch 059 | loss 5.496 | nll_loss 5.075 | ppl 33.71 | wps 24641 | ups 0.38 | wpb 65492.5 | bsz 127.9 | num_updates 23858 | lr 0.000204731 | gnorm 0.513 | loss_scale 16 | train_wall 943 | gb_free 9.7 | wall 56485
2022-03-14 03:43:20 | INFO | fairseq.trainer | begin training epoch 60
2022-03-14 03:43:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:45:08 | INFO | train_inner | epoch 060:     42 / 407 loss=5.499, nll_loss=5.078, ppl=33.77, wps=22587.3, ups=0.35, wpb=65360.1, bsz=127.7, num_updates=23900, lr=0.000204551, gnorm=0.515, loss_scale=16, train_wall=234, gb_free=9.7, wall=56594
2022-03-14 03:49:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 03:49:29 | INFO | train_inner | epoch 060:    143 / 407 loss=5.472, nll_loss=5.05, ppl=33.12, wps=25168.6, ups=0.38, wpb=65536, bsz=128, num_updates=24000, lr=0.000204124, gnorm=0.511, loss_scale=16, train_wall=236, gb_free=9.7, wall=56854
2022-03-14 03:53:51 | INFO | train_inner | epoch 060:    243 / 407 loss=5.487, nll_loss=5.066, ppl=33.49, wps=25038.9, ups=0.38, wpb=65536, bsz=128, num_updates=24100, lr=0.0002037, gnorm=0.514, loss_scale=16, train_wall=237, gb_free=9.7, wall=57116
2022-03-14 03:58:09 | INFO | train_inner | epoch 060:    343 / 407 loss=5.512, nll_loss=5.091, ppl=34.09, wps=25392.6, ups=0.39, wpb=65536, bsz=128, num_updates=24200, lr=0.000203279, gnorm=0.51, loss_scale=32, train_wall=234, gb_free=9.7, wall=57374
2022-03-14 04:00:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:01:21 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 5.747 | nll_loss 5.309 | ppl 39.64 | wps 46463.9 | wpb 511.9 | bsz 1 | num_updates 24263 | best_loss 5.747
2022-03-14 04:01:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 24263 updates
2022-03-14 04:01:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:01:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:01:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 60 @ 24263 updates, score 5.747) (writing took 2.286072298011277 seconds)
2022-03-14 04:01:24 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-14 04:01:24 | INFO | train | epoch 060 | loss 5.491 | nll_loss 5.069 | ppl 33.57 | wps 24478.3 | ups 0.37 | wpb 65492.6 | bsz 127.9 | num_updates 24263 | lr 0.000203015 | gnorm 0.512 | loss_scale 32 | train_wall 952 | gb_free 9.7 | wall 57569
2022-03-14 04:01:24 | INFO | fairseq.trainer | begin training epoch 61
2022-03-14 04:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:03:00 | INFO | train_inner | epoch 061:     37 / 407 loss=5.495, nll_loss=5.073, ppl=33.67, wps=22472, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=24300, lr=0.00020286, gnorm=0.515, loss_scale=32, train_wall=235, gb_free=9.7, wall=57665
2022-03-14 04:04:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 04:07:21 | INFO | train_inner | epoch 061:    138 / 407 loss=5.467, nll_loss=5.044, ppl=33, wps=25023.9, ups=0.38, wpb=65536, bsz=128, num_updates=24400, lr=0.000202444, gnorm=0.507, loss_scale=16, train_wall=237, gb_free=9.7, wall=57926
2022-03-14 04:11:40 | INFO | train_inner | epoch 061:    238 / 407 loss=5.478, nll_loss=5.056, ppl=33.26, wps=25313.8, ups=0.39, wpb=65534.2, bsz=128, num_updates=24500, lr=0.000202031, gnorm=0.514, loss_scale=32, train_wall=234, gb_free=9.7, wall=58185
2022-03-14 04:15:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:16:00 | INFO | train_inner | epoch 061:    339 / 407 loss=5.505, nll_loss=5.085, ppl=33.93, wps=25276.2, ups=0.39, wpb=65536, bsz=128, num_updates=24600, lr=0.000201619, gnorm=0.511, loss_scale=32, train_wall=235, gb_free=9.7, wall=58445
2022-03-14 04:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:19:24 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 5.75 | nll_loss 5.309 | ppl 39.65 | wps 45862.3 | wpb 511.9 | bsz 1 | num_updates 24668 | best_loss 5.747
2022-03-14 04:19:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 24668 updates
2022-03-14 04:19:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:19:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:19:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 61 @ 24668 updates, score 5.75) (writing took 1.3253171439864673 seconds)
2022-03-14 04:19:26 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-14 04:19:26 | INFO | train | epoch 061 | loss 5.486 | nll_loss 5.064 | ppl 33.44 | wps 24514.9 | ups 0.37 | wpb 65492.6 | bsz 127.9 | num_updates 24668 | lr 0.000201341 | gnorm 0.512 | loss_scale 32 | train_wall 951 | gb_free 9.7 | wall 58651
2022-03-14 04:19:26 | INFO | fairseq.trainer | begin training epoch 62
2022-03-14 04:19:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:20:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 04:20:51 | INFO | train_inner | epoch 062:     33 / 407 loss=5.49, nll_loss=5.069, ppl=33.56, wps=22430.6, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=24700, lr=0.000201211, gnorm=0.515, loss_scale=16, train_wall=236, gb_free=9.7, wall=58736
2022-03-14 04:25:07 | INFO | train_inner | epoch 062:    133 / 407 loss=5.465, nll_loss=5.042, ppl=32.96, wps=25609.2, ups=0.39, wpb=65534.2, bsz=128, num_updates=24800, lr=0.000200805, gnorm=0.513, loss_scale=16, train_wall=231, gb_free=9.7, wall=58992
2022-03-14 04:28:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 04:29:28 | INFO | train_inner | epoch 062:    234 / 407 loss=5.475, nll_loss=5.052, ppl=33.19, wps=25070, ups=0.38, wpb=65536, bsz=128, num_updates=24900, lr=0.000200401, gnorm=0.513, loss_scale=16, train_wall=237, gb_free=9.7, wall=59253
2022-03-14 04:33:45 | INFO | train_inner | epoch 062:    334 / 407 loss=5.495, nll_loss=5.074, ppl=33.68, wps=25525.3, ups=0.39, wpb=65536, bsz=128, num_updates=25000, lr=0.0002, gnorm=0.517, loss_scale=16, train_wall=232, gb_free=9.7, wall=59510
2022-03-14 04:36:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:37:21 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 5.743 | nll_loss 5.304 | ppl 39.49 | wps 46578.7 | wpb 511.9 | bsz 1 | num_updates 25073 | best_loss 5.743
2022-03-14 04:37:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 25073 updates
2022-03-14 04:37:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:37:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 62 @ 25073 updates, score 5.743) (writing took 2.236644436023198 seconds)
2022-03-14 04:37:23 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-14 04:37:23 | INFO | train | epoch 062 | loss 5.48 | nll_loss 5.058 | ppl 33.31 | wps 24622.8 | ups 0.38 | wpb 65492.6 | bsz 127.9 | num_updates 25073 | lr 0.000199709 | gnorm 0.516 | loss_scale 32 | train_wall 947 | gb_free 9.7 | wall 59728
2022-03-14 04:37:23 | INFO | fairseq.trainer | begin training epoch 63
2022-03-14 04:37:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:38:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 04:38:35 | INFO | train_inner | epoch 063:     28 / 407 loss=5.482, nll_loss=5.06, ppl=33.36, wps=22548.2, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=25100, lr=0.000199601, gnorm=0.52, loss_scale=16, train_wall=234, gb_free=9.7, wall=59800
2022-03-14 04:42:50 | INFO | train_inner | epoch 063:    128 / 407 loss=5.463, nll_loss=5.04, ppl=32.9, wps=25652, ups=0.39, wpb=65536, bsz=128, num_updates=25200, lr=0.000199205, gnorm=0.517, loss_scale=16, train_wall=231, gb_free=9.7, wall=60055
2022-03-14 04:47:03 | INFO | train_inner | epoch 063:    228 / 407 loss=5.468, nll_loss=5.045, ppl=33.02, wps=25937.7, ups=0.4, wpb=65534.2, bsz=128, num_updates=25300, lr=0.000198811, gnorm=0.518, loss_scale=32, train_wall=228, gb_free=9.7, wall=60308
2022-03-14 04:47:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 04:51:19 | INFO | train_inner | epoch 063:    329 / 407 loss=5.489, nll_loss=5.067, ppl=33.53, wps=25566.3, ups=0.39, wpb=65536, bsz=128, num_updates=25400, lr=0.000198419, gnorm=0.514, loss_scale=16, train_wall=232, gb_free=9.7, wall=60564
2022-03-14 04:54:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 04:54:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:55:06 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 5.744 | nll_loss 5.306 | ppl 39.56 | wps 46889 | wpb 511.9 | bsz 1 | num_updates 25477 | best_loss 5.743
2022-03-14 04:55:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 25477 updates
2022-03-14 04:55:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:55:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:55:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 63 @ 25477 updates, score 5.744) (writing took 1.2790626889909618 seconds)
2022-03-14 04:55:07 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-14 04:55:07 | INFO | train | epoch 063 | loss 5.475 | nll_loss 5.053 | ppl 33.19 | wps 24870.9 | ups 0.38 | wpb 65492.5 | bsz 127.9 | num_updates 25477 | lr 0.000198119 | gnorm 0.516 | loss_scale 16 | train_wall 935 | gb_free 9.7 | wall 60792
2022-03-14 04:55:07 | INFO | fairseq.trainer | begin training epoch 64
2022-03-14 04:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:56:05 | INFO | train_inner | epoch 064:     23 / 407 loss=5.483, nll_loss=5.061, ppl=33.38, wps=22856.3, ups=0.35, wpb=65360.1, bsz=127.7, num_updates=25500, lr=0.00019803, gnorm=0.518, loss_scale=16, train_wall=232, gb_free=9.7, wall=60850
2022-03-14 05:00:20 | INFO | train_inner | epoch 064:    123 / 407 loss=5.452, nll_loss=5.029, ppl=32.64, wps=25773, ups=0.39, wpb=65536, bsz=128, num_updates=25600, lr=0.000197642, gnorm=0.519, loss_scale=32, train_wall=230, gb_free=9.7, wall=61105
2022-03-14 05:03:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 05:04:37 | INFO | train_inner | epoch 064:    224 / 407 loss=5.47, nll_loss=5.048, ppl=33.07, wps=25509, ups=0.39, wpb=65536, bsz=128, num_updates=25700, lr=0.000197257, gnorm=0.516, loss_scale=16, train_wall=232, gb_free=9.7, wall=61362
2022-03-14 05:08:50 | INFO | train_inner | epoch 064:    324 / 407 loss=5.477, nll_loss=5.054, ppl=33.23, wps=25876.3, ups=0.39, wpb=65536, bsz=128, num_updates=25800, lr=0.000196875, gnorm=0.516, loss_scale=32, train_wall=229, gb_free=9.7, wall=61615
2022-03-14 05:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 05:12:48 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 5.743 | nll_loss 5.303 | ppl 39.48 | wps 46889.7 | wpb 511.9 | bsz 1 | num_updates 25883 | best_loss 5.743
2022-03-14 05:12:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 25883 updates
2022-03-14 05:12:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:12:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:12:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 64 @ 25883 updates, score 5.743) (writing took 2.334940403990913 seconds)
2022-03-14 05:12:51 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-14 05:12:51 | INFO | train | epoch 064 | loss 5.47 | nll_loss 5.048 | ppl 33.08 | wps 24992.5 | ups 0.38 | wpb 65492.7 | bsz 127.9 | num_updates 25883 | lr 0.000196559 | gnorm 0.518 | loss_scale 32 | train_wall 934 | gb_free 9.7 | wall 61856
2022-03-14 05:12:51 | INFO | fairseq.trainer | begin training epoch 65
2022-03-14 05:12:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 05:13:34 | INFO | train_inner | epoch 065:     17 / 407 loss=5.484, nll_loss=5.062, ppl=33.4, wps=22995.7, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=25900, lr=0.000196494, gnorm=0.52, loss_scale=32, train_wall=229, gb_free=9.7, wall=61899
2022-03-14 05:14:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 05:17:49 | INFO | train_inner | epoch 065:    118 / 407 loss=5.452, nll_loss=5.028, ppl=32.63, wps=25735.9, ups=0.39, wpb=65536, bsz=128, num_updates=26000, lr=0.000196116, gnorm=0.515, loss_scale=16, train_wall=230, gb_free=9.7, wall=62154
2022-03-14 05:20:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 05:22:07 | INFO | train_inner | epoch 065:    219 / 407 loss=5.458, nll_loss=5.035, ppl=32.78, wps=25350.3, ups=0.39, wpb=65536, bsz=128, num_updates=26100, lr=0.00019574, gnorm=0.515, loss_scale=16, train_wall=234, gb_free=9.7, wall=62412
2022-03-14 05:26:19 | INFO | train_inner | epoch 065:    319 / 407 loss=5.481, nll_loss=5.059, ppl=33.33, wps=26061.5, ups=0.4, wpb=65534.2, bsz=128, num_updates=26200, lr=0.000195366, gnorm=0.517, loss_scale=16, train_wall=227, gb_free=9.7, wall=62664
2022-03-14 05:29:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 05:30:27 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 5.734 | nll_loss 5.295 | ppl 39.25 | wps 47831.9 | wpb 511.9 | bsz 1 | num_updates 26288 | best_loss 5.734
2022-03-14 05:30:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 26288 updates
2022-03-14 05:30:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:30:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:30:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 65 @ 26288 updates, score 5.734) (writing took 2.2302555589703843 seconds)
2022-03-14 05:30:30 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-14 05:30:30 | INFO | train | epoch 065 | loss 5.465 | nll_loss 5.041 | ppl 32.93 | wps 25046.6 | ups 0.38 | wpb 65492.6 | bsz 127.9 | num_updates 26288 | lr 0.000195039 | gnorm 0.514 | loss_scale 32 | train_wall 930 | gb_free 9.7 | wall 62915
2022-03-14 05:30:30 | INFO | fairseq.trainer | begin training epoch 66
2022-03-14 05:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 05:31:01 | INFO | train_inner | epoch 066:     12 / 407 loss=5.466, nll_loss=5.043, ppl=32.98, wps=23191.5, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=26300, lr=0.000194994, gnorm=0.511, loss_scale=32, train_wall=227, gb_free=9.7, wall=62946
2022-03-14 05:32:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 05:35:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 05:35:18 | INFO | train_inner | epoch 066:    114 / 407 loss=5.436, nll_loss=5.011, ppl=32.24, wps=25492.1, ups=0.39, wpb=65536, bsz=128, num_updates=26400, lr=0.000194625, gnorm=0.518, loss_scale=16, train_wall=232, gb_free=9.7, wall=63203
2022-03-14 05:39:31 | INFO | train_inner | epoch 066:    214 / 407 loss=5.462, nll_loss=5.039, ppl=32.88, wps=25868.1, ups=0.39, wpb=65536, bsz=128, num_updates=26500, lr=0.000194257, gnorm=0.521, loss_scale=16, train_wall=229, gb_free=9.7, wall=63456
2022-03-14 05:40:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 05:43:48 | INFO | train_inner | epoch 066:    315 / 407 loss=5.465, nll_loss=5.042, ppl=32.94, wps=25499, ups=0.39, wpb=65536, bsz=128, num_updates=26600, lr=0.000193892, gnorm=0.524, loss_scale=16, train_wall=232, gb_free=9.7, wall=63713
2022-03-14 05:46:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 05:47:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 05:48:09 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 5.736 | nll_loss 5.296 | ppl 39.28 | wps 46672.7 | wpb 511.9 | bsz 1 | num_updates 26691 | best_loss 5.734
2022-03-14 05:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 26691 updates
2022-03-14 05:48:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 05:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 05:48:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 66 @ 26691 updates, score 5.736) (writing took 1.3187947109690867 seconds)
2022-03-14 05:48:10 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-14 05:48:10 | INFO | train | epoch 066 | loss 5.459 | nll_loss 5.036 | ppl 32.81 | wps 24886.9 | ups 0.38 | wpb 65492.3 | bsz 127.9 | num_updates 26691 | lr 0.000193561 | gnorm 0.519 | loss_scale 16 | train_wall 931 | gb_free 9.7 | wall 63975
2022-03-14 05:48:10 | INFO | fairseq.trainer | begin training epoch 67
2022-03-14 05:48:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 05:48:33 | INFO | train_inner | epoch 067:      9 / 407 loss=5.477, nll_loss=5.055, ppl=33.24, wps=22910.2, ups=0.35, wpb=65360.1, bsz=127.7, num_updates=26700, lr=0.000193528, gnorm=0.516, loss_scale=16, train_wall=231, gb_free=9.7, wall=63998
2022-03-14 05:52:47 | INFO | train_inner | epoch 067:    109 / 407 loss=5.427, nll_loss=5.002, ppl=32.05, wps=25784.3, ups=0.39, wpb=65536, bsz=128, num_updates=26800, lr=0.000193167, gnorm=0.52, loss_scale=32, train_wall=230, gb_free=9.7, wall=64253
2022-03-14 05:53:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 05:57:03 | INFO | train_inner | epoch 067:    210 / 407 loss=5.453, nll_loss=5.029, ppl=32.66, wps=25639.7, ups=0.39, wpb=65534.2, bsz=128, num_updates=26900, lr=0.000192807, gnorm=0.523, loss_scale=16, train_wall=231, gb_free=9.7, wall=64508
2022-03-14 06:01:18 | INFO | train_inner | epoch 067:    310 / 407 loss=5.467, nll_loss=5.044, ppl=32.99, wps=25690.6, ups=0.39, wpb=65536, bsz=128, num_updates=27000, lr=0.00019245, gnorm=0.517, loss_scale=32, train_wall=231, gb_free=9.7, wall=64763
2022-03-14 06:02:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 06:05:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 06:05:52 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 5.74 | nll_loss 5.299 | ppl 39.36 | wps 47308.6 | wpb 511.9 | bsz 1 | num_updates 27096 | best_loss 5.734
2022-03-14 06:05:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 27096 updates
2022-03-14 06:05:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:05:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:05:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 67 @ 27096 updates, score 5.74) (writing took 1.218555085011758 seconds)
2022-03-14 06:05:53 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-14 06:05:53 | INFO | train | epoch 067 | loss 5.456 | nll_loss 5.032 | ppl 32.73 | wps 24961.4 | ups 0.38 | wpb 65492.6 | bsz 127.9 | num_updates 27096 | lr 0.000192109 | gnorm 0.52 | loss_scale 16 | train_wall 934 | gb_free 9.7 | wall 65038
2022-03-14 06:05:53 | INFO | fairseq.trainer | begin training epoch 68
2022-03-14 06:05:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 06:06:03 | INFO | train_inner | epoch 068:      4 / 407 loss=5.478, nll_loss=5.055, ppl=33.25, wps=22940.1, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=27100, lr=0.000192095, gnorm=0.521, loss_scale=16, train_wall=231, gb_free=9.7, wall=65048
2022-03-14 06:08:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 06:10:19 | INFO | train_inner | epoch 068:    105 / 407 loss=5.424, nll_loss=4.999, ppl=31.98, wps=25583.6, ups=0.39, wpb=65534.2, bsz=128, num_updates=27200, lr=0.000191741, gnorm=0.519, loss_scale=16, train_wall=232, gb_free=9.7, wall=65304
2022-03-14 06:14:30 | INFO | train_inner | epoch 068:    205 / 407 loss=5.443, nll_loss=5.019, ppl=32.43, wps=26089.7, ups=0.4, wpb=65536, bsz=128, num_updates=27300, lr=0.00019139, gnorm=0.517, loss_scale=32, train_wall=227, gb_free=9.7, wall=65555
2022-03-14 06:17:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 06:18:45 | INFO | train_inner | epoch 068:    306 / 407 loss=5.464, nll_loss=5.041, ppl=32.92, wps=25709.3, ups=0.39, wpb=65536, bsz=128, num_updates=27400, lr=0.00019104, gnorm=0.517, loss_scale=16, train_wall=230, gb_free=9.7, wall=65810
2022-03-14 06:22:54 | INFO | train_inner | epoch 068:    406 / 407 loss=5.475, nll_loss=5.052, ppl=33.18, wps=26375.3, ups=0.4, wpb=65536, bsz=128, num_updates=27500, lr=0.000190693, gnorm=0.516, loss_scale=16, train_wall=224, gb_free=9.7, wall=66059
2022-03-14 06:22:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 06:23:24 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 5.733 | nll_loss 5.292 | ppl 39.18 | wps 47852.1 | wpb 511.9 | bsz 1 | num_updates 27501 | best_loss 5.733
2022-03-14 06:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 27501 updates
2022-03-14 06:23:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 06:23:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 06:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 68 @ 27501 updates, score 5.733) (writing took 2.2909158960101195 seconds)
2022-03-14 06:23:26 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-14 06:23:26 | INFO | train | epoch 068 | loss 5.451 | nll_loss 5.027 | ppl 32.61 | wps 25187.3 | ups 0.38 | wpb 65492.6 | bsz 127.9 | num_updates 27501 | lr 0.000190689 | gnorm 0.518 | loss_scale 16 | train_wall 924 | gb_free 9.7 | wall 66091
2022-03-14 06:23:26 | INFO | fairseq.trainer | begin training epoch 69
2022-03-14 06:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 06:24:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 06:27:34 | INFO | train_inner | epoch 069:    100 / 407 loss=5.426, nll_loss=5.001, ppl=32.02, wps=23306.4, ups=0.36, wpb=65361.9, bsz=127.7, num_updates=27600, lr=0.000190347, gnorm=0.523, loss_scale=16, train_wall=226, gb_free=9.7, wall=66339
2022-03-14 06:31:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 06:31:44 | INFO | train_inner | epoch 069:    201 / 407 loss=5.439, nll_loss=5.014, ppl=32.32, wps=26226.8, ups=0.4, wpb=65536, bsz=128, num_updates=27700, lr=0.000190003, gnorm=0.523, loss_scale=16, train_wall=226, gb_free=9.7, wall=66589
2022-03-14 06:35:49 | INFO | train_inner | epoch 069:    301 / 407 loss=5.453, nll_loss=5.029, ppl=32.65, wps=26749.5, ups=0.41, wpb=65536, bsz=128, num_updates=27800, lr=0.000189661, gnorm=0.517, loss_scale=16, train_wall=221, gb_free=9.7, wall=66834
2022-03-14 06:37:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 06:39:54 | INFO | train_inner | epoch 069:    402 / 407 loss=5.469, nll_loss=5.046, ppl=33.04, wps=26711.8, ups=0.41, wpb=65534.2, bsz=128, num_updates=27900, lr=0.000189321, gnorm=0.518, loss_scale=16, train_wall=221, gb_free=9.7, wall=67080
2022-03-14 06:40:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 06:40:33 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 5.732 | nll_loss 5.291 | ppl 39.14 | wps 49090 | wpb 511.9 | bsz 1 | num_updates 27905 | best_loss 5.732
2022-03-14 06:40:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 27905 updates
2022-03-14 06:40:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 06:40:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 06:40:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 69 @ 27905 updates, score 5.732) (writing took 2.2620310130296275 seconds)
2022-03-14 06:40:36 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-14 06:40:36 | INFO | train | epoch 069 | loss 5.447 | nll_loss 5.023 | ppl 32.51 | wps 25698.5 | ups 0.39 | wpb 65492.5 | bsz 127.9 | num_updates 27905 | lr 0.000189304 | gnorm 0.52 | loss_scale 16 | train_wall 902 | gb_free 9.7 | wall 67121
2022-03-14 06:40:36 | INFO | fairseq.trainer | begin training epoch 70
2022-03-14 06:40:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 06:44:27 | INFO | train_inner | epoch 070:     95 / 407 loss=5.416, nll_loss=4.99, ppl=31.79, wps=23998.6, ups=0.37, wpb=65361.9, bsz=127.7, num_updates=28000, lr=0.000188982, gnorm=0.522, loss_scale=32, train_wall=219, gb_free=9.7, wall=67352
2022-03-14 06:48:29 | INFO | train_inner | epoch 070:    195 / 407 loss=5.431, nll_loss=5.006, ppl=32.12, wps=27088.5, ups=0.41, wpb=65536, bsz=128, num_updates=28100, lr=0.000188646, gnorm=0.519, loss_scale=64, train_wall=218, gb_free=9.7, wall=67594
2022-03-14 06:48:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 06:52:37 | INFO | train_inner | epoch 070:    296 / 407 loss=5.458, nll_loss=5.034, ppl=32.77, wps=26434.9, ups=0.4, wpb=65534.2, bsz=128, num_updates=28200, lr=0.000188311, gnorm=0.518, loss_scale=32, train_wall=224, gb_free=9.7, wall=67842
2022-03-14 06:53:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 06:56:42 | INFO | train_inner | epoch 070:    397 / 407 loss=5.463, nll_loss=5.04, ppl=32.9, wps=26733.9, ups=0.41, wpb=65536, bsz=128, num_updates=28300, lr=0.000187978, gnorm=0.522, loss_scale=32, train_wall=221, gb_free=9.7, wall=68087
2022-03-14 06:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 06:57:32 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 5.731 | nll_loss 5.29 | ppl 39.12 | wps 49039.1 | wpb 511.9 | bsz 1 | num_updates 28310 | best_loss 5.731
2022-03-14 06:57:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 28310 updates
2022-03-14 06:57:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 06:57:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 06:57:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 70 @ 28310 updates, score 5.731) (writing took 2.2398918860126287 seconds)
2022-03-14 06:57:35 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-14 06:57:35 | INFO | train | epoch 070 | loss 5.443 | nll_loss 5.018 | ppl 32.41 | wps 26027.4 | ups 0.4 | wpb 65492.6 | bsz 127.9 | num_updates 28310 | lr 0.000187945 | gnorm 0.52 | loss_scale 32 | train_wall 892 | gb_free 9.7 | wall 68140
2022-03-14 06:57:35 | INFO | fairseq.trainer | begin training epoch 71
2022-03-14 06:57:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 06:59:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 07:01:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:01:19 | INFO | train_inner | epoch 071:     92 / 407 loss=5.414, nll_loss=4.989, ppl=31.75, wps=23617.3, ups=0.36, wpb=65360.1, bsz=127.7, num_updates=28400, lr=0.000187647, gnorm=0.52, loss_scale=16, train_wall=223, gb_free=9.7, wall=68364
2022-03-14 07:05:22 | INFO | train_inner | epoch 071:    192 / 407 loss=5.432, nll_loss=5.007, ppl=32.16, wps=26925.7, ups=0.41, wpb=65536, bsz=128, num_updates=28500, lr=0.000187317, gnorm=0.516, loss_scale=16, train_wall=219, gb_free=9.7, wall=68607
2022-03-14 07:07:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:09:31 | INFO | train_inner | epoch 071:    293 / 407 loss=5.447, nll_loss=5.022, ppl=32.5, wps=26366.3, ups=0.4, wpb=65536, bsz=128, num_updates=28600, lr=0.000186989, gnorm=0.526, loss_scale=16, train_wall=224, gb_free=9.7, wall=68856
2022-03-14 07:13:33 | INFO | train_inner | epoch 071:    393 / 407 loss=5.457, nll_loss=5.034, ppl=32.76, wps=27042.8, ups=0.41, wpb=65536, bsz=128, num_updates=28700, lr=0.000186663, gnorm=0.526, loss_scale=32, train_wall=218, gb_free=9.7, wall=69098
2022-03-14 07:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:14:34 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 5.721 | nll_loss 5.28 | ppl 38.86 | wps 49232.7 | wpb 511.9 | bsz 1 | num_updates 28714 | best_loss 5.721
2022-03-14 07:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 28714 updates
2022-03-14 07:14:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 07:14:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 07:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 71 @ 28714 updates, score 5.721) (writing took 2.34331825299887 seconds)
2022-03-14 07:14:36 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-14 07:14:36 | INFO | train | epoch 071 | loss 5.438 | nll_loss 5.013 | ppl 32.3 | wps 25908.8 | ups 0.4 | wpb 65492.5 | bsz 127.9 | num_updates 28714 | lr 0.000186618 | gnorm 0.522 | loss_scale 32 | train_wall 894 | gb_free 9.7 | wall 69161
2022-03-14 07:14:36 | INFO | fairseq.trainer | begin training epoch 72
2022-03-14 07:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:14:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:18:08 | INFO | train_inner | epoch 072:     87 / 407 loss=5.419, nll_loss=4.993, ppl=31.85, wps=23764.2, ups=0.36, wpb=65361.9, bsz=127.7, num_updates=28800, lr=0.000186339, gnorm=0.525, loss_scale=16, train_wall=221, gb_free=9.7, wall=69373
2022-03-14 07:22:08 | INFO | train_inner | epoch 072:    187 / 407 loss=5.421, nll_loss=4.995, ppl=31.89, wps=27290.9, ups=0.42, wpb=65534.2, bsz=128, num_updates=28900, lr=0.000186016, gnorm=0.521, loss_scale=32, train_wall=216, gb_free=9.7, wall=69613
2022-03-14 07:24:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 07:26:10 | INFO | train_inner | epoch 072:    288 / 407 loss=5.443, nll_loss=5.019, ppl=32.42, wps=27116, ups=0.41, wpb=65536, bsz=128, num_updates=29000, lr=0.000185695, gnorm=0.519, loss_scale=32, train_wall=218, gb_free=9.7, wall=69855
2022-03-14 07:29:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:30:13 | INFO | train_inner | epoch 072:    389 / 407 loss=5.454, nll_loss=5.031, ppl=32.68, wps=26908.2, ups=0.41, wpb=65536, bsz=128, num_updates=29100, lr=0.000185376, gnorm=0.516, loss_scale=16, train_wall=219, gb_free=9.7, wall=70098
2022-03-14 07:30:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:31:22 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 5.721 | nll_loss 5.28 | ppl 38.86 | wps 49990.4 | wpb 511.9 | bsz 1 | num_updates 29118 | best_loss 5.721
2022-03-14 07:31:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 29118 updates
2022-03-14 07:31:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 07:31:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 07:31:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 72 @ 29118 updates, score 5.721) (writing took 2.154595193977002 seconds)
2022-03-14 07:31:24 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-14 07:31:24 | INFO | train | epoch 072 | loss 5.434 | nll_loss 5.009 | ppl 32.21 | wps 26234 | ups 0.4 | wpb 65492.5 | bsz 127.9 | num_updates 29118 | lr 0.000185319 | gnorm 0.521 | loss_scale 16 | train_wall 882 | gb_free 9.7 | wall 70170
2022-03-14 07:31:25 | INFO | fairseq.trainer | begin training epoch 73
2022-03-14 07:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:34:40 | INFO | train_inner | epoch 073:     82 / 407 loss=5.407, nll_loss=4.981, ppl=31.58, wps=24466.4, ups=0.37, wpb=65360.1, bsz=127.7, num_updates=29200, lr=0.000185058, gnorm=0.523, loss_scale=16, train_wall=214, gb_free=9.7, wall=70365
2022-03-14 07:35:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:38:42 | INFO | train_inner | epoch 073:    183 / 407 loss=5.429, nll_loss=5.004, ppl=32.08, wps=27111.8, ups=0.41, wpb=65536, bsz=128, num_updates=29300, lr=0.000184742, gnorm=0.521, loss_scale=16, train_wall=218, gb_free=9.7, wall=70607
2022-03-14 07:40:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:42:42 | INFO | train_inner | epoch 073:    284 / 407 loss=5.434, nll_loss=5.009, ppl=32.2, wps=27317.7, ups=0.42, wpb=65536, bsz=128, num_updates=29400, lr=0.000184428, gnorm=0.523, loss_scale=16, train_wall=216, gb_free=9.7, wall=70847
2022-03-14 07:46:44 | INFO | train_inner | epoch 073:    384 / 407 loss=5.446, nll_loss=5.021, ppl=32.48, wps=27137.1, ups=0.41, wpb=65536, bsz=128, num_updates=29500, lr=0.000184115, gnorm=0.523, loss_scale=32, train_wall=218, gb_free=9.7, wall=71089
2022-03-14 07:47:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:48:05 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 5.724 | nll_loss 5.282 | ppl 38.92 | wps 49718.9 | wpb 511.9 | bsz 1 | num_updates 29523 | best_loss 5.721
2022-03-14 07:48:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 29523 updates
2022-03-14 07:48:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 07:48:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 07:48:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 73 @ 29523 updates, score 5.724) (writing took 1.270954822015483 seconds)
2022-03-14 07:48:06 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-14 07:48:06 | INFO | train | epoch 073 | loss 5.43 | nll_loss 5.005 | ppl 32.11 | wps 26479.9 | ups 0.4 | wpb 65492.6 | bsz 127.9 | num_updates 29523 | lr 0.000184043 | gnorm 0.522 | loss_scale 32 | train_wall 876 | gb_free 9.7 | wall 71171
2022-03-14 07:48:06 | INFO | fairseq.trainer | begin training epoch 74
2022-03-14 07:48:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:51:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 07:51:13 | INFO | train_inner | epoch 074:     78 / 407 loss=5.417, nll_loss=4.991, ppl=31.81, wps=24278.9, ups=0.37, wpb=65361.9, bsz=127.7, num_updates=29600, lr=0.000183804, gnorm=0.523, loss_scale=32, train_wall=217, gb_free=9.7, wall=71358
2022-03-14 07:51:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:55:14 | INFO | train_inner | epoch 074:    179 / 407 loss=5.411, nll_loss=4.985, ppl=31.67, wps=27199.4, ups=0.42, wpb=65536, bsz=128, num_updates=29700, lr=0.000183494, gnorm=0.523, loss_scale=16, train_wall=217, gb_free=9.7, wall=71599
2022-03-14 07:59:13 | INFO | train_inner | epoch 074:    279 / 407 loss=5.446, nll_loss=5.021, ppl=32.47, wps=27432.8, ups=0.42, wpb=65534.2, bsz=128, num_updates=29800, lr=0.000183186, gnorm=0.523, loss_scale=32, train_wall=215, gb_free=9.7, wall=71838
2022-03-14 08:02:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 08:02:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 08:03:16 | INFO | train_inner | epoch 074:    381 / 407 loss=5.439, nll_loss=5.015, ppl=32.33, wps=26878, ups=0.41, wpb=65536, bsz=128, num_updates=29900, lr=0.000182879, gnorm=0.522, loss_scale=16, train_wall=219, gb_free=9.7, wall=72081
2022-03-14 08:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:04:45 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 5.73 | nll_loss 5.288 | ppl 39.08 | wps 50027.3 | wpb 511.9 | bsz 1 | num_updates 29926 | best_loss 5.721
2022-03-14 08:04:45 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-14 08:04:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 29926 updates
2022-03-14 08:04:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 08:04:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 08:04:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 74 @ 29926 updates, score 5.73) (writing took 1.3032065280131064 seconds)
2022-03-14 08:04:46 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-14 08:04:46 | INFO | train | epoch 074 | loss 5.426 | nll_loss 5.001 | ppl 32.02 | wps 26398.7 | ups 0.4 | wpb 65492.3 | bsz 127.9 | num_updates 29926 | lr 0.0001828 | gnorm 0.522 | loss_scale 16 | train_wall 875 | gb_free 9.7 | wall 72171
2022-03-14 08:04:46 | INFO | fairseq_cli.train | done training in 72170.5 seconds
