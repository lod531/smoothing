Sender: LSF System <lsfadmin@eu-g3-053>
Subject: Job 210004851: <iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1> was submitted from host <eu-login-04> by user <andriusb> in cluster <euler> at Sun Mar 20 11:38:48 2022
Job was executed on host(s) <eu-g3-053>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Sun Mar 20 11:39:10 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar 20 11:39:10 2022
Terminated at Sun Mar 20 13:14:17 2022
Results reported at Sun Mar 20 13:14:17 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.4 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.14,0.06,0.80\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5700.93 sec.
    Max Memory :                                 5142 MB
    Average Memory :                             3255.52 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14858.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   5706 sec.
    Turnaround time :                            5729 sec.

The output (if any) follows:

2022-03-20 11:39:15 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.14,0.06,0.80)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.4, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.14,0.06,0.80)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-20 11:39:15 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-20 11:39:15 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-20 11:39:16 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-20 11:39:16 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-20 11:39:16 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1180/160239 [00:00<00:13, 11795.12it/s]  2%|▏         | 2548/160239 [00:00<00:12, 12901.16it/s]  2%|▏         | 3953/160239 [00:00<00:11, 13421.86it/s]  3%|▎         | 5296/160239 [00:00<00:11, 13202.34it/s]  4%|▍         | 6634/160239 [00:00<00:11, 13262.93it/s]  5%|▍         | 7961/160239 [00:00<00:11, 12963.07it/s]  6%|▌         | 9259/160239 [00:00<00:11, 12867.91it/s]  7%|▋         | 10619/160239 [00:00<00:11, 13094.98it/s]  7%|▋         | 11930/160239 [00:00<00:11, 13031.70it/s]  8%|▊         | 13258/160239 [00:01<00:11, 13105.14it/s]  9%|▉         | 14570/160239 [00:01<00:11, 13029.64it/s] 10%|▉         | 15874/160239 [00:01<00:11, 12855.29it/s] 11%|█         | 17161/160239 [00:01<00:11, 12623.30it/s] 12%|█▏        | 18458/160239 [00:01<00:11, 12724.26it/s] 12%|█▏        | 19843/160239 [00:01<00:10, 13055.57it/s] 13%|█▎        | 21150/160239 [00:01<00:10, 12981.72it/s] 14%|█▍        | 22450/160239 [00:01<00:10, 12840.90it/s] 15%|█▍        | 23735/160239 [00:01<00:10, 12834.48it/s] 16%|█▌        | 25020/160239 [00:01<00:10, 12758.83it/s] 16%|█▋        | 26297/160239 [00:02<00:10, 12659.68it/s] 17%|█▋        | 27569/160239 [00:02<00:10, 12677.36it/s] 18%|█▊        | 28895/160239 [00:02<00:10, 12849.30it/s] 19%|█▉        | 30181/160239 [00:02<00:10, 12639.21it/s] 20%|█▉        | 31557/160239 [00:02<00:09, 12969.72it/s] 21%|██        | 32856/160239 [00:02<00:09, 12899.54it/s] 21%|██▏       | 34147/160239 [00:02<00:10, 12532.02it/s] 22%|██▏       | 35403/160239 [00:02<00:10, 12400.30it/s] 23%|██▎       | 36766/160239 [00:02<00:09, 12756.03it/s] 24%|██▎       | 38044/160239 [00:02<00:09, 12753.07it/s] 25%|██▍       | 39347/160239 [00:03<00:09, 12832.44it/s] 25%|██▌       | 40682/160239 [00:03<00:09, 12982.66it/s] 26%|██▌       | 41982/160239 [00:03<00:09, 12769.73it/s] 27%|██▋       | 43261/160239 [00:03<00:09, 12461.33it/s] 28%|██▊       | 44510/160239 [00:03<00:09, 12217.96it/s] 29%|██▊       | 45925/160239 [00:03<00:08, 12772.10it/s] 29%|██▉       | 47210/160239 [00:03<00:08, 12794.46it/s] 30%|███       | 48492/160239 [00:03<00:08, 12789.95it/s] 31%|███       | 49789/160239 [00:03<00:08, 12843.07it/s] 32%|███▏      | 51111/160239 [00:03<00:08, 12953.38it/s] 33%|███▎      | 52435/160239 [00:04<00:08, 13033.22it/s] 34%|███▎      | 53740/160239 [00:04<00:08, 12877.23it/s] 34%|███▍      | 55061/160239 [00:04<00:08, 12973.98it/s] 35%|███▌      | 56377/160239 [00:04<00:07, 13027.88it/s] 36%|███▌      | 57701/160239 [00:04<00:07, 13089.11it/s] 37%|███▋      | 59067/160239 [00:04<00:07, 13258.62it/s] 38%|███▊      | 60409/160239 [00:04<00:07, 13303.23it/s] 39%|███▊      | 61740/160239 [00:04<00:07, 12760.76it/s] 39%|███▉      | 63137/160239 [00:04<00:07, 13111.86it/s] 40%|████      | 64512/160239 [00:05<00:07, 13298.64it/s] 41%|████      | 65934/160239 [00:05<00:06, 13567.84it/s] 42%|████▏     | 67294/160239 [00:05<00:07, 13243.08it/s] 43%|████▎     | 68622/160239 [00:05<00:07, 12994.04it/s] 44%|████▎     | 69925/160239 [00:05<00:06, 12960.13it/s] 44%|████▍     | 71271/160239 [00:05<00:06, 13104.04it/s] 45%|████▌     | 72584/160239 [00:05<00:06, 12893.69it/s] 46%|████▌     | 73876/160239 [00:05<00:06, 12804.80it/s] 47%|████▋     | 75158/160239 [00:05<00:06, 12690.80it/s] 48%|████▊     | 76428/160239 [00:05<00:06, 12659.39it/s] 49%|████▊     | 77842/160239 [00:06<00:06, 13095.17it/s] 49%|████▉     | 79167/160239 [00:06<00:06, 13140.22it/s] 50%|█████     | 80554/160239 [00:06<00:05, 13355.88it/s] 51%|█████     | 81911/160239 [00:06<00:05, 13418.85it/s] 52%|█████▏    | 83254/160239 [00:06<00:05, 13389.40it/s] 53%|█████▎    | 84594/160239 [00:06<00:05, 13351.23it/s] 54%|█████▎    | 85971/160239 [00:06<00:05, 13474.02it/s] 55%|█████▍    | 87372/160239 [00:06<00:05, 13633.95it/s] 55%|█████▌    | 88736/160239 [00:06<00:05, 13469.20it/s] 56%|█████▌    | 90096/160239 [00:06<00:05, 13505.51it/s] 57%|█████▋    | 91448/160239 [00:07<00:05, 13346.85it/s] 58%|█████▊    | 92784/160239 [00:07<00:05, 13278.26it/s] 59%|█████▊    | 94113/160239 [00:07<00:05, 12872.37it/s] 60%|█████▉    | 95452/160239 [00:07<00:04, 13021.99it/s] 60%|██████    | 96777/160239 [00:07<00:04, 13086.79it/s] 61%|██████    | 98101/160239 [00:07<00:04, 13131.13it/s] 62%|██████▏   | 99442/160239 [00:07<00:04, 13211.86it/s] 63%|██████▎   | 100815/160239 [00:07<00:04, 13365.23it/s] 64%|██████▍   | 102154/160239 [00:07<00:04, 13371.74it/s] 65%|██████▍   | 103492/160239 [00:07<00:04, 12901.00it/s] 65%|██████▌   | 104908/160239 [00:08<00:04, 13266.12it/s] 66%|██████▋   | 106239/160239 [00:08<00:04, 13149.45it/s] 67%|██████▋   | 107557/160239 [00:08<00:04, 12862.99it/s] 68%|██████▊   | 108847/160239 [00:08<00:04, 12693.51it/s] 69%|██████▊   | 110119/160239 [00:08<00:03, 12641.46it/s] 70%|██████▉   | 111474/160239 [00:08<00:03, 12904.80it/s] 70%|███████   | 112783/160239 [00:08<00:03, 12956.34it/s] 71%|███████   | 114113/160239 [00:08<00:03, 13057.17it/s] 72%|███████▏  | 115420/160239 [00:08<00:03, 12996.43it/s] 73%|███████▎  | 116721/160239 [00:08<00:03, 12933.71it/s] 74%|███████▎  | 118024/160239 [00:09<00:03, 12960.41it/s] 75%|███████▍  | 119393/160239 [00:09<00:03, 13175.99it/s] 75%|███████▌  | 120712/160239 [00:09<00:03, 12939.75it/s] 76%|███████▌  | 122169/160239 [00:09<00:02, 13419.43it/s] 77%|███████▋  | 123513/160239 [00:09<00:02, 13291.16it/s] 78%|███████▊  | 124844/160239 [00:09<00:02, 12980.62it/s] 79%|███████▊  | 126145/160239 [00:09<00:02, 12959.62it/s] 80%|███████▉  | 127465/160239 [00:09<00:02, 13027.09it/s] 80%|████████  | 128811/160239 [00:09<00:02, 13153.78it/s] 81%|████████  | 130128/160239 [00:10<00:02, 12712.09it/s] 82%|████████▏ | 131441/160239 [00:10<00:02, 12832.57it/s] 83%|████████▎ | 132732/160239 [00:10<00:02, 12852.72it/s] 84%|████████▎ | 134020/160239 [00:10<00:02, 12500.38it/s] 84%|████████▍ | 135310/160239 [00:10<00:01, 12615.80it/s] 85%|████████▌ | 136658/160239 [00:10<00:01, 12868.42it/s] 86%|████████▌ | 138003/160239 [00:10<00:01, 13039.78it/s] 87%|████████▋ | 139363/160239 [00:10<00:01, 13204.78it/s] 88%|████████▊ | 140751/160239 [00:10<00:01, 13404.39it/s] 89%|████████▊ | 142093/160239 [00:10<00:01, 13161.63it/s] 89%|████████▉ | 143411/160239 [00:11<00:01, 13077.14it/s] 90%|█████████ | 144720/160239 [00:11<00:01, 13032.37it/s] 91%|█████████ | 146025/160239 [00:11<00:01, 12809.97it/s] 92%|█████████▏| 147308/160239 [00:11<00:01, 12798.57it/s] 93%|█████████▎| 148589/160239 [00:11<00:00, 12524.90it/s] 94%|█████████▎| 149858/160239 [00:11<00:00, 12569.78it/s] 94%|█████████▍| 151165/160239 [00:11<00:00, 12713.82it/s] 95%|█████████▌| 152475/160239 [00:11<00:00, 12827.89it/s] 96%|█████████▌| 153759/160239 [00:11<00:00, 12714.14it/s] 97%|█████████▋| 155165/160239 [00:11<00:00, 13111.45it/s] 98%|█████████▊| 156493/160239 [00:12<00:00, 13160.71it/s] 98%|█████████▊| 157816/160239 [00:12<00:00, 13180.75it/s] 99%|█████████▉| 159135/160239 [00:12<00:00, 13112.44it/s]100%|██████████| 160239/160239 [00:12<00:00, 12986.14it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3882/160239 [00:00<00:04, 38812.17it/s]  5%|▍         | 7764/160239 [00:00<00:03, 38756.58it/s]  7%|▋         | 11695/160239 [00:00<00:03, 39005.85it/s] 10%|▉         | 15596/160239 [00:00<00:03, 38962.64it/s] 12%|█▏        | 19493/160239 [00:00<00:03, 38824.73it/s] 15%|█▍        | 23384/160239 [00:00<00:03, 38852.08it/s] 17%|█▋        | 27270/160239 [00:00<00:03, 38789.32it/s] 19%|█▉        | 31149/160239 [00:00<00:03, 38621.81it/s] 22%|██▏       | 35012/160239 [00:00<00:03, 38513.75it/s] 24%|██▍       | 38921/160239 [00:01<00:03, 38682.40it/s] 27%|██▋       | 42790/160239 [00:01<00:03, 38602.96it/s] 29%|██▉       | 46668/160239 [00:01<00:02, 38655.99it/s] 32%|███▏      | 50537/160239 [00:01<00:02, 38665.05it/s] 34%|███▍      | 54482/160239 [00:01<00:02, 38899.63it/s] 37%|███▋      | 58520/160239 [00:01<00:02, 39344.74it/s] 39%|███▉      | 62456/160239 [00:01<00:02, 39346.86it/s] 42%|████▏     | 66605/160239 [00:01<00:02, 39989.41it/s] 44%|████▍     | 70605/160239 [00:01<00:02, 39407.70it/s] 47%|████▋     | 74548/160239 [00:01<00:02, 39225.93it/s] 49%|████▉     | 78596/160239 [00:02<00:02, 39598.10it/s] 52%|█████▏    | 82653/160239 [00:02<00:01, 39886.64it/s] 54%|█████▍    | 86748/160239 [00:02<00:01, 40202.82it/s] 57%|█████▋    | 90770/160239 [00:02<00:01, 40117.49it/s] 59%|█████▉    | 94783/160239 [00:02<00:01, 39637.01it/s] 62%|██████▏   | 98775/160239 [00:02<00:01, 39720.21it/s] 64%|██████▍   | 102789/160239 [00:02<00:01, 39844.02it/s] 67%|██████▋   | 106795/160239 [00:02<00:01, 39902.82it/s] 69%|██████▉   | 110786/160239 [00:02<00:01, 39385.96it/s] 72%|███████▏  | 114807/160239 [00:02<00:01, 39627.29it/s] 74%|███████▍  | 118772/160239 [00:03<00:01, 39622.40it/s] 77%|███████▋  | 122901/160239 [00:03<00:00, 40114.55it/s] 79%|███████▉  | 126914/160239 [00:03<00:00, 39726.79it/s] 82%|████████▏ | 130889/160239 [00:03<00:00, 39374.81it/s] 84%|████████▍ | 134828/160239 [00:03<00:00, 39140.10it/s] 87%|████████▋ | 138843/160239 [00:03<00:00, 39437.52it/s] 89%|████████▉ | 142788/160239 [00:03<00:00, 39246.23it/s] 92%|█████████▏| 146714/160239 [00:03<00:00, 39033.37it/s] 94%|█████████▍| 150618/160239 [00:03<00:00, 38915.68it/s] 96%|█████████▋| 154590/160239 [00:03<00:00, 39150.34it/s] 99%|█████████▉| 158555/160239 [00:04<00:00, 39296.38it/s]100%|██████████| 160239/160239 [00:04<00:00, 39318.63it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2347.12it/s]2022-03-20 11:39:35 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-20 11:39:35 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-20 11:39:35 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-20 11:39:35 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-20 11:39:35 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-20 11:39:35 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-20 11:39:35 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-20 11:39:35 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-20 11:39:35 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-20 11:39:35 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-20 11:39:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-20 11:39:35 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-20 11:39:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-20 11:39:35 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-20 11:39:35 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-20 11:39:35 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 11:39:35 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 11:39:35 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-20 11:39:35 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-20 11:39:35 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-20 11:39:35 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-20 11:39:35 | INFO | fairseq.trainer | begin training epoch 1
2022-03-20 11:39:35 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-20 11:39:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-20 11:39:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-20 11:39:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-20 11:39:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-20 11:40:16 | INFO | train_inner | epoch 001:    104 / 157 loss=12.864, ppl=7455.74, wps=66804.5, ups=2.66, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.929, loss_scale=8, train_wall=40, gb_free=12.1, wall=41
2022-03-20 11:40:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:40:39 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-20 11:40:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:40:42 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-20 11:40:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:40:45 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-20 11:40:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:40:48 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-20 11:40:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:40:51 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:40:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:40:55 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,
2022-03-20 11:40:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:41:00 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:41:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:41:05 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:41:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:41:12 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:41:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:41:15 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:41:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:41:15 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.022 | ppl 4158.12 | bleu 0.02 | wps 4596.7 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-20 11:41:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-20 11:41:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:41:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.02) (writing took 1.5942324637435377 seconds)
2022-03-20 11:41:16 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-20 11:41:16 | INFO | train | epoch 001 | loss 12.439 | ppl 5554.59 | wps 39194.6 | ups 1.56 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.346 | loss_scale 8 | train_wall 60 | gb_free 22.3 | wall 101
KL Stats: Epoch 1 Divergences: Uniform: 0.5553232215528806 Unigram: 1.4975518104283185
2022-03-20 11:41:16 | INFO | fairseq.trainer | begin training epoch 2
2022-03-20 11:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 11:41:34 | INFO | train_inner | epoch 002:     47 / 157 loss=11.352, ppl=2613.9, wps=32402.1, ups=1.28, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.119, loss_scale=8, train_wall=37, gb_free=12.9, wall=119
2022-03-20 11:42:12 | INFO | train_inner | epoch 002:    147 / 157 loss=10.829, ppl=1819.5, wps=66735.4, ups=2.65, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=1.154, loss_scale=8, train_wall=37, gb_free=12.2, wall=157
2022-03-20 11:42:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:42:19 | INFO | fairseq.tasks.translation | example hypothesis: we we we we.
2022-03-20 11:42:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:42:22 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the.
2022-03-20 11:42:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:42:26 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the.
2022-03-20 11:42:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:42:30 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:42:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:42:36 | INFO | fairseq.tasks.translation | example hypothesis: and and we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:42:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:42:41 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-20 11:42:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:42:47 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:42:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:42:53 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:42:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:43:00 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:43:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:43:02 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 11:43:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:43:02 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.277 | ppl 2481.7 | bleu 0.01 | wps 3761.2 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-20 11:43:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-20 11:43:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 11:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 11:43:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 2 @ 310 updates, score 0.01) (writing took 0.7370683862827718 seconds)
2022-03-20 11:43:03 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-20 11:43:03 | INFO | train | epoch 002 | loss 10.894 | ppl 1903.16 | wps 36982.2 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.083 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 208
KL Stats: Epoch 2 Divergences: Uniform: 0.7147863151250963 Unigram: 0.40313299254395946
2022-03-20 11:43:03 | INFO | fairseq.trainer | begin training epoch 3
2022-03-20 11:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 11:43:37 | INFO | train_inner | epoch 003:     90 / 157 loss=10.542, ppl=1491.34, wps=28979.4, ups=1.18, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=1.023, loss_scale=8, train_wall=36, gb_free=11.8, wall=242
2022-03-20 11:44:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:44:06 | INFO | fairseq.tasks.translation | example hypothesis: we we.
2022-03-20 11:44:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:44:10 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the.
2022-03-20 11:44:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:44:14 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the.
2022-03-20 11:44:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:44:19 | INFO | fairseq.tasks.translation | example hypothesis: and and it's, and it's, it's, and it's's, and it's's's's, and it's, and and it's's's's, and it's's's's
2022-03-20 11:44:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:44:25 | INFO | fairseq.tasks.translation | example hypothesis: and and it it's's's, it it it it's's's's's, it's's's, it's's's, and it it it's's's's's's's, and it it's's's's's's
2022-03-20 11:44:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:44:30 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and and and and and and and and and and and and and and and the the the the the the the the the the the the the the the, and and and the the the the the the the the the the the the the the the
2022-03-20 11:44:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:44:36 | INFO | fairseq.tasks.translation | example hypothesis: and and it, and it's, and it's, and it it's, and it's, and it's, and it's, and it's, and it's, and it's's, and it's, and it's, and it's, and it's's's, and it's's's, and it's's, and
2022-03-20 11:44:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:44:43 | INFO | fairseq.tasks.translation | example hypothesis: and and and and we we, and we we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we we we we we the the the the the the the the the the the the, and we, and we, and we, and
2022-03-20 11:44:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:44:50 | INFO | fairseq.tasks.translation | example hypothesis: and i, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-20 11:44:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:44:53 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we, we, we, we, we, and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, and we, we, we, and we, and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, and we, we, we, we, we, we, we, we, we, we, we, we, we, and we, we, we,
2022-03-20 11:44:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:44:53 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.133 | ppl 2245.66 | bleu 0.1 | wps 3482.2 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.1
2022-03-20 11:44:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-20 11:44:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:44:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:44:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.1) (writing took 1.633679535239935 seconds)
2022-03-20 11:44:54 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-20 11:44:54 | INFO | train | epoch 003 | loss 10.454 | ppl 1402.38 | wps 35496.2 | ups 1.41 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.152 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 319
KL Stats: Epoch 3 Divergences: Uniform: 0.930019566437542 Unigram: 0.34668169542524646
2022-03-20 11:44:54 | INFO | fairseq.trainer | begin training epoch 4
2022-03-20 11:44:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 11:45:07 | INFO | train_inner | epoch 004:     33 / 157 loss=10.346, ppl=1301.64, wps=28135.8, ups=1.11, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.186, loss_scale=8, train_wall=37, gb_free=12, wall=333
2022-03-20 11:45:45 | INFO | train_inner | epoch 004:    133 / 157 loss=10.228, ppl=1199.4, wps=67115.4, ups=2.66, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.196, loss_scale=8, train_wall=37, gb_free=10.8, wall=370
2022-03-20 11:45:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:45:58 | INFO | fairseq.tasks.translation | example hypothesis: we're're the in the in the.
2022-03-20 11:45:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:46:02 | INFO | fairseq.tasks.translation | example hypothesis: this is is the of the of the of the of the of the of the.
2022-03-20 11:46:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:46:07 | INFO | fairseq.tasks.translation | example hypothesis: and the of the of the of the.
2022-03-20 11:46:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:46:12 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, and it's a, and it's a and it's a.
2022-03-20 11:46:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:46:17 | INFO | fairseq.tasks.translation | example hypothesis: and it's a that's a that's a that's a that's a that's a that's not not not not not not not not not not not not not not not not not not not not not not not not.
2022-03-20 11:46:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:46:23 | INFO | fairseq.tasks.translation | example hypothesis: and this is a of the of the of the of the of the of the of the of the of the of the of the and the of the of the of the and the of the of the and the of the of the of the of the of the of the of the of the and
2022-03-20 11:46:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:46:29 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, but it's a, but you can can can can can can can can can't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't
2022-03-20 11:46:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:46:35 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-20 11:46:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:46:43 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-20 11:46:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:46:46 | INFO | fairseq.tasks.translation | example hypothesis: and so, the of the of the of the of the of the of the of the of the of the of the of the, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-20 11:46:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:46:46 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.77 | ppl 1745.83 | bleu 0.49 | wps 3411 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.49
2022-03-20 11:46:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-20 11:46:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:46:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:46:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.49) (writing took 1.7053426010534167 seconds)
2022-03-20 11:46:47 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-20 11:46:47 | INFO | train | epoch 004 | loss 10.224 | ppl 1196.19 | wps 34903.9 | ups 1.39 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.129 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 432
KL Stats: Epoch 4 Divergences: Uniform: 0.9471409272011628 Unigram: 0.5145779223533401
2022-03-20 11:46:48 | INFO | fairseq.trainer | begin training epoch 5
2022-03-20 11:46:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 11:47:16 | INFO | train_inner | epoch 005:     76 / 157 loss=10.089, ppl=1089.34, wps=26888.9, ups=1.09, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.316, loss_scale=8, train_wall=36, gb_free=11.5, wall=461
2022-03-20 11:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:47:51 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world in the world.
2022-03-20 11:47:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:47:55 | INFO | fairseq.tasks.translation | example hypothesis: this is that's the world of the world of the world.
2022-03-20 11:47:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:48:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world of the world of the world.
2022-03-20 11:48:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:48:04 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of it's a lot of it's a lot, and it's a lot of it's a lot.
2022-03-20 11:48:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:48:09 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not not not not that we're not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not
2022-03-20 11:48:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:48:15 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world of the world in the world in the world in the world in the world in the world in the world in the world in the world in the world in the world in the world in the world in the world in the world in the world
2022-03-20 11:48:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:48:21 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not in the world, but they're the world, but they're not not not not not not not not not not not not not not not not not not not not not not not not not not
2022-03-20 11:48:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:48:27 | INFO | fairseq.tasks.translation | example hypothesis: and we're to see the world of the world, and we're the world of the world, and we have to be the world of the world, and we're the world of the world, and we have to have to be the world of the world, and we're the world of the world, and we have to be the world to have to be to be the world to be the world to be the world to be the world of the world to be
2022-03-20 11:48:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:48:35 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "" "" it's, "" "" "" it's, "" "" "it's," "" "" it's, "" "" "" "" "" "" it's, "it's," it's, "" "" "" "" "" "" it's, "" "" "" "" "it's," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" it's, "" "" "" "" "" "" "" "" "" "it's," it's, "it's," "" "" it's, "" "" "" "" "" "" "" "" "" ""
2022-03-20 11:48:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:48:37 | INFO | fairseq.tasks.translation | example hypothesis: so, we're that we have to be a lot of the world, and we have to be a lot, and we have to be a lot, and we have to be to be to be a lot of the world, and we have to be to be that we have to be a lot, and we have to be to be to be to be to be to be that we have to be a lot to be a lot of the world, and we have to be to be to be that we have to be a lot, and we have to be a lot to be to be to be a lot to be a lot, and we have to be a lot to be to be to be a lot to be to be to be to be to be a lot to be to be that we have to be to be to be that we have to be that we have to be to be to be to be to be that we have to be in the world, in the world, and we have to be to be to be to be to be to be
2022-03-20 11:48:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:48:37 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.422 | ppl 1372.07 | bleu 1.02 | wps 3514.5 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.02
2022-03-20 11:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-20 11:48:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:48:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.02) (writing took 1.6882440699264407 seconds)
2022-03-20 11:48:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-20 11:48:39 | INFO | train | epoch 005 | loss 9.897 | ppl 953.73 | wps 35316.4 | ups 1.4 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.292 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 544
KL Stats: Epoch 5 Divergences: Uniform: 0.9889733088155631 Unigram: 0.7561531098864266
2022-03-20 11:48:39 | INFO | fairseq.trainer | begin training epoch 6
2022-03-20 11:48:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 11:48:46 | INFO | train_inner | epoch 006:     19 / 157 loss=9.751, ppl=861.58, wps=28138.9, ups=1.11, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.274, loss_scale=8, train_wall=37, gb_free=12.7, wall=552
2022-03-20 11:49:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-20 11:49:25 | INFO | train_inner | epoch 006:    120 / 157 loss=9.645, ppl=800.56, wps=66268.4, ups=2.63, wpb=25234.2, bsz=1007, num_updates=900, lr=0.0001125, gnorm=1.235, loss_scale=4, train_wall=38, gb_free=12.2, wall=590
2022-03-20 11:49:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:49:42 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world.
2022-03-20 11:49:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:49:47 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world.
2022-03-20 11:49:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:49:51 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a lot of the world.
2022-03-20 11:49:51 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:49:55 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of there's a lot.
2022-03-20 11:49:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:50:00 | INFO | fairseq.tasks.translation | example hypothesis: and it's not what we're going to do that we're going to do it's going to do it.
2022-03-20 11:50:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:50:05 | INFO | fairseq.tasks.translation | example hypothesis: and this is in the world, in the world, and in the world, in the world, and in the world.
2022-03-20 11:50:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:50:10 | INFO | fairseq.tasks.translation | example hypothesis: but they're not going to see the world.
2022-03-20 11:50:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:50:15 | INFO | fairseq.tasks.translation | example hypothesis: so, we can see the world, and we can see the world, and we can see the world.
2022-03-20 11:50:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:50:21 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "you know," you know, "" it's going to say, "you know," you know, "" you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's going to say, "it's going to say," it's going to say, "you know," you know, "you know," you know, "it's going to say," you know, "you know," it's going to say, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," "
2022-03-20 11:50:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:50:23 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of fact, and we're going to be a lot of the world, and we're going to be a lot of the world.
2022-03-20 11:50:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:50:23 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.194 | ppl 1171.28 | bleu 1.75 | wps 4026.2 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.75
2022-03-20 11:50:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-20 11:50:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:50:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.75) (writing took 1.7145548360422254 seconds)
2022-03-20 11:50:25 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-20 11:50:25 | INFO | train | epoch 006 | loss 9.648 | ppl 802.52 | wps 37071 | ups 1.48 | wpb 25122.4 | bsz 1014.9 | num_updates 937 | lr 0.000117125 | gnorm 1.291 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 650
KL Stats: Epoch 6 Divergences: Uniform: 1.0511607848641025 Unigram: 0.9161375519752867
2022-03-20 11:50:25 | INFO | fairseq.trainer | begin training epoch 7
2022-03-20 11:50:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 11:50:49 | INFO | train_inner | epoch 007:     63 / 157 loss=9.508, ppl=728.31, wps=29845, ups=1.19, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.137, loss_scale=4, train_wall=37, gb_free=13, wall=674
2022-03-20 11:51:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:51:28 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world.
2022-03-20 11:51:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:51:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the world that is the first first idea of the world.
2022-03-20 11:51:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:51:38 | INFO | fairseq.tasks.translation | example hypothesis: you're going to be going to be able to be able to be able to be able to be able to be two.
2022-03-20 11:51:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:51:43 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot, there's a lot of there are there are going to be a lot, and there's going to be a lot of there.
2022-03-20 11:51:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:51:49 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're going to do that we're going to do it, and we're going to do it's going to do it, and we're going to do it's going to do it's going to do it's
2022-03-20 11:51:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:51:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the world, in the world, and the world, and the world, and the world is the world, and the world, and the world in the world, and the world, and in the world, and the world, and the world, and the world, and the world
2022-03-20 11:51:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:52:00 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to see, but there are a lot of these are, but they're going to be, but they're going to be, but they're going to be a lot of these things, but they're going to be a lot of these things, but they're going to be, but they're going to be a lot of the
2022-03-20 11:52:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:52:06 | INFO | fairseq.tasks.translation | example hypothesis: and if we can see, if we can see a lot of the world, and we can see that we can see that we can see that we can see that we can see that we can see a lot of the world, and we can see that we can see it, we can see a lot of the world, and we can see a lot of the world, and we can see that we can see that we can see that we can see a lot of
2022-03-20 11:52:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:52:14 | INFO | fairseq.tasks.translation | example hypothesis: and if you said, "we said," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say, and then it's going to say, and then then then then then then then then then then then then
2022-03-20 11:52:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:52:17 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to be a lot of a lot of the world, if we're going to be going to be a lot of the world, and then we're going to be going to be a lot of the world, and then we're going to be going to be going to be a lot of the world, and then we're going to be going to be going to be a lot of the world, and then it's going to be going to be going to be a lot of the world, and then we're going to be going to be a lot of the world, and then it's going to be going to be going to be going to be going to be a lot of the world, and then we're going to be going to be a lot of the world, and then we're going to be going to be a lot of the world, and then we're going to be going to be a lot of the world, and then we're going to be going to be a lot of the world, and then it's a
2022-03-20 11:52:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:52:17 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.016 | ppl 1035.21 | bleu 1.5 | wps 3363.1 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 1.75
2022-03-20 11:52:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-20 11:52:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 11:52:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 11:52:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 7 @ 1094 updates, score 1.5) (writing took 0.7832265761680901 seconds)
2022-03-20 11:52:17 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-20 11:52:17 | INFO | train | epoch 007 | loss 9.395 | ppl 673.44 | wps 35073.1 | ups 1.39 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.067 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 763
KL Stats: Epoch 7 Divergences: Uniform: 1.0905734472939015 Unigram: 1.0286718513606974
2022-03-20 11:52:18 | INFO | fairseq.trainer | begin training epoch 8
2022-03-20 11:52:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 11:52:20 | INFO | train_inner | epoch 008:      6 / 157 loss=9.367, ppl=660.33, wps=27409, ups=1.1, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.078, loss_scale=4, train_wall=37, gb_free=12.5, wall=765
2022-03-20 11:52:58 | INFO | train_inner | epoch 008:    106 / 157 loss=9.177, ppl=578.85, wps=67399.3, ups=2.67, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.088, loss_scale=4, train_wall=37, gb_free=12.9, wall=803
2022-03-20 11:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:53:20 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in this.
2022-03-20 11:53:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:53:25 | INFO | fairseq.tasks.translation | example hypothesis: here's the first thing that's the first thing.
2022-03-20 11:53:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:53:29 | INFO | fairseq.tasks.translation | example hypothesis: now, you can be able to make a new new new new new new new new new new new new new new new new.
2022-03-20 11:53:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:53:34 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the brain.
2022-03-20 11:53:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:53:38 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we don't know that we don't know, and we're going to do it, and we're going to do it's not not going to do it.
2022-03-20 11:53:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:53:44 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the world, in the people who are in the world, and people who are in the people in the world, and people in the people in the world.
2022-03-20 11:53:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:53:49 | INFO | fairseq.tasks.translation | example hypothesis: but if you're not a lot of these are, but they're going to get a lot of the same, but they're not, but they're going to get a lot of the same.
2022-03-20 11:53:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:53:55 | INFO | fairseq.tasks.translation | example hypothesis: and if we can see that, we can see, we can see a lot of the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, we can
2022-03-20 11:53:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:54:02 | INFO | fairseq.tasks.translation | example hypothesis: and then, "the" "" "" "" "" "" "" "the" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-20 11:54:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:54:04 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world that we're going to be a lot of the world, which is that we're going to be a lot of the world.
2022-03-20 11:54:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:54:04 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.844 | ppl 918.77 | bleu 2.22 | wps 3762.6 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.22
2022-03-20 11:54:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-20 11:54:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:54:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:54:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.22) (writing took 1.6162554491311312 seconds)
2022-03-20 11:54:06 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-20 11:54:06 | INFO | train | epoch 008 | loss 9.243 | ppl 605.82 | wps 36493.2 | ups 1.45 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.048 | loss_scale 4 | train_wall 58 | gb_free 11.7 | wall 871
KL Stats: Epoch 8 Divergences: Uniform: 1.1262164918447544 Unigram: 1.0963241288206491
2022-03-20 11:54:06 | INFO | fairseq.trainer | begin training epoch 9
2022-03-20 11:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 11:54:25 | INFO | train_inner | epoch 009:     49 / 157 loss=9.169, ppl=575.7, wps=29437.8, ups=1.15, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=0.983, loss_scale=4, train_wall=37, gb_free=13.1, wall=890
2022-03-20 11:55:02 | INFO | train_inner | epoch 009:    149 / 157 loss=9.115, ppl=554.39, wps=66738.2, ups=2.69, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=0.949, loss_scale=4, train_wall=37, gb_free=12.5, wall=927
2022-03-20 11:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:55:09 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the middle of the world.
2022-03-20 11:55:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:55:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the most one of the most one of the most most most most of the most of the most most of the most of the most of the
2022-03-20 11:55:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:55:18 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-20 11:55:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:55:24 | INFO | fairseq.tasks.translation | example hypothesis: there's a lot of life, and there's a lot of life, and there's a lot of life.
2022-03-20 11:55:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:55:29 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not just just just just just just just just just just just just just just just just just just just just just just just just just like that we're going to do that we're going to do it's not not going to
2022-03-20 11:55:29 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:55:35 | INFO | fairseq.tasks.translation | example hypothesis: and and in fact, in the most people who have been in the most people who have been in the most people in the people in the people who have been been in the people who have been been in the people who who who have been been in the world, and the people who had a
2022-03-20 11:55:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:55:41 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to have a lot of the same, you're not going to be able to get a lot of the united states, but they're not going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-20 11:55:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:55:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take a lot of the brain, and then we can see it, and then then we can see that if you can see that we can see it, we can see it, and then we can see it, and then then we can see that we can see that if we can see it's going to be a lot of the brain, and then then we can see that if we can see the brain, and then we can see
2022-03-20 11:55:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:55:55 | INFO | fairseq.tasks.translation | example hypothesis: and if i said, "" "" you know, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-20 11:55:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:55:57 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to be a lot of the world, if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be
2022-03-20 11:55:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:55:57 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.695 | ppl 828.59 | bleu 2.07 | wps 3403.7 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 2.22
2022-03-20 11:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-20 11:55:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 11:55:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 11:55:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 9 @ 1408 updates, score 2.07) (writing took 0.7552933902479708 seconds)
2022-03-20 11:55:58 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-20 11:55:58 | INFO | train | epoch 009 | loss 9.09 | ppl 544.89 | wps 35160.4 | ups 1.4 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 0.976 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 983
KL Stats: Epoch 9 Divergences: Uniform: 1.1563045683838638 Unigram: 1.1541871968128687
2022-03-20 11:55:58 | INFO | fairseq.trainer | begin training epoch 10
2022-03-20 11:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 11:56:33 | INFO | train_inner | epoch 010:     92 / 157 loss=9.039, ppl=526.21, wps=27450.4, ups=1.09, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=0.907, loss_scale=4, train_wall=37, gb_free=12.4, wall=1019
2022-03-20 11:56:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:57:01 | INFO | fairseq.tasks.translation | example hypothesis: we've got this.
2022-03-20 11:57:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:57:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most of the most most of the most most most most of the most most of the most of the most most of the most of
2022-03-20 11:57:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:57:09 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new york.
2022-03-20 11:57:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:57:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a lot of where you're going to go and where it's where you're going to go and where it's where you're going to be where you're going to
2022-03-20 11:57:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:57:18 | INFO | fairseq.tasks.translation | example hypothesis: it's not a little bit of what we're going to do, and we're not going to do, and we're not going to do, and we're going to do it's not going to be going to do with all of the
2022-03-20 11:57:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:57:24 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the united states, in the united states, and the most people who had a lot of people in the most people who are in the united states, and people who are in the united states for the people for the people for the people in the people who are in the
2022-03-20 11:57:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:57:30 | INFO | fairseq.tasks.translation | example hypothesis: well, some of course, some of course, but they're not going to go, but if you're going to go, but it's not a lot of course, but it's not a lot of course, but it's not a lot of course, but it's not a lot of course, but it's not the same, but it's
2022-03-20 11:57:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:57:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we can take the brain, and then we can take the brain, we can take the brain, and then we can use the brain, and then we can use the brain, and then we can use the brain, and then we can take the brain, and then we can use the brain, and then we can use the brain, and then we can use the brain, and then we can use the brain, and then take the brain, and the
2022-03-20 11:57:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:57:43 | INFO | fairseq.tasks.translation | example hypothesis: one: one: one: one: one: "well," well, "well," well, "you know," you know, "well," well, "well," you know, "well," well, "well," you know, "well," well, "well," well, "well," well, "well," you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "you know," well, "well," well, "well," well, "well," well, "well," well, "you know," well, "well," well, "well," you know, "well,"
2022-03-20 11:57:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:57:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get a lot of the world, we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get a
2022-03-20 11:57:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:57:46 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.473 | ppl 710.55 | bleu 3.23 | wps 3659.6 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 3.23
2022-03-20 11:57:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-20 11:57:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:57:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:57:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 3.23) (writing took 1.6879568467848003 seconds)
2022-03-20 11:57:47 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-20 11:57:47 | INFO | train | epoch 010 | loss 8.927 | ppl 486.73 | wps 36092.5 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.909 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1093
KL Stats: Epoch 10 Divergences: Uniform: 1.1922674982471408 Unigram: 1.2073088534128031
2022-03-20 11:57:48 | INFO | fairseq.trainer | begin training epoch 11
2022-03-20 11:57:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 11:58:01 | INFO | train_inner | epoch 011:     35 / 157 loss=8.864, ppl=466.08, wps=28362.4, ups=1.14, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=0.969, loss_scale=4, train_wall=36, gb_free=11.5, wall=1106
2022-03-20 11:58:39 | INFO | train_inner | epoch 011:    135 / 157 loss=8.629, ppl=395.99, wps=67954.4, ups=2.66, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.898, loss_scale=4, train_wall=37, gb_free=11.5, wall=1144
2022-03-20 11:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 11:58:52 | INFO | fairseq.tasks.translation | example hypothesis: we found this in this room, in the middle of this room.
2022-03-20 11:58:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 11:58:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most most most of the most most most most most of the most most most most of the most most of the most most most most
2022-03-20 11:58:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 11:59:02 | INFO | fairseq.tasks.translation | example hypothesis: these are a new new new new new new new new new new new new new new new new new new new new new new york.
2022-03-20 11:59:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 11:59:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an example, where it's where you're going to go and where where you're going to go back to where where where it's where you're going to go back and where where
2022-03-20 11:59:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 11:59:12 | INFO | fairseq.tasks.translation | example hypothesis: it's not not just just just just a little bit of what we're going to do, and we're going to do is not just just a little bit of what we're going to do.
2022-03-20 11:59:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 11:59:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the people like the people, and the people who have been used for people for the people for the people for a lot of people, and it's a lot of people.
2022-03-20 11:59:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 11:59:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some of some of you're going to get some of them, but it's not the same time, but it's not the same time, but it's not the same time, but it's the same time, but it's not a lot of the same time.
2022-03-20 11:59:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 11:59:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we can take the brain, we can see it, and we can see it in the ocean, and then we can see it into a little bit of the brain, and we can see it, and we can take it into a little bit of the brain, and we can see it.
2022-03-20 11:59:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 11:59:33 | INFO | fairseq.tasks.translation | example hypothesis: audience: "well," you know, "you know," you know, "well," well, "you know," well, "well," you know, "well," well, "well," you know, "well," well, "well," well, "well," you know, "well," well, "well," you know, "well," well, "well," well, "well," you know, "well," you know, "well," well, "well," well, "well," well, "you know," you know, "you know," well, "well," you know, "well," well, "well," well, "well," you know, "you know," you know, "you know," well, ""
2022-03-20 11:59:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 11:59:35 | INFO | fairseq.tasks.translation | example hypothesis: in fact, there's a lot of time that we're going to go to the world, and then we're going to do it, and we're going to get a lot of the world, and then we're going to do that we're going to get a lot of the world, and we're going to do it in a lot of the world that we're going to have a lot of the world.
2022-03-20 11:59:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 11:59:35 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.33 | ppl 643.66 | bleu 4.03 | wps 3793.1 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 4.03
2022-03-20 11:59:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-20 11:59:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:59:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 11:59:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 4.03) (writing took 1.6419718521647155 seconds)
2022-03-20 11:59:37 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-20 11:59:37 | INFO | train | epoch 011 | loss 8.742 | ppl 428.05 | wps 36023.8 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.924 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1202
KL Stats: Epoch 11 Divergences: Uniform: 1.230172739282811 Unigram: 1.2709320842861456
2022-03-20 11:59:37 | INFO | fairseq.trainer | begin training epoch 12
2022-03-20 11:59:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:00:07 | INFO | train_inner | epoch 012:     78 / 157 loss=8.689, ppl=412.62, wps=28399.3, ups=1.14, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.931, loss_scale=4, train_wall=37, gb_free=12.1, wall=1232
2022-03-20 12:00:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:00:40 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-20 12:00:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:00:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of course of the most most of the most most of the most of the most of the most of the most of the most.
2022-03-20 12:00:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:00:48 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new new new new new two two two two.
2022-03-20 12:00:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:00:52 | INFO | fairseq.tasks.translation | example hypothesis: for example.
2022-03-20 12:00:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:00:57 | INFO | fairseq.tasks.translation | example hypothesis: it's not a few years that we don't have a few years ago, and we're going to look at his eyes, and what's going to do.
2022-03-20 12:00:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:01:02 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, people like the most people like the people who have been working for the people who have been used to be able to build a million people in the united states, and it's a few years.
2022-03-20 12:01:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:01:08 | INFO | fairseq.tasks.translation | example hypothesis: first.
2022-03-20 12:01:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:01:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can use the information that we can create a kind of information, and we can create a kind of information, and we can use the brain, and then we can use the brain, and then we can use the brain, and then we can use it, and then we can create a kind of information, and we can create a kind of information, and then we can use the brain, and we can use that can
2022-03-20 12:01:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:01:21 | INFO | fairseq.tasks.translation | example hypothesis: dh: one of the most interesting thing it's interesting, and it's interesting, and it's interesting for me to say, "and if you're going to say," if you're going to say, "you're going to say," well, "you're going to say," well, "you're going to say," well, "you're going to say," you're going to say, "well," well, "well," you're going to say, "you're going to say," well, "well," well, "well," well, "you're going to say," you're going to do it's going to say, "well," well, "well," well, "well," well, "you know," you know, "you're going to do it's going to say, you can
2022-03-20 12:01:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:01:23 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, the fact, the last year, and the mother has been a few years, and if we're going to be able to create a lot of the world, if we're going to create a system that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-20 12:01:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:01:23 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.077 | ppl 540.17 | bleu 5.51 | wps 3767.5 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 5.51
2022-03-20 12:01:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-20 12:01:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:01:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:01:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 5.51) (writing took 1.6920456187799573 seconds)
2022-03-20 12:01:25 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-20 12:01:25 | INFO | train | epoch 012 | loss 8.567 | ppl 379.25 | wps 36573 | ups 1.45 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.935 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1310
KL Stats: Epoch 12 Divergences: Uniform: 1.2716466499793093 Unigram: 1.3244377504080973
2022-03-20 12:01:25 | INFO | fairseq.trainer | begin training epoch 13
2022-03-20 12:01:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:01:33 | INFO | train_inner | epoch 013:     21 / 157 loss=8.464, ppl=353.05, wps=28962.7, ups=1.15, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=0.992, loss_scale=4, train_wall=37, gb_free=12, wall=1319
2022-03-20 12:02:11 | INFO | train_inner | epoch 013:    121 / 157 loss=8.392, ppl=335.91, wps=67100.4, ups=2.65, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.924, loss_scale=4, train_wall=37, gb_free=11.7, wall=1356
2022-03-20 12:02:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:02:28 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppon the house.
2022-03-20 12:02:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:02:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the mamao, most of the most most most most most of the most.
2022-03-20 12:02:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:02:36 | INFO | fairseq.tasks.translation | example hypothesis: these new new new new new new new new new new technologies are going to be used.
2022-03-20 12:02:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:02:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food where they're going to be going to be working with.
2022-03-20 12:02:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:02:44 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just going to see a couple of eyes, and what's going to do.
2022-03-20 12:02:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:02:48 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, people like the people who were used to be used for the number of people, and that's a huge number for example.
2022-03-20 12:02:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:02:52 | INFO | fairseq.tasks.translation | example hypothesis: first of some of these things are not going to be able to be able to use the energy, but if you don't need your energy, you need to do it.
2022-03-20 12:02:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:02:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use information information that we can be able to be able to create a kind of information, and all the information that's going to be able to be able to be able to create a kind of information.
2022-03-20 12:02:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:03:00 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reasons it's interesting, and it's going to say, "oh," you know, "you know," you know, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," you're going to do it. "
2022-03-20 12:03:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:03:03 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still still still still the mother, and we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be
2022-03-20 12:03:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:03:03 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.843 | ppl 459.13 | bleu 8.94 | wps 4734.5 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 8.94
2022-03-20 12:03:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-20 12:03:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:03:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:03:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 8.94) (writing took 1.7297346671111882 seconds)
2022-03-20 12:03:04 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-20 12:03:04 | INFO | train | epoch 013 | loss 8.367 | ppl 330.1 | wps 39756.8 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.941 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 1409
KL Stats: Epoch 13 Divergences: Uniform: 1.3156104134536049 Unigram: 1.383210139034396
2022-03-20 12:03:05 | INFO | fairseq.trainer | begin training epoch 14
2022-03-20 12:03:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:03:29 | INFO | train_inner | epoch 014:     64 / 157 loss=8.265, ppl=307.52, wps=32066.3, ups=1.28, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.924, loss_scale=4, train_wall=37, gb_free=12.3, wall=1434
2022-03-20 12:04:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:04:08 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppm in the next school.
2022-03-20 12:04:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:04:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the right point of oha, most of the most of the most of the most of you know here.
2022-03-20 12:04:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:04:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new ways that are two new ways of the new new new new ways.
2022-03-20 12:04:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:04:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food where they're going to be, and where they're going to be going to be.
2022-03-20 12:04:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:04:25 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just just a few of the brain on his head, and what's going to understand.
2022-03-20 12:04:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:04:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamamamamamace of the responsibility for people who had found the number of animals, and the number of animals has been built for a million years.
2022-03-20 12:04:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:04:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the pattern of the brain, but it doesn't want to be able, but if you don't need to get the energy, you need to get the energy, you need to be able to get the energy, and get the energy.
2022-03-20 12:04:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:04:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that we can see is going to be able to be able to be able to be able to start with a structure of the information, and the information of the information, and the information that's going to create a structure of the structure, and the structure of the information, and the structure of the information, and the information, and the structure of the information, and the information that's all the structure of the information that's
2022-03-20 12:04:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:04:43 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reasons it's interesting, and it's interesting for me to do this, and i'm going to talk to you, "well, you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you've got to go to love," you know, "and then you've got to talk," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," and then
2022-03-20 12:04:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:04:45 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still the mother, and the design of the design of the design, and we've got a lot of the design that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-20 12:04:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:04:45 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.615 | ppl 392.19 | bleu 10.73 | wps 4379.6 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 10.73
2022-03-20 12:04:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-20 12:04:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:04:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:04:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 10.73) (writing took 1.7123082880862057 seconds)
2022-03-20 12:04:47 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-20 12:04:47 | INFO | train | epoch 014 | loss 8.14 | ppl 282.03 | wps 38505.2 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.91 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1512
KL Stats: Epoch 14 Divergences: Uniform: 1.3590389674564123 Unigram: 1.4213955059784098
2022-03-20 12:04:47 | INFO | fairseq.trainer | begin training epoch 15
2022-03-20 12:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:04:50 | INFO | train_inner | epoch 015:      7 / 157 loss=8.013, ppl=258.34, wps=31435, ups=1.23, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.873, loss_scale=4, train_wall=37, gb_free=12, wall=1515
2022-03-20 12:05:28 | INFO | train_inner | epoch 015:    107 / 157 loss=7.912, ppl=240.86, wps=67061.4, ups=2.67, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.928, loss_scale=4, train_wall=37, gb_free=12, wall=1553
2022-03-20 12:05:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:05:50 | INFO | fairseq.tasks.translation | example hypothesis: we made this ppon in the clinics.
2022-03-20 12:05:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:05:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the bottom of doha, most of you know, most of you know.
2022-03-20 12:05:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:05:58 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new.
2022-03-20 12:05:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:06:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese chinese food, where they're going to get with, and they're going to be used.
2022-03-20 12:06:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:06:06 | INFO | fairseq.tasks.translation | example hypothesis: it's pretty clear that we're not just able to understand a few of his head and understand what all of the things are.
2022-03-20 12:06:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:06:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamacy of the responsibility for the number of animals, the number of animals, and this is a number for example.
2022-03-20 12:06:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:06:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the cameras in the field, but it doesn't have to move, if you don't need your energy, it doesn't need your energy, and if you need the energy, you need your energy.
2022-03-20 12:06:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:06:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this structure, we can start able to start with a structure that we can start with a huge structure of the structure of the structure, and the structure of the structure, the structure, and the structure of the structure, and the structure, and the structure of the structure of the structure, and the structure, which is the structure of the structure of the structure, and the structure of the structure, and the structure
2022-03-20 12:06:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:06:25 | INFO | fairseq.tasks.translation | example hypothesis: david: one of the reasons it's interesting, and it's interesting for me to do that for example, "oh," oh, "oh, you know," oh, "well," you know, if you've got a lot of women in this talk, "and then you're working with a long revolution."
2022-03-20 12:06:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:06:27 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, the mother is still still still the invention of the design, and a huge design that we had to use that if we had to use a system, we had to see that if we were able to use it, it was a huge system, we were able to use the same system, and we're able to use it to use it to use it to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the
2022-03-20 12:06:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:06:27 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.356 | ppl 327.72 | bleu 13.03 | wps 4427.9 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 13.03
2022-03-20 12:06:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-20 12:06:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:06:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:06:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 13.03) (writing took 1.6222886331379414 seconds)
2022-03-20 12:06:29 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-20 12:06:29 | INFO | train | epoch 015 | loss 7.928 | ppl 243.5 | wps 38833.3 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.899 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1614
KL Stats: Epoch 15 Divergences: Uniform: 1.401428792667129 Unigram: 1.4523081616224989
2022-03-20 12:06:29 | INFO | fairseq.trainer | begin training epoch 16
2022-03-20 12:06:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:06:48 | INFO | train_inner | epoch 016:     50 / 157 loss=7.859, ppl=232.23, wps=31603.3, ups=1.24, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.857, loss_scale=4, train_wall=37, gb_free=12.4, wall=1633
2022-03-20 12:07:25 | INFO | train_inner | epoch 016:    150 / 157 loss=7.778, ppl=219.45, wps=66509.9, ups=2.7, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.891, loss_scale=4, train_wall=37, gb_free=12.6, wall=1670
2022-03-20 12:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:07:32 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinics.
2022-03-20 12:07:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:07:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the red line of doha, most of you know.
2022-03-20 12:07:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:07:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new orts.
2022-03-20 12:07:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:07:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese food, where they're going to get.
2022-03-20 12:07:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:07:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to understand a couple of electrop and understand what all the thoughts are on the mind.
2022-03-20 12:07:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:07:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamamacy, people came back to the number of animals.
2022-03-20 12:07:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:07:53 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of you are in the field, but you don't need it, but if you don't need your energy, you need your energy.
2022-03-20 12:07:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:07:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start to start with a traditional structure, we can start able to start able to start able to start with a very large structure of the structure of the structure of the structure, and the whole structure of information.
2022-03-20 12:07:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:08:01 | INFO | fairseq.tasks.translation | example hypothesis: hth: one of the reasons that it's interesting to do for me, "well, is that it's the best time to say," well, "well, if we're going to say," if you're going to say that the best revolution is a lot of women's first time. "
2022-03-20 12:08:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:08:02 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention, and a lot of design that we have to use a lot of work on our airplane, is that if we had to use a huge level of money.
2022-03-20 12:08:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:08:02 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.323 | ppl 320.25 | bleu 11.1 | wps 5392.7 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 13.03
2022-03-20 12:08:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-20 12:08:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:08:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:08:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 11.1) (writing took 0.7493585096672177 seconds)
2022-03-20 12:08:03 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-20 12:08:03 | INFO | train | epoch 016 | loss 7.74 | ppl 213.83 | wps 41843.4 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.897 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 1708
KL Stats: Epoch 16 Divergences: Uniform: 1.4419432705066184 Unigram: 1.484891270542926
2022-03-20 12:08:03 | INFO | fairseq.trainer | begin training epoch 17
2022-03-20 12:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:08:38 | INFO | train_inner | epoch 017:     93 / 157 loss=7.602, ppl=194.26, wps=34537.7, ups=1.37, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.93, loss_scale=4, train_wall=37, gb_free=13.1, wall=1744
2022-03-20 12:09:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:09:06 | INFO | fairseq.tasks.translation | example hypothesis: we made this pppace in the clinic clinic clinic clinics.
2022-03-20 12:09:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:09:11 | INFO | fairseq.tasks.translation | example hypothesis: that's the red line of doha ha ha, most of the most of you know.
2022-03-20 12:09:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:09:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create two new types.
2022-03-20 12:09:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:09:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese chinese food food, where he's going to be, and they're going to get up with it.
2022-03-20 12:09:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:09:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand what all the thoughts are on the mind.
2022-03-20 12:09:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:09:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamacy of the responsibility of responsibility, the number of animals came back to the number of animals, and this has been built in the namibia.
2022-03-20 12:09:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:09:33 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the bbols of magnetic magnetic lines, but it doesn't want to move out, but if you don't need to move your energy, and you know, it doesn't need the energy of energy.
2022-03-20 12:09:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:09:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use the reflection of this reflection, we can begin to start with a traditional form of the face of the structure, and that's all the information that we can start through the structure of the structure, and all the information, and the information, and the information that's all the information that we can start through the structure of the information, and the structure of the information.
2022-03-20 12:09:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:09:43 | INFO | fairseq.tasks.translation | example hypothesis: th th: the reasons it's interesting, and it's interesting for me to do this, "well, for example, you know, you know," you know, you know, "you know," you know, "you're working with a lot of women," and you're working on this talk, "when you're working on the stage."
2022-03-20 12:09:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:09:45 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother of the invention of the invention of the invention, and a great design design that we've got to use a unique design on the ground, and if you're able to see it, it's a unique system that we have to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-20 12:09:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:09:45 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.129 | ppl 279.89 | bleu 14.11 | wps 4188.2 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 14.11
2022-03-20 12:09:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-20 12:09:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:09:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 14.11) (writing took 1.6477095689624548 seconds)
2022-03-20 12:09:47 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-20 12:09:47 | INFO | train | epoch 017 | loss 7.592 | ppl 192.97 | wps 37950.4 | ups 1.51 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.9 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1812
KL Stats: Epoch 17 Divergences: Uniform: 1.482467955237936 Unigram: 1.502257639632167
2022-03-20 12:09:47 | INFO | fairseq.trainer | begin training epoch 18
2022-03-20 12:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:10:01 | INFO | train_inner | epoch 018:     36 / 157 loss=7.488, ppl=179.55, wps=30504.7, ups=1.21, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.848, loss_scale=4, train_wall=37, gb_free=12.5, wall=1826
2022-03-20 12:10:39 | INFO | train_inner | epoch 018:    136 / 157 loss=7.432, ppl=172.63, wps=66227.2, ups=2.67, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.761, loss_scale=4, train_wall=37, gb_free=12.3, wall=1864
2022-03-20 12:10:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:10:50 | INFO | fairseq.tasks.translation | example hypothesis: we did this pace in the clinic clinics.
2022-03-20 12:10:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:10:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the red line of doha, which is most likely to know.
2022-03-20 12:10:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:10:58 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new locks.
2022-03-20 12:10:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:11:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where happy legs and salt with the legs.
2022-03-20 12:11:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:11:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get a few electrodes on his head and understand what all its thoughts are.
2022-03-20 12:11:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:11:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamaa, like the responsibility for the life, the number of animals, the number of animals, and this is a conviation for the iibia.
2022-03-20 12:11:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:11:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are the magnetic magnetic lines in the field, but the superconductor, if you don't need your energy, if you need the energy, and you don't need your energy.
2022-03-20 12:11:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:11:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start able to start with a traditional face of traditional face, and we can start able to start able to start able to start with a real form of the shape, and the shape of the information.
2022-03-20 12:11:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:11:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedwomen, which is that when somebody said, "oh, if you're talking about the best thing," if you're talking about it. "
2022-03-20 12:11:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:11:26 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention, and one part of the design that we've got to solve in our plane, that we had to solve a unique result of the air, and if you're able to use it in the ground.
2022-03-20 12:11:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:11:26 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.909 | ppl 240.3 | bleu 17.09 | wps 4622.8 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 17.09
2022-03-20 12:11:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-20 12:11:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:11:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:11:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 17.09) (writing took 1.6226686388254166 seconds)
2022-03-20 12:11:27 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-20 12:11:27 | INFO | train | epoch 018 | loss 7.391 | ppl 167.88 | wps 39348 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.769 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1913
KL Stats: Epoch 18 Divergences: Uniform: 1.528822300576766 Unigram: 1.5349736761093855
2022-03-20 12:11:28 | INFO | fairseq.trainer | begin training epoch 19
2022-03-20 12:11:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:11:58 | INFO | train_inner | epoch 019:     79 / 157 loss=7.267, ppl=154.05, wps=32303.5, ups=1.26, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.759, loss_scale=4, train_wall=37, gb_free=12.2, wall=1943
2022-03-20 12:12:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:12:30 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic clinic.
2022-03-20 12:12:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:12:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most familiar here.
2022-03-20 12:12:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:12:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to be made by two new trucks.
2022-03-20 12:12:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:12:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs and salt with salsales.
2022-03-20 12:12:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:12:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head, and understand what all its thoughts are.
2022-03-20 12:12:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:12:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamato people like the responsibility of life, the number of animals grew back, and this is a foundation for conservation.
2022-03-20 12:12:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:12:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the boul field of magnetic magnetic lines, but the sullalalalalalarm doesn't move their energy, if you need energy, the energy and so forth.
2022-03-20 12:12:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:12:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can begin to start with a traditional face of the face of the face, and the whole information that comes through the structure of the structure.
2022-03-20 12:12:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:13:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure me for tedwomen, is that... "
2022-03-20 12:13:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:13:05 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother still is still the invention of the invention, and a great part of the design that we were on our airplane, that we had to solve a unique result of the ground, and if we had to use the ground, it's a unique way to be connected to a certain way that it would be connected to us.
2022-03-20 12:13:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:13:05 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.749 | ppl 215.17 | bleu 19.22 | wps 4761.9 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 19.22
2022-03-20 12:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-20 12:13:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:13:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:13:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 19.22) (writing took 1.7269384218379855 seconds)
2022-03-20 12:13:07 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-20 12:13:07 | INFO | train | epoch 019 | loss 7.202 | ppl 147.19 | wps 39769.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.755 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 2012
KL Stats: Epoch 19 Divergences: Uniform: 1.5637392479769405 Unigram: 1.5672657872131117
2022-03-20 12:13:07 | INFO | fairseq.trainer | begin training epoch 20
2022-03-20 12:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:13:15 | INFO | train_inner | epoch 020:     22 / 157 loss=7.126, ppl=139.7, wps=31988.7, ups=1.29, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.726, loss_scale=4, train_wall=36, gb_free=12.8, wall=2021
2022-03-20 12:13:54 | INFO | train_inner | epoch 020:    122 / 157 loss=7.001, ppl=128.07, wps=67878.2, ups=2.62, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.713, loss_scale=4, train_wall=38, gb_free=11.8, wall=2059
2022-03-20 12:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:14:10 | INFO | fairseq.tasks.translation | example hypothesis: we did these pills in the clinic clinics.
2022-03-20 12:14:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:14:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, the most likely to know here.
2022-03-20 12:14:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:14:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf.
2022-03-20 12:14:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:14:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where happy legs are going to eat with salsalsalsalz and pupppets.
2022-03-20 12:14:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:14:27 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electromagnetic electrodes on his head and understand exactly what all its thoughts are on the road.
2022-03-20 12:14:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:14:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the human responsibility for the wild responsibility, the number of animals grew back to the wild animals, and this is a foundation of conservation in namibia.
2022-03-20 12:14:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:14:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some bbols of magnetic magnetic fields start in the interfaces, but the susullant doesn't move when they need their energy, and that's how they need their energy.
2022-03-20 12:14:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:14:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start able to start with a traditional facial facial face, which is the real implications of the face of the face and the information, and through the information, and through the whole structure of this structure.
2022-03-20 12:14:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:14:45 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting to measure it interesting and measure it interesting and measure it for me here for tedwomen in tedwomen, is that... yes, the best one of you said, "when we're working on a very long time."
2022-03-20 12:14:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:14:47 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother of invention is still the invention of invention, and a big part of the design of the design work that we're a result of it was a unique problem that we had to solve all the problems of the problems that were connected to the ground, and it's all sorts of the way that we're going to use, or to see the way to be able to see the power of an exact act act act.
2022-03-20 12:14:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:14:47 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.703 | ppl 208.4 | bleu 20.63 | wps 4423.5 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 20.63
2022-03-20 12:14:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-20 12:14:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:14:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:14:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 20.63) (writing took 1.7314440570771694 seconds)
2022-03-20 12:14:48 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-20 12:14:48 | INFO | train | epoch 020 | loss 7.032 | ppl 130.85 | wps 38798.9 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.722 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 2114
KL Stats: Epoch 20 Divergences: Uniform: 1.5984116223808729 Unigram: 1.5974818924406267
2022-03-20 12:14:49 | INFO | fairseq.trainer | begin training epoch 21
2022-03-20 12:14:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:15:13 | INFO | train_inner | epoch 021:     65 / 157 loss=6.902, ppl=119.56, wps=31232.7, ups=1.26, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.74, loss_scale=4, train_wall=36, gb_free=12, wall=2138
2022-03-20 12:15:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:15:51 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinics.
2022-03-20 12:15:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:15:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most familiar here.
2022-03-20 12:15:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:16:00 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that will make the two new pigs.
2022-03-20 12:16:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:16:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food food, where happy legs are going to be made with salsalz and pink.
2022-03-20 12:16:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:16:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head, and understand what all his thoughts are on the road.
2022-03-20 12:16:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:16:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the makea, the people of the responsibility of life, grew up to the number of the wild animals, and that's a foundation for the namibia.
2022-03-20 12:16:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:16:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloop of magnetic fields are in the interior lines, but the sucks like the suck, it doesn't like that, if you need your energy, you need your energy, and that's how the sucks.
2022-03-20 12:16:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:16:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial faces that can start with all the information.
2022-03-20 12:16:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:16:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me to be a lot of women. "
2022-03-20 12:16:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:16:24 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention, and a big part of the design work that we're going to see in our plane, was a result that we had to solve the unique problems that were connected to the ground.
2022-03-20 12:16:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:16:24 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.539 | ppl 185.96 | bleu 20.25 | wps 5072 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 20.63
2022-03-20 12:16:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-20 12:16:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:16:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:16:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 21 @ 3292 updates, score 20.25) (writing took 0.7621348169632256 seconds)
2022-03-20 12:16:24 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-20 12:16:24 | INFO | train | epoch 021 | loss 6.908 | ppl 120.12 | wps 41124.1 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.727 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 2210
KL Stats: Epoch 21 Divergences: Uniform: 1.6223977275223869 Unigram: 1.608635811165147
2022-03-20 12:16:25 | INFO | fairseq.trainer | begin training epoch 22
2022-03-20 12:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:16:28 | INFO | train_inner | epoch 022:      8 / 157 loss=6.979, ppl=126.11, wps=33110.1, ups=1.34, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.731, loss_scale=4, train_wall=37, gb_free=12, wall=2213
2022-03-20 12:17:05 | INFO | train_inner | epoch 022:    108 / 157 loss=6.879, ppl=117.67, wps=66095.8, ups=2.68, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.734, loss_scale=4, train_wall=37, gb_free=12, wall=2251
2022-03-20 12:17:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:17:27 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-20 12:17:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:17:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 12:17:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:17:35 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are two new pigs.
2022-03-20 12:17:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:17:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where frog legs and pipin.
2022-03-20 12:17:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:17:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head, and understand what all his thoughts are on the road.
2022-03-20 12:17:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:17:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people's responsibility for the wild animals, the number of wild animals, and that's a foundation for the namibia.
2022-03-20 12:17:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:17:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field are starting in the inner, but the susulant doesn't like if they need their movements, and so the suicide disorder.
2022-03-20 12:17:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:17:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big constructions of the face of the face and the fundamental shape of the information that gives it all the ports and the ports of the information.
2022-03-20 12:17:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:17:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measured for me here at tedwomen, is that... well, you know, you know, you know, the best one said, "the men who said," and then we're going to support you in a table revolution. "
2022-03-20 12:17:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:18:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're going to see in our airplane, was a result of the unique problems that we had to solve in the ground -- and it allows us to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the aircraft.
2022-03-20 12:18:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:18:01 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.435 | ppl 173.03 | bleu 21.67 | wps 4825.3 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 21.67
2022-03-20 12:18:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-20 12:18:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:18:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:18:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 22 @ 3449 updates, score 21.67) (writing took 1.710480802692473 seconds)
2022-03-20 12:18:03 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-20 12:18:03 | INFO | train | epoch 022 | loss 6.793 | ppl 110.92 | wps 40062.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.685 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2308
KL Stats: Epoch 22 Divergences: Uniform: 1.6450393877761407 Unigram: 1.6266575804711843
2022-03-20 12:18:03 | INFO | fairseq.trainer | begin training epoch 23
2022-03-20 12:18:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:18:23 | INFO | train_inner | epoch 023:     51 / 157 loss=6.716, ppl=105.13, wps=32934.5, ups=1.29, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.588, loss_scale=4, train_wall=37, gb_free=11.9, wall=2328
2022-03-20 12:19:00 | INFO | train_inner | epoch 023:    151 / 157 loss=6.557, ppl=94.13, wps=68154.5, ups=2.68, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.66, loss_scale=4, train_wall=37, gb_free=11.9, wall=2365
2022-03-20 12:19:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:19:06 | INFO | fairseq.tasks.translation | example hypothesis: we did these pills in the clinic.
2022-03-20 12:19:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:19:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-20 12:19:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:19:14 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that make two new pigs.
2022-03-20 12:19:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:19:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are served with salz.
2022-03-20 12:19:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:19:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand what all his thoughts are on the road.
2022-03-20 12:19:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:19:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people have been responsible for the wild animals, and this is a foundation of natural protection in namibia.
2022-03-20 12:19:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:19:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnet lines in the inner, but the sulant doesn't, if they're moving, because they need their movements, their energy, and so the superconductor of magnetic disorders, and so the supermagnetic disorders of magnetic field.
2022-03-20 12:19:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:19:36 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, which gives the big constructions of the face and reform the real fundamental shape of the face and repeat it, and through the information, which is the whole information that all the portion of this reflective structure, and all the ports, we can fold a different portion of this reflection, we can fold, we can fold
2022-03-20 12:19:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:19:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measure it to me at tedwomen is that -- "well, when you were going to go to the best," when someone said, "when someone said," you go to the men, "and then we're working on a table," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know, when you know," you know, "you know," you know, "you know, it's going to be a long, when you know," you know, it's going to help you know, you know, when you know, "you know," you know, "you're going to be a long time," you know, "
2022-03-20 12:19:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:19:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're using in our plane, was a result that we had to solve the unique problems that we had to solve the ground, so it was connected to the ground to the ground, and it's all the way that it would be connected to a transportation system, if you could be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do it, if you're able to do it, if you're able to do it, if you're able to do it, if you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-20 12:19:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:19:44 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.418 | ppl 171.06 | bleu 22.95 | wps 4328 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 22.95
2022-03-20 12:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-20 12:19:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:19:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:19:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 22.95) (writing took 1.6943616732023656 seconds)
2022-03-20 12:19:46 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-20 12:19:46 | INFO | train | epoch 023 | loss 6.651 | ppl 100.47 | wps 38431.2 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.642 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2411
KL Stats: Epoch 23 Divergences: Uniform: 1.656929749702158 Unigram: 1.6465964037654939
2022-03-20 12:19:46 | INFO | fairseq.trainer | begin training epoch 24
2022-03-20 12:19:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:20:22 | INFO | train_inner | epoch 024:     94 / 157 loss=6.625, ppl=98.71, wps=30545.4, ups=1.23, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.624, loss_scale=4, train_wall=37, gb_free=11.9, wall=2447
2022-03-20 12:20:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:20:49 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-20 12:20:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:20:53 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-20 12:20:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:20:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are made by two new pigs.
2022-03-20 12:20:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:21:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where frog legs are served with salz and pit.
2022-03-20 12:21:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:21:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-20 12:21:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:21:09 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals, people have been overwhelmed for the wild, grew the number of wild animals again, and that's a basis of conservation.
2022-03-20 12:21:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:21:13 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloodings of magnetic fields are caught in the inside, but the susuperconductor doesn't like you move, because their movements need energy, and so the superconductor disorders.
2022-03-20 12:21:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:21:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the big constructions of the face and the basic shape, and through the information that contains the whole structure of the face.
2022-03-20 12:21:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:21:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's going to be interesting and measured for me here at tedwomen is that... well, when they were delicious, "when someone said," you go to men and say, "and then we're going to support them for a long time. '' '"
2022-03-20 12:21:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:21:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we were at our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continents and refrigerated by a refrigering system that allows us to use the same if you can use it in the same way to use it to help us see the power of a security system.
2022-03-20 12:21:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:21:23 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.247 | ppl 151.93 | bleu 25.3 | wps 4858.5 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 25.3
2022-03-20 12:21:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-20 12:21:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:21:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 25.3) (writing took 1.6473723049275577 seconds)
2022-03-20 12:21:24 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-20 12:21:24 | INFO | train | epoch 024 | loss 6.555 | ppl 94.05 | wps 40145.8 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.602 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2509
KL Stats: Epoch 24 Divergences: Uniform: 1.673581041110555 Unigram: 1.6621997061854765
2022-03-20 12:21:25 | INFO | fairseq.trainer | begin training epoch 25
2022-03-20 12:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:21:39 | INFO | train_inner | epoch 025:     37 / 157 loss=6.426, ppl=85.97, wps=33068.6, ups=1.3, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.582, loss_scale=4, train_wall=37, gb_free=12.1, wall=2524
2022-03-20 12:22:16 | INFO | train_inner | epoch 025:    137 / 157 loss=6.513, ppl=91.32, wps=66680.2, ups=2.66, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.639, loss_scale=4, train_wall=37, gb_free=12, wall=2561
2022-03-20 12:22:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:22:28 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-20 12:22:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:22:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 12:22:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:22:35 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are two new pigs.
2022-03-20 12:22:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:22:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food is french food where frog legs are served with salz and pitems.
2022-03-20 12:22:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:22:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:22:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:22:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people who took responsibility for the wild animals. and this is a basis of conservation in namibia.
2022-03-20 12:22:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:22:51 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some dragonflies are caught in the inner field, but the supraleiters may not use their movements, and so the superconductor disorders.
2022-03-20 12:22:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:22:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with a traditional facial face and reform the basic shape of the face, and reform it through the information that pulls the whole portion.
2022-03-20 12:22:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:22:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that do it high-interesting and measure it for me to be here at tedwomen is that... well, at that time. "
2022-03-20 12:22:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:23:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything variable to a variable system, and that allows us to do with a refrigering system, and that we're either able to use a car system, or if you're able to see it in the aircraft, if you're able to do it.
2022-03-20 12:23:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:23:00 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.295 | ppl 157.01 | bleu 22.56 | wps 5116.6 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 25.3
2022-03-20 12:23:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-20 12:23:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:23:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:23:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 22.56) (writing took 0.8085002950392663 seconds)
2022-03-20 12:23:01 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-20 12:23:01 | INFO | train | epoch 025 | loss 6.475 | ppl 88.98 | wps 40910.1 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.622 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2606
KL Stats: Epoch 25 Divergences: Uniform: 1.6794522311577476 Unigram: 1.6732594090017372
2022-03-20 12:23:01 | INFO | fairseq.trainer | begin training epoch 26
2022-03-20 12:23:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:23:31 | INFO | train_inner | epoch 026:     80 / 157 loss=6.354, ppl=81.8, wps=33891.1, ups=1.33, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.572, loss_scale=4, train_wall=37, gb_free=12.2, wall=2637
2022-03-20 12:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:24:04 | INFO | fairseq.tasks.translation | example hypothesis: we put this beep in the clinic.
2022-03-20 12:24:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:24:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here.
2022-03-20 12:24:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:24:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are two new pigs.
2022-03-20 12:24:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:24:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pitems.
2022-03-20 12:24:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:24:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-20 12:24:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:24:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people of responsibility for the wild, the number of wild animals grew back again, and that's a basis of conservation in namibia.
2022-03-20 12:24:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:24:28 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloop of magnetic field lines are caught in the inner, but the suicide doesn't like it, if they're moving, because their movements need energy, and so the suide disorders.
2022-03-20 12:24:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:24:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big constructions of the face and the basic shape, and through the information that pulls all the ports and fold.
2022-03-20 12:24:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:24:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measure it, for me here at tedwomen, is that... well, when they were dedicated, it's best than someone said, "turn to the men on dtable and they say," if the revolution begins to support you, "we've already been in this period of time," well, "we're working with a millennium," you know, "you know," well. "
2022-03-20 12:24:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:24:39 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a refrigeration system, and that allows us to use an aircraft to fly in the aircraft, or if we're able to see the mechanism of an aircraft.
2022-03-20 12:24:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:24:39 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.087 | ppl 135.91 | bleu 27.62 | wps 4663.1 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 27.62
2022-03-20 12:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-20 12:24:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:24:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:24:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 27.62) (writing took 1.7453304608352482 seconds)
2022-03-20 12:24:41 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-20 12:24:41 | INFO | train | epoch 026 | loss 6.38 | ppl 83.31 | wps 39575.9 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.572 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2706
KL Stats: Epoch 26 Divergences: Uniform: 1.6895238101013392 Unigram: 1.6850544704311279
2022-03-20 12:24:41 | INFO | fairseq.trainer | begin training epoch 27
2022-03-20 12:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:24:50 | INFO | train_inner | epoch 027:     23 / 157 loss=6.369, ppl=82.63, wps=31676.4, ups=1.27, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.567, loss_scale=4, train_wall=37, gb_free=12.9, wall=2715
2022-03-20 12:25:28 | INFO | train_inner | epoch 027:    123 / 157 loss=6.322, ppl=80.02, wps=66941.8, ups=2.67, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.552, loss_scale=4, train_wall=37, gb_free=11.7, wall=2753
2022-03-20 12:25:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:25:44 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:25:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:25:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know here.
2022-03-20 12:25:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:25:52 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that make two new pigs.
2022-03-20 12:25:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:25:55 | INFO | fairseq.tasks.translation | example hypothesis: for example, french food, where frog legs are served with salz and pitcase.
2022-03-20 12:25:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:25:59 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:25:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:26:04 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-20 12:26:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:26:08 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the supraleiters don't like to move, because their movements need energy, and so the sulal disorders.
2022-03-20 12:26:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:26:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which gives the big constructions of the face and the basic shape, and through the information that pulls all the ports and fold.
2022-03-20 12:26:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:26:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured for me here at tedwomen, is that... tall, when someone said, "turn you to the men on your table and say," if the revolution starts to support you. "
2022-03-20 12:26:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:26:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at the top of our airplane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and refrigering system that allows us to use an aircraft to refrightening, if you're either able to see the same thing.
2022-03-20 12:26:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:26:17 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.045 | ppl 132.03 | bleu 27.35 | wps 4930.4 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 27.62
2022-03-20 12:26:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-20 12:26:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:26:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:26:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 27 @ 4234 updates, score 27.35) (writing took 0.7703723767772317 seconds)
2022-03-20 12:26:18 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-20 12:26:18 | INFO | train | epoch 027 | loss 6.296 | ppl 78.55 | wps 40454 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.548 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2803
KL Stats: Epoch 27 Divergences: Uniform: 1.6919434141085676 Unigram: 1.6956284278908667
2022-03-20 12:26:18 | INFO | fairseq.trainer | begin training epoch 28
2022-03-20 12:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:26:43 | INFO | train_inner | epoch 028:     66 / 157 loss=6.288, ppl=78.16, wps=32872.8, ups=1.32, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.549, loss_scale=4, train_wall=37, gb_free=12.8, wall=2828
2022-03-20 12:27:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:27:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:27:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:27:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 12:27:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:27:29 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are two new pigs.
2022-03-20 12:27:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:27:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frozen legs are served with salz and pitcase.
2022-03-20 12:27:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:27:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-20 12:27:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:27:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wild animals grew back, and this is a basis for conservation in namibia.
2022-03-20 12:27:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:27:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the superconductor doesn't like it, if you use your movements, and the supralty disorders.
2022-03-20 12:27:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:27:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial that gives the big constructions of the face and the basic shape of the information that's all the ports and all the fold.
2022-03-20 12:27:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:27:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured for me to be here at tedwomen, is that... well, when the strip dinner was best summarized by the men in your table, and they say, "if the revolution starts supporting you."
2022-03-20 12:27:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:27:55 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a big part of the design work that we're at our plane at the stest, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigering system that allows us to be able to use in the air, or to see the aircraft, if we can be able to solve the aircraft, or to be able to be able to be able to get rid of an aircraft.
2022-03-20 12:27:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:27:55 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.992 | ppl 127.26 | bleu 28.74 | wps 4752.8 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 28.74
2022-03-20 12:27:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-20 12:27:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:27:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:27:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 28.74) (writing took 1.6734976316802204 seconds)
2022-03-20 12:27:57 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-20 12:27:57 | INFO | train | epoch 028 | loss 6.226 | ppl 74.87 | wps 39904 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.543 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2902
KL Stats: Epoch 28 Divergences: Uniform: 1.7000959941644838 Unigram: 1.7048654306005486
2022-03-20 12:27:57 | INFO | fairseq.trainer | begin training epoch 29
2022-03-20 12:27:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:28:01 | INFO | train_inner | epoch 029:      9 / 157 loss=6.204, ppl=73.74, wps=32490, ups=1.29, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.557, loss_scale=4, train_wall=37, gb_free=11.8, wall=2906
2022-03-20 12:28:38 | INFO | train_inner | epoch 029:    109 / 157 loss=6.175, ppl=72.27, wps=66738.4, ups=2.65, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.503, loss_scale=4, train_wall=37, gb_free=11.7, wall=2944
2022-03-20 12:28:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:29:00 | INFO | fairseq.tasks.translation | example hypothesis: we put this beep in the clinic.
2022-03-20 12:29:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:29:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 12:29:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:29:08 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are two new pigs.
2022-03-20 12:29:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:29:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-20 12:29:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:29:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:29:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:29:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of how people took responsibility for wildlife, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-20 12:29:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:29:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught in the inside, but the supralbuters don't like to move, because their movements need energy, and so the supralty disorder.
2022-03-20 12:29:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:29:28 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial that gives the big constructions of facial and reform the fundamental information that constructs the entire ports and all the folds.
2022-03-20 12:29:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:29:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measured to me here at tedwomen, is that... tyes, when stripped dinner, it was best summarized when somebody said, "turn you to men on your table and tell you about this revolution, then we support you."
2022-03-20 12:29:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:29:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're on our airplane on the stumes, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and refrigerator system that allows us to use a machine to see if you can see the aircraft.
2022-03-20 12:29:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:29:34 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.949 | ppl 123.54 | bleu 28.83 | wps 4867.2 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 28.83
2022-03-20 12:29:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-20 12:29:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:29:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:29:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 28.83) (writing took 1.7269293102435768 seconds)
2022-03-20 12:29:36 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-20 12:29:36 | INFO | train | epoch 029 | loss 6.155 | ppl 71.27 | wps 40046.5 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.513 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3001
KL Stats: Epoch 29 Divergences: Uniform: 1.7011469523959901 Unigram: 1.7121345043719398
2022-03-20 12:29:36 | INFO | fairseq.trainer | begin training epoch 30
2022-03-20 12:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:29:56 | INFO | train_inner | epoch 030:     52 / 157 loss=6.155, ppl=71.28, wps=32431.2, ups=1.29, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.515, loss_scale=4, train_wall=37, gb_free=12.1, wall=3021
2022-03-20 12:30:33 | INFO | train_inner | epoch 030:    152 / 157 loss=6.06, ppl=66.71, wps=67731.4, ups=2.67, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.455, loss_scale=4, train_wall=37, gb_free=12.9, wall=3058
2022-03-20 12:30:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:30:39 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:30:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:30:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-20 12:30:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:30:47 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-20 12:30:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:30:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are served with salz and pepper.
2022-03-20 12:30:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:30:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:30:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:30:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wild animals grew up again, and that's a basis for conservation in namibia.
2022-03-20 12:30:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:31:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorders.
2022-03-20 12:31:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:31:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constructions of the face and the basic shape, and recover it through the information that pulls all the ports structure and all a fold.
2022-03-20 12:31:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:31:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... tyes, when dinner was best summarized when someone said, "turn to the men on your table and tell you," if the revolution starts to support you. "
2022-03-20 12:31:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:31:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft to either see if you're in the air.
2022-03-20 12:31:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:31:12 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.903 | ppl 119.72 | bleu 29.45 | wps 4941.1 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 29.45
2022-03-20 12:31:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-20 12:31:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:31:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:31:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 29.45) (writing took 1.7381824208423495 seconds)
2022-03-20 12:31:14 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-20 12:31:14 | INFO | train | epoch 030 | loss 6.09 | ppl 68.1 | wps 40118.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.477 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3099
KL Stats: Epoch 30 Divergences: Uniform: 1.704567164932201 Unigram: 1.723706528297686
2022-03-20 12:31:14 | INFO | fairseq.trainer | begin training epoch 31
2022-03-20 12:31:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:31:51 | INFO | train_inner | epoch 031:     95 / 157 loss=6.046, ppl=66.07, wps=32979.2, ups=1.29, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.516, loss_scale=4, train_wall=37, gb_free=11.7, wall=3136
2022-03-20 12:32:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:32:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:32:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:32:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of them here.
2022-03-20 12:32:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:32:25 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks signs that create two new pigs.
2022-03-20 12:32:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:32:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are served with salz and ppeppepper.
2022-03-20 12:32:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:32:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:32:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:32:37 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the human responsibility for the wild, the number of wildanimals grew back, and that's a basis for conservation in namibia.
2022-03-20 12:32:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:32:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught in the inside, but the supraleiter doesn't like it if you move, because your movements use energy, and so the superconduction disorders.
2022-03-20 12:32:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:32:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that gives the big constructions of the face and recover the basic shape of the face, and recover it through the same information that pulls the whole portion structure and all a fold.
2022-03-20 12:32:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:32:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting to be here for me at tedwomen is that... tyes, it was best summarized when someone said, "turn you to your men on your table and tell you," if the revolution begins to support you. "
2022-03-20 12:32:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:32:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane was a result of solving the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to use in the aircraft, or whether you're in the air conditioning.
2022-03-20 12:32:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:32:52 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.856 | ppl 115.85 | bleu 30.14 | wps 4714.2 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.14
2022-03-20 12:32:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-20 12:32:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:32:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:32:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 30.14) (writing took 1.6336501389741898 seconds)
2022-03-20 12:32:53 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-20 12:32:53 | INFO | train | epoch 031 | loss 6.061 | ppl 66.77 | wps 39757.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.499 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3199
KL Stats: Epoch 31 Divergences: Uniform: 1.703341111034669 Unigram: 1.723278049328946
2022-03-20 12:32:54 | INFO | fairseq.trainer | begin training epoch 32
2022-03-20 12:32:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:33:08 | INFO | train_inner | epoch 032:     38 / 157 loss=6.026, ppl=65.17, wps=32009.7, ups=1.28, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.453, loss_scale=4, train_wall=37, gb_free=12.5, wall=3214
2022-03-20 12:33:46 | INFO | train_inner | epoch 032:    138 / 157 loss=5.976, ppl=62.95, wps=67586.6, ups=2.67, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.493, loss_scale=4, train_wall=37, gb_free=12.5, wall=3251
2022-03-20 12:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:33:56 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:33:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:34:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of the ones here.
2022-03-20 12:34:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:34:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will cross two new pigs.
2022-03-20 12:34:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:34:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-20 12:34:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:34:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-20 12:34:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:34:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for the wild, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-20 12:34:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:34:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are caught in the inside, but the superconductor doesn't like it when they move because they're moving, because they're using their movements, and so the superconducting disorders.
2022-03-20 12:34:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:34:25 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can, which is the big constructions of the face and the basic shape, and refers it through the entire ports structure and all the fits.
2022-03-20 12:34:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:34:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measuring it to me here at tedwomen is that -- well, when we were dinner, it's best summarized when somebody said, "turn you to the men on your table," and then we support you. "the truth is that we've already supported you for a long time in silver, and then we've been supporting the future."
2022-03-20 12:34:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:34:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane is the most staggering, was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variation and refrigeration system that allows us to stop a machine in the aircraft, and that would allow us to use aircraft, or to be able to make a specific, or to fly, if you see the earth.
2022-03-20 12:34:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:34:32 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.808 | ppl 112.03 | bleu 30.31 | wps 4629.4 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 30.31
2022-03-20 12:34:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-20 12:34:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:34:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 32 @ 5019 updates, score 30.31) (writing took 1.7115453388541937 seconds)
2022-03-20 12:34:33 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-20 12:34:33 | INFO | train | epoch 032 | loss 5.997 | ppl 63.86 | wps 39493.5 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.477 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 3299
KL Stats: Epoch 32 Divergences: Uniform: 1.7033903029666206 Unigram: 1.7311805876474784
2022-03-20 12:34:34 | INFO | fairseq.trainer | begin training epoch 33
2022-03-20 12:34:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:35:05 | INFO | train_inner | epoch 033:     81 / 157 loss=5.955, ppl=62.02, wps=31834.5, ups=1.27, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.477, loss_scale=4, train_wall=37, gb_free=12.1, wall=3330
2022-03-20 12:35:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:35:37 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:35:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:35:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most of the ones here.
2022-03-20 12:35:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:35:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks signs that are going to transcend two new pigs.
2022-03-20 12:35:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:35:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-20 12:35:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:35:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-20 12:35:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:35:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wild animals grew up again, and that's a basis for conservation in namibia.
2022-03-20 12:35:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:36:02 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught in the inside, but the supraleiter doesn't like the superconductor if you move because your movements use energy, and so the superconductor disorders.
2022-03-20 12:36:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:36:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constructions of the face, and refers it through the one of the information that pulls the entire por-structure and all the fits.
2022-03-20 12:36:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:36:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's very interesting and measured it to me here at tedwomen is that... tyes, when dinner was put it best together when someone said, "turn you to the men on your table and tell you," if the revolution starts supporting you. "the truth is that we love women, we've already started supporting you for this long time,"
2022-03-20 12:36:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:36:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and cooling system that allows us to use liquid transportation in the aircraft until you see the air conditioning.
2022-03-20 12:36:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:36:12 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.784 | ppl 110.17 | bleu 31.46 | wps 4626.2 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.46
2022-03-20 12:36:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-20 12:36:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:36:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.46) (writing took 1.6100363479927182 seconds)
2022-03-20 12:36:14 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-20 12:36:14 | INFO | train | epoch 033 | loss 5.957 | ppl 62.11 | wps 39342.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.461 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3399
KL Stats: Epoch 33 Divergences: Uniform: 1.7071189078710565 Unigram: 1.7382723618036278
2022-03-20 12:36:14 | INFO | fairseq.trainer | begin training epoch 34
2022-03-20 12:36:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:36:24 | INFO | train_inner | epoch 034:     24 / 157 loss=5.979, ppl=63.08, wps=31681.1, ups=1.26, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.461, loss_scale=4, train_wall=37, gb_free=12, wall=3409
2022-03-20 12:37:01 | INFO | train_inner | epoch 034:    124 / 157 loss=5.921, ppl=60.61, wps=67031.3, ups=2.67, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.49, loss_scale=4, train_wall=37, gb_free=11.8, wall=3447
2022-03-20 12:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:37:18 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:37:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:37:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here know.
2022-03-20 12:37:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:37:26 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of dinners that are going to transcend two new pigs.
2022-03-20 12:37:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:37:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pill.
2022-03-20 12:37:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:37:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:37:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:37:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife animals grew again, and that's a basis of conservation in namibia.
2022-03-20 12:37:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:37:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured in the inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconductor disorders are disturbed.
2022-03-20 12:37:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:37:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that gives the big constructions of the face and refers it through the same information that pulls the entire porter structure and all a fold.
2022-03-20 12:37:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:37:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that -- well, in striking dinner, it was best summarized when someone said, "turn you to the men on your table and tell you," if the revolution begins to support you, then we support you. 'the truth is that we've already been supporting you for this topic for you for a long time. "
2022-03-20 12:37:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:37:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variation and a cooling system that allows us to be able to be able to do with liquid traffic in a particular way, if you're going to see the same thing that we're going to be able to do, if you're going to see the same to be connected to a security conditioning system, if you're in the same to the ground, if you're in the same way that's the same way that's the same to be connected to the same to be connected to the earth.
2022-03-20 12:37:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:37:54 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.788 | ppl 110.51 | bleu 31.28 | wps 4546.6 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 31.46
2022-03-20 12:37:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-20 12:37:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 31.28) (writing took 0.7699250490404665 seconds)
2022-03-20 12:37:55 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-20 12:37:55 | INFO | train | epoch 034 | loss 5.925 | ppl 60.76 | wps 39186.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.493 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 3500
KL Stats: Epoch 34 Divergences: Uniform: 1.7087163032183685 Unigram: 1.7407166855120797
2022-03-20 12:37:55 | INFO | fairseq.trainer | begin training epoch 35
2022-03-20 12:37:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:38:20 | INFO | train_inner | epoch 035:     67 / 157 loss=5.882, ppl=58.98, wps=31935.2, ups=1.27, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.466, loss_scale=4, train_wall=36, gb_free=12.9, wall=3525
2022-03-20 12:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:38:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:38:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:39:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of the ones here.
2022-03-20 12:39:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:39:05 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of dinners that are going to transcend two new pigs.
2022-03-20 12:39:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:39:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-20 12:39:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:39:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-20 12:39:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:39:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wildlife animals grew up again, and that's become a basis for conservation in namibia.
2022-03-20 12:39:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:39:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught in the inside, but the superconductor doesn't like it when they're moving, because their movements are using energy, and so the superconductor disorders.
2022-03-20 12:39:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:39:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this mirror reflection, we can start to start with a traditional facial that restores the big constructions of the face and the basic shape through the one of the information that pulls the entire por-structure and all the fits.
2022-03-20 12:39:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:39:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's interesting and measuring it to me here at tedwomen is that -- well, when dinner was best summarized by the time someone said, "turn you to the men on your table and tell you," if the revolution begins to support you. "the truth is that we've already been supporting you for a long time with sildy dy harbor,"
2022-03-20 12:39:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:39:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable operating and a cooling system that allows us to use an aircraft in the aircraft to either be a particular vehicle that we see when you're in the air conditioning the air conditional space, if you're in the air conditioning the air conditioning the air conditioning or the air conditioning, you're going to the air conditioning, you see the air conditioning in the air conditioning the air conditioning the air conditional space, if you're going to the air conditioning it's in the air conditioning the air.
2022-03-20 12:39:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:39:32 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.742 | ppl 107.07 | bleu 31.39 | wps 4718.8 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 31.46
2022-03-20 12:39:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-20 12:39:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:39:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 35 @ 5490 updates, score 31.39) (writing took 0.7949349479749799 seconds)
2022-03-20 12:39:33 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-20 12:39:33 | INFO | train | epoch 035 | loss 5.882 | ppl 58.96 | wps 40099.7 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.45 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3598
KL Stats: Epoch 35 Divergences: Uniform: 1.7097936701429883 Unigram: 1.7508597140221482
2022-03-20 12:39:33 | INFO | fairseq.trainer | begin training epoch 36
2022-03-20 12:39:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:39:37 | INFO | train_inner | epoch 036:     10 / 157 loss=5.929, ppl=60.93, wps=32264.2, ups=1.29, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.448, loss_scale=4, train_wall=37, gb_free=12.8, wall=3603
2022-03-20 12:40:15 | INFO | train_inner | epoch 036:    110 / 157 loss=5.823, ppl=56.6, wps=67040.5, ups=2.65, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.423, loss_scale=4, train_wall=37, gb_free=12.9, wall=3640
2022-03-20 12:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:40:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-20 12:40:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:40:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of the people here know.
2022-03-20 12:40:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:40:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-20 12:40:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:40:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and ppepper.
2022-03-20 12:40:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:40:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:40:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:40:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of how people took responsibility for wildlife, the number of wildlife animals grew up again, and that's a basis for conservation in namibia.
2022-03-20 12:40:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:41:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured in the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-20 12:41:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:41:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can begin to restore the big constructions of the face, and the basic shape, and recommend it through the information that pulls the whole por-structure and all the fussions.
2022-03-20 12:41:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:41:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it was very interesting and measurable to be here for me at tedwomen is that -- well, when dinner was first summarized when someone said, "turn to the men on your table, and we'll support you, 'if the revolution,' if the revolution begins, we'll support you. '' the truth, women is that we've already been supporting you in this topic for this long time, and then we've already started to support you, and then, you know, you know, you know, ["] ["] ["] ["] ["] ["] [["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-20 12:41:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:41:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane at the stumbling, was a result of solving the unique problems that were connected to operating it on the ground -- everything, from a continuous variable, and a cooling system of refrigeration, it allows us to use a steady machine in the air-go-box, and it allows us to use it to make a propulsion system that would be a propulsion system that would be able to make it, or to make it?
2022-03-20 12:41:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:41:12 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.727 | ppl 105.9 | bleu 31.61 | wps 4564.5 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 31.61
2022-03-20 12:41:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-20 12:41:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:41:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 31.61) (writing took 1.7460620878264308 seconds)
2022-03-20 12:41:14 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-20 12:41:14 | INFO | train | epoch 036 | loss 5.843 | ppl 57.38 | wps 39233.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.444 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3699
KL Stats: Epoch 36 Divergences: Uniform: 1.7095082851873398 Unigram: 1.7509381756823923
2022-03-20 12:41:14 | INFO | fairseq.trainer | begin training epoch 37
2022-03-20 12:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:41:34 | INFO | train_inner | epoch 037:     53 / 157 loss=5.732, ppl=53.16, wps=32276, ups=1.26, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.448, loss_scale=4, train_wall=37, gb_free=12.8, wall=3719
2022-03-20 12:42:12 | INFO | train_inner | epoch 037:    153 / 157 loss=5.929, ppl=60.91, wps=66310.2, ups=2.67, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.474, loss_scale=4, train_wall=37, gb_free=11.7, wall=3757
2022-03-20 12:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:42:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-20 12:42:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:42:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here know.
2022-03-20 12:42:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:42:25 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dining that will be overlawn two new pigs.
2022-03-20 12:42:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:42:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pills.
2022-03-20 12:42:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:42:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all are his thoughts on the track.
2022-03-20 12:42:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:42:37 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife grew again, and this has become a basis for conservation in namibia.
2022-03-20 12:42:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:42:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field captured inside, but the superconductor doesn't like to move because their movements use energy, and so the superconductor disorders.
2022-03-20 12:42:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:42:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can begin to restore the big constructions of the face and the basic shape, and recover it through the theft of the information that pulls the entire por-structure and all the fits.
2022-03-20 12:42:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:42:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's extremely interesting and measured to me here at tedwomen is that -- well, when dinner was first summarized at the best time when someone said, "turn you to men on your table and say," when the revolution starts supporting you. ""
2022-03-20 12:42:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:42:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and cooling system with fluid that allows us to use in the same way that allows us to use an aircraft in the same way, to a particular way, or to a particular solution to the wrong way, if you see the same way that it's the wrong thing.
2022-03-20 12:42:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:42:52 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.698 | ppl 103.82 | bleu 32.09 | wps 4604.5 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.09
2022-03-20 12:42:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-20 12:42:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:42:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:42:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 32.09) (writing took 1.7670610179193318 seconds)
2022-03-20 12:42:54 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-20 12:42:54 | INFO | train | epoch 037 | loss 5.824 | ppl 56.67 | wps 39299 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.452 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3799
KL Stats: Epoch 37 Divergences: Uniform: 1.7091079473548179 Unigram: 1.7540936190285765
2022-03-20 12:42:55 | INFO | fairseq.trainer | begin training epoch 38
2022-03-20 12:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:43:31 | INFO | train_inner | epoch 038:     96 / 157 loss=5.926, ppl=60.8, wps=31052.4, ups=1.26, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.468, loss_scale=4, train_wall=37, gb_free=12.6, wall=3836
2022-03-20 12:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:43:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:43:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:44:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here know.
2022-03-20 12:44:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:44:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-20 12:44:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:44:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and ppepper.
2022-03-20 12:44:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:44:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:44:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:44:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wild animals grew back again, and this has become a basis for conservation in namibia.
2022-03-20 12:44:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:44:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-20 12:44:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:44:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection reflection, we can start with a traditional face that gives the big constructions of the face and the basic shape, and recommending it through the information that pulls the entire por-structure and all the fine ones.
2022-03-20 12:44:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:44:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been highly interesting and measured to me here at tedwomen is that -- well, when dinner dinner, it was best summarized when someone said, "turn you to men on your table and tell you," if the revolution begins, we support you. "the truth, love women, is that we've already started supporting you with this topic for a long time."
2022-03-20 12:44:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:44:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane at the most stumbling was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation and a cooling system with fluid, that allows us to use a machine in the stopand go-go-state traffic, either to use a particular vehicle, or a propulsion system, or an aircraft conditionality, or a particular vehicle system that allows us to use, to use, or an aircraft conditioning machine, to use, to use, or a propaganda conditionality, to use, to use, or a machine, to use, to use, or a particular vehicle conditionality, or a machine, or a vehicle conditionality, to drive, or a vehicle, to use, or a progressive, to use, to use, or a vehicle condition
2022-03-20 12:44:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:44:32 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.69 | ppl 103.25 | bleu 31.82 | wps 4659.6 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.09
2022-03-20 12:44:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-20 12:44:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:44:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:44:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 31.82) (writing took 0.7975119771435857 seconds)
2022-03-20 12:44:33 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-20 12:44:33 | INFO | train | epoch 038 | loss 5.81 | ppl 56.09 | wps 39926.2 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.462 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3898
KL Stats: Epoch 38 Divergences: Uniform: 1.7113272198749347 Unigram: 1.7602191032195422
2022-03-20 12:44:34 | INFO | fairseq.trainer | begin training epoch 39
2022-03-20 12:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:44:49 | INFO | train_inner | epoch 039:     39 / 157 loss=5.604, ppl=48.63, wps=33560.4, ups=1.29, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.417, loss_scale=4, train_wall=37, gb_free=11.8, wall=3914
2022-03-20 12:45:26 | INFO | train_inner | epoch 039:    139 / 157 loss=5.819, ppl=56.44, wps=66305.1, ups=2.67, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.461, loss_scale=4, train_wall=37, gb_free=12.8, wall=3951
2022-03-20 12:45:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:45:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:45:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:45:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you here know.
2022-03-20 12:45:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:45:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dining that will be overlaid two new pigs.
2022-03-20 12:45:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:45:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pills.
2022-03-20 12:45:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:45:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:45:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:45:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-20 12:45:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:46:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it, if you move, because your movements are using energy, and so the superconductor is disturbing.
2022-03-20 12:46:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:46:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can that gives the big contextures of the face and the basic shape, and we recover it through the one that refers the entire por-structure and all the fits.
2022-03-20 12:46:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:46:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been very interesting and appropriate to be here for me at tedwomen is that -- well, in the dinner dinner dinner, it was best summarized when someone said, "turn you to the men in your table, and we support you," the truth, love, is that we've already started supporting you with this topic for a long time in the future of silspring, "to download our primordial castine,"
2022-03-20 12:46:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:46:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane was the most stumbling, which is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable operating and cooling system that allows us to use an aircraft device in the aircraft, to be used to a particular vehicle, or a particular vehicle, if you're going to be able to get rid of the most propelled in the ground, or the same way, if you're going to get rid of a car system that we're going to operate the same way that you're going to get rid of a car system that you're going to get rid of a car system that you're going to get rid of the air system that you're going to get rid of the ground, all the same way that you're going to get rid of a vehicle, and you're going to be able to get rid of
2022-03-20 12:46:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:46:12 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 6.656 | ppl 100.83 | bleu 32.54 | wps 4596.9 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 32.54
2022-03-20 12:46:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-20 12:46:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:46:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:46:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 32.54) (writing took 1.744626454077661 seconds)
2022-03-20 12:46:14 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-20 12:46:14 | INFO | train | epoch 039 | loss 5.764 | ppl 54.34 | wps 39293.2 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.433 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 3999
KL Stats: Epoch 39 Divergences: Uniform: 1.7110517459169732 Unigram: 1.7644412245375023
2022-03-20 12:46:14 | INFO | fairseq.trainer | begin training epoch 40
2022-03-20 12:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:46:45 | INFO | train_inner | epoch 040:     82 / 157 loss=5.8, ppl=55.73, wps=31393.2, ups=1.27, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.402, loss_scale=4, train_wall=37, gb_free=12.2, wall=4030
2022-03-20 12:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:47:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-20 12:47:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:47:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, probably most of you here know.
2022-03-20 12:47:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:47:24 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-20 12:47:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:47:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pills.
2022-03-20 12:47:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:47:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:47:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:47:37 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-20 12:47:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:47:41 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorders.
2022-03-20 12:47:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:47:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constructions of the face and the basic shape, and regrets it through the information that pulls all the por-structure and all the fits.
2022-03-20 12:47:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:47:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and appropriate for me to be here at tedwomen is that -- well, when dinner was stripped, it was best summarized when someone said, "turn you to the men in your desk and say," if the revolution begins to support you, then we support you. '"the truth, love women is that we've already been supporting you about this topic for a long time."
2022-03-20 12:47:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:47:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane was the result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable drivers and a cooling system of fluid that allows us to use an aircraft machine in the stop-go-traffic to a particular vehicle, or if you fly the propsible to the ground, or if you can see it's connected to a mechanism, it's all the same thing, it's all the same to a car system that we see it's going to be operated, all the same to be operated to a car, all the ground, all the same way, and see it's going to a mechanism, it's in the air system that we see it's in the same way.
2022-03-20 12:47:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:47:52 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 6.669 | ppl 101.74 | bleu 32.54 | wps 4648.1 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 32.54
2022-03-20 12:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-20 12:47:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:47:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 40 @ 6275 updates, score 32.54) (writing took 1.7589384457096457 seconds)
2022-03-20 12:47:54 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-20 12:47:54 | INFO | train | epoch 040 | loss 5.734 | ppl 53.23 | wps 39445 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.409 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 4099
KL Stats: Epoch 40 Divergences: Uniform: 1.7155554541975746 Unigram: 1.7722607921567426
2022-03-20 12:47:54 | INFO | fairseq.trainer | begin training epoch 41
2022-03-20 12:47:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:48:04 | INFO | train_inner | epoch 041:     25 / 157 loss=5.713, ppl=52.46, wps=32415.6, ups=1.27, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.422, loss_scale=4, train_wall=37, gb_free=12.6, wall=4109
2022-03-20 12:48:41 | INFO | train_inner | epoch 041:    125 / 157 loss=5.738, ppl=53.38, wps=66596.9, ups=2.67, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.459, loss_scale=4, train_wall=37, gb_free=12, wall=4146
2022-03-20 12:48:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:48:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:48:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:49:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-20 12:49:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:49:04 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dining that are going to be two new pigs.
2022-03-20 12:49:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:49:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pills.
2022-03-20 12:49:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:49:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:49:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:49:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife animals grew up again, and that's become a basis for conservation in namibia.
2022-03-20 12:49:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:49:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-20 12:49:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:49:25 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constructions of the face and the basic shape, and recommends it through the information that refers the whole por-structure and all the fine folds.
2022-03-20 12:49:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:49:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, when dinner dinner was best summarized when someone said, "turn to the men in your desk and say," if the revolution begins, then we support you, "the truth, women is that we've already started to support you for a long time."
2022-03-20 12:49:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:49:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable, and a cooling system with fluid that allows us to use an aircraft machine in the stop-go-traffic to a particular vehicle, if you fly the ground, or if you fly the propelled it to a mechanism, all the same time you see it in the air conditional space, you see it in the air conditionally, you see it in the air conditional direction you see it in the air conditional space, you can see it in the air conditional space, and you see it in the air conditioning, you see it all the same way, you can see it in the air conditional areas that you can see it in the air conditionally, until you see it's either drill you can see the air condition
2022-03-20 12:49:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:49:32 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 6.618 | ppl 98.25 | bleu 32.72 | wps 4644.3 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 32.72
2022-03-20 12:49:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-20 12:49:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:49:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:49:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 32.72) (writing took 1.6543975258246064 seconds)
2022-03-20 12:49:34 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-20 12:49:34 | INFO | train | epoch 041 | loss 5.727 | ppl 52.95 | wps 39583.4 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.441 | loss_scale 4 | train_wall 58 | gb_free 11.7 | wall 4199
KL Stats: Epoch 41 Divergences: Uniform: 1.7114571754952344 Unigram: 1.7701028789907356
2022-03-20 12:49:34 | INFO | fairseq.trainer | begin training epoch 42
2022-03-20 12:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:49:59 | INFO | train_inner | epoch 042:     68 / 157 loss=5.683, ppl=51.37, wps=32058.4, ups=1.28, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.423, loss_scale=4, train_wall=37, gb_free=22.3, wall=4225
2022-03-20 12:50:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:50:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:50:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:50:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-20 12:50:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:50:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will be two new pigs.
2022-03-20 12:50:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:50:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pill.
2022-03-20 12:50:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:50:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:50:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:50:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew up again, and this has become a foundation for conservation in namibia.
2022-03-20 12:50:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:51:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field captured inside, but the superconductor doesn't like it when they move because their movements use energy, and so the superconductor disorders.
2022-03-20 12:51:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:51:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that refers the big constructions of the face and the basic shape, and recommends it through the information that refers the whole por-structure and all the fine folds.
2022-03-20 12:51:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:51:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to me here at tedwomen is that -- well, when dinner dinner, it was best summarized when someone said, "turn to men on your table and say," 'when the revolution begins, we support you.' "the truth, love women, is that we've already been supporting you in this topic for a long time."
2022-03-20 12:51:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:51:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable drivers and a cooling system of liquid, that allows us to use an aircraft machine in the stop-go-traffic to a particular driver of the propeller, if you fly the wrong, or if you see the air conditionality of a mechanism.
2022-03-20 12:51:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:51:11 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 6.641 | ppl 99.81 | bleu 32.3 | wps 4729.7 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 32.72
2022-03-20 12:51:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-20 12:51:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:51:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:51:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 32.3) (writing took 0.761927014682442 seconds)
2022-03-20 12:51:12 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-20 12:51:12 | INFO | train | epoch 042 | loss 5.696 | ppl 51.82 | wps 40152.7 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.418 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 4297
KL Stats: Epoch 42 Divergences: Uniform: 1.7138515021293539 Unigram: 1.7771116190145742
2022-03-20 12:51:12 | INFO | fairseq.trainer | begin training epoch 43
2022-03-20 12:51:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:51:17 | INFO | train_inner | epoch 043:     11 / 157 loss=5.655, ppl=50.39, wps=33037.6, ups=1.29, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.392, loss_scale=4, train_wall=37, gb_free=12.1, wall=4302
2022-03-20 12:51:54 | INFO | train_inner | epoch 043:    111 / 157 loss=5.725, ppl=52.89, wps=66702.5, ups=2.68, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.437, loss_scale=4, train_wall=37, gb_free=11.9, wall=4339
2022-03-20 12:52:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:52:15 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:52:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:52:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here know.
2022-03-20 12:52:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:52:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dining that will be two new pigs transcend.
2022-03-20 12:52:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:52:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-20 12:52:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:52:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-20 12:52:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:52:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew back, and this has become a basis for conservation in namibia.
2022-03-20 12:52:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:52:39 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting.
2022-03-20 12:52:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:52:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big conscores of the face and the basic shape back, and recovers it through the information that refers the whole por-structure and all the fine.
2022-03-20 12:52:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:52:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to me here at tedwomen is that... well, when strictly dinner, it was best summarized as someone said, "turn to men on your table and say," 'if the revolution begins, then we support you.' the truth, love, women is that we've already started supporting you with this topic for a long time. "
2022-03-20 12:52:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:52:50 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane is the most stumbling result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable operating and a cooling system with fluid that allows us to use an aircraft machine in the stop-go-transportation to a particular propulsion machine, either drive the propellant, or when you see the most propulsive propelled, the soil is the wrong, all the same to see the mechanism in the same way we see the same way that drives when you see the wrong direction you can see the earth's going to see the mechanism in the same way that drives the wrong direction you can see the earth.
2022-03-20 12:52:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:52:50 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 6.606 | ppl 97.44 | bleu 33 | wps 4657.3 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33
2022-03-20 12:52:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-20 12:52:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:52:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:52:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.0) (writing took 1.7673743315972388 seconds)
2022-03-20 12:52:52 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-20 12:52:52 | INFO | train | epoch 043 | loss 5.675 | ppl 51.09 | wps 39521 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.42 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 4397
KL Stats: Epoch 43 Divergences: Uniform: 1.7144732121732469 Unigram: 1.7789871097575456
2022-03-20 12:52:52 | INFO | fairseq.trainer | begin training epoch 44
2022-03-20 12:52:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:53:13 | INFO | train_inner | epoch 044:     54 / 157 loss=5.7, ppl=51.99, wps=31636.3, ups=1.27, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.445, loss_scale=4, train_wall=37, gb_free=12.3, wall=4418
2022-03-20 12:53:50 | INFO | train_inner | epoch 044:    154 / 157 loss=5.602, ppl=48.57, wps=68648.8, ups=2.69, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.382, loss_scale=4, train_wall=37, gb_free=12, wall=4455
2022-03-20 12:53:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:53:55 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-20 12:53:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:53:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-20 12:53:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:54:03 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-20 12:54:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:54:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pills.
2022-03-20 12:54:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:54:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:54:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:54:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach how people took responsibility for wildlife, the number of wild animals grew back, and this has become a basis for conservation in namibia.
2022-03-20 12:54:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:54:19 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-20 12:54:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:54:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial that gives the big constructions of the face and the basic shape, and we remove it through the one of the information that puts the whole por-structure and all the fine.
2022-03-20 12:54:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:54:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, when dinner, it was best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, then we support you. "the truth, women, we've already been supporting you with this topic for a long time."
2022-03-20 12:54:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:54:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane was on the stumbling toes, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable operating and a cooling system with fluid, it allows us to use an aircraft machine in the stop-go-traffic, to a particular driver, if you can see the propelled, or the prophecy system that's connected to the soil -- all the mechanism, all the mechanism, all the same way down to a crash.
2022-03-20 12:54:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:54:29 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 6.601 | ppl 97.05 | bleu 33.17 | wps 4787.2 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.17
2022-03-20 12:54:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-20 12:54:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:54:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 44 @ 6903 updates, score 33.17) (writing took 1.7517308299429715 seconds)
2022-03-20 12:54:31 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-20 12:54:31 | INFO | train | epoch 044 | loss 5.658 | ppl 50.5 | wps 39886.7 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.419 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 4496
KL Stats: Epoch 44 Divergences: Uniform: 1.7141670474308337 Unigram: 1.7803071476316863
2022-03-20 12:54:31 | INFO | fairseq.trainer | begin training epoch 45
2022-03-20 12:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:55:08 | INFO | train_inner | epoch 045:     97 / 157 loss=5.568, ppl=47.45, wps=32771.1, ups=1.28, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.419, loss_scale=4, train_wall=37, gb_free=12.7, wall=4533
2022-03-20 12:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:55:34 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-20 12:55:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:55:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here know.
2022-03-20 12:55:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:55:42 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dining that will transcend two new pigs.
2022-03-20 12:55:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:55:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and pfsuitcase.
2022-03-20 12:55:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:55:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all of its thoughts are on the track.
2022-03-20 12:55:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:55:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife grew back up, and that's become a basis for conservation in namibia.
2022-03-20 12:55:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:55:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor is disturbing.
2022-03-20 12:55:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:56:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial that gives the big constructions of the face and the shape back, and recover it through the information that refers the whole por-structure and all the fine.
2022-03-20 12:56:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:56:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to me here at tedwomen is that... well, when dinner dinner, it was best summarized as someone said, "turn to the men on your table and tell them," if the revolution begins, then we support you. "the truth, love, women is that we've already started downstaying you at this topic for a long time."
2022-03-20 12:56:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:56:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable gear, and a cooling system that allows us to use an aircraft machine in the stop-go-traffic, to a particular propulsion machine, or if you fly to the ground, you can see the prophecy.
2022-03-20 12:56:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:56:08 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 6.587 | ppl 96.13 | bleu 33.24 | wps 4883.5 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.24
2022-03-20 12:56:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-20 12:56:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:56:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:56:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 45 @ 7060 updates, score 33.24) (writing took 1.6891211871989071 seconds)
2022-03-20 12:56:09 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-20 12:56:09 | INFO | train | epoch 045 | loss 5.64 | ppl 49.88 | wps 40143.7 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.422 | loss_scale 4 | train_wall 58 | gb_free 13.2 | wall 4594
KL Stats: Epoch 45 Divergences: Uniform: 1.7132784033940776 Unigram: 1.783017518398744
2022-03-20 12:56:10 | INFO | fairseq.trainer | begin training epoch 46
2022-03-20 12:56:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:56:25 | INFO | train_inner | epoch 046:     40 / 157 loss=5.754, ppl=53.95, wps=31568.5, ups=1.3, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.422, loss_scale=4, train_wall=36, gb_free=12.4, wall=4610
2022-03-20 12:57:03 | INFO | train_inner | epoch 046:    140 / 157 loss=5.574, ppl=47.63, wps=67577.8, ups=2.66, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.389, loss_scale=4, train_wall=37, gb_free=11.7, wall=4648
2022-03-20 12:57:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:57:13 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep on the clinic.
2022-03-20 12:57:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:57:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-20 12:57:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:57:20 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dining that will transcend two new pigs.
2022-03-20 12:57:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:57:24 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pfsuitcase.
2022-03-20 12:57:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:57:28 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 12:57:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:57:32 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew back, and this has become a basis for conservation in namibia.
2022-03-20 12:57:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:57:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconductor disturbs.
2022-03-20 12:57:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:57:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial that gives the big conscores of the face and the basic form, and recommends it through the theft of information that refers the entire por-structure and all the fine.
2022-03-20 12:57:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:57:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... well, when dinner dinner, it was best summarized when someone said, "turn to men on your table and say to them," if the revolution begins, we support you. "the truth, women love you for a long time.
2022-03-20 12:57:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:57:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane is the most stumbling result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable operating and cooling system that allows us to use an aircraft on the stop-go-traffic, to a particular driver, either drives the propelled or the propelled, if you fly the same thing to the ground, all the way down to the safety facilities that we see, all the way down to the air conditioning.
2022-03-20 12:57:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:57:47 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 6.586 | ppl 96.07 | bleu 32.94 | wps 4779.3 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.24
2022-03-20 12:57:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-20 12:57:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:57:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 12:57:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 32.94) (writing took 0.7628691871650517 seconds)
2022-03-20 12:57:48 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-20 12:57:48 | INFO | train | epoch 046 | loss 5.614 | ppl 48.97 | wps 40075.2 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.404 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 4693
KL Stats: Epoch 46 Divergences: Uniform: 1.7155539161972182 Unigram: 1.7883430232030488
2022-03-20 12:57:48 | INFO | fairseq.trainer | begin training epoch 47
2022-03-20 12:57:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:58:20 | INFO | train_inner | epoch 047:     83 / 157 loss=5.597, ppl=48.41, wps=32684.1, ups=1.3, wpb=25147.5, bsz=1057.7, num_updates=7300, lr=0.000370117, gnorm=0.418, loss_scale=4, train_wall=37, gb_free=11.9, wall=4725
2022-03-20 12:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 12:58:52 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 12:58:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 12:58:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you here know.
2022-03-20 12:58:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 12:58:59 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dining that will transcend two new pigs.
2022-03-20 12:58:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 12:59:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-20 12:59:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 12:59:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-20 12:59:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 12:59:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-20 12:59:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 12:59:15 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move because their movements use energy, and that's how the superconductor is disturbing.
2022-03-20 12:59:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 12:59:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this reflection, we can start with a traditional facial can, which repeats the big contures of the face and the basic shape, and reproduce it through the information that refers the whole por-structure and all the fine.
2022-03-20 12:59:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 12:59:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, when dinner, it was best summarized when someone said, "turn you to the men of your desk and say to them," when the revolution begins, we support you. '"the truth, women love you about this topic for a long time."
2022-03-20 12:59:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 12:59:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we are on our plane the most staggering, was a result that we had to solve the unique problems associated with operating it on the ground -- everything, from a continuously variable gear and a cooling system that allows us to use an aircraft in the stop-go-traffic, to a particular vehicle that would be drifted if you fly the same to the ground.
2022-03-20 12:59:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 12:59:25 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 6.589 | ppl 96.25 | bleu 33.39 | wps 4975.2 | wpb 17862.2 | bsz 728.3 | num_updates 7374 | best_bleu 33.39
2022-03-20 12:59:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7374 updates
2022-03-20 12:59:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:59:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 12:59:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 47 @ 7374 updates, score 33.39) (writing took 1.6996577749960124 seconds)
2022-03-20 12:59:26 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-20 12:59:26 | INFO | train | epoch 047 | loss 5.6 | ppl 48.51 | wps 40077.5 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 7374 | lr 0.000368255 | gnorm 0.405 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 4791
KL Stats: Epoch 47 Divergences: Uniform: 1.7159066185605951 Unigram: 1.7933735621681495
2022-03-20 12:59:27 | INFO | fairseq.trainer | begin training epoch 48
2022-03-20 12:59:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 12:59:36 | INFO | train_inner | epoch 048:     26 / 157 loss=5.575, ppl=47.66, wps=32722, ups=1.3, wpb=25089, bsz=1043, num_updates=7400, lr=0.000367607, gnorm=0.414, loss_scale=4, train_wall=37, gb_free=11.7, wall=4801
2022-03-20 13:00:14 | INFO | train_inner | epoch 048:    126 / 157 loss=5.573, ppl=47.61, wps=67469, ups=2.63, wpb=25678, bsz=966, num_updates=7500, lr=0.000365148, gnorm=0.374, loss_scale=4, train_wall=38, gb_free=12.3, wall=4840
2022-03-20 13:00:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 13:00:29 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 13:00:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 13:00:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-20 13:00:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 13:00:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-20 13:00:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 13:00:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-20 13:00:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 13:00:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-20 13:00:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 13:00:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the face of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-20 13:00:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 13:00:54 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor doesn't like it.
2022-03-20 13:00:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 13:00:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big contures of the face, and recommends it through the information that refers the entire por-structure and all the fine ones.
2022-03-20 13:00:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 13:01:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, when dinner was striking, it was best summarized when someone said, "turn you to the men on your table and say to you," when the revolution begins, then we support you. "the truth, women, love, we've been supporting you for a long time. at rachel carroman," at the dinner, we've started to support you about this topic for a long time.
2022-03-20 13:01:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 13:01:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still part of the design work that we're on our plane at the most stumbling of our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable, and a coolness system that allows us to use an aircraft machine at the stopgo-traffic, to a particular driver's vehicle that either drives the propelled when you fly the propelled the prophecy, or if you fly the propelled the propeller, or you see the propelled at the bottom of a car conditioning, you can see that you can see in the air conditioning for a car conditioning, you can see when you can see the wheel to fly to the ground, you see the wheel up to the wheel up to the wheel up to the ground, you can see the wheel up to the wheel, you can see if you can see the wheel up
2022-03-20 13:01:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 13:01:05 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 6.568 | ppl 94.89 | bleu 33.44 | wps 4612.3 | wpb 17862.2 | bsz 728.3 | num_updates 7531 | best_bleu 33.44
2022-03-20 13:01:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7531 updates
2022-03-20 13:01:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 13:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 13:01:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 48 @ 7531 updates, score 33.44) (writing took 1.6356147327460349 seconds)
2022-03-20 13:01:06 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-20 13:01:06 | INFO | train | epoch 048 | loss 5.583 | ppl 47.95 | wps 39457.1 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 7531 | lr 0.000364396 | gnorm 0.405 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 4892
KL Stats: Epoch 48 Divergences: Uniform: 1.71596948073972 Unigram: 1.792744236547787
2022-03-20 13:01:07 | INFO | fairseq.trainer | begin training epoch 49
2022-03-20 13:01:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 13:01:33 | INFO | train_inner | epoch 049:     69 / 157 loss=5.659, ppl=50.52, wps=31131.4, ups=1.28, wpb=24399, bsz=1004.6, num_updates=7600, lr=0.000362738, gnorm=0.421, loss_scale=4, train_wall=36, gb_free=12.2, wall=4918
2022-03-20 13:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 13:02:09 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-20 13:02:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 13:02:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you here know.
2022-03-20 13:02:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 13:02:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-20 13:02:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 13:02:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and pepper.
2022-03-20 13:02:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 13:02:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 13:02:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 13:02:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildanimals grew up again, and this has become a basis for conservation in namibia.
2022-03-20 13:02:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 13:02:33 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are captured inside, but the superconductor doesn't like it when they move because they use energy, and so the superconductor is disturbing.
2022-03-20 13:02:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 13:02:37 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and recover it through the one that refers the entire por-structure and all the fine.
2022-03-20 13:02:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 13:02:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, when dinner, it was best summarized as someone said, "turn to the men of your desk and say to them," if the revolution begins, then we support you. "the truth, love women is that we've already started supporting you with this topic for a long time. at rachel carried siltheo," our sandor the future. "
2022-03-20 13:02:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 13:02:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're on our airplane is the result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable gear and a refrigerator system of liquid that allows us to use an aircraft on the stop and go-traffic to a particular vehicle that will either drive the prophecy or the propulsion of a propulsion of a mechanism if you fly, all the promoting the way you see the mechanism to a security facility facility facilities.
2022-03-20 13:02:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 13:02:43 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 6.577 | ppl 95.47 | bleu 33.01 | wps 4829.2 | wpb 17862.2 | bsz 728.3 | num_updates 7688 | best_bleu 33.44
2022-03-20 13:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7688 updates
2022-03-20 13:02:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 13:02:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 13:02:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 49 @ 7688 updates, score 33.01) (writing took 0.7355649480596185 seconds)
2022-03-20 13:02:44 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-20 13:02:44 | INFO | train | epoch 049 | loss 5.565 | ppl 47.34 | wps 40507.5 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 7688 | lr 0.000360656 | gnorm 0.393 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 4989
KL Stats: Epoch 49 Divergences: Uniform: 1.7175402667011017 Unigram: 1.798708455634741
2022-03-20 13:02:44 | INFO | fairseq.trainer | begin training epoch 50
2022-03-20 13:02:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 13:02:49 | INFO | train_inner | epoch 050:     12 / 157 loss=5.511, ppl=45.61, wps=33564.2, ups=1.31, wpb=25586.8, bsz=1069, num_updates=7700, lr=0.000360375, gnorm=0.392, loss_scale=4, train_wall=37, gb_free=12.9, wall=4994
2022-03-20 13:03:27 | INFO | train_inner | epoch 050:    112 / 157 loss=5.512, ppl=45.62, wps=67461.4, ups=2.65, wpb=25420, bsz=1059.8, num_updates=7800, lr=0.000358057, gnorm=0.398, loss_scale=4, train_wall=37, gb_free=11.9, wall=5032
2022-03-20 13:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 13:03:47 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-20 13:03:47 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 13:03:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you here know.
2022-03-20 13:03:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 13:03:55 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-20 13:03:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 13:03:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and pills.
2022-03-20 13:03:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 13:04:03 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-20 13:04:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 13:04:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-20 13:04:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 13:04:11 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements are using energy, and that's how the superconductor is disturbing.
2022-03-20 13:04:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 13:04:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructions of the face and the basic shape, and then recommends it through the one information that refers the entire por-structure and all the fine ones.
2022-03-20 13:04:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 13:04:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me at tedwomen is that... well, when dinner was best summarized, it was said, "turn to the men of your desk and say," if the revolution begins, we support you. '"the truth, love women is that we've already been supporting you with this topic for a long time. at rachson carchel siltheo boro, our catheo."
2022-03-20 13:04:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 13:04:22 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our plane is the most stumbling result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable gear and a cooling system that allows us to use an aircraft in the stop-go-traffic aircraft, to a particular driver's ride, either drill the propsidewalks or the propsical problems that were connected to the crying propsidewalks.
2022-03-20 13:04:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 13:04:22 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 6.547 | ppl 93.52 | bleu 33.85 | wps 4704.4 | wpb 17862.2 | bsz 728.3 | num_updates 7845 | best_bleu 33.85
2022-03-20 13:04:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7845 updates
2022-03-20 13:04:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 13:04:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 13:04:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 50 @ 7845 updates, score 33.85) (writing took 1.6869704760611057 seconds)
2022-03-20 13:04:23 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-20 13:04:23 | INFO | train | epoch 050 | loss 5.55 | ppl 46.86 | wps 39649.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7845 | lr 0.000357029 | gnorm 0.397 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 5089
KL Stats: Epoch 50 Divergences: Uniform: 1.7167397169122134 Unigram: 1.7993580150183621
2022-03-20 13:04:24 | INFO | fairseq.trainer | begin training epoch 51
2022-03-20 13:04:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 13:04:45 | INFO | train_inner | epoch 051:     55 / 157 loss=5.591, ppl=48.19, wps=31891.4, ups=1.28, wpb=24912.1, bsz=989.4, num_updates=7900, lr=0.000355784, gnorm=0.386, loss_scale=4, train_wall=37, gb_free=12.9, wall=5110
2022-03-20 13:05:22 | INFO | train_inner | epoch 051:    155 / 157 loss=5.512, ppl=45.63, wps=67989.7, ups=2.7, wpb=25169.7, bsz=1006.8, num_updates=8000, lr=0.000353553, gnorm=0.413, loss_scale=4, train_wall=37, gb_free=11.6, wall=5147
2022-03-20 13:05:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 13:05:26 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-20 13:05:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 13:05:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here know.
2022-03-20 13:05:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 13:05:34 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dining that two new pigs will be crossed.
2022-03-20 13:05:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 13:05:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and pepper.
2022-03-20 13:05:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 13:05:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on its head and understanding exactly what all his thoughts are on the track.
2022-03-20 13:05:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 13:05:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-20 13:05:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 13:05:50 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are caught inside, but the superconductor doesn't like it if they move because of their movements, and that's how the superconductor is disturbing.
2022-03-20 13:05:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 13:05:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big configurations of the face and the basic shape, and we can begin to fold it through the information that refers all the por-structure and all the fine ones.
2022-03-20 13:05:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 13:05:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me at tedwomen is that... well, at the dinner dinner, it was best summarized when someone said, "turn to the men of your table and tell them, 'if the revolution begins, then we support you.'" the truth, love women, we've already supported you about this topic for a long time. 'at rachel carchel thera borne and down our future stream. "
2022-03-20 13:05:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 13:06:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a great part of the design work that we're on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable system and a cooling system with fluid, that allows us to use an aircraft in the stop-go-go-and-traffic to a specific vehicle that would be driven, or if you look at the ground, to the mechanism.
2022-03-20 13:06:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 13:06:00 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 6.558 | ppl 94.24 | bleu 33.79 | wps 4853.2 | wpb 17862.2 | bsz 728.3 | num_updates 8002 | best_bleu 33.85
2022-03-20 13:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8002 updates
2022-03-20 13:06:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 13:06:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 13:06:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 51 @ 8002 updates, score 33.79) (writing took 0.7776026171632111 seconds)
2022-03-20 13:06:01 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-20 13:06:01 | INFO | train | epoch 051 | loss 5.533 | ppl 46.3 | wps 40493.5 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 8002 | lr 0.000353509 | gnorm 0.403 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 5186
KL Stats: Epoch 51 Divergences: Uniform: 1.7185215912700995 Unigram: 1.8037843407482048
2022-03-20 13:06:01 | INFO | fairseq.trainer | begin training epoch 52
2022-03-20 13:06:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 13:06:38 | INFO | train_inner | epoch 052:     98 / 157 loss=5.5, ppl=45.26, wps=32822.8, ups=1.31, wpb=25057.5, bsz=1065.7, num_updates=8100, lr=0.000351364, gnorm=0.411, loss_scale=4, train_wall=37, gb_free=11.7, wall=5223
2022-03-20 13:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 13:07:05 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 13:07:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 13:07:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you here know.
2022-03-20 13:07:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 13:07:13 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-20 13:07:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 13:07:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-20 13:07:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 13:07:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 13:07:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 13:07:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-20 13:07:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 13:07:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductions are disturbing.
2022-03-20 13:07:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 13:07:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big contexts of the face and the basic shape, and we recover it through the most information that refers the whole por-structure and all the fine wrinkles.
2022-03-20 13:07:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 13:07:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it was very interesting and appropriate to be here at tedwomen is that -- well, at the dinner dinner dinner dinner, it was best summarized when someone said, "turn you to the men at your table and tell them," if the revolution begins, then we support you. "the truth, love, women, we've already started to support you with rachel siltheo."
2022-03-20 13:07:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 13:07:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're on our plane is the most stumbling part of the fact that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable, and a coolness system that allows us to use an aircraft in the stop-go traffic to a particular vehicle that either drives the prophecy or if you fly the mechanism, you can see the same to the ground.
2022-03-20 13:07:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 13:07:39 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 6.536 | ppl 92.78 | bleu 33.94 | wps 4905.2 | wpb 17862.2 | bsz 728.3 | num_updates 8159 | best_bleu 33.94
2022-03-20 13:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 8159 updates
2022-03-20 13:07:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 13:07:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 13:07:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 52 @ 8159 updates, score 33.94) (writing took 1.8670225110836327 seconds)
2022-03-20 13:07:41 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-20 13:07:41 | INFO | train | epoch 052 | loss 5.528 | ppl 46.15 | wps 39619.6 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 8159 | lr 0.000350091 | gnorm 0.412 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 5286
KL Stats: Epoch 52 Divergences: Uniform: 1.7194602734728006 Unigram: 1.803537901525157
2022-03-20 13:07:41 | INFO | fairseq.trainer | begin training epoch 53
2022-03-20 13:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 13:07:56 | INFO | train_inner | epoch 053:     41 / 157 loss=5.547, ppl=46.77, wps=32132.9, ups=1.28, wpb=25151.3, bsz=978.2, num_updates=8200, lr=0.000349215, gnorm=0.423, loss_scale=4, train_wall=37, gb_free=12, wall=5302
2022-03-20 13:08:34 | INFO | train_inner | epoch 053:    141 / 157 loss=5.563, ppl=47.28, wps=66447.2, ups=2.67, wpb=24894.4, bsz=1025.6, num_updates=8300, lr=0.000347105, gnorm=0.416, loss_scale=4, train_wall=37, gb_free=12.2, wall=5339
2022-03-20 13:08:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 13:08:43 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 13:08:43 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 13:08:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you here know.
2022-03-20 13:08:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 13:08:52 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-20 13:08:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 13:08:56 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-20 13:08:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 13:09:00 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 13:09:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 13:09:04 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-20 13:09:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 13:09:08 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move because their movements use energy, and that's how the superconductor is disturbing.
2022-03-20 13:09:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 13:09:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructions of the face and the basic shape, and reproduce it through the information that refers the whole porn structure and all the fine wrinkles.
2022-03-20 13:09:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 13:09:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that, you know, when strictly dinner, it was best summarized when someone said, "turn to the men of your desk and tell them," if the revolution begins, then we support you. '"the truth, women, love, is that we've already supported you about this topic for a long time. at rachson carel," with silspring. "
2022-03-20 13:09:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 13:09:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, nevertheless, the mother of invention, and a large part of the design work that we're on our airplane is the most stumbling result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variable gear and a cooling system that allows us to use an aircraft machine in the stop-go-traffic to a particular driver that either drives the propeller, or when you're on the ground, to see the safety facilities, all the way down to the same way.
2022-03-20 13:09:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 13:09:18 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 6.524 | ppl 92.05 | bleu 34.13 | wps 4735.3 | wpb 17862.2 | bsz 728.3 | num_updates 8316 | best_bleu 34.13
2022-03-20 13:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 8316 updates
2022-03-20 13:09:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 13:09:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt
2022-03-20 13:09:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_best.pt (epoch 53 @ 8316 updates, score 34.13) (writing took 1.8774732509627938 seconds)
2022-03-20 13:09:20 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-20 13:09:20 | INFO | train | epoch 053 | loss 5.518 | ppl 45.83 | wps 39771 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 8316 | lr 0.000346771 | gnorm 0.412 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 5385
KL Stats: Epoch 53 Divergences: Uniform: 1.720144802025909 Unigram: 1.8066051867185342
2022-03-20 13:09:20 | INFO | fairseq.trainer | begin training epoch 54
2022-03-20 13:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 13:09:52 | INFO | train_inner | epoch 054:     84 / 157 loss=5.45, ppl=43.72, wps=32712.2, ups=1.28, wpb=25481.9, bsz=991, num_updates=8400, lr=0.000345033, gnorm=0.407, loss_scale=4, train_wall=37, gb_free=11.9, wall=5417
2022-03-20 13:10:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 13:10:23 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 13:10:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 13:10:27 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you here know.
2022-03-20 13:10:27 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 13:10:31 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-20 13:10:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 13:10:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-20 13:10:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 13:10:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 13:10:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 13:10:43 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildanimals grew up again, and that's become a basis for conservation in namibia.
2022-03-20 13:10:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 13:10:47 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, so the superconductor disorder.
2022-03-20 13:10:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 13:10:51 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that gives the big contextures of the face and the basic form, and we recover it through the information that refers the entire por-structure and all the fine folds.
2022-03-20 13:10:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 13:10:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn you to the men of your table and tell them," if the revolution begins, then we support you. "the truth, love, women is that we've already supported you about this topic for a long time. at rachel carrot with silspring."
2022-03-20 13:10:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 13:10:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we stumble on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously varied varying, and a cooling system with fluid that allows us to use an aircraft machine in the stop-go-go-go-traffic, to a particular driver, either drive the propeller, or if you fly to the ground.
2022-03-20 13:10:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 13:10:57 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 6.54 | ppl 93.02 | bleu 33.75 | wps 4850 | wpb 17862.2 | bsz 728.3 | num_updates 8473 | best_bleu 34.13
2022-03-20 13:10:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 8473 updates
2022-03-20 13:10:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 13:10:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 13:10:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 54 @ 8473 updates, score 33.75) (writing took 0.7722567929886281 seconds)
2022-03-20 13:10:57 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-20 13:10:57 | INFO | train | epoch 054 | loss 5.502 | ppl 45.31 | wps 40512.5 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 8473 | lr 0.000343543 | gnorm 0.406 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 5483
KL Stats: Epoch 54 Divergences: Uniform: 1.7203804963562708 Unigram: 1.8090302760071415
2022-03-20 13:10:58 | INFO | fairseq.trainer | begin training epoch 55
2022-03-20 13:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 13:11:08 | INFO | train_inner | epoch 055:     27 / 157 loss=5.507, ppl=45.46, wps=33041.4, ups=1.31, wpb=25284.2, bsz=1058, num_updates=8500, lr=0.000342997, gnorm=0.389, loss_scale=4, train_wall=37, gb_free=11.5, wall=5493
2022-03-20 13:11:46 | INFO | train_inner | epoch 055:    127 / 157 loss=5.492, ppl=45.01, wps=67399.9, ups=2.69, wpb=25067.6, bsz=963.8, num_updates=8600, lr=0.000340997, gnorm=0.412, loss_scale=4, train_wall=37, gb_free=12.8, wall=5531
2022-03-20 13:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 13:12:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-20 13:12:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 13:12:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you here know.
2022-03-20 13:12:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 13:12:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-20 13:12:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 13:12:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-20 13:12:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 13:12:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-20 13:12:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 13:12:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wild animals grew back up, and that's become a basis for conservation in namibia.
2022-03-20 13:12:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 13:12:24 | INFO | fairseq.tasks.translation | example hypothesis: first, there are some bundles of magnetic field captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconductor disorders.
2022-03-20 13:12:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 13:12:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refers the big contures of the face and the basic shape, and then recommends it through the information that refers all the porn structure and all the fine things.
2022-03-20 13:12:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 13:12:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that -- well, at the striking dinner, it was best summarized when someone said, "turn to the men of your table and tell them," if the revolution starts to support you. "the truth, women, we've already supported you about this topic for a long time. at rachel carrot, the future of our pristine."
2022-03-20 13:12:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 13:12:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the design work, and a big part of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to it on the ground -- all the way from a continuously variable, and a cooling system with fluid that allows us to use an aircraft in the stop-go-go traffic, to a particular driver that drives the propeller, either when you fly the soil, or when you fly to the ground, you see it to a constitutional mechanism, it's all the same way to a constitution, it's going to a constitution, it's all the wrong way to a mechanism, it's going to a constitution, it's all the ground, it's going to a constitution, it's going to a constitution, and to a constitute the mechanical system that we see it, it, it's going to a constitute
2022-03-20 13:12:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 13:12:36 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 6.516 | ppl 91.54 | bleu 34 | wps 4652.4 | wpb 17862.2 | bsz 728.3 | num_updates 8630 | best_bleu 34.13
2022-03-20 13:12:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 8630 updates
2022-03-20 13:12:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 13:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 13:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 55 @ 8630 updates, score 34.0) (writing took 0.7791158691979945 seconds)
2022-03-20 13:12:36 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-20 13:12:36 | INFO | train | epoch 055 | loss 5.487 | ppl 44.84 | wps 39943 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 8630 | lr 0.000340404 | gnorm 0.398 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 5581
KL Stats: Epoch 55 Divergences: Uniform: 1.7204098656482743 Unigram: 1.8106178509885196
2022-03-20 13:12:37 | INFO | fairseq.trainer | begin training epoch 56
2022-03-20 13:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 13:13:03 | INFO | train_inner | epoch 056:     70 / 157 loss=5.561, ppl=47.21, wps=31601.9, ups=1.29, wpb=24477.2, bsz=993.4, num_updates=8700, lr=0.000339032, gnorm=0.398, loss_scale=4, train_wall=37, gb_free=11.8, wall=5608
2022-03-20 13:13:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 13:13:39 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 13:13:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 13:13:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which i think most of you here know.
2022-03-20 13:13:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 13:13:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-20 13:13:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 13:13:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-20 13:13:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 13:13:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 13:13:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 13:13:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the face of how people took responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-20 13:13:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 13:14:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like it when they move because their movements use energy, and so the superconductor disorders.
2022-03-20 13:14:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 13:14:07 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can that refers the big constraints of the face and the basic shape, and reproduce it through the information that refers the whole por-structure and all the fine folds.
2022-03-20 13:14:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 13:14:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn to the men of your desk and say," if the revolution starts, then we support you. "the truth, women is that we've supported you in this topic for a long time. at rachson carson," with silspring. "
2022-03-20 13:14:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 13:14:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're the most proud of on our plane was a result of either pushing the unique problems that were connected to operate on the ground -- everything, from a continuously varied manner and a cooling system that allows us to use an aircraft in the stop-go-traffic, to a particular driver that drives the propeller, or when you fly the ground, to become a mechanism.
2022-03-20 13:14:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 13:14:12 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 6.532 | ppl 92.54 | bleu 33.8 | wps 4983.8 | wpb 17862.2 | bsz 728.3 | num_updates 8787 | best_bleu 34.13
2022-03-20 13:14:12 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-20 13:14:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 8787 updates
2022-03-20 13:14:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 13:14:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt
2022-03-20 13:14:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.14_0.06_0.80_#1/checkpoint_last.pt (epoch 56 @ 8787 updates, score 33.8) (writing took 0.7904139617457986 seconds)
2022-03-20 13:14:13 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-20 13:14:13 | INFO | train | epoch 056 | loss 5.476 | ppl 44.51 | wps 40818.4 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 8787 | lr 0.000337349 | gnorm 0.397 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 5678
2022-03-20 13:14:13 | INFO | fairseq_cli.train | done training in 5677.9 seconds
