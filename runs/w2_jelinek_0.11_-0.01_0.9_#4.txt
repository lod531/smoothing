Sender: LSF System <lsfadmin@eu-g2-09>
Subject: Job 202625117: <w2_jelinek_0.11_-0.01_0.9_#4> in cluster <euler> Exited

Job <w2_jelinek_0.11_-0.01_0.9_#4> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Jan 31 08:50:30 2022
Job was executed on host(s) <eu-g2-09>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Jan 31 08:50:45 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Jan 31 08:50:45 2022
Terminated at Tue Feb  1 04:51:12 2022
Results reported at Tue Feb  1 04:51:12 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.11, -0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72814.00 sec.
    Max Memory :                                 5638 MB
    Average Memory :                             3239.81 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14362.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72028 sec.
    Turnaround time :                            72042 sec.

The output (if any) follows:

2022-01-31 08:51:08 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.11, -0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-31 08:51:08 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-31 08:51:09 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1412/36718 [00:00<00:02, 14117.22it/s]  8%|▊         | 2824/36718 [00:00<00:02, 13526.19it/s] 12%|█▏        | 4363/36718 [00:00<00:02, 14356.92it/s] 16%|█▋        | 6001/36718 [00:00<00:02, 15140.92it/s] 20%|██        | 7518/36718 [00:00<00:02, 14421.34it/s] 24%|██▍       | 8968/36718 [00:00<00:01, 14153.62it/s] 28%|██▊       | 10391/36718 [00:00<00:01, 14176.85it/s] 32%|███▏      | 11812/36718 [00:00<00:01, 13962.19it/s] 36%|███▌      | 13306/36718 [00:00<00:01, 14257.46it/s] 40%|████      | 14763/36718 [00:01<00:01, 14349.62it/s] 44%|████▍     | 16200/36718 [00:01<00:01, 14142.64it/s] 48%|████▊     | 17616/36718 [00:01<00:01, 14076.53it/s] 52%|█████▏    | 19119/36718 [00:01<00:01, 14357.77it/s] 56%|█████▌    | 20557/36718 [00:01<00:01, 14300.01it/s] 60%|█████▉    | 21988/36718 [00:01<00:01, 14136.47it/s] 64%|██████▍   | 23488/36718 [00:01<00:00, 14386.78it/s] 69%|██████▊   | 25182/36718 [00:01<00:00, 15144.88it/s] 73%|███████▎  | 26699/36718 [00:01<00:00, 14555.63it/s] 77%|███████▋  | 28161/36718 [00:01<00:00, 14076.95it/s] 81%|████████  | 29591/36718 [00:02<00:00, 14133.88it/s] 84%|████████▍ | 31009/36718 [00:02<00:00, 13783.66it/s] 88%|████████▊ | 32392/36718 [00:02<00:00, 13646.69it/s] 92%|█████████▏| 33760/36718 [00:02<00:00, 13591.94it/s] 96%|█████████▌| 35224/36718 [00:02<00:00, 13890.15it/s]100%|█████████▉| 36653/36718 [00:02<00:00, 13998.77it/s]100%|██████████| 36718/36718 [00:02<00:00, 14171.04it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  7%|▋         | 2688/36718 [00:00<00:01, 26853.52it/s] 15%|█▌        | 5648/36718 [00:00<00:01, 28458.36it/s] 23%|██▎       | 8494/36718 [00:00<00:01, 27691.39it/s] 31%|███       | 11266/36718 [00:00<00:00, 27361.81it/s] 38%|███▊      | 14016/36718 [00:00<00:00, 27410.12it/s] 46%|████▌     | 16759/36718 [00:00<00:00, 27188.04it/s] 53%|█████▎    | 19633/36718 [00:00<00:00, 27685.46it/s] 61%|██████    | 22403/36718 [00:00<00:00, 27229.76it/s] 69%|██████▉   | 25518/36718 [00:00<00:00, 28426.86it/s] 77%|███████▋  | 28365/36718 [00:01<00:00, 27589.45it/s] 85%|████████▍ | 31131/36718 [00:01<00:00, 26684.13it/s] 92%|█████████▏| 33809/36718 [00:01<00:00, 26258.47it/s] 99%|█████████▉| 36464/36718 [00:01<00:00, 26332.05it/s]100%|██████████| 36718/36718 [00:01<00:00, 27090.97it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 38.94it/s]2022-01-31 08:51:31 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-31 08:51:31 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-31 08:51:31 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-31 08:51:31 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-31 08:51:31 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-31 08:51:31 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-31 08:51:31 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-31 08:51:31 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-31 08:51:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:51:31 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-31 08:51:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:51:31 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-31 08:51:31 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-31 08:51:31 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint_last.pt
2022-01-31 08:51:31 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint_last.pt
2022-01-31 08:51:31 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-31 08:51:31 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-31 08:51:31 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-31 08:51:31 | INFO | fairseq.trainer | begin training epoch 1
2022-01-31 08:51:31 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-31 08:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-31 08:57:22 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.719 | ppl 26972.1 | wps 7984.8 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-31 08:57:22 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-31 08:57:22 | INFO | train | epoch 001 | loss 16.136 | ppl 71992.6 | wps 5986.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.202 | train_wall 321 | gb_free 6.1 | wall 351
KL Stats: Epoch 1 Divergences: Uniform: 0.5171106382047024 Unigram: 3.6858789449895797
2022-01-31 08:57:22 | INFO | fairseq.trainer | begin training epoch 2
2022-01-31 08:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:00:23 | INFO | train_inner | epoch 002:     36 / 64 loss=15.602, ppl=49731.4, wps=6164.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.623, train_wall=502, gb_free=6.1, wall=532
2022-01-31 09:02:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:03:09 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.729 | ppl 13581.3 | wps 7984.8 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-31 09:03:09 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-31 09:03:09 | INFO | train | epoch 002 | loss 14.447 | ppl 22336.3 | wps 6012.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.477 | train_wall 319 | gb_free 6.1 | wall 698
KL Stats: Epoch 2 Divergences: Uniform: 0.533560633236072 Unigram: 2.4169236367086384
2022-01-31 09:03:09 | INFO | fairseq.trainer | begin training epoch 3
2022-01-31 09:03:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:08:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:08:58 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.917 | ppl 7734.78 | wps 8021.2 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-31 09:08:58 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-31 09:08:58 | INFO | train | epoch 003 | loss 13.555 | ppl 12038 | wps 5992.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.19 | train_wall 320 | gb_free 6.1 | wall 1047
KL Stats: Epoch 3 Divergences: Uniform: 0.5162869045801074 Unigram: 1.7356846949496483
2022-01-31 09:08:58 | INFO | fairseq.trainer | begin training epoch 4
2022-01-31 09:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:09:38 | INFO | train_inner | epoch 004:      8 / 64 loss=13.687, ppl=13186.1, wps=5875.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.219, train_wall=499, gb_free=6.1, wall=1087
2022-01-31 09:14:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:14:46 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.084 | ppl 4340.64 | wps 8013 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-31 09:14:46 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-31 09:14:46 | INFO | train | epoch 004 | loss 12.618 | ppl 6284.38 | wps 5997.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.947 | train_wall 320 | gb_free 6.1 | wall 1395
KL Stats: Epoch 4 Divergences: Uniform: 0.5977791940112988 Unigram: 1.1260147594738896
2022-01-31 09:14:46 | INFO | fairseq.trainer | begin training epoch 5
2022-01-31 09:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:18:27 | INFO | train_inner | epoch 005:     44 / 64 loss=12.274, ppl=4951.8, wps=6173, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.834, train_wall=501, gb_free=6.1, wall=1616
2022-01-31 09:20:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:20:34 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.571 | ppl 3042.87 | wps 8036.5 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-31 09:20:34 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-31 09:20:34 | INFO | train | epoch 005 | loss 11.834 | ppl 3651.25 | wps 5998.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.681 | train_wall 320 | gb_free 6.1 | wall 1743
KL Stats: Epoch 5 Divergences: Uniform: 0.8302719691463222 Unigram: 0.6766878780237157
2022-01-31 09:20:34 | INFO | fairseq.trainer | begin training epoch 6
2022-01-31 09:20:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:25:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:26:22 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.325 | ppl 2565.28 | wps 7998.3 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-31 09:26:22 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-31 09:26:22 | INFO | train | epoch 006 | loss 11.408 | ppl 2718.18 | wps 6002.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.581 | train_wall 320 | gb_free 6.1 | wall 2091
KL Stats: Epoch 6 Divergences: Uniform: 1.1180389069262155 Unigram: 0.4816152227226491
2022-01-31 09:26:22 | INFO | fairseq.trainer | begin training epoch 7
2022-01-31 09:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:27:43 | INFO | train_inner | epoch 007:     16 / 64 loss=11.431, ppl=2760.11, wps=5871, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.579, train_wall=499, gb_free=6.1, wall=2172
2022-01-31 09:31:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:32:10 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.179 | ppl 2318.3 | wps 8031.1 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-31 09:32:10 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-31 09:32:10 | INFO | train | epoch 007 | loss 11.209 | ppl 2366.67 | wps 6001.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.523 | train_wall 320 | gb_free 6.1 | wall 2439
KL Stats: Epoch 7 Divergences: Uniform: 1.3326223716701977 Unigram: 0.4965568794391444
2022-01-31 09:32:10 | INFO | fairseq.trainer | begin training epoch 8
2022-01-31 09:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:36:32 | INFO | train_inner | epoch 008:     52 / 64 loss=11.147, ppl=2267.25, wps=6172.2, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=501, gb_free=6.1, wall=2701
2022-01-31 09:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:37:59 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.072 | ppl 2152.22 | wps 8003.1 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-31 09:37:59 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-31 09:37:59 | INFO | train | epoch 008 | loss 11.094 | ppl 2186.43 | wps 5990.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 320 | gb_free 6.1 | wall 2788
KL Stats: Epoch 8 Divergences: Uniform: 1.441088107761361 Unigram: 0.5781758444816125
2022-01-31 09:37:59 | INFO | fairseq.trainer | begin training epoch 9
2022-01-31 09:37:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:43:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:43:47 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.953 | ppl 1981.77 | wps 8185.8 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-31 09:43:47 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-31 09:43:47 | INFO | train | epoch 009 | loss 10.986 | ppl 2027.84 | wps 6003.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 320 | gb_free 6.1 | wall 3135
KL Stats: Epoch 9 Divergences: Uniform: 1.48232923694785 Unigram: 0.6909154184225449
2022-01-31 09:43:47 | INFO | fairseq.trainer | begin training epoch 10
2022-01-31 09:43:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:45:47 | INFO | train_inner | epoch 010:     24 / 64 loss=10.976, ppl=2014.52, wps=5870.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.487, train_wall=500, gb_free=6.1, wall=3256
2022-01-31 09:49:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:49:35 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.845 | ppl 1839.79 | wps 8021.6 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-31 09:49:35 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-31 09:49:35 | INFO | train | epoch 010 | loss 10.873 | ppl 1875.96 | wps 5993.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.483 | train_wall 320 | gb_free 6.1 | wall 3484
KL Stats: Epoch 10 Divergences: Uniform: 1.5051192626707617 Unigram: 0.815548152644212
2022-01-31 09:49:35 | INFO | fairseq.trainer | begin training epoch 11
2022-01-31 09:49:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:54:37 | INFO | train_inner | epoch 011:     60 / 64 loss=10.796, ppl=1777.34, wps=6166.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=501, gb_free=6.1, wall=3786
2022-01-31 09:54:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:55:24 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.736 | ppl 1705.87 | wps 7991.4 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-31 09:55:24 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-31 09:55:24 | INFO | train | epoch 011 | loss 10.755 | ppl 1727.8 | wps 5990.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.498 | train_wall 320 | gb_free 6.1 | wall 3833
KL Stats: Epoch 11 Divergences: Uniform: 1.5223130737470618 Unigram: 0.9408259592847829
2022-01-31 09:55:24 | INFO | fairseq.trainer | begin training epoch 12
2022-01-31 09:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:01:12 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.625 | ppl 1579.34 | wps 8001.8 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-31 10:01:12 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-31 10:01:12 | INFO | train | epoch 012 | loss 10.636 | ppl 1591.2 | wps 5995.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.482 | train_wall 320 | gb_free 6.1 | wall 4181
KL Stats: Epoch 12 Divergences: Uniform: 1.5328654112733315 Unigram: 1.0622536844536299
2022-01-31 10:01:12 | INFO | fairseq.trainer | begin training epoch 13
2022-01-31 10:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:03:53 | INFO | train_inner | epoch 013:     32 / 64 loss=10.612, ppl=1564.61, wps=5865.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.496, train_wall=500, gb_free=6.1, wall=4342
2022-01-31 10:06:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:06:59 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.535 | ppl 1483.58 | wps 8040.4 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-31 10:06:59 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-31 10:06:59 | INFO | train | epoch 013 | loss 10.52 | ppl 1468.57 | wps 6011.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 319 | gb_free 6.1 | wall 4528
KL Stats: Epoch 13 Divergences: Uniform: 1.557062515511917 Unigram: 1.1693127984424936
2022-01-31 10:06:59 | INFO | fairseq.trainer | begin training epoch 14
2022-01-31 10:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:12:48 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.439 | ppl 1388.02 | wps 7999.4 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-31 10:12:48 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-31 10:12:48 | INFO | train | epoch 014 | loss 10.409 | ppl 1359.25 | wps 5994.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.56 | train_wall 320 | gb_free 6.1 | wall 4877
KL Stats: Epoch 14 Divergences: Uniform: 1.5836099849189593 Unigram: 1.2676935243543073
2022-01-31 10:12:48 | INFO | fairseq.trainer | begin training epoch 15
2022-01-31 10:12:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:13:08 | INFO | train_inner | epoch 015:      4 / 64 loss=10.431, ppl=1380.83, wps=5874.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.538, train_wall=499, gb_free=6.1, wall=4897
2022-01-31 10:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:18:37 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.369 | ppl 1322.21 | wps 7983.5 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-31 10:18:37 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-31 10:18:37 | INFO | train | epoch 015 | loss 10.296 | ppl 1257.56 | wps 5983.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.541 | train_wall 321 | gb_free 6.1 | wall 5226
KL Stats: Epoch 15 Divergences: Uniform: 1.604885217723347 Unigram: 1.3585080924798159
2022-01-31 10:18:37 | INFO | fairseq.trainer | begin training epoch 16
2022-01-31 10:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:21:59 | INFO | train_inner | epoch 016:     40 / 64 loss=10.255, ppl=1221.97, wps=6161.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.56, train_wall=502, gb_free=6.1, wall=5428
2022-01-31 10:23:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:24:26 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.289 | ppl 1250.83 | wps 8005.2 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-31 10:24:26 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-31 10:24:26 | INFO | train | epoch 016 | loss 10.19 | ppl 1167.96 | wps 5990.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.557 | train_wall 320 | gb_free 6.1 | wall 5575
KL Stats: Epoch 16 Divergences: Uniform: 1.6324820278276087 Unigram: 1.4446118608136946
2022-01-31 10:24:26 | INFO | fairseq.trainer | begin training epoch 17
2022-01-31 10:24:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:29:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:30:14 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.194 | ppl 1171.03 | wps 8000.7 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-31 10:30:14 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-31 10:30:14 | INFO | train | epoch 017 | loss 10.083 | ppl 1084.72 | wps 5995.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.548 | train_wall 320 | gb_free 6.1 | wall 5923
KL Stats: Epoch 17 Divergences: Uniform: 1.666492520836899 Unigram: 1.5197929693654648
2022-01-31 10:30:14 | INFO | fairseq.trainer | begin training epoch 18
2022-01-31 10:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:31:15 | INFO | train_inner | epoch 018:     12 / 64 loss=10.097, ppl=1095.43, wps=5863, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.551, train_wall=500, gb_free=6.1, wall=5984
2022-01-31 10:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:36:03 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.134 | ppl 1123.53 | wps 8016.4 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-31 10:36:03 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-31 10:36:03 | INFO | train | epoch 018 | loss 9.983 | ppl 1011.78 | wps 5984.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.569 | train_wall 321 | gb_free 6.1 | wall 6272
KL Stats: Epoch 18 Divergences: Uniform: 1.6990609249431612 Unigram: 1.594492043593805
2022-01-31 10:36:03 | INFO | fairseq.trainer | begin training epoch 19
2022-01-31 10:36:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:40:05 | INFO | train_inner | epoch 019:     48 / 64 loss=9.933, ppl=977.65, wps=6156.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.54, train_wall=502, gb_free=6.1, wall=6514
2022-01-31 10:41:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:41:52 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.057 | ppl 1065.24 | wps 8000 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-31 10:41:52 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-31 10:41:52 | INFO | train | epoch 019 | loss 9.879 | ppl 941.9 | wps 5980.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 321 | gb_free 6.1 | wall 6621
KL Stats: Epoch 19 Divergences: Uniform: 1.7271330018494322 Unigram: 1.6682365866592075
2022-01-31 10:41:52 | INFO | fairseq.trainer | begin training epoch 20
2022-01-31 10:41:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:47:40 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.973 | ppl 1004.87 | wps 8157.1 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-31 10:47:40 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-31 10:47:40 | INFO | train | epoch 020 | loss 9.783 | ppl 880.93 | wps 6010.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.548 | train_wall 320 | gb_free 6.1 | wall 6969
KL Stats: Epoch 20 Divergences: Uniform: 1.7575968569032996 Unigram: 1.7355260210888046
2022-01-31 10:47:40 | INFO | fairseq.trainer | begin training epoch 21
2022-01-31 10:47:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:49:21 | INFO | train_inner | epoch 021:     20 / 64 loss=9.778, ppl=877.87, wps=5869.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.545, train_wall=500, gb_free=6.1, wall=7070
2022-01-31 10:53:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:53:28 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.931 | ppl 976.06 | wps 8008.6 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-31 10:53:28 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-31 10:53:28 | INFO | train | epoch 021 | loss 9.689 | ppl 825.32 | wps 5987.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.53 | train_wall 321 | gb_free 6.1 | wall 7317
KL Stats: Epoch 21 Divergences: Uniform: 1.7872851899185553 Unigram: 1.8023461702925017
2022-01-31 10:53:28 | INFO | fairseq.trainer | begin training epoch 22
2022-01-31 10:53:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:58:11 | INFO | train_inner | epoch 022:     56 / 64 loss=9.636, ppl=795.86, wps=6164.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.541, train_wall=502, gb_free=6.1, wall=7600
2022-01-31 10:58:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:59:17 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.867 | ppl 933.84 | wps 8010.3 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-31 10:59:17 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-31 10:59:17 | INFO | train | epoch 022 | loss 9.6 | ppl 775.94 | wps 5984.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.55 | train_wall 321 | gb_free 6.1 | wall 7666
KL Stats: Epoch 22 Divergences: Uniform: 1.8113941170615828 Unigram: 1.8674924177854684
2022-01-31 10:59:17 | INFO | fairseq.trainer | begin training epoch 23
2022-01-31 10:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:04:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:05:06 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.803 | ppl 893.61 | wps 8013.2 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-31 11:05:06 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-31 11:05:06 | INFO | train | epoch 023 | loss 9.513 | ppl 730.66 | wps 5985.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.516 | train_wall 321 | gb_free 6.1 | wall 8015
KL Stats: Epoch 23 Divergences: Uniform: 1.839375828670175 Unigram: 1.9252475437142296
2022-01-31 11:05:06 | INFO | fairseq.trainer | begin training epoch 24
2022-01-31 11:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:07:28 | INFO | train_inner | epoch 024:     28 / 64 loss=9.498, ppl=723.12, wps=5855.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.531, train_wall=501, gb_free=6.1, wall=8157
2022-01-31 11:10:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:10:55 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.745 | ppl 857.85 | wps 7980.8 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-31 11:10:55 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-31 11:10:55 | INFO | train | epoch 024 | loss 9.43 | ppl 689.88 | wps 5995.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.564 | train_wall 320 | gb_free 6.1 | wall 8364
KL Stats: Epoch 24 Divergences: Uniform: 1.8600812712828954 Unigram: 1.978621486976207
2022-01-31 11:10:55 | INFO | fairseq.trainer | begin training epoch 25
2022-01-31 11:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:16:16 | INFO | train_inner | epoch 025:     64 / 64 loss=9.376, ppl=664.63, wps=6165.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.545, train_wall=500, gb_free=6.1, wall=8685
2022-01-31 11:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:16:44 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.715 | ppl 840.18 | wps 7989.2 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-31 11:16:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-31 11:16:44 | INFO | train | epoch 025 | loss 9.349 | ppl 651.95 | wps 5986.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.53 | train_wall 321 | gb_free 6.1 | wall 8713
KL Stats: Epoch 25 Divergences: Uniform: 1.88861118038125 Unigram: 2.0342098927952903
2022-01-31 11:16:44 | INFO | fairseq.trainer | begin training epoch 26
2022-01-31 11:16:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:22:32 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.664 | ppl 811.31 | wps 8025.1 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-31 11:22:32 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-31 11:22:32 | INFO | train | epoch 026 | loss 9.268 | ppl 616.35 | wps 5990 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.545 | train_wall 321 | gb_free 6.1 | wall 9061
KL Stats: Epoch 26 Divergences: Uniform: 1.9008871858722096 Unigram: 2.0835399930338516
2022-01-31 11:22:32 | INFO | fairseq.trainer | begin training epoch 27
2022-01-31 11:22:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:25:34 | INFO | train_inner | epoch 027:     36 / 64 loss=9.24, ppl=604.67, wps=5862, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.54, train_wall=502, gb_free=6.1, wall=9243
2022-01-31 11:27:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:28:21 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.631 | ppl 792.98 | wps 7994.6 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-31 11:28:21 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-31 11:28:21 | INFO | train | epoch 027 | loss 9.188 | ppl 583.25 | wps 5988.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.533 | train_wall 321 | gb_free 6.1 | wall 9410
KL Stats: Epoch 27 Divergences: Uniform: 1.9268720136236943 Unigram: 2.1285420285295604
2022-01-31 11:28:21 | INFO | fairseq.trainer | begin training epoch 28
2022-01-31 11:28:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:33:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:34:10 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.604 | ppl 778.42 | wps 7979.4 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-31 11:34:10 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-31 11:34:10 | INFO | train | epoch 028 | loss 9.11 | ppl 552.5 | wps 5992.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.527 | train_wall 320 | gb_free 6.1 | wall 9759
KL Stats: Epoch 28 Divergences: Uniform: 1.9558787386098861 Unigram: 2.1766612490600235
2022-01-31 11:34:10 | INFO | fairseq.trainer | begin training epoch 29
2022-01-31 11:34:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:34:50 | INFO | train_inner | epoch 029:      8 / 64 loss=9.125, ppl=558.51, wps=5860.3, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.532, train_wall=500, gb_free=6.1, wall=9799
2022-01-31 11:39:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:39:58 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.567 | ppl 758.66 | wps 7984.8 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-31 11:39:58 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-31 11:39:58 | INFO | train | epoch 029 | loss 9.031 | ppl 523.09 | wps 5992.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.525 | train_wall 320 | gb_free 6.1 | wall 10107
KL Stats: Epoch 29 Divergences: Uniform: 1.9760192409918353 Unigram: 2.2196457963808873
2022-01-31 11:39:58 | INFO | fairseq.trainer | begin training epoch 30
2022-01-31 11:39:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:43:40 | INFO | train_inner | epoch 030:     44 / 64 loss=8.998, ppl=511.29, wps=6165.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.516, train_wall=501, gb_free=6.1, wall=10329
2022-01-31 11:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:45:47 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.544 | ppl 746.67 | wps 7996.3 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-31 11:45:47 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-31 11:45:47 | INFO | train | epoch 030 | loss 8.954 | ppl 495.79 | wps 5988.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.523 | train_wall 321 | gb_free 6.1 | wall 10456
KL Stats: Epoch 30 Divergences: Uniform: 1.993195625183268 Unigram: 2.2669259936768267
2022-01-31 11:45:47 | INFO | fairseq.trainer | begin training epoch 31
2022-01-31 11:45:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:51:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:51:35 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.494 | ppl 720.96 | wps 7959.8 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-31 11:51:35 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-31 11:51:35 | INFO | train | epoch 031 | loss 8.874 | ppl 469.22 | wps 6002.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.5 | train_wall 320 | gb_free 6.1 | wall 10804
KL Stats: Epoch 31 Divergences: Uniform: 2.0115572472863126 Unigram: 2.3072716586599338
2022-01-31 11:51:35 | INFO | fairseq.trainer | begin training epoch 32
2022-01-31 11:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:52:56 | INFO | train_inner | epoch 032:     16 / 64 loss=8.875, ppl=469.65, wps=5863.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.508, train_wall=500, gb_free=6.1, wall=10885
2022-01-31 11:56:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:57:24 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.46 | ppl 704.15 | wps 8004.4 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-31 11:57:24 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-31 11:57:24 | INFO | train | epoch 032 | loss 8.801 | ppl 445.89 | wps 5978.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.512 | train_wall 321 | gb_free 6.1 | wall 11153
KL Stats: Epoch 32 Divergences: Uniform: 2.039364226489823 Unigram: 2.349113817485872
2022-01-31 11:57:24 | INFO | fairseq.trainer | begin training epoch 33
2022-01-31 11:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:01:47 | INFO | train_inner | epoch 033:     52 / 64 loss=8.764, ppl=434.62, wps=6160.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.515, train_wall=502, gb_free=6.1, wall=11416
2022-01-31 12:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:03:13 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.444 | ppl 696.27 | wps 7987.7 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-31 12:03:13 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-31 12:03:13 | INFO | train | epoch 033 | loss 8.726 | ppl 423.47 | wps 5984.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.514 | train_wall 321 | gb_free 6.1 | wall 11502
KL Stats: Epoch 33 Divergences: Uniform: 2.0618618398150814 Unigram: 2.397358807785163
2022-01-31 12:03:13 | INFO | fairseq.trainer | begin training epoch 34
2022-01-31 12:03:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:08:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:09:02 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.424 | ppl 686.89 | wps 8011.3 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-31 12:09:02 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-31 12:09:02 | INFO | train | epoch 034 | loss 8.65 | ppl 401.83 | wps 5986.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.516 | train_wall 321 | gb_free 6.1 | wall 11851
KL Stats: Epoch 34 Divergences: Uniform: 2.082294738509631 Unigram: 2.4387711432051034
2022-01-31 12:09:02 | INFO | fairseq.trainer | begin training epoch 35
2022-01-31 12:09:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:11:03 | INFO | train_inner | epoch 035:     24 / 64 loss=8.638, ppl=398.25, wps=5854.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.515, train_wall=501, gb_free=6.1, wall=11972
2022-01-31 12:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:14:51 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.396 | ppl 673.88 | wps 8009.2 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-31 12:14:51 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-31 12:14:51 | INFO | train | epoch 035 | loss 8.578 | ppl 382.13 | wps 5988.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.509 | train_wall 321 | gb_free 6.1 | wall 12200
KL Stats: Epoch 35 Divergences: Uniform: 2.103809158483506 Unigram: 2.475979529853614
2022-01-31 12:14:51 | INFO | fairseq.trainer | begin training epoch 36
2022-01-31 12:14:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:19:54 | INFO | train_inner | epoch 036:     60 / 64 loss=8.534, ppl=370.75, wps=6162.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.51, train_wall=502, gb_free=6.1, wall=12503
2022-01-31 12:20:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:20:40 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.37 | ppl 661.76 | wps 7997.9 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-31 12:20:40 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-31 12:20:40 | INFO | train | epoch 036 | loss 8.505 | ppl 363.21 | wps 5983.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.51 | train_wall 321 | gb_free 6.1 | wall 12549
KL Stats: Epoch 36 Divergences: Uniform: 2.1246713908365233 Unigram: 2.5216195951606557
2022-01-31 12:20:40 | INFO | fairseq.trainer | begin training epoch 37
2022-01-31 12:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:26:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:26:29 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.39 | ppl 670.9 | wps 8012.9 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-31 12:26:29 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-31 12:26:29 | INFO | train | epoch 037 | loss 8.435 | ppl 346.1 | wps 5987.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.513 | train_wall 321 | gb_free 6.1 | wall 12898
KL Stats: Epoch 37 Divergences: Uniform: 2.1425923121224177 Unigram: 2.564022273420494
2022-01-31 12:26:29 | INFO | fairseq.trainer | begin training epoch 38
2022-01-31 12:26:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:29:10 | INFO | train_inner | epoch 038:     32 / 64 loss=8.414, ppl=341.01, wps=5856.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.511, train_wall=501, gb_free=6.1, wall=13059
2022-01-31 12:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:32:18 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.369 | ppl 661.03 | wps 8010.4 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-31 12:32:18 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-31 12:32:18 | INFO | train | epoch 038 | loss 8.367 | ppl 330.06 | wps 5986 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.512 | train_wall 321 | gb_free 6.1 | wall 13247
KL Stats: Epoch 38 Divergences: Uniform: 2.171568709799728 Unigram: 2.5955388278258518
2022-01-31 12:32:18 | INFO | fairseq.trainer | begin training epoch 39
2022-01-31 12:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:38:06 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.347 | ppl 651.15 | wps 7992.8 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-31 12:38:06 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-31 12:38:06 | INFO | train | epoch 039 | loss 8.298 | ppl 314.65 | wps 6002.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.504 | train_wall 320 | gb_free 6.1 | wall 13595
KL Stats: Epoch 39 Divergences: Uniform: 2.1804200416663146 Unigram: 2.640163408085552
2022-01-31 12:38:06 | INFO | fairseq.trainer | begin training epoch 40
2022-01-31 12:38:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:38:26 | INFO | train_inner | epoch 040:      4 / 64 loss=8.319, ppl=319.43, wps=5867.4, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.508, train_wall=499, gb_free=6.1, wall=13615
2022-01-31 12:43:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:43:54 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.326 | ppl 641.68 | wps 8035 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-31 12:43:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-31 12:43:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint40.pt
2022-01-31 12:43:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint40.pt
2022-01-31 12:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.326) (writing took 5.329638067632914 seconds)
2022-01-31 12:43:59 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-31 12:43:59 | INFO | train | epoch 040 | loss 8.229 | ppl 300.03 | wps 5908.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.508 | train_wall 320 | gb_free 6.1 | wall 13948
KL Stats: Epoch 40 Divergences: Uniform: 2.2076651354763066 Unigram: 2.67738658187128
2022-01-31 12:43:59 | INFO | fairseq.trainer | begin training epoch 41
2022-01-31 12:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:47:21 | INFO | train_inner | epoch 041:     40 / 64 loss=8.205, ppl=295.15, wps=6107.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.506, train_wall=501, gb_free=6.1, wall=14150
2022-01-31 12:49:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:49:48 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.317 | ppl 637.77 | wps 7999.8 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.317
2022-01-31 12:49:48 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-31 12:49:48 | INFO | train | epoch 041 | loss 8.165 | ppl 286.96 | wps 5987.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.505 | train_wall 321 | gb_free 6.1 | wall 14297
KL Stats: Epoch 41 Divergences: Uniform: 2.221443738611444 Unigram: 2.712206682521822
2022-01-31 12:49:48 | INFO | fairseq.trainer | begin training epoch 42
2022-01-31 12:49:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:55:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:55:36 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.294 | ppl 627.71 | wps 7966.9 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.294
2022-01-31 12:55:36 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-31 12:55:36 | INFO | train | epoch 042 | loss 8.101 | ppl 274.49 | wps 6007.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.515 | train_wall 319 | gb_free 6.1 | wall 14645
KL Stats: Epoch 42 Divergences: Uniform: 2.237935346230051 Unigram: 2.7540435213223597
2022-01-31 12:55:36 | INFO | fairseq.trainer | begin training epoch 43
2022-01-31 12:55:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:56:36 | INFO | train_inner | epoch 043:     12 / 64 loss=8.107, ppl=275.71, wps=5870, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.514, train_wall=499, gb_free=6.1, wall=14705
2022-01-31 13:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:01:24 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.327 | ppl 642.05 | wps 8020 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.326
2022-01-31 13:01:24 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-31 13:01:24 | INFO | train | epoch 043 | loss 8.036 | ppl 262.4 | wps 5994.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.507 | train_wall 320 | gb_free 6.1 | wall 14993
KL Stats: Epoch 43 Divergences: Uniform: 2.261333200701914 Unigram: 2.7913128920147487
2022-01-31 13:01:24 | INFO | fairseq.trainer | begin training epoch 44
2022-01-31 13:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:05:26 | INFO | train_inner | epoch 044:     48 / 64 loss=8.002, ppl=256.33, wps=6167.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.513, train_wall=501, gb_free=6.1, wall=15235
2022-01-31 13:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:07:13 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.34 | ppl 648.11 | wps 7981.7 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.326
2022-01-31 13:07:13 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-31 13:07:13 | INFO | train | epoch 044 | loss 7.976 | ppl 251.79 | wps 5985.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.513 | train_wall 321 | gb_free 6.1 | wall 15342
KL Stats: Epoch 44 Divergences: Uniform: 2.2775280908431363 Unigram: 2.826799115233034
2022-01-31 13:07:13 | INFO | fairseq.trainer | begin training epoch 45
2022-01-31 13:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:13:02 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.316 | ppl 637.33 | wps 8002.6 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.316
2022-01-31 13:13:02 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-31 13:13:02 | INFO | train | epoch 045 | loss 7.913 | ppl 241.04 | wps 5991.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.515 | train_wall 320 | gb_free 6.1 | wall 15691
KL Stats: Epoch 45 Divergences: Uniform: 2.294562090570219 Unigram: 2.869581372061677
2022-01-31 13:13:02 | INFO | fairseq.trainer | begin training epoch 46
2022-01-31 13:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:14:42 | INFO | train_inner | epoch 046:     20 / 64 loss=7.913, ppl=240.97, wps=5862, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.514, train_wall=500, gb_free=6.1, wall=15791
2022-01-31 13:18:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:18:49 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.313 | ppl 635.98 | wps 8007.8 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.313
2022-01-31 13:18:49 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-31 13:18:49 | INFO | train | epoch 046 | loss 7.854 | ppl 231.41 | wps 6010 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.523 | train_wall 319 | gb_free 6.1 | wall 16038
KL Stats: Epoch 46 Divergences: Uniform: 2.3092151561208794 Unigram: 2.894159442310697
2022-01-31 13:18:49 | INFO | fairseq.trainer | begin training epoch 47
2022-01-31 13:18:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:23:32 | INFO | train_inner | epoch 047:     56 / 64 loss=7.823, ppl=226.49, wps=6170.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.51, train_wall=501, gb_free=6.1, wall=16321
2022-01-31 13:24:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:24:38 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.302 | ppl 631.18 | wps 8024.8 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.302
2022-01-31 13:24:38 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-31 13:24:38 | INFO | train | epoch 047 | loss 7.796 | ppl 222.18 | wps 5980.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.506 | train_wall 321 | gb_free 6.1 | wall 16387
KL Stats: Epoch 47 Divergences: Uniform: 2.3318123438598524 Unigram: 2.925511145136698
2022-01-31 13:24:38 | INFO | fairseq.trainer | begin training epoch 48
2022-01-31 13:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:29:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:30:27 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.294 | ppl 627.78 | wps 8038.7 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.294
2022-01-31 13:30:27 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-31 13:30:27 | INFO | train | epoch 048 | loss 7.739 | ppl 213.6 | wps 5999.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.518 | train_wall 320 | gb_free 6.1 | wall 16736
KL Stats: Epoch 48 Divergences: Uniform: 2.347705015858914 Unigram: 2.963357710594926
2022-01-31 13:30:27 | INFO | fairseq.trainer | begin training epoch 49
2022-01-31 13:30:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:32:48 | INFO | train_inner | epoch 049:     28 / 64 loss=7.721, ppl=211.01, wps=5866.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.517, train_wall=500, gb_free=6.1, wall=16877
2022-01-31 13:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:36:15 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.333 | ppl 645.13 | wps 8175.8 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.326
2022-01-31 13:36:15 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-31 13:36:15 | INFO | train | epoch 049 | loss 7.682 | ppl 205.3 | wps 5999.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.518 | train_wall 320 | gb_free 6.1 | wall 17084
KL Stats: Epoch 49 Divergences: Uniform: 2.3515043399411204 Unigram: 2.9950348147804133
2022-01-31 13:36:15 | INFO | fairseq.trainer | begin training epoch 50
2022-01-31 13:36:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:41:35 | INFO | train_inner | epoch 050:     64 / 64 loss=7.657, ppl=201.84, wps=6178.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.529, train_wall=500, gb_free=6.1, wall=17404
2022-01-31 13:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:42:03 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.347 | ppl 651.01 | wps 8030.6 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.326
2022-01-31 13:42:03 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-31 13:42:03 | INFO | train | epoch 050 | loss 7.63 | ppl 198.14 | wps 6003.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.534 | train_wall 320 | gb_free 6.1 | wall 17432
KL Stats: Epoch 50 Divergences: Uniform: 2.3674361136453816 Unigram: 3.0203142879382803
2022-01-31 13:42:03 | INFO | fairseq.trainer | begin training epoch 51
2022-01-31 13:42:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:47:51 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.355 | ppl 654.97 | wps 8015.4 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.326
2022-01-31 13:47:51 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-31 13:47:51 | INFO | train | epoch 051 | loss 7.574 | ppl 190.59 | wps 5997.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.519 | train_wall 320 | gb_free 6.1 | wall 17780
KL Stats: Epoch 51 Divergences: Uniform: 2.394050767778345 Unigram: 3.0478396800905134
2022-01-31 13:47:51 | INFO | fairseq.trainer | begin training epoch 52
2022-01-31 13:47:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:50:52 | INFO | train_inner | epoch 052:     36 / 64 loss=7.55, ppl=187.46, wps=5868.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.52, train_wall=501, gb_free=6.1, wall=17961
2022-01-31 13:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:53:39 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.344 | ppl 650.08 | wps 7999.8 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.326
2022-01-31 13:53:39 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-31 13:53:39 | INFO | train | epoch 052 | loss 7.522 | ppl 183.8 | wps 5991.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.525 | train_wall 320 | gb_free 6.1 | wall 18128
KL Stats: Epoch 52 Divergences: Uniform: 2.407123674882871 Unigram: 3.0920985578908637
2022-01-31 13:53:39 | INFO | fairseq.trainer | begin training epoch 53
2022-01-31 13:53:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:59:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:59:27 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.331 | ppl 644.16 | wps 7986.1 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.326
2022-01-31 13:59:27 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-31 13:59:27 | INFO | train | epoch 053 | loss 7.471 | ppl 177.37 | wps 6010.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.518 | train_wall 319 | gb_free 6.1 | wall 18476
KL Stats: Epoch 53 Divergences: Uniform: 2.4222252122360075 Unigram: 3.1153657475525254
2022-01-31 13:59:27 | INFO | fairseq.trainer | begin training epoch 54
2022-01-31 13:59:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:00:07 | INFO | train_inner | epoch 054:      8 / 64 loss=7.483, ppl=178.96, wps=5874.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.525, train_wall=499, gb_free=6.1, wall=18516
2022-01-31 14:04:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:05:15 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.364 | ppl 658.91 | wps 8004.8 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.326
2022-01-31 14:05:15 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-31 14:05:15 | INFO | train | epoch 054 | loss 7.42 | ppl 171.3 | wps 5991.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.526 | train_wall 320 | gb_free 6.1 | wall 18824
KL Stats: Epoch 54 Divergences: Uniform: 2.431386707625916 Unigram: 3.1426068885666076
2022-01-31 14:05:16 | INFO | fairseq.trainer | begin training epoch 55
2022-01-31 14:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:08:57 | INFO | train_inner | epoch 055:     44 / 64 loss=7.393, ppl=168.11, wps=6167.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.527, train_wall=501, gb_free=6.1, wall=19046
2022-01-31 14:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:11:04 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.382 | ppl 667.26 | wps 8006.2 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.326
2022-01-31 14:11:04 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-31 14:11:04 | INFO | train | epoch 055 | loss 7.374 | ppl 165.85 | wps 5994.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.54 | train_wall 320 | gb_free 6.1 | wall 19173
KL Stats: Epoch 55 Divergences: Uniform: 2.4412968343911676 Unigram: 3.177885878313609
2022-01-31 14:11:04 | INFO | fairseq.trainer | begin training epoch 56
2022-01-31 14:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:16:53 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.465 | ppl 706.55 | wps 8001.7 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.326
2022-01-31 14:16:53 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-31 14:16:53 | INFO | train | epoch 056 | loss 7.324 | ppl 160.22 | wps 5986.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.529 | train_wall 321 | gb_free 6.1 | wall 19522
KL Stats: Epoch 56 Divergences: Uniform: 2.4449243932843365 Unigram: 3.1982874194093136
2022-01-31 14:16:53 | INFO | fairseq.trainer | begin training epoch 57
2022-01-31 14:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:18:13 | INFO | train_inner | epoch 057:     16 / 64 loss=7.328, ppl=160.69, wps=5859.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.537, train_wall=500, gb_free=6.1, wall=19602
2022-01-31 14:22:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:22:41 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.471 | ppl 709.45 | wps 7992.2 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.326
2022-01-31 14:22:41 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-31 14:22:41 | INFO | train | epoch 057 | loss 7.277 | ppl 155.09 | wps 5994.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.541 | train_wall 320 | gb_free 6.1 | wall 19870
KL Stats: Epoch 57 Divergences: Uniform: 2.4738395278632668 Unigram: 3.235402570953911
2022-01-31 14:22:41 | INFO | fairseq.trainer | begin training epoch 58
2022-01-31 14:22:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:27:04 | INFO | train_inner | epoch 058:     52 / 64 loss=7.252, ppl=152.45, wps=6159.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.536, train_wall=502, gb_free=6.1, wall=20133
2022-01-31 14:28:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:28:31 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.49 | ppl 719.27 | wps 8024.8 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.326
2022-01-31 14:28:31 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-31 14:28:31 | INFO | train | epoch 058 | loss 7.232 | ppl 150.32 | wps 5977.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.539 | train_wall 321 | gb_free 6.1 | wall 20220
KL Stats: Epoch 58 Divergences: Uniform: 2.482570292629034 Unigram: 3.261137688260474
2022-01-31 14:28:31 | INFO | fairseq.trainer | begin training epoch 59
2022-01-31 14:28:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:34:20 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.54 | ppl 744.53 | wps 7989.6 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.326
2022-01-31 14:34:20 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-31 14:34:20 | INFO | train | epoch 059 | loss 7.186 | ppl 145.64 | wps 5985.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.538 | train_wall 321 | gb_free 6.1 | wall 20569
KL Stats: Epoch 59 Divergences: Uniform: 2.4963397731052948 Unigram: 3.288185482177531
2022-01-31 14:34:20 | INFO | fairseq.trainer | begin training epoch 60
2022-01-31 14:34:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:36:21 | INFO | train_inner | epoch 060:     24 / 64 loss=7.18, ppl=145.01, wps=5858.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.541, train_wall=500, gb_free=6.1, wall=20689
2022-01-31 14:39:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:40:07 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.494 | ppl 720.97 | wps 8191 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.326
2022-01-31 14:40:07 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-31 14:40:07 | INFO | train | epoch 060 | loss 7.141 | ppl 141.18 | wps 6011.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.55 | train_wall 320 | gb_free 6.1 | wall 20916
KL Stats: Epoch 60 Divergences: Uniform: 2.5131464301878434 Unigram: 3.3220301948543978
2022-01-31 14:40:07 | INFO | fairseq.trainer | begin training epoch 61
2022-01-31 14:40:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:45:10 | INFO | train_inner | epoch 061:     60 / 64 loss=7.122, ppl=139.32, wps=6176.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.552, train_wall=501, gb_free=6.1, wall=21219
2022-01-31 14:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:45:56 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.549 | ppl 748.88 | wps 8027 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.326
2022-01-31 14:45:56 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-31 14:45:56 | INFO | train | epoch 061 | loss 7.099 | ppl 137.1 | wps 5987.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.553 | train_wall 321 | gb_free 6.1 | wall 21265
KL Stats: Epoch 61 Divergences: Uniform: 2.525891462538542 Unigram: 3.3346169889105512
2022-01-31 14:45:56 | INFO | fairseq.trainer | begin training epoch 62
2022-01-31 14:45:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:51:44 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.514 | ppl 731.26 | wps 7996.4 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.326
2022-01-31 14:51:44 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-31 14:51:44 | INFO | train | epoch 062 | loss 7.058 | ppl 133.27 | wps 5994 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.557 | train_wall 320 | gb_free 6.1 | wall 21613
KL Stats: Epoch 62 Divergences: Uniform: 2.528594754930607 Unigram: 3.373237554412178
2022-01-31 14:51:44 | INFO | fairseq.trainer | begin training epoch 63
2022-01-31 14:51:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:54:26 | INFO | train_inner | epoch 063:     32 / 64 loss=7.032, ppl=130.88, wps=5858.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.554, train_wall=500, gb_free=6.1, wall=21775
2022-01-31 14:57:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:57:34 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.547 | ppl 748.13 | wps 7982.4 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.326
2022-01-31 14:57:34 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-31 14:57:34 | INFO | train | epoch 063 | loss 7.014 | ppl 129.21 | wps 5971.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.551 | train_wall 321 | gb_free 6.1 | wall 21963
KL Stats: Epoch 63 Divergences: Uniform: 2.549045492901148 Unigram: 3.4021279169515246
2022-01-31 14:57:34 | INFO | fairseq.trainer | begin training epoch 64
2022-01-31 14:57:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:02:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:03:23 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.615 | ppl 784.25 | wps 7998.1 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.326
2022-01-31 15:03:23 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-31 15:03:23 | INFO | train | epoch 064 | loss 6.972 | ppl 125.53 | wps 5992.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.564 | train_wall 320 | gb_free 6.1 | wall 22312
KL Stats: Epoch 64 Divergences: Uniform: 2.5551295953489017 Unigram: 3.4205264833520586
2022-01-31 15:03:23 | INFO | fairseq.trainer | begin training epoch 65
2022-01-31 15:03:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:03:43 | INFO | train_inner | epoch 065:      4 / 64 loss=6.998, ppl=127.86, wps=5853.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.562, train_wall=501, gb_free=6.1, wall=22332
2022-01-31 15:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:09:12 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.627 | ppl 790.78 | wps 7998.2 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.326
2022-01-31 15:09:12 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-31 15:09:12 | INFO | train | epoch 065 | loss 6.928 | ppl 121.77 | wps 5987.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.562 | train_wall 321 | gb_free 6.1 | wall 22660
KL Stats: Epoch 65 Divergences: Uniform: 2.563942976226502 Unigram: 3.445737368680613
2022-01-31 15:09:12 | INFO | fairseq.trainer | begin training epoch 66
2022-01-31 15:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:12:33 | INFO | train_inner | epoch 066:     40 / 64 loss=6.904, ppl=119.75, wps=6161, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.567, train_wall=502, gb_free=6.1, wall=22862
2022-01-31 15:14:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:15:01 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.639 | ppl 797.29 | wps 8004.3 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.326
2022-01-31 15:15:01 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-31 15:15:01 | INFO | train | epoch 066 | loss 6.888 | ppl 118.46 | wps 5981.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.563 | train_wall 321 | gb_free 6.1 | wall 23010
KL Stats: Epoch 66 Divergences: Uniform: 2.5772898308287924 Unigram: 3.471961225872827
2022-01-31 15:15:01 | INFO | fairseq.trainer | begin training epoch 67
2022-01-31 15:15:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:20:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:20:50 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.638 | ppl 796.8 | wps 7989 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.326
2022-01-31 15:20:50 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-31 15:20:50 | INFO | train | epoch 067 | loss 6.847 | ppl 115.1 | wps 5984.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.569 | train_wall 321 | gb_free 6.1 | wall 23359
KL Stats: Epoch 67 Divergences: Uniform: 2.5950305911630087 Unigram: 3.507518799528248
2022-01-31 15:20:50 | INFO | fairseq.trainer | begin training epoch 68
2022-01-31 15:20:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:21:50 | INFO | train_inner | epoch 068:     12 / 64 loss=6.856, ppl=115.81, wps=5855.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.563, train_wall=501, gb_free=6.1, wall=23419
2022-01-31 15:26:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:26:37 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.681 | ppl 820.87 | wps 8033.2 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.326
2022-01-31 15:26:37 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-31 15:26:37 | INFO | train | epoch 068 | loss 6.81 | ppl 112.18 | wps 6013.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.582 | train_wall 319 | gb_free 6.1 | wall 23706
KL Stats: Epoch 68 Divergences: Uniform: 2.6060593442497813 Unigram: 3.5349998447665416
2022-01-31 15:26:37 | INFO | fairseq.trainer | begin training epoch 69
2022-01-31 15:26:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:30:39 | INFO | train_inner | epoch 069:     48 / 64 loss=6.792, ppl=110.8, wps=6181, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.581, train_wall=500, gb_free=6.1, wall=23948
2022-01-31 15:31:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:32:26 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.681 | ppl 820.85 | wps 7989.8 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.326
2022-01-31 15:32:26 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-31 15:32:26 | INFO | train | epoch 069 | loss 6.772 | ppl 109.27 | wps 5992.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.582 | train_wall 320 | gb_free 6.1 | wall 24054
KL Stats: Epoch 69 Divergences: Uniform: 2.618332367180402 Unigram: 3.5546142788288915
2022-01-31 15:32:26 | INFO | fairseq.trainer | begin training epoch 70
2022-01-31 15:32:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:38:14 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.785 | ppl 882.26 | wps 8004.8 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.326
2022-01-31 15:38:14 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-31 15:38:14 | INFO | train | epoch 070 | loss 6.736 | ppl 106.58 | wps 5998 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.575 | train_wall 320 | gb_free 6.1 | wall 24403
KL Stats: Epoch 70 Divergences: Uniform: 2.6226714181201594 Unigram: 3.571775430475295
2022-01-31 15:38:14 | INFO | fairseq.trainer | begin training epoch 71
2022-01-31 15:38:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:39:55 | INFO | train_inner | epoch 071:     20 / 64 loss=6.73, ppl=106.18, wps=5865.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.58, train_wall=500, gb_free=6.1, wall=24504
2022-01-31 15:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:44:01 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.776 | ppl 876.47 | wps 8113.8 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.326
2022-01-31 15:44:01 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-31 15:44:01 | INFO | train | epoch 071 | loss 6.701 | ppl 104.07 | wps 6011.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.588 | train_wall 320 | gb_free 6.1 | wall 24750
KL Stats: Epoch 71 Divergences: Uniform: 2.635696134088942 Unigram: 3.5959790520174897
2022-01-31 15:44:01 | INFO | fairseq.trainer | begin training epoch 72
2022-01-31 15:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:48:44 | INFO | train_inner | epoch 072:     56 / 64 loss=6.686, ppl=102.96, wps=6176.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.584, train_wall=501, gb_free=6.1, wall=25033
2022-01-31 15:49:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:49:50 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.668 | ppl 813.59 | wps 7998.9 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.326
2022-01-31 15:49:50 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-31 15:49:50 | INFO | train | epoch 072 | loss 6.666 | ppl 101.56 | wps 5985.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.583 | train_wall 321 | gb_free 6.1 | wall 25099
KL Stats: Epoch 72 Divergences: Uniform: 2.6509674567939228 Unigram: 3.627942886767364
2022-01-31 15:49:50 | INFO | fairseq.trainer | begin training epoch 73
2022-01-31 15:49:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:55:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:55:39 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.777 | ppl 877.34 | wps 8004 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.326
2022-01-31 15:55:39 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-31 15:55:39 | INFO | train | epoch 073 | loss 6.634 | ppl 99.29 | wps 5983.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.582 | train_wall 321 | gb_free 6.1 | wall 25448
KL Stats: Epoch 73 Divergences: Uniform: 2.6515154245954804 Unigram: 3.641509598538551
2022-01-31 15:55:39 | INFO | fairseq.trainer | begin training epoch 74
2022-01-31 15:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:58:00 | INFO | train_inner | epoch 074:     28 / 64 loss=6.622, ppl=98.52, wps=5858.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.584, train_wall=500, gb_free=6.1, wall=25589
2022-01-31 16:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:01:28 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.728 | ppl 847.88 | wps 7985 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.326
2022-01-31 16:01:28 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-31 16:01:28 | INFO | train | epoch 074 | loss 6.6 | ppl 97.02 | wps 5992.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.585 | train_wall 320 | gb_free 6.1 | wall 25797
KL Stats: Epoch 74 Divergences: Uniform: 2.6599145195931793 Unigram: 3.6727161269901174
2022-01-31 16:01:28 | INFO | fairseq.trainer | begin training epoch 75
2022-01-31 16:01:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:06:49 | INFO | train_inner | epoch 075:     64 / 64 loss=6.592, ppl=96.45, wps=6167, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.592, train_wall=500, gb_free=6.1, wall=26118
2022-01-31 16:06:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:07:16 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.859 | ppl 928.85 | wps 7982.5 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.326
2022-01-31 16:07:16 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-31 16:07:16 | INFO | train | epoch 075 | loss 6.572 | ppl 95.13 | wps 5993 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.597 | train_wall 320 | gb_free 6.1 | wall 26145
KL Stats: Epoch 75 Divergences: Uniform: 2.6677873147311764 Unigram: 3.6916189951416234
2022-01-31 16:07:16 | INFO | fairseq.trainer | begin training epoch 76
2022-01-31 16:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:12:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:13:05 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.804 | ppl 893.85 | wps 7999.9 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.326
2022-01-31 16:13:05 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-31 16:13:05 | INFO | train | epoch 076 | loss 6.541 | ppl 93.14 | wps 5985.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.607 | train_wall 321 | gb_free 6.1 | wall 26494
KL Stats: Epoch 76 Divergences: Uniform: 2.676770203705105 Unigram: 3.7220396256901878
2022-01-31 16:13:05 | INFO | fairseq.trainer | begin training epoch 77
2022-01-31 16:13:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:16:07 | INFO | train_inner | epoch 077:     36 / 64 loss=6.516, ppl=91.54, wps=5859.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.606, train_wall=502, gb_free=6.1, wall=26676
2022-01-31 16:18:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:18:54 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.758 | ppl 865.93 | wps 7973.4 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.326
2022-01-31 16:18:54 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-31 16:18:54 | INFO | train | epoch 077 | loss 6.511 | ppl 91.23 | wps 5986.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.616 | train_wall 321 | gb_free 6.1 | wall 26843
KL Stats: Epoch 77 Divergences: Uniform: 2.6854287922990836 Unigram: 3.751392547575252
2022-01-31 16:18:54 | INFO | fairseq.trainer | begin training epoch 78
2022-01-31 16:18:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:24:43 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.805 | ppl 894.51 | wps 7974.6 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.326
2022-01-31 16:24:43 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-31 16:24:43 | INFO | train | epoch 078 | loss 6.483 | ppl 89.43 | wps 5982.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.613 | train_wall 321 | gb_free 6.1 | wall 27192
KL Stats: Epoch 78 Divergences: Uniform: 2.691453206607939 Unigram: 3.766316553036266
2022-01-31 16:24:43 | INFO | fairseq.trainer | begin training epoch 79
2022-01-31 16:24:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:25:23 | INFO | train_inner | epoch 079:      8 / 64 loss=6.497, ppl=90.33, wps=5857, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.617, train_wall=500, gb_free=6.1, wall=27232
2022-01-31 16:30:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:30:32 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.889 | ppl 948.02 | wps 7995.3 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.326
2022-01-31 16:30:32 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-31 16:30:32 | INFO | train | epoch 079 | loss 6.451 | ppl 87.51 | wps 5995.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.601 | train_wall 320 | gb_free 6.1 | wall 27540
KL Stats: Epoch 79 Divergences: Uniform: 2.6939372343324948 Unigram: 3.78126672993646
2022-01-31 16:30:32 | INFO | fairseq.trainer | begin training epoch 80
2022-01-31 16:30:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:34:13 | INFO | train_inner | epoch 080:     44 / 64 loss=6.435, ppl=86.53, wps=6163, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.601, train_wall=502, gb_free=6.1, wall=27762
2022-01-31 16:35:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:36:20 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.808 | ppl 896.48 | wps 7990.6 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.326
2022-01-31 16:36:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-31 16:36:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint80.pt
2022-01-31 16:36:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint80.pt
2022-01-31 16:36:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.808) (writing took 3.6581702642142773 seconds)
2022-01-31 16:36:24 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-31 16:36:24 | INFO | train | epoch 080 | loss 6.427 | ppl 86.02 | wps 5925.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.609 | train_wall 321 | gb_free 6.1 | wall 27893
KL Stats: Epoch 80 Divergences: Uniform: 2.7024125311039207 Unigram: 3.807613960436276
2022-01-31 16:36:24 | INFO | fairseq.trainer | begin training epoch 81
2022-01-31 16:36:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:42:13 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.903 | ppl 957.55 | wps 8003.7 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.326
2022-01-31 16:42:13 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-31 16:42:13 | INFO | train | epoch 081 | loss 6.401 | ppl 84.53 | wps 5985.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.622 | train_wall 321 | gb_free 6.1 | wall 28242
KL Stats: Epoch 81 Divergences: Uniform: 2.7187858859645067 Unigram: 3.8318851558145184
2022-01-31 16:42:13 | INFO | fairseq.trainer | begin training epoch 82
2022-01-31 16:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:43:34 | INFO | train_inner | epoch 082:     16 / 64 loss=6.408, ppl=84.92, wps=5817.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.625, train_wall=501, gb_free=6.1, wall=28323
2022-01-31 16:47:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:48:01 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.839 | ppl 915.94 | wps 7949.4 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.326
2022-01-31 16:48:01 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-31 16:48:01 | INFO | train | epoch 082 | loss 6.374 | ppl 82.95 | wps 5998.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.617 | train_wall 320 | gb_free 6.1 | wall 28590
KL Stats: Epoch 82 Divergences: Uniform: 2.723287194768852 Unigram: 3.8658415518810205
2022-01-31 16:48:01 | INFO | fairseq.trainer | begin training epoch 83
2022-01-31 16:48:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:52:23 | INFO | train_inner | epoch 083:     52 / 64 loss=6.36, ppl=82.13, wps=6170.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.627, train_wall=501, gb_free=6.1, wall=28852
2022-01-31 16:53:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:53:50 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.775 | ppl 876.01 | wps 8012.4 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.326
2022-01-31 16:53:50 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-31 16:53:50 | INFO | train | epoch 083 | loss 6.35 | ppl 81.55 | wps 5987.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.639 | train_wall 321 | gb_free 6.1 | wall 28939
KL Stats: Epoch 83 Divergences: Uniform: 2.733066352271949 Unigram: 3.8812998243823773
2022-01-31 16:53:50 | INFO | fairseq.trainer | begin training epoch 84
2022-01-31 16:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:59:39 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.843 | ppl 918.37 | wps 7983.5 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.326
2022-01-31 16:59:39 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-31 16:59:39 | INFO | train | epoch 084 | loss 6.323 | ppl 80.07 | wps 5984.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.625 | train_wall 321 | gb_free 6.1 | wall 29288
KL Stats: Epoch 84 Divergences: Uniform: 2.7399716252387494 Unigram: 3.8974870511599766
2022-01-31 16:59:39 | INFO | fairseq.trainer | begin training epoch 85
2022-01-31 16:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:01:40 | INFO | train_inner | epoch 085:     24 / 64 loss=6.312, ppl=79.48, wps=5858.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.626, train_wall=500, gb_free=6.1, wall=29409
2022-01-31 17:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:05:28 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.882 | ppl 943.79 | wps 7988.4 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.326
2022-01-31 17:05:28 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-31 17:05:28 | INFO | train | epoch 085 | loss 6.3 | ppl 78.79 | wps 5991.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.635 | train_wall 320 | gb_free 6.1 | wall 29637
KL Stats: Epoch 85 Divergences: Uniform: 2.7499357247638323 Unigram: 3.920821769577209
2022-01-31 17:05:28 | INFO | fairseq.trainer | begin training epoch 86
2022-01-31 17:05:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:10:30 | INFO | train_inner | epoch 086:     60 / 64 loss=6.297, ppl=78.64, wps=6164.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.638, train_wall=501, gb_free=6.1, wall=29939
2022-01-31 17:10:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:11:16 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.933 | ppl 977.34 | wps 8004.9 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.326
2022-01-31 17:11:16 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-31 17:11:16 | INFO | train | epoch 086 | loss 6.276 | ppl 77.47 | wps 5989.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.639 | train_wall 321 | gb_free 6.1 | wall 29985
KL Stats: Epoch 86 Divergences: Uniform: 2.749816638440277 Unigram: 3.9447428747330355
2022-01-31 17:11:16 | INFO | fairseq.trainer | begin training epoch 87
2022-01-31 17:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:17:05 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.93 | ppl 975.62 | wps 8001.9 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.326
2022-01-31 17:17:05 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-31 17:17:05 | INFO | train | epoch 087 | loss 6.254 | ppl 76.3 | wps 5983.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.656 | train_wall 321 | gb_free 6.1 | wall 30334
KL Stats: Epoch 87 Divergences: Uniform: 2.7570176675909104 Unigram: 3.9567084475405947
2022-01-31 17:17:05 | INFO | fairseq.trainer | begin training epoch 88
2022-01-31 17:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:19:47 | INFO | train_inner | epoch 088:     32 / 64 loss=6.24, ppl=75.6, wps=5854.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.653, train_wall=501, gb_free=6.1, wall=30496
2022-01-31 17:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:22:54 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.901 | ppl 955.9 | wps 8013.7 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.326
2022-01-31 17:22:54 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-31 17:22:54 | INFO | train | epoch 088 | loss 6.231 | ppl 75.1 | wps 5984.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.651 | train_wall 321 | gb_free 6.1 | wall 30683
KL Stats: Epoch 88 Divergences: Uniform: 2.763481384587193 Unigram: 3.9818362478568616
2022-01-31 17:22:54 | INFO | fairseq.trainer | begin training epoch 89
2022-01-31 17:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:28:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:28:43 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.911 | ppl 962.89 | wps 8147.7 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.326
2022-01-31 17:28:43 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-31 17:28:43 | INFO | train | epoch 089 | loss 6.213 | ppl 74.2 | wps 5999.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.674 | train_wall 320 | gb_free 6.1 | wall 31031
KL Stats: Epoch 89 Divergences: Uniform: 2.772029917556553 Unigram: 3.9957191701788295
2022-01-31 17:28:43 | INFO | fairseq.trainer | begin training epoch 90
2022-01-31 17:28:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:29:02 | INFO | train_inner | epoch 090:      4 / 64 loss=6.224, ppl=74.73, wps=5868.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.667, train_wall=500, gb_free=6.1, wall=31051
2022-01-31 17:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:34:31 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.974 | ppl 1005.38 | wps 8018.5 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.326
2022-01-31 17:34:31 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-31 17:34:31 | INFO | train | epoch 090 | loss 6.188 | ppl 72.91 | wps 5996.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.655 | train_wall 320 | gb_free 6.1 | wall 31380
KL Stats: Epoch 90 Divergences: Uniform: 2.7743925227094532 Unigram: 4.011171219457905
2022-01-31 17:34:31 | INFO | fairseq.trainer | begin training epoch 91
2022-01-31 17:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:37:52 | INFO | train_inner | epoch 091:     40 / 64 loss=6.17, ppl=71.99, wps=6164.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.653, train_wall=502, gb_free=6.1, wall=31581
2022-01-31 17:39:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:40:20 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.945 | ppl 985.5 | wps 7993.2 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.326
2022-01-31 17:40:20 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-31 17:40:20 | INFO | train | epoch 091 | loss 6.166 | ppl 71.78 | wps 5989.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.657 | train_wall 320 | gb_free 6.1 | wall 31728
KL Stats: Epoch 91 Divergences: Uniform: 2.7827876296722778 Unigram: 4.044986030868144
2022-01-31 17:40:20 | INFO | fairseq.trainer | begin training epoch 92
2022-01-31 17:40:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:46:09 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.98 | ppl 1010.04 | wps 8017.3 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.326
2022-01-31 17:46:09 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-31 17:46:09 | INFO | train | epoch 092 | loss 6.147 | ppl 70.88 | wps 5982.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.681 | train_wall 321 | gb_free 6.1 | wall 32078
KL Stats: Epoch 92 Divergences: Uniform: 2.789062773022607 Unigram: 4.062267832792022
2022-01-31 17:46:09 | INFO | fairseq.trainer | begin training epoch 93
2022-01-31 17:46:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:47:09 | INFO | train_inner | epoch 093:     12 / 64 loss=6.156, ppl=71.32, wps=5855.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.674, train_wall=501, gb_free=6.1, wall=32138
2022-01-31 17:51:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:51:56 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.911 | ppl 962.51 | wps 7980 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.326
2022-01-31 17:51:56 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-31 17:51:56 | INFO | train | epoch 093 | loss 6.129 | ppl 70 | wps 6006.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.677 | train_wall 319 | gb_free 6.1 | wall 32425
KL Stats: Epoch 93 Divergences: Uniform: 2.7930974417456613 Unigram: 4.082826242518859
2022-01-31 17:51:56 | INFO | fairseq.trainer | begin training epoch 94
2022-01-31 17:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:55:58 | INFO | train_inner | epoch 094:     48 / 64 loss=6.115, ppl=69.29, wps=6177.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.68, train_wall=500, gb_free=6.1, wall=32667
2022-01-31 17:57:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:57:45 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 10.009 | ppl 1030.45 | wps 7998 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.326
2022-01-31 17:57:45 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-31 17:57:45 | INFO | train | epoch 094 | loss 6.108 | ppl 68.96 | wps 5992.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.679 | train_wall 320 | gb_free 6.1 | wall 32774
KL Stats: Epoch 94 Divergences: Uniform: 2.794718596335257 Unigram: 4.100380602911532
2022-01-31 17:57:45 | INFO | fairseq.trainer | begin training epoch 95
2022-01-31 17:57:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:03:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:03:34 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 10.034 | ppl 1048.51 | wps 7992.6 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.326
2022-01-31 18:03:34 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-31 18:03:34 | INFO | train | epoch 095 | loss 6.088 | ppl 68.01 | wps 5988 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.671 | train_wall 321 | gb_free 6.1 | wall 33123
KL Stats: Epoch 95 Divergences: Uniform: 2.798401115843311 Unigram: 4.116616116594432
2022-01-31 18:03:34 | INFO | fairseq.trainer | begin training epoch 96
2022-01-31 18:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:05:15 | INFO | train_inner | epoch 096:     20 / 64 loss=6.087, ppl=67.98, wps=5859.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.679, train_wall=500, gb_free=6.1, wall=33224
2022-01-31 18:08:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:09:22 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.938 | ppl 981.04 | wps 8001.8 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.326
2022-01-31 18:09:22 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-31 18:09:22 | INFO | train | epoch 096 | loss 6.071 | ppl 67.21 | wps 5989.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.698 | train_wall 321 | gb_free 6.1 | wall 33471
KL Stats: Epoch 96 Divergences: Uniform: 2.8145845751205765 Unigram: 4.132888318801318
2022-01-31 18:09:22 | INFO | fairseq.trainer | begin training epoch 97
2022-01-31 18:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:14:04 | INFO | train_inner | epoch 097:     56 / 64 loss=6.065, ppl=66.94, wps=6169.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.693, train_wall=501, gb_free=6.1, wall=33753
2022-01-31 18:14:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:15:11 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 10.029 | ppl 1044.88 | wps 7997.9 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.326
2022-01-31 18:15:11 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-31 18:15:11 | INFO | train | epoch 097 | loss 6.054 | ppl 66.42 | wps 5996.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.694 | train_wall 320 | gb_free 6.1 | wall 33820
KL Stats: Epoch 97 Divergences: Uniform: 2.8203055707285576 Unigram: 4.15749548320711
2022-01-31 18:15:11 | INFO | fairseq.trainer | begin training epoch 98
2022-01-31 18:15:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:20:59 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.983 | ppl 1012.16 | wps 8005.6 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.326
2022-01-31 18:20:59 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-31 18:20:59 | INFO | train | epoch 098 | loss 6.034 | ppl 65.54 | wps 5991.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.722 | train_wall 320 | gb_free 6.1 | wall 34168
KL Stats: Epoch 98 Divergences: Uniform: 2.8204585626503125 Unigram: 4.162579997613385
2022-01-31 18:20:59 | INFO | fairseq.trainer | begin training epoch 99
2022-01-31 18:20:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:23:21 | INFO | train_inner | epoch 099:     28 / 64 loss=6.025, ppl=65.13, wps=5860.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.724, train_wall=500, gb_free=6.1, wall=34310
2022-01-31 18:26:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:26:48 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 10.008 | ppl 1029.95 | wps 8020.6 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.326
2022-01-31 18:26:48 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-31 18:26:48 | INFO | train | epoch 099 | loss 6.016 | ppl 64.72 | wps 5988.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.722 | train_wall 321 | gb_free 6.1 | wall 34517
KL Stats: Epoch 99 Divergences: Uniform: 2.826178525640231 Unigram: 4.1873297947436185
2022-01-31 18:26:48 | INFO | fairseq.trainer | begin training epoch 100
2022-01-31 18:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:32:09 | INFO | train_inner | epoch 100:     64 / 64 loss=6.019, ppl=64.83, wps=6170.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.723, train_wall=500, gb_free=6.1, wall=34838
2022-01-31 18:32:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:32:36 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 10.007 | ppl 1028.75 | wps 8102.2 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.326
2022-01-31 18:32:36 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-31 18:32:36 | INFO | train | epoch 100 | loss 6.001 | ppl 64.04 | wps 6007.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.727 | train_wall 320 | gb_free 6.1 | wall 34865
KL Stats: Epoch 100 Divergences: Uniform: 2.824272446985833 Unigram: 4.195015192349328
2022-01-31 18:32:36 | INFO | fairseq.trainer | begin training epoch 101
2022-01-31 18:32:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:38:25 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 10.07 | ppl 1075.1 | wps 7990 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.326
2022-01-31 18:38:25 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-31 18:38:25 | INFO | train | epoch 101 | loss 5.983 | ppl 63.23 | wps 5982.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.731 | train_wall 321 | gb_free 6.1 | wall 35214
KL Stats: Epoch 101 Divergences: Uniform: 2.8393487423407042 Unigram: 4.218693767713537
2022-01-31 18:38:25 | INFO | fairseq.trainer | begin training epoch 102
2022-01-31 18:38:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:41:26 | INFO | train_inner | epoch 102:     36 / 64 loss=5.968, ppl=62.61, wps=5861.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.731, train_wall=502, gb_free=6.1, wall=35395
2022-01-31 18:43:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:44:14 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 10.079 | ppl 1081.82 | wps 8022 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.326
2022-01-31 18:44:14 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-31 18:44:14 | INFO | train | epoch 102 | loss 5.968 | ppl 62.57 | wps 5991.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.729 | train_wall 320 | gb_free 6.1 | wall 35563
KL Stats: Epoch 102 Divergences: Uniform: 2.839530661642631 Unigram: 4.2357347550203786
2022-01-31 18:44:14 | INFO | fairseq.trainer | begin training epoch 103
2022-01-31 18:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:49:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:50:03 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 10.091 | ppl 1090.82 | wps 7990.4 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.326
2022-01-31 18:50:03 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-31 18:50:03 | INFO | train | epoch 103 | loss 5.949 | ppl 61.78 | wps 5983 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.721 | train_wall 321 | gb_free 6.1 | wall 35912
KL Stats: Epoch 103 Divergences: Uniform: 2.8518920019897314 Unigram: 4.2535451524161365
2022-01-31 18:50:03 | INFO | fairseq.trainer | begin training epoch 104
2022-01-31 18:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:50:43 | INFO | train_inner | epoch 104:      8 / 64 loss=5.957, ppl=62.11, wps=5855.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.722, train_wall=501, gb_free=6.1, wall=35952
2022-01-31 18:55:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:55:51 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 10.078 | ppl 1080.67 | wps 7972.2 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.326
2022-01-31 18:55:51 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-31 18:55:51 | INFO | train | epoch 104 | loss 5.936 | ppl 61.23 | wps 5994.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.735 | train_wall 320 | gb_free 6.1 | wall 36260
KL Stats: Epoch 104 Divergences: Uniform: 2.846316067525878 Unigram: 4.271676171900059
2022-01-31 18:55:51 | INFO | fairseq.trainer | begin training epoch 105
2022-01-31 18:55:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:59:33 | INFO | train_inner | epoch 105:     44 / 64 loss=5.924, ppl=60.72, wps=6163.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.741, train_wall=501, gb_free=6.1, wall=36482
2022-01-31 19:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:01:41 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 10.029 | ppl 1044.78 | wps 7912.5 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.326
2022-01-31 19:01:41 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-31 19:01:41 | INFO | train | epoch 105 | loss 5.921 | ppl 60.57 | wps 5971.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.745 | train_wall 321 | gb_free 6.1 | wall 36610
KL Stats: Epoch 105 Divergences: Uniform: 2.853214934408744 Unigram: 4.285304926894688
2022-01-31 19:01:41 | INFO | fairseq.trainer | begin training epoch 106
2022-01-31 19:01:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:07:33 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 10.108 | ppl 1103.91 | wps 7931.1 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.326
2022-01-31 19:07:33 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-31 19:07:33 | INFO | train | epoch 106 | loss 5.903 | ppl 59.84 | wps 5939.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.729 | train_wall 323 | gb_free 6.1 | wall 36962
KL Stats: Epoch 106 Divergences: Uniform: 2.8544577686616277 Unigram: 4.292459220183567
2022-01-31 19:07:33 | INFO | fairseq.trainer | begin training epoch 107
2022-01-31 19:07:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:08:54 | INFO | train_inner | epoch 107:     16 / 64 loss=5.907, ppl=60, wps=5814.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.737, train_wall=504, gb_free=6.1, wall=37043
2022-01-31 19:12:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:13:24 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 10.11 | ppl 1105.39 | wps 7935.3 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.326
2022-01-31 19:13:24 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-31 19:13:24 | INFO | train | epoch 107 | loss 5.887 | ppl 59.19 | wps 5949.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.745 | train_wall 323 | gb_free 6.1 | wall 37313
KL Stats: Epoch 107 Divergences: Uniform: 2.8634388464797724 Unigram: 4.313897806964236
2022-01-31 19:13:24 | INFO | fairseq.trainer | begin training epoch 108
2022-01-31 19:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:17:46 | INFO | train_inner | epoch 108:     52 / 64 loss=5.883, ppl=59, wps=6139.7, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.756, train_wall=503, gb_free=6.1, wall=37575
2022-01-31 19:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:19:13 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 10.112 | ppl 1106.8 | wps 7938.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.326
2022-01-31 19:19:13 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-31 19:19:13 | INFO | train | epoch 108 | loss 5.876 | ppl 58.74 | wps 5970 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.777 | train_wall 321 | gb_free 6.1 | wall 37662
KL Stats: Epoch 108 Divergences: Uniform: 2.867727607078569 Unigram: 4.324856370171599
2022-01-31 19:19:13 | INFO | fairseq.trainer | begin training epoch 109
2022-01-31 19:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:24:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:25:05 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.121 | ppl 1113.86 | wps 7936.9 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.326
2022-01-31 19:25:05 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-31 19:25:05 | INFO | train | epoch 109 | loss 5.86 | ppl 58.09 | wps 5949.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.763 | train_wall 323 | gb_free 6.1 | wall 38014
KL Stats: Epoch 109 Divergences: Uniform: 2.8681110768544635 Unigram: 4.346300518147637
2022-01-31 19:25:05 | INFO | fairseq.trainer | begin training epoch 110
2022-01-31 19:25:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:27:06 | INFO | train_inner | epoch 110:     24 / 64 loss=5.854, ppl=57.86, wps=5820, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.769, train_wall=504, gb_free=6.1, wall=38135
2022-01-31 19:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:30:56 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.166 | ppl 1148.73 | wps 7955.7 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.326
2022-01-31 19:30:56 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-31 19:30:56 | INFO | train | epoch 110 | loss 5.847 | ppl 57.54 | wps 5946.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.769 | train_wall 323 | gb_free 6.1 | wall 38365
KL Stats: Epoch 110 Divergences: Uniform: 2.8757373250647222 Unigram: 4.360464246337592
2022-01-31 19:30:56 | INFO | fairseq.trainer | begin training epoch 111
2022-01-31 19:30:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:35:59 | INFO | train_inner | epoch 111:     60 / 64 loss=5.846, ppl=57.51, wps=6133.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.778, train_wall=504, gb_free=6.1, wall=38668
2022-01-31 19:36:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:36:45 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.132 | ppl 1121.93 | wps 7965.9 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.326
2022-01-31 19:36:45 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-31 19:36:45 | INFO | train | epoch 111 | loss 5.833 | ppl 57 | wps 5974.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.783 | train_wall 321 | gb_free 6.1 | wall 38714
KL Stats: Epoch 111 Divergences: Uniform: 2.8757006983412037 Unigram: 4.379962283666537
2022-01-31 19:36:45 | INFO | fairseq.trainer | begin training epoch 112
2022-01-31 19:36:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:42:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:42:36 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.18 | ppl 1159.82 | wps 7930.5 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.326
2022-01-31 19:42:36 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-31 19:42:36 | INFO | train | epoch 112 | loss 5.818 | ppl 56.42 | wps 5950.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.779 | train_wall 323 | gb_free 6.1 | wall 39065
KL Stats: Epoch 112 Divergences: Uniform: 2.879814677591912 Unigram: 4.395338171490341
2022-01-31 19:42:36 | INFO | fairseq.trainer | begin training epoch 113
2022-01-31 19:42:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:45:19 | INFO | train_inner | epoch 113:     32 / 64 loss=5.806, ppl=55.96, wps=5828.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.778, train_wall=503, gb_free=6.1, wall=39228
2022-01-31 19:48:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:48:27 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.134 | ppl 1123.32 | wps 7968.2 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.326
2022-01-31 19:48:27 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-31 19:48:27 | INFO | train | epoch 113 | loss 5.803 | ppl 55.84 | wps 5955.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.773 | train_wall 322 | gb_free 6.1 | wall 39416
KL Stats: Epoch 113 Divergences: Uniform: 2.887484484654345 Unigram: 4.408567771877758
2022-01-31 19:48:27 | INFO | fairseq.trainer | begin training epoch 114
2022-01-31 19:48:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:53:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:54:18 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.158 | ppl 1142.84 | wps 7938.2 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.326
2022-01-31 19:54:18 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-31 19:54:18 | INFO | train | epoch 114 | loss 5.791 | ppl 55.37 | wps 5960.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.791 | train_wall 322 | gb_free 6.1 | wall 39767
KL Stats: Epoch 114 Divergences: Uniform: 2.888618008486176 Unigram: 4.419617988774367
2022-01-31 19:54:18 | INFO | fairseq.trainer | begin training epoch 115
2022-01-31 19:54:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:54:38 | INFO | train_inner | epoch 115:      4 / 64 loss=5.803, ppl=55.84, wps=5828.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.789, train_wall=503, gb_free=6.1, wall=39787
2022-01-31 19:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:00:07 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.163 | ppl 1146.61 | wps 7950.7 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.326
2022-01-31 20:00:07 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-31 20:00:07 | INFO | train | epoch 115 | loss 5.779 | ppl 54.9 | wps 5973.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.8 | train_wall 321 | gb_free 6.1 | wall 40116
KL Stats: Epoch 115 Divergences: Uniform: 2.893427841725796 Unigram: 4.43073827533578
2022-01-31 20:00:07 | INFO | fairseq.trainer | begin training epoch 116
2022-01-31 20:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:03:30 | INFO | train_inner | epoch 116:     40 / 64 loss=5.764, ppl=54.35, wps=6142.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.791, train_wall=503, gb_free=6.1, wall=40319
2022-01-31 20:05:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:05:58 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.127 | ppl 1118.07 | wps 7943.2 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.326
2022-01-31 20:05:58 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-31 20:05:58 | INFO | train | epoch 116 | loss 5.765 | ppl 54.38 | wps 5961.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.788 | train_wall 322 | gb_free 6.1 | wall 40467
KL Stats: Epoch 116 Divergences: Uniform: 2.8974294330192256 Unigram: 4.437428403736695
2022-01-31 20:05:58 | INFO | fairseq.trainer | begin training epoch 117
2022-01-31 20:05:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:11:49 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.225 | ppl 1196.82 | wps 7958.4 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.326
2022-01-31 20:11:49 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-31 20:11:49 | INFO | train | epoch 117 | loss 5.754 | ppl 53.98 | wps 5945.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.801 | train_wall 323 | gb_free 6.1 | wall 40818
KL Stats: Epoch 117 Divergences: Uniform: 2.896982778298606 Unigram: 4.461594135032143
2022-01-31 20:11:49 | INFO | fairseq.trainer | begin training epoch 118
2022-01-31 20:11:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:12:50 | INFO | train_inner | epoch 118:     12 / 64 loss=5.76, ppl=54.18, wps=5822.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.808, train_wall=503, gb_free=6.1, wall=40879
2022-01-31 20:17:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:17:39 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.171 | ppl 1153.16 | wps 8101 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.326
2022-01-31 20:17:39 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-31 20:17:39 | INFO | train | epoch 118 | loss 5.742 | ppl 53.5 | wps 5959.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.812 | train_wall 323 | gb_free 6.1 | wall 41168
KL Stats: Epoch 118 Divergences: Uniform: 2.90852886467471 Unigram: 4.4740443212743655
2022-01-31 20:17:39 | INFO | fairseq.trainer | begin training epoch 119
2022-01-31 20:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:21:42 | INFO | train_inner | epoch 119:     48 / 64 loss=5.73, ppl=53.08, wps=6142.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.795, train_wall=504, gb_free=6.1, wall=41411
2022-01-31 20:23:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:23:29 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.157 | ppl 1141.33 | wps 7943.6 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.326
2022-01-31 20:23:29 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-31 20:23:29 | INFO | train | epoch 119 | loss 5.727 | ppl 52.97 | wps 5970.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.795 | train_wall 321 | gb_free 6.1 | wall 41518
KL Stats: Epoch 119 Divergences: Uniform: 2.9090011743138326 Unigram: 4.493895493027797
2022-01-31 20:23:29 | INFO | fairseq.trainer | begin training epoch 120
2022-01-31 20:23:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:28:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:29:20 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.224 | ppl 1196.03 | wps 7928.4 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.326
2022-01-31 20:29:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-31 20:29:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint120.pt
2022-01-31 20:29:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint120.pt
2022-01-31 20:29:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.224) (writing took 3.810221966356039 seconds)
2022-01-31 20:29:24 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-31 20:29:24 | INFO | train | epoch 120 | loss 5.718 | ppl 52.65 | wps 5885 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.841 | train_wall 323 | gb_free 6.1 | wall 41873
KL Stats: Epoch 120 Divergences: Uniform: 2.913523930948785 Unigram: 4.500055369619682
2022-01-31 20:29:24 | INFO | fairseq.trainer | begin training epoch 121
2022-01-31 20:29:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:31:05 | INFO | train_inner | epoch 121:     20 / 64 loss=5.72, ppl=52.72, wps=5785.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.843, train_wall=503, gb_free=6.1, wall=41974
2022-01-31 20:34:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:35:15 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.202 | ppl 1178.1 | wps 7915.3 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.326
2022-01-31 20:35:15 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-31 20:35:15 | INFO | train | epoch 121 | loss 5.708 | ppl 52.27 | wps 5954 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.832 | train_wall 322 | gb_free 6.1 | wall 42224
KL Stats: Epoch 121 Divergences: Uniform: 2.9143809572728645 Unigram: 4.514382908834228
2022-01-31 20:35:15 | INFO | fairseq.trainer | begin training epoch 122
2022-01-31 20:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:39:58 | INFO | train_inner | epoch 122:     56 / 64 loss=5.704, ppl=52.12, wps=6135.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.825, train_wall=504, gb_free=6.1, wall=42507
2022-01-31 20:40:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:41:05 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.184 | ppl 1163.16 | wps 7923.3 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.326
2022-01-31 20:41:05 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-31 20:41:05 | INFO | train | epoch 122 | loss 5.696 | ppl 51.83 | wps 5961.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.833 | train_wall 322 | gb_free 6.1 | wall 42574
KL Stats: Epoch 122 Divergences: Uniform: 2.91664986985025 Unigram: 4.526332197218961
2022-01-31 20:41:05 | INFO | fairseq.trainer | begin training epoch 123
2022-01-31 20:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:46:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:46:56 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.226 | ppl 1197.87 | wps 7947.3 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.326
2022-01-31 20:46:56 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-31 20:46:56 | INFO | train | epoch 123 | loss 5.682 | ppl 51.35 | wps 5953.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.835 | train_wall 322 | gb_free 6.1 | wall 42925
KL Stats: Epoch 123 Divergences: Uniform: 2.9160364511221504 Unigram: 4.544041454553922
2022-01-31 20:46:56 | INFO | fairseq.trainer | begin training epoch 124
2022-01-31 20:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:49:18 | INFO | train_inner | epoch 124:     28 / 64 loss=5.675, ppl=51.1, wps=5823, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.827, train_wall=503, gb_free=6.1, wall=43067
2022-01-31 20:52:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:52:47 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.217 | ppl 1190.37 | wps 7936.1 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.326
2022-01-31 20:52:47 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-31 20:52:47 | INFO | train | epoch 124 | loss 5.67 | ppl 50.93 | wps 5956.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.824 | train_wall 322 | gb_free 6.1 | wall 43276
KL Stats: Epoch 124 Divergences: Uniform: 2.915198025362681 Unigram: 4.5475545003580296
2022-01-31 20:52:47 | INFO | fairseq.trainer | begin training epoch 125
2022-01-31 20:52:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:58:10 | INFO | train_inner | epoch 125:     64 / 64 loss=5.675, ppl=51.09, wps=6127.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.834, train_wall=503, gb_free=6.1, wall=43599
2022-01-31 20:58:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:58:37 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.261 | ppl 1227.09 | wps 7945.8 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.326
2022-01-31 20:58:37 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-31 20:58:37 | INFO | train | epoch 125 | loss 5.661 | ppl 50.59 | wps 5954.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.831 | train_wall 322 | gb_free 6.1 | wall 43626
KL Stats: Epoch 125 Divergences: Uniform: 2.9228282789627396 Unigram: 4.566401216859982
2022-01-31 20:58:37 | INFO | fairseq.trainer | begin training epoch 126
2022-01-31 20:58:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:04:27 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.196 | ppl 1173.32 | wps 7935.4 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.326
2022-01-31 21:04:27 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-31 21:04:27 | INFO | train | epoch 126 | loss 5.65 | ppl 50.21 | wps 5975.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.825 | train_wall 321 | gb_free 6.1 | wall 43976
KL Stats: Epoch 126 Divergences: Uniform: 2.931145260506506 Unigram: 4.583903470570598
2022-01-31 21:04:27 | INFO | fairseq.trainer | begin training epoch 127
2022-01-31 21:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:07:30 | INFO | train_inner | epoch 127:     36 / 64 loss=5.638, ppl=49.81, wps=5836.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.851, train_wall=503, gb_free=6.1, wall=44159
2022-01-31 21:09:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:10:18 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.195 | ppl 1172.5 | wps 7962.9 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.326
2022-01-31 21:10:18 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-31 21:10:18 | INFO | train | epoch 127 | loss 5.641 | ppl 49.91 | wps 5945.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.877 | train_wall 323 | gb_free 6.1 | wall 44327
KL Stats: Epoch 127 Divergences: Uniform: 2.9329548366748117 Unigram: 4.585434422617852
2022-01-31 21:10:18 | INFO | fairseq.trainer | begin training epoch 128
2022-01-31 21:10:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:15:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:16:09 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.228 | ppl 1198.91 | wps 7922.1 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.326
2022-01-31 21:16:09 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-31 21:16:09 | INFO | train | epoch 128 | loss 5.629 | ppl 49.48 | wps 5947.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.868 | train_wall 323 | gb_free 6.1 | wall 44678
KL Stats: Epoch 128 Divergences: Uniform: 2.923145826054424 Unigram: 4.595537100375836
2022-01-31 21:16:09 | INFO | fairseq.trainer | begin training epoch 129
2022-01-31 21:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:16:50 | INFO | train_inner | epoch 129:      8 / 64 loss=5.636, ppl=49.74, wps=5817.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.866, train_wall=504, gb_free=6.1, wall=44719
2022-01-31 21:21:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:21:59 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.189 | ppl 1167.42 | wps 8066.3 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.326
2022-01-31 21:21:59 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-31 21:21:59 | INFO | train | epoch 129 | loss 5.622 | ppl 49.25 | wps 5972.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.888 | train_wall 322 | gb_free 6.1 | wall 45028
KL Stats: Epoch 129 Divergences: Uniform: 2.929744821625501 Unigram: 4.607004362268021
2022-01-31 21:21:59 | INFO | fairseq.trainer | begin training epoch 130
2022-01-31 21:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:25:42 | INFO | train_inner | epoch 130:     44 / 64 loss=5.609, ppl=48.82, wps=6140.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.875, train_wall=504, gb_free=6.1, wall=45251
2022-01-31 21:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:27:50 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.288 | ppl 1250.45 | wps 7919.3 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.326
2022-01-31 21:27:50 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-31 21:27:50 | INFO | train | epoch 130 | loss 5.608 | ppl 48.79 | wps 5952.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.865 | train_wall 322 | gb_free 6.1 | wall 45379
KL Stats: Epoch 130 Divergences: Uniform: 2.9330096932659666 Unigram: 4.628320513647819
2022-01-31 21:27:50 | INFO | fairseq.trainer | begin training epoch 131
2022-01-31 21:27:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:33:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:33:41 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.251 | ppl 1218.75 | wps 7921.3 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.326
2022-01-31 21:33:41 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-31 21:33:41 | INFO | train | epoch 131 | loss 5.601 | ppl 48.52 | wps 5955.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.894 | train_wall 322 | gb_free 6.1 | wall 45730
KL Stats: Epoch 131 Divergences: Uniform: 2.934985056698084 Unigram: 4.629325769765611
2022-01-31 21:33:41 | INFO | fairseq.trainer | begin training epoch 132
2022-01-31 21:33:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:35:02 | INFO | train_inner | epoch 132:     16 / 64 loss=5.603, ppl=48.6, wps=5826.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.882, train_wall=503, gb_free=6.1, wall=45811
2022-01-31 21:39:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:39:32 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.265 | ppl 1230.66 | wps 7944.9 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.326
2022-01-31 21:39:32 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-31 21:39:32 | INFO | train | epoch 132 | loss 5.589 | ppl 48.14 | wps 5952.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.885 | train_wall 322 | gb_free 6.1 | wall 46080
KL Stats: Epoch 132 Divergences: Uniform: 2.9356706579473353 Unigram: 4.653152776304161
2022-01-31 21:39:32 | INFO | fairseq.trainer | begin training epoch 133
2022-01-31 21:39:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:43:54 | INFO | train_inner | epoch 133:     52 / 64 loss=5.584, ppl=47.97, wps=6139.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.904, train_wall=503, gb_free=6.1, wall=46343
2022-01-31 21:44:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:45:21 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.282 | ppl 1245.27 | wps 7963 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.326
2022-01-31 21:45:21 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-31 21:45:21 | INFO | train | epoch 133 | loss 5.58 | ppl 47.84 | wps 5975 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.912 | train_wall 321 | gb_free 6.1 | wall 46430
KL Stats: Epoch 133 Divergences: Uniform: 2.947139322413797 Unigram: 4.658479379644619
2022-01-31 21:45:21 | INFO | fairseq.trainer | begin training epoch 134
2022-01-31 21:45:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:50:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:51:12 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.317 | ppl 1275.84 | wps 7911.4 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.326
2022-01-31 21:51:12 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-31 21:51:12 | INFO | train | epoch 134 | loss 5.571 | ppl 47.55 | wps 5949.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.926 | train_wall 323 | gb_free 6.1 | wall 46781
KL Stats: Epoch 134 Divergences: Uniform: 2.9411135552673406 Unigram: 4.677324379702118
2022-01-31 21:51:12 | INFO | fairseq.trainer | begin training epoch 135
2022-01-31 21:51:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:53:14 | INFO | train_inner | epoch 135:     24 / 64 loss=5.571, ppl=47.53, wps=5825.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.924, train_wall=503, gb_free=6.1, wall=46903
2022-01-31 21:56:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:57:02 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.251 | ppl 1218.18 | wps 7920.9 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.326
2022-01-31 21:57:02 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-31 21:57:02 | INFO | train | epoch 135 | loss 5.56 | ppl 47.19 | wps 5962.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.884 | train_wall 322 | gb_free 6.1 | wall 47131
KL Stats: Epoch 135 Divergences: Uniform: 2.950843291657266 Unigram: 4.686307114280704
2022-01-31 21:57:02 | INFO | fairseq.trainer | begin training epoch 136
2022-01-31 21:57:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:02:06 | INFO | train_inner | epoch 136:     60 / 64 loss=5.562, ppl=47.24, wps=6134.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.901, train_wall=504, gb_free=6.1, wall=47435
2022-01-31 22:02:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:02:53 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.327 | ppl 1284.9 | wps 8001.6 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.326
2022-01-31 22:02:53 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-31 22:02:53 | INFO | train | epoch 136 | loss 5.554 | ppl 46.97 | wps 5960.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.924 | train_wall 322 | gb_free 6.1 | wall 47482
KL Stats: Epoch 136 Divergences: Uniform: 2.944617387616682 Unigram: 4.688226809884727
2022-01-31 22:02:53 | INFO | fairseq.trainer | begin training epoch 137
2022-01-31 22:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:08:42 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.411 | ppl 1361.73 | wps 7945.3 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.326
2022-01-31 22:08:42 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-31 22:08:42 | INFO | train | epoch 137 | loss 5.543 | ppl 46.62 | wps 5979.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.913 | train_wall 321 | gb_free 6.1 | wall 47831
KL Stats: Epoch 137 Divergences: Uniform: 2.946300688395223 Unigram: 4.705965392175802
2022-01-31 22:08:42 | INFO | fairseq.trainer | begin training epoch 138
2022-01-31 22:08:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:11:24 | INFO | train_inner | epoch 138:     32 / 64 loss=5.534, ppl=46.34, wps=5841.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.913, train_wall=502, gb_free=6.1, wall=47993
2022-01-31 22:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:14:33 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.385 | ppl 1337.12 | wps 7956.5 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.326
2022-01-31 22:14:33 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-31 22:14:33 | INFO | train | epoch 138 | loss 5.534 | ppl 46.32 | wps 5953.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.932 | train_wall 322 | gb_free 6.1 | wall 48182
KL Stats: Epoch 138 Divergences: Uniform: 2.9470303372917734 Unigram: 4.708562935610321
2022-01-31 22:14:33 | INFO | fairseq.trainer | begin training epoch 139
2022-01-31 22:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:20:24 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.315 | ppl 1274.14 | wps 7947.4 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.326
2022-01-31 22:20:24 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-31 22:20:24 | INFO | train | epoch 139 | loss 5.525 | ppl 46.04 | wps 5957.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.94 | train_wall 322 | gb_free 6.1 | wall 48532
KL Stats: Epoch 139 Divergences: Uniform: 2.951840734883938 Unigram: 4.724573653060703
2022-01-31 22:20:24 | INFO | fairseq.trainer | begin training epoch 140
2022-01-31 22:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:20:44 | INFO | train_inner | epoch 140:      4 / 64 loss=5.533, ppl=46.29, wps=5828.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.946, train_wall=503, gb_free=6.1, wall=48553
2022-01-31 22:25:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:26:13 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.317 | ppl 1275.93 | wps 7933.1 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.326
2022-01-31 22:26:13 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-31 22:26:13 | INFO | train | epoch 140 | loss 5.518 | ppl 45.83 | wps 5979.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.956 | train_wall 321 | gb_free 6.1 | wall 48882
KL Stats: Epoch 140 Divergences: Uniform: 2.951970174690379 Unigram: 4.729392544407343
2022-01-31 22:26:13 | INFO | fairseq.trainer | begin training epoch 141
2022-01-31 22:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:29:35 | INFO | train_inner | epoch 141:     40 / 64 loss=5.509, ppl=45.54, wps=6147.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.949, train_wall=503, gb_free=6.1, wall=49084
2022-01-31 22:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:32:03 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.319 | ppl 1277.59 | wps 7916.3 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.326
2022-01-31 22:32:03 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-31 22:32:03 | INFO | train | epoch 141 | loss 5.508 | ppl 45.5 | wps 5963.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.936 | train_wall 322 | gb_free 6.1 | wall 49232
KL Stats: Epoch 141 Divergences: Uniform: 2.9578667965350127 Unigram: 4.747178242992836
2022-01-31 22:32:03 | INFO | fairseq.trainer | begin training epoch 142
2022-01-31 22:32:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:37:54 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.308 | ppl 1267.72 | wps 7955.1 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.326
2022-01-31 22:37:54 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-31 22:37:54 | INFO | train | epoch 142 | loss 5.499 | ppl 45.22 | wps 5952.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.949 | train_wall 323 | gb_free 6.1 | wall 49583
KL Stats: Epoch 142 Divergences: Uniform: 2.9559981076917383 Unigram: 4.753810440652697
2022-01-31 22:37:54 | INFO | fairseq.trainer | begin training epoch 143
2022-01-31 22:37:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:38:55 | INFO | train_inner | epoch 143:     12 / 64 loss=5.501, ppl=45.28, wps=5826.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.945, train_wall=503, gb_free=6.1, wall=49644
2022-01-31 22:43:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:43:45 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.365 | ppl 1318.93 | wps 7952.1 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.326
2022-01-31 22:43:45 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-31 22:43:45 | INFO | train | epoch 143 | loss 5.494 | ppl 45.06 | wps 5956 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.967 | train_wall 322 | gb_free 6.1 | wall 49934
KL Stats: Epoch 143 Divergences: Uniform: 2.9670587138393114 Unigram: 4.763425698769235
2022-01-31 22:43:45 | INFO | fairseq.trainer | begin training epoch 144
2022-01-31 22:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:47:47 | INFO | train_inner | epoch 144:     48 / 64 loss=5.489, ppl=44.92, wps=6143.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.967, train_wall=503, gb_free=6.1, wall=50176
2022-01-31 22:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:49:34 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.39 | ppl 1342.29 | wps 7933.9 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.326
2022-01-31 22:49:34 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-31 22:49:34 | INFO | train | epoch 144 | loss 5.485 | ppl 44.8 | wps 5974.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.965 | train_wall 321 | gb_free 6.1 | wall 50283
KL Stats: Epoch 144 Divergences: Uniform: 2.9577879231609985 Unigram: 4.7651672522015325
2022-01-31 22:49:34 | INFO | fairseq.trainer | begin training epoch 145
2022-01-31 22:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:55:25 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.422 | ppl 1371.71 | wps 7959.1 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.326
2022-01-31 22:55:25 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-31 22:55:25 | INFO | train | epoch 145 | loss 5.476 | ppl 44.51 | wps 5953 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.951 | train_wall 322 | gb_free 6.1 | wall 50634
KL Stats: Epoch 145 Divergences: Uniform: 2.967391096111726 Unigram: 4.781376787889179
2022-01-31 22:55:25 | INFO | fairseq.trainer | begin training epoch 146
2022-01-31 22:55:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:57:07 | INFO | train_inner | epoch 146:     20 / 64 loss=5.473, ppl=44.43, wps=5824.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.961, train_wall=503, gb_free=6.1, wall=50736
2022-01-31 23:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:01:16 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.347 | ppl 1302.37 | wps 7935 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.326
2022-01-31 23:01:16 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-31 23:01:16 | INFO | train | epoch 146 | loss 5.468 | ppl 44.26 | wps 5956.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.988 | train_wall 322 | gb_free 6.1 | wall 50985
KL Stats: Epoch 146 Divergences: Uniform: 2.963370392600854 Unigram: 4.788961304699745
2022-01-31 23:01:16 | INFO | fairseq.trainer | begin training epoch 147
2022-01-31 23:01:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:06:00 | INFO | train_inner | epoch 147:     56 / 64 loss=5.47, ppl=44.31, wps=6130.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.992, train_wall=504, gb_free=6.1, wall=51269
2022-01-31 23:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:07:05 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.319 | ppl 1277.7 | wps 8111.4 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.326
2022-01-31 23:07:05 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-31 23:07:05 | INFO | train | epoch 147 | loss 5.461 | ppl 44.03 | wps 5974.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.998 | train_wall 322 | gb_free 6.1 | wall 51334
KL Stats: Epoch 147 Divergences: Uniform: 2.968024547503252 Unigram: 4.795234353395235
2022-01-31 23:07:05 | INFO | fairseq.trainer | begin training epoch 148
2022-01-31 23:07:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:12:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:12:56 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.344 | ppl 1300.1 | wps 7919.9 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.326
2022-01-31 23:12:56 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-31 23:12:56 | INFO | train | epoch 148 | loss 5.451 | ppl 43.74 | wps 5961.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.981 | train_wall 322 | gb_free 6.1 | wall 51685
KL Stats: Epoch 148 Divergences: Uniform: 2.970875453483355 Unigram: 4.814836934678458
2022-01-31 23:12:56 | INFO | fairseq.trainer | begin training epoch 149
2022-01-31 23:12:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:15:18 | INFO | train_inner | epoch 149:     28 / 64 loss=5.447, ppl=43.62, wps=5842.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.99, train_wall=502, gb_free=6.1, wall=51827
2022-01-31 23:18:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:18:46 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.364 | ppl 1317.92 | wps 7940.1 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.326
2022-01-31 23:18:46 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-31 23:18:46 | INFO | train | epoch 149 | loss 5.447 | ppl 43.63 | wps 5963.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 1.03 | train_wall 322 | gb_free 6.1 | wall 52035
KL Stats: Epoch 149 Divergences: Uniform: 2.9728071771089204 Unigram: 4.820278068674547
2022-01-31 23:18:46 | INFO | fairseq.trainer | begin training epoch 150
2022-01-31 23:18:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:24:09 | INFO | train_inner | epoch 150:     64 / 64 loss=5.449, ppl=43.67, wps=6138.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=1.017, train_wall=502, gb_free=6.1, wall=52358
2022-01-31 23:24:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:24:36 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.406 | ppl 1356.62 | wps 7911.8 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.326
2022-01-31 23:24:36 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-31 23:24:36 | INFO | train | epoch 150 | loss 5.437 | ppl 43.32 | wps 5961.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.999 | train_wall 322 | gb_free 6.1 | wall 52385
KL Stats: Epoch 150 Divergences: Uniform: 2.973089248087477 Unigram: 4.815940756613659
2022-01-31 23:24:36 | INFO | fairseq.trainer | begin training epoch 151
2022-01-31 23:24:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:29:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:30:25 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.395 | ppl 1346.83 | wps 7918.5 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.326
2022-01-31 23:30:25 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-31 23:30:25 | INFO | train | epoch 151 | loss 5.429 | ppl 43.07 | wps 5983.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.012 | train_wall 321 | gb_free 6.1 | wall 52734
KL Stats: Epoch 151 Divergences: Uniform: 2.9696210993696095 Unigram: 4.833747653182327
2022-01-31 23:30:25 | INFO | fairseq.trainer | begin training epoch 152
2022-01-31 23:30:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:33:28 | INFO | train_inner | epoch 152:     36 / 64 loss=5.416, ppl=42.7, wps=5845.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.018, train_wall=502, gb_free=6.1, wall=52917
2022-01-31 23:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:36:16 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.405 | ppl 1355.57 | wps 7922.5 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.326
2022-01-31 23:36:16 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-31 23:36:16 | INFO | train | epoch 152 | loss 5.422 | ppl 42.86 | wps 5959.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.016 | train_wall 322 | gb_free 6.1 | wall 53085
KL Stats: Epoch 152 Divergences: Uniform: 2.9755798518472494 Unigram: 4.846741600138211
2022-01-31 23:36:16 | INFO | fairseq.trainer | begin training epoch 153
2022-01-31 23:36:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:41:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:42:07 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.447 | ppl 1396.14 | wps 7973.7 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.326
2022-01-31 23:42:07 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-31 23:42:07 | INFO | train | epoch 153 | loss 5.413 | ppl 42.61 | wps 5948.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.992 | train_wall 323 | gb_free 6.1 | wall 53436
KL Stats: Epoch 153 Divergences: Uniform: 2.976073612597483 Unigram: 4.856112391695784
2022-01-31 23:42:07 | INFO | fairseq.trainer | begin training epoch 154
2022-01-31 23:42:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:42:47 | INFO | train_inner | epoch 154:      8 / 64 loss=5.421, ppl=42.85, wps=5823.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.998, train_wall=503, gb_free=6.1, wall=53476
2022-01-31 23:47:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:47:57 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.436 | ppl 1385.55 | wps 7989.9 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.326
2022-01-31 23:47:57 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-31 23:47:57 | INFO | train | epoch 154 | loss 5.408 | ppl 42.46 | wps 5959.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.035 | train_wall 322 | gb_free 6.1 | wall 53786
KL Stats: Epoch 154 Divergences: Uniform: 2.9810862469239283 Unigram: 4.857268663601933
2022-01-31 23:47:57 | INFO | fairseq.trainer | begin training epoch 155
2022-01-31 23:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:51:39 | INFO | train_inner | epoch 155:     44 / 64 loss=5.399, ppl=42.2, wps=6144.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.036, train_wall=503, gb_free=6.1, wall=54008
2022-01-31 23:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:53:47 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.385 | ppl 1336.99 | wps 7955.3 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.326
2022-01-31 23:53:47 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-31 23:53:47 | INFO | train | epoch 155 | loss 5.401 | ppl 42.25 | wps 5979.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.044 | train_wall 321 | gb_free 6.1 | wall 54136
KL Stats: Epoch 155 Divergences: Uniform: 2.9841395142974716 Unigram: 4.877648546174004
2022-01-31 23:53:47 | INFO | fairseq.trainer | begin training epoch 156
2022-01-31 23:53:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:59:37 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.458 | ppl 1406.57 | wps 7934.6 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.326
2022-01-31 23:59:37 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-31 23:59:37 | INFO | train | epoch 156 | loss 5.394 | ppl 42.05 | wps 5954.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.054 | train_wall 322 | gb_free 6.1 | wall 54486
KL Stats: Epoch 156 Divergences: Uniform: 2.9802092739702912 Unigram: 4.878030227757643
2022-01-31 23:59:37 | INFO | fairseq.trainer | begin training epoch 157
2022-01-31 23:59:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:00:59 | INFO | train_inner | epoch 157:     16 / 64 loss=5.399, ppl=42.21, wps=5828.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.046, train_wall=503, gb_free=6.1, wall=54568
2022-02-01 00:05:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:05:29 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.442 | ppl 1391.18 | wps 7946.2 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.326
2022-02-01 00:05:29 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-01 00:05:29 | INFO | train | epoch 157 | loss 5.386 | ppl 41.82 | wps 5948.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.024 | train_wall 323 | gb_free 6.1 | wall 54838
KL Stats: Epoch 157 Divergences: Uniform: 2.984939463234879 Unigram: 4.8915829757981655
2022-02-01 00:05:29 | INFO | fairseq.trainer | begin training epoch 158
2022-02-01 00:05:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:09:52 | INFO | train_inner | epoch 158:     52 / 64 loss=5.38, ppl=41.65, wps=6130.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.047, train_wall=504, gb_free=6.1, wall=55101
2022-02-01 00:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:11:18 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.44 | ppl 1389.46 | wps 7888.7 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.326
2022-02-01 00:11:18 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-01 00:11:18 | INFO | train | epoch 158 | loss 5.382 | ppl 41.69 | wps 5969 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.068 | train_wall 321 | gb_free 6.1 | wall 55187
KL Stats: Epoch 158 Divergences: Uniform: 2.981100016469909 Unigram: 4.895714819510672
2022-02-01 00:11:18 | INFO | fairseq.trainer | begin training epoch 159
2022-02-01 00:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:16:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:17:09 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.457 | ppl 1405.15 | wps 7921 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.326
2022-02-01 00:17:09 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-01 00:17:09 | INFO | train | epoch 159 | loss 5.373 | ppl 41.44 | wps 5953.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.075 | train_wall 322 | gb_free 6.1 | wall 55538
KL Stats: Epoch 159 Divergences: Uniform: 2.9847001847403876 Unigram: 4.912320133637599
2022-02-01 00:17:09 | INFO | fairseq.trainer | begin training epoch 160
2022-02-01 00:17:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:19:11 | INFO | train_inner | epoch 160:     24 / 64 loss=5.372, ppl=41.43, wps=5829.8, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.076, train_wall=502, gb_free=6.1, wall=55660
2022-02-01 00:22:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:23:00 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.473 | ppl 1421.17 | wps 7968.2 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.326
2022-02-01 00:23:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-01 00:23:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint160.pt
2022-02-01 00:23:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint160.pt
2022-02-01 00:23:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.473) (writing took 3.8460837863385677 seconds)
2022-02-01 00:23:04 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-01 00:23:04 | INFO | train | epoch 160 | loss 5.367 | ppl 41.26 | wps 5890.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.041 | train_wall 322 | gb_free 6.1 | wall 55893
KL Stats: Epoch 160 Divergences: Uniform: 2.9856770664016987 Unigram: 4.922376669516735
2022-02-01 00:23:04 | INFO | fairseq.trainer | begin training epoch 161
2022-02-01 00:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:28:08 | INFO | train_inner | epoch 161:     60 / 64 loss=5.368, ppl=41.3, wps=6083, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.051, train_wall=505, gb_free=6.1, wall=56197
2022-02-01 00:28:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:28:55 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.374 | ppl 1327.43 | wps 7954 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.326
2022-02-01 00:28:55 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-01 00:28:55 | INFO | train | epoch 161 | loss 5.361 | ppl 41.09 | wps 5952.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.066 | train_wall 323 | gb_free 6.1 | wall 56244
KL Stats: Epoch 161 Divergences: Uniform: 2.988834571372759 Unigram: 4.92429793933948
2022-02-01 00:28:55 | INFO | fairseq.trainer | begin training epoch 162
2022-02-01 00:28:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:34:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:34:44 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.457 | ppl 1405.7 | wps 7957.3 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.326
2022-02-01 00:34:44 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-01 00:34:44 | INFO | train | epoch 162 | loss 5.352 | ppl 40.86 | wps 5982.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.046 | train_wall 321 | gb_free 6.1 | wall 56593
KL Stats: Epoch 162 Divergences: Uniform: 2.9962826371986604 Unigram: 4.934040904521307
2022-02-01 00:34:44 | INFO | fairseq.trainer | begin training epoch 163
2022-02-01 00:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:37:26 | INFO | train_inner | epoch 163:     32 / 64 loss=5.34, ppl=40.5, wps=5846.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.057, train_wall=501, gb_free=6.1, wall=56755
2022-02-01 00:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:40:34 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.522 | ppl 1470.1 | wps 7960.7 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.326
2022-02-01 00:40:34 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-01 00:40:34 | INFO | train | epoch 163 | loss 5.35 | ppl 40.78 | wps 5958.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.093 | train_wall 322 | gb_free 6.1 | wall 56943
KL Stats: Epoch 163 Divergences: Uniform: 2.9887244471750205 Unigram: 4.947805474506079
2022-02-01 00:40:34 | INFO | fairseq.trainer | begin training epoch 164
2022-02-01 00:40:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:45:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:46:20 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.417 | ppl 1367.5 | wps 8314.6 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.326
2022-02-01 00:46:20 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-01 00:46:20 | INFO | train | epoch 164 | loss 5.341 | ppl 40.54 | wps 6041.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.1 | train_wall 319 | gb_free 6.1 | wall 57289
KL Stats: Epoch 164 Divergences: Uniform: 2.9881662757355425 Unigram: 4.949558263771067
2022-02-01 00:46:20 | INFO | fairseq.trainer | begin training epoch 165
2022-02-01 00:46:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:46:40 | INFO | train_inner | epoch 165:      4 / 64 loss=5.356, ppl=40.97, wps=5886, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.1, train_wall=499, gb_free=6.1, wall=57309
2022-02-01 00:51:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:51:58 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.468 | ppl 1416.63 | wps 8322.7 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.326
2022-02-01 00:51:58 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-01 00:51:58 | INFO | train | epoch 165 | loss 5.333 | ppl 40.31 | wps 6180.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.079 | train_wall 311 | gb_free 6.1 | wall 57627
KL Stats: Epoch 165 Divergences: Uniform: 2.994881500628489 Unigram: 4.9666141733507345
2022-02-01 00:51:58 | INFO | fairseq.trainer | begin training epoch 166
2022-02-01 00:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:55:14 | INFO | train_inner | epoch 166:     40 / 64 loss=5.327, ppl=40.14, wps=6359, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.102, train_wall=486, gb_free=6.1, wall=57823
2022-02-01 00:57:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:57:36 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.363 | ppl 1317.33 | wps 8319.8 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.326
2022-02-01 00:57:36 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-01 00:57:36 | INFO | train | epoch 166 | loss 5.33 | ppl 40.23 | wps 6179.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.122 | train_wall 311 | gb_free 6.1 | wall 57965
KL Stats: Epoch 166 Divergences: Uniform: 2.9992728981504 Unigram: 4.971394016326823
2022-02-01 00:57:36 | INFO | fairseq.trainer | begin training epoch 167
2022-02-01 00:57:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:03:15 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.359 | ppl 1313.38 | wps 8308.1 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.326
2022-02-01 01:03:15 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-01 01:03:15 | INFO | train | epoch 167 | loss 5.323 | ppl 40.03 | wps 6168.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.121 | train_wall 311 | gb_free 6.1 | wall 58304
KL Stats: Epoch 167 Divergences: Uniform: 2.9950113051000087 Unigram: 4.9742442550947015
2022-02-01 01:03:15 | INFO | fairseq.trainer | begin training epoch 168
2022-02-01 01:03:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:04:13 | INFO | train_inner | epoch 168:     12 / 64 loss=5.325, ppl=40.09, wps=6039.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.117, train_wall=486, gb_free=6.1, wall=58362
2022-02-01 01:08:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:08:53 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.485 | ppl 1432.75 | wps 8354.5 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.326
2022-02-01 01:08:53 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-01 01:08:53 | INFO | train | epoch 168 | loss 5.318 | ppl 39.89 | wps 6174.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.128 | train_wall 311 | gb_free 6.1 | wall 58642
KL Stats: Epoch 168 Divergences: Uniform: 3.000312554799235 Unigram: 4.978208199639454
2022-02-01 01:08:53 | INFO | fairseq.trainer | begin training epoch 169
2022-02-01 01:08:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:12:48 | INFO | train_inner | epoch 169:     48 / 64 loss=5.317, ppl=39.86, wps=6353.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.124, train_wall=487, gb_free=6.1, wall=58877
2022-02-01 01:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:14:31 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.442 | ppl 1390.67 | wps 8341 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.326
2022-02-01 01:14:31 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-01 01:14:31 | INFO | train | epoch 169 | loss 5.312 | ppl 39.71 | wps 6182 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.118 | train_wall 311 | gb_free 6.1 | wall 58980
KL Stats: Epoch 169 Divergences: Uniform: 2.9983674913737386 Unigram: 4.990433999394714
2022-02-01 01:14:31 | INFO | fairseq.trainer | begin training epoch 170
2022-02-01 01:14:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:19:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:20:09 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.483 | ppl 1431.53 | wps 8352.5 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.326
2022-02-01 01:20:09 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-01 01:20:09 | INFO | train | epoch 170 | loss 5.306 | ppl 39.55 | wps 6174.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.128 | train_wall 311 | gb_free 6.1 | wall 59318
KL Stats: Epoch 170 Divergences: Uniform: 3.0005937742223963 Unigram: 4.998865152537638
2022-02-01 01:20:09 | INFO | fairseq.trainer | begin training epoch 171
2022-02-01 01:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:21:47 | INFO | train_inner | epoch 171:     20 / 64 loss=5.3, ppl=39.4, wps=6049, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.137, train_wall=485, gb_free=6.1, wall=59416
2022-02-01 01:25:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:25:47 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.471 | ppl 1419.8 | wps 8317.2 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.326
2022-02-01 01:25:47 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-01 01:25:47 | INFO | train | epoch 171 | loss 5.3 | ppl 39.4 | wps 6181 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.181 | train_wall 311 | gb_free 6.1 | wall 59656
KL Stats: Epoch 171 Divergences: Uniform: 3.000937250419241 Unigram: 5.008228403168469
2022-02-01 01:25:47 | INFO | fairseq.trainer | begin training epoch 172
2022-02-01 01:25:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:30:21 | INFO | train_inner | epoch 172:     56 / 64 loss=5.303, ppl=39.48, wps=6352.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.167, train_wall=487, gb_free=6.1, wall=59930
2022-02-01 01:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:31:25 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.458 | ppl 1406.26 | wps 8345.8 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.326
2022-02-01 01:31:25 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-01 01:31:25 | INFO | train | epoch 172 | loss 5.294 | ppl 39.23 | wps 6173.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.164 | train_wall 311 | gb_free 6.1 | wall 59994
KL Stats: Epoch 172 Divergences: Uniform: 3.0039760474887784 Unigram: 5.011681364315963
2022-02-01 01:31:25 | INFO | fairseq.trainer | begin training epoch 173
2022-02-01 01:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:36:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:37:04 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.395 | ppl 1346.09 | wps 8337.4 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.326
2022-02-01 01:37:04 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-01 01:37:04 | INFO | train | epoch 173 | loss 5.287 | ppl 39.05 | wps 6163.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.175 | train_wall 312 | gb_free 6.1 | wall 60333
KL Stats: Epoch 173 Divergences: Uniform: 3.00334954737982 Unigram: 5.0166818895606635
2022-02-01 01:37:04 | INFO | fairseq.trainer | begin training epoch 174
2022-02-01 01:37:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:39:21 | INFO | train_inner | epoch 174:     28 / 64 loss=5.281, ppl=38.88, wps=6037.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.163, train_wall=486, gb_free=6.1, wall=60470
2022-02-01 01:42:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:42:43 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.473 | ppl 1421.64 | wps 8294.8 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.326
2022-02-01 01:42:43 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-01 01:42:43 | INFO | train | epoch 174 | loss 5.283 | ppl 38.93 | wps 6170.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.165 | train_wall 311 | gb_free 6.1 | wall 60672
KL Stats: Epoch 174 Divergences: Uniform: 3.0051567015836254 Unigram: 5.029634433378922
2022-02-01 01:42:43 | INFO | fairseq.trainer | begin training epoch 175
2022-02-01 01:42:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:47:55 | INFO | train_inner | epoch 175:     64 / 64 loss=5.287, ppl=39.03, wps=6348.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.177, train_wall=486, gb_free=6.1, wall=60984
2022-02-01 01:47:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:48:21 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.534 | ppl 1482.38 | wps 8339.7 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.326
2022-02-01 01:48:21 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-01 01:48:21 | INFO | train | epoch 175 | loss 5.275 | ppl 38.73 | wps 6176.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.165 | train_wall 311 | gb_free 6.1 | wall 61010
KL Stats: Epoch 175 Divergences: Uniform: 3.015325232606118 Unigram: 5.039678662076189
2022-02-01 01:48:21 | INFO | fairseq.trainer | begin training epoch 176
2022-02-01 01:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:53:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:53:59 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.52 | ppl 1468.83 | wps 8307.3 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.326
2022-02-01 01:53:59 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-01 01:53:59 | INFO | train | epoch 176 | loss 5.271 | ppl 38.62 | wps 6175.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.18 | train_wall 311 | gb_free 6.1 | wall 61348
KL Stats: Epoch 176 Divergences: Uniform: 3.0099425586763084 Unigram: 5.046631055147024
2022-02-01 01:53:59 | INFO | fairseq.trainer | begin training epoch 177
2022-02-01 01:53:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:56:56 | INFO | train_inner | epoch 177:     36 / 64 loss=5.258, ppl=38.27, wps=6041.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.187, train_wall=487, gb_free=6.1, wall=61524
2022-02-01 01:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:59:38 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.424 | ppl 1373.76 | wps 8309.1 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.326
2022-02-01 01:59:38 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-01 01:59:38 | INFO | train | epoch 177 | loss 5.265 | ppl 38.45 | wps 6166 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.217 | train_wall 312 | gb_free 6.1 | wall 61687
KL Stats: Epoch 177 Divergences: Uniform: 3.0112642756156056 Unigram: 5.050980110777996
2022-02-01 01:59:38 | INFO | fairseq.trainer | begin training epoch 178
2022-02-01 01:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:04:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:05:16 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.498 | ppl 1446.53 | wps 8299.9 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.326
2022-02-01 02:05:16 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-01 02:05:16 | INFO | train | epoch 178 | loss 5.262 | ppl 38.38 | wps 6173.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.203 | train_wall 311 | gb_free 6.1 | wall 62025
KL Stats: Epoch 178 Divergences: Uniform: 3.0118346679914385 Unigram: 5.055410763553868
2022-02-01 02:05:16 | INFO | fairseq.trainer | begin training epoch 179
2022-02-01 02:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:05:55 | INFO | train_inner | epoch 179:      8 / 64 loss=5.269, ppl=38.57, wps=6040.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.21, train_wall=486, gb_free=6.1, wall=62064
2022-02-01 02:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:10:54 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.44 | ppl 1388.73 | wps 8304.1 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.326
2022-02-01 02:10:54 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-01 02:10:54 | INFO | train | epoch 179 | loss 5.255 | ppl 38.19 | wps 6180.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.198 | train_wall 311 | gb_free 6.1 | wall 62363
KL Stats: Epoch 179 Divergences: Uniform: 3.0139144278609695 Unigram: 5.063057981593525
2022-02-01 02:10:54 | INFO | fairseq.trainer | begin training epoch 180
2022-02-01 02:10:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:14:29 | INFO | train_inner | epoch 180:     44 / 64 loss=5.25, ppl=38.06, wps=6355.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.203, train_wall=487, gb_free=6.1, wall=62578
2022-02-01 02:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:16:32 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.422 | ppl 1372.27 | wps 8294.5 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.326
2022-02-01 02:16:32 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-01 02:16:32 | INFO | train | epoch 180 | loss 5.251 | ppl 38.09 | wps 6169.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.222 | train_wall 311 | gb_free 6.1 | wall 62701
KL Stats: Epoch 180 Divergences: Uniform: 3.015776991050507 Unigram: 5.070970856979377
2022-02-01 02:16:33 | INFO | fairseq.trainer | begin training epoch 181
2022-02-01 02:16:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:21:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:22:11 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.488 | ppl 1436.01 | wps 8353 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.326
2022-02-01 02:22:11 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-01 02:22:11 | INFO | train | epoch 181 | loss 5.243 | ppl 37.87 | wps 6176.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.216 | train_wall 311 | gb_free 6.1 | wall 63040
KL Stats: Epoch 181 Divergences: Uniform: 3.0187921644685747 Unigram: 5.081654839657489
2022-02-01 02:22:11 | INFO | fairseq.trainer | begin training epoch 182
2022-02-01 02:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:23:29 | INFO | train_inner | epoch 182:     16 / 64 loss=5.244, ppl=37.91, wps=6041.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.23, train_wall=486, gb_free=6.1, wall=63118
2022-02-01 02:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:27:49 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.41 | ppl 1360.67 | wps 8322.5 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.326
2022-02-01 02:27:49 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-01 02:27:49 | INFO | train | epoch 182 | loss 5.241 | ppl 37.82 | wps 6178.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.241 | train_wall 311 | gb_free 6.1 | wall 63378
KL Stats: Epoch 182 Divergences: Uniform: 3.019154154032112 Unigram: 5.0797379849701
2022-02-01 02:27:49 | INFO | fairseq.trainer | begin training epoch 183
2022-02-01 02:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:32:03 | INFO | train_inner | epoch 183:     52 / 64 loss=5.239, ppl=37.77, wps=6358.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.262, train_wall=486, gb_free=6.1, wall=63632
2022-02-01 02:33:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:33:27 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.437 | ppl 1386.39 | wps 8308.1 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.326
2022-02-01 02:33:27 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-01 02:33:27 | INFO | train | epoch 183 | loss 5.236 | ppl 37.68 | wps 6182.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.274 | train_wall 311 | gb_free 6.1 | wall 63715
KL Stats: Epoch 183 Divergences: Uniform: 3.019949897151495 Unigram: 5.095525725492096
2022-02-01 02:33:27 | INFO | fairseq.trainer | begin training epoch 184
2022-02-01 02:33:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:39:04 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.43 | ppl 1379.62 | wps 8309.8 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.326
2022-02-01 02:39:04 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-01 02:39:04 | INFO | train | epoch 184 | loss 5.231 | ppl 37.55 | wps 6184 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.235 | train_wall 311 | gb_free 6.1 | wall 64053
KL Stats: Epoch 184 Divergences: Uniform: 3.0190379417477002 Unigram: 5.096809579381083
2022-02-01 02:39:04 | INFO | fairseq.trainer | begin training epoch 185
2022-02-01 02:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:41:02 | INFO | train_inner | epoch 185:     24 / 64 loss=5.231, ppl=37.54, wps=6050.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.241, train_wall=485, gb_free=6.1, wall=64171
2022-02-01 02:44:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:44:42 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.48 | ppl 1427.78 | wps 8304.9 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.326
2022-02-01 02:44:42 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-01 02:44:42 | INFO | train | epoch 185 | loss 5.226 | ppl 37.44 | wps 6180.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.283 | train_wall 311 | gb_free 6.1 | wall 64391
KL Stats: Epoch 185 Divergences: Uniform: 3.016914206825253 Unigram: 5.106786464195065
2022-02-01 02:44:42 | INFO | fairseq.trainer | begin training epoch 186
2022-02-01 02:44:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:49:36 | INFO | train_inner | epoch 186:     60 / 64 loss=5.227, ppl=37.46, wps=6360.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.292, train_wall=486, gb_free=6.1, wall=64685
2022-02-01 02:49:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:50:20 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.411 | ppl 1361.39 | wps 8360 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.326
2022-02-01 02:50:20 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-01 02:50:20 | INFO | train | epoch 186 | loss 5.223 | ppl 37.34 | wps 6185.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.29 | train_wall 311 | gb_free 6.1 | wall 64729
KL Stats: Epoch 186 Divergences: Uniform: 3.017672078005219 Unigram: 5.110796530723995
2022-02-01 02:50:20 | INFO | fairseq.trainer | begin training epoch 187
2022-02-01 02:50:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:55:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:55:58 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.482 | ppl 1430.5 | wps 8306.4 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.326
2022-02-01 02:55:58 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-01 02:55:58 | INFO | train | epoch 187 | loss 5.217 | ppl 37.2 | wps 6182.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.263 | train_wall 311 | gb_free 6.1 | wall 65067
KL Stats: Epoch 187 Divergences: Uniform: 3.020967771358295 Unigram: 5.118241081542562
2022-02-01 02:55:58 | INFO | fairseq.trainer | begin training epoch 188
2022-02-01 02:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:58:34 | INFO | train_inner | epoch 188:     32 / 64 loss=5.21, ppl=37.01, wps=6053.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.272, train_wall=485, gb_free=6.1, wall=65223
2022-02-01 03:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:01:36 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.476 | ppl 1424.66 | wps 8311.3 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.326
2022-02-01 03:01:36 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-01 03:01:36 | INFO | train | epoch 188 | loss 5.209 | ppl 37 | wps 6178.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.279 | train_wall 311 | gb_free 6.1 | wall 65405
KL Stats: Epoch 188 Divergences: Uniform: 3.019819845583933 Unigram: 5.126205599260394
2022-02-01 03:01:36 | INFO | fairseq.trainer | begin training epoch 189
2022-02-01 03:01:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:07:13 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.441 | ppl 1390.09 | wps 8334.8 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.326
2022-02-01 03:07:13 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-01 03:07:13 | INFO | train | epoch 189 | loss 5.207 | ppl 36.95 | wps 6186.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.335 | train_wall 311 | gb_free 6.1 | wall 65742
KL Stats: Epoch 189 Divergences: Uniform: 3.0199039292451917 Unigram: 5.1277280512038095
2022-02-01 03:07:13 | INFO | fairseq.trainer | begin training epoch 190
2022-02-01 03:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:07:33 | INFO | train_inner | epoch 190:      4 / 64 loss=5.213, ppl=37.08, wps=6048.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.313, train_wall=485, gb_free=6.1, wall=65762
2022-02-01 03:12:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:12:52 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.454 | ppl 1403.15 | wps 8325.1 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.326
2022-02-01 03:12:52 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-01 03:12:52 | INFO | train | epoch 190 | loss 5.201 | ppl 36.78 | wps 6174.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.3 | train_wall 311 | gb_free 6.1 | wall 66081
KL Stats: Epoch 190 Divergences: Uniform: 3.0226450112466012 Unigram: 5.1327704773761935
2022-02-01 03:12:52 | INFO | fairseq.trainer | begin training epoch 191
2022-02-01 03:12:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:16:07 | INFO | train_inner | epoch 191:     40 / 64 loss=5.19, ppl=36.5, wps=6361.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.293, train_wall=486, gb_free=6.1, wall=66276
2022-02-01 03:18:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:18:29 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.454 | ppl 1402.27 | wps 8370.3 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.326
2022-02-01 03:18:29 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-01 03:18:29 | INFO | train | epoch 191 | loss 5.196 | ppl 36.66 | wps 6190.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.277 | train_wall 310 | gb_free 6.1 | wall 66418
KL Stats: Epoch 191 Divergences: Uniform: 3.023339571446987 Unigram: 5.142581513866657
2022-02-01 03:18:29 | INFO | fairseq.trainer | begin training epoch 192
2022-02-01 03:18:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:23:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:24:07 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.476 | ppl 1424.34 | wps 8327.3 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.326
2022-02-01 03:24:07 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-01 03:24:07 | INFO | train | epoch 192 | loss 5.193 | ppl 36.58 | wps 6185.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.338 | train_wall 311 | gb_free 6.1 | wall 66756
KL Stats: Epoch 192 Divergences: Uniform: 3.0228202068906227 Unigram: 5.143725730237356
2022-02-01 03:24:07 | INFO | fairseq.trainer | begin training epoch 193
2022-02-01 03:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:25:05 | INFO | train_inner | epoch 193:     12 / 64 loss=5.199, ppl=36.74, wps=6053.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.328, train_wall=485, gb_free=6.1, wall=66814
2022-02-01 03:29:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:29:45 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.466 | ppl 1414.78 | wps 8313.5 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.326
2022-02-01 03:29:45 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-01 03:29:45 | INFO | train | epoch 193 | loss 5.19 | ppl 36.5 | wps 6180.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.343 | train_wall 311 | gb_free 6.1 | wall 67094
KL Stats: Epoch 193 Divergences: Uniform: 3.026802161403407 Unigram: 5.153601186729461
2022-02-01 03:29:45 | INFO | fairseq.trainer | begin training epoch 194
2022-02-01 03:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:33:39 | INFO | train_inner | epoch 194:     48 / 64 loss=5.186, ppl=36.39, wps=6365.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.348, train_wall=486, gb_free=6.1, wall=67328
2022-02-01 03:34:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:35:22 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.435 | ppl 1384.71 | wps 8366.5 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.326
2022-02-01 03:35:22 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-01 03:35:22 | INFO | train | epoch 194 | loss 5.184 | ppl 36.36 | wps 6195.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.369 | train_wall 310 | gb_free 6.1 | wall 67431
KL Stats: Epoch 194 Divergences: Uniform: 3.0267364787251165 Unigram: 5.155686279005651
2022-02-01 03:35:22 | INFO | fairseq.trainer | begin training epoch 195
2022-02-01 03:35:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:41:00 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.464 | ppl 1412.64 | wps 8357.2 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.326
2022-02-01 03:41:00 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-01 03:41:00 | INFO | train | epoch 195 | loss 5.18 | ppl 36.25 | wps 6180.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.361 | train_wall 311 | gb_free 6.1 | wall 67769
KL Stats: Epoch 195 Divergences: Uniform: 3.0246999717742877 Unigram: 5.161739679955399
2022-02-01 03:41:00 | INFO | fairseq.trainer | begin training epoch 196
2022-02-01 03:41:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:42:38 | INFO | train_inner | epoch 196:     20 / 64 loss=5.178, ppl=36.2, wps=6048.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.356, train_wall=485, gb_free=6.1, wall=67867
2022-02-01 03:46:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:46:38 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.431 | ppl 1380.96 | wps 8327 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.326
2022-02-01 03:46:38 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-01 03:46:38 | INFO | train | epoch 196 | loss 5.176 | ppl 36.15 | wps 6167.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.352 | train_wall 312 | gb_free 6.1 | wall 68107
KL Stats: Epoch 196 Divergences: Uniform: 3.0263476945324257 Unigram: 5.169377428131848
2022-02-01 03:46:38 | INFO | fairseq.trainer | begin training epoch 197
2022-02-01 03:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:51:12 | INFO | train_inner | epoch 197:     56 / 64 loss=5.176, ppl=36.16, wps=6350.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.379, train_wall=487, gb_free=6.1, wall=68381
2022-02-01 03:51:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:52:16 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.515 | ppl 1462.97 | wps 8323.6 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.326
2022-02-01 03:52:16 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-01 03:52:16 | INFO | train | epoch 197 | loss 5.171 | ppl 36.04 | wps 6178.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.395 | train_wall 311 | gb_free 6.1 | wall 68445
KL Stats: Epoch 197 Divergences: Uniform: 3.0288804799675466 Unigram: 5.171969335448514
2022-02-01 03:52:16 | INFO | fairseq.trainer | begin training epoch 198
2022-02-01 03:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:57:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:57:54 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.461 | ppl 1409.24 | wps 8303.9 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.326
2022-02-01 03:57:54 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-01 03:57:54 | INFO | train | epoch 198 | loss 5.167 | ppl 35.94 | wps 6185.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.414 | train_wall 311 | gb_free 6.1 | wall 68783
KL Stats: Epoch 198 Divergences: Uniform: 3.030845318695624 Unigram: 5.185619835106468
2022-02-01 03:57:54 | INFO | fairseq.trainer | begin training epoch 199
2022-02-01 03:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:00:11 | INFO | train_inner | epoch 199:     28 / 64 loss=5.162, ppl=35.79, wps=6047.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.397, train_wall=485, gb_free=6.1, wall=68920
2022-02-01 04:03:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:03:33 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.437 | ppl 1386.43 | wps 8308.9 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.326
2022-02-01 04:03:33 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-01 04:03:33 | INFO | train | epoch 199 | loss 5.16 | ppl 35.76 | wps 6165.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.355 | train_wall 312 | gb_free 6.1 | wall 69122
KL Stats: Epoch 199 Divergences: Uniform: 3.0302740565628885 Unigram: 5.193646351813847
2022-02-01 04:03:33 | INFO | fairseq.trainer | begin training epoch 200
2022-02-01 04:03:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:08:45 | INFO | train_inner | epoch 200:     64 / 64 loss=5.17, ppl=35.99, wps=6347.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.39, train_wall=486, gb_free=6.1, wall=69434
2022-02-01 04:08:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:09:11 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.491 | ppl 1438.71 | wps 8304.1 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.326
2022-02-01 04:09:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-01 04:09:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint200.pt
2022-02-01 04:09:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint200.pt
2022-02-01 04:09:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.491) (writing took 3.643976854160428 seconds)
2022-02-01 04:09:15 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-01 04:09:15 | INFO | train | epoch 200 | loss 5.158 | ppl 35.7 | wps 6104.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.404 | train_wall 311 | gb_free 6.1 | wall 69464
KL Stats: Epoch 200 Divergences: Uniform: 3.0285782648942443 Unigram: 5.1993120202370555
2022-02-01 04:09:15 | INFO | fairseq.trainer | begin training epoch 201
2022-02-01 04:09:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:14:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:14:53 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.494 | ppl 1441.79 | wps 8295.7 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.326
2022-02-01 04:14:53 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-01 04:14:53 | INFO | train | epoch 201 | loss 5.155 | ppl 35.63 | wps 6172.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.418 | train_wall 311 | gb_free 6.1 | wall 69802
KL Stats: Epoch 201 Divergences: Uniform: 3.027663156396804 Unigram: 5.1950693989773615
2022-02-01 04:14:53 | INFO | fairseq.trainer | begin training epoch 202
2022-02-01 04:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:17:49 | INFO | train_inner | epoch 202:     36 / 64 loss=5.14, ppl=35.27, wps=6004.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.419, train_wall=487, gb_free=6.1, wall=69978
2022-02-01 04:20:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:20:31 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.484 | ppl 1432.59 | wps 8312.7 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.326
2022-02-01 04:20:31 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-01 04:20:31 | INFO | train | epoch 202 | loss 5.148 | ppl 35.46 | wps 6181 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.405 | train_wall 311 | gb_free 6.1 | wall 70140
KL Stats: Epoch 202 Divergences: Uniform: 3.028541582190509 Unigram: 5.210616738014204
2022-02-01 04:20:31 | INFO | fairseq.trainer | begin training epoch 203
2022-02-01 04:20:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:26:10 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.443 | ppl 1391.83 | wps 8325 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.326
2022-02-01 04:26:10 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-01 04:26:10 | INFO | train | epoch 203 | loss 5.145 | ppl 35.37 | wps 6161.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.455 | train_wall 312 | gb_free 6.1 | wall 70479
KL Stats: Epoch 203 Divergences: Uniform: 3.0285699207730894 Unigram: 5.2168153046609245
2022-02-01 04:26:10 | INFO | fairseq.trainer | begin training epoch 204
2022-02-01 04:26:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:26:49 | INFO | train_inner | epoch 204:      8 / 64 loss=5.153, ppl=35.58, wps=6033.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.431, train_wall=486, gb_free=6.1, wall=70518
2022-02-01 04:31:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:31:49 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.483 | ppl 1431.1 | wps 8325.4 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.326
2022-02-01 04:31:49 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-01 04:31:49 | INFO | train | epoch 204 | loss 5.139 | ppl 35.25 | wps 6167.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.438 | train_wall 312 | gb_free 6.1 | wall 70818
KL Stats: Epoch 204 Divergences: Uniform: 3.035448135083059 Unigram: 5.221081664283911
2022-02-01 04:31:49 | INFO | fairseq.trainer | begin training epoch 205
2022-02-01 04:31:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:35:24 | INFO | train_inner | epoch 205:     44 / 64 loss=5.135, ppl=35.13, wps=6346.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.448, train_wall=487, gb_free=6.1, wall=71033
2022-02-01 04:37:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:37:27 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.495 | ppl 1443.33 | wps 8310.5 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.326
2022-02-01 04:37:27 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-01 04:37:27 | INFO | train | epoch 205 | loss 5.135 | ppl 35.14 | wps 6169.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.457 | train_wall 311 | gb_free 6.1 | wall 71156
KL Stats: Epoch 205 Divergences: Uniform: 3.0338626720616406 Unigram: 5.231691087027735
2022-02-01 04:37:27 | INFO | fairseq.trainer | begin training epoch 206
2022-02-01 04:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:42:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:43:06 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.496 | ppl 1444.49 | wps 8310 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.326
2022-02-01 04:43:06 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-01 04:43:06 | INFO | train | epoch 206 | loss 5.132 | ppl 35.06 | wps 6168.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.43 | train_wall 311 | gb_free 6.1 | wall 71495
KL Stats: Epoch 206 Divergences: Uniform: 3.031974173840871 Unigram: 5.23500968824743
2022-02-01 04:43:06 | INFO | fairseq.trainer | begin training epoch 207
2022-02-01 04:43:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:44:24 | INFO | train_inner | epoch 207:     16 / 64 loss=5.133, ppl=35.1, wps=6039.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.439, train_wall=486, gb_free=6.1, wall=71573
2022-02-01 04:48:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:48:44 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.515 | ppl 1463.37 | wps 8250.3 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.326
2022-02-01 04:48:44 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-02-01 04:48:44 | INFO | train | epoch 207 | loss 5.129 | ppl 35 | wps 6173.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.482 | train_wall 311 | gb_free 6.1 | wall 71833
KL Stats: Epoch 207 Divergences: Uniform: 3.033549174593652 Unigram: 5.23813205520894
2022-02-01 04:48:44 | INFO | fairseq.trainer | begin training epoch 208
2022-02-01 04:48:44 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
Sender: LSF System <lsfadmin@eu-g2-12>
Subject: Job 202993363: <w2_jelinek_0.11_-0.01_0.9_#4> in cluster <euler> Exited

Job <w2_jelinek_0.11_-0.01_0.9_#4> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:06:15 2022
Job was executed on host(s) <eu-g2-12>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:06:34 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:06:34 2022
Terminated at Thu Feb  3 02:06:42 2022
Results reported at Thu Feb  3 02:06:42 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.11, -0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 402 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72903.00 sec.
    Max Memory :                                 6227 MB
    Average Memory :                             3764.72 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13773.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72007 sec.
    Turnaround time :                            72027 sec.

The output (if any) follows:

2022-02-02 06:06:42 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 402, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 402, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.11, -0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:06:42 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:06:43 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1418/36718 [00:00<00:02, 14172.85it/s]  8%|▊         | 2836/36718 [00:00<00:02, 13721.35it/s] 12%|█▏        | 4444/36718 [00:00<00:02, 14769.44it/s] 17%|█▋        | 6080/36718 [00:00<00:01, 15382.37it/s] 21%|██        | 7621/36718 [00:00<00:01, 14589.82it/s] 25%|██▍       | 9088/36718 [00:00<00:01, 14448.14it/s] 29%|██▊       | 10538/36718 [00:00<00:01, 14332.36it/s] 33%|███▎      | 12019/36718 [00:00<00:01, 14478.58it/s] 37%|███▋      | 13470/36718 [00:00<00:01, 14397.16it/s] 41%|████      | 14965/36718 [00:01<00:01, 14555.57it/s] 45%|████▍     | 16422/36718 [00:01<00:01, 14270.82it/s] 49%|████▊     | 17883/36718 [00:01<00:01, 14366.45it/s] 53%|█████▎    | 19480/36718 [00:01<00:01, 14828.44it/s] 57%|█████▋    | 20965/36718 [00:01<00:01, 14442.42it/s] 61%|██████    | 22413/36718 [00:01<00:00, 14337.04it/s] 65%|██████▌   | 24042/36718 [00:01<00:00, 14903.60it/s] 70%|██████▉   | 25624/36718 [00:01<00:00, 15173.97it/s] 74%|███████▍  | 27144/36718 [00:01<00:00, 14493.44it/s] 78%|███████▊  | 28668/36718 [00:01<00:00, 14707.84it/s] 82%|████████▏ | 30145/36718 [00:02<00:00, 14448.30it/s] 86%|████████▌ | 31595/36718 [00:02<00:00, 14079.54it/s] 90%|████████▉ | 33008/36718 [00:02<00:00, 13797.66it/s] 94%|█████████▍| 34427/36718 [00:02<00:00, 13908.95it/s] 98%|█████████▊| 35871/36718 [00:02<00:00, 14060.46it/s]100%|██████████| 36718/36718 [00:02<00:00, 14416.84it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2771/36718 [00:00<00:01, 27706.20it/s] 16%|█▋        | 6012/36718 [00:00<00:01, 30462.92it/s] 25%|██▍       | 9059/36718 [00:00<00:00, 29338.26it/s] 33%|███▎      | 11998/36718 [00:00<00:00, 29086.06it/s] 41%|████      | 14917/36718 [00:00<00:00, 29116.77it/s] 49%|████▊     | 17831/36718 [00:00<00:00, 28962.16it/s] 57%|█████▋    | 20807/36718 [00:00<00:00, 29213.11it/s] 65%|██████▍   | 23812/36718 [00:00<00:00, 29476.47it/s] 73%|███████▎  | 26801/36718 [00:00<00:00, 29599.94it/s] 81%|████████  | 29762/36718 [00:01<00:00, 29564.52it/s] 89%|████████▉ | 32719/36718 [00:01<00:00, 28869.44it/s] 97%|█████████▋| 35610/36718 [00:01<00:00, 28800.10it/s]100%|██████████| 36718/36718 [00:01<00:00, 29133.53it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 71.05it/s]2022-02-02 06:06:56 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:06:56 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:06:56 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:06:56 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:06:56 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:06:56 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:06:56 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:06:56 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:06:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:06:56 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-02-02 06:06:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:06:56 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:06:56 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:06:56 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint_last.pt
2022-02-02 06:06:56 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint_last.pt
2022-02-02 06:06:56 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:06:56 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:06:56 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:06:56 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:06:56 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:12:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:12:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.676 | ppl 26172.3 | wps 8603.4 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:12:28 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:12:28 | INFO | train | epoch 001 | loss 15.984 | ppl 64798.4 | wps 6306.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.233 | train_wall 305 | gb_free 6.1 | wall 332
KL Stats: Epoch 1 Divergences: Uniform: 0.532216525162478 Unigram: 3.5851457164491807
2022-02-02 06:12:28 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:15:21 | INFO | train_inner | epoch 002:     36 / 64 loss=15.464, ppl=45184.1, wps=6490.4, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.632, train_wall=477, gb_free=6.1, wall=505
2022-02-02 06:17:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:17:59 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.624 | ppl 12625.8 | wps 8628.6 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:17:59 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:17:59 | INFO | train | epoch 002 | loss 14.325 | ppl 20521.3 | wps 6314.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.447 | train_wall 305 | gb_free 6.1 | wall 663
KL Stats: Epoch 2 Divergences: Uniform: 0.5386803948609394 Unigram: 2.325965643775659
2022-02-02 06:17:59 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:17:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:23:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:23:30 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.811 | ppl 7187.16 | wps 8598.9 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:23:30 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:23:30 | INFO | train | epoch 003 | loss 13.434 | ppl 11069.7 | wps 6309 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.151 | train_wall 305 | gb_free 6.1 | wall 994
KL Stats: Epoch 3 Divergences: Uniform: 0.5232687048842205 Unigram: 1.645502595863393
2022-02-02 06:23:30 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:24:08 | INFO | train_inner | epoch 004:      8 / 64 loss=13.562, ppl=12095.6, wps=6176.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.183, train_wall=476, gb_free=6.1, wall=1033
2022-02-02 06:28:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:29:01 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.033 | ppl 4191.7 | wps 8610.9 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:29:01 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:29:01 | INFO | train | epoch 004 | loss 12.521 | ppl 5878.82 | wps 6314.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.902 | train_wall 305 | gb_free 6.1 | wall 1325
KL Stats: Epoch 4 Divergences: Uniform: 0.6118842508334665 Unigram: 1.0530587882398765
2022-02-02 06:29:01 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:29:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:32:32 | INFO | train_inner | epoch 005:     44 / 64 loss=12.199, ppl=4703.22, wps=6492.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.796, train_wall=477, gb_free=6.1, wall=1536
2022-02-02 06:34:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:34:32 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.577 | ppl 3055.7 | wps 8583.3 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:34:32 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:34:32 | INFO | train | epoch 005 | loss 11.783 | ppl 3524.7 | wps 6308 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.664 | train_wall 305 | gb_free 6.1 | wall 1656
KL Stats: Epoch 5 Divergences: Uniform: 0.8524732343154752 Unigram: 0.6230855680707821
2022-02-02 06:34:32 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:34:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:40:03 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.339 | ppl 2590.41 | wps 8624 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:40:03 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:40:03 | INFO | train | epoch 006 | loss 11.399 | ppl 2700.39 | wps 6296.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.563 | train_wall 306 | gb_free 6.1 | wall 1988
KL Stats: Epoch 6 Divergences: Uniform: 1.1470876770764524 Unigram: 0.4469195299290362
2022-02-02 06:40:03 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:41:20 | INFO | train_inner | epoch 007:     16 / 64 loss=11.415, ppl=2730.62, wps=6166.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.569, train_wall=476, gb_free=6.1, wall=2065
2022-02-02 06:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:45:35 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.176 | ppl 2313.5 | wps 8598.1 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:45:35 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:45:35 | INFO | train | epoch 007 | loss 11.208 | ppl 2365.12 | wps 6307.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.538 | train_wall 305 | gb_free 6.1 | wall 2319
KL Stats: Epoch 7 Divergences: Uniform: 1.3429696869966563 Unigram: 0.48538394806070745
2022-02-02 06:45:35 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:45:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:49:44 | INFO | train_inner | epoch 008:     52 / 64 loss=11.143, ppl=2261.41, wps=6491.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.522, train_wall=477, gb_free=6.1, wall=2568
2022-02-02 06:50:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:51:05 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.074 | ppl 2155.36 | wps 8611 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:51:05 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:51:05 | INFO | train | epoch 008 | loss 11.089 | ppl 2177.69 | wps 6315 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.517 | train_wall 305 | gb_free 6.1 | wall 2650
KL Stats: Epoch 8 Divergences: Uniform: 1.4460118666681459 Unigram: 0.5781557459700017
2022-02-02 06:51:05 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:51:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:56:36 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.954 | ppl 1984.18 | wps 8594 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 06:56:36 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 06:56:36 | INFO | train | epoch 009 | loss 10.981 | ppl 2020.99 | wps 6308.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.512 | train_wall 305 | gb_free 6.1 | wall 2981
KL Stats: Epoch 9 Divergences: Uniform: 1.4858506190422318 Unigram: 0.6908559018222692
2022-02-02 06:56:36 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 06:56:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:58:31 | INFO | train_inner | epoch 010:     24 / 64 loss=10.968, ppl=2002.79, wps=6177.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.512, train_wall=476, gb_free=6.1, wall=3096
2022-02-02 07:01:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:02:07 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.831 | ppl 1822.05 | wps 8610.1 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:02:07 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:02:07 | INFO | train | epoch 010 | loss 10.867 | ppl 1867.83 | wps 6310.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.52 | train_wall 305 | gb_free 6.1 | wall 3312
KL Stats: Epoch 10 Divergences: Uniform: 1.5084968646049923 Unigram: 0.8162639381829443
2022-02-02 07:02:07 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:02:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:06:55 | INFO | train_inner | epoch 011:     60 / 64 loss=10.792, ppl=1772.75, wps=6489.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.509, train_wall=477, gb_free=6.1, wall=3599
2022-02-02 07:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:07:38 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.741 | ppl 1711.91 | wps 8608.3 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:07:38 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:07:38 | INFO | train | epoch 011 | loss 10.747 | ppl 1718.72 | wps 6309.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.493 | train_wall 305 | gb_free 6.1 | wall 3643
KL Stats: Epoch 11 Divergences: Uniform: 1.5229914525959474 Unigram: 0.9471299795378487
2022-02-02 07:07:38 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:07:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:12:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:13:10 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.617 | ppl 1570.56 | wps 8609.3 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:13:10 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:13:10 | INFO | train | epoch 012 | loss 10.627 | ppl 1581.49 | wps 6306.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.473 | train_wall 305 | gb_free 6.1 | wall 3974
KL Stats: Epoch 12 Divergences: Uniform: 1.5365359710684048 Unigram: 1.0703202309314273
2022-02-02 07:13:10 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:13:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:15:43 | INFO | train_inner | epoch 013:     32 / 64 loss=10.596, ppl=1548.11, wps=6172.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.51, train_wall=476, gb_free=6.1, wall=4127
2022-02-02 07:18:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:18:41 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.514 | ppl 1462.02 | wps 8596.1 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:18:41 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:18:41 | INFO | train | epoch 013 | loss 10.513 | ppl 1461.19 | wps 6295 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.528 | train_wall 306 | gb_free 6.1 | wall 4306
KL Stats: Epoch 13 Divergences: Uniform: 1.5618578519918525 Unigram: 1.1747399706656383
2022-02-02 07:18:41 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:18:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:23:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:24:12 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.418 | ppl 1368.06 | wps 8637.3 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:24:12 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:24:12 | INFO | train | epoch 014 | loss 10.399 | ppl 1350.08 | wps 6308.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.524 | train_wall 305 | gb_free 6.1 | wall 4637
KL Stats: Epoch 14 Divergences: Uniform: 1.5833179406785352 Unigram: 1.271693918581174
2022-02-02 07:24:12 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:24:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:24:32 | INFO | train_inner | epoch 015:      4 / 64 loss=10.427, ppl=1376.73, wps=6168.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.51, train_wall=476, gb_free=6.1, wall=4656
2022-02-02 07:29:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:29:43 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.334 | ppl 1290.74 | wps 8604.9 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:29:43 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:29:43 | INFO | train | epoch 015 | loss 10.285 | ppl 1247.91 | wps 6310.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.487 | train_wall 305 | gb_free 6.1 | wall 4968
KL Stats: Epoch 15 Divergences: Uniform: 1.6098163477114134 Unigram: 1.3642691309273216
2022-02-02 07:29:43 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:29:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:32:55 | INFO | train_inner | epoch 016:     40 / 64 loss=10.246, ppl=1214.57, wps=6490.8, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.523, train_wall=477, gb_free=6.1, wall=5159
2022-02-02 07:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:35:15 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.248 | ppl 1216.36 | wps 8621 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:35:15 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:35:15 | INFO | train | epoch 016 | loss 10.176 | ppl 1156.92 | wps 6307.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.544 | train_wall 305 | gb_free 6.1 | wall 5299
KL Stats: Epoch 16 Divergences: Uniform: 1.6443981169807715 Unigram: 1.4471748958838235
2022-02-02 07:35:15 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:40:45 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.187 | ppl 1165.76 | wps 8639.7 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:40:45 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:40:45 | INFO | train | epoch 017 | loss 10.068 | ppl 1073.72 | wps 6313.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.534 | train_wall 305 | gb_free 6.1 | wall 5630
KL Stats: Epoch 17 Divergences: Uniform: 1.6724935480609662 Unigram: 1.529656490748372
2022-02-02 07:40:45 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:40:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:41:43 | INFO | train_inner | epoch 018:     12 / 64 loss=10.081, ppl=1083.33, wps=6177.4, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.529, train_wall=476, gb_free=6.1, wall=5687
2022-02-02 07:45:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:46:16 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.103 | ppl 1100.11 | wps 8620.2 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 07:46:16 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 07:46:16 | INFO | train | epoch 018 | loss 9.965 | ppl 999.75 | wps 6314.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.551 | train_wall 305 | gb_free 6.1 | wall 5960
KL Stats: Epoch 18 Divergences: Uniform: 1.703279521589114 Unigram: 1.6078775345459018
2022-02-02 07:46:16 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 07:46:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:50:06 | INFO | train_inner | epoch 019:     48 / 64 loss=9.917, ppl=966.45, wps=6491.8, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.57, train_wall=477, gb_free=6.1, wall=6191
2022-02-02 07:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:51:47 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.042 | ppl 1054.25 | wps 8639.8 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 07:51:47 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 07:51:47 | INFO | train | epoch 019 | loss 9.869 | ppl 935.4 | wps 6309.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.588 | train_wall 305 | gb_free 6.1 | wall 6291
KL Stats: Epoch 19 Divergences: Uniform: 1.7288829367053917 Unigram: 1.6803671583513444
2022-02-02 07:51:47 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 07:51:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:56:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:57:18 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.977 | ppl 1008.12 | wps 8605.5 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 07:57:18 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 07:57:18 | INFO | train | epoch 020 | loss 9.775 | ppl 876.04 | wps 6309.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.566 | train_wall 305 | gb_free 6.1 | wall 6622
KL Stats: Epoch 20 Divergences: Uniform: 1.7600059609808925 Unigram: 1.7454005291977301
2022-02-02 07:57:18 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 07:57:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:58:54 | INFO | train_inner | epoch 021:     20 / 64 loss=9.774, ppl=875.3, wps=6179.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.551, train_wall=476, gb_free=6.1, wall=6718
2022-02-02 08:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:02:48 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.917 | ppl 966.47 | wps 8640.6 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:02:48 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:02:48 | INFO | train | epoch 021 | loss 9.682 | ppl 821.31 | wps 6327 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.536 | train_wall 304 | gb_free 6.1 | wall 6953
KL Stats: Epoch 21 Divergences: Uniform: 1.784028863621139 Unigram: 1.8106058982547737
2022-02-02 08:02:48 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:02:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:07:17 | INFO | train_inner | epoch 022:     56 / 64 loss=9.63, ppl=792.31, wps=6501, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.557, train_wall=476, gb_free=6.1, wall=7221
2022-02-02 08:07:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:08:19 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.878 | ppl 941.23 | wps 8664.4 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:08:19 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:08:19 | INFO | train | epoch 022 | loss 9.594 | ppl 772.9 | wps 6319.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.568 | train_wall 304 | gb_free 6.1 | wall 7283
KL Stats: Epoch 22 Divergences: Uniform: 1.8134081018695924 Unigram: 1.8773980869804547
2022-02-02 08:08:19 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:08:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:13:49 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.795 | ppl 888.31 | wps 8634.9 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:13:49 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:13:49 | INFO | train | epoch 023 | loss 9.509 | ppl 728.81 | wps 6325.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.571 | train_wall 304 | gb_free 6.1 | wall 7613
KL Stats: Epoch 23 Divergences: Uniform: 1.8323004803972884 Unigram: 1.9332290691531504
2022-02-02 08:13:49 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:13:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:16:03 | INFO | train_inner | epoch 024:     28 / 64 loss=9.494, ppl=720.96, wps=6193.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.563, train_wall=474, gb_free=6.1, wall=7747
2022-02-02 08:18:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:19:19 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.768 | ppl 872.01 | wps 8637.5 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:19:19 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:19:19 | INFO | train | epoch 024 | loss 9.425 | ppl 687.53 | wps 6328.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.539 | train_wall 304 | gb_free 6.1 | wall 7943
KL Stats: Epoch 24 Divergences: Uniform: 1.8641132377170744 Unigram: 1.9929101312631403
2022-02-02 08:19:19 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:24:24 | INFO | train_inner | epoch 025:     64 / 64 loss=9.372, ppl=662.46, wps=6508.8, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.55, train_wall=474, gb_free=6.1, wall=8248
2022-02-02 08:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:24:49 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.713 | ppl 839.19 | wps 8668.1 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:24:49 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:24:49 | INFO | train | epoch 025 | loss 9.346 | ppl 650.55 | wps 6330.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.554 | train_wall 304 | gb_free 6.1 | wall 8273
KL Stats: Epoch 25 Divergences: Uniform: 1.8806894128183973 Unigram: 2.045713274202715
2022-02-02 08:24:49 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:24:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:29:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:30:19 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.678 | ppl 819.43 | wps 8620.6 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:30:19 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:30:19 | INFO | train | epoch 026 | loss 9.266 | ppl 615.61 | wps 6331.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.544 | train_wall 304 | gb_free 6.1 | wall 8603
KL Stats: Epoch 26 Divergences: Uniform: 1.9060600173245839 Unigram: 2.0961414874525954
2022-02-02 08:30:19 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:30:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:33:11 | INFO | train_inner | epoch 027:     36 / 64 loss=9.238, ppl=603.66, wps=6197.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.545, train_wall=475, gb_free=6.1, wall=8775
2022-02-02 08:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:35:50 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.646 | ppl 801.13 | wps 8648.8 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:35:50 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:35:50 | INFO | train | epoch 027 | loss 9.186 | ppl 582.61 | wps 6303.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.544 | train_wall 305 | gb_free 6.1 | wall 8935
KL Stats: Epoch 27 Divergences: Uniform: 1.9293721179352619 Unigram: 2.141951867754175
2022-02-02 08:35:50 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:35:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:41:21 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.603 | ppl 777.7 | wps 8635.2 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 08:41:21 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 08:41:21 | INFO | train | epoch 028 | loss 9.107 | ppl 551.34 | wps 6322.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.529 | train_wall 304 | gb_free 6.1 | wall 9265
KL Stats: Epoch 28 Divergences: Uniform: 1.9429086363691253 Unigram: 2.190577476965392
2022-02-02 08:41:21 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 08:41:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:41:59 | INFO | train_inner | epoch 029:      8 / 64 loss=9.121, ppl=556.84, wps=6177.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.535, train_wall=476, gb_free=6.1, wall=9303
2022-02-02 08:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:46:50 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.576 | ppl 763.12 | wps 8660.7 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 08:46:50 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 08:46:50 | INFO | train | epoch 029 | loss 9.031 | ppl 523.07 | wps 6331.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.556 | train_wall 304 | gb_free 6.1 | wall 9595
KL Stats: Epoch 29 Divergences: Uniform: 1.9719688187585214 Unigram: 2.2330926058295564
2022-02-02 08:46:50 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 08:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:50:21 | INFO | train_inner | epoch 030:     44 / 64 loss=8.997, ppl=510.78, wps=6512.9, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.545, train_wall=475, gb_free=6.1, wall=9805
2022-02-02 08:51:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:52:20 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.528 | ppl 738.26 | wps 8629.2 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 08:52:20 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 08:52:20 | INFO | train | epoch 030 | loss 8.953 | ppl 495.61 | wps 6330.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.535 | train_wall 304 | gb_free 6.1 | wall 9925
KL Stats: Epoch 30 Divergences: Uniform: 1.9939345428798656 Unigram: 2.2718834092867835
2022-02-02 08:52:20 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 08:52:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:57:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:57:51 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.516 | ppl 732.23 | wps 8651.7 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 08:57:51 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 08:57:51 | INFO | train | epoch 031 | loss 8.878 | ppl 470.61 | wps 6323.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.524 | train_wall 304 | gb_free 6.1 | wall 10255
KL Stats: Epoch 31 Divergences: Uniform: 2.015728857588144 Unigram: 2.3182112439388813
2022-02-02 08:57:51 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 08:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:59:07 | INFO | train_inner | epoch 032:     16 / 64 loss=8.88, ppl=471.24, wps=6191.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.528, train_wall=475, gb_free=6.1, wall=10332
2022-02-02 09:02:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:03:21 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.487 | ppl 717.44 | wps 8654.8 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:03:21 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:03:21 | INFO | train | epoch 032 | loss 8.804 | ppl 447.04 | wps 6328.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.529 | train_wall 304 | gb_free 6.1 | wall 10585
KL Stats: Epoch 32 Divergences: Uniform: 2.0383504856124857 Unigram: 2.3563680151436945
2022-02-02 09:03:21 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:03:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:07:29 | INFO | train_inner | epoch 033:     52 / 64 loss=8.768, ppl=436.09, wps=6508.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.537, train_wall=476, gb_free=6.1, wall=10834
2022-02-02 09:08:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:08:51 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.45 | ppl 699.19 | wps 8661.6 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:08:51 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:08:51 | INFO | train | epoch 033 | loss 8.73 | ppl 424.75 | wps 6328.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.538 | train_wall 304 | gb_free 6.1 | wall 10915
KL Stats: Epoch 33 Divergences: Uniform: 2.05903558735312 Unigram: 2.395099418934747
2022-02-02 09:08:51 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:13:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:14:21 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.445 | ppl 696.95 | wps 8635.3 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:14:21 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:14:21 | INFO | train | epoch 034 | loss 8.657 | ppl 403.61 | wps 6322 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.538 | train_wall 304 | gb_free 6.1 | wall 11245
KL Stats: Epoch 34 Divergences: Uniform: 2.073223304706206 Unigram: 2.4376531025064927
2022-02-02 09:14:21 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:16:16 | INFO | train_inner | epoch 035:     24 / 64 loss=8.649, ppl=401.43, wps=6191, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.532, train_wall=475, gb_free=6.1, wall=11360
2022-02-02 09:19:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:19:51 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.404 | ppl 677.6 | wps 8642.7 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:19:51 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:19:51 | INFO | train | epoch 035 | loss 8.585 | ppl 384.01 | wps 6325.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.517 | train_wall 304 | gb_free 6.1 | wall 11576
KL Stats: Epoch 35 Divergences: Uniform: 2.0946252808484087 Unigram: 2.476035670815073
2022-02-02 09:19:51 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:24:40 | INFO | train_inner | epoch 036:     60 / 64 loss=8.542, ppl=372.72, wps=6480.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.518, train_wall=478, gb_free=6.1, wall=11864
2022-02-02 09:24:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:25:23 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.402 | ppl 676.46 | wps 8642.4 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:25:23 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:25:23 | INFO | train | epoch 036 | loss 8.514 | ppl 365.62 | wps 6289.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.526 | train_wall 306 | gb_free 6.1 | wall 11908
KL Stats: Epoch 36 Divergences: Uniform: 2.1194771736185656 Unigram: 2.5167133911842248
2022-02-02 09:25:23 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:25:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:30:54 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.389 | ppl 670.45 | wps 8632.6 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:30:54 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:30:54 | INFO | train | epoch 037 | loss 8.442 | ppl 347.72 | wps 6324.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.506 | train_wall 304 | gb_free 6.1 | wall 12238
KL Stats: Epoch 37 Divergences: Uniform: 2.143385198980874 Unigram: 2.563525847419336
2022-02-02 09:30:54 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:30:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:33:27 | INFO | train_inner | epoch 038:     32 / 64 loss=8.421, ppl=342.78, wps=6188.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.512, train_wall=475, gb_free=6.1, wall=12391
2022-02-02 09:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:36:24 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.362 | ppl 657.85 | wps 8630.3 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 09:36:24 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 09:36:24 | INFO | train | epoch 038 | loss 8.375 | ppl 332.05 | wps 6318.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.519 | train_wall 304 | gb_free 6.1 | wall 12568
KL Stats: Epoch 38 Divergences: Uniform: 2.15914029668714 Unigram: 2.5965195588942795
2022-02-02 09:36:24 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 09:36:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:41:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:41:55 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.36 | ppl 657.23 | wps 8660.7 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 09:41:55 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 09:41:55 | INFO | train | epoch 039 | loss 8.308 | ppl 317 | wps 6323.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.518 | train_wall 304 | gb_free 6.1 | wall 12899
KL Stats: Epoch 39 Divergences: Uniform: 2.1793710446812766 Unigram: 2.634721747938919
2022-02-02 09:41:55 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 09:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:42:14 | INFO | train_inner | epoch 040:      4 / 64 loss=8.328, ppl=321.41, wps=6188.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.52, train_wall=475, gb_free=6.1, wall=12918
2022-02-02 09:46:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:47:24 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.357 | ppl 655.61 | wps 8631.7 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 09:47:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 09:47:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint40.pt
2022-02-02 09:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint40.pt
2022-02-02 09:47:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.357) (writing took 4.9040997049887665 seconds)
2022-02-02 09:47:29 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 09:47:29 | INFO | train | epoch 040 | loss 8.242 | ppl 302.65 | wps 6237.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.509 | train_wall 304 | gb_free 6.1 | wall 13234
KL Stats: Epoch 40 Divergences: Uniform: 2.1924744142302925 Unigram: 2.6719401696497633
2022-02-02 09:47:29 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 09:47:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:50:40 | INFO | train_inner | epoch 041:     40 / 64 loss=8.209, ppl=295.87, wps=6450.2, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.505, train_wall=475, gb_free=6.1, wall=13425
2022-02-02 09:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:52:59 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.348 | ppl 651.76 | wps 8656.2 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.348
2022-02-02 09:52:59 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 09:52:59 | INFO | train | epoch 041 | loss 8.176 | ppl 289.14 | wps 6329.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.503 | train_wall 304 | gb_free 6.1 | wall 13564
KL Stats: Epoch 41 Divergences: Uniform: 2.2104224685663865 Unigram: 2.711020051665799
2022-02-02 09:52:59 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 09:52:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:58:31 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.35 | ppl 652.72 | wps 8664.9 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.35
2022-02-02 09:58:31 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 09:58:31 | INFO | train | epoch 042 | loss 8.115 | ppl 277.18 | wps 6302.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.53 | train_wall 305 | gb_free 6.1 | wall 13895
KL Stats: Epoch 42 Divergences: Uniform: 2.2367147871297677 Unigram: 2.7402491197023084
2022-02-02 09:58:31 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 09:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:59:28 | INFO | train_inner | epoch 043:     12 / 64 loss=8.128, ppl=279.74, wps=6175.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.522, train_wall=476, gb_free=6.1, wall=13953
2022-02-02 10:03:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:04:01 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.373 | ppl 663.17 | wps 8635.6 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.357
2022-02-02 10:04:01 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:04:01 | INFO | train | epoch 043 | loss 8.051 | ppl 265.15 | wps 6325.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.51 | train_wall 304 | gb_free 6.1 | wall 14225
KL Stats: Epoch 43 Divergences: Uniform: 2.250755716100355 Unigram: 2.7754518523303022
2022-02-02 10:04:01 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:04:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:07:50 | INFO | train_inner | epoch 044:     48 / 64 loss=8.019, ppl=259.39, wps=6509.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.505, train_wall=475, gb_free=6.1, wall=14455
2022-02-02 10:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:09:31 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.375 | ppl 663.79 | wps 8643.3 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.357
2022-02-02 10:09:31 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:09:31 | INFO | train | epoch 044 | loss 7.987 | ppl 253.78 | wps 6331.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.501 | train_wall 304 | gb_free 6.1 | wall 14555
KL Stats: Epoch 44 Divergences: Uniform: 2.2722975111409816 Unigram: 2.8162888375801667
2022-02-02 10:09:31 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:15:01 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.365 | ppl 659.29 | wps 8639.3 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.357
2022-02-02 10:15:01 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:15:01 | INFO | train | epoch 045 | loss 7.927 | ppl 243.3 | wps 6332.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.499 | train_wall 304 | gb_free 6.1 | wall 14885
KL Stats: Epoch 45 Divergences: Uniform: 2.285846568190993 Unigram: 2.849739244446668
2022-02-02 10:15:01 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:15:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:16:36 | INFO | train_inner | epoch 046:     20 / 64 loss=7.923, ppl=242.71, wps=6198.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.504, train_wall=474, gb_free=6.1, wall=14980
2022-02-02 10:20:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:20:31 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.39 | ppl 670.86 | wps 8638.7 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.357
2022-02-02 10:20:31 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:20:31 | INFO | train | epoch 046 | loss 7.869 | ppl 233.84 | wps 6331.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.516 | train_wall 304 | gb_free 6.1 | wall 15215
KL Stats: Epoch 46 Divergences: Uniform: 2.301309290537557 Unigram: 2.8770913240701104
2022-02-02 10:20:31 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:20:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:24:59 | INFO | train_inner | epoch 047:     56 / 64 loss=7.837, ppl=228.62, wps=6504.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.513, train_wall=476, gb_free=6.1, wall=15483
2022-02-02 10:25:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:26:01 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.405 | ppl 678.09 | wps 8607.6 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.357
2022-02-02 10:26:01 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:26:01 | INFO | train | epoch 047 | loss 7.812 | ppl 224.7 | wps 6318.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.518 | train_wall 304 | gb_free 6.1 | wall 15545
KL Stats: Epoch 47 Divergences: Uniform: 2.3120693366791056 Unigram: 2.9170551973081302
2022-02-02 10:26:01 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:26:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:31:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:31:33 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.411 | ppl 680.7 | wps 8645.6 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.357
2022-02-02 10:31:33 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 10:31:33 | INFO | train | epoch 048 | loss 7.755 | ppl 216 | wps 6301.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.506 | train_wall 305 | gb_free 6.1 | wall 15877
KL Stats: Epoch 48 Divergences: Uniform: 2.330615605770404 Unigram: 2.944205138929886
2022-02-02 10:31:33 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 10:31:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:33:46 | INFO | train_inner | epoch 049:     28 / 64 loss=7.74, ppl=213.75, wps=6178.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.514, train_wall=476, gb_free=6.1, wall=16011
2022-02-02 10:36:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:37:02 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.465 | ppl 706.96 | wps 8644 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.357
2022-02-02 10:37:02 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 10:37:02 | INFO | train | epoch 049 | loss 7.7 | ppl 207.89 | wps 6331.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.518 | train_wall 304 | gb_free 6.1 | wall 16207
KL Stats: Epoch 49 Divergences: Uniform: 2.343963150125157 Unigram: 2.9760172636943873
2022-02-02 10:37:02 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 10:37:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:42:07 | INFO | train_inner | epoch 050:     64 / 64 loss=7.671, ppl=203.75, wps=6511.6, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.518, train_wall=474, gb_free=6.1, wall=16511
2022-02-02 10:42:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:42:32 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.419 | ppl 684.42 | wps 8645.6 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.357
2022-02-02 10:42:32 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 10:42:32 | INFO | train | epoch 050 | loss 7.644 | ppl 199.97 | wps 6333.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.521 | train_wall 304 | gb_free 6.1 | wall 16536
KL Stats: Epoch 50 Divergences: Uniform: 2.3721242188031653 Unigram: 3.0045832350578934
2022-02-02 10:42:32 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 10:42:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:47:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:48:02 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.51 | ppl 729.29 | wps 8668 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.357
2022-02-02 10:48:02 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 10:48:02 | INFO | train | epoch 051 | loss 7.591 | ppl 192.83 | wps 6332.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.517 | train_wall 304 | gb_free 6.1 | wall 16866
KL Stats: Epoch 51 Divergences: Uniform: 2.374818777117367 Unigram: 3.032275349946748
2022-02-02 10:48:02 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 10:48:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:50:54 | INFO | train_inner | epoch 052:     36 / 64 loss=7.568, ppl=189.77, wps=6199.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.523, train_wall=475, gb_free=6.1, wall=17038
2022-02-02 10:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:53:32 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.463 | ppl 705.51 | wps 8644.9 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.357
2022-02-02 10:53:32 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 10:53:32 | INFO | train | epoch 052 | loss 7.541 | ppl 186.21 | wps 6329.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.531 | train_wall 304 | gb_free 6.1 | wall 17196
KL Stats: Epoch 52 Divergences: Uniform: 2.3901037932817957 Unigram: 3.0704480652485326
2022-02-02 10:53:32 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 10:53:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:59:02 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.528 | ppl 738.1 | wps 8631.1 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.357
2022-02-02 10:59:02 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 10:59:02 | INFO | train | epoch 053 | loss 7.488 | ppl 179.57 | wps 6327 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.521 | train_wall 304 | gb_free 6.1 | wall 17526
KL Stats: Epoch 53 Divergences: Uniform: 2.401166944465688 Unigram: 3.0951773065278334
2022-02-02 10:59:02 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 10:59:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:59:40 | INFO | train_inner | epoch 054:      8 / 64 loss=7.5, ppl=181.04, wps=6193.1, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.522, train_wall=474, gb_free=6.1, wall=17565
2022-02-02 11:04:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:04:32 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.57 | ppl 760.29 | wps 8626.7 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.357
2022-02-02 11:04:32 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:04:32 | INFO | train | epoch 054 | loss 7.439 | ppl 173.51 | wps 6331.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.528 | train_wall 304 | gb_free 6.1 | wall 17856
KL Stats: Epoch 54 Divergences: Uniform: 2.4061062001568234 Unigram: 3.1299810201075147
2022-02-02 11:04:32 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:04:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:08:02 | INFO | train_inner | epoch 055:     44 / 64 loss=7.414, ppl=170.59, wps=6509.2, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.528, train_wall=476, gb_free=6.1, wall=18067
2022-02-02 11:09:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:10:02 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.495 | ppl 721.57 | wps 8697.1 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.357
2022-02-02 11:10:02 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:10:02 | INFO | train | epoch 055 | loss 7.388 | ppl 167.54 | wps 6324.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.529 | train_wall 304 | gb_free 6.1 | wall 18186
KL Stats: Epoch 55 Divergences: Uniform: 2.4420362946408303 Unigram: 3.1549257487124778
2022-02-02 11:10:02 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:15:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:15:38 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.567 | ppl 758.69 | wps 8497.8 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.357
2022-02-02 11:15:38 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:15:38 | INFO | train | epoch 056 | loss 7.34 | ppl 161.99 | wps 6219.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.524 | train_wall 309 | gb_free 6.1 | wall 18522
KL Stats: Epoch 56 Divergences: Uniform: 2.440601594068186 Unigram: 3.182083228827052
2022-02-02 11:15:38 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:15:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:16:55 | INFO | train_inner | epoch 057:     16 / 64 loss=7.338, ppl=161.77, wps=6117.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.523, train_wall=481, gb_free=6.1, wall=18600
2022-02-02 11:20:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:21:11 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.569 | ppl 759.49 | wps 8577.5 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.357
2022-02-02 11:21:11 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:21:11 | INFO | train | epoch 057 | loss 7.295 | ppl 157.05 | wps 6267.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.53 | train_wall 307 | gb_free 6.1 | wall 18855
KL Stats: Epoch 57 Divergences: Uniform: 2.461245372461521 Unigram: 3.2091052273988616
2022-02-02 11:21:11 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:21:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:25:21 | INFO | train_inner | epoch 058:     52 / 64 loss=7.277, ppl=155.04, wps=6459.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.543, train_wall=479, gb_free=6.1, wall=19106
2022-02-02 11:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:26:43 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.578 | ppl 764.34 | wps 8531.5 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.357
2022-02-02 11:26:43 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 11:26:43 | INFO | train | epoch 058 | loss 7.25 | ppl 152.23 | wps 6287.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.552 | train_wall 306 | gb_free 6.1 | wall 19188
KL Stats: Epoch 58 Divergences: Uniform: 2.4681383281932954 Unigram: 3.2400327821969457
2022-02-02 11:26:43 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 11:26:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:32:16 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.66 | ppl 809.17 | wps 8564.5 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.357
2022-02-02 11:32:16 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 11:32:16 | INFO | train | epoch 059 | loss 7.202 | ppl 147.22 | wps 6286.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.548 | train_wall 306 | gb_free 6.1 | wall 19520
KL Stats: Epoch 59 Divergences: Uniform: 2.487501880935283 Unigram: 3.269311308596222
2022-02-02 11:32:16 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 11:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:34:11 | INFO | train_inner | epoch 060:     24 / 64 loss=7.191, ppl=146.07, wps=6152.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.547, train_wall=477, gb_free=6.1, wall=19635
2022-02-02 11:37:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:37:48 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.665 | ppl 812.08 | wps 8580.4 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.357
2022-02-02 11:37:48 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 11:37:48 | INFO | train | epoch 060 | loss 7.159 | ppl 142.88 | wps 6287.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.54 | train_wall 306 | gb_free 6.1 | wall 19852
KL Stats: Epoch 60 Divergences: Uniform: 2.506605892249123 Unigram: 3.2944802183920787
2022-02-02 11:37:48 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 11:37:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:42:36 | INFO | train_inner | epoch 061:     60 / 64 loss=7.141, ppl=141.15, wps=6469.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.547, train_wall=478, gb_free=6.1, wall=20141
2022-02-02 11:42:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:43:20 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.642 | ppl 798.97 | wps 8576.8 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.357
2022-02-02 11:43:20 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 11:43:20 | INFO | train | epoch 061 | loss 7.113 | ppl 138.39 | wps 6288.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.548 | train_wall 306 | gb_free 6.1 | wall 20184
KL Stats: Epoch 61 Divergences: Uniform: 2.5152972281058523 Unigram: 3.324547722981974
2022-02-02 11:43:20 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 11:43:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:48:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:48:52 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.63 | ppl 792.34 | wps 8554.5 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.357
2022-02-02 11:48:52 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 11:48:52 | INFO | train | epoch 062 | loss 7.071 | ppl 134.5 | wps 6282.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.559 | train_wall 306 | gb_free 6.1 | wall 20517
KL Stats: Epoch 62 Divergences: Uniform: 2.5297409688108927 Unigram: 3.3431098118285525
2022-02-02 11:48:52 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 11:48:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:51:26 | INFO | train_inner | epoch 063:     32 / 64 loss=7.047, ppl=132.24, wps=6152.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.56, train_wall=477, gb_free=6.1, wall=20670
2022-02-02 11:53:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:54:24 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.712 | ppl 838.88 | wps 8542.7 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.357
2022-02-02 11:54:24 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 11:54:24 | INFO | train | epoch 063 | loss 7.029 | ppl 130.61 | wps 6290.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.558 | train_wall 306 | gb_free 6.1 | wall 20849
KL Stats: Epoch 63 Divergences: Uniform: 2.5427326420599017 Unigram: 3.3777133227981992
2022-02-02 11:54:24 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 11:54:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:59:57 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.747 | ppl 859.03 | wps 8542.6 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.357
2022-02-02 11:59:57 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 11:59:57 | INFO | train | epoch 064 | loss 6.986 | ppl 126.79 | wps 6286.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.558 | train_wall 306 | gb_free 6.1 | wall 21181
KL Stats: Epoch 64 Divergences: Uniform: 2.5393703030418195 Unigram: 3.401348097928619
2022-02-02 11:59:57 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 11:59:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:00:16 | INFO | train_inner | epoch 065:      4 / 64 loss=7.009, ppl=128.77, wps=6152.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.557, train_wall=477, gb_free=6.1, wall=21200
2022-02-02 12:05:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:05:32 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.75 | ppl 860.89 | wps 8570.9 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.357
2022-02-02 12:05:32 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:05:32 | INFO | train | epoch 065 | loss 6.943 | ppl 123.06 | wps 6226.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.561 | train_wall 309 | gb_free 6.1 | wall 21516
KL Stats: Epoch 65 Divergences: Uniform: 2.5674386883755553 Unigram: 3.4270084631268416
2022-02-02 12:05:32 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:05:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:08:45 | INFO | train_inner | epoch 066:     40 / 64 loss=6.922, ppl=121.26, wps=6425.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.567, train_wall=482, gb_free=6.1, wall=21709
2022-02-02 12:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:11:05 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.823 | ppl 905.82 | wps 8533.3 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.357
2022-02-02 12:11:05 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:11:05 | INFO | train | epoch 066 | loss 6.903 | ppl 119.65 | wps 6281 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.58 | train_wall 306 | gb_free 6.1 | wall 21849
KL Stats: Epoch 66 Divergences: Uniform: 2.564731190588757 Unigram: 3.450385068714804
2022-02-02 12:11:05 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:16:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:16:37 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.826 | ppl 907.88 | wps 8557.1 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.357
2022-02-02 12:16:37 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:16:37 | INFO | train | epoch 067 | loss 6.859 | ppl 116.11 | wps 6289.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.546 | train_wall 306 | gb_free 6.1 | wall 22181
KL Stats: Epoch 67 Divergences: Uniform: 2.589344800021243 Unigram: 3.4922703011957634
2022-02-02 12:16:37 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:16:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:17:34 | INFO | train_inner | epoch 068:     12 / 64 loss=6.868, ppl=116.84, wps=6152.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.558, train_wall=477, gb_free=6.1, wall=22239
2022-02-02 12:21:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:22:09 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.933 | ppl 977.5 | wps 8551.3 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.357
2022-02-02 12:22:09 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 12:22:09 | INFO | train | epoch 068 | loss 6.822 | ppl 113.14 | wps 6286.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.553 | train_wall 306 | gb_free 6.1 | wall 22513
KL Stats: Epoch 68 Divergences: Uniform: 2.5864921661678335 Unigram: 3.5072215451064026
2022-02-02 12:22:09 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 12:22:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:26:00 | INFO | train_inner | epoch 069:     48 / 64 loss=6.802, ppl=111.59, wps=6469.6, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.568, train_wall=478, gb_free=6.1, wall=22744
2022-02-02 12:27:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:27:41 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.828 | ppl 908.95 | wps 8577.4 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.357
2022-02-02 12:27:41 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 12:27:41 | INFO | train | epoch 069 | loss 6.786 | ppl 110.37 | wps 6293.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.584 | train_wall 306 | gb_free 6.1 | wall 22845
KL Stats: Epoch 69 Divergences: Uniform: 2.6044312079006757 Unigram: 3.5361163610889284
2022-02-02 12:27:41 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 12:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:32:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:33:13 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.827 | ppl 908.59 | wps 8563.4 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.357
2022-02-02 12:33:13 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 12:33:13 | INFO | train | epoch 070 | loss 6.747 | ppl 107.44 | wps 6285.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.58 | train_wall 306 | gb_free 6.1 | wall 23177
KL Stats: Epoch 70 Divergences: Uniform: 2.616108234014397 Unigram: 3.5601115329393638
2022-02-02 12:33:13 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 12:33:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:34:49 | INFO | train_inner | epoch 071:     20 / 64 loss=6.742, ppl=107.07, wps=6154.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.575, train_wall=477, gb_free=6.1, wall=23274
2022-02-02 12:38:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:38:45 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.929 | ppl 974.57 | wps 8538.6 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.357
2022-02-02 12:38:45 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 12:38:45 | INFO | train | epoch 071 | loss 6.71 | ppl 104.69 | wps 6284.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.566 | train_wall 306 | gb_free 6.1 | wall 23510
KL Stats: Epoch 71 Divergences: Uniform: 2.624400742256107 Unigram: 3.5873372754783985
2022-02-02 12:38:45 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 12:38:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:43:15 | INFO | train_inner | epoch 072:     56 / 64 loss=6.696, ppl=103.7, wps=6462.9, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.572, train_wall=479, gb_free=6.1, wall=23779
2022-02-02 12:43:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:44:18 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.955 | ppl 992.58 | wps 8553.8 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.357
2022-02-02 12:44:18 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 12:44:18 | INFO | train | epoch 072 | loss 6.677 | ppl 102.34 | wps 6282.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.58 | train_wall 306 | gb_free 6.1 | wall 23842
KL Stats: Epoch 72 Divergences: Uniform: 2.6313769955980053 Unigram: 3.61415598152269
2022-02-02 12:44:18 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 12:44:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:49:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:49:50 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.985 | ppl 1013.14 | wps 8546.2 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.357
2022-02-02 12:49:50 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 12:49:50 | INFO | train | epoch 073 | loss 6.643 | ppl 99.97 | wps 6283.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.58 | train_wall 306 | gb_free 6.1 | wall 24175
KL Stats: Epoch 73 Divergences: Uniform: 2.6367408282165257 Unigram: 3.6344146256546312
2022-02-02 12:49:50 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 12:49:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:52:05 | INFO | train_inner | epoch 074:     28 / 64 loss=6.631, ppl=99.1, wps=6151.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.58, train_wall=477, gb_free=6.1, wall=24309
2022-02-02 12:54:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:55:22 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.945 | ppl 985.73 | wps 8545.8 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.357
2022-02-02 12:55:22 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 12:55:22 | INFO | train | epoch 074 | loss 6.611 | ppl 97.78 | wps 6290.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.594 | train_wall 306 | gb_free 6.1 | wall 24507
KL Stats: Epoch 74 Divergences: Uniform: 2.654431700865216 Unigram: 3.655105671880513
2022-02-02 12:55:22 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 12:55:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:00:29 | INFO | train_inner | epoch 075:     64 / 64 loss=6.605, ppl=97.37, wps=6467.1, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.606, train_wall=477, gb_free=6.1, wall=24813
2022-02-02 13:00:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:00:54 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.041 | ppl 1053.56 | wps 8578.4 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.357
2022-02-02 13:00:54 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 13:00:54 | INFO | train | epoch 075 | loss 6.581 | ppl 95.71 | wps 6288.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.603 | train_wall 306 | gb_free 6.1 | wall 24839
KL Stats: Epoch 75 Divergences: Uniform: 2.653342187960202 Unigram: 3.691807685086741
2022-02-02 13:00:54 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 13:00:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:06:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:06:27 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.031 | ppl 1046.44 | wps 8541.9 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.357
2022-02-02 13:06:27 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:06:27 | INFO | train | epoch 076 | loss 6.548 | ppl 93.55 | wps 6281.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.593 | train_wall 306 | gb_free 6.1 | wall 25171
KL Stats: Epoch 76 Divergences: Uniform: 2.6687785273279765 Unigram: 3.7035510369633973
2022-02-02 13:06:27 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:06:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:09:20 | INFO | train_inner | epoch 077:     36 / 64 loss=6.528, ppl=92.29, wps=6151.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.596, train_wall=479, gb_free=6.1, wall=25344
2022-02-02 13:11:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:11:59 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.953 | ppl 991.5 | wps 8546.2 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.357
2022-02-02 13:11:59 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:11:59 | INFO | train | epoch 077 | loss 6.517 | ppl 91.61 | wps 6285.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.606 | train_wall 306 | gb_free 6.1 | wall 25504
KL Stats: Epoch 77 Divergences: Uniform: 2.681485047406003 Unigram: 3.7406421884451238
2022-02-02 13:11:59 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:11:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:17:31 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.08 | ppl 1082.37 | wps 8546.1 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.357
2022-02-02 13:17:31 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 13:17:31 | INFO | train | epoch 078 | loss 6.491 | ppl 89.94 | wps 6289.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.609 | train_wall 306 | gb_free 6.1 | wall 25836
KL Stats: Epoch 78 Divergences: Uniform: 2.6799649118160174 Unigram: 3.7545962488180367
2022-02-02 13:17:31 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 13:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:18:10 | INFO | train_inner | epoch 079:      8 / 64 loss=6.5, ppl=90.49, wps=6155, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.607, train_wall=477, gb_free=6.1, wall=25874
2022-02-02 13:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:23:04 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.026 | ppl 1042.52 | wps 8578.1 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.357
2022-02-02 13:23:04 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 13:23:04 | INFO | train | epoch 079 | loss 6.459 | ppl 87.96 | wps 6284.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.594 | train_wall 306 | gb_free 6.1 | wall 26168
KL Stats: Epoch 79 Divergences: Uniform: 2.697117266949155 Unigram: 3.779767089137701
2022-02-02 13:23:04 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 13:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:26:36 | INFO | train_inner | epoch 080:     44 / 64 loss=6.443, ppl=86.98, wps=6461.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.608, train_wall=479, gb_free=6.1, wall=26380
2022-02-02 13:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:28:36 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.174 | ppl 1155.58 | wps 8542.5 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.357
2022-02-02 13:28:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 13:28:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint80.pt
2022-02-02 13:28:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint80.pt
2022-02-02 13:28:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint80.pt (epoch 80 @ 5120 updates, score 10.174) (writing took 3.4956958320108242 seconds)
2022-02-02 13:28:40 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 13:28:40 | INFO | train | epoch 080 | loss 6.434 | ppl 86.44 | wps 6215.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.615 | train_wall 306 | gb_free 6.1 | wall 26504
KL Stats: Epoch 80 Divergences: Uniform: 2.6958819449450564 Unigram: 3.793434542229691
2022-02-02 13:28:40 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 13:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:33:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:34:12 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.042 | ppl 1054.36 | wps 8547.6 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.357
2022-02-02 13:34:12 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 13:34:12 | INFO | train | epoch 081 | loss 6.406 | ppl 84.81 | wps 6284.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.624 | train_wall 306 | gb_free 6.1 | wall 26836
KL Stats: Epoch 81 Divergences: Uniform: 2.7071627823448265 Unigram: 3.8172056945863426
2022-02-02 13:34:12 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 13:34:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:35:29 | INFO | train_inner | epoch 082:     16 / 64 loss=6.41, ppl=85.01, wps=6109.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.615, train_wall=478, gb_free=6.1, wall=26913
2022-02-02 13:39:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:39:45 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 10.105 | ppl 1101.14 | wps 8532.2 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.357
2022-02-02 13:39:45 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 13:39:45 | INFO | train | epoch 082 | loss 6.381 | ppl 83.34 | wps 6279.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.62 | train_wall 306 | gb_free 6.1 | wall 27169
KL Stats: Epoch 82 Divergences: Uniform: 2.711214733928032 Unigram: 3.837250989540598
2022-02-02 13:39:45 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 13:39:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:43:55 | INFO | train_inner | epoch 083:     52 / 64 loss=6.373, ppl=82.86, wps=6463.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.638, train_wall=479, gb_free=6.1, wall=27419
2022-02-02 13:44:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:45:17 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 10.06 | ppl 1067.46 | wps 8587.2 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.357
2022-02-02 13:45:17 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 13:45:17 | INFO | train | epoch 083 | loss 6.357 | ppl 81.95 | wps 6287 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.646 | train_wall 306 | gb_free 6.1 | wall 27501
KL Stats: Epoch 83 Divergences: Uniform: 2.7263251205999692 Unigram: 3.8727872446807714
2022-02-02 13:45:17 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 13:45:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:50:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:50:50 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 10.136 | ppl 1125.41 | wps 8526.8 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.357
2022-02-02 13:50:50 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 13:50:50 | INFO | train | epoch 084 | loss 6.33 | ppl 80.47 | wps 6275.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.629 | train_wall 306 | gb_free 6.1 | wall 27834
KL Stats: Epoch 84 Divergences: Uniform: 2.7314402783017555 Unigram: 3.881178094395732
2022-02-02 13:50:50 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 13:50:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:52:45 | INFO | train_inner | epoch 085:     24 / 64 loss=6.32, ppl=79.88, wps=6145.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.631, train_wall=478, gb_free=6.1, wall=27950
2022-02-02 13:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:56:22 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 10.089 | ppl 1088.81 | wps 8565.8 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.357
2022-02-02 13:56:22 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 13:56:22 | INFO | train | epoch 085 | loss 6.306 | ppl 79.1 | wps 6288 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.632 | train_wall 306 | gb_free 6.1 | wall 28166
KL Stats: Epoch 85 Divergences: Uniform: 2.732507781563364 Unigram: 3.9026177783463196
2022-02-02 13:56:22 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 13:56:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:01:10 | INFO | train_inner | epoch 086:     60 / 64 loss=6.301, ppl=78.82, wps=6471.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.642, train_wall=478, gb_free=6.1, wall=28455
2022-02-02 14:01:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:01:54 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 10.106 | ppl 1102.15 | wps 8581.1 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.357
2022-02-02 14:01:54 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 14:01:54 | INFO | train | epoch 086 | loss 6.282 | ppl 77.83 | wps 6293.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.651 | train_wall 306 | gb_free 6.1 | wall 28498
KL Stats: Epoch 86 Divergences: Uniform: 2.746469571121629 Unigram: 3.923680506332472
2022-02-02 14:01:54 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 14:01:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:07:26 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 10.219 | ppl 1191.96 | wps 8555.2 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.357
2022-02-02 14:07:26 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:07:26 | INFO | train | epoch 087 | loss 6.259 | ppl 76.59 | wps 6286.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.649 | train_wall 306 | gb_free 6.1 | wall 28830
KL Stats: Epoch 87 Divergences: Uniform: 2.7441078739276317 Unigram: 3.94586295802171
2022-02-02 14:07:26 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:07:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:10:00 | INFO | train_inner | epoch 088:     32 / 64 loss=6.243, ppl=75.74, wps=6156.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.652, train_wall=477, gb_free=6.1, wall=28984
2022-02-02 14:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:12:58 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 10.053 | ppl 1062.23 | wps 8549.5 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.357
2022-02-02 14:12:58 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 14:12:58 | INFO | train | epoch 088 | loss 6.235 | ppl 75.32 | wps 6292.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.653 | train_wall 305 | gb_free 6.1 | wall 29162
KL Stats: Epoch 88 Divergences: Uniform: 2.764050759900902 Unigram: 3.967099810725998
2022-02-02 14:12:58 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 14:12:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:18:30 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 10.122 | ppl 1114.14 | wps 8541.2 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.357
2022-02-02 14:18:30 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 14:18:30 | INFO | train | epoch 089 | loss 6.214 | ppl 74.23 | wps 6294.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.651 | train_wall 305 | gb_free 6.1 | wall 29494
KL Stats: Epoch 89 Divergences: Uniform: 2.757633945754619 Unigram: 3.994552953477124
2022-02-02 14:18:30 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 14:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:18:49 | INFO | train_inner | epoch 090:      4 / 64 loss=6.23, ppl=75.05, wps=6159.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.65, train_wall=477, gb_free=6.1, wall=29513
2022-02-02 14:23:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:24:02 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 10.177 | ppl 1157.95 | wps 8534.7 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.357
2022-02-02 14:24:02 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 14:24:02 | INFO | train | epoch 090 | loss 6.192 | ppl 73.13 | wps 6281.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.657 | train_wall 306 | gb_free 6.1 | wall 29827
KL Stats: Epoch 90 Divergences: Uniform: 2.7697839794082744 Unigram: 4.013040969068085
2022-02-02 14:24:02 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 14:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:27:15 | INFO | train_inner | epoch 091:     40 / 64 loss=6.171, ppl=72.04, wps=6462.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.66, train_wall=479, gb_free=6.1, wall=30019
2022-02-02 14:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:29:34 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 10.166 | ppl 1148.61 | wps 8580.3 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.357
2022-02-02 14:29:34 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 14:29:34 | INFO | train | epoch 091 | loss 6.171 | ppl 72.04 | wps 6290.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.669 | train_wall 306 | gb_free 6.1 | wall 30159
KL Stats: Epoch 91 Divergences: Uniform: 2.77667673375942 Unigram: 4.029177099770564
2022-02-02 14:29:34 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 14:29:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:34:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:35:07 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 10.183 | ppl 1162.3 | wps 8500.5 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.357
2022-02-02 14:35:07 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 14:35:07 | INFO | train | epoch 092 | loss 6.151 | ppl 71.05 | wps 6285.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.681 | train_wall 306 | gb_free 6.1 | wall 30491
KL Stats: Epoch 92 Divergences: Uniform: 2.7810916701688058 Unigram: 4.047162157982337
2022-02-02 14:35:07 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 14:35:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:36:05 | INFO | train_inner | epoch 093:     12 / 64 loss=6.161, ppl=71.55, wps=6153.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.684, train_wall=477, gb_free=6.1, wall=30549
2022-02-02 14:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:40:39 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 10.212 | ppl 1186.49 | wps 8573.3 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.357
2022-02-02 14:40:39 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 14:40:39 | INFO | train | epoch 093 | loss 6.131 | ppl 70.1 | wps 6283.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.683 | train_wall 306 | gb_free 6.1 | wall 30823
KL Stats: Epoch 93 Divergences: Uniform: 2.790221843093012 Unigram: 4.062010145166213
2022-02-02 14:40:39 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 14:40:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:44:30 | INFO | train_inner | epoch 094:     48 / 64 loss=6.118, ppl=69.48, wps=6461.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.672, train_wall=479, gb_free=6.1, wall=31055
2022-02-02 14:45:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:46:12 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 10.239 | ppl 1208.31 | wps 8553.8 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.357
2022-02-02 14:46:12 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 14:46:12 | INFO | train | epoch 094 | loss 6.11 | ppl 69.05 | wps 6280.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.663 | train_wall 306 | gb_free 6.1 | wall 31156
KL Stats: Epoch 94 Divergences: Uniform: 2.785310294434488 Unigram: 4.084306052140644
2022-02-02 14:46:12 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 14:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:51:44 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 10.217 | ppl 1190.01 | wps 8560.4 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.357
2022-02-02 14:51:44 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 14:51:44 | INFO | train | epoch 095 | loss 6.091 | ppl 68.19 | wps 6290.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.694 | train_wall 306 | gb_free 6.1 | wall 31488
KL Stats: Epoch 95 Divergences: Uniform: 2.796188313009683 Unigram: 4.103962976139914
2022-02-02 14:51:44 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 14:51:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:53:20 | INFO | train_inner | epoch 096:     20 / 64 loss=6.089, ppl=68.07, wps=6155.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.685, train_wall=477, gb_free=6.1, wall=31584
2022-02-02 14:56:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:57:16 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 10.268 | ppl 1232.78 | wps 8563.7 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.357
2022-02-02 14:57:16 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 14:57:16 | INFO | train | epoch 096 | loss 6.071 | ppl 67.24 | wps 6287 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.693 | train_wall 306 | gb_free 6.1 | wall 31820
KL Stats: Epoch 96 Divergences: Uniform: 2.799836325529042 Unigram: 4.119819108190083
2022-02-02 14:57:16 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 14:57:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:01:45 | INFO | train_inner | epoch 097:     56 / 64 loss=6.067, ppl=67.04, wps=6470, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.694, train_wall=478, gb_free=6.1, wall=32089
2022-02-02 15:02:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:02:48 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 10.212 | ppl 1186.27 | wps 8553.9 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.357
2022-02-02 15:02:48 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 15:02:48 | INFO | train | epoch 097 | loss 6.053 | ppl 66.39 | wps 6292.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.693 | train_wall 306 | gb_free 6.1 | wall 32152
KL Stats: Epoch 97 Divergences: Uniform: 2.811112434769862 Unigram: 4.140997794803598
2022-02-02 15:02:48 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 15:02:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:07:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:08:20 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 10.248 | ppl 1215.85 | wps 8534.9 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.357
2022-02-02 15:08:20 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 15:08:20 | INFO | train | epoch 098 | loss 6.034 | ppl 65.53 | wps 6280.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.711 | train_wall 306 | gb_free 6.1 | wall 32485
KL Stats: Epoch 98 Divergences: Uniform: 2.8147290707481103 Unigram: 4.1620342120878755
2022-02-02 15:08:20 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 15:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:10:35 | INFO | train_inner | epoch 099:     28 / 64 loss=6.025, ppl=65.12, wps=6152.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.709, train_wall=477, gb_free=6.1, wall=32619
2022-02-02 15:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:13:55 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 10.256 | ppl 1222.52 | wps 8561.7 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.357
2022-02-02 15:13:55 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 15:13:55 | INFO | train | epoch 099 | loss 6.016 | ppl 64.72 | wps 6237.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.71 | train_wall 308 | gb_free 6.1 | wall 32819
KL Stats: Epoch 99 Divergences: Uniform: 2.816596355006476 Unigram: 4.179410547137102
2022-02-02 15:13:55 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 15:13:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:19:02 | INFO | train_inner | epoch 100:     64 / 64 loss=6.016, ppl=64.7, wps=6428.4, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.723, train_wall=480, gb_free=6.1, wall=33126
2022-02-02 15:19:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:19:27 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 10.259 | ppl 1224.97 | wps 8579 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.357
2022-02-02 15:19:27 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 15:19:27 | INFO | train | epoch 100 | loss 6 | ppl 64 | wps 6286.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.727 | train_wall 306 | gb_free 6.1 | wall 33152
KL Stats: Epoch 100 Divergences: Uniform: 2.8213181107297136 Unigram: 4.198739960835978
2022-02-02 15:19:27 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 15:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:24:59 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 10.202 | ppl 1177.82 | wps 8622.7 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.357
2022-02-02 15:24:59 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 15:24:59 | INFO | train | epoch 101 | loss 5.983 | ppl 63.24 | wps 6297.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.73 | train_wall 305 | gb_free 6.1 | wall 33483
KL Stats: Epoch 101 Divergences: Uniform: 2.8350737641982593 Unigram: 4.221041048467291
2022-02-02 15:24:59 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 15:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:27:52 | INFO | train_inner | epoch 102:     36 / 64 loss=5.964, ppl=62.43, wps=6161.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.733, train_wall=478, gb_free=6.1, wall=33657
2022-02-02 15:30:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:30:31 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 10.146 | ppl 1133.16 | wps 8583.3 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.357
2022-02-02 15:30:31 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 15:30:31 | INFO | train | epoch 102 | loss 5.965 | ppl 62.47 | wps 6288.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.731 | train_wall 306 | gb_free 6.1 | wall 33816
KL Stats: Epoch 102 Divergences: Uniform: 2.8349124158799146 Unigram: 4.23258254478309
2022-02-02 15:30:31 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 15:30:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:35:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:36:04 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 10.227 | ppl 1198.72 | wps 8548.4 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.357
2022-02-02 15:36:04 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 15:36:04 | INFO | train | epoch 103 | loss 5.95 | ppl 61.82 | wps 6286.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.73 | train_wall 306 | gb_free 6.1 | wall 34148
KL Stats: Epoch 103 Divergences: Uniform: 2.837568227524129 Unigram: 4.247417000839565
2022-02-02 15:36:04 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 15:36:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:36:42 | INFO | train_inner | epoch 104:      8 / 64 loss=5.96, ppl=62.24, wps=6154.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.727, train_wall=477, gb_free=6.1, wall=34186
2022-02-02 15:41:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:41:35 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 10.212 | ppl 1186.28 | wps 8556.9 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.357
2022-02-02 15:41:35 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 15:41:35 | INFO | train | epoch 104 | loss 5.933 | ppl 61.09 | wps 6292.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.73 | train_wall 306 | gb_free 6.1 | wall 34480
KL Stats: Epoch 104 Divergences: Uniform: 2.836682081010889 Unigram: 4.266617668505726
2022-02-02 15:41:35 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 15:41:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:45:07 | INFO | train_inner | epoch 105:     44 / 64 loss=5.924, ppl=60.7, wps=6474.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.729, train_wall=478, gb_free=6.1, wall=34691
2022-02-02 15:46:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:47:07 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 10.305 | ppl 1265.03 | wps 8553.4 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.357
2022-02-02 15:47:07 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 15:47:07 | INFO | train | epoch 105 | loss 5.916 | ppl 60.38 | wps 6296.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.727 | train_wall 305 | gb_free 6.1 | wall 34811
KL Stats: Epoch 105 Divergences: Uniform: 2.850286077405419 Unigram: 4.277567129054707
2022-02-02 15:47:07 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 15:47:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:52:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:52:39 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 10.255 | ppl 1221.8 | wps 8540.6 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.357
2022-02-02 15:52:39 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 15:52:39 | INFO | train | epoch 106 | loss 5.904 | ppl 59.87 | wps 6292.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.774 | train_wall 306 | gb_free 6.1 | wall 35143
KL Stats: Epoch 106 Divergences: Uniform: 2.849756043167893 Unigram: 4.296829027014206
2022-02-02 15:52:39 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 15:52:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:53:56 | INFO | train_inner | epoch 107:     16 / 64 loss=5.901, ppl=59.76, wps=6157.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.763, train_wall=477, gb_free=6.1, wall=35221
2022-02-02 15:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:58:12 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 10.202 | ppl 1177.64 | wps 8554.4 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.357
2022-02-02 15:58:12 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 15:58:12 | INFO | train | epoch 107 | loss 5.887 | ppl 59.18 | wps 6281.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.76 | train_wall 306 | gb_free 6.1 | wall 35476
KL Stats: Epoch 107 Divergences: Uniform: 2.8603028501873804 Unigram: 4.31183823129626
2022-02-02 15:58:12 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 15:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:02:24 | INFO | train_inner | epoch 108:     52 / 64 loss=5.883, ppl=59.03, wps=6431, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.752, train_wall=481, gb_free=6.1, wall=35729
2022-02-02 16:03:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:03:48 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 10.228 | ppl 1199.64 | wps 8438.9 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.357
2022-02-02 16:03:48 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 16:03:48 | INFO | train | epoch 108 | loss 5.872 | ppl 58.58 | wps 6217.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.751 | train_wall 309 | gb_free 6.1 | wall 35812
KL Stats: Epoch 108 Divergences: Uniform: 2.866753061136245 Unigram: 4.337158457311164
2022-02-02 16:03:48 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 16:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:09:24 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.363 | ppl 1317.11 | wps 8422.1 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.357
2022-02-02 16:09:24 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 16:09:24 | INFO | train | epoch 109 | loss 5.857 | ppl 57.97 | wps 6202.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.765 | train_wall 310 | gb_free 6.1 | wall 36149
KL Stats: Epoch 109 Divergences: Uniform: 2.863208087031385 Unigram: 4.338649745522951
2022-02-02 16:09:24 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 16:09:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:11:21 | INFO | train_inner | epoch 110:     24 / 64 loss=5.85, ppl=57.69, wps=6073.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.767, train_wall=484, gb_free=6.1, wall=36265
2022-02-02 16:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:15:00 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.224 | ppl 1195.83 | wps 8440.6 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.357
2022-02-02 16:15:00 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 16:15:00 | INFO | train | epoch 110 | loss 5.843 | ppl 57.42 | wps 6213.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.781 | train_wall 309 | gb_free 6.1 | wall 36485
KL Stats: Epoch 110 Divergences: Uniform: 2.8692498922453846 Unigram: 4.358958393322115
2022-02-02 16:15:00 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 16:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:19:53 | INFO | train_inner | epoch 111:     60 / 64 loss=5.845, ppl=57.48, wps=6382.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.795, train_wall=485, gb_free=6.1, wall=36777
2022-02-02 16:20:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:20:37 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.314 | ppl 1273.14 | wps 8426.1 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.357
2022-02-02 16:20:37 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 16:20:37 | INFO | train | epoch 111 | loss 5.831 | ppl 56.94 | wps 6198.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.802 | train_wall 310 | gb_free 6.1 | wall 36822
KL Stats: Epoch 111 Divergences: Uniform: 2.8735454205243363 Unigram: 4.368739689184833
2022-02-02 16:20:37 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 16:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:25:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:26:14 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.384 | ppl 1335.99 | wps 8427.8 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.357
2022-02-02 16:26:14 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 16:26:14 | INFO | train | epoch 112 | loss 5.815 | ppl 56.28 | wps 6202.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.771 | train_wall 310 | gb_free 6.1 | wall 37158
KL Stats: Epoch 112 Divergences: Uniform: 2.869928011511148 Unigram: 4.389409567057902
2022-02-02 16:26:14 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 16:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:28:50 | INFO | train_inner | epoch 113:     32 / 64 loss=5.801, ppl=55.77, wps=6075.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.779, train_wall=483, gb_free=6.1, wall=37314
2022-02-02 16:31:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:31:50 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.388 | ppl 1340.37 | wps 8538.8 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.357
2022-02-02 16:31:50 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 16:31:50 | INFO | train | epoch 113 | loss 5.802 | ppl 55.78 | wps 6218.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.781 | train_wall 309 | gb_free 6.1 | wall 37494
KL Stats: Epoch 113 Divergences: Uniform: 2.8758320778780284 Unigram: 4.395736471896589
2022-02-02 16:31:50 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 16:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:37:23 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.305 | ppl 1265.36 | wps 8540.4 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.357
2022-02-02 16:37:23 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 16:37:23 | INFO | train | epoch 114 | loss 5.789 | ppl 55.31 | wps 6267.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.806 | train_wall 307 | gb_free 6.1 | wall 37828
KL Stats: Epoch 114 Divergences: Uniform: 2.8808982101377785 Unigram: 4.411243806348819
2022-02-02 16:37:23 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 16:37:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:37:43 | INFO | train_inner | epoch 115:      4 / 64 loss=5.803, ppl=55.82, wps=6118.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.796, train_wall=480, gb_free=6.1, wall=37847
2022-02-02 16:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:42:57 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.386 | ppl 1338.12 | wps 8542.4 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.357
2022-02-02 16:42:57 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 16:42:57 | INFO | train | epoch 115 | loss 5.776 | ppl 54.81 | wps 6264.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.809 | train_wall 307 | gb_free 6.1 | wall 38161
KL Stats: Epoch 115 Divergences: Uniform: 2.8806896698617743 Unigram: 4.430674850490957
2022-02-02 16:42:57 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 16:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:46:10 | INFO | train_inner | epoch 116:     40 / 64 loss=5.762, ppl=54.28, wps=6446.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.806, train_wall=480, gb_free=6.1, wall=38354
2022-02-02 16:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:48:30 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.302 | ppl 1262.78 | wps 8523.4 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.357
2022-02-02 16:48:30 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 16:48:30 | INFO | train | epoch 116 | loss 5.763 | ppl 54.29 | wps 6271.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.797 | train_wall 307 | gb_free 6.1 | wall 38494
KL Stats: Epoch 116 Divergences: Uniform: 2.8850070683097924 Unigram: 4.44038936311914
2022-02-02 16:48:30 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 16:48:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:54:03 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.295 | ppl 1256.46 | wps 8527.1 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.357
2022-02-02 16:54:03 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 16:54:03 | INFO | train | epoch 117 | loss 5.75 | ppl 53.8 | wps 6266 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.808 | train_wall 307 | gb_free 6.1 | wall 38827
KL Stats: Epoch 117 Divergences: Uniform: 2.895048915784305 Unigram: 4.4554862741147785
2022-02-02 16:54:03 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 16:54:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:55:01 | INFO | train_inner | epoch 118:     12 / 64 loss=5.755, ppl=54.01, wps=6133.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.806, train_wall=479, gb_free=6.1, wall=38885
2022-02-02 16:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:59:36 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.273 | ppl 1237.39 | wps 8540.5 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.357
2022-02-02 16:59:36 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 16:59:36 | INFO | train | epoch 118 | loss 5.736 | ppl 53.29 | wps 6280.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.806 | train_wall 306 | gb_free 6.1 | wall 39160
KL Stats: Epoch 118 Divergences: Uniform: 2.9030227965902236 Unigram: 4.47455055450155
2022-02-02 16:59:36 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 16:59:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:03:26 | INFO | train_inner | epoch 119:     48 / 64 loss=5.726, ppl=52.95, wps=6468.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.811, train_wall=478, gb_free=6.1, wall=39391
2022-02-02 17:04:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:05:08 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.404 | ppl 1354.95 | wps 8544.5 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.357
2022-02-02 17:05:08 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 17:05:08 | INFO | train | epoch 119 | loss 5.725 | ppl 52.91 | wps 6292.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.83 | train_wall 306 | gb_free 6.1 | wall 39492
KL Stats: Epoch 119 Divergences: Uniform: 2.8955771956928453 Unigram: 4.482411504373834
2022-02-02 17:05:08 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 17:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:10:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:10:40 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.294 | ppl 1255.19 | wps 8548.6 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.357
2022-02-02 17:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 17:10:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint120.pt
2022-02-02 17:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint120.pt
2022-02-02 17:10:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.294) (writing took 3.5406652899982873 seconds)
2022-02-02 17:10:43 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 17:10:43 | INFO | train | epoch 120 | loss 5.713 | ppl 52.46 | wps 6223.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.851 | train_wall 306 | gb_free 6.1 | wall 39827
KL Stats: Epoch 120 Divergences: Uniform: 2.899229170108868 Unigram: 4.50425853593795
2022-02-02 17:10:43 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 17:10:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:12:19 | INFO | train_inner | epoch 121:     20 / 64 loss=5.713, ppl=52.45, wps=6115.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.855, train_wall=477, gb_free=6.1, wall=39924
2022-02-02 17:15:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:16:15 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.349 | ppl 1303.94 | wps 8551.9 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.357
2022-02-02 17:16:15 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 17:16:15 | INFO | train | epoch 121 | loss 5.701 | ppl 52.03 | wps 6287.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.842 | train_wall 306 | gb_free 6.1 | wall 40160
KL Stats: Epoch 121 Divergences: Uniform: 2.905242417687265 Unigram: 4.5065356215211585
2022-02-02 17:16:15 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 17:16:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:20:45 | INFO | train_inner | epoch 122:     56 / 64 loss=5.7, ppl=51.98, wps=6462.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.833, train_wall=479, gb_free=6.1, wall=40429
2022-02-02 17:21:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:21:48 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.408 | ppl 1358.49 | wps 8544.6 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.357
2022-02-02 17:21:48 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 17:21:48 | INFO | train | epoch 122 | loss 5.689 | ppl 51.6 | wps 6280.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.837 | train_wall 306 | gb_free 6.1 | wall 40492
KL Stats: Epoch 122 Divergences: Uniform: 2.8987870806860383 Unigram: 4.525278439375755
2022-02-02 17:21:48 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 17:21:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:26:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:27:20 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.276 | ppl 1239.63 | wps 8527.5 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.357
2022-02-02 17:27:20 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 17:27:20 | INFO | train | epoch 123 | loss 5.68 | ppl 51.25 | wps 6288.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.862 | train_wall 306 | gb_free 6.1 | wall 40824
KL Stats: Epoch 123 Divergences: Uniform: 2.9146122647770976 Unigram: 4.537839571211638
2022-02-02 17:27:20 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 17:27:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:29:35 | INFO | train_inner | epoch 124:     28 / 64 loss=5.673, ppl=51.01, wps=6151.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.855, train_wall=477, gb_free=6.1, wall=40959
2022-02-02 17:32:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:32:53 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.312 | ppl 1271.53 | wps 8502 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.357
2022-02-02 17:32:53 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 17:32:53 | INFO | train | epoch 124 | loss 5.665 | ppl 50.72 | wps 6268.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.841 | train_wall 307 | gb_free 6.1 | wall 41158
KL Stats: Epoch 124 Divergences: Uniform: 2.9134367011781803 Unigram: 4.554359096344238
2022-02-02 17:32:53 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 17:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:38:01 | INFO | train_inner | epoch 125:     64 / 64 loss=5.667, ppl=50.79, wps=6438.7, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.852, train_wall=479, gb_free=6.1, wall=41466
2022-02-02 17:38:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:38:27 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.33 | ppl 1287.08 | wps 8497.1 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.357
2022-02-02 17:38:27 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 17:38:27 | INFO | train | epoch 125 | loss 5.655 | ppl 50.39 | wps 6257.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.857 | train_wall 307 | gb_free 6.1 | wall 41491
KL Stats: Epoch 125 Divergences: Uniform: 2.917922323034755 Unigram: 4.5675064147021365
2022-02-02 17:38:27 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 17:38:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:44:01 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.425 | ppl 1374.62 | wps 8522.3 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.357
2022-02-02 17:44:01 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 17:44:01 | INFO | train | epoch 126 | loss 5.645 | ppl 50.05 | wps 6258.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.875 | train_wall 307 | gb_free 6.1 | wall 41825
KL Stats: Epoch 126 Divergences: Uniform: 2.9262786349666103 Unigram: 4.583382409887741
2022-02-02 17:44:01 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 17:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:46:55 | INFO | train_inner | epoch 127:     36 / 64 loss=5.629, ppl=49.5, wps=6125.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.862, train_wall=481, gb_free=6.1, wall=41999
2022-02-02 17:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:49:35 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.416 | ppl 1366.17 | wps 8508.8 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.357
2022-02-02 17:49:35 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 17:49:35 | INFO | train | epoch 127 | loss 5.636 | ppl 49.72 | wps 6257.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.849 | train_wall 307 | gb_free 6.1 | wall 42159
KL Stats: Epoch 127 Divergences: Uniform: 2.9155248765991995 Unigram: 4.591380394886083
2022-02-02 17:49:35 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 17:49:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:54:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:55:08 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.337 | ppl 1293.48 | wps 8496 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.357
2022-02-02 17:55:08 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 17:55:08 | INFO | train | epoch 128 | loss 5.624 | ppl 49.33 | wps 6265.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.878 | train_wall 307 | gb_free 6.1 | wall 42492
KL Stats: Epoch 128 Divergences: Uniform: 2.9202934297730114 Unigram: 4.606134876906475
2022-02-02 17:55:08 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 17:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:55:47 | INFO | train_inner | epoch 129:      8 / 64 loss=5.637, ppl=49.77, wps=6130.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.874, train_wall=479, gb_free=6.1, wall=42531
2022-02-02 18:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:00:42 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.38 | ppl 1332.94 | wps 8485.5 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.357
2022-02-02 18:00:42 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 18:00:42 | INFO | train | epoch 129 | loss 5.616 | ppl 49.05 | wps 6258.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.902 | train_wall 307 | gb_free 6.1 | wall 42826
KL Stats: Epoch 129 Divergences: Uniform: 2.925766995891803 Unigram: 4.614984761012484
2022-02-02 18:00:42 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 18:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:04:14 | INFO | train_inner | epoch 130:     44 / 64 loss=5.604, ppl=48.65, wps=6438.2, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.889, train_wall=481, gb_free=6.1, wall=43039
2022-02-02 18:05:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:06:15 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.424 | ppl 1373.43 | wps 8490.9 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.357
2022-02-02 18:06:15 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 18:06:15 | INFO | train | epoch 130 | loss 5.603 | ppl 48.61 | wps 6259.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.872 | train_wall 307 | gb_free 6.1 | wall 43160
KL Stats: Epoch 130 Divergences: Uniform: 2.9263529572230786 Unigram: 4.6221537710664755
2022-02-02 18:06:15 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 18:06:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:11:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:11:49 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.361 | ppl 1314.83 | wps 8514.8 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.357
2022-02-02 18:11:49 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 18:11:49 | INFO | train | epoch 131 | loss 5.595 | ppl 48.33 | wps 6264.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.9 | train_wall 307 | gb_free 6.1 | wall 43493
KL Stats: Epoch 131 Divergences: Uniform: 2.9301492751993923 Unigram: 4.635866447284494
2022-02-02 18:11:49 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 18:11:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:13:06 | INFO | train_inner | epoch 132:     16 / 64 loss=5.595, ppl=48.34, wps=6130.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.889, train_wall=479, gb_free=6.1, wall=43570
2022-02-02 18:16:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:17:22 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.441 | ppl 1390.35 | wps 8534.9 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.357
2022-02-02 18:17:22 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 18:17:22 | INFO | train | epoch 132 | loss 5.586 | ppl 48.02 | wps 6267.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.914 | train_wall 307 | gb_free 6.1 | wall 43826
KL Stats: Epoch 132 Divergences: Uniform: 2.9286565344650057 Unigram: 4.647930316061536
2022-02-02 18:17:22 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 18:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:21:32 | INFO | train_inner | epoch 133:     52 / 64 loss=5.581, ppl=47.88, wps=6457.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.905, train_wall=479, gb_free=6.1, wall=44076
2022-02-02 18:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:22:54 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.453 | ppl 1402.19 | wps 8488.8 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.357
2022-02-02 18:22:54 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 18:22:54 | INFO | train | epoch 133 | loss 5.572 | ppl 47.57 | wps 6282.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.878 | train_wall 306 | gb_free 6.1 | wall 44159
KL Stats: Epoch 133 Divergences: Uniform: 2.9369353301991796 Unigram: 4.659428361146862
2022-02-02 18:22:54 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 18:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:28:27 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.383 | ppl 1335.38 | wps 8540.4 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.357
2022-02-02 18:28:27 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 18:28:27 | INFO | train | epoch 134 | loss 5.566 | ppl 47.37 | wps 6283.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.924 | train_wall 306 | gb_free 6.1 | wall 44491
KL Stats: Epoch 134 Divergences: Uniform: 2.939255413350877 Unigram: 4.672048897622587
2022-02-02 18:28:27 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 18:28:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:30:22 | INFO | train_inner | epoch 135:     24 / 64 loss=5.556, ppl=47.06, wps=6149.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.899, train_wall=477, gb_free=6.1, wall=44607
2022-02-02 18:33:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:33:59 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.442 | ppl 1391.52 | wps 8516.4 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.357
2022-02-02 18:33:59 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 18:33:59 | INFO | train | epoch 135 | loss 5.554 | ppl 46.99 | wps 6285.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.902 | train_wall 306 | gb_free 6.1 | wall 44823
KL Stats: Epoch 135 Divergences: Uniform: 2.9346916206772997 Unigram: 4.68025902182168
2022-02-02 18:33:59 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 18:33:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:38:48 | INFO | train_inner | epoch 136:     60 / 64 loss=5.56, ppl=47.18, wps=6462.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.932, train_wall=479, gb_free=6.1, wall=45112
2022-02-02 18:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:39:32 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.409 | ppl 1359.5 | wps 8544.6 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.357
2022-02-02 18:39:32 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 18:39:32 | INFO | train | epoch 136 | loss 5.547 | ppl 46.76 | wps 6283.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.931 | train_wall 306 | gb_free 6.1 | wall 45156
KL Stats: Epoch 136 Divergences: Uniform: 2.938422410688134 Unigram: 4.688587628519911
2022-02-02 18:39:32 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 18:39:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:45:04 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.416 | ppl 1365.99 | wps 8561.2 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.357
2022-02-02 18:45:04 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 18:45:04 | INFO | train | epoch 137 | loss 5.533 | ppl 46.3 | wps 6291.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.916 | train_wall 306 | gb_free 6.1 | wall 45488
KL Stats: Epoch 137 Divergences: Uniform: 2.9452147918757046 Unigram: 4.705109268625312
2022-02-02 18:45:04 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 18:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:47:37 | INFO | train_inner | epoch 138:     32 / 64 loss=5.524, ppl=46.01, wps=6159.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.923, train_wall=477, gb_free=6.1, wall=45641
2022-02-02 18:50:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:50:35 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.354 | ppl 1308.67 | wps 8553.4 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.357
2022-02-02 18:50:35 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 18:50:35 | INFO | train | epoch 138 | loss 5.528 | ppl 46.14 | wps 6295.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.944 | train_wall 305 | gb_free 6.1 | wall 45820
KL Stats: Epoch 138 Divergences: Uniform: 2.951382468130871 Unigram: 4.720773701132322
2022-02-02 18:50:35 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 18:50:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:55:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:56:07 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.378 | ppl 1330.82 | wps 8558.7 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.357
2022-02-02 18:56:07 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 18:56:07 | INFO | train | epoch 139 | loss 5.516 | ppl 45.77 | wps 6294.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.952 | train_wall 305 | gb_free 6.1 | wall 46151
KL Stats: Epoch 139 Divergences: Uniform: 2.9520065859588476 Unigram: 4.728375228732838
2022-02-02 18:56:07 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 18:56:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:56:26 | INFO | train_inner | epoch 140:      4 / 64 loss=5.528, ppl=46.15, wps=6159.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.952, train_wall=477, gb_free=6.1, wall=46171
2022-02-02 19:01:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:01:39 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.403 | ppl 1353.95 | wps 8546.3 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.357
2022-02-02 19:01:39 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 19:01:39 | INFO | train | epoch 140 | loss 5.509 | ppl 45.55 | wps 6287.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.956 | train_wall 306 | gb_free 6.1 | wall 46484
KL Stats: Epoch 140 Divergences: Uniform: 2.9465950882493046 Unigram: 4.741926791770586
2022-02-02 19:01:39 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 19:01:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:04:52 | INFO | train_inner | epoch 141:     40 / 64 loss=5.499, ppl=45.21, wps=6468.3, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.95, train_wall=478, gb_free=6.1, wall=46676
2022-02-02 19:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:07:12 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.463 | ppl 1411.45 | wps 8551.3 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.357
2022-02-02 19:07:12 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 19:07:12 | INFO | train | epoch 141 | loss 5.502 | ppl 45.3 | wps 6287.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.952 | train_wall 306 | gb_free 6.1 | wall 46816
KL Stats: Epoch 141 Divergences: Uniform: 2.954030343071387 Unigram: 4.75412117889919
2022-02-02 19:07:12 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 19:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:12:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:12:43 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.443 | ppl 1391.58 | wps 8578.2 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.357
2022-02-02 19:12:43 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 19:12:43 | INFO | train | epoch 142 | loss 5.494 | ppl 45.06 | wps 6293.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.972 | train_wall 306 | gb_free 6.1 | wall 47148
KL Stats: Epoch 142 Divergences: Uniform: 2.9619648620598698 Unigram: 4.762711754387027
2022-02-02 19:12:43 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 19:12:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:13:41 | INFO | train_inner | epoch 143:     12 / 64 loss=5.5, ppl=45.26, wps=6154.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.975, train_wall=477, gb_free=6.1, wall=47206
2022-02-02 19:17:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:18:16 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.417 | ppl 1367.43 | wps 8546.2 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.357
2022-02-02 19:18:16 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 19:18:16 | INFO | train | epoch 143 | loss 5.485 | ppl 44.78 | wps 6280.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.959 | train_wall 306 | gb_free 6.1 | wall 47480
KL Stats: Epoch 143 Divergences: Uniform: 2.9626687889463152 Unigram: 4.772689738487382
2022-02-02 19:18:16 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 19:18:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:22:07 | INFO | train_inner | epoch 144:     48 / 64 loss=5.475, ppl=44.46, wps=6465.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.952, train_wall=479, gb_free=6.1, wall=47711
2022-02-02 19:23:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:23:48 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.52 | ppl 1468.44 | wps 8553.3 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.357
2022-02-02 19:23:48 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 19:23:48 | INFO | train | epoch 144 | loss 5.475 | ppl 44.47 | wps 6289 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.958 | train_wall 306 | gb_free 6.1 | wall 47812
KL Stats: Epoch 144 Divergences: Uniform: 2.964622407926753 Unigram: 4.793078727315809
2022-02-02 19:23:48 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 19:23:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:29:20 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.407 | ppl 1358.21 | wps 8575.1 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.357
2022-02-02 19:29:20 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 19:29:20 | INFO | train | epoch 145 | loss 5.469 | ppl 44.3 | wps 6292 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 1.023 | train_wall 306 | gb_free 6.1 | wall 48144
KL Stats: Epoch 145 Divergences: Uniform: 2.965559347967968 Unigram: 4.792505992765803
2022-02-02 19:29:20 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 19:29:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:30:56 | INFO | train_inner | epoch 146:     20 / 64 loss=5.471, ppl=44.36, wps=6158.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=1.011, train_wall=477, gb_free=6.1, wall=48240
2022-02-02 19:34:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:34:52 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.424 | ppl 1373.59 | wps 8548.8 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.357
2022-02-02 19:34:52 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 19:34:52 | INFO | train | epoch 146 | loss 5.46 | ppl 44.01 | wps 6293.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.996 | train_wall 305 | gb_free 6.1 | wall 48476
KL Stats: Epoch 146 Divergences: Uniform: 2.9641882076932227 Unigram: 4.801677223422291
2022-02-02 19:34:52 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 19:34:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:39:21 | INFO | train_inner | epoch 147:     56 / 64 loss=5.456, ppl=43.89, wps=6475.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.982, train_wall=478, gb_free=6.1, wall=48745
2022-02-02 19:39:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:40:24 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.371 | ppl 1324.44 | wps 8558.4 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.357
2022-02-02 19:40:24 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 19:40:24 | INFO | train | epoch 147 | loss 5.451 | ppl 43.75 | wps 6295 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.993 | train_wall 305 | gb_free 6.1 | wall 48808
KL Stats: Epoch 147 Divergences: Uniform: 2.9639222710808806 Unigram: 4.808484106025746
2022-02-02 19:40:24 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 19:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:45:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:45:56 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.409 | ppl 1359.61 | wps 8553.2 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.357
2022-02-02 19:45:56 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 19:45:56 | INFO | train | epoch 148 | loss 5.444 | ppl 43.53 | wps 6290.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.988 | train_wall 306 | gb_free 6.1 | wall 49140
KL Stats: Epoch 148 Divergences: Uniform: 2.9679688575582084 Unigram: 4.826304436999853
2022-02-02 19:45:56 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 19:45:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:48:10 | INFO | train_inner | epoch 149:     28 / 64 loss=5.438, ppl=43.36, wps=6157.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=1.008, train_wall=477, gb_free=6.1, wall=49275
2022-02-02 19:51:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:51:28 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.501 | ppl 1449.14 | wps 8576.9 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.357
2022-02-02 19:51:28 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 19:51:28 | INFO | train | epoch 149 | loss 5.438 | ppl 43.36 | wps 6292.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 1.038 | train_wall 306 | gb_free 6.1 | wall 49472
KL Stats: Epoch 149 Divergences: Uniform: 2.9688951497177416 Unigram: 4.823071381593883
2022-02-02 19:51:28 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 19:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:56:34 | INFO | train_inner | epoch 150:     64 / 64 loss=5.442, ppl=43.49, wps=6466.5, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=1.024, train_wall=477, gb_free=6.1, wall=49779
2022-02-02 19:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:57:00 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.437 | ppl 1386.53 | wps 8538.5 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.357
2022-02-02 19:57:00 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 19:57:00 | INFO | train | epoch 150 | loss 5.43 | ppl 43.11 | wps 6283.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 1.008 | train_wall 306 | gb_free 6.1 | wall 49804
KL Stats: Epoch 150 Divergences: Uniform: 2.973447392582629 Unigram: 4.847806388306395
2022-02-02 19:57:00 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 19:57:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:02:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:02:32 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.522 | ppl 1469.94 | wps 8557.6 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.357
2022-02-02 20:02:32 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 20:02:32 | INFO | train | epoch 151 | loss 5.422 | ppl 42.86 | wps 6290.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.013 | train_wall 306 | gb_free 6.1 | wall 50136
KL Stats: Epoch 151 Divergences: Uniform: 2.9698222392514393 Unigram: 4.8535098305713635
2022-02-02 20:02:32 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 20:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:05:26 | INFO | train_inner | epoch 152:     36 / 64 loss=5.411, ppl=42.55, wps=6151.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.034, train_wall=479, gb_free=6.1, wall=50310
2022-02-02 20:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:08:05 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.469 | ppl 1417.02 | wps 8540.5 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.357
2022-02-02 20:08:05 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 20:08:05 | INFO | train | epoch 152 | loss 5.415 | ppl 42.65 | wps 6275 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.051 | train_wall 306 | gb_free 6.1 | wall 50469
KL Stats: Epoch 152 Divergences: Uniform: 2.9757149288297704 Unigram: 4.864467185071665
2022-02-02 20:08:05 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 20:08:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:13:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:13:37 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.385 | ppl 1337.08 | wps 8552.3 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.357
2022-02-02 20:13:37 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 20:13:37 | INFO | train | epoch 153 | loss 5.406 | ppl 42.39 | wps 6282.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 1.032 | train_wall 306 | gb_free 6.1 | wall 50802
KL Stats: Epoch 153 Divergences: Uniform: 2.977486294214322 Unigram: 4.87297828960461
2022-02-02 20:13:37 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 20:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:14:16 | INFO | train_inner | epoch 154:      8 / 64 loss=5.412, ppl=42.57, wps=6149.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=1.032, train_wall=478, gb_free=6.1, wall=50840
2022-02-02 20:18:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:19:09 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.46 | ppl 1408.91 | wps 8554.4 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.357
2022-02-02 20:19:09 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 20:19:09 | INFO | train | epoch 154 | loss 5.4 | ppl 42.21 | wps 6291.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.061 | train_wall 306 | gb_free 6.1 | wall 51134
KL Stats: Epoch 154 Divergences: Uniform: 2.9792725730884144 Unigram: 4.885605456508428
2022-02-02 20:19:09 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 20:19:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:22:41 | INFO | train_inner | epoch 155:     44 / 64 loss=5.39, ppl=41.94, wps=6469.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.047, train_wall=478, gb_free=6.1, wall=51345
2022-02-02 20:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:24:41 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.458 | ppl 1407.01 | wps 8550.9 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.357
2022-02-02 20:24:41 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 20:24:41 | INFO | train | epoch 155 | loss 5.392 | ppl 41.98 | wps 6287.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.046 | train_wall 306 | gb_free 6.1 | wall 51466
KL Stats: Epoch 155 Divergences: Uniform: 2.9746181138398855 Unigram: 4.891043725248659
2022-02-02 20:24:41 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 20:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:29:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:30:14 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.408 | ppl 1358.81 | wps 8547.1 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.357
2022-02-02 20:30:14 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 20:30:14 | INFO | train | epoch 156 | loss 5.387 | ppl 41.84 | wps 6285 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.09 | train_wall 306 | gb_free 6.1 | wall 51798
KL Stats: Epoch 156 Divergences: Uniform: 2.983035515744158 Unigram: 4.907107761051196
2022-02-02 20:30:14 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 20:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:31:31 | INFO | train_inner | epoch 157:     16 / 64 loss=5.39, ppl=41.92, wps=6151, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.079, train_wall=478, gb_free=6.1, wall=51875
2022-02-02 20:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:35:46 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.535 | ppl 1483.95 | wps 8550.6 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.357
2022-02-02 20:35:46 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 20:35:46 | INFO | train | epoch 157 | loss 5.377 | ppl 41.56 | wps 6280.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.04 | train_wall 306 | gb_free 6.1 | wall 52131
KL Stats: Epoch 157 Divergences: Uniform: 2.9821358361987076 Unigram: 4.921284113256232
2022-02-02 20:35:46 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 20:35:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:39:56 | INFO | train_inner | epoch 158:     52 / 64 loss=5.375, ppl=41.5, wps=6464.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.053, train_wall=479, gb_free=6.1, wall=52381
2022-02-02 20:40:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:41:18 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.503 | ppl 1451.2 | wps 8570.6 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.357
2022-02-02 20:41:18 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 20:41:18 | INFO | train | epoch 158 | loss 5.373 | ppl 41.44 | wps 6288.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.073 | train_wall 306 | gb_free 6.1 | wall 52463
KL Stats: Epoch 158 Divergences: Uniform: 2.9814300678911816 Unigram: 4.914162606172862
2022-02-02 20:41:18 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 20:41:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:46:51 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.494 | ppl 1442.34 | wps 8551.4 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.357
2022-02-02 20:46:51 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 20:46:51 | INFO | train | epoch 159 | loss 5.363 | ppl 41.15 | wps 6285.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.056 | train_wall 306 | gb_free 6.1 | wall 52795
KL Stats: Epoch 159 Divergences: Uniform: 2.9903740271218235 Unigram: 4.931095437584482
2022-02-02 20:46:51 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 20:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:48:46 | INFO | train_inner | epoch 160:     24 / 64 loss=5.361, ppl=41.1, wps=6152.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.075, train_wall=477, gb_free=6.1, wall=52911
2022-02-02 20:51:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:52:23 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.522 | ppl 1470.13 | wps 8551.8 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.357
2022-02-02 20:52:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 20:52:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint160.pt
2022-02-02 20:52:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint160.pt
2022-02-02 20:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.522) (writing took 3.5800556399917696 seconds)
2022-02-02 20:52:27 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 20:52:27 | INFO | train | epoch 160 | loss 5.359 | ppl 41.04 | wps 6218.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.087 | train_wall 306 | gb_free 6.1 | wall 53131
KL Stats: Epoch 160 Divergences: Uniform: 2.9839679846698 Unigram: 4.933723366318731
2022-02-02 20:52:27 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 20:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:57:15 | INFO | train_inner | epoch 161:     60 / 64 loss=5.361, ppl=41.08, wps=6422.7, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.089, train_wall=478, gb_free=6.1, wall=53419
2022-02-02 20:57:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:57:59 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.546 | ppl 1494.79 | wps 8555.5 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.357
2022-02-02 20:57:59 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 20:57:59 | INFO | train | epoch 161 | loss 5.351 | ppl 40.82 | wps 6290.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.099 | train_wall 306 | gb_free 6.1 | wall 53463
KL Stats: Epoch 161 Divergences: Uniform: 2.9924511688315385 Unigram: 4.950488863444254
2022-02-02 20:57:59 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 20:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:03:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:03:31 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.514 | ppl 1462.6 | wps 8537.2 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.357
2022-02-02 21:03:31 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 21:03:31 | INFO | train | epoch 162 | loss 5.345 | ppl 40.65 | wps 6278.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.127 | train_wall 306 | gb_free 6.1 | wall 53796
KL Stats: Epoch 162 Divergences: Uniform: 2.994758908186708 Unigram: 4.958399589359099
2022-02-02 21:03:31 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 21:03:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:06:06 | INFO | train_inner | epoch 163:     32 / 64 loss=5.334, ppl=40.32, wps=6144.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.135, train_wall=478, gb_free=6.1, wall=53950
2022-02-02 21:08:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:09:04 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.563 | ppl 1512.71 | wps 8573.6 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.357
2022-02-02 21:09:04 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 21:09:04 | INFO | train | epoch 163 | loss 5.339 | ppl 40.48 | wps 6279 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.152 | train_wall 306 | gb_free 6.1 | wall 54128
KL Stats: Epoch 163 Divergences: Uniform: 2.9882776797532085 Unigram: 4.962697395683658
2022-02-02 21:09:04 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 21:09:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:14:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:14:36 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.53 | ppl 1478.51 | wps 8538.2 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.357
2022-02-02 21:14:36 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 21:14:36 | INFO | train | epoch 164 | loss 5.333 | ppl 40.31 | wps 6287.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.121 | train_wall 306 | gb_free 6.1 | wall 54460
KL Stats: Epoch 164 Divergences: Uniform: 2.987573902182615 Unigram: 4.973062571344829
2022-02-02 21:14:36 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 21:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:14:55 | INFO | train_inner | epoch 165:      4 / 64 loss=5.343, ppl=40.6, wps=6153.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.133, train_wall=477, gb_free=6.1, wall=54480
2022-02-02 21:19:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:20:08 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.51 | ppl 1458.7 | wps 8582.1 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.357
2022-02-02 21:20:08 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 21:20:08 | INFO | train | epoch 165 | loss 5.326 | ppl 40.12 | wps 6292.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.137 | train_wall 306 | gb_free 6.1 | wall 54792
KL Stats: Epoch 165 Divergences: Uniform: 2.9946084897675833 Unigram: 4.982493676559374
2022-02-02 21:20:08 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 21:20:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:23:21 | INFO | train_inner | epoch 166:     40 / 64 loss=5.316, ppl=39.83, wps=6469.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.136, train_wall=478, gb_free=6.1, wall=54985
2022-02-02 21:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:25:40 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.577 | ppl 1527.65 | wps 8553.1 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.357
2022-02-02 21:25:40 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 21:25:40 | INFO | train | epoch 166 | loss 5.321 | ppl 39.98 | wps 6287.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.148 | train_wall 306 | gb_free 6.1 | wall 55125
KL Stats: Epoch 166 Divergences: Uniform: 2.9938342371253612 Unigram: 4.9917233619910055
2022-02-02 21:25:40 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 21:25:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:30:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:31:12 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.482 | ppl 1430.01 | wps 8566.2 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.357
2022-02-02 21:31:12 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 21:31:12 | INFO | train | epoch 167 | loss 5.317 | ppl 39.85 | wps 6289.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.156 | train_wall 306 | gb_free 6.1 | wall 55457
KL Stats: Epoch 167 Divergences: Uniform: 3.000077146876403 Unigram: 4.99961906065689
2022-02-02 21:31:12 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 21:31:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:32:10 | INFO | train_inner | epoch 168:     12 / 64 loss=5.324, ppl=40.05, wps=6154.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.16, train_wall=477, gb_free=6.1, wall=55514
2022-02-02 21:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:36:45 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.482 | ppl 1430.11 | wps 8545.8 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.357
2022-02-02 21:36:45 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 21:36:45 | INFO | train | epoch 168 | loss 5.307 | ppl 39.6 | wps 6283.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.146 | train_wall 306 | gb_free 6.1 | wall 55789
KL Stats: Epoch 168 Divergences: Uniform: 2.9954201190989123 Unigram: 5.003125994140923
2022-02-02 21:36:45 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 21:36:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:40:38 | INFO | train_inner | epoch 169:     48 / 64 loss=5.298, ppl=39.35, wps=6441.8, ups=0.2, wpb=32686.1, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.146, train_wall=481, gb_free=6.1, wall=56022
2022-02-02 21:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:42:19 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.572 | ppl 1522.62 | wps 8549.4 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.357
2022-02-02 21:42:19 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 21:42:19 | INFO | train | epoch 169 | loss 5.302 | ppl 39.45 | wps 6250.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.161 | train_wall 308 | gb_free 6.1 | wall 56123
KL Stats: Epoch 169 Divergences: Uniform: 3.0060175410176297 Unigram: 5.015993261146799
2022-02-02 21:42:19 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 21:42:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:47:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:47:51 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.634 | ppl 1588.85 | wps 8561.6 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.357
2022-02-02 21:47:51 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 21:47:51 | INFO | train | epoch 170 | loss 5.297 | ppl 39.33 | wps 6290.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.161 | train_wall 306 | gb_free 6.1 | wall 56455
KL Stats: Epoch 170 Divergences: Uniform: 3.0021089580500333 Unigram: 5.024978774841553
2022-02-02 21:47:51 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 21:47:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:49:27 | INFO | train_inner | epoch 171:     20 / 64 loss=5.302, ppl=39.45, wps=6156.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.182, train_wall=477, gb_free=6.1, wall=56551
2022-02-02 21:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:53:23 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.46 | ppl 1408.24 | wps 8549.7 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.357
2022-02-02 21:53:23 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 21:53:23 | INFO | train | epoch 171 | loss 5.293 | ppl 39.2 | wps 6294.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.216 | train_wall 305 | gb_free 6.1 | wall 56787
KL Stats: Epoch 171 Divergences: Uniform: 3.0065102293604595 Unigram: 5.028731876513824
2022-02-02 21:53:23 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 21:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:57:52 | INFO | train_inner | epoch 172:     56 / 64 loss=5.288, ppl=39.07, wps=6474.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.18, train_wall=478, gb_free=6.1, wall=57056
2022-02-02 21:58:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:58:55 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.497 | ppl 1445.3 | wps 8552.5 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.357
2022-02-02 21:58:55 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 21:58:55 | INFO | train | epoch 172 | loss 5.284 | ppl 38.97 | wps 6293.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.168 | train_wall 305 | gb_free 6.1 | wall 57119
KL Stats: Epoch 172 Divergences: Uniform: 3.006793934135928 Unigram: 5.035653622267884
2022-02-02 21:58:55 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 21:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:04:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:04:27 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.499 | ppl 1446.99 | wps 8558.3 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.357
2022-02-02 22:04:27 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 22:04:27 | INFO | train | epoch 173 | loss 5.279 | ppl 38.83 | wps 6288.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.167 | train_wall 306 | gb_free 6.1 | wall 57451
KL Stats: Epoch 173 Divergences: Uniform: 3.0099115262706704 Unigram: 5.043109543102347
2022-02-02 22:04:27 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 22:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:06:41 | INFO | train_inner | epoch 174:     28 / 64 loss=5.273, ppl=38.65, wps=6156.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.17, train_wall=477, gb_free=6.1, wall=57586
2022-02-02 22:09:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:09:59 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.54 | ppl 1488.52 | wps 8525.1 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.357
2022-02-02 22:09:59 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 22:09:59 | INFO | train | epoch 174 | loss 5.274 | ppl 38.68 | wps 6291.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.197 | train_wall 305 | gb_free 6.1 | wall 57783
KL Stats: Epoch 174 Divergences: Uniform: 3.00319879678319 Unigram: 5.05049940135497
2022-02-02 22:09:59 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 22:09:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:15:05 | INFO | train_inner | epoch 175:     64 / 64 loss=5.282, ppl=38.9, wps=6468.7, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.206, train_wall=477, gb_free=6.1, wall=58090
2022-02-02 22:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:15:31 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.54 | ppl 1488.55 | wps 8539.6 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.357
2022-02-02 22:15:31 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 22:15:31 | INFO | train | epoch 175 | loss 5.268 | ppl 38.52 | wps 6288.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.196 | train_wall 306 | gb_free 6.1 | wall 58115
KL Stats: Epoch 175 Divergences: Uniform: 3.011627001705246 Unigram: 5.068128046119578
2022-02-02 22:15:31 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 22:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:21:03 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.596 | ppl 1548.11 | wps 8539.8 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.357
2022-02-02 22:21:03 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 22:21:03 | INFO | train | epoch 176 | loss 5.265 | ppl 38.45 | wps 6292.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.239 | train_wall 305 | gb_free 6.1 | wall 58447
KL Stats: Epoch 176 Divergences: Uniform: 3.0081586890679914 Unigram: 5.0761083386180355
2022-02-02 22:21:03 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 22:21:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:23:56 | INFO | train_inner | epoch 177:     36 / 64 loss=5.249, ppl=38.03, wps=6157.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.219, train_wall=478, gb_free=6.1, wall=58620
2022-02-02 22:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:26:35 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.582 | ppl 1532.89 | wps 8548.8 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.357
2022-02-02 22:26:35 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 22:26:35 | INFO | train | epoch 177 | loss 5.256 | ppl 38.22 | wps 6287.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.188 | train_wall 306 | gb_free 6.1 | wall 58779
KL Stats: Epoch 177 Divergences: Uniform: 3.0086350887550863 Unigram: 5.080541718233653
2022-02-02 22:26:35 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 22:26:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:31:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:32:07 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.556 | ppl 1505.34 | wps 8536.8 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.357
2022-02-02 22:32:07 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-02 22:32:07 | INFO | train | epoch 178 | loss 5.252 | ppl 38.12 | wps 6289.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.23 | train_wall 306 | gb_free 6.1 | wall 59111
KL Stats: Epoch 178 Divergences: Uniform: 3.0137219041704975 Unigram: 5.085486910050041
2022-02-02 22:32:07 | INFO | fairseq.trainer | begin training epoch 179
2022-02-02 22:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:32:46 | INFO | train_inner | epoch 179:      8 / 64 loss=5.261, ppl=38.33, wps=6154.8, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.222, train_wall=477, gb_free=6.1, wall=59150
2022-02-02 22:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:37:39 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.606 | ppl 1558.7 | wps 8547.8 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.357
2022-02-02 22:37:39 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-02 22:37:39 | INFO | train | epoch 179 | loss 5.249 | ppl 38.02 | wps 6292.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.24 | train_wall 306 | gb_free 6.1 | wall 59443
KL Stats: Epoch 179 Divergences: Uniform: 3.0112192081547926 Unigram: 5.084582339801949
2022-02-02 22:37:39 | INFO | fairseq.trainer | begin training epoch 180
2022-02-02 22:37:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:41:11 | INFO | train_inner | epoch 180:     44 / 64 loss=5.245, ppl=37.92, wps=6472.7, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.246, train_wall=478, gb_free=6.1, wall=59655
2022-02-02 22:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:43:11 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.596 | ppl 1547.35 | wps 8557.9 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.357
2022-02-02 22:43:11 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-02 22:43:11 | INFO | train | epoch 180 | loss 5.243 | ppl 37.86 | wps 6292.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.253 | train_wall 306 | gb_free 6.1 | wall 59775
KL Stats: Epoch 180 Divergences: Uniform: 3.0116565965092876 Unigram: 5.09212692631545
2022-02-02 22:43:11 | INFO | fairseq.trainer | begin training epoch 181
2022-02-02 22:43:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:48:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:48:43 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.626 | ppl 1579.84 | wps 8575.4 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.357
2022-02-02 22:48:43 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-02 22:48:43 | INFO | train | epoch 181 | loss 5.237 | ppl 37.72 | wps 6292.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.254 | train_wall 305 | gb_free 6.1 | wall 60107
KL Stats: Epoch 181 Divergences: Uniform: 3.015812518064361 Unigram: 5.106716434107957
2022-02-02 22:48:43 | INFO | fairseq.trainer | begin training epoch 182
2022-02-02 22:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:50:00 | INFO | train_inner | epoch 182:     16 / 64 loss=5.237, ppl=37.7, wps=6158.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.245, train_wall=477, gb_free=6.1, wall=60184
2022-02-02 22:53:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:54:15 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.573 | ppl 1523.74 | wps 8525.8 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.357
2022-02-02 22:54:15 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-02 22:54:15 | INFO | train | epoch 182 | loss 5.23 | ppl 37.54 | wps 6283.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.254 | train_wall 306 | gb_free 6.1 | wall 60440
KL Stats: Epoch 182 Divergences: Uniform: 3.0183162018292964 Unigram: 5.113279906474798
2022-02-02 22:54:15 | INFO | fairseq.trainer | begin training epoch 183
2022-02-02 22:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:58:28 | INFO | train_inner | epoch 183:     52 / 64 loss=5.229, ppl=37.5, wps=6432.8, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.265, train_wall=481, gb_free=6.1, wall=60692
2022-02-02 22:59:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:59:53 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.567 | ppl 1517.08 | wps 8309.2 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.357
2022-02-02 22:59:53 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-02 22:59:53 | INFO | train | epoch 183 | loss 5.228 | ppl 37.48 | wps 6192.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.272 | train_wall 310 | gb_free 6.1 | wall 60777
KL Stats: Epoch 183 Divergences: Uniform: 3.0206215052513667 Unigram: 5.124408115771311
2022-02-02 22:59:53 | INFO | fairseq.trainer | begin training epoch 184
2022-02-02 22:59:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:05:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:05:36 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.598 | ppl 1549.51 | wps 8198.7 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.357
2022-02-02 23:05:36 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-02 23:05:36 | INFO | train | epoch 184 | loss 5.222 | ppl 37.32 | wps 6080.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.266 | train_wall 316 | gb_free 6.1 | wall 61120
KL Stats: Epoch 184 Divergences: Uniform: 3.0193315815830357 Unigram: 5.126835910891936
2022-02-02 23:05:36 | INFO | fairseq.trainer | begin training epoch 185
2022-02-02 23:05:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:07:36 | INFO | train_inner | epoch 185:     24 / 64 loss=5.217, ppl=37.19, wps=5952.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.264, train_wall=493, gb_free=6.1, wall=61240
2022-02-02 23:10:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:11:19 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.572 | ppl 1522.03 | wps 8219.4 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.357
2022-02-02 23:11:19 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-02 23:11:19 | INFO | train | epoch 185 | loss 5.216 | ppl 37.16 | wps 6082.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.282 | train_wall 316 | gb_free 6.1 | wall 61464
KL Stats: Epoch 185 Divergences: Uniform: 3.0233673425023415 Unigram: 5.131707438880795
2022-02-02 23:11:19 | INFO | fairseq.trainer | begin training epoch 186
2022-02-02 23:11:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:16:17 | INFO | train_inner | epoch 186:     60 / 64 loss=5.221, ppl=37.29, wps=6265.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.29, train_wall=494, gb_free=6.1, wall=61761
2022-02-02 23:16:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:17:02 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.637 | ppl 1592.57 | wps 8229.1 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.357
2022-02-02 23:17:02 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-02 23:17:02 | INFO | train | epoch 186 | loss 5.211 | ppl 37.05 | wps 6092.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.279 | train_wall 315 | gb_free 6.1 | wall 61807
KL Stats: Epoch 186 Divergences: Uniform: 3.027816344831342 Unigram: 5.14219858209345
2022-02-02 23:17:02 | INFO | fairseq.trainer | begin training epoch 187
2022-02-02 23:17:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:22:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:22:45 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.598 | ppl 1550.15 | wps 8229.9 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.357
2022-02-02 23:22:45 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-02 23:22:45 | INFO | train | epoch 187 | loss 5.206 | ppl 36.91 | wps 6096.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.313 | train_wall 315 | gb_free 6.1 | wall 62149
KL Stats: Epoch 187 Divergences: Uniform: 3.016172175612706 Unigram: 5.14140947606899
2022-02-02 23:22:45 | INFO | fairseq.trainer | begin training epoch 188
2022-02-02 23:22:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:25:24 | INFO | train_inner | epoch 188:     32 / 64 loss=5.2, ppl=36.76, wps=5965.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.317, train_wall=492, gb_free=6.1, wall=62308
2022-02-02 23:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:28:28 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.675 | ppl 1635.42 | wps 8208.4 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.357
2022-02-02 23:28:28 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-02 23:28:28 | INFO | train | epoch 188 | loss 5.202 | ppl 36.81 | wps 6088.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.348 | train_wall 316 | gb_free 6.1 | wall 62492
KL Stats: Epoch 188 Divergences: Uniform: 3.010274532049749 Unigram: 5.153166846704123
2022-02-02 23:28:28 | INFO | fairseq.trainer | begin training epoch 189
2022-02-02 23:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:33:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:34:11 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.62 | ppl 1574.3 | wps 8224.6 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.357
2022-02-02 23:34:11 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-02 23:34:11 | INFO | train | epoch 189 | loss 5.194 | ppl 36.6 | wps 6094.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.307 | train_wall 315 | gb_free 6.1 | wall 62835
KL Stats: Epoch 189 Divergences: Uniform: 3.0245302945732595 Unigram: 5.163717574243592
2022-02-02 23:34:11 | INFO | fairseq.trainer | begin training epoch 190
2022-02-02 23:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:34:31 | INFO | train_inner | epoch 190:      4 / 64 loss=5.202, ppl=36.82, wps=5960.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.33, train_wall=492, gb_free=6.1, wall=62855
2022-02-02 23:39:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:39:53 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.594 | ppl 1545.32 | wps 8229.8 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.357
2022-02-02 23:39:53 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-02 23:39:53 | INFO | train | epoch 190 | loss 5.192 | ppl 36.55 | wps 6095.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.312 | train_wall 315 | gb_free 6.1 | wall 63178
KL Stats: Epoch 190 Divergences: Uniform: 3.026996363865446 Unigram: 5.171526446217597
2022-02-02 23:39:53 | INFO | fairseq.trainer | begin training epoch 191
2022-02-02 23:39:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:43:12 | INFO | train_inner | epoch 191:     40 / 64 loss=5.185, ppl=36.39, wps=6268.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.329, train_wall=493, gb_free=6.1, wall=63376
2022-02-02 23:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:45:36 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.593 | ppl 1544.22 | wps 8244.1 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.357
2022-02-02 23:45:36 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-02 23:45:36 | INFO | train | epoch 191 | loss 5.188 | ppl 36.45 | wps 6093.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.369 | train_wall 315 | gb_free 6.1 | wall 63520
KL Stats: Epoch 191 Divergences: Uniform: 3.0251499920805665 Unigram: 5.169653120011263
2022-02-02 23:45:36 | INFO | fairseq.trainer | begin training epoch 192
2022-02-02 23:45:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:51:19 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.528 | ppl 1476.29 | wps 8115.6 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.357
2022-02-02 23:51:19 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-02 23:51:19 | INFO | train | epoch 192 | loss 5.183 | ppl 36.34 | wps 6095.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.354 | train_wall 315 | gb_free 6.1 | wall 63863
KL Stats: Epoch 192 Divergences: Uniform: 3.022178626727169 Unigram: 5.181564865247758
2022-02-02 23:51:19 | INFO | fairseq.trainer | begin training epoch 193
2022-02-02 23:51:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:52:18 | INFO | train_inner | epoch 193:     12 / 64 loss=5.184, ppl=36.35, wps=5964.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.369, train_wall=492, gb_free=6.1, wall=63923
2022-02-02 23:56:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:57:01 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.545 | ppl 1493.64 | wps 8216.7 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.357
2022-02-02 23:57:01 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-02 23:57:01 | INFO | train | epoch 193 | loss 5.177 | ppl 36.16 | wps 6094.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.384 | train_wall 315 | gb_free 6.1 | wall 64206
KL Stats: Epoch 193 Divergences: Uniform: 3.0245584550562086 Unigram: 5.191287650460938
2022-02-02 23:57:01 | INFO | fairseq.trainer | begin training epoch 194
2022-02-02 23:57:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:01:00 | INFO | train_inner | epoch 194:     48 / 64 loss=5.174, ppl=36.1, wps=6269.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.375, train_wall=493, gb_free=6.1, wall=64444
2022-02-03 00:02:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:02:44 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.567 | ppl 1517.39 | wps 8218.9 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.357
2022-02-03 00:02:44 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-03 00:02:44 | INFO | train | epoch 194 | loss 5.172 | ppl 36.06 | wps 6091.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.378 | train_wall 315 | gb_free 6.1 | wall 64549
KL Stats: Epoch 194 Divergences: Uniform: 3.0292153410312603 Unigram: 5.196566245633128
2022-02-03 00:02:44 | INFO | fairseq.trainer | begin training epoch 195
2022-02-03 00:02:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:08:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:08:27 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.576 | ppl 1526.07 | wps 8249.7 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.357
2022-02-03 00:08:27 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-03 00:08:27 | INFO | train | epoch 195 | loss 5.17 | ppl 35.99 | wps 6103.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.384 | train_wall 315 | gb_free 6.1 | wall 64891
KL Stats: Epoch 195 Divergences: Uniform: 3.027596346918234 Unigram: 5.203745295088185
2022-02-03 00:08:27 | INFO | fairseq.trainer | begin training epoch 196
2022-02-03 00:08:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:10:06 | INFO | train_inner | epoch 196:     20 / 64 loss=5.167, ppl=35.92, wps=5967, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.38, train_wall=492, gb_free=6.1, wall=64990
2022-02-03 00:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:14:09 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.585 | ppl 1536.35 | wps 8247.6 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.357
2022-02-03 00:14:09 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 00:14:09 | INFO | train | epoch 196 | loss 5.166 | ppl 35.9 | wps 6093.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.392 | train_wall 315 | gb_free 6.1 | wall 65234
KL Stats: Epoch 196 Divergences: Uniform: 3.0320314157818666 Unigram: 5.208256452706883
2022-02-03 00:14:09 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 00:14:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:18:47 | INFO | train_inner | epoch 197:     56 / 64 loss=5.17, ppl=35.99, wps=6266, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.403, train_wall=494, gb_free=6.1, wall=65512
2022-02-03 00:19:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:19:52 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.584 | ppl 1535.16 | wps 8262.6 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.357
2022-02-03 00:19:52 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 00:19:52 | INFO | train | epoch 197 | loss 5.162 | ppl 35.81 | wps 6088.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.405 | train_wall 316 | gb_free 6.1 | wall 65577
KL Stats: Epoch 197 Divergences: Uniform: 3.0259904264610076 Unigram: 5.21077180787081
2022-02-03 00:19:52 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 00:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:25:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:25:35 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.631 | ppl 1585.72 | wps 8265.3 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.357
2022-02-03 00:25:35 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 00:25:35 | INFO | train | epoch 198 | loss 5.154 | ppl 35.61 | wps 6093.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.394 | train_wall 315 | gb_free 6.1 | wall 65919
KL Stats: Epoch 198 Divergences: Uniform: 3.0347852973582423 Unigram: 5.223729935742144
2022-02-03 00:25:35 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 00:25:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:27:54 | INFO | train_inner | epoch 199:     28 / 64 loss=5.151, ppl=35.53, wps=5966.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.415, train_wall=492, gb_free=6.1, wall=66058
2022-02-03 00:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:31:18 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.64 | ppl 1596.06 | wps 8229.6 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.357
2022-02-03 00:31:18 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 00:31:18 | INFO | train | epoch 199 | loss 5.153 | ppl 35.59 | wps 6096.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.449 | train_wall 315 | gb_free 6.1 | wall 66262
KL Stats: Epoch 199 Divergences: Uniform: 3.029164351731261 Unigram: 5.22557066008614
2022-02-03 00:31:18 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 00:31:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:36:34 | INFO | train_inner | epoch 200:     64 / 64 loss=5.158, ppl=35.7, wps=6268.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.438, train_wall=492, gb_free=6.1, wall=66578
2022-02-03 00:36:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:37:00 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.583 | ppl 1533.54 | wps 8254 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.357
2022-02-03 00:37:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-03 00:37:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint200.pt
2022-02-03 00:37:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint200.pt
2022-02-03 00:37:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#4/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.583) (writing took 3.6629377419885714 seconds)
2022-02-03 00:37:04 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-03 00:37:04 | INFO | train | epoch 200 | loss 5.147 | ppl 35.42 | wps 6030.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.435 | train_wall 315 | gb_free 6.1 | wall 66608
KL Stats: Epoch 200 Divergences: Uniform: 3.030708705378912 Unigram: 5.233732012500247
2022-02-03 00:37:04 | INFO | fairseq.trainer | begin training epoch 201
2022-02-03 00:37:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:42:47 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.665 | ppl 1623.56 | wps 8216.1 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.357
2022-02-03 00:42:47 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-03 00:42:47 | INFO | train | epoch 201 | loss 5.144 | ppl 35.36 | wps 6094.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.426 | train_wall 315 | gb_free 6.1 | wall 66951
KL Stats: Epoch 201 Divergences: Uniform: 3.037359328466789 Unigram: 5.238197542538497
2022-02-03 00:42:47 | INFO | fairseq.trainer | begin training epoch 202
2022-02-03 00:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:45:45 | INFO | train_inner | epoch 202:     36 / 64 loss=5.132, ppl=35.07, wps=5927.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.45, train_wall=493, gb_free=6.1, wall=67129
2022-02-03 00:48:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:48:29 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.693 | ppl 1655.24 | wps 8225.2 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.357
2022-02-03 00:48:29 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-03 00:48:29 | INFO | train | epoch 202 | loss 5.141 | ppl 35.28 | wps 6098.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.468 | train_wall 315 | gb_free 6.1 | wall 67294
KL Stats: Epoch 202 Divergences: Uniform: 3.0352679614326554 Unigram: 5.248300093944159
2022-02-03 00:48:29 | INFO | fairseq.trainer | begin training epoch 203
2022-02-03 00:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:53:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:54:12 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.649 | ppl 1605.89 | wps 8240.5 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.357
2022-02-03 00:54:12 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-03 00:54:12 | INFO | train | epoch 203 | loss 5.136 | ppl 35.15 | wps 6099.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.474 | train_wall 315 | gb_free 6.1 | wall 67636
KL Stats: Epoch 203 Divergences: Uniform: 3.0413348836682927 Unigram: 5.248892028967751
2022-02-03 00:54:12 | INFO | fairseq.trainer | begin training epoch 204
2022-02-03 00:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:54:51 | INFO | train_inner | epoch 204:      8 / 64 loss=5.144, ppl=35.36, wps=5969.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.464, train_wall=492, gb_free=6.1, wall=67676
2022-02-03 00:59:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:59:54 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.655 | ppl 1612.04 | wps 8233.2 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.357
2022-02-03 00:59:54 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-03 00:59:54 | INFO | train | epoch 204 | loss 5.133 | ppl 35.1 | wps 6102.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.481 | train_wall 315 | gb_free 6.1 | wall 67978
KL Stats: Epoch 204 Divergences: Uniform: 3.0405905668967255 Unigram: 5.258767372441197
2022-02-03 00:59:54 | INFO | fairseq.trainer | begin training epoch 205
2022-02-03 00:59:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:03:32 | INFO | train_inner | epoch 205:     44 / 64 loss=5.123, ppl=34.84, wps=6276.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.478, train_wall=493, gb_free=6.1, wall=68196
2022-02-03 01:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:05:36 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.698 | ppl 1660.77 | wps 8233.4 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.357
2022-02-03 01:05:36 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-03 01:05:36 | INFO | train | epoch 205 | loss 5.126 | ppl 34.93 | wps 6099.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.502 | train_wall 315 | gb_free 6.1 | wall 68321
KL Stats: Epoch 205 Divergences: Uniform: 3.0334410931976223 Unigram: 5.27035125329449
2022-02-03 01:05:36 | INFO | fairseq.trainer | begin training epoch 206
2022-02-03 01:05:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:10:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:11:20 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.647 | ppl 1603.25 | wps 8219.9 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.357
2022-02-03 01:11:20 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-03 01:11:20 | INFO | train | epoch 206 | loss 5.125 | ppl 34.89 | wps 6086.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.498 | train_wall 316 | gb_free 6.1 | wall 68664
KL Stats: Epoch 206 Divergences: Uniform: 3.036412821840404 Unigram: 5.270731707969561
2022-02-03 01:11:20 | INFO | fairseq.trainer | begin training epoch 207
2022-02-03 01:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:12:39 | INFO | train_inner | epoch 207:     16 / 64 loss=5.128, ppl=34.98, wps=5962.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.527, train_wall=492, gb_free=6.1, wall=68743
2022-02-03 01:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:17:02 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.588 | ppl 1539.57 | wps 8237.3 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.357
2022-02-03 01:17:02 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-02-03 01:17:02 | INFO | train | epoch 207 | loss 5.12 | ppl 34.77 | wps 6102.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.554 | train_wall 315 | gb_free 6.1 | wall 69006
KL Stats: Epoch 207 Divergences: Uniform: 3.0385452367653065 Unigram: 5.273876379396563
2022-02-03 01:17:02 | INFO | fairseq.trainer | begin training epoch 208
2022-02-03 01:17:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:21:20 | INFO | train_inner | epoch 208:     52 / 64 loss=5.116, ppl=34.67, wps=6272.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.525, train_wall=493, gb_free=6.1, wall=69264
2022-02-03 01:22:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:22:45 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 10.692 | ppl 1653.99 | wps 8230.8 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.357
2022-02-03 01:22:45 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-02-03 01:22:45 | INFO | train | epoch 208 | loss 5.114 | ppl 34.62 | wps 6092.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.52 | train_wall 315 | gb_free 6.1 | wall 69349
KL Stats: Epoch 208 Divergences: Uniform: 3.040913005325988 Unigram: 5.279561243425514
2022-02-03 01:22:45 | INFO | fairseq.trainer | begin training epoch 209
2022-02-03 01:22:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:28:27 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 10.66 | ppl 1617.97 | wps 8244.9 | wpb 2034.1 | bsz 4 | num_updates 13376 | best_loss 9.357
2022-02-03 01:28:27 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-02-03 01:28:27 | INFO | train | epoch 209 | loss 5.113 | ppl 34.6 | wps 6092.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13376 | lr 0.000273424 | gnorm 1.53 | train_wall 315 | gb_free 6.1 | wall 69692
KL Stats: Epoch 209 Divergences: Uniform: 3.0390467865965496 Unigram: 5.29058845255886
2022-02-03 01:28:27 | INFO | fairseq.trainer | begin training epoch 210
2022-02-03 01:28:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:30:27 | INFO | train_inner | epoch 210:     24 / 64 loss=5.108, ppl=34.5, wps=5962.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=13400, lr=0.000273179, gnorm=1.531, train_wall=492, gb_free=6.1, wall=69811
2022-02-03 01:33:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:34:10 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 10.599 | ppl 1550.57 | wps 8239.9 | wpb 2034.1 | bsz 4 | num_updates 13440 | best_loss 9.357
2022-02-03 01:34:10 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-02-03 01:34:10 | INFO | train | epoch 210 | loss 5.109 | ppl 34.51 | wps 6091.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13440 | lr 0.000272772 | gnorm 1.567 | train_wall 315 | gb_free 6.1 | wall 70035
KL Stats: Epoch 210 Divergences: Uniform: 3.0451140975190225 Unigram: 5.294169341094538
2022-02-03 01:34:10 | INFO | fairseq.trainer | begin training epoch 211
2022-02-03 01:34:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:39:08 | INFO | train_inner | epoch 211:     60 / 64 loss=5.114, ppl=34.63, wps=6269.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=13500, lr=0.000272166, gnorm=1.554, train_wall=493, gb_free=6.1, wall=70332
2022-02-03 01:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:39:53 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 10.626 | ppl 1580.41 | wps 8228.6 | wpb 2034.1 | bsz 4 | num_updates 13504 | best_loss 9.357
2022-02-03 01:39:53 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-02-03 01:39:53 | INFO | train | epoch 211 | loss 5.104 | ppl 34.38 | wps 6096.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13504 | lr 0.000272125 | gnorm 1.53 | train_wall 315 | gb_free 6.1 | wall 70377
KL Stats: Epoch 211 Divergences: Uniform: 3.042942473161395 Unigram: 5.307715300819475
2022-02-03 01:39:53 | INFO | fairseq.trainer | begin training epoch 212
2022-02-03 01:39:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:45:35 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 10.65 | ppl 1606.3 | wps 8225.3 | wpb 2034.1 | bsz 4 | num_updates 13568 | best_loss 9.357
2022-02-03 01:45:35 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-02-03 01:45:35 | INFO | train | epoch 212 | loss 5.101 | ppl 34.33 | wps 6098 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13568 | lr 0.000271483 | gnorm 1.573 | train_wall 315 | gb_free 6.1 | wall 70720
KL Stats: Epoch 212 Divergences: Uniform: 3.036457171399912 Unigram: 5.30602638064307
2022-02-03 01:45:35 | INFO | fairseq.trainer | begin training epoch 213
2022-02-03 01:45:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:48:14 | INFO | train_inner | epoch 213:     32 / 64 loss=5.094, ppl=34.14, wps=5967.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13600, lr=0.000271163, gnorm=1.601, train_wall=492, gb_free=6.1, wall=70878
2022-02-03 01:50:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:51:18 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 10.682 | ppl 1642.93 | wps 8219.9 | wpb 2034.1 | bsz 4 | num_updates 13632 | best_loss 9.357
2022-02-03 01:51:18 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-02-03 01:51:18 | INFO | train | epoch 213 | loss 5.1 | ppl 34.29 | wps 6096 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13632 | lr 0.000270845 | gnorm 1.631 | train_wall 315 | gb_free 6.1 | wall 71062
KL Stats: Epoch 213 Divergences: Uniform: 3.0442019588302838 Unigram: 5.305477054924421
2022-02-03 01:51:18 | INFO | fairseq.trainer | begin training epoch 214
2022-02-03 01:51:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:57:00 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 10.577 | ppl 1527.1 | wps 8228.8 | wpb 2034.1 | bsz 4 | num_updates 13696 | best_loss 9.357
2022-02-03 01:57:00 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-02-03 01:57:00 | INFO | train | epoch 214 | loss 5.092 | ppl 34.12 | wps 6099.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13696 | lr 0.000270211 | gnorm 1.571 | train_wall 315 | gb_free 6.1 | wall 71405
KL Stats: Epoch 214 Divergences: Uniform: 3.0346293072672985 Unigram: 5.311855824534437
2022-02-03 01:57:00 | INFO | fairseq.trainer | begin training epoch 215
2022-02-03 01:57:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:57:20 | INFO | train_inner | epoch 215:      4 / 64 loss=5.102, ppl=34.35, wps=5967.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=13700, lr=0.000270172, gnorm=1.584, train_wall=492, gb_free=6.1, wall=71425
2022-02-03 02:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:02:43 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 10.582 | ppl 1533.09 | wps 8224.8 | wpb 2034.1 | bsz 4 | num_updates 13760 | best_loss 9.357
2022-02-03 02:02:43 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-02-03 02:02:43 | INFO | train | epoch 215 | loss 5.09 | ppl 34.07 | wps 6090.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13760 | lr 0.000269582 | gnorm 1.593 | train_wall 315 | gb_free 6.1 | wall 71748
KL Stats: Epoch 215 Divergences: Uniform: 3.045354769910329 Unigram: 5.319350221238557
2022-02-03 02:02:43 | INFO | fairseq.trainer | begin training epoch 216
2022-02-03 02:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:06:02 | INFO | train_inner | epoch 216:     40 / 64 loss=5.084, ppl=33.93, wps=6266.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=13800, lr=0.000269191, gnorm=1.594, train_wall=494, gb_free=6.1, wall=71946
User defined signal 2
