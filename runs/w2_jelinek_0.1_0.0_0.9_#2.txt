Sender: LSF System <lsfadmin@eu-g2-11>
Subject: Job 202625106: <w2_jelinek_0.1_0.0_0.9_#2> in cluster <euler> Exited

Job <w2_jelinek_0.1_0.0_0.9_#2> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Jan 31 08:49:57 2022
Job was executed on host(s) <eu-g2-11>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Jan 31 08:50:12 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Jan 31 08:50:12 2022
Terminated at Tue Feb  1 04:50:24 2022
Results reported at Tue Feb  1 04:50:24 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.1, 0.0, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72890.00 sec.
    Max Memory :                                 6034 MB
    Average Memory :                             3592.85 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13966.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72011 sec.
    Turnaround time :                            72027 sec.

The output (if any) follows:

2022-01-31 08:50:20 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.1, 0.0, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-31 08:50:20 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-31 08:50:22 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1439/36718 [00:00<00:02, 14364.57it/s]  8%|▊         | 2876/36718 [00:00<00:02, 13422.24it/s] 12%|█▏        | 4324/36718 [00:00<00:02, 13886.69it/s] 16%|█▌        | 5895/36718 [00:00<00:02, 14584.51it/s] 20%|██        | 7358/36718 [00:00<00:02, 13764.04it/s] 24%|██▍       | 8744/36718 [00:00<00:02, 13410.60it/s] 28%|██▊       | 10140/36718 [00:00<00:01, 13569.20it/s] 31%|███▏      | 11502/36718 [00:00<00:01, 13305.39it/s] 35%|███▌      | 12866/36718 [00:00<00:01, 13397.97it/s] 39%|███▉      | 14279/36718 [00:01<00:01, 13613.30it/s] 43%|████▎     | 15643/36718 [00:01<00:01, 13604.20it/s] 46%|████▋     | 17006/36718 [00:01<00:01, 13454.51it/s] 50%|████▉     | 18353/36718 [00:01<00:01, 13446.14it/s] 54%|█████▍    | 19844/36718 [00:01<00:01, 13878.18it/s] 58%|█████▊    | 21234/36718 [00:01<00:01, 13821.16it/s] 62%|██████▏   | 22639/36718 [00:01<00:01, 13888.91it/s] 66%|██████▌   | 24215/36718 [00:01<00:00, 14443.03it/s] 70%|███████   | 25736/36718 [00:01<00:00, 14668.41it/s] 74%|███████▍  | 27204/36718 [00:01<00:00, 13936.40it/s] 78%|███████▊  | 28747/36718 [00:02<00:00, 14358.67it/s] 82%|████████▏ | 30191/36718 [00:02<00:00, 14190.14it/s] 86%|████████▌ | 31616/36718 [00:02<00:00, 13914.69it/s] 90%|████████▉ | 33012/36718 [00:02<00:00, 13659.28it/s] 94%|█████████▎| 34411/36718 [00:02<00:00, 13753.59it/s] 98%|█████████▊| 35846/36718 [00:02<00:00, 13920.82it/s]100%|██████████| 36718/36718 [00:02<00:00, 13851.51it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  7%|▋         | 2652/36718 [00:00<00:01, 26516.99it/s] 15%|█▌        | 5665/36718 [00:00<00:01, 28610.23it/s] 23%|██▎       | 8526/36718 [00:00<00:01, 27115.55it/s] 31%|███       | 11261/36718 [00:00<00:00, 27201.68it/s] 38%|███▊      | 13987/36718 [00:00<00:00, 27115.82it/s] 45%|████▌     | 16702/36718 [00:00<00:00, 26513.87it/s] 53%|█████▎    | 19530/36718 [00:00<00:00, 27066.63it/s] 61%|██████    | 22241/36718 [00:00<00:00, 26537.49it/s] 69%|██████▉   | 25268/36718 [00:00<00:00, 27670.65it/s] 76%|███████▋  | 28041/36718 [00:01<00:00, 26547.26it/s] 84%|████████▍ | 30796/36718 [00:01<00:00, 26839.35it/s] 91%|█████████▏| 33514/36718 [00:01<00:00, 26938.21it/s] 99%|█████████▉| 36332/36718 [00:01<00:00, 27301.48it/s]100%|██████████| 36718/36718 [00:01<00:00, 27085.96it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.35it/s]2022-01-31 08:50:35 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-31 08:50:35 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-31 08:50:35 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-31 08:50:35 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-31 08:50:35 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-31 08:50:35 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-31 08:50:35 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-31 08:50:35 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-31 08:50:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:50:35 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-31 08:50:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:50:35 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-31 08:50:35 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-31 08:50:35 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint_last.pt
2022-01-31 08:50:35 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint_last.pt
2022-01-31 08:50:35 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-31 08:50:35 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-31 08:50:35 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-31 08:50:35 | INFO | fairseq.trainer | begin training epoch 1
2022-01-31 08:50:35 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-31 08:55:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-31 08:56:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.699 | ppl 26592.6 | wps 8042.4 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-31 08:56:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-31 08:56:27 | INFO | train | epoch 001 | loss 16.133 | ppl 71847.7 | wps 5964.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.237 | train_wall 322 | gb_free 6.1 | wall 351
KL Stats: Epoch 1 Divergences: Uniform: 0.517208394610612 Unigram: 3.6856011076604216
2022-01-31 08:56:27 | INFO | fairseq.trainer | begin training epoch 2
2022-01-31 08:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 08:59:29 | INFO | train_inner | epoch 002:     36 / 64 loss=15.593, ppl=49417.3, wps=6138.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.652, train_wall=504, gb_free=6.1, wall=534
2022-01-31 09:01:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:02:17 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.698 | ppl 13288.5 | wps 8056.5 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-31 09:02:17 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-31 09:02:17 | INFO | train | epoch 002 | loss 14.424 | ppl 21986.4 | wps 5966 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.494 | train_wall 322 | gb_free 6.1 | wall 701
KL Stats: Epoch 2 Divergences: Uniform: 0.5345499046738815 Unigram: 2.415997657361054
2022-01-31 09:02:17 | INFO | fairseq.trainer | begin training epoch 3
2022-01-31 09:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:08:06 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.877 | ppl 7520.44 | wps 7989.1 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-31 09:08:06 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-31 09:08:06 | INFO | train | epoch 003 | loss 13.522 | ppl 11762.5 | wps 5979 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.204 | train_wall 321 | gb_free 6.1 | wall 1051
KL Stats: Epoch 3 Divergences: Uniform: 0.5190752576416564 Unigram: 1.733469657351904
2022-01-31 09:08:06 | INFO | fairseq.trainer | begin training epoch 4
2022-01-31 09:08:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:08:47 | INFO | train_inner | epoch 004:      8 / 64 loss=13.655, ppl=12898.2, wps=5846.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.233, train_wall=502, gb_free=6.1, wall=1091
2022-01-31 09:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:13:56 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.032 | ppl 4186.81 | wps 8029.5 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-31 09:13:56 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-31 09:13:56 | INFO | train | epoch 004 | loss 12.574 | ppl 6099.57 | wps 5975.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.959 | train_wall 321 | gb_free 6.1 | wall 1400
KL Stats: Epoch 4 Divergences: Uniform: 0.6028876543785803 Unigram: 1.119898046115955
2022-01-31 09:13:56 | INFO | fairseq.trainer | begin training epoch 5
2022-01-31 09:13:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:17:38 | INFO | train_inner | epoch 005:     44 / 64 loss=12.226, ppl=4790.33, wps=6152.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.843, train_wall=503, gb_free=6.1, wall=1622
2022-01-31 09:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:19:45 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.513 | ppl 2922.68 | wps 8086.2 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-31 09:19:45 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-31 09:19:45 | INFO | train | epoch 005 | loss 11.78 | ppl 3516.08 | wps 5983.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.687 | train_wall 321 | gb_free 6.1 | wall 1749
KL Stats: Epoch 5 Divergences: Uniform: 0.8414502514768483 Unigram: 0.6666348311195255
2022-01-31 09:19:45 | INFO | fairseq.trainer | begin training epoch 6
2022-01-31 09:19:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:25:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:25:35 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.267 | ppl 2463.98 | wps 7990.8 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-31 09:25:35 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-31 09:25:35 | INFO | train | epoch 006 | loss 11.348 | ppl 2607.18 | wps 5961.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.584 | train_wall 322 | gb_free 6.1 | wall 2100
KL Stats: Epoch 6 Divergences: Uniform: 1.1381679960636897 Unigram: 0.466223778536306
2022-01-31 09:25:35 | INFO | fairseq.trainer | begin training epoch 7
2022-01-31 09:25:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:26:56 | INFO | train_inner | epoch 007:     16 / 64 loss=11.371, ppl=2648.07, wps=5838.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.582, train_wall=502, gb_free=6.1, wall=2181
2022-01-31 09:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:31:25 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.122 | ppl 2229.25 | wps 7993.4 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-31 09:31:25 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-31 09:31:25 | INFO | train | epoch 007 | loss 11.147 | ppl 2267.92 | wps 5966.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.524 | train_wall 322 | gb_free 6.1 | wall 2450
KL Stats: Epoch 7 Divergences: Uniform: 1.3621972641625302 Unigram: 0.4759570718658166
2022-01-31 09:31:25 | INFO | fairseq.trainer | begin training epoch 8
2022-01-31 09:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:35:49 | INFO | train_inner | epoch 008:     52 / 64 loss=11.086, ppl=2173.19, wps=6133.7, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=504, gb_free=6.1, wall=2714
2022-01-31 09:36:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:37:16 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.017 | ppl 2072.77 | wps 7994.7 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-31 09:37:16 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-31 09:37:16 | INFO | train | epoch 008 | loss 11.034 | ppl 2096.41 | wps 5953.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 323 | gb_free 6.1 | wall 2801
KL Stats: Epoch 8 Divergences: Uniform: 1.477641246290245 Unigram: 0.55090545782554
2022-01-31 09:37:16 | INFO | fairseq.trainer | begin training epoch 9
2022-01-31 09:37:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:42:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:43:07 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.9 | ppl 1910.42 | wps 7999.3 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-31 09:43:07 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-31 09:43:07 | INFO | train | epoch 009 | loss 10.927 | ppl 1947.19 | wps 5947.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 323 | gb_free 6.1 | wall 3152
KL Stats: Epoch 9 Divergences: Uniform: 1.522980453171203 Unigram: 0.6545921842945029
2022-01-31 09:43:07 | INFO | fairseq.trainer | begin training epoch 10
2022-01-31 09:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:45:09 | INFO | train_inner | epoch 010:     24 / 64 loss=10.918, ppl=1934.73, wps=5822.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.488, train_wall=504, gb_free=6.1, wall=3274
2022-01-31 09:48:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:48:57 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.795 | ppl 1776.39 | wps 7989 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-31 09:48:57 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-31 09:48:57 | INFO | train | epoch 010 | loss 10.817 | ppl 1804.08 | wps 5960.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.484 | train_wall 322 | gb_free 6.1 | wall 3502
KL Stats: Epoch 10 Divergences: Uniform: 1.5479367586754715 Unigram: 0.768739755027727
2022-01-31 09:48:58 | INFO | fairseq.trainer | begin training epoch 11
2022-01-31 09:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:54:00 | INFO | train_inner | epoch 011:     60 / 64 loss=10.74, ppl=1710.71, wps=6150.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=503, gb_free=6.1, wall=3805
2022-01-31 09:54:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:54:46 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.686 | ppl 1647.97 | wps 8138.2 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-31 09:54:46 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-31 09:54:46 | INFO | train | epoch 011 | loss 10.7 | ppl 1663.77 | wps 5995 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.498 | train_wall 321 | gb_free 6.1 | wall 3851
KL Stats: Epoch 11 Divergences: Uniform: 1.5662919629482603 Unigram: 0.8823497823434991
2022-01-31 09:54:46 | INFO | fairseq.trainer | begin training epoch 12
2022-01-31 09:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:00:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:00:34 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.578 | ppl 1528.88 | wps 8074.1 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-31 10:00:34 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-31 10:00:34 | INFO | train | epoch 012 | loss 10.583 | ppl 1533.59 | wps 6004.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.479 | train_wall 320 | gb_free 6.1 | wall 4198
KL Stats: Epoch 12 Divergences: Uniform: 1.5772463506558076 Unigram: 0.9927787941083134
2022-01-31 10:00:34 | INFO | fairseq.trainer | begin training epoch 13
2022-01-31 10:00:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:03:15 | INFO | train_inner | epoch 013:     32 / 64 loss=10.559, ppl=1508.19, wps=5877.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.494, train_wall=499, gb_free=6.1, wall=4359
2022-01-31 10:05:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:06:22 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.488 | ppl 1435.97 | wps 8092.6 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-31 10:06:22 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-31 10:06:22 | INFO | train | epoch 013 | loss 10.468 | ppl 1416.33 | wps 6004 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 320 | gb_free 6.1 | wall 4546
KL Stats: Epoch 13 Divergences: Uniform: 1.6027387457321445 Unigram: 1.089840558810177
2022-01-31 10:06:22 | INFO | fairseq.trainer | begin training epoch 14
2022-01-31 10:06:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:11:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:12:10 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.393 | ppl 1344.23 | wps 8078.5 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-31 10:12:10 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-31 10:12:10 | INFO | train | epoch 014 | loss 10.357 | ppl 1311.24 | wps 6001.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.557 | train_wall 320 | gb_free 6.1 | wall 4894
KL Stats: Epoch 14 Divergences: Uniform: 1.6292497132864732 Unigram: 1.1795074918034127
2022-01-31 10:12:10 | INFO | fairseq.trainer | begin training epoch 15
2022-01-31 10:12:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:12:30 | INFO | train_inner | epoch 015:      4 / 64 loss=10.379, ppl=1332.01, wps=5874.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.537, train_wall=499, gb_free=6.1, wall=4914
2022-01-31 10:17:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:17:56 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.323 | ppl 1280.73 | wps 8138 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-31 10:17:56 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-31 10:17:56 | INFO | train | epoch 015 | loss 10.245 | ppl 1213.45 | wps 6026.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.537 | train_wall 319 | gb_free 6.1 | wall 5241
KL Stats: Epoch 15 Divergences: Uniform: 1.6525316768046014 Unigram: 1.2610839664592142
2022-01-31 10:17:56 | INFO | fairseq.trainer | begin training epoch 16
2022-01-31 10:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:21:17 | INFO | train_inner | epoch 016:     40 / 64 loss=10.204, ppl=1179.28, wps=6201.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.557, train_wall=499, gb_free=6.1, wall=5441
2022-01-31 10:23:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:23:42 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.243 | ppl 1211.72 | wps 8117.8 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-31 10:23:42 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-31 10:23:42 | INFO | train | epoch 016 | loss 10.138 | ppl 1127.16 | wps 6033.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.555 | train_wall 318 | gb_free 6.1 | wall 5587
KL Stats: Epoch 16 Divergences: Uniform: 1.6810889769489374 Unigram: 1.3394041445537825
2022-01-31 10:23:42 | INFO | fairseq.trainer | begin training epoch 17
2022-01-31 10:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:29:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:29:28 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.15 | ppl 1136.44 | wps 8134.5 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-31 10:29:28 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-31 10:29:28 | INFO | train | epoch 017 | loss 10.032 | ppl 1046.81 | wps 6049.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.548 | train_wall 318 | gb_free 6.1 | wall 5932
KL Stats: Epoch 17 Divergences: Uniform: 1.7144411620276798 Unigram: 1.40776968261585
2022-01-31 10:29:28 | INFO | fairseq.trainer | begin training epoch 18
2022-01-31 10:29:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:30:27 | INFO | train_inner | epoch 018:     12 / 64 loss=10.046, ppl=1057.12, wps=5919.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.55, train_wall=495, gb_free=6.1, wall=5992
2022-01-31 10:34:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:35:13 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.087 | ppl 1087.63 | wps 8122.8 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-31 10:35:13 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-31 10:35:13 | INFO | train | epoch 018 | loss 9.932 | ppl 976.59 | wps 6055.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.572 | train_wall 317 | gb_free 6.1 | wall 6277
KL Stats: Epoch 18 Divergences: Uniform: 1.7496488849904026 Unigram: 1.4746713423485551
2022-01-31 10:35:13 | INFO | fairseq.trainer | begin training epoch 19
2022-01-31 10:35:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:39:11 | INFO | train_inner | epoch 019:     48 / 64 loss=9.882, ppl=943.63, wps=6241.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.543, train_wall=495, gb_free=6.1, wall=6516
2022-01-31 10:40:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:40:56 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.013 | ppl 1033.27 | wps 8182.4 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-31 10:40:56 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-31 10:40:56 | INFO | train | epoch 019 | loss 9.828 | ppl 909.12 | wps 6081.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 316 | gb_free 6.1 | wall 6621
KL Stats: Epoch 19 Divergences: Uniform: 1.7792725108540752 Unigram: 1.5414256647434226
2022-01-31 10:40:56 | INFO | fairseq.trainer | begin training epoch 20
2022-01-31 10:40:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:46:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:46:40 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.928 | ppl 973.96 | wps 8165.2 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-31 10:46:40 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-31 10:46:40 | INFO | train | epoch 020 | loss 9.732 | ppl 850.39 | wps 6079.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.553 | train_wall 316 | gb_free 6.1 | wall 6964
KL Stats: Epoch 20 Divergences: Uniform: 1.810073113896505 Unigram: 1.6018857836352949
2022-01-31 10:46:40 | INFO | fairseq.trainer | begin training epoch 21
2022-01-31 10:46:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:48:19 | INFO | train_inner | epoch 021:     20 / 64 loss=9.727, ppl=847.46, wps=5945.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.547, train_wall=493, gb_free=6.1, wall=7064
2022-01-31 10:51:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:52:24 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.886 | ppl 945.96 | wps 8179.1 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-31 10:52:24 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-31 10:52:24 | INFO | train | epoch 021 | loss 9.638 | ppl 796.65 | wps 6058.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.528 | train_wall 317 | gb_free 6.1 | wall 7309
KL Stats: Epoch 21 Divergences: Uniform: 1.8398694904232575 Unigram: 1.6609174339600896
2022-01-31 10:52:24 | INFO | fairseq.trainer | begin training epoch 22
2022-01-31 10:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:57:04 | INFO | train_inner | epoch 022:     56 / 64 loss=9.585, ppl=768.17, wps=6235.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.536, train_wall=496, gb_free=6.1, wall=7588
2022-01-31 10:57:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:58:09 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.82 | ppl 903.64 | wps 8206.4 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-31 10:58:09 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-31 10:58:09 | INFO | train | epoch 022 | loss 9.549 | ppl 749.04 | wps 6062.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.547 | train_wall 317 | gb_free 6.1 | wall 7653
KL Stats: Epoch 22 Divergences: Uniform: 1.8648498854105915 Unigram: 1.7173722735310575
2022-01-31 10:58:09 | INFO | fairseq.trainer | begin training epoch 23
2022-01-31 10:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:03:53 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.761 | ppl 867.89 | wps 8184.6 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-31 11:03:53 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-31 11:03:53 | INFO | train | epoch 023 | loss 9.462 | ppl 705.38 | wps 6070.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.517 | train_wall 317 | gb_free 6.1 | wall 7998
KL Stats: Epoch 23 Divergences: Uniform: 1.8927516774288877 Unigram: 1.7692917245152893
2022-01-31 11:03:53 | INFO | fairseq.trainer | begin training epoch 24
2022-01-31 11:03:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:06:13 | INFO | train_inner | epoch 024:     28 / 64 loss=9.447, ppl=698.06, wps=5937.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.529, train_wall=494, gb_free=6.1, wall=8137
2022-01-31 11:09:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:09:37 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.702 | ppl 832.69 | wps 8208.5 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-31 11:09:37 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-31 11:09:37 | INFO | train | epoch 024 | loss 9.379 | ppl 665.78 | wps 6063.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.551 | train_wall 317 | gb_free 6.1 | wall 8342
KL Stats: Epoch 24 Divergences: Uniform: 1.9145869638355795 Unigram: 1.815088546175561
2022-01-31 11:09:37 | INFO | fairseq.trainer | begin training epoch 25
2022-01-31 11:09:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:14:55 | INFO | train_inner | epoch 025:     64 / 64 loss=9.325, ppl=641.36, wps=6242.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.531, train_wall=494, gb_free=6.1, wall=8659
2022-01-31 11:14:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:15:21 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.67 | ppl 814.62 | wps 8171.3 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-31 11:15:21 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-31 11:15:21 | INFO | train | epoch 025 | loss 9.297 | ppl 629.17 | wps 6069.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.52 | train_wall 316 | gb_free 6.1 | wall 8686
KL Stats: Epoch 25 Divergences: Uniform: 1.9436216731098985 Unigram: 1.8632243217175344
2022-01-31 11:15:21 | INFO | fairseq.trainer | begin training epoch 26
2022-01-31 11:15:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:20:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:21:06 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.619 | ppl 786.47 | wps 8181.1 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-31 11:21:06 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-31 11:21:06 | INFO | train | epoch 026 | loss 9.217 | ppl 595.05 | wps 6057.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.546 | train_wall 317 | gb_free 6.1 | wall 9031
KL Stats: Epoch 26 Divergences: Uniform: 1.9564830183824116 Unigram: 1.9069174388965078
2022-01-31 11:21:06 | INFO | fairseq.trainer | begin training epoch 27
2022-01-31 11:21:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:24:06 | INFO | train_inner | epoch 027:     36 / 64 loss=9.189, ppl=583.53, wps=5933.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.535, train_wall=496, gb_free=6.1, wall=9210
2022-01-31 11:26:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:26:50 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.589 | ppl 769.97 | wps 8175 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-31 11:26:50 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-31 11:26:50 | INFO | train | epoch 027 | loss 9.136 | ppl 562.48 | wps 6069.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.52 | train_wall 316 | gb_free 6.1 | wall 9375
KL Stats: Epoch 27 Divergences: Uniform: 1.9820231089738016 Unigram: 1.9459831047947016
2022-01-31 11:26:50 | INFO | fairseq.trainer | begin training epoch 28
2022-01-31 11:26:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:32:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:32:35 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.564 | ppl 756.84 | wps 8176.9 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-31 11:32:35 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-31 11:32:35 | INFO | train | epoch 028 | loss 9.058 | ppl 532.98 | wps 6057.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.525 | train_wall 317 | gb_free 6.1 | wall 9720
KL Stats: Epoch 28 Divergences: Uniform: 2.013568105456356 Unigram: 1.9871563517777484
2022-01-31 11:32:35 | INFO | fairseq.trainer | begin training epoch 29
2022-01-31 11:32:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:33:15 | INFO | train_inner | epoch 029:      8 / 64 loss=9.073, ppl=538.73, wps=5930.8, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.527, train_wall=495, gb_free=6.1, wall=9760
2022-01-31 11:37:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:38:19 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.532 | ppl 740.08 | wps 8168.2 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-31 11:38:19 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-31 11:38:19 | INFO | train | epoch 029 | loss 8.979 | ppl 504.73 | wps 6066.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.527 | train_wall 317 | gb_free 6.1 | wall 10064
KL Stats: Epoch 29 Divergences: Uniform: 2.0329932599294147 Unigram: 2.024818367922089
2022-01-31 11:38:19 | INFO | fairseq.trainer | begin training epoch 30
2022-01-31 11:38:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:41:59 | INFO | train_inner | epoch 030:     44 / 64 loss=8.946, ppl=493.36, wps=6239.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.519, train_wall=496, gb_free=6.1, wall=10284
2022-01-31 11:43:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:44:04 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.503 | ppl 725.54 | wps 8164.4 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-31 11:44:04 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-31 11:44:04 | INFO | train | epoch 030 | loss 8.902 | ppl 478.35 | wps 6058.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.522 | train_wall 317 | gb_free 6.1 | wall 10409
KL Stats: Epoch 30 Divergences: Uniform: 2.052228590990245 Unigram: 2.0652157583080077
2022-01-31 11:44:04 | INFO | fairseq.trainer | begin training epoch 31
2022-01-31 11:44:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:49:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:49:47 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.455 | ppl 701.6 | wps 8253.8 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-31 11:49:47 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-31 11:49:47 | INFO | train | epoch 031 | loss 8.823 | ppl 452.88 | wps 6099.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.495 | train_wall 315 | gb_free 6.1 | wall 10751
KL Stats: Epoch 31 Divergences: Uniform: 2.0699090993621323 Unigram: 2.0991911459540558
2022-01-31 11:49:47 | INFO | fairseq.trainer | begin training epoch 32
2022-01-31 11:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:51:06 | INFO | train_inner | epoch 032:     16 / 64 loss=8.824, ppl=453.24, wps=5962.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.503, train_wall=492, gb_free=6.1, wall=10830
2022-01-31 11:55:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:55:29 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.419 | ppl 684.59 | wps 8303.7 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-31 11:55:29 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-31 11:55:29 | INFO | train | epoch 032 | loss 8.749 | ppl 430.28 | wps 6094.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.508 | train_wall 316 | gb_free 6.1 | wall 11094
KL Stats: Epoch 32 Divergences: Uniform: 2.0962749504270524 Unigram: 2.136079636775701
2022-01-31 11:55:29 | INFO | fairseq.trainer | begin training epoch 33
2022-01-31 11:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:59:47 | INFO | train_inner | epoch 033:     52 / 64 loss=8.712, ppl=419.42, wps=6273.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.512, train_wall=493, gb_free=6.1, wall=11351
2022-01-31 12:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:01:12 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.404 | ppl 677.58 | wps 8195 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-31 12:01:12 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-31 12:01:12 | INFO | train | epoch 033 | loss 8.675 | ppl 408.64 | wps 6098.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.51 | train_wall 315 | gb_free 6.1 | wall 11436
KL Stats: Epoch 33 Divergences: Uniform: 2.121835613589365 Unigram: 2.1758039922540684
2022-01-31 12:01:12 | INFO | fairseq.trainer | begin training epoch 34
2022-01-31 12:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:06:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:06:56 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.392 | ppl 672.03 | wps 8182.8 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-31 12:06:56 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-31 12:06:56 | INFO | train | epoch 034 | loss 8.599 | ppl 387.82 | wps 6068.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.512 | train_wall 317 | gb_free 6.1 | wall 11781
KL Stats: Epoch 34 Divergences: Uniform: 2.141329987124237 Unigram: 2.211969545667456
2022-01-31 12:06:56 | INFO | fairseq.trainer | begin training epoch 35
2022-01-31 12:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:08:56 | INFO | train_inner | epoch 035:     24 / 64 loss=8.586, ppl=384.4, wps=5939.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.514, train_wall=494, gb_free=6.1, wall=11900
2022-01-31 12:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:12:40 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.357 | ppl 655.6 | wps 8181.6 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-31 12:12:40 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-31 12:12:40 | INFO | train | epoch 035 | loss 8.527 | ppl 368.88 | wps 6066.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.507 | train_wall 317 | gb_free 6.1 | wall 12125
KL Stats: Epoch 35 Divergences: Uniform: 2.1630275068524356 Unigram: 2.2423064347854256
2022-01-31 12:12:40 | INFO | fairseq.trainer | begin training epoch 36
2022-01-31 12:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:17:39 | INFO | train_inner | epoch 036:     60 / 64 loss=8.483, ppl=357.73, wps=6241.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.499, train_wall=496, gb_free=6.1, wall=12424
2022-01-31 12:17:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:18:25 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.331 | ppl 643.93 | wps 8180 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-31 12:18:25 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-31 12:18:25 | INFO | train | epoch 036 | loss 8.453 | ppl 350.43 | wps 6066.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.497 | train_wall 317 | gb_free 6.1 | wall 12469
KL Stats: Epoch 36 Divergences: Uniform: 2.1848241602427367 Unigram: 2.2812232144715994
2022-01-31 12:18:25 | INFO | fairseq.trainer | begin training epoch 37
2022-01-31 12:18:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:23:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:24:08 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.349 | ppl 652.24 | wps 8192 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-31 12:24:08 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-31 12:24:08 | INFO | train | epoch 037 | loss 8.384 | ppl 334.07 | wps 6072.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.509 | train_wall 316 | gb_free 6.1 | wall 12813
KL Stats: Epoch 37 Divergences: Uniform: 2.203489617035752 Unigram: 2.316397890322906
2022-01-31 12:24:08 | INFO | fairseq.trainer | begin training epoch 38
2022-01-31 12:24:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:26:48 | INFO | train_inner | epoch 038:     32 / 64 loss=8.363, ppl=329.14, wps=5941.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.507, train_wall=494, gb_free=6.1, wall=12973
2022-01-31 12:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:29:53 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.329 | ppl 643.01 | wps 8157.1 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-31 12:29:53 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-31 12:29:53 | INFO | train | epoch 038 | loss 8.315 | ppl 318.58 | wps 6068.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.507 | train_wall 317 | gb_free 6.1 | wall 13157
KL Stats: Epoch 38 Divergences: Uniform: 2.234366494922494 Unigram: 2.3405972583210315
2022-01-31 12:29:53 | INFO | fairseq.trainer | begin training epoch 39
2022-01-31 12:29:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:35:38 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.312 | ppl 635.73 | wps 8186 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-31 12:35:38 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-31 12:35:38 | INFO | train | epoch 039 | loss 8.246 | ppl 303.68 | wps 6053.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.498 | train_wall 317 | gb_free 6.1 | wall 13502
KL Stats: Epoch 39 Divergences: Uniform: 2.24170071921029 Unigram: 2.3802682186199515
2022-01-31 12:35:38 | INFO | fairseq.trainer | begin training epoch 40
2022-01-31 12:35:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:35:58 | INFO | train_inner | epoch 040:      4 / 64 loss=8.268, ppl=308.33, wps=5928.1, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.504, train_wall=495, gb_free=6.1, wall=13522
2022-01-31 12:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:41:22 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.29 | ppl 625.94 | wps 8200.2 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-31 12:41:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-31 12:41:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint40.pt
2022-01-31 12:41:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint40.pt
2022-01-31 12:41:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.29) (writing took 4.941421438008547 seconds)
2022-01-31 12:41:27 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-31 12:41:27 | INFO | train | epoch 040 | loss 8.178 | ppl 289.55 | wps 5985.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.501 | train_wall 316 | gb_free 6.1 | wall 13851
KL Stats: Epoch 40 Divergences: Uniform: 2.267977422467878 Unigram: 2.411234622630235
2022-01-31 12:41:27 | INFO | fairseq.trainer | begin training epoch 41
2022-01-31 12:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:44:46 | INFO | train_inner | epoch 041:     40 / 64 loss=8.154, ppl=284.87, wps=6185.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.499, train_wall=495, gb_free=6.1, wall=14051
2022-01-31 12:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:47:11 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.28 | ppl 621.58 | wps 8188.1 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.28
2022-01-31 12:47:11 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-31 12:47:11 | INFO | train | epoch 041 | loss 8.114 | ppl 277.01 | wps 6063.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.502 | train_wall 317 | gb_free 6.1 | wall 14196
KL Stats: Epoch 41 Divergences: Uniform: 2.2836917864710187 Unigram: 2.4385710476876574
2022-01-31 12:47:11 | INFO | fairseq.trainer | begin training epoch 42
2022-01-31 12:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:52:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:52:55 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.258 | ppl 612.46 | wps 8179.8 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.258
2022-01-31 12:52:55 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-31 12:52:55 | INFO | train | epoch 042 | loss 8.05 | ppl 264.98 | wps 6069.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.513 | train_wall 317 | gb_free 6.1 | wall 14540
KL Stats: Epoch 42 Divergences: Uniform: 2.300976599368634 Unigram: 2.474831047345943
2022-01-31 12:52:55 | INFO | fairseq.trainer | begin training epoch 43
2022-01-31 12:52:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:53:55 | INFO | train_inner | epoch 043:     12 / 64 loss=8.056, ppl=266.17, wps=5938.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.512, train_wall=494, gb_free=6.1, wall=14600
2022-01-31 12:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:58:39 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.288 | ppl 625.11 | wps 8204.4 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.288
2022-01-31 12:58:39 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-31 12:58:39 | INFO | train | epoch 043 | loss 7.984 | ppl 253.21 | wps 6071.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.497 | train_wall 316 | gb_free 6.1 | wall 14884
KL Stats: Epoch 43 Divergences: Uniform: 2.3226290864516934 Unigram: 2.503865702121564
2022-01-31 12:58:39 | INFO | fairseq.trainer | begin training epoch 44
2022-01-31 12:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:02:38 | INFO | train_inner | epoch 044:     48 / 64 loss=7.95, ppl=247.32, wps=6246.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.502, train_wall=495, gb_free=6.1, wall=15123
2022-01-31 13:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:04:23 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.295 | ppl 627.97 | wps 8276.6 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.29
2022-01-31 13:04:23 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-31 13:04:23 | INFO | train | epoch 044 | loss 7.925 | ppl 243.09 | wps 6083.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.509 | train_wall 316 | gb_free 6.1 | wall 15227
KL Stats: Epoch 44 Divergences: Uniform: 2.341551777314357 Unigram: 2.5316330457442717
2022-01-31 13:04:23 | INFO | fairseq.trainer | begin training epoch 45
2022-01-31 13:04:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:09:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:10:04 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.265 | ppl 615.16 | wps 8276.5 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.265
2022-01-31 13:10:04 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-31 13:10:04 | INFO | train | epoch 045 | loss 7.861 | ppl 232.52 | wps 6121.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.503 | train_wall 314 | gb_free 6.1 | wall 15568
KL Stats: Epoch 45 Divergences: Uniform: 2.3594785450936633 Unigram: 2.5660223371443935
2022-01-31 13:10:04 | INFO | fairseq.trainer | begin training epoch 46
2022-01-31 13:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:11:42 | INFO | train_inner | epoch 046:     20 / 64 loss=7.861, ppl=232.52, wps=5990.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.506, train_wall=490, gb_free=6.1, wall=15667
2022-01-31 13:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:15:45 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.274 | ppl 619.17 | wps 8235.3 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.274
2022-01-31 13:15:45 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-31 13:15:45 | INFO | train | epoch 046 | loss 7.803 | ppl 223.28 | wps 6128 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.513 | train_wall 313 | gb_free 6.1 | wall 15909
KL Stats: Epoch 46 Divergences: Uniform: 2.372532614273227 Unigram: 2.5855353878595224
2022-01-31 13:15:45 | INFO | fairseq.trainer | begin training epoch 47
2022-01-31 13:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:20:21 | INFO | train_inner | epoch 047:     56 / 64 loss=7.772, ppl=218.56, wps=6306.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.503, train_wall=490, gb_free=6.1, wall=16185
2022-01-31 13:20:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:21:25 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.261 | ppl 613.7 | wps 8274.3 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.261
2022-01-31 13:21:25 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-31 13:21:25 | INFO | train | epoch 047 | loss 7.744 | ppl 214.38 | wps 6132.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.498 | train_wall 313 | gb_free 6.1 | wall 16250
KL Stats: Epoch 47 Divergences: Uniform: 2.3953707973744356 Unigram: 2.6122049747759957
2022-01-31 13:21:25 | INFO | fairseq.trainer | begin training epoch 48
2022-01-31 13:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:27:06 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.253 | ppl 610.2 | wps 8263.1 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.253
2022-01-31 13:27:06 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-31 13:27:06 | INFO | train | epoch 048 | loss 7.687 | ppl 206.13 | wps 6121.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.511 | train_wall 314 | gb_free 6.1 | wall 16591
KL Stats: Epoch 48 Divergences: Uniform: 2.4143608979421143 Unigram: 2.642530954947643
2022-01-31 13:27:06 | INFO | fairseq.trainer | begin training epoch 49
2022-01-31 13:27:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:29:25 | INFO | train_inner | epoch 049:     28 / 64 loss=7.67, ppl=203.61, wps=5993.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.507, train_wall=490, gb_free=6.1, wall=16729
2022-01-31 13:32:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:32:47 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.282 | ppl 622.5 | wps 8280.3 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.282
2022-01-31 13:32:47 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-31 13:32:47 | INFO | train | epoch 049 | loss 7.63 | ppl 198.12 | wps 6124.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.507 | train_wall 314 | gb_free 6.1 | wall 16932
KL Stats: Epoch 49 Divergences: Uniform: 2.4188905508318213 Unigram: 2.6677853228301935
2022-01-31 13:32:47 | INFO | fairseq.trainer | begin training epoch 50
2022-01-31 13:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:38:03 | INFO | train_inner | epoch 050:     64 / 64 loss=7.606, ppl=194.86, wps=6291.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.525, train_wall=490, gb_free=6.1, wall=17247
2022-01-31 13:38:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:38:29 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.295 | ppl 628.08 | wps 8209.8 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.29
2022-01-31 13:38:29 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-31 13:38:29 | INFO | train | epoch 050 | loss 7.58 | ppl 191.31 | wps 6107.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.532 | train_wall 314 | gb_free 6.1 | wall 17274
KL Stats: Epoch 50 Divergences: Uniform: 2.4357930271031853 Unigram: 2.6851564620898873
2022-01-31 13:38:29 | INFO | fairseq.trainer | begin training epoch 51
2022-01-31 13:38:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:43:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:44:11 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.306 | ppl 632.87 | wps 8265.4 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.29
2022-01-31 13:44:11 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-31 13:44:11 | INFO | train | epoch 051 | loss 7.523 | ppl 183.98 | wps 6111.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.508 | train_wall 314 | gb_free 6.1 | wall 17616
KL Stats: Epoch 51 Divergences: Uniform: 2.4625107206030523 Unigram: 2.7080783075721224
2022-01-31 13:44:11 | INFO | fairseq.trainer | begin training epoch 52
2022-01-31 13:44:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:47:09 | INFO | train_inner | epoch 052:     36 / 64 loss=7.5, ppl=180.96, wps=5980.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.509, train_wall=492, gb_free=6.1, wall=17794
2022-01-31 13:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:49:53 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.291 | ppl 626.58 | wps 8290.8 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.29
2022-01-31 13:49:53 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-31 13:49:53 | INFO | train | epoch 052 | loss 7.471 | ppl 177.46 | wps 6117 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.52 | train_wall 314 | gb_free 6.1 | wall 17957
KL Stats: Epoch 52 Divergences: Uniform: 2.473241743594871 Unigram: 2.7419926173095432
2022-01-31 13:49:53 | INFO | fairseq.trainer | begin training epoch 53
2022-01-31 13:49:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:55:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:55:34 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.276 | ppl 620.04 | wps 8215.2 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.276
2022-01-31 13:55:34 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-31 13:55:34 | INFO | train | epoch 053 | loss 7.42 | ppl 171.21 | wps 6111.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.509 | train_wall 314 | gb_free 6.1 | wall 18299
KL Stats: Epoch 53 Divergences: Uniform: 2.4961905188418685 Unigram: 2.7590443627653363
2022-01-31 13:55:34 | INFO | fairseq.trainer | begin training epoch 54
2022-01-31 13:55:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:56:14 | INFO | train_inner | epoch 054:      8 / 64 loss=7.433, ppl=172.79, wps=5979.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.52, train_wall=491, gb_free=6.1, wall=18339
2022-01-31 14:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:01:18 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.33 | ppl 643.61 | wps 8185 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.29
2022-01-31 14:01:18 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-31 14:01:18 | INFO | train | epoch 054 | loss 7.37 | ppl 165.42 | wps 6069.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.525 | train_wall 317 | gb_free 6.1 | wall 18643
KL Stats: Epoch 54 Divergences: Uniform: 2.497436100146636 Unigram: 2.779324647748518
2022-01-31 14:01:18 | INFO | fairseq.trainer | begin training epoch 55
2022-01-31 14:01:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:04:58 | INFO | train_inner | epoch 055:     44 / 64 loss=7.342, ppl=162.23, wps=6245.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.518, train_wall=495, gb_free=6.1, wall=18862
2022-01-31 14:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:07:03 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.327 | ppl 642.36 | wps 8191.8 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.29
2022-01-31 14:07:03 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-31 14:07:03 | INFO | train | epoch 055 | loss 7.322 | ppl 160.05 | wps 6067.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.529 | train_wall 317 | gb_free 6.1 | wall 18987
KL Stats: Epoch 55 Divergences: Uniform: 2.512791394446619 Unigram: 2.808401310438587
2022-01-31 14:07:03 | INFO | fairseq.trainer | begin training epoch 56
2022-01-31 14:07:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:12:47 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.438 | ppl 693.63 | wps 8160.6 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.29
2022-01-31 14:12:47 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-31 14:12:47 | INFO | train | epoch 056 | loss 7.273 | ppl 154.69 | wps 6068.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.52 | train_wall 317 | gb_free 6.1 | wall 19331
KL Stats: Epoch 56 Divergences: Uniform: 2.51154919936294 Unigram: 2.825248114648947
2022-01-31 14:12:47 | INFO | fairseq.trainer | begin training epoch 57
2022-01-31 14:12:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:14:07 | INFO | train_inner | epoch 057:     16 / 64 loss=7.277, ppl=155.13, wps=5938, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.53, train_wall=494, gb_free=6.1, wall=19411
2022-01-31 14:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:18:31 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.416 | ppl 683.01 | wps 8209.5 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.29
2022-01-31 14:18:31 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-31 14:18:31 | INFO | train | epoch 057 | loss 7.226 | ppl 149.71 | wps 6073.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.531 | train_wall 316 | gb_free 6.1 | wall 19675
KL Stats: Epoch 57 Divergences: Uniform: 2.5433143425453415 Unigram: 2.8541784453698913
2022-01-31 14:18:31 | INFO | fairseq.trainer | begin training epoch 58
2022-01-31 14:18:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:22:49 | INFO | train_inner | epoch 058:     52 / 64 loss=7.202, ppl=147.19, wps=6250.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.527, train_wall=495, gb_free=6.1, wall=19934
2022-01-31 14:23:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:24:15 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.422 | ppl 685.83 | wps 8188 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.29
2022-01-31 14:24:15 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-31 14:24:15 | INFO | train | epoch 058 | loss 7.181 | ppl 145.13 | wps 6069.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.529 | train_wall 317 | gb_free 6.1 | wall 20019
KL Stats: Epoch 58 Divergences: Uniform: 2.5545396036536654 Unigram: 2.8690830763847734
2022-01-31 14:24:15 | INFO | fairseq.trainer | begin training epoch 59
2022-01-31 14:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:29:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:29:58 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.487 | ppl 717.77 | wps 8205.6 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.29
2022-01-31 14:29:58 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-31 14:29:58 | INFO | train | epoch 059 | loss 7.137 | ppl 140.7 | wps 6077 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.536 | train_wall 316 | gb_free 6.1 | wall 20363
KL Stats: Epoch 59 Divergences: Uniform: 2.56783731048286 Unigram: 2.8899126929068535
2022-01-31 14:29:58 | INFO | fairseq.trainer | begin training epoch 60
2022-01-31 14:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:31:58 | INFO | train_inner | epoch 060:     24 / 64 loss=7.13, ppl=140.11, wps=5941.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.536, train_wall=494, gb_free=6.1, wall=20483
2022-01-31 14:35:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:35:43 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.44 | ppl 694.49 | wps 8178.3 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.29
2022-01-31 14:35:43 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-31 14:35:43 | INFO | train | epoch 060 | loss 7.092 | ppl 136.47 | wps 6062.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.542 | train_wall 317 | gb_free 6.1 | wall 20708
KL Stats: Epoch 60 Divergences: Uniform: 2.582392889607815 Unigram: 2.9171904700626756
2022-01-31 14:35:43 | INFO | fairseq.trainer | begin training epoch 61
2022-01-31 14:35:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:40:42 | INFO | train_inner | epoch 061:     60 / 64 loss=7.073, ppl=134.67, wps=6238.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.547, train_wall=496, gb_free=6.1, wall=21007
2022-01-31 14:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:41:27 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.498 | ppl 722.85 | wps 8171.4 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.29
2022-01-31 14:41:27 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-31 14:41:27 | INFO | train | epoch 061 | loss 7.05 | ppl 132.51 | wps 6063.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.549 | train_wall 317 | gb_free 6.1 | wall 21052
KL Stats: Epoch 61 Divergences: Uniform: 2.6006211294791353 Unigram: 2.92704817183114
2022-01-31 14:41:27 | INFO | fairseq.trainer | begin training epoch 62
2022-01-31 14:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:47:12 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.468 | ppl 708.08 | wps 8165.1 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.29
2022-01-31 14:47:12 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-31 14:47:12 | INFO | train | epoch 062 | loss 7.008 | ppl 128.75 | wps 6069.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.551 | train_wall 316 | gb_free 6.1 | wall 21396
KL Stats: Epoch 62 Divergences: Uniform: 2.606305320687258 Unigram: 2.9574455860398685
2022-01-31 14:47:12 | INFO | fairseq.trainer | begin training epoch 63
2022-01-31 14:47:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:49:51 | INFO | train_inner | epoch 063:     32 / 64 loss=6.983, ppl=126.47, wps=5938.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.55, train_wall=494, gb_free=6.1, wall=21556
2022-01-31 14:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:52:56 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.48 | ppl 713.92 | wps 8162.7 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.29
2022-01-31 14:52:56 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-31 14:52:56 | INFO | train | epoch 063 | loss 6.965 | ppl 124.9 | wps 6068.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.547 | train_wall 317 | gb_free 6.1 | wall 21740
KL Stats: Epoch 63 Divergences: Uniform: 2.618785416238635 Unigram: 2.9738992967448974
2022-01-31 14:52:56 | INFO | fairseq.trainer | begin training epoch 64
2022-01-31 14:52:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:58:40 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.558 | ppl 753.82 | wps 8171.1 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.29
2022-01-31 14:58:40 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-31 14:58:40 | INFO | train | epoch 064 | loss 6.922 | ppl 121.26 | wps 6069.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.558 | train_wall 316 | gb_free 6.1 | wall 22085
KL Stats: Epoch 64 Divergences: Uniform: 2.628982474525611 Unigram: 2.992738841747211
2022-01-31 14:58:40 | INFO | fairseq.trainer | begin training epoch 65
2022-01-31 14:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:59:00 | INFO | train_inner | epoch 065:      4 / 64 loss=6.949, ppl=123.54, wps=5938.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.554, train_wall=494, gb_free=6.1, wall=22105
2022-01-31 15:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:04:24 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.565 | ppl 757.63 | wps 8192.6 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.29
2022-01-31 15:04:24 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-31 15:04:24 | INFO | train | epoch 065 | loss 6.879 | ppl 117.73 | wps 6062.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.555 | train_wall 317 | gb_free 6.1 | wall 22429
KL Stats: Epoch 65 Divergences: Uniform: 2.6387180847112095 Unigram: 3.0134925258143763
2022-01-31 15:04:24 | INFO | fairseq.trainer | begin training epoch 66
2022-01-31 15:04:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:07:44 | INFO | train_inner | epoch 066:     40 / 64 loss=6.855, ppl=115.79, wps=6239.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.561, train_wall=496, gb_free=6.1, wall=22628
2022-01-31 15:09:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:10:08 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.577 | ppl 763.57 | wps 8180.8 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.29
2022-01-31 15:10:08 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-31 15:10:08 | INFO | train | epoch 066 | loss 6.839 | ppl 114.52 | wps 6069.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.555 | train_wall 317 | gb_free 6.1 | wall 22773
KL Stats: Epoch 66 Divergences: Uniform: 2.651188497166606 Unigram: 3.0278592977426446
2022-01-31 15:10:08 | INFO | fairseq.trainer | begin training epoch 67
2022-01-31 15:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:15:53 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.553 | ppl 751.36 | wps 8165.7 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.29
2022-01-31 15:15:53 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-31 15:15:53 | INFO | train | epoch 067 | loss 6.798 | ppl 111.25 | wps 6068.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.554 | train_wall 317 | gb_free 6.1 | wall 23117
KL Stats: Epoch 67 Divergences: Uniform: 2.6699556343512065 Unigram: 3.0547058660614717
2022-01-31 15:15:53 | INFO | fairseq.trainer | begin training epoch 68
2022-01-31 15:15:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:16:52 | INFO | train_inner | epoch 068:     12 / 64 loss=6.806, ppl=111.93, wps=5939.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.551, train_wall=494, gb_free=6.1, wall=23177
2022-01-31 15:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:21:37 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.626 | ppl 789.97 | wps 8168.9 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.29
2022-01-31 15:21:37 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-31 15:21:37 | INFO | train | epoch 068 | loss 6.762 | ppl 108.5 | wps 6069.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.578 | train_wall 316 | gb_free 6.1 | wall 23461
KL Stats: Epoch 68 Divergences: Uniform: 2.6794011551594132 Unigram: 3.0733487497051186
2022-01-31 15:21:37 | INFO | fairseq.trainer | begin training epoch 69
2022-01-31 15:21:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:25:36 | INFO | train_inner | epoch 069:     48 / 64 loss=6.743, ppl=107.1, wps=6242, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.566, train_wall=495, gb_free=6.1, wall=23701
2022-01-31 15:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:27:21 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.635 | ppl 795.11 | wps 8160.8 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.29
2022-01-31 15:27:21 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-31 15:27:21 | INFO | train | epoch 069 | loss 6.722 | ppl 105.55 | wps 6061.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.555 | train_wall 317 | gb_free 6.1 | wall 23806
KL Stats: Epoch 69 Divergences: Uniform: 2.692300496289744 Unigram: 3.089894889250788
2022-01-31 15:27:21 | INFO | fairseq.trainer | begin training epoch 70
2022-01-31 15:27:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:33:06 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.703 | ppl 833.37 | wps 8180 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.29
2022-01-31 15:33:06 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-31 15:33:06 | INFO | train | epoch 070 | loss 6.687 | ppl 103.03 | wps 6063.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.559 | train_wall 317 | gb_free 6.1 | wall 24151
KL Stats: Epoch 70 Divergences: Uniform: 2.697833402813989 Unigram: 3.100456947016811
2022-01-31 15:33:06 | INFO | fairseq.trainer | begin training epoch 71
2022-01-31 15:33:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:34:45 | INFO | train_inner | epoch 071:     20 / 64 loss=6.681, ppl=102.63, wps=5934.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.563, train_wall=494, gb_free=6.1, wall=24250
2022-01-31 15:38:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:38:50 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.688 | ppl 824.87 | wps 8202.5 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.29
2022-01-31 15:38:50 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-31 15:38:50 | INFO | train | epoch 071 | loss 6.654 | ppl 100.68 | wps 6070.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.578 | train_wall 317 | gb_free 6.1 | wall 24495
KL Stats: Epoch 71 Divergences: Uniform: 2.708446192201698 Unigram: 3.123140413180172
2022-01-31 15:38:50 | INFO | fairseq.trainer | begin training epoch 72
2022-01-31 15:38:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:43:28 | INFO | train_inner | epoch 072:     56 / 64 loss=6.638, ppl=99.61, wps=6249.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.573, train_wall=495, gb_free=6.1, wall=24773
2022-01-31 15:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:44:34 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.641 | ppl 798.24 | wps 8192.2 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.29
2022-01-31 15:44:34 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-31 15:44:34 | INFO | train | epoch 072 | loss 6.618 | ppl 98.23 | wps 6076.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.57 | train_wall 316 | gb_free 6.1 | wall 24838
KL Stats: Epoch 72 Divergences: Uniform: 2.7257006899600444 Unigram: 3.1415577593031747
2022-01-31 15:44:34 | INFO | fairseq.trainer | begin training epoch 73
2022-01-31 15:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:49:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:50:17 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.73 | ppl 849.4 | wps 8206.5 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.29
2022-01-31 15:50:17 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-31 15:50:17 | INFO | train | epoch 073 | loss 6.586 | ppl 96.04 | wps 6080.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.571 | train_wall 316 | gb_free 6.1 | wall 25182
KL Stats: Epoch 73 Divergences: Uniform: 2.7247781095322745 Unigram: 3.157295048210391
2022-01-31 15:50:17 | INFO | fairseq.trainer | begin training epoch 74
2022-01-31 15:50:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:52:37 | INFO | train_inner | epoch 074:     28 / 64 loss=6.575, ppl=95.31, wps=5945.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.572, train_wall=494, gb_free=6.1, wall=25321
2022-01-31 15:55:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:56:01 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.626 | ppl 790.1 | wps 8182 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.29
2022-01-31 15:56:01 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-31 15:56:01 | INFO | train | epoch 074 | loss 6.554 | ppl 93.93 | wps 6073.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.586 | train_wall 316 | gb_free 6.1 | wall 25526
KL Stats: Epoch 74 Divergences: Uniform: 2.7385114359950893 Unigram: 3.184915355719623
2022-01-31 15:56:01 | INFO | fairseq.trainer | begin training epoch 75
2022-01-31 15:56:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:01:18 | INFO | train_inner | epoch 075:     64 / 64 loss=6.544, ppl=93.31, wps=6246.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.584, train_wall=494, gb_free=6.1, wall=25843
2022-01-31 16:01:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:01:45 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.766 | ppl 870.43 | wps 8169.3 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.29
2022-01-31 16:01:45 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-31 16:01:45 | INFO | train | epoch 075 | loss 6.523 | ppl 91.96 | wps 6068 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.578 | train_wall 317 | gb_free 6.1 | wall 25870
KL Stats: Epoch 75 Divergences: Uniform: 2.741120185949408 Unigram: 3.1948940729597544
2022-01-31 16:01:45 | INFO | fairseq.trainer | begin training epoch 76
2022-01-31 16:01:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:07:30 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.725 | ppl 846.13 | wps 8217.8 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.29
2022-01-31 16:07:30 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-31 16:07:30 | INFO | train | epoch 076 | loss 6.494 | ppl 90.12 | wps 6062.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.598 | train_wall 317 | gb_free 6.1 | wall 26214
KL Stats: Epoch 76 Divergences: Uniform: 2.7547274526891528 Unigram: 3.215229785341821
2022-01-31 16:07:30 | INFO | fairseq.trainer | begin training epoch 77
2022-01-31 16:07:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:10:29 | INFO | train_inner | epoch 077:     36 / 64 loss=6.468, ppl=88.54, wps=5937.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.592, train_wall=496, gb_free=6.1, wall=26394
2022-01-31 16:12:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:13:14 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.766 | ppl 870.59 | wps 8187.4 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.29
2022-01-31 16:13:14 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-31 16:13:14 | INFO | train | epoch 077 | loss 6.464 | ppl 88.27 | wps 6072.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.597 | train_wall 316 | gb_free 6.1 | wall 26558
KL Stats: Epoch 77 Divergences: Uniform: 2.755473268862782 Unigram: 3.2377440815124308
2022-01-31 16:13:14 | INFO | fairseq.trainer | begin training epoch 78
2022-01-31 16:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:18:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:18:58 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.73 | ppl 849.26 | wps 8149.9 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.29
2022-01-31 16:18:58 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-31 16:18:58 | INFO | train | epoch 078 | loss 6.437 | ppl 86.62 | wps 6064.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.601 | train_wall 317 | gb_free 6.1 | wall 26903
KL Stats: Epoch 78 Divergences: Uniform: 2.7689016539416627 Unigram: 3.249212446923897
2022-01-31 16:18:58 | INFO | fairseq.trainer | begin training epoch 79
2022-01-31 16:18:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:19:38 | INFO | train_inner | epoch 079:      8 / 64 loss=6.451, ppl=87.5, wps=5935.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.605, train_wall=494, gb_free=6.1, wall=26943
2022-01-31 16:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:24:42 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.827 | ppl 908.13 | wps 8198.9 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.29
2022-01-31 16:24:42 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-31 16:24:42 | INFO | train | epoch 079 | loss 6.405 | ppl 84.75 | wps 6065.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.588 | train_wall 317 | gb_free 6.1 | wall 27247
KL Stats: Epoch 79 Divergences: Uniform: 2.7718663429399095 Unigram: 3.2610553525788384
2022-01-31 16:24:42 | INFO | fairseq.trainer | begin training epoch 80
2022-01-31 16:24:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:28:21 | INFO | train_inner | epoch 080:     44 / 64 loss=6.389, ppl=83.81, wps=6244.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.591, train_wall=495, gb_free=6.1, wall=27466
2022-01-31 16:30:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:30:26 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.742 | ppl 856.06 | wps 8174.8 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.29
2022-01-31 16:30:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-31 16:30:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint80.pt
2022-01-31 16:30:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint80.pt
2022-01-31 16:30:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.742) (writing took 3.447802871465683 seconds)
2022-01-31 16:30:30 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-31 16:30:30 | INFO | train | epoch 080 | loss 6.381 | ppl 83.32 | wps 6010.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.603 | train_wall 316 | gb_free 6.1 | wall 27595
KL Stats: Epoch 80 Divergences: Uniform: 2.7778181665693977 Unigram: 3.2833505363608273
2022-01-31 16:30:30 | INFO | fairseq.trainer | begin training epoch 81
2022-01-31 16:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:36:15 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.814 | ppl 900.02 | wps 8175.6 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.29
2022-01-31 16:36:15 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-31 16:36:15 | INFO | train | epoch 081 | loss 6.355 | ppl 81.83 | wps 6061.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.615 | train_wall 317 | gb_free 6.1 | wall 27939
KL Stats: Epoch 81 Divergences: Uniform: 2.7978398000934734 Unigram: 3.299518783093557
2022-01-31 16:36:15 | INFO | fairseq.trainer | begin training epoch 82
2022-01-31 16:36:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:37:34 | INFO | train_inner | epoch 082:     16 / 64 loss=6.361, ppl=82.2, wps=5896.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.62, train_wall=495, gb_free=6.1, wall=28019
2022-01-31 16:41:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:41:59 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.772 | ppl 874.33 | wps 8195.4 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.29
2022-01-31 16:41:59 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-31 16:41:59 | INFO | train | epoch 082 | loss 6.328 | ppl 80.34 | wps 6067.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.61 | train_wall 317 | gb_free 6.1 | wall 28283
KL Stats: Epoch 82 Divergences: Uniform: 2.7992774490986303 Unigram: 3.322864494797816
2022-01-31 16:41:59 | INFO | fairseq.trainer | begin training epoch 83
2022-01-31 16:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:46:18 | INFO | train_inner | epoch 083:     52 / 64 loss=6.314, ppl=79.55, wps=6244.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.609, train_wall=495, gb_free=6.1, wall=28542
2022-01-31 16:47:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:47:43 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.693 | ppl 827.92 | wps 8195.2 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.29
2022-01-31 16:47:43 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-31 16:47:43 | INFO | train | epoch 083 | loss 6.304 | ppl 78.99 | wps 6069.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.618 | train_wall 317 | gb_free 6.1 | wall 28628
KL Stats: Epoch 83 Divergences: Uniform: 2.8133406032734958 Unigram: 3.33984726680632
2022-01-31 16:47:43 | INFO | fairseq.trainer | begin training epoch 84
2022-01-31 16:47:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:53:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:53:26 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.779 | ppl 878.48 | wps 8166.9 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.29
2022-01-31 16:53:26 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-31 16:53:26 | INFO | train | epoch 084 | loss 6.279 | ppl 77.63 | wps 6079.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.615 | train_wall 316 | gb_free 6.1 | wall 28971
KL Stats: Epoch 84 Divergences: Uniform: 2.8156578613819674 Unigram: 3.349408390783385
2022-01-31 16:53:26 | INFO | fairseq.trainer | begin training epoch 85
2022-01-31 16:53:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:55:26 | INFO | train_inner | epoch 085:     24 / 64 loss=6.268, ppl=77.06, wps=5948.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.615, train_wall=493, gb_free=6.1, wall=29090
2022-01-31 16:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:59:10 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.797 | ppl 889.54 | wps 8201.3 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.29
2022-01-31 16:59:10 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-31 16:59:10 | INFO | train | epoch 085 | loss 6.255 | ppl 76.35 | wps 6081.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.623 | train_wall 316 | gb_free 6.1 | wall 29315
KL Stats: Epoch 85 Divergences: Uniform: 2.8300923714889614 Unigram: 3.3609882021183126
2022-01-31 16:59:10 | INFO | fairseq.trainer | begin training epoch 86
2022-01-31 16:59:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:04:09 | INFO | train_inner | epoch 086:     60 / 64 loss=6.252, ppl=76.21, wps=6248.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.629, train_wall=495, gb_free=6.1, wall=29613
2022-01-31 17:04:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:04:54 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.815 | ppl 900.81 | wps 8210.5 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.29
2022-01-31 17:04:54 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-31 17:04:54 | INFO | train | epoch 086 | loss 6.231 | ppl 75.11 | wps 6068.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.632 | train_wall 317 | gb_free 6.1 | wall 29659
KL Stats: Epoch 86 Divergences: Uniform: 2.828308306320265 Unigram: 3.385656513217498
2022-01-31 17:04:54 | INFO | fairseq.trainer | begin training epoch 87
2022-01-31 17:04:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:10:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:10:39 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.851 | ppl 923.6 | wps 8175.6 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.29
2022-01-31 17:10:39 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-31 17:10:39 | INFO | train | epoch 087 | loss 6.209 | ppl 73.97 | wps 6062.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.651 | train_wall 317 | gb_free 6.1 | wall 30003
KL Stats: Epoch 87 Divergences: Uniform: 2.8336558541984913 Unigram: 3.393945844237983
2022-01-31 17:10:39 | INFO | fairseq.trainer | begin training epoch 88
2022-01-31 17:10:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:13:18 | INFO | train_inner | epoch 088:     32 / 64 loss=6.196, ppl=73.32, wps=5935.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.651, train_wall=494, gb_free=6.1, wall=30163
2022-01-31 17:15:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:16:22 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.815 | ppl 900.84 | wps 8227.6 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.29
2022-01-31 17:16:22 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-31 17:16:22 | INFO | train | epoch 088 | loss 6.186 | ppl 72.83 | wps 6077.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.648 | train_wall 316 | gb_free 6.1 | wall 30347
KL Stats: Epoch 88 Divergences: Uniform: 2.841669920757512 Unigram: 3.409556756483096
2022-01-31 17:16:22 | INFO | fairseq.trainer | begin training epoch 89
2022-01-31 17:16:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:22:06 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.82 | ppl 904.14 | wps 8227.7 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.29
2022-01-31 17:22:06 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-31 17:22:06 | INFO | train | epoch 089 | loss 6.168 | ppl 71.89 | wps 6081.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.661 | train_wall 316 | gb_free 6.1 | wall 30690
KL Stats: Epoch 89 Divergences: Uniform: 2.852255433916887 Unigram: 3.4218323981026466
2022-01-31 17:22:06 | INFO | fairseq.trainer | begin training epoch 90
2022-01-31 17:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:22:26 | INFO | train_inner | epoch 090:      4 / 64 loss=6.178, ppl=72.41, wps=5951.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.657, train_wall=493, gb_free=6.1, wall=30710
2022-01-31 17:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:27:49 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.893 | ppl 950.67 | wps 8163.6 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.29
2022-01-31 17:27:49 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-31 17:27:49 | INFO | train | epoch 090 | loss 6.144 | ppl 70.71 | wps 6086.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.637 | train_wall 316 | gb_free 6.1 | wall 31034
KL Stats: Epoch 90 Divergences: Uniform: 2.8513590447171446 Unigram: 3.431394040505197
2022-01-31 17:27:49 | INFO | fairseq.trainer | begin training epoch 91
2022-01-31 17:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:31:08 | INFO | train_inner | epoch 091:     40 / 64 loss=6.125, ppl=69.81, wps=6252.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.635, train_wall=495, gb_free=6.1, wall=31233
2022-01-31 17:33:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:33:33 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.885 | ppl 945.52 | wps 8201.6 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.29
2022-01-31 17:33:33 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-31 17:33:33 | INFO | train | epoch 091 | loss 6.122 | ppl 69.63 | wps 6065.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.645 | train_wall 317 | gb_free 6.1 | wall 31378
KL Stats: Epoch 91 Divergences: Uniform: 2.8609451318496184 Unigram: 3.457986270169708
2022-01-31 17:33:33 | INFO | fairseq.trainer | begin training epoch 92
2022-01-31 17:33:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:38:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:39:17 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.901 | ppl 956 | wps 8174.2 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.29
2022-01-31 17:39:17 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-31 17:39:17 | INFO | train | epoch 092 | loss 6.104 | ppl 68.77 | wps 6071.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.666 | train_wall 316 | gb_free 6.1 | wall 31722
KL Stats: Epoch 92 Divergences: Uniform: 2.865546964509086 Unigram: 3.466909888157885
2022-01-31 17:39:17 | INFO | fairseq.trainer | begin training epoch 93
2022-01-31 17:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:40:17 | INFO | train_inner | epoch 093:     12 / 64 loss=6.113, ppl=69.21, wps=5941.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.662, train_wall=494, gb_free=6.1, wall=31782
2022-01-31 17:44:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:45:01 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.848 | ppl 921.78 | wps 8187.4 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.29
2022-01-31 17:45:01 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-31 17:45:01 | INFO | train | epoch 093 | loss 6.086 | ppl 67.92 | wps 6069.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.664 | train_wall 317 | gb_free 6.1 | wall 32066
KL Stats: Epoch 93 Divergences: Uniform: 2.8747369600728625 Unigram: 3.4833577734282213
2022-01-31 17:45:01 | INFO | fairseq.trainer | begin training epoch 94
2022-01-31 17:45:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:49:00 | INFO | train_inner | epoch 094:     48 / 64 loss=6.071, ppl=67.24, wps=6246.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.666, train_wall=495, gb_free=6.1, wall=32305
2022-01-31 17:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:50:45 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.927 | ppl 973.76 | wps 8168.5 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.29
2022-01-31 17:50:45 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-31 17:50:45 | INFO | train | epoch 094 | loss 6.064 | ppl 66.9 | wps 6070.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.665 | train_wall 316 | gb_free 6.1 | wall 32410
KL Stats: Epoch 94 Divergences: Uniform: 2.877513395115581 Unigram: 3.49938328150797
2022-01-31 17:50:45 | INFO | fairseq.trainer | begin training epoch 95
2022-01-31 17:50:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:56:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:56:30 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.937 | ppl 980.42 | wps 8187.9 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.29
2022-01-31 17:56:30 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-31 17:56:30 | INFO | train | epoch 095 | loss 6.045 | ppl 66.01 | wps 6058.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.661 | train_wall 317 | gb_free 6.1 | wall 32755
KL Stats: Epoch 95 Divergences: Uniform: 2.8821069702168756 Unigram: 3.510813961333822
2022-01-31 17:56:30 | INFO | fairseq.trainer | begin training epoch 96
2022-01-31 17:56:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:58:10 | INFO | train_inner | epoch 096:     20 / 64 loss=6.044, ppl=65.97, wps=5932.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.663, train_wall=495, gb_free=6.1, wall=32854
2022-01-31 18:01:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:02:14 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.858 | ppl 927.75 | wps 8173.4 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.29
2022-01-31 18:02:14 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-31 18:02:14 | INFO | train | epoch 096 | loss 6.029 | ppl 65.28 | wps 6074.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.675 | train_wall 316 | gb_free 6.1 | wall 33099
KL Stats: Epoch 96 Divergences: Uniform: 2.89185744150977 Unigram: 3.5185268952801025
2022-01-31 18:02:14 | INFO | fairseq.trainer | begin training epoch 97
2022-01-31 18:02:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:06:52 | INFO | train_inner | epoch 097:     56 / 64 loss=6.023, ppl=65.03, wps=6251.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.686, train_wall=495, gb_free=6.1, wall=33377
2022-01-31 18:07:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:07:58 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.934 | ppl 977.99 | wps 8209.9 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.29
2022-01-31 18:07:58 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-31 18:07:58 | INFO | train | epoch 097 | loss 6.012 | ppl 64.52 | wps 6078.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.688 | train_wall 316 | gb_free 6.1 | wall 33442
KL Stats: Epoch 97 Divergences: Uniform: 2.9008521560663865 Unigram: 3.5440895684390825
2022-01-31 18:07:58 | INFO | fairseq.trainer | begin training epoch 98
2022-01-31 18:07:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:13:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:13:41 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.922 | ppl 969.96 | wps 8133.2 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.29
2022-01-31 18:13:41 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-31 18:13:41 | INFO | train | epoch 098 | loss 5.991 | ppl 63.61 | wps 6073.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.694 | train_wall 316 | gb_free 6.1 | wall 33786
KL Stats: Epoch 98 Divergences: Uniform: 2.898821637305587 Unigram: 3.5435061844200546
2022-01-31 18:13:41 | INFO | fairseq.trainer | begin training epoch 99
2022-01-31 18:13:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:16:01 | INFO | train_inner | epoch 099:     28 / 64 loss=5.982, ppl=63.22, wps=5944.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.693, train_wall=493, gb_free=6.1, wall=33926
2022-01-31 18:18:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:19:25 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.938 | ppl 980.89 | wps 8192.8 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.29
2022-01-31 18:19:25 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-31 18:19:25 | INFO | train | epoch 099 | loss 5.974 | ppl 62.84 | wps 6071.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.695 | train_wall 316 | gb_free 6.1 | wall 34130
KL Stats: Epoch 99 Divergences: Uniform: 2.9051198747705156 Unigram: 3.5648624337201005
2022-01-31 18:19:26 | INFO | fairseq.trainer | begin training epoch 100
2022-01-31 18:19:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:24:42 | INFO | train_inner | epoch 100:     64 / 64 loss=5.977, ppl=62.99, wps=6250, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.705, train_wall=494, gb_free=6.1, wall=34447
2022-01-31 18:24:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:25:09 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.881 | ppl 942.76 | wps 8183.1 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.29
2022-01-31 18:25:09 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-31 18:25:09 | INFO | train | epoch 100 | loss 5.96 | ppl 62.25 | wps 6077.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.711 | train_wall 316 | gb_free 6.1 | wall 34474
KL Stats: Epoch 100 Divergences: Uniform: 2.9088823478908683 Unigram: 3.573776732324972
2022-01-31 18:25:09 | INFO | fairseq.trainer | begin training epoch 101
2022-01-31 18:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:30:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:30:53 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.939 | ppl 981.4 | wps 8222.5 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.29
2022-01-31 18:30:53 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-31 18:30:53 | INFO | train | epoch 101 | loss 5.939 | ppl 61.35 | wps 6078.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.708 | train_wall 316 | gb_free 6.1 | wall 34817
KL Stats: Epoch 101 Divergences: Uniform: 2.918221504488258 Unigram: 3.5912306227262847
2022-01-31 18:30:53 | INFO | fairseq.trainer | begin training epoch 102
2022-01-31 18:30:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:33:52 | INFO | train_inner | epoch 102:     36 / 64 loss=5.926, ppl=60.78, wps=5948, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.717, train_wall=495, gb_free=6.1, wall=34997
2022-01-31 18:36:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:36:37 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.944 | ppl 985.34 | wps 8172.1 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.29
2022-01-31 18:36:37 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-31 18:36:37 | INFO | train | epoch 102 | loss 5.926 | ppl 60.79 | wps 6068.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.725 | train_wall 317 | gb_free 6.1 | wall 35162
KL Stats: Epoch 102 Divergences: Uniform: 2.9149174840514838 Unigram: 3.5996971195981176
2022-01-31 18:36:37 | INFO | fairseq.trainer | begin training epoch 103
2022-01-31 18:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:41:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:42:21 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.942 | ppl 983.48 | wps 8184.6 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.29
2022-01-31 18:42:21 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-31 18:42:21 | INFO | train | epoch 103 | loss 5.908 | ppl 60.05 | wps 6064.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.712 | train_wall 317 | gb_free 6.1 | wall 35506
KL Stats: Epoch 103 Divergences: Uniform: 2.929068771193835 Unigram: 3.6135491361842385
2022-01-31 18:42:21 | INFO | fairseq.trainer | begin training epoch 104
2022-01-31 18:42:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:43:01 | INFO | train_inner | epoch 104:      8 / 64 loss=5.915, ppl=60.35, wps=5934.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.716, train_wall=494, gb_free=6.1, wall=35546
2022-01-31 18:47:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:48:06 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.97 | ppl 1002.85 | wps 8176.5 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.29
2022-01-31 18:48:06 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-31 18:48:06 | INFO | train | epoch 104 | loss 5.895 | ppl 59.49 | wps 6060.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.723 | train_wall 317 | gb_free 6.1 | wall 35851
KL Stats: Epoch 104 Divergences: Uniform: 2.921846406913788 Unigram: 3.628791090228322
2022-01-31 18:48:06 | INFO | fairseq.trainer | begin training epoch 105
2022-01-31 18:48:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:51:45 | INFO | train_inner | epoch 105:     44 / 64 loss=5.882, ppl=58.97, wps=6236, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.724, train_wall=496, gb_free=6.1, wall=36070
2022-01-31 18:53:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:53:50 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.926 | ppl 972.58 | wps 8158.1 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.29
2022-01-31 18:53:50 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-31 18:53:50 | INFO | train | epoch 105 | loss 5.877 | ppl 58.79 | wps 6064.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.727 | train_wall 317 | gb_free 6.1 | wall 36195
KL Stats: Epoch 105 Divergences: Uniform: 2.927999191902184 Unigram: 3.6371713334382823
2022-01-31 18:53:50 | INFO | fairseq.trainer | begin training epoch 106
2022-01-31 18:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:59:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:59:35 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.952 | ppl 990.24 | wps 8190 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.29
2022-01-31 18:59:35 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-31 18:59:35 | INFO | train | epoch 106 | loss 5.861 | ppl 58.14 | wps 6068.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.717 | train_wall 317 | gb_free 6.1 | wall 36539
KL Stats: Epoch 106 Divergences: Uniform: 2.933958317510721 Unigram: 3.641976673868673
2022-01-31 18:59:35 | INFO | fairseq.trainer | begin training epoch 107
2022-01-31 18:59:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:00:55 | INFO | train_inner | epoch 107:     16 / 64 loss=5.865, ppl=58.27, wps=5934.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.721, train_wall=494, gb_free=6.1, wall=36619
2022-01-31 19:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:05:20 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.959 | ppl 995.17 | wps 8167.9 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.29
2022-01-31 19:05:20 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-31 19:05:20 | INFO | train | epoch 107 | loss 5.846 | ppl 57.53 | wps 6054 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.722 | train_wall 317 | gb_free 6.1 | wall 36884
KL Stats: Epoch 107 Divergences: Uniform: 2.944170568341739 Unigram: 3.662934894409383
2022-01-31 19:05:20 | INFO | fairseq.trainer | begin training epoch 108
2022-01-31 19:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:09:39 | INFO | train_inner | epoch 108:     52 / 64 loss=5.842, ppl=57.35, wps=6236, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.726, train_wall=496, gb_free=6.1, wall=37143
2022-01-31 19:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:11:04 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.941 | ppl 983.21 | wps 8137.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.29
2022-01-31 19:11:04 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-31 19:11:04 | INFO | train | epoch 108 | loss 5.835 | ppl 57.09 | wps 6058.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.736 | train_wall 317 | gb_free 6.1 | wall 37229
KL Stats: Epoch 108 Divergences: Uniform: 2.9456544628261834 Unigram: 3.6713233821613227
2022-01-31 19:11:04 | INFO | fairseq.trainer | begin training epoch 109
2022-01-31 19:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:16:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:16:49 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.963 | ppl 998.24 | wps 8150 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.29
2022-01-31 19:16:49 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-31 19:16:49 | INFO | train | epoch 109 | loss 5.819 | ppl 56.47 | wps 6052.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.742 | train_wall 317 | gb_free 6.1 | wall 37574
KL Stats: Epoch 109 Divergences: Uniform: 2.9469948557816874 Unigram: 3.686066909625802
2022-01-31 19:16:49 | INFO | fairseq.trainer | begin training epoch 110
2022-01-31 19:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:18:49 | INFO | train_inner | epoch 110:     24 / 64 loss=5.813, ppl=56.23, wps=5921.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.747, train_wall=495, gb_free=6.1, wall=37694
2022-01-31 19:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:22:34 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.052 | ppl 1061.29 | wps 8141.6 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.29
2022-01-31 19:22:34 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-31 19:22:34 | INFO | train | epoch 110 | loss 5.806 | ppl 55.95 | wps 6058 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.748 | train_wall 317 | gb_free 6.1 | wall 37919
KL Stats: Epoch 110 Divergences: Uniform: 2.9529942547645347 Unigram: 3.688917320143949
2022-01-31 19:22:34 | INFO | fairseq.trainer | begin training epoch 111
2022-01-31 19:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:27:33 | INFO | train_inner | epoch 111:     60 / 64 loss=5.805, ppl=55.92, wps=6233.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.758, train_wall=496, gb_free=6.1, wall=38218
2022-01-31 19:27:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:28:19 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.997 | ppl 1021.8 | wps 8173 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.29
2022-01-31 19:28:19 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-31 19:28:19 | INFO | train | epoch 111 | loss 5.793 | ppl 55.43 | wps 6058.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.77 | train_wall 317 | gb_free 6.1 | wall 38264
KL Stats: Epoch 111 Divergences: Uniform: 2.958232169144957 Unigram: 3.712586618136471
2022-01-31 19:28:19 | INFO | fairseq.trainer | begin training epoch 112
2022-01-31 19:28:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:33:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:34:03 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.038 | ppl 1051.03 | wps 8178 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.29
2022-01-31 19:34:03 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-31 19:34:03 | INFO | train | epoch 112 | loss 5.778 | ppl 54.86 | wps 6066.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.748 | train_wall 317 | gb_free 6.1 | wall 38608
KL Stats: Epoch 112 Divergences: Uniform: 2.956651482749292 Unigram: 3.7232129993938203
2022-01-31 19:34:03 | INFO | fairseq.trainer | begin training epoch 113
2022-01-31 19:34:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:36:43 | INFO | train_inner | epoch 113:     32 / 64 loss=5.766, ppl=54.41, wps=5933.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.75, train_wall=495, gb_free=6.1, wall=38768
2022-01-31 19:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:39:48 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.065 | ppl 1071.18 | wps 8182.9 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.29
2022-01-31 19:39:48 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-31 19:39:48 | INFO | train | epoch 113 | loss 5.763 | ppl 54.3 | wps 6059.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.76 | train_wall 317 | gb_free 6.1 | wall 38953
KL Stats: Epoch 113 Divergences: Uniform: 2.970154316013673 Unigram: 3.7323132333785125
2022-01-31 19:39:48 | INFO | fairseq.trainer | begin training epoch 114
2022-01-31 19:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:45:33 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.032 | ppl 1046.72 | wps 8181.3 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.29
2022-01-31 19:45:33 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-31 19:45:33 | INFO | train | epoch 114 | loss 5.75 | ppl 53.83 | wps 6060.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.772 | train_wall 317 | gb_free 6.1 | wall 39297
KL Stats: Epoch 114 Divergences: Uniform: 2.9633227946014338 Unigram: 3.7364174323879875
2022-01-31 19:45:33 | INFO | fairseq.trainer | begin training epoch 115
2022-01-31 19:45:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:45:53 | INFO | train_inner | epoch 115:      4 / 64 loss=5.763, ppl=54.3, wps=5930.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.772, train_wall=495, gb_free=6.1, wall=39317
2022-01-31 19:50:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:51:17 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.052 | ppl 1061.8 | wps 8171.6 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.29
2022-01-31 19:51:17 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-31 19:51:17 | INFO | train | epoch 115 | loss 5.738 | ppl 53.38 | wps 6064.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.781 | train_wall 317 | gb_free 6.1 | wall 39642
KL Stats: Epoch 115 Divergences: Uniform: 2.9710936173829725 Unigram: 3.7451520825405944
2022-01-31 19:51:17 | INFO | fairseq.trainer | begin training epoch 116
2022-01-31 19:51:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:54:36 | INFO | train_inner | epoch 116:     40 / 64 loss=5.724, ppl=52.87, wps=6240.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.776, train_wall=496, gb_free=6.1, wall=39841
2022-01-31 19:56:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:57:01 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.013 | ppl 1033.54 | wps 8186.4 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.29
2022-01-31 19:57:01 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-31 19:57:01 | INFO | train | epoch 116 | loss 5.725 | ppl 52.89 | wps 6066.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.774 | train_wall 317 | gb_free 6.1 | wall 39986
KL Stats: Epoch 116 Divergences: Uniform: 2.9725005049944664 Unigram: 3.7522981510763427
2022-01-31 19:57:01 | INFO | fairseq.trainer | begin training epoch 117
2022-01-31 19:57:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:02:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:02:46 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.074 | ppl 1077.9 | wps 8163.7 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.29
2022-01-31 20:02:46 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-31 20:02:46 | INFO | train | epoch 117 | loss 5.715 | ppl 52.53 | wps 6054.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.789 | train_wall 317 | gb_free 6.1 | wall 40331
KL Stats: Epoch 117 Divergences: Uniform: 2.9722236854681903 Unigram: 3.771100226900496
2022-01-31 20:02:46 | INFO | fairseq.trainer | begin training epoch 118
2022-01-31 20:02:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:03:46 | INFO | train_inner | epoch 118:     12 / 64 loss=5.72, ppl=52.71, wps=5927.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.792, train_wall=495, gb_free=6.1, wall=40391
2022-01-31 20:08:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:08:31 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.103 | ppl 1099.98 | wps 8154.4 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.29
2022-01-31 20:08:31 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-31 20:08:31 | INFO | train | epoch 118 | loss 5.702 | ppl 52.07 | wps 6059.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.8 | train_wall 317 | gb_free 6.1 | wall 40676
KL Stats: Epoch 118 Divergences: Uniform: 2.984010811334602 Unigram: 3.7770286188409217
2022-01-31 20:08:31 | INFO | fairseq.trainer | begin training epoch 119
2022-01-31 20:08:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:12:30 | INFO | train_inner | epoch 119:     48 / 64 loss=5.691, ppl=51.68, wps=6238, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.795, train_wall=496, gb_free=6.1, wall=40915
2022-01-31 20:13:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:14:15 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.057 | ppl 1065.31 | wps 8163.2 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.29
2022-01-31 20:14:15 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-31 20:14:15 | INFO | train | epoch 119 | loss 5.688 | ppl 51.56 | wps 6064.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.802 | train_wall 317 | gb_free 6.1 | wall 41020
KL Stats: Epoch 119 Divergences: Uniform: 2.9861449888426623 Unigram: 3.7924699652105027
2022-01-31 20:14:15 | INFO | fairseq.trainer | begin training epoch 120
2022-01-31 20:14:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:20:01 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.094 | ppl 1093.28 | wps 8130.5 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.29
2022-01-31 20:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-31 20:20:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint120.pt
2022-01-31 20:20:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint120.pt
2022-01-31 20:20:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.094) (writing took 4.2514712903648615 seconds)
2022-01-31 20:20:05 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-31 20:20:05 | INFO | train | epoch 120 | loss 5.678 | ppl 51.2 | wps 5974.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.794 | train_wall 318 | gb_free 6.1 | wall 41370
KL Stats: Epoch 120 Divergences: Uniform: 2.989256713001981 Unigram: 3.7992169731096115
2022-01-31 20:20:05 | INFO | fairseq.trainer | begin training epoch 121
2022-01-31 20:20:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:21:45 | INFO | train_inner | epoch 121:     20 / 64 loss=5.679, ppl=51.23, wps=5875.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.8, train_wall=495, gb_free=6.1, wall=41470
2022-01-31 20:25:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:25:50 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.088 | ppl 1088.68 | wps 8158.9 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.29
2022-01-31 20:25:50 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-31 20:25:50 | INFO | train | epoch 121 | loss 5.667 | ppl 50.8 | wps 6054.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.802 | train_wall 317 | gb_free 6.1 | wall 41715
KL Stats: Epoch 121 Divergences: Uniform: 2.9903880911724228 Unigram: 3.807805982421252
2022-01-31 20:25:50 | INFO | fairseq.trainer | begin training epoch 122
2022-01-31 20:25:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:30:29 | INFO | train_inner | epoch 122:     56 / 64 loss=5.665, ppl=50.73, wps=6237.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.812, train_wall=496, gb_free=6.1, wall=41994
2022-01-31 20:31:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:31:34 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.039 | ppl 1052.15 | wps 8153.2 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.29
2022-01-31 20:31:34 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-31 20:31:34 | INFO | train | epoch 122 | loss 5.657 | ppl 50.44 | wps 6063.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.822 | train_wall 317 | gb_free 6.1 | wall 42059
KL Stats: Epoch 122 Divergences: Uniform: 2.996788647457382 Unigram: 3.8190911733675574
2022-01-31 20:31:34 | INFO | fairseq.trainer | begin training epoch 123
2022-01-31 20:31:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:36:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:37:19 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.127 | ppl 1118.49 | wps 8142.4 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.29
2022-01-31 20:37:19 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-31 20:37:19 | INFO | train | epoch 123 | loss 5.643 | ppl 49.99 | wps 6057.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.804 | train_wall 317 | gb_free 6.1 | wall 42404
KL Stats: Epoch 123 Divergences: Uniform: 2.996793557737226 Unigram: 3.8350295237419716
2022-01-31 20:37:19 | INFO | fairseq.trainer | begin training epoch 124
2022-01-31 20:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:39:39 | INFO | train_inner | epoch 124:     28 / 64 loss=5.637, ppl=49.76, wps=5921.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.806, train_wall=495, gb_free=6.1, wall=42544
2022-01-31 20:42:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:43:05 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.057 | ppl 1065.51 | wps 8160.5 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.29
2022-01-31 20:43:05 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-31 20:43:05 | INFO | train | epoch 124 | loss 5.634 | ppl 49.66 | wps 6043.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.828 | train_wall 318 | gb_free 6.1 | wall 42749
KL Stats: Epoch 124 Divergences: Uniform: 2.9909709621629235 Unigram: 3.8277534898841745
2022-01-31 20:43:05 | INFO | fairseq.trainer | begin training epoch 125
2022-01-31 20:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:48:22 | INFO | train_inner | epoch 125:     64 / 64 loss=5.637, ppl=49.76, wps=6232.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.833, train_wall=495, gb_free=6.1, wall=43067
2022-01-31 20:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:48:49 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.106 | ppl 1102.37 | wps 8189.3 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.29
2022-01-31 20:48:49 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-31 20:48:49 | INFO | train | epoch 125 | loss 5.622 | ppl 49.26 | wps 6062.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.827 | train_wall 317 | gb_free 6.1 | wall 43094
KL Stats: Epoch 125 Divergences: Uniform: 2.998012022288492 Unigram: 3.8434956307629187
2022-01-31 20:48:49 | INFO | fairseq.trainer | begin training epoch 126
2022-01-31 20:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:54:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:54:34 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.118 | ppl 1111.02 | wps 8170.1 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.29
2022-01-31 20:54:34 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-31 20:54:34 | INFO | train | epoch 126 | loss 5.611 | ppl 48.88 | wps 6062.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.814 | train_wall 317 | gb_free 6.1 | wall 43438
KL Stats: Epoch 126 Divergences: Uniform: 3.0052412037737253 Unigram: 3.854848321786839
2022-01-31 20:54:34 | INFO | fairseq.trainer | begin training epoch 127
2022-01-31 20:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:57:33 | INFO | train_inner | epoch 127:     36 / 64 loss=5.599, ppl=48.49, wps=5933, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.832, train_wall=496, gb_free=6.1, wall=43618
2022-01-31 20:59:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:00:18 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.102 | ppl 1098.67 | wps 8182.4 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.29
2022-01-31 21:00:18 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-31 21:00:18 | INFO | train | epoch 127 | loss 5.602 | ppl 48.57 | wps 6060.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.842 | train_wall 317 | gb_free 6.1 | wall 43783
KL Stats: Epoch 127 Divergences: Uniform: 3.0059959567815424 Unigram: 3.861290193059103
2022-01-31 21:00:18 | INFO | fairseq.trainer | begin training epoch 128
2022-01-31 21:00:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:05:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:06:03 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.125 | ppl 1116.66 | wps 8098.9 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.29
2022-01-31 21:06:03 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-31 21:06:03 | INFO | train | epoch 128 | loss 5.591 | ppl 48.2 | wps 6053.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.844 | train_wall 317 | gb_free 6.1 | wall 44128
KL Stats: Epoch 128 Divergences: Uniform: 3.0055516493145857 Unigram: 3.8689075788285434
2022-01-31 21:06:03 | INFO | fairseq.trainer | begin training epoch 129
2022-01-31 21:06:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:06:44 | INFO | train_inner | epoch 129:      8 / 64 loss=5.598, ppl=48.45, wps=5924.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.838, train_wall=495, gb_free=6.1, wall=44168
2022-01-31 21:11:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:11:49 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.124 | ppl 1115.58 | wps 8127.4 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.29
2022-01-31 21:11:49 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-31 21:11:49 | INFO | train | epoch 129 | loss 5.584 | ppl 47.98 | wps 6041.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.854 | train_wall 318 | gb_free 6.1 | wall 44474
KL Stats: Epoch 129 Divergences: Uniform: 3.002639358222511 Unigram: 3.877890855219435
2022-01-31 21:11:49 | INFO | fairseq.trainer | begin training epoch 130
2022-01-31 21:11:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:15:29 | INFO | train_inner | epoch 130:     44 / 64 loss=5.571, ppl=47.55, wps=6219.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.845, train_wall=497, gb_free=6.1, wall=44694
2022-01-31 21:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:17:35 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.128 | ppl 1118.85 | wps 8069.3 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.29
2022-01-31 21:17:35 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-31 21:17:35 | INFO | train | epoch 130 | loss 5.571 | ppl 47.53 | wps 6037.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.841 | train_wall 318 | gb_free 6.1 | wall 44820
KL Stats: Epoch 130 Divergences: Uniform: 3.008637856865691 Unigram: 3.888506879184281
2022-01-31 21:17:35 | INFO | fairseq.trainer | begin training epoch 131
2022-01-31 21:17:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:22:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:23:21 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.099 | ppl 1096.83 | wps 8160.7 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.29
2022-01-31 21:23:21 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-31 21:23:21 | INFO | train | epoch 131 | loss 5.563 | ppl 47.27 | wps 6043.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.86 | train_wall 318 | gb_free 6.1 | wall 45165
KL Stats: Epoch 131 Divergences: Uniform: 3.014075638398138 Unigram: 3.892896715503664
2022-01-31 21:23:21 | INFO | fairseq.trainer | begin training epoch 132
2022-01-31 21:23:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:24:41 | INFO | train_inner | epoch 132:     16 / 64 loss=5.566, ppl=47.37, wps=5908.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.859, train_wall=496, gb_free=6.1, wall=45245
2022-01-31 21:28:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:29:06 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.128 | ppl 1119.28 | wps 8173.6 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.29
2022-01-31 21:29:06 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-31 21:29:06 | INFO | train | epoch 132 | loss 5.553 | ppl 46.96 | wps 6052.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.872 | train_wall 317 | gb_free 6.1 | wall 45510
KL Stats: Epoch 132 Divergences: Uniform: 3.01276792201581 Unigram: 3.9087337620037164
2022-01-31 21:29:06 | INFO | fairseq.trainer | begin training epoch 133
2022-01-31 21:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:33:25 | INFO | train_inner | epoch 133:     52 / 64 loss=5.547, ppl=46.77, wps=6232.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.872, train_wall=496, gb_free=6.1, wall=45770
2022-01-31 21:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:34:51 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.095 | ppl 1093.75 | wps 8131.6 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.29
2022-01-31 21:34:51 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-31 21:34:51 | INFO | train | epoch 133 | loss 5.542 | ppl 46.6 | wps 6051.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.871 | train_wall 317 | gb_free 6.1 | wall 45856
KL Stats: Epoch 133 Divergences: Uniform: 3.0247023631560235 Unigram: 3.9125850140334126
2022-01-31 21:34:51 | INFO | fairseq.trainer | begin training epoch 134
2022-01-31 21:34:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:40:36 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.213 | ppl 1187.23 | wps 8172.5 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.29
2022-01-31 21:40:36 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-31 21:40:36 | INFO | train | epoch 134 | loss 5.534 | ppl 46.35 | wps 6046.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.901 | train_wall 318 | gb_free 6.1 | wall 46201
KL Stats: Epoch 134 Divergences: Uniform: 3.015347536859965 Unigram: 3.918390897978585
2022-01-31 21:40:36 | INFO | fairseq.trainer | begin training epoch 135
2022-01-31 21:40:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:42:36 | INFO | train_inner | epoch 135:     24 / 64 loss=5.533, ppl=46.3, wps=5916.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.892, train_wall=496, gb_free=6.1, wall=46321
2022-01-31 21:45:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:46:21 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.154 | ppl 1138.99 | wps 8154.3 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.29
2022-01-31 21:46:21 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-31 21:46:21 | INFO | train | epoch 135 | loss 5.524 | ppl 46.03 | wps 6059 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.879 | train_wall 317 | gb_free 6.1 | wall 46546
KL Stats: Epoch 135 Divergences: Uniform: 3.021054618791427 Unigram: 3.929158523143052
2022-01-31 21:46:21 | INFO | fairseq.trainer | begin training epoch 136
2022-01-31 21:46:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:51:20 | INFO | train_inner | epoch 136:     60 / 64 loss=5.525, ppl=46.05, wps=6236.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.886, train_wall=496, gb_free=6.1, wall=46845
2022-01-31 21:51:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:52:06 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.168 | ppl 1150.12 | wps 8159.3 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.29
2022-01-31 21:52:06 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-31 21:52:06 | INFO | train | epoch 136 | loss 5.516 | ppl 45.75 | wps 6060.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.889 | train_wall 317 | gb_free 6.1 | wall 46890
KL Stats: Epoch 136 Divergences: Uniform: 3.0212329563118856 Unigram: 3.933462528562313
2022-01-31 21:52:06 | INFO | fairseq.trainer | begin training epoch 137
2022-01-31 21:52:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:57:51 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.222 | ppl 1194.61 | wps 8159.8 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.29
2022-01-31 21:57:51 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-31 21:57:51 | INFO | train | epoch 137 | loss 5.509 | ppl 45.53 | wps 6049.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.921 | train_wall 318 | gb_free 6.1 | wall 47236
KL Stats: Epoch 137 Divergences: Uniform: 3.023289416453281 Unigram: 3.944449442310223
2022-01-31 21:57:51 | INFO | fairseq.trainer | begin training epoch 138
2022-01-31 21:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:00:30 | INFO | train_inner | epoch 138:     32 / 64 loss=5.499, ppl=45.23, wps=5923.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.903, train_wall=495, gb_free=6.1, wall=47395
2022-01-31 22:03:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:03:36 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.237 | ppl 1206.99 | wps 8168.2 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.29
2022-01-31 22:03:36 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-31 22:03:36 | INFO | train | epoch 138 | loss 5.497 | ppl 45.16 | wps 6060.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.891 | train_wall 317 | gb_free 6.1 | wall 47580
KL Stats: Epoch 138 Divergences: Uniform: 3.025632021112861 Unigram: 3.946643257903037
2022-01-31 22:03:36 | INFO | fairseq.trainer | begin training epoch 139
2022-01-31 22:03:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:08:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:09:20 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.211 | ppl 1185.54 | wps 8180.7 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.29
2022-01-31 22:09:20 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-31 22:09:20 | INFO | train | epoch 139 | loss 5.488 | ppl 44.88 | wps 6057.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.923 | train_wall 317 | gb_free 6.1 | wall 47925
KL Stats: Epoch 139 Divergences: Uniform: 3.028012962908518 Unigram: 3.9649852330664555
2022-01-31 22:09:20 | INFO | fairseq.trainer | begin training epoch 140
2022-01-31 22:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:09:40 | INFO | train_inner | epoch 140:      4 / 64 loss=5.496, ppl=45.12, wps=5927.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.921, train_wall=495, gb_free=6.1, wall=47945
2022-01-31 22:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:15:05 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.195 | ppl 1171.92 | wps 8132.8 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.29
2022-01-31 22:15:05 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-31 22:15:05 | INFO | train | epoch 140 | loss 5.48 | ppl 44.64 | wps 6063.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.922 | train_wall 317 | gb_free 6.1 | wall 48270
KL Stats: Epoch 140 Divergences: Uniform: 3.027051586497375 Unigram: 3.9706657729675863
2022-01-31 22:15:05 | INFO | fairseq.trainer | begin training epoch 141
2022-01-31 22:15:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:18:24 | INFO | train_inner | epoch 141:     40 / 64 loss=5.472, ppl=44.39, wps=6239.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.924, train_wall=496, gb_free=6.1, wall=48469
2022-01-31 22:20:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:20:50 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.251 | ppl 1218.6 | wps 8116.9 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.29
2022-01-31 22:20:50 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-31 22:20:50 | INFO | train | epoch 141 | loss 5.472 | ppl 44.39 | wps 6057.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.916 | train_wall 317 | gb_free 6.1 | wall 48614
KL Stats: Epoch 141 Divergences: Uniform: 3.033565383459058 Unigram: 3.9799895220949977
2022-01-31 22:20:50 | INFO | fairseq.trainer | begin training epoch 142
2022-01-31 22:20:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:26:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:26:34 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.203 | ppl 1178.51 | wps 8199.2 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.29
2022-01-31 22:26:34 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-31 22:26:34 | INFO | train | epoch 142 | loss 5.464 | ppl 44.14 | wps 6058.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.946 | train_wall 317 | gb_free 6.1 | wall 48959
KL Stats: Epoch 142 Divergences: Uniform: 3.0330811368059276 Unigram: 3.978078231566015
2022-01-31 22:26:34 | INFO | fairseq.trainer | begin training epoch 143
2022-01-31 22:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:27:34 | INFO | train_inner | epoch 143:     12 / 64 loss=5.465, ppl=44.17, wps=5926.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.931, train_wall=495, gb_free=6.1, wall=49019
2022-01-31 22:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:32:19 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.191 | ppl 1168.61 | wps 8186.6 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.29
2022-01-31 22:32:19 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-31 22:32:19 | INFO | train | epoch 143 | loss 5.455 | ppl 43.86 | wps 6062.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.918 | train_wall 317 | gb_free 6.1 | wall 49304
KL Stats: Epoch 143 Divergences: Uniform: 3.04291486221581 Unigram: 3.9888203822397097
2022-01-31 22:32:19 | INFO | fairseq.trainer | begin training epoch 144
2022-01-31 22:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:36:19 | INFO | train_inner | epoch 144:     48 / 64 loss=5.452, ppl=43.79, wps=6232.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.915, train_wall=496, gb_free=6.1, wall=49543
2022-01-31 22:37:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:38:04 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.278 | ppl 1241.81 | wps 8187.7 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.29
2022-01-31 22:38:04 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-31 22:38:04 | INFO | train | epoch 144 | loss 5.45 | ppl 43.7 | wps 6053.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.917 | train_wall 317 | gb_free 6.1 | wall 49649
KL Stats: Epoch 144 Divergences: Uniform: 3.0339599184814263 Unigram: 3.990451990949594
2022-01-31 22:38:04 | INFO | fairseq.trainer | begin training epoch 145
2022-01-31 22:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:43:48 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.215 | ppl 1188.73 | wps 8167 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.29
2022-01-31 22:43:48 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-31 22:43:48 | INFO | train | epoch 145 | loss 5.442 | ppl 43.48 | wps 6065.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.945 | train_wall 317 | gb_free 6.1 | wall 49993
KL Stats: Epoch 145 Divergences: Uniform: 3.042607400558072 Unigram: 4.001060286258201
2022-01-31 22:43:48 | INFO | fairseq.trainer | begin training epoch 146
2022-01-31 22:43:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:45:28 | INFO | train_inner | epoch 146:     20 / 64 loss=5.438, ppl=43.36, wps=5933.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.947, train_wall=495, gb_free=6.1, wall=50093
2022-01-31 22:49:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:49:33 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.231 | ppl 1201.56 | wps 8165.7 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.29
2022-01-31 22:49:33 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-31 22:49:33 | INFO | train | epoch 146 | loss 5.431 | ppl 43.16 | wps 6063.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.961 | train_wall 317 | gb_free 6.1 | wall 50337
KL Stats: Epoch 146 Divergences: Uniform: 3.03956439491912 Unigram: 4.0042693935602545
2022-01-31 22:49:33 | INFO | fairseq.trainer | begin training epoch 147
2022-01-31 22:49:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:54:12 | INFO | train_inner | epoch 147:     56 / 64 loss=5.433, ppl=43.21, wps=6237.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.969, train_wall=496, gb_free=6.1, wall=50617
2022-01-31 22:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:55:17 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.183 | ppl 1162.53 | wps 8172.8 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.29
2022-01-31 22:55:17 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-31 22:55:17 | INFO | train | epoch 147 | loss 5.424 | ppl 42.94 | wps 6061.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.98 | train_wall 317 | gb_free 6.1 | wall 50682
KL Stats: Epoch 147 Divergences: Uniform: 3.045200730132041 Unigram: 4.01579120177139
2022-01-31 22:55:17 | INFO | fairseq.trainer | begin training epoch 148
2022-01-31 22:55:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:00:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:01:02 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.208 | ppl 1182.65 | wps 8165.2 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.29
2022-01-31 23:01:02 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-31 23:01:02 | INFO | train | epoch 148 | loss 5.417 | ppl 42.71 | wps 6058.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.953 | train_wall 317 | gb_free 6.1 | wall 51027
KL Stats: Epoch 148 Divergences: Uniform: 3.0429937698763845 Unigram: 4.0224635293099595
2022-01-31 23:01:02 | INFO | fairseq.trainer | begin training epoch 149
2022-01-31 23:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:03:22 | INFO | train_inner | epoch 149:     28 / 64 loss=5.412, ppl=42.59, wps=5927.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.957, train_wall=495, gb_free=6.1, wall=51167
2022-01-31 23:06:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:06:47 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.287 | ppl 1249.06 | wps 8164.2 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.29
2022-01-31 23:06:47 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-31 23:06:47 | INFO | train | epoch 149 | loss 5.411 | ppl 42.55 | wps 6054.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.965 | train_wall 317 | gb_free 6.1 | wall 51372
KL Stats: Epoch 149 Divergences: Uniform: 3.0491225005148572 Unigram: 4.029804365612695
2022-01-31 23:06:47 | INFO | fairseq.trainer | begin training epoch 150
2022-01-31 23:06:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:12:05 | INFO | train_inner | epoch 150:     64 / 64 loss=5.413, ppl=42.61, wps=6228.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.972, train_wall=495, gb_free=6.1, wall=51690
2022-01-31 23:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:12:32 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.286 | ppl 1248.38 | wps 8187.4 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.29
2022-01-31 23:12:32 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-31 23:12:32 | INFO | train | epoch 150 | loss 5.402 | ppl 42.29 | wps 6055 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.97 | train_wall 317 | gb_free 6.1 | wall 51717
KL Stats: Epoch 150 Divergences: Uniform: 3.047466270880227 Unigram: 4.0299796912070125
2022-01-31 23:12:32 | INFO | fairseq.trainer | begin training epoch 151
2022-01-31 23:12:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:17:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:18:17 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.223 | ppl 1195.37 | wps 8143.3 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.29
2022-01-31 23:18:17 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-31 23:18:17 | INFO | train | epoch 151 | loss 5.394 | ppl 42.06 | wps 6056.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.997 | train_wall 317 | gb_free 6.1 | wall 52062
KL Stats: Epoch 151 Divergences: Uniform: 3.0434594882418198 Unigram: 4.039476807996849
2022-01-31 23:18:17 | INFO | fairseq.trainer | begin training epoch 152
2022-01-31 23:18:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:21:16 | INFO | train_inner | epoch 152:     36 / 64 loss=5.381, ppl=41.69, wps=5928.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.995, train_wall=496, gb_free=6.1, wall=52241
2022-01-31 23:23:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:24:02 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.213 | ppl 1186.53 | wps 8163.5 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.29
2022-01-31 23:24:02 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-31 23:24:02 | INFO | train | epoch 152 | loss 5.388 | ppl 41.86 | wps 6059.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.003 | train_wall 317 | gb_free 6.1 | wall 52406
KL Stats: Epoch 152 Divergences: Uniform: 3.0542965377641687 Unigram: 4.050538004423532
2022-01-31 23:24:02 | INFO | fairseq.trainer | begin training epoch 153
2022-01-31 23:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:29:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:29:46 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.263 | ppl 1228.88 | wps 8178.9 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.29
2022-01-31 23:29:46 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-31 23:29:46 | INFO | train | epoch 153 | loss 5.379 | ppl 41.62 | wps 6061.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.986 | train_wall 317 | gb_free 6.1 | wall 52751
KL Stats: Epoch 153 Divergences: Uniform: 3.0533656572374936 Unigram: 4.056986386332573
2022-01-31 23:29:46 | INFO | fairseq.trainer | begin training epoch 154
2022-01-31 23:29:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:30:26 | INFO | train_inner | epoch 154:      8 / 64 loss=5.388, ppl=41.86, wps=5930.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.997, train_wall=495, gb_free=6.1, wall=52791
2022-01-31 23:35:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:35:31 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.282 | ppl 1244.96 | wps 8137.7 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.29
2022-01-31 23:35:31 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-31 23:35:31 | INFO | train | epoch 154 | loss 5.373 | ppl 41.44 | wps 6060.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.011 | train_wall 317 | gb_free 6.1 | wall 53095
KL Stats: Epoch 154 Divergences: Uniform: 3.0596152090571267 Unigram: 4.058354967814046
2022-01-31 23:35:31 | INFO | fairseq.trainer | begin training epoch 155
2022-01-31 23:35:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:39:11 | INFO | train_inner | epoch 155:     44 / 64 loss=5.365, ppl=41.2, wps=6231.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.994, train_wall=496, gb_free=6.1, wall=53315
2022-01-31 23:40:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:41:16 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.261 | ppl 1226.66 | wps 8155.2 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.29
2022-01-31 23:41:16 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-31 23:41:16 | INFO | train | epoch 155 | loss 5.367 | ppl 41.28 | wps 6049.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.002 | train_wall 318 | gb_free 6.1 | wall 53441
KL Stats: Epoch 155 Divergences: Uniform: 3.0548763614837404 Unigram: 4.070180938448104
2022-01-31 23:41:16 | INFO | fairseq.trainer | begin training epoch 156
2022-01-31 23:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:46:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:47:01 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.271 | ppl 1235.58 | wps 8162.3 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.29
2022-01-31 23:47:01 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-31 23:47:01 | INFO | train | epoch 156 | loss 5.36 | ppl 41.06 | wps 6061.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.034 | train_wall 317 | gb_free 6.1 | wall 53785
KL Stats: Epoch 156 Divergences: Uniform: 3.056439922483455 Unigram: 4.069101174672444
2022-01-31 23:47:01 | INFO | fairseq.trainer | begin training epoch 157
2022-01-31 23:47:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:48:20 | INFO | train_inner | epoch 157:     16 / 64 loss=5.366, ppl=41.24, wps=5929, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.036, train_wall=495, gb_free=6.1, wall=53865
2022-01-31 23:52:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:52:45 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.232 | ppl 1202.85 | wps 8167 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.29
2022-01-31 23:52:45 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-01-31 23:52:45 | INFO | train | epoch 157 | loss 5.352 | ppl 40.85 | wps 6059.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.022 | train_wall 317 | gb_free 6.1 | wall 54130
KL Stats: Epoch 157 Divergences: Uniform: 3.0608715626910903 Unigram: 4.079767542947836
2022-01-31 23:52:45 | INFO | fairseq.trainer | begin training epoch 158
2022-01-31 23:52:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:57:05 | INFO | train_inner | epoch 158:     52 / 64 loss=5.346, ppl=40.67, wps=6236.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.014, train_wall=496, gb_free=6.1, wall=54389
2022-01-31 23:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:58:30 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.288 | ppl 1250.01 | wps 8173.1 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.29
2022-01-31 23:58:30 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-01-31 23:58:30 | INFO | train | epoch 158 | loss 5.346 | ppl 40.68 | wps 6062.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.016 | train_wall 317 | gb_free 6.1 | wall 54475
KL Stats: Epoch 158 Divergences: Uniform: 3.0558533945773583 Unigram: 4.086374289821213
2022-01-31 23:58:30 | INFO | fairseq.trainer | begin training epoch 159
2022-01-31 23:58:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:03:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:04:14 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.326 | ppl 1283.23 | wps 8163.8 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.29
2022-02-01 00:04:14 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-01 00:04:14 | INFO | train | epoch 159 | loss 5.34 | ppl 40.51 | wps 6061.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.054 | train_wall 317 | gb_free 6.1 | wall 54819
KL Stats: Epoch 159 Divergences: Uniform: 3.0549733275791513 Unigram: 4.093062282084784
2022-02-01 00:04:14 | INFO | fairseq.trainer | begin training epoch 160
2022-02-01 00:04:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:06:14 | INFO | train_inner | epoch 160:     24 / 64 loss=5.339, ppl=40.48, wps=5931.2, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.058, train_wall=495, gb_free=6.1, wall=54939
2022-02-01 00:09:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:09:59 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.269 | ppl 1234.01 | wps 8158 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.29
2022-02-01 00:09:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-01 00:09:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint160.pt
2022-02-01 00:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint160.pt
2022-02-01 00:10:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.269) (writing took 4.05583181604743 seconds)
2022-02-01 00:10:03 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-01 00:10:03 | INFO | train | epoch 160 | loss 5.333 | ppl 40.31 | wps 5992.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.046 | train_wall 317 | gb_free 6.1 | wall 55168
KL Stats: Epoch 160 Divergences: Uniform: 3.0616603969628158 Unigram: 4.100983607626151
2022-02-01 00:10:03 | INFO | fairseq.trainer | begin training epoch 161
2022-02-01 00:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:15:02 | INFO | train_inner | epoch 161:     60 / 64 loss=5.334, ppl=40.34, wps=6190.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.04, train_wall=496, gb_free=6.1, wall=55467
2022-02-01 00:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:15:48 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.24 | ppl 1209.22 | wps 8161.6 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.29
2022-02-01 00:15:48 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-01 00:15:48 | INFO | train | epoch 161 | loss 5.327 | ppl 40.14 | wps 6061.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.041 | train_wall 317 | gb_free 6.1 | wall 55512
KL Stats: Epoch 161 Divergences: Uniform: 3.0672003823918232 Unigram: 4.102704337899334
2022-02-01 00:15:48 | INFO | fairseq.trainer | begin training epoch 162
2022-02-01 00:15:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:21:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:21:32 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.242 | ppl 1211.15 | wps 8142.7 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.29
2022-02-01 00:21:32 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-01 00:21:32 | INFO | train | epoch 162 | loss 5.319 | ppl 39.92 | wps 6064.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.039 | train_wall 317 | gb_free 6.1 | wall 55857
KL Stats: Epoch 162 Divergences: Uniform: 3.068637760702473 Unigram: 4.110482323820518
2022-02-01 00:21:32 | INFO | fairseq.trainer | begin training epoch 163
2022-02-01 00:21:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:24:11 | INFO | train_inner | epoch 163:     32 / 64 loss=5.306, ppl=39.57, wps=5934.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.044, train_wall=494, gb_free=6.1, wall=56016
2022-02-01 00:26:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:27:17 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.387 | ppl 1338.81 | wps 8114.2 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.29
2022-02-01 00:27:17 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-01 00:27:17 | INFO | train | epoch 163 | loss 5.316 | ppl 39.83 | wps 6061.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.056 | train_wall 317 | gb_free 6.1 | wall 56201
KL Stats: Epoch 163 Divergences: Uniform: 3.0683272439429246 Unigram: 4.117609959309015
2022-02-01 00:27:17 | INFO | fairseq.trainer | begin training epoch 164
2022-02-01 00:27:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:33:01 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.279 | ppl 1242.12 | wps 8166.3 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.29
2022-02-01 00:33:01 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-01 00:33:01 | INFO | train | epoch 164 | loss 5.308 | ppl 39.61 | wps 6064.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.07 | train_wall 317 | gb_free 6.1 | wall 56546
KL Stats: Epoch 164 Divergences: Uniform: 3.0633462307138863 Unigram: 4.121737585562999
2022-02-01 00:33:01 | INFO | fairseq.trainer | begin training epoch 165
2022-02-01 00:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:33:21 | INFO | train_inner | epoch 165:      4 / 64 loss=5.323, ppl=40.02, wps=5931.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.065, train_wall=494, gb_free=6.1, wall=56566
2022-02-01 00:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:38:45 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.389 | ppl 1340.62 | wps 8176.6 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.29
2022-02-01 00:38:45 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-01 00:38:45 | INFO | train | epoch 165 | loss 5.3 | ppl 39.39 | wps 6065.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.058 | train_wall 317 | gb_free 6.1 | wall 56890
KL Stats: Epoch 165 Divergences: Uniform: 3.0696356733587122 Unigram: 4.132712199113341
2022-02-01 00:38:45 | INFO | fairseq.trainer | begin training epoch 166
2022-02-01 00:38:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:42:04 | INFO | train_inner | epoch 166:     40 / 64 loss=5.293, ppl=39.2, wps=6243.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.057, train_wall=495, gb_free=6.1, wall=57089
2022-02-01 00:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:44:29 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.191 | ppl 1168.97 | wps 8155.3 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.29
2022-02-01 00:44:29 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-01 00:44:29 | INFO | train | epoch 166 | loss 5.295 | ppl 39.27 | wps 6067.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.075 | train_wall 317 | gb_free 6.1 | wall 57234
KL Stats: Epoch 166 Divergences: Uniform: 3.0707235288683488 Unigram: 4.136854159265849
2022-02-01 00:44:29 | INFO | fairseq.trainer | begin training epoch 167
2022-02-01 00:44:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:50:14 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.205 | ppl 1180.29 | wps 8174.1 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.29
2022-02-01 00:50:14 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-01 00:50:14 | INFO | train | epoch 167 | loss 5.29 | ppl 39.13 | wps 6060.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.092 | train_wall 317 | gb_free 6.1 | wall 57579
KL Stats: Epoch 167 Divergences: Uniform: 3.0688495478310482 Unigram: 4.136527112892242
2022-02-01 00:50:14 | INFO | fairseq.trainer | begin training epoch 168
2022-02-01 00:50:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:51:14 | INFO | train_inner | epoch 168:     12 / 64 loss=5.292, ppl=39.18, wps=5931.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.097, train_wall=495, gb_free=6.1, wall=57639
2022-02-01 00:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:55:59 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.294 | ppl 1255.7 | wps 8113.3 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.29
2022-02-01 00:55:59 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-01 00:55:59 | INFO | train | epoch 168 | loss 5.284 | ppl 38.96 | wps 6057.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.11 | train_wall 317 | gb_free 6.1 | wall 57924
KL Stats: Epoch 168 Divergences: Uniform: 3.0764219447659538 Unigram: 4.141364380141867
2022-02-01 00:55:59 | INFO | fairseq.trainer | begin training epoch 169
2022-02-01 00:55:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:59:58 | INFO | train_inner | epoch 169:     48 / 64 loss=5.283, ppl=38.94, wps=6230.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.106, train_wall=496, gb_free=6.1, wall=58163
2022-02-01 01:01:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:01:44 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.264 | ppl 1229.46 | wps 8132.2 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.29
2022-02-01 01:01:44 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-01 01:01:44 | INFO | train | epoch 169 | loss 5.278 | ppl 38.8 | wps 6050.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.091 | train_wall 317 | gb_free 6.1 | wall 58269
KL Stats: Epoch 169 Divergences: Uniform: 3.0743679720933206 Unigram: 4.148062016241189
2022-02-01 01:01:44 | INFO | fairseq.trainer | begin training epoch 170
2022-02-01 01:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:07:29 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.318 | ppl 1276.73 | wps 8149.1 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.29
2022-02-01 01:07:29 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-01 01:07:29 | INFO | train | epoch 170 | loss 5.272 | ppl 38.64 | wps 6048.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.13 | train_wall 318 | gb_free 6.1 | wall 58614
KL Stats: Epoch 170 Divergences: Uniform: 3.076272813574346 Unigram: 4.152342232925544
2022-02-01 01:07:29 | INFO | fairseq.trainer | begin training epoch 171
2022-02-01 01:07:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:09:09 | INFO | train_inner | epoch 171:     20 / 64 loss=5.267, ppl=38.51, wps=5921.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.133, train_wall=495, gb_free=6.1, wall=58714
2022-02-01 01:12:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:13:14 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.268 | ppl 1233.32 | wps 8123.5 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.29
2022-02-01 01:13:14 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-01 01:13:14 | INFO | train | epoch 171 | loss 5.268 | ppl 38.52 | wps 6059.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.148 | train_wall 317 | gb_free 6.1 | wall 58959
KL Stats: Epoch 171 Divergences: Uniform: 3.07382952283342 Unigram: 4.158352140104088
2022-02-01 01:13:14 | INFO | fairseq.trainer | begin training epoch 172
2022-02-01 01:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:17:53 | INFO | train_inner | epoch 172:     56 / 64 loss=5.269, ppl=38.56, wps=6232.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.117, train_wall=496, gb_free=6.1, wall=59238
2022-02-01 01:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:18:59 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.295 | ppl 1256.31 | wps 8154.9 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.29
2022-02-01 01:18:59 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-01 01:18:59 | INFO | train | epoch 172 | loss 5.259 | ppl 38.3 | wps 6060.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.111 | train_wall 317 | gb_free 6.1 | wall 59303
KL Stats: Epoch 172 Divergences: Uniform: 3.0753096500291752 Unigram: 4.166689883747262
2022-02-01 01:18:59 | INFO | fairseq.trainer | begin training epoch 173
2022-02-01 01:18:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:24:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:24:43 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.232 | ppl 1202.99 | wps 8167.1 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.29
2022-02-01 01:24:43 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-01 01:24:43 | INFO | train | epoch 173 | loss 5.256 | ppl 38.22 | wps 6059.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.162 | train_wall 317 | gb_free 6.1 | wall 59648
KL Stats: Epoch 173 Divergences: Uniform: 3.07695695849138 Unigram: 4.16835253364607
2022-02-01 01:24:43 | INFO | fairseq.trainer | begin training epoch 174
2022-02-01 01:24:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:27:03 | INFO | train_inner | epoch 174:     28 / 64 loss=5.25, ppl=38.05, wps=5932, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.147, train_wall=495, gb_free=6.1, wall=59788
2022-02-01 01:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:30:27 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.342 | ppl 1297.96 | wps 8162.6 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.29
2022-02-01 01:30:27 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-01 01:30:27 | INFO | train | epoch 174 | loss 5.251 | ppl 38.08 | wps 6072.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.132 | train_wall 316 | gb_free 6.1 | wall 59992
KL Stats: Epoch 174 Divergences: Uniform: 3.0758240920302606 Unigram: 4.178547501511114
2022-02-01 01:30:27 | INFO | fairseq.trainer | begin training epoch 175
2022-02-01 01:30:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:35:45 | INFO | train_inner | epoch 175:     64 / 64 loss=5.254, ppl=38.17, wps=6246.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.139, train_wall=494, gb_free=6.1, wall=60309
2022-02-01 01:35:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:36:11 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.366 | ppl 1319.3 | wps 8180 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.29
2022-02-01 01:36:11 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-01 01:36:11 | INFO | train | epoch 175 | loss 5.244 | ppl 37.89 | wps 6070.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.132 | train_wall 316 | gb_free 6.1 | wall 60336
KL Stats: Epoch 175 Divergences: Uniform: 3.086779721408646 Unigram: 4.180490780977265
2022-02-01 01:36:12 | INFO | fairseq.trainer | begin training epoch 176
2022-02-01 01:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:41:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:41:56 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.31 | ppl 1269.41 | wps 8153.9 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.29
2022-02-01 01:41:56 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-01 01:41:56 | INFO | train | epoch 176 | loss 5.239 | ppl 37.77 | wps 6070.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.157 | train_wall 316 | gb_free 6.1 | wall 60680
KL Stats: Epoch 176 Divergences: Uniform: 3.08545310413684 Unigram: 4.189388365730729
2022-02-01 01:41:56 | INFO | fairseq.trainer | begin training epoch 177
2022-02-01 01:41:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:44:55 | INFO | train_inner | epoch 177:     36 / 64 loss=5.226, ppl=37.44, wps=5940.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.158, train_wall=495, gb_free=6.1, wall=60860
2022-02-01 01:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:47:40 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.29 | ppl 1252.21 | wps 8159.7 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.29
2022-02-01 01:47:40 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-01 01:47:40 | INFO | train | epoch 177 | loss 5.234 | ppl 37.63 | wps 6068 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.181 | train_wall 317 | gb_free 6.1 | wall 61024
KL Stats: Epoch 177 Divergences: Uniform: 3.0804037656246477 Unigram: 4.191443756110289
2022-02-01 01:47:40 | INFO | fairseq.trainer | begin training epoch 178
2022-02-01 01:47:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:53:24 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.292 | ppl 1253.46 | wps 8172.6 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.29
2022-02-01 01:53:24 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-01 01:53:24 | INFO | train | epoch 178 | loss 5.23 | ppl 37.53 | wps 6072.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.169 | train_wall 316 | gb_free 6.1 | wall 61368
KL Stats: Epoch 178 Divergences: Uniform: 3.0918264613382243 Unigram: 4.19606172038458
2022-02-01 01:53:24 | INFO | fairseq.trainer | begin training epoch 179
2022-02-01 01:53:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:54:04 | INFO | train_inner | epoch 179:      8 / 64 loss=5.237, ppl=37.72, wps=5940.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.177, train_wall=494, gb_free=6.1, wall=61408
2022-02-01 01:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:59:08 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.266 | ppl 1231.27 | wps 8166.7 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.29
2022-02-01 01:59:08 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-01 01:59:08 | INFO | train | epoch 179 | loss 5.223 | ppl 37.35 | wps 6070.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.194 | train_wall 316 | gb_free 6.1 | wall 61712
KL Stats: Epoch 179 Divergences: Uniform: 3.0924607379352893 Unigram: 4.201193349392108
2022-02-01 01:59:08 | INFO | fairseq.trainer | begin training epoch 180
2022-02-01 01:59:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:02:47 | INFO | train_inner | epoch 180:     44 / 64 loss=5.219, ppl=37.24, wps=6244.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.191, train_wall=495, gb_free=6.1, wall=61932
2022-02-01 02:04:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:04:52 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.245 | ppl 1213.84 | wps 8175.2 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.29
2022-02-01 02:04:52 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-01 02:04:52 | INFO | train | epoch 180 | loss 5.22 | ppl 37.26 | wps 6064.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.215 | train_wall 317 | gb_free 6.1 | wall 62057
KL Stats: Epoch 180 Divergences: Uniform: 3.087293082642333 Unigram: 4.205507170926503
2022-02-01 02:04:52 | INFO | fairseq.trainer | begin training epoch 181
2022-02-01 02:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:10:37 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.325 | ppl 1283 | wps 8143.6 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.29
2022-02-01 02:10:37 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-01 02:10:37 | INFO | train | epoch 181 | loss 5.213 | ppl 37.1 | wps 6064.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.216 | train_wall 317 | gb_free 6.1 | wall 62401
KL Stats: Epoch 181 Divergences: Uniform: 3.0915367225514907 Unigram: 4.212614743062987
2022-02-01 02:10:37 | INFO | fairseq.trainer | begin training epoch 182
2022-02-01 02:10:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:11:56 | INFO | train_inner | epoch 182:     16 / 64 loss=5.214, ppl=37.12, wps=5932.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.228, train_wall=494, gb_free=6.1, wall=62481
2022-02-01 02:15:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:16:21 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.265 | ppl 1230.47 | wps 8168.9 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.29
2022-02-01 02:16:21 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-01 02:16:21 | INFO | train | epoch 182 | loss 5.208 | ppl 36.98 | wps 6062.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.209 | train_wall 317 | gb_free 6.1 | wall 62746
KL Stats: Epoch 182 Divergences: Uniform: 3.0913826336714623 Unigram: 4.209573042218123
2022-02-01 02:16:21 | INFO | fairseq.trainer | begin training epoch 183
2022-02-01 02:16:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:20:40 | INFO | train_inner | epoch 183:     52 / 64 loss=5.206, ppl=36.92, wps=6236.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.211, train_wall=496, gb_free=6.1, wall=63005
2022-02-01 02:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:22:06 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.33 | ppl 1287.48 | wps 8178.4 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.29
2022-02-01 02:22:06 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-01 02:22:06 | INFO | train | epoch 183 | loss 5.203 | ppl 36.83 | wps 6055.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.213 | train_wall 317 | gb_free 6.1 | wall 63091
KL Stats: Epoch 183 Divergences: Uniform: 3.094593125240463 Unigram: 4.221917499291648
2022-02-01 02:22:06 | INFO | fairseq.trainer | begin training epoch 184
2022-02-01 02:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:27:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:27:50 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.254 | ppl 1220.84 | wps 8184.4 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.29
2022-02-01 02:27:50 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-01 02:27:50 | INFO | train | epoch 184 | loss 5.2 | ppl 36.75 | wps 6064 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.24 | train_wall 317 | gb_free 6.1 | wall 63435
KL Stats: Epoch 184 Divergences: Uniform: 3.0945662885996907 Unigram: 4.222409460844064
2022-02-01 02:27:50 | INFO | fairseq.trainer | begin training epoch 185
2022-02-01 02:27:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:29:50 | INFO | train_inner | epoch 185:     24 / 64 loss=5.2, ppl=36.75, wps=5931.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.239, train_wall=495, gb_free=6.1, wall=63555
2022-02-01 02:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:33:35 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.29 | ppl 1251.86 | wps 8164.3 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.29
2022-02-01 02:33:35 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-01 02:33:35 | INFO | train | epoch 185 | loss 5.195 | ppl 36.63 | wps 6061.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.245 | train_wall 317 | gb_free 6.1 | wall 63780
KL Stats: Epoch 185 Divergences: Uniform: 3.091036509366973 Unigram: 4.227940000643267
2022-02-01 02:33:35 | INFO | fairseq.trainer | begin training epoch 186
2022-02-01 02:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:38:34 | INFO | train_inner | epoch 186:     60 / 64 loss=5.195, ppl=36.62, wps=6236.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.227, train_wall=496, gb_free=6.1, wall=64079
2022-02-01 02:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:39:19 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.201 | ppl 1176.96 | wps 8203.3 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.29
2022-02-01 02:39:19 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-01 02:39:19 | INFO | train | epoch 186 | loss 5.19 | ppl 36.52 | wps 6063.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.217 | train_wall 317 | gb_free 6.1 | wall 64124
KL Stats: Epoch 186 Divergences: Uniform: 3.0946367632480287 Unigram: 4.230184487538818
2022-02-01 02:39:19 | INFO | fairseq.trainer | begin training epoch 187
2022-02-01 02:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:44:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:45:04 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.295 | ppl 1256.65 | wps 8148.4 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.29
2022-02-01 02:45:04 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-01 02:45:04 | INFO | train | epoch 187 | loss 5.184 | ppl 36.36 | wps 6059.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.233 | train_wall 317 | gb_free 6.1 | wall 64469
KL Stats: Epoch 187 Divergences: Uniform: 3.0938049467521087 Unigram: 4.234701700544971
2022-02-01 02:45:04 | INFO | fairseq.trainer | begin training epoch 188
2022-02-01 02:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:47:44 | INFO | train_inner | epoch 188:     32 / 64 loss=5.178, ppl=36.19, wps=5930.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.232, train_wall=495, gb_free=6.1, wall=64628
2022-02-01 02:50:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:50:49 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.287 | ppl 1249.59 | wps 8178.8 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.29
2022-02-01 02:50:49 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-01 02:50:49 | INFO | train | epoch 188 | loss 5.18 | ppl 36.24 | wps 6061.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.267 | train_wall 317 | gb_free 6.1 | wall 64813
KL Stats: Epoch 188 Divergences: Uniform: 3.092809704743752 Unigram: 4.242493715595257
2022-02-01 02:50:49 | INFO | fairseq.trainer | begin training epoch 189
2022-02-01 02:50:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:56:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:56:33 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.312 | ppl 1271.15 | wps 8166.1 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.29
2022-02-01 02:56:33 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-01 02:56:33 | INFO | train | epoch 189 | loss 5.175 | ppl 36.13 | wps 6057.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.283 | train_wall 317 | gb_free 6.1 | wall 65158
KL Stats: Epoch 189 Divergences: Uniform: 3.0961535629885386 Unigram: 4.2497315273462695
2022-02-01 02:56:33 | INFO | fairseq.trainer | begin training epoch 190
2022-02-01 02:56:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:56:54 | INFO | train_inner | epoch 190:      4 / 64 loss=5.182, ppl=36.29, wps=5929.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.288, train_wall=495, gb_free=6.1, wall=65178
2022-02-01 03:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:02:18 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.287 | ppl 1249.1 | wps 8175.3 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.29
2022-02-01 03:02:18 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-01 03:02:18 | INFO | train | epoch 190 | loss 5.169 | ppl 35.98 | wps 6055.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.233 | train_wall 317 | gb_free 6.1 | wall 65503
KL Stats: Epoch 190 Divergences: Uniform: 3.0983491784141055 Unigram: 4.251850199498339
2022-02-01 03:02:18 | INFO | fairseq.trainer | begin training epoch 191
2022-02-01 03:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:05:38 | INFO | train_inner | epoch 191:     40 / 64 loss=5.159, ppl=35.73, wps=6232.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.268, train_wall=496, gb_free=6.1, wall=65703
2022-02-01 03:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:08:03 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.288 | ppl 1250.47 | wps 8177.9 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.29
2022-02-01 03:08:03 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-01 03:08:03 | INFO | train | epoch 191 | loss 5.166 | ppl 35.91 | wps 6057.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.306 | train_wall 317 | gb_free 6.1 | wall 65848
KL Stats: Epoch 191 Divergences: Uniform: 3.0940748690712256 Unigram: 4.253456637005355
2022-02-01 03:08:03 | INFO | fairseq.trainer | begin training epoch 192
2022-02-01 03:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:13:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:13:48 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.299 | ppl 1259.75 | wps 8169.4 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.29
2022-02-01 03:13:48 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-01 03:13:48 | INFO | train | epoch 192 | loss 5.162 | ppl 35.81 | wps 6063.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.296 | train_wall 317 | gb_free 6.1 | wall 66192
KL Stats: Epoch 192 Divergences: Uniform: 3.0947993938202227 Unigram: 4.250821258140256
2022-02-01 03:13:48 | INFO | fairseq.trainer | begin training epoch 193
2022-02-01 03:13:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:14:48 | INFO | train_inner | epoch 193:     12 / 64 loss=5.168, ppl=35.96, wps=5930.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.292, train_wall=495, gb_free=6.1, wall=66252
2022-02-01 03:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:19:32 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.301 | ppl 1261.9 | wps 8158.9 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.29
2022-02-01 03:19:32 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-01 03:19:32 | INFO | train | epoch 193 | loss 5.157 | ppl 35.69 | wps 6059.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.273 | train_wall 317 | gb_free 6.1 | wall 66537
KL Stats: Epoch 193 Divergences: Uniform: 3.1003788430797647 Unigram: 4.259927600847051
2022-02-01 03:19:32 | INFO | fairseq.trainer | begin training epoch 194
2022-02-01 03:19:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:23:32 | INFO | train_inner | epoch 194:     48 / 64 loss=5.153, ppl=35.59, wps=6235, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.291, train_wall=496, gb_free=6.1, wall=66776
2022-02-01 03:24:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:25:17 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.315 | ppl 1273.45 | wps 8168.7 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.29
2022-02-01 03:25:17 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-01 03:25:17 | INFO | train | epoch 194 | loss 5.152 | ppl 35.56 | wps 6060 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.318 | train_wall 317 | gb_free 6.1 | wall 66882
KL Stats: Epoch 194 Divergences: Uniform: 3.0979535202952526 Unigram: 4.2663521347604645
2022-02-01 03:25:17 | INFO | fairseq.trainer | begin training epoch 195
2022-02-01 03:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:30:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:31:02 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.299 | ppl 1259.65 | wps 8180.1 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.29
2022-02-01 03:31:02 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-01 03:31:02 | INFO | train | epoch 195 | loss 5.151 | ppl 35.52 | wps 6059.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.344 | train_wall 317 | gb_free 6.1 | wall 67226
KL Stats: Epoch 195 Divergences: Uniform: 3.098361891320267 Unigram: 4.269793585147849
2022-02-01 03:31:02 | INFO | fairseq.trainer | begin training epoch 196
2022-02-01 03:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:32:42 | INFO | train_inner | epoch 196:     20 / 64 loss=5.147, ppl=35.44, wps=5929.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.328, train_wall=495, gb_free=6.1, wall=67326
2022-02-01 03:36:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:36:47 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.248 | ppl 1215.66 | wps 8106.8 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.29
2022-02-01 03:36:47 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-01 03:36:47 | INFO | train | epoch 196 | loss 5.145 | ppl 35.38 | wps 6053.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.326 | train_wall 317 | gb_free 6.1 | wall 67571
KL Stats: Epoch 196 Divergences: Uniform: 3.098819283554409 Unigram: 4.271692922154481
2022-02-01 03:36:47 | INFO | fairseq.trainer | begin training epoch 197
2022-02-01 03:36:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:41:26 | INFO | train_inner | epoch 197:     56 / 64 loss=5.146, ppl=35.4, wps=6228, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.348, train_wall=496, gb_free=6.1, wall=67851
2022-02-01 03:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:42:32 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.281 | ppl 1244.51 | wps 8193.3 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.29
2022-02-01 03:42:32 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-01 03:42:32 | INFO | train | epoch 197 | loss 5.141 | ppl 35.28 | wps 6057.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.349 | train_wall 317 | gb_free 6.1 | wall 67916
KL Stats: Epoch 197 Divergences: Uniform: 3.098889325705307 Unigram: 4.275688122708269
2022-02-01 03:42:32 | INFO | fairseq.trainer | begin training epoch 198
2022-02-01 03:42:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:47:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:48:17 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.304 | ppl 1264.34 | wps 8156.4 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.29
2022-02-01 03:48:17 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-01 03:48:17 | INFO | train | epoch 198 | loss 5.134 | ppl 35.11 | wps 6053.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.344 | train_wall 317 | gb_free 6.1 | wall 68261
KL Stats: Epoch 198 Divergences: Uniform: 3.1030448544464586 Unigram: 4.280950893574802
2022-02-01 03:48:17 | INFO | fairseq.trainer | begin training epoch 199
2022-02-01 03:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:50:36 | INFO | train_inner | epoch 199:     28 / 64 loss=5.129, ppl=35, wps=5926.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.349, train_wall=495, gb_free=6.1, wall=68401
2022-02-01 03:53:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:54:01 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.292 | ppl 1253.39 | wps 8174.2 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.29
2022-02-01 03:54:01 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-01 03:54:01 | INFO | train | epoch 199 | loss 5.132 | ppl 35.07 | wps 6056.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.359 | train_wall 317 | gb_free 6.1 | wall 68606
KL Stats: Epoch 199 Divergences: Uniform: 3.1042581933686537 Unigram: 4.289522006148716
2022-02-01 03:54:01 | INFO | fairseq.trainer | begin training epoch 200
2022-02-01 03:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:59:19 | INFO | train_inner | epoch 200:     64 / 64 loss=5.139, ppl=35.25, wps=6231.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.373, train_wall=495, gb_free=6.1, wall=68924
2022-02-01 03:59:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:59:46 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.31 | ppl 1269.58 | wps 8175 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.29
2022-02-01 03:59:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-01 03:59:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint200.pt
2022-02-01 03:59:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint200.pt
2022-02-01 03:59:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.31) (writing took 3.3450746964663267 seconds)
2022-02-01 03:59:50 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-01 03:59:50 | INFO | train | epoch 200 | loss 5.127 | ppl 34.94 | wps 6000 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.379 | train_wall 317 | gb_free 6.1 | wall 68954
KL Stats: Epoch 200 Divergences: Uniform: 3.1040061602738502 Unigram: 4.2921871000324625
2022-02-01 03:59:50 | INFO | fairseq.trainer | begin training epoch 201
2022-02-01 03:59:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:05:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:05:34 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.313 | ppl 1272.44 | wps 8172.2 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.29
2022-02-01 04:05:34 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-01 04:05:34 | INFO | train | epoch 201 | loss 5.124 | ppl 34.86 | wps 6063.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.352 | train_wall 317 | gb_free 6.1 | wall 69299
KL Stats: Epoch 201 Divergences: Uniform: 3.101620626724724 Unigram: 4.288970773716371
2022-02-01 04:05:34 | INFO | fairseq.trainer | begin training epoch 202
2022-02-01 04:05:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:08:34 | INFO | train_inner | epoch 202:     36 / 64 loss=5.11, ppl=34.54, wps=5897.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.372, train_wall=496, gb_free=6.1, wall=69478
2022-02-01 04:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:11:19 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.274 | ppl 1238.31 | wps 8148 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.29
2022-02-01 04:11:19 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-01 04:11:19 | INFO | train | epoch 202 | loss 5.12 | ppl 34.76 | wps 6058.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.402 | train_wall 317 | gb_free 6.1 | wall 69643
KL Stats: Epoch 202 Divergences: Uniform: 3.1020919952824335 Unigram: 4.2968964796832445
2022-02-01 04:11:19 | INFO | fairseq.trainer | begin training epoch 203
2022-02-01 04:11:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:17:04 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.307 | ppl 1266.52 | wps 8193.9 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.29
2022-02-01 04:17:04 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-01 04:17:04 | INFO | train | epoch 203 | loss 5.114 | ppl 34.64 | wps 6053.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.397 | train_wall 317 | gb_free 6.1 | wall 69988
KL Stats: Epoch 203 Divergences: Uniform: 3.0984851214497344 Unigram: 4.300568405596669
2022-02-01 04:17:04 | INFO | fairseq.trainer | begin training epoch 204
2022-02-01 04:17:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:17:44 | INFO | train_inner | epoch 204:      8 / 64 loss=5.123, ppl=34.86, wps=5926, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.396, train_wall=495, gb_free=6.1, wall=70028
2022-02-01 04:22:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:22:48 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.329 | ppl 1286.52 | wps 8145.7 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.29
2022-02-01 04:22:48 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-01 04:22:48 | INFO | train | epoch 204 | loss 5.11 | ppl 34.54 | wps 6066.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.43 | train_wall 317 | gb_free 6.1 | wall 70333
KL Stats: Epoch 204 Divergences: Uniform: 3.107564652278272 Unigram: 4.305003483666878
2022-02-01 04:22:48 | INFO | fairseq.trainer | begin training epoch 205
2022-02-01 04:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:26:28 | INFO | train_inner | epoch 205:     44 / 64 loss=5.105, ppl=34.42, wps=6236.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.42, train_wall=496, gb_free=6.1, wall=70552
2022-02-01 04:28:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:28:33 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.307 | ppl 1266.46 | wps 8186.7 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.29
2022-02-01 04:28:33 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-01 04:28:33 | INFO | train | epoch 205 | loss 5.106 | ppl 34.43 | wps 6055 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.398 | train_wall 317 | gb_free 6.1 | wall 70678
KL Stats: Epoch 205 Divergences: Uniform: 3.103387533692429 Unigram: 4.30764055125088
2022-02-01 04:28:33 | INFO | fairseq.trainer | begin training epoch 206
2022-02-01 04:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:34:18 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.338 | ppl 1294.76 | wps 8129.8 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.29
2022-02-01 04:34:18 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-01 04:34:18 | INFO | train | epoch 206 | loss 5.104 | ppl 34.38 | wps 6048.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.415 | train_wall 318 | gb_free 6.1 | wall 71023
KL Stats: Epoch 206 Divergences: Uniform: 3.1042884527393517 Unigram: 4.31436337252167
2022-02-01 04:34:18 | INFO | fairseq.trainer | begin training epoch 207
2022-02-01 04:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:35:38 | INFO | train_inner | epoch 207:     16 / 64 loss=5.104, ppl=34.4, wps=5921.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.405, train_wall=496, gb_free=6.1, wall=71103
2022-02-01 04:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:40:04 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.316 | ppl 1274.35 | wps 8121 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.29
2022-02-01 04:40:04 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-02-01 04:40:04 | INFO | train | epoch 207 | loss 5.1 | ppl 34.3 | wps 6047.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.447 | train_wall 318 | gb_free 6.1 | wall 71368
KL Stats: Epoch 207 Divergences: Uniform: 3.108362030041149 Unigram: 4.317138901933585
2022-02-01 04:40:04 | INFO | fairseq.trainer | begin training epoch 208
2022-02-01 04:40:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:44:23 | INFO | train_inner | epoch 208:     52 / 64 loss=5.097, ppl=34.22, wps=6224.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.444, train_wall=497, gb_free=6.1, wall=71628
2022-02-01 04:45:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:45:49 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 10.356 | ppl 1310.39 | wps 8177.8 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.29
2022-02-01 04:45:49 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-02-01 04:45:49 | INFO | train | epoch 208 | loss 5.094 | ppl 34.16 | wps 6054 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.437 | train_wall 317 | gb_free 6.1 | wall 71713
KL Stats: Epoch 208 Divergences: Uniform: 3.1096772310525322 Unigram: 4.3228445427713
2022-02-01 04:45:49 | INFO | fairseq.trainer | begin training epoch 209
2022-02-01 04:45:49 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
Sender: LSF System <lsfadmin@eu-g3-022>
Subject: Job 202993538: <w2_jelinek_0.1_0.0_0.9_#2> in cluster <euler> Exited

Job <w2_jelinek_0.1_0.0_0.9_#2> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:06:53 2022
Job was executed on host(s) <eu-g3-022>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:07:02 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:07:02 2022
Terminated at Thu Feb  3 02:07:20 2022
Results reported at Thu Feb  3 02:07:20 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.1, 0.0, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 2002 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   71962.20 sec.
    Max Memory :                                 5964 MB
    Average Memory :                             3072.36 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14036.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72017 sec.
    Turnaround time :                            72027 sec.

The output (if any) follows:

2022-02-02 06:07:11 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2002, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 2002, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.1, 0.0, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:07:12 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:07:13 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  3%|▎         | 1154/36718 [00:00<00:03, 11532.89it/s]  6%|▋         | 2308/36718 [00:00<00:03, 10734.40it/s] 10%|▉         | 3593/36718 [00:00<00:02, 11657.37it/s] 13%|█▎        | 4929/36718 [00:00<00:02, 12298.00it/s] 17%|█▋        | 6229/36718 [00:00<00:02, 12540.54it/s] 20%|██        | 7487/36718 [00:00<00:02, 12018.41it/s] 24%|██▎       | 8695/36718 [00:00<00:02, 11671.93it/s] 27%|██▋       | 9940/36718 [00:00<00:02, 11905.08it/s] 30%|███       | 11135/36718 [00:00<00:02, 11769.26it/s] 34%|███▎      | 12315/36718 [00:01<00:02, 11720.62it/s] 37%|███▋      | 13590/36718 [00:01<00:01, 12027.48it/s] 40%|████      | 14795/36718 [00:01<00:01, 11979.55it/s] 44%|████▎     | 15995/36718 [00:01<00:01, 11764.33it/s] 47%|████▋     | 17178/36718 [00:01<00:01, 11783.52it/s] 50%|████▉     | 18358/36718 [00:01<00:01, 11753.67it/s] 54%|█████▎    | 19709/36718 [00:01<00:01, 12269.98it/s] 57%|█████▋    | 20938/36718 [00:01<00:01, 11976.02it/s] 60%|██████    | 22138/36718 [00:01<00:01, 11656.71it/s] 64%|██████▍   | 23431/36718 [00:01<00:01, 12023.56it/s] 68%|██████▊   | 24874/36718 [00:02<00:00, 12725.03it/s] 71%|███████   | 26151/36718 [00:02<00:00, 12496.82it/s] 75%|███████▍  | 27405/36718 [00:02<00:00, 11813.12it/s] 78%|███████▊  | 28706/36718 [00:02<00:00, 12147.33it/s] 82%|████████▏ | 29929/36718 [00:02<00:00, 11965.01it/s] 85%|████████▍ | 31132/36718 [00:02<00:00, 11426.92it/s] 88%|████████▊ | 32283/36718 [00:02<00:00, 11365.95it/s] 91%|█████████ | 33425/36718 [00:02<00:00, 11342.62it/s] 94%|█████████▍| 34695/36718 [00:02<00:00, 11731.62it/s] 98%|█████████▊| 35873/36718 [00:03<00:00, 11565.90it/s]100%|██████████| 36718/36718 [00:03<00:00, 11852.03it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  6%|▌         | 2042/36718 [00:00<00:01, 20408.24it/s] 12%|█▏        | 4516/36718 [00:00<00:01, 22944.65it/s] 19%|█▊        | 6863/36718 [00:00<00:01, 23183.64it/s] 25%|██▌       | 9182/36718 [00:00<00:01, 23059.05it/s] 31%|███▏      | 11489/36718 [00:00<00:01, 23044.97it/s] 38%|███▊      | 13850/36718 [00:00<00:00, 23235.60it/s] 44%|████▍     | 16174/36718 [00:00<00:00, 22973.86it/s] 50%|█████     | 18473/36718 [00:00<00:00, 22969.04it/s] 57%|█████▋    | 20931/36718 [00:00<00:00, 23464.13it/s] 63%|██████▎   | 23278/36718 [00:01<00:00, 23408.00it/s] 71%|███████   | 25903/36718 [00:01<00:00, 24268.66it/s] 77%|███████▋  | 28331/36718 [00:01<00:00, 23561.39it/s] 84%|████████▎ | 30692/36718 [00:01<00:00, 23240.26it/s] 90%|████████▉ | 33020/36718 [00:01<00:00, 22829.86it/s] 96%|█████████▋| 35363/36718 [00:01<00:00, 23004.97it/s]100%|██████████| 36718/36718 [00:01<00:00, 23141.17it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 83.06it/s]2022-02-02 06:07:26 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:07:26 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:07:26 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:07:26 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:07:26 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:07:26 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:07:26 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:07:26 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:07:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:07:26 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-02-02 06:07:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:07:26 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:07:26 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:07:26 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint_last.pt
2022-02-02 06:07:26 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint_last.pt
2022-02-02 06:07:26 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:07:26 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:07:26 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:07:26 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:07:26 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:12:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:13:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.633 | ppl 25402.1 | wps 8263.6 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:13:11 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:13:11 | INFO | train | epoch 001 | loss 15.988 | ppl 64982.4 | wps 6101.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.097 | train_wall 315 | gb_free 6.1 | wall 345
KL Stats: Epoch 1 Divergences: Uniform: 0.5245409625612573 Unigram: 3.58323873607942
2022-02-02 06:13:11 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:16:10 | INFO | train_inner | epoch 002:     36 / 64 loss=15.466, ppl=45256.3, wps=6276.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.557, train_wall=492, gb_free=6.1, wall=524
2022-02-02 06:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:18:54 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.584 | ppl 12278.8 | wps 8281.5 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:18:54 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:18:54 | INFO | train | epoch 002 | loss 14.323 | ppl 20491.1 | wps 6097.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.487 | train_wall 315 | gb_free 6.1 | wall 688
KL Stats: Epoch 2 Divergences: Uniform: 0.5326479465973096 Unigram: 2.337533271212182
2022-02-02 06:18:54 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:18:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:24:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:24:36 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.784 | ppl 7054.23 | wps 8265.5 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:24:36 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:24:36 | INFO | train | epoch 003 | loss 13.422 | ppl 10978.4 | wps 6098.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.186 | train_wall 314 | gb_free 6.1 | wall 1030
KL Stats: Epoch 3 Divergences: Uniform: 0.5203934234880735 Unigram: 1.6550042171029584
2022-02-02 06:24:36 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:24:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:25:16 | INFO | train_inner | epoch 004:      8 / 64 loss=13.553, ppl=12015.1, wps=5967.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.222, train_wall=491, gb_free=6.1, wall=1070
2022-02-02 06:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:30:19 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.996 | ppl 4083.88 | wps 8243.7 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:30:19 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:30:19 | INFO | train | epoch 004 | loss 12.515 | ppl 5852.69 | wps 6095.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.913 | train_wall 315 | gb_free 6.1 | wall 1373
KL Stats: Epoch 4 Divergences: Uniform: 0.6095922498559084 Unigram: 1.0450958055334518
2022-02-02 06:30:19 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:30:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:33:57 | INFO | train_inner | epoch 005:     44 / 64 loss=12.187, ppl=4664.19, wps=6275, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.807, train_wall=492, gb_free=6.1, wall=1591
2022-02-02 06:35:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:36:01 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.503 | ppl 2901.52 | wps 8263.5 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:36:01 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:36:01 | INFO | train | epoch 005 | loss 11.763 | ppl 3476.37 | wps 6104.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.664 | train_wall 314 | gb_free 6.1 | wall 1715
KL Stats: Epoch 5 Divergences: Uniform: 0.8525872959119185 Unigram: 0.6006268674645803
2022-02-02 06:36:01 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:36:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:41:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:41:43 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.256 | ppl 2446.31 | wps 8262.9 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:41:43 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:41:43 | INFO | train | epoch 006 | loss 11.354 | ppl 2617.01 | wps 6106 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.599 | train_wall 314 | gb_free 6.1 | wall 2057
KL Stats: Epoch 6 Divergences: Uniform: 1.1449667736524167 Unigram: 0.42182785497471537
2022-02-02 06:41:43 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:41:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:43:03 | INFO | train_inner | epoch 007:     16 / 64 loss=11.374, ppl=2654.26, wps=5974.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.604, train_wall=490, gb_free=6.1, wall=2137
2022-02-02 06:47:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:47:26 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.148 | ppl 2268.87 | wps 8287.9 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:47:26 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:47:26 | INFO | train | epoch 007 | loss 11.152 | ppl 2275.7 | wps 6093.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.539 | train_wall 315 | gb_free 6.1 | wall 2400
KL Stats: Epoch 7 Divergences: Uniform: 1.3665982048298801 Unigram: 0.4606969968985834
2022-02-02 06:47:26 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:47:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:51:45 | INFO | train_inner | epoch 008:     52 / 64 loss=11.09, ppl=2179.14, wps=6259.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.496, train_wall=493, gb_free=6.1, wall=2659
2022-02-02 06:52:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:53:10 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.038 | ppl 2102.69 | wps 8246.3 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:53:10 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:53:10 | INFO | train | epoch 008 | loss 11.036 | ppl 2099.09 | wps 6078.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.487 | train_wall 316 | gb_free 6.1 | wall 2744
KL Stats: Epoch 8 Divergences: Uniform: 1.4798720016830824 Unigram: 0.5444815517847558
2022-02-02 06:53:10 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:53:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:58:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:58:52 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.927 | ppl 1947.6 | wps 8300.2 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 06:58:52 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 06:58:52 | INFO | train | epoch 009 | loss 10.932 | ppl 1953.58 | wps 6102.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.507 | train_wall 314 | gb_free 6.1 | wall 3086
KL Stats: Epoch 9 Divergences: Uniform: 1.5272703975558122 Unigram: 0.6494264087304505
2022-02-02 06:58:52 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 06:58:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:00:51 | INFO | train_inner | epoch 010:     24 / 64 loss=10.918, ppl=1935.31, wps=5969.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.502, train_wall=491, gb_free=6.1, wall=3205
2022-02-02 07:04:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:04:34 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.792 | ppl 1773.27 | wps 8237.1 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:04:34 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:04:34 | INFO | train | epoch 010 | loss 10.822 | ppl 1810.16 | wps 6101.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.5 | train_wall 314 | gb_free 6.1 | wall 3428
KL Stats: Epoch 10 Divergences: Uniform: 1.55133536742414 Unigram: 0.7595373169348285
2022-02-02 07:04:34 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:04:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:09:32 | INFO | train_inner | epoch 011:     60 / 64 loss=10.749, ppl=1720.78, wps=6276.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.489, train_wall=492, gb_free=6.1, wall=3725
2022-02-02 07:09:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:10:16 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.691 | ppl 1653.42 | wps 8293.4 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:10:16 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:10:16 | INFO | train | epoch 011 | loss 10.707 | ppl 1671.42 | wps 6102.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.482 | train_wall 314 | gb_free 6.1 | wall 3770
KL Stats: Epoch 11 Divergences: Uniform: 1.5621338953614181 Unigram: 0.8783227711109072
2022-02-02 07:10:16 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:10:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:15:59 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.586 | ppl 1537.48 | wps 8292.1 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:15:59 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:15:59 | INFO | train | epoch 012 | loss 10.59 | ppl 1541.13 | wps 6097.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.493 | train_wall 315 | gb_free 6.1 | wall 4113
KL Stats: Epoch 12 Divergences: Uniform: 1.5818456976984112 Unigram: 0.9845019863067708
2022-02-02 07:15:59 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:15:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:18:37 | INFO | train_inner | epoch 013:     32 / 64 loss=10.56, ppl=1510, wps=5972.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.5, train_wall=491, gb_free=6.1, wall=4271
2022-02-02 07:21:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:21:41 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.492 | ppl 1439.93 | wps 8286.7 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:21:41 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:21:41 | INFO | train | epoch 013 | loss 10.475 | ppl 1423.16 | wps 6109.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.542 | train_wall 314 | gb_free 6.1 | wall 4455
KL Stats: Epoch 13 Divergences: Uniform: 1.6105368219372225 Unigram: 1.0783627816321741
2022-02-02 07:21:41 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:21:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:27:24 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.398 | ppl 1349.15 | wps 8295.1 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:27:24 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:27:24 | INFO | train | epoch 014 | loss 10.361 | ppl 1314.74 | wps 6091.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.517 | train_wall 315 | gb_free 6.1 | wall 4798
KL Stats: Epoch 14 Divergences: Uniform: 1.6242960283505457 Unigram: 1.1678906298191665
2022-02-02 07:27:24 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:27:44 | INFO | train_inner | epoch 015:      4 / 64 loss=10.39, ppl=1341.54, wps=5967.3, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.535, train_wall=491, gb_free=6.1, wall=4818
2022-02-02 07:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:33:06 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.314 | ppl 1273.07 | wps 8304.1 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:33:06 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:33:06 | INFO | train | epoch 015 | loss 10.249 | ppl 1217.16 | wps 6107.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.51 | train_wall 314 | gb_free 6.1 | wall 5140
KL Stats: Epoch 15 Divergences: Uniform: 1.6587707165660088 Unigram: 1.246075221341925
2022-02-02 07:33:06 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:33:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:36:24 | INFO | train_inner | epoch 016:     40 / 64 loss=10.207, ppl=1182.3, wps=6280.8, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.509, train_wall=492, gb_free=6.1, wall=5338
2022-02-02 07:38:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:38:48 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.237 | ppl 1207.08 | wps 8313.8 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:38:48 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:38:48 | INFO | train | epoch 016 | loss 10.138 | ppl 1127.09 | wps 6101.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.506 | train_wall 314 | gb_free 6.1 | wall 5482
KL Stats: Epoch 16 Divergences: Uniform: 1.6861799383396263 Unigram: 1.3241745374809093
2022-02-02 07:38:48 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:38:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:44:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:44:31 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.151 | ppl 1137.13 | wps 8270.8 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:44:31 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:44:31 | INFO | train | epoch 017 | loss 10.029 | ppl 1045.13 | wps 6098.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.522 | train_wall 314 | gb_free 6.1 | wall 5824
KL Stats: Epoch 17 Divergences: Uniform: 1.7147157176356818 Unigram: 1.3932404905438582
2022-02-02 07:44:31 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:44:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:45:30 | INFO | train_inner | epoch 018:     12 / 64 loss=10.04, ppl=1052.53, wps=5971, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.514, train_wall=491, gb_free=6.1, wall=5884
2022-02-02 07:49:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:50:12 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.076 | ppl 1079.09 | wps 8273.1 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 07:50:12 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 07:50:12 | INFO | train | epoch 018 | loss 9.923 | ppl 970.77 | wps 6114.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.521 | train_wall 314 | gb_free 6.1 | wall 6166
KL Stats: Epoch 18 Divergences: Uniform: 1.750069432770788 Unigram: 1.4638917256713813
2022-02-02 07:50:12 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 07:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:54:10 | INFO | train_inner | epoch 019:     48 / 64 loss=9.876, ppl=939.37, wps=6286.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.549, train_wall=491, gb_free=6.1, wall=6404
2022-02-02 07:55:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:55:54 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.004 | ppl 1026.71 | wps 8257.7 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 07:55:54 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 07:55:54 | INFO | train | epoch 019 | loss 9.822 | ppl 905.24 | wps 6101.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.556 | train_wall 314 | gb_free 6.1 | wall 6508
KL Stats: Epoch 19 Divergences: Uniform: 1.7805860514012222 Unigram: 1.5330454782544376
2022-02-02 07:55:54 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 07:55:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:01:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:01:36 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.939 | ppl 981.46 | wps 8298.5 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 08:01:36 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 08:01:36 | INFO | train | epoch 020 | loss 9.724 | ppl 845.43 | wps 6108.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.529 | train_wall 314 | gb_free 6.1 | wall 6850
KL Stats: Epoch 20 Divergences: Uniform: 1.8092580089238925 Unigram: 1.5960787227298756
2022-02-02 08:01:36 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 08:01:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:03:16 | INFO | train_inner | epoch 021:     20 / 64 loss=9.719, ppl=842.54, wps=5973, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.52, train_wall=491, gb_free=6.1, wall=6950
2022-02-02 08:06:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:07:19 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.872 | ppl 936.89 | wps 8272 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:07:19 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:07:19 | INFO | train | epoch 021 | loss 9.631 | ppl 793.08 | wps 6103.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.522 | train_wall 314 | gb_free 6.1 | wall 7192
KL Stats: Epoch 21 Divergences: Uniform: 1.8357964818127357 Unigram: 1.6543166604615613
2022-02-02 08:07:19 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:11:56 | INFO | train_inner | epoch 022:     56 / 64 loss=9.586, ppl=768.35, wps=6277.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.528, train_wall=492, gb_free=6.1, wall=7470
2022-02-02 08:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:13:01 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.831 | ppl 911.03 | wps 8292.4 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:13:01 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:13:01 | INFO | train | epoch 022 | loss 9.544 | ppl 746.67 | wps 6099.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.532 | train_wall 314 | gb_free 6.1 | wall 7535
KL Stats: Epoch 22 Divergences: Uniform: 1.8639488481596953 Unigram: 1.7096292751395221
2022-02-02 08:13:01 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:13:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:18:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:18:43 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.77 | ppl 873.05 | wps 8304.9 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:18:43 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:18:43 | INFO | train | epoch 023 | loss 9.458 | ppl 703.35 | wps 6100.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.554 | train_wall 314 | gb_free 6.1 | wall 7877
KL Stats: Epoch 23 Divergences: Uniform: 1.8858844410616507 Unigram: 1.7606200217354102
2022-02-02 08:18:43 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:18:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:21:02 | INFO | train_inner | epoch 024:     28 / 64 loss=9.437, ppl=692.97, wps=5973.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.543, train_wall=491, gb_free=6.1, wall=8016
2022-02-02 08:23:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:24:25 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.719 | ppl 842.56 | wps 8287.1 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:24:25 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:24:25 | INFO | train | epoch 024 | loss 9.375 | ppl 663.83 | wps 6109.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.53 | train_wall 314 | gb_free 6.1 | wall 8219
KL Stats: Epoch 24 Divergences: Uniform: 1.9172752432647515 Unigram: 1.8078709650822762
2022-02-02 08:24:25 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:24:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:29:41 | INFO | train_inner | epoch 025:     64 / 64 loss=9.324, ppl=640.88, wps=6278.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.551, train_wall=490, gb_free=6.1, wall=8535
2022-02-02 08:29:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:30:08 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.682 | ppl 821.71 | wps 8273.7 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:30:08 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:30:08 | INFO | train | epoch 025 | loss 9.294 | ppl 627.87 | wps 6100.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.556 | train_wall 314 | gb_free 6.1 | wall 8561
KL Stats: Epoch 25 Divergences: Uniform: 1.941439153986193 Unigram: 1.8528557107335348
2022-02-02 08:30:08 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:35:51 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.63 | ppl 792.11 | wps 8238.3 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:35:51 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:35:51 | INFO | train | epoch 026 | loss 9.213 | ppl 593.39 | wps 6082.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.534 | train_wall 315 | gb_free 6.1 | wall 8905
KL Stats: Epoch 26 Divergences: Uniform: 1.9649640195273421 Unigram: 1.8958474377023873
2022-02-02 08:35:51 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:38:49 | INFO | train_inner | epoch 027:     36 / 64 loss=9.185, ppl=582.06, wps=5961.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.535, train_wall=493, gb_free=6.1, wall=9083
2022-02-02 08:41:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:41:33 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.585 | ppl 768.18 | wps 8275.3 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:41:33 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:41:33 | INFO | train | epoch 027 | loss 9.134 | ppl 561.69 | wps 6106 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.532 | train_wall 314 | gb_free 6.1 | wall 9247
KL Stats: Epoch 27 Divergences: Uniform: 1.9798913457051839 Unigram: 1.938825376923752
2022-02-02 08:41:33 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:41:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:47:14 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.559 | ppl 754.07 | wps 8295 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 08:47:14 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 08:47:14 | INFO | train | epoch 028 | loss 9.054 | ppl 531.67 | wps 6123.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.519 | train_wall 313 | gb_free 6.1 | wall 9588
KL Stats: Epoch 28 Divergences: Uniform: 2.0093033029088114 Unigram: 1.9773189082867402
2022-02-02 08:47:14 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 08:47:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:47:54 | INFO | train_inner | epoch 029:      8 / 64 loss=9.067, ppl=536.36, wps=5988.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.525, train_wall=489, gb_free=6.1, wall=9628
2022-02-02 08:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:52:57 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.529 | ppl 738.53 | wps 8286.9 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 08:52:57 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 08:52:57 | INFO | train | epoch 029 | loss 8.977 | ppl 504.03 | wps 6098.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.538 | train_wall 315 | gb_free 6.1 | wall 9930
KL Stats: Epoch 29 Divergences: Uniform: 2.0335104203044283 Unigram: 2.015590994610979
2022-02-02 08:52:57 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 08:52:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:56:34 | INFO | train_inner | epoch 030:     44 / 64 loss=8.945, ppl=492.92, wps=6278, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.523, train_wall=492, gb_free=6.1, wall=10148
2022-02-02 08:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:58:39 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.488 | ppl 717.96 | wps 8250.5 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 08:58:39 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 08:58:39 | INFO | train | epoch 030 | loss 8.902 | ppl 478.42 | wps 6092.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.522 | train_wall 315 | gb_free 6.1 | wall 10273
KL Stats: Epoch 30 Divergences: Uniform: 2.0549655671760974 Unigram: 2.050306474797418
2022-02-02 08:58:39 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 08:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:03:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:04:21 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.457 | ppl 703.01 | wps 8294.9 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 09:04:21 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 09:04:21 | INFO | train | epoch 031 | loss 8.824 | ppl 453.33 | wps 6114.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.515 | train_wall 314 | gb_free 6.1 | wall 10615
KL Stats: Epoch 31 Divergences: Uniform: 2.0796942397641227 Unigram: 2.0925505349649836
2022-02-02 09:04:21 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 09:04:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:05:40 | INFO | train_inner | epoch 032:     16 / 64 loss=8.83, ppl=455, wps=5974, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.527, train_wall=490, gb_free=6.1, wall=10694
2022-02-02 09:09:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:10:02 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.442 | ppl 695.55 | wps 8269.4 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:10:02 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:10:02 | INFO | train | epoch 032 | loss 8.75 | ppl 430.44 | wps 6115.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.513 | train_wall 314 | gb_free 6.1 | wall 10956
KL Stats: Epoch 32 Divergences: Uniform: 2.098869830092165 Unigram: 2.1307663535521497
2022-02-02 09:10:02 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:14:20 | INFO | train_inner | epoch 033:     52 / 64 loss=8.712, ppl=419.35, wps=6284.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.509, train_wall=491, gb_free=6.1, wall=11214
2022-02-02 09:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:15:44 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.406 | ppl 678.6 | wps 8279.1 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:15:44 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:15:44 | INFO | train | epoch 033 | loss 8.678 | ppl 409.44 | wps 6107.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.517 | train_wall 314 | gb_free 6.1 | wall 11298
KL Stats: Epoch 33 Divergences: Uniform: 2.1239443089874173 Unigram: 2.167099693114632
2022-02-02 09:15:44 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:21:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:21:26 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.395 | ppl 673.43 | wps 8265.4 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:21:26 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:21:26 | INFO | train | epoch 034 | loss 8.603 | ppl 388.84 | wps 6109.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.518 | train_wall 314 | gb_free 6.1 | wall 11640
KL Stats: Epoch 34 Divergences: Uniform: 2.150046160630634 Unigram: 2.203356504017017
2022-02-02 09:21:26 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:21:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:23:26 | INFO | train_inner | epoch 035:     24 / 64 loss=8.592, ppl=385.84, wps=5974.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.516, train_wall=490, gb_free=6.1, wall=11760
2022-02-02 09:26:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:27:08 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.365 | ppl 659.44 | wps 8291.7 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:27:08 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:27:08 | INFO | train | epoch 035 | loss 8.531 | ppl 369.85 | wps 6106.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.502 | train_wall 314 | gb_free 6.1 | wall 11982
KL Stats: Epoch 35 Divergences: Uniform: 2.1654475244267273 Unigram: 2.236917610545186
2022-02-02 09:27:08 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:32:05 | INFO | train_inner | epoch 036:     60 / 64 loss=8.491, ppl=359.75, wps=6293.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.501, train_wall=490, gb_free=6.1, wall=12279
2022-02-02 09:32:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:32:50 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.335 | ppl 645.95 | wps 8323.9 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:32:50 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:32:50 | INFO | train | epoch 036 | loss 8.461 | ppl 352.38 | wps 6120.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.502 | train_wall 313 | gb_free 6.1 | wall 12324
KL Stats: Epoch 36 Divergences: Uniform: 2.1820838397415914 Unigram: 2.2726465420780104
2022-02-02 09:32:50 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:32:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:38:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:38:32 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.347 | ppl 651.34 | wps 8265.8 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:38:32 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:38:32 | INFO | train | epoch 037 | loss 8.391 | ppl 335.71 | wps 6105.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.5 | train_wall 314 | gb_free 6.1 | wall 12666
KL Stats: Epoch 37 Divergences: Uniform: 2.2074132185748456 Unigram: 2.3066190538859295
2022-02-02 09:38:32 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:38:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:41:10 | INFO | train_inner | epoch 038:     32 / 64 loss=8.363, ppl=329.18, wps=5982.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.503, train_wall=490, gb_free=6.1, wall=12824
2022-02-02 09:43:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:44:13 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.314 | ppl 636.57 | wps 8283.1 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 09:44:13 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 09:44:13 | INFO | train | epoch 038 | loss 8.323 | ppl 320.19 | wps 6119.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.503 | train_wall 313 | gb_free 6.1 | wall 13007
KL Stats: Epoch 38 Divergences: Uniform: 2.2262659756490724 Unigram: 2.3402713084824076
2022-02-02 09:44:13 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 09:44:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:49:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:49:55 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.303 | ppl 631.85 | wps 8267.7 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 09:49:55 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 09:49:55 | INFO | train | epoch 039 | loss 8.256 | ppl 305.73 | wps 6108.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.505 | train_wall 314 | gb_free 6.1 | wall 13349
KL Stats: Epoch 39 Divergences: Uniform: 2.25040633076305 Unigram: 2.36804443711553
2022-02-02 09:49:55 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 09:49:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:50:15 | INFO | train_inner | epoch 040:      4 / 64 loss=8.285, ppl=311.88, wps=5982, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.502, train_wall=490, gb_free=6.1, wall=13369
2022-02-02 09:55:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:55:37 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.263 | ppl 614.47 | wps 8294.4 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 09:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 09:55:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint40.pt
2022-02-02 09:55:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint40.pt
2022-02-02 09:55:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.263) (writing took 4.540268170647323 seconds)
2022-02-02 09:55:42 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 09:55:42 | INFO | train | epoch 040 | loss 8.189 | ppl 291.81 | wps 6019.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.501 | train_wall 314 | gb_free 6.1 | wall 13696
KL Stats: Epoch 40 Divergences: Uniform: 2.2645464574184833 Unigram: 2.3990367005996265
2022-02-02 09:55:42 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 09:55:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:59:00 | INFO | train_inner | epoch 041:     40 / 64 loss=8.158, ppl=285.53, wps=6223.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.503, train_wall=492, gb_free=6.1, wall=13894
2022-02-02 10:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:01:24 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.279 | ppl 621.1 | wps 8283.4 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.263
2022-02-02 10:01:24 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 10:01:24 | INFO | train | epoch 041 | loss 8.125 | ppl 279.14 | wps 6109.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.506 | train_wall 314 | gb_free 6.1 | wall 14038
KL Stats: Epoch 41 Divergences: Uniform: 2.2846633551970514 Unigram: 2.4318522310659083
2022-02-02 10:01:24 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 10:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:06:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:07:06 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.284 | ppl 623.41 | wps 8265 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.263
2022-02-02 10:07:06 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 10:07:06 | INFO | train | epoch 042 | loss 8.061 | ppl 267.06 | wps 6102.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.51 | train_wall 314 | gb_free 6.1 | wall 14380
KL Stats: Epoch 42 Divergences: Uniform: 2.306706908751317 Unigram: 2.46126139751287
2022-02-02 10:07:06 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 10:07:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:08:06 | INFO | train_inner | epoch 043:     12 / 64 loss=8.07, ppl=268.79, wps=5970.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.511, train_wall=491, gb_free=6.1, wall=14440
2022-02-02 10:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:12:50 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.268 | ppl 616.7 | wps 8248.5 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.263
2022-02-02 10:12:50 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:12:50 | INFO | train | epoch 043 | loss 7.999 | ppl 255.81 | wps 6069.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.505 | train_wall 316 | gb_free 6.1 | wall 14724
KL Stats: Epoch 43 Divergences: Uniform: 2.3252302647906835 Unigram: 2.4929346643550314
2022-02-02 10:12:50 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:12:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:16:49 | INFO | train_inner | epoch 044:     48 / 64 loss=7.965, ppl=249.88, wps=6244.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.499, train_wall=494, gb_free=6.1, wall=14963
2022-02-02 10:18:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:18:34 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.267 | ppl 616.12 | wps 8254.2 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.263
2022-02-02 10:18:34 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:18:34 | INFO | train | epoch 044 | loss 7.937 | ppl 245.07 | wps 6080.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.506 | train_wall 315 | gb_free 6.1 | wall 15068
KL Stats: Epoch 44 Divergences: Uniform: 2.3418946822801803 Unigram: 2.5214624286385785
2022-02-02 10:18:34 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:18:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:23:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:24:18 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.288 | ppl 625 | wps 7864.7 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.263
2022-02-02 10:24:18 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:24:18 | INFO | train | epoch 045 | loss 7.875 | ppl 234.74 | wps 6070.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.5 | train_wall 315 | gb_free 6.1 | wall 15412
KL Stats: Epoch 45 Divergences: Uniform: 2.3658268763867687 Unigram: 2.5498538708295286
2022-02-02 10:24:18 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:24:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:25:57 | INFO | train_inner | epoch 046:     20 / 64 loss=7.874, ppl=234.61, wps=5947.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.512, train_wall=491, gb_free=6.1, wall=15511
2022-02-02 10:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:30:01 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.278 | ppl 621 | wps 8200.3 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.263
2022-02-02 10:30:01 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:30:01 | INFO | train | epoch 046 | loss 7.819 | ppl 225.82 | wps 6074.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.516 | train_wall 316 | gb_free 6.1 | wall 15755
KL Stats: Epoch 46 Divergences: Uniform: 2.375337299113267 Unigram: 2.5730592147329356
2022-02-02 10:30:01 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:30:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:34:40 | INFO | train_inner | epoch 047:     56 / 64 loss=7.788, ppl=220.97, wps=6255.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.506, train_wall=493, gb_free=6.1, wall=16034
2022-02-02 10:35:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:35:44 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.305 | ppl 632.37 | wps 8300.5 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.263
2022-02-02 10:35:44 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:35:44 | INFO | train | epoch 047 | loss 7.759 | ppl 216.56 | wps 6090.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.506 | train_wall 315 | gb_free 6.1 | wall 16098
KL Stats: Epoch 47 Divergences: Uniform: 2.401643124464825 Unigram: 2.6024097024838873
2022-02-02 10:35:44 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:35:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:41:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:41:29 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.261 | ppl 613.63 | wps 8196.7 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.261
2022-02-02 10:41:29 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 10:41:29 | INFO | train | epoch 048 | loss 7.702 | ppl 208.21 | wps 6059.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.514 | train_wall 316 | gb_free 6.1 | wall 16443
KL Stats: Epoch 48 Divergences: Uniform: 2.41278108627702 Unigram: 2.631118602557972
2022-02-02 10:41:29 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 10:41:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:43:48 | INFO | train_inner | epoch 049:     28 / 64 loss=7.685, ppl=205.77, wps=5942, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.512, train_wall=493, gb_free=6.1, wall=16582
2022-02-02 10:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:47:13 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.287 | ppl 624.52 | wps 8264.4 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.263
2022-02-02 10:47:13 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 10:47:13 | INFO | train | epoch 049 | loss 7.646 | ppl 200.31 | wps 6077.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.505 | train_wall 316 | gb_free 6.1 | wall 16787
KL Stats: Epoch 49 Divergences: Uniform: 2.4314468920733523 Unigram: 2.649589855089962
2022-02-02 10:47:13 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 10:47:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:52:29 | INFO | train_inner | epoch 050:     64 / 64 loss=7.621, ppl=196.92, wps=6263.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.509, train_wall=492, gb_free=6.1, wall=17103
2022-02-02 10:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:52:56 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.297 | ppl 629.14 | wps 8036.3 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.263
2022-02-02 10:52:56 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 10:52:56 | INFO | train | epoch 050 | loss 7.593 | ppl 193.04 | wps 6083.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.512 | train_wall 315 | gb_free 6.1 | wall 17130
KL Stats: Epoch 50 Divergences: Uniform: 2.4565570591504553 Unigram: 2.6783133649423925
2022-02-02 10:52:56 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 10:52:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:58:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:58:41 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.305 | ppl 632.32 | wps 8158.6 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.263
2022-02-02 10:58:41 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 10:58:41 | INFO | train | epoch 051 | loss 7.54 | ppl 186.14 | wps 6054.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.519 | train_wall 317 | gb_free 6.1 | wall 17475
KL Stats: Epoch 51 Divergences: Uniform: 2.460764380597666 Unigram: 2.6988499694753108
2022-02-02 10:58:41 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 10:58:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:01:41 | INFO | train_inner | epoch 052:     36 / 64 loss=7.512, ppl=182.54, wps=5922.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.513, train_wall=495, gb_free=6.1, wall=17655
2022-02-02 11:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:04:25 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.277 | ppl 620.5 | wps 8227.6 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.263
2022-02-02 11:04:25 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 11:04:25 | INFO | train | epoch 052 | loss 7.486 | ppl 179.22 | wps 6065 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.505 | train_wall 316 | gb_free 6.1 | wall 17819
KL Stats: Epoch 52 Divergences: Uniform: 2.4753263696161736 Unigram: 2.728176214300258
2022-02-02 11:04:25 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 11:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:10:10 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.297 | ppl 629.09 | wps 8195.5 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.263
2022-02-02 11:10:10 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 11:10:10 | INFO | train | epoch 053 | loss 7.435 | ppl 173.04 | wps 6068.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.528 | train_wall 316 | gb_free 6.1 | wall 18163
KL Stats: Epoch 53 Divergences: Uniform: 2.491023438060437 Unigram: 2.74908097415726
2022-02-02 11:10:10 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 11:10:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:10:50 | INFO | train_inner | epoch 054:      8 / 64 loss=7.448, ppl=174.61, wps=5938.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.522, train_wall=493, gb_free=6.1, wall=18204
2022-02-02 11:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:15:55 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.297 | ppl 628.96 | wps 8216.1 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.263
2022-02-02 11:15:55 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:15:55 | INFO | train | epoch 054 | loss 7.384 | ppl 167 | wps 6053.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.51 | train_wall 317 | gb_free 6.1 | wall 18508
KL Stats: Epoch 54 Divergences: Uniform: 2.5106096568236707 Unigram: 2.775867023628868
2022-02-02 11:15:55 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:15:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:19:34 | INFO | train_inner | epoch 055:     44 / 64 loss=7.362, ppl=164.47, wps=6230.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.516, train_wall=495, gb_free=6.1, wall=18728
2022-02-02 11:21:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:21:39 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.329 | ppl 643.32 | wps 8218 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.263
2022-02-02 11:21:39 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:21:39 | INFO | train | epoch 055 | loss 7.336 | ppl 161.57 | wps 6059.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.525 | train_wall 316 | gb_free 6.1 | wall 18853
KL Stats: Epoch 55 Divergences: Uniform: 2.5263644096537057 Unigram: 2.7940657030885294
2022-02-02 11:21:39 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:27:23 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.342 | ppl 648.93 | wps 8215.2 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.263
2022-02-02 11:27:23 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:27:23 | INFO | train | epoch 056 | loss 7.287 | ppl 156.22 | wps 6067.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.535 | train_wall 316 | gb_free 6.1 | wall 19197
KL Stats: Epoch 56 Divergences: Uniform: 2.529946175777166 Unigram: 2.812779235882173
2022-02-02 11:27:23 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:27:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:28:44 | INFO | train_inner | epoch 057:     16 / 64 loss=7.29, ppl=156.46, wps=5931.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.536, train_wall=494, gb_free=6.1, wall=19278
2022-02-02 11:32:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:33:08 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.349 | ppl 652 | wps 8208.6 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.263
2022-02-02 11:33:08 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:33:08 | INFO | train | epoch 057 | loss 7.239 | ppl 151.1 | wps 6060.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.539 | train_wall 316 | gb_free 6.1 | wall 19542
KL Stats: Epoch 57 Divergences: Uniform: 2.5558656027091646 Unigram: 2.847148085614072
2022-02-02 11:33:08 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:33:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:37:26 | INFO | train_inner | epoch 058:     52 / 64 loss=7.217, ppl=148.76, wps=6262.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.542, train_wall=493, gb_free=6.1, wall=19799
2022-02-02 11:38:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:38:50 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.336 | ppl 646.13 | wps 8258.8 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.263
2022-02-02 11:38:50 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 11:38:50 | INFO | train | epoch 058 | loss 7.194 | ppl 146.4 | wps 6105 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.543 | train_wall 314 | gb_free 6.1 | wall 19884
KL Stats: Epoch 58 Divergences: Uniform: 2.557077373127063 Unigram: 2.8646299507794675
2022-02-02 11:38:50 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 11:38:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:44:34 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.378 | ppl 665.17 | wps 8267 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.263
2022-02-02 11:44:34 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 11:44:34 | INFO | train | epoch 059 | loss 7.147 | ppl 141.75 | wps 6082.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.534 | train_wall 315 | gb_free 6.1 | wall 20228
KL Stats: Epoch 59 Divergences: Uniform: 2.5735593815671036 Unigram: 2.884000359563578
2022-02-02 11:44:34 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 11:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:46:33 | INFO | train_inner | epoch 060:     24 / 64 loss=7.136, ppl=140.63, wps=5954.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.535, train_wall=492, gb_free=6.1, wall=20347
2022-02-02 11:49:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:50:17 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.406 | ppl 678.49 | wps 8247.6 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.263
2022-02-02 11:50:17 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 11:50:17 | INFO | train | epoch 060 | loss 7.105 | ppl 137.64 | wps 6079.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.545 | train_wall 315 | gb_free 6.1 | wall 20571
KL Stats: Epoch 60 Divergences: Uniform: 2.5842025982661614 Unigram: 2.9018026119965317
2022-02-02 11:50:17 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 11:50:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:55:16 | INFO | train_inner | epoch 061:     60 / 64 loss=7.088, ppl=136.06, wps=6249.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.547, train_wall=494, gb_free=6.1, wall=20870
2022-02-02 11:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:56:01 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.387 | ppl 669.62 | wps 8255.9 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.263
2022-02-02 11:56:01 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 11:56:01 | INFO | train | epoch 061 | loss 7.063 | ppl 133.68 | wps 6072.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.551 | train_wall 316 | gb_free 6.1 | wall 20915
KL Stats: Epoch 61 Divergences: Uniform: 2.610802016256123 Unigram: 2.926876160604288
2022-02-02 11:56:01 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 11:56:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:01:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:01:44 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.378 | ppl 665.31 | wps 8216.5 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.263
2022-02-02 12:01:44 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 12:01:44 | INFO | train | epoch 062 | loss 7.021 | ppl 129.85 | wps 6088.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.571 | train_wall 315 | gb_free 6.1 | wall 21258
KL Stats: Epoch 62 Divergences: Uniform: 2.6198164025148816 Unigram: 2.9451081747485963
2022-02-02 12:01:44 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 12:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:04:23 | INFO | train_inner | epoch 063:     32 / 64 loss=7.001, ppl=128.11, wps=5955.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.564, train_wall=492, gb_free=6.1, wall=21417
2022-02-02 12:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:07:27 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.475 | ppl 711.61 | wps 8241.7 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.263
2022-02-02 12:07:27 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 12:07:27 | INFO | train | epoch 063 | loss 6.976 | ppl 125.87 | wps 6086.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.55 | train_wall 315 | gb_free 6.1 | wall 21601
KL Stats: Epoch 63 Divergences: Uniform: 2.6222405331006753 Unigram: 2.9613507969666206
2022-02-02 12:07:27 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 12:07:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:12:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:13:12 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.43 | ppl 689.84 | wps 8245.7 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.263
2022-02-02 12:13:12 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 12:13:12 | INFO | train | epoch 064 | loss 6.933 | ppl 122.19 | wps 6062 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.563 | train_wall 316 | gb_free 6.1 | wall 21946
KL Stats: Epoch 64 Divergences: Uniform: 2.640296945347555 Unigram: 2.992070710875964
2022-02-02 12:13:12 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 12:13:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:13:32 | INFO | train_inner | epoch 065:      4 / 64 loss=6.951, ppl=123.75, wps=5944.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.559, train_wall=493, gb_free=6.1, wall=21966
2022-02-02 12:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:18:55 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.433 | ppl 691.44 | wps 8264.6 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.263
2022-02-02 12:18:55 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:18:55 | INFO | train | epoch 065 | loss 6.892 | ppl 118.78 | wps 6085.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.57 | train_wall 315 | gb_free 6.1 | wall 22289
KL Stats: Epoch 65 Divergences: Uniform: 2.656611217586824 Unigram: 3.0095681168479596
2022-02-02 12:18:55 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:18:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:22:15 | INFO | train_inner | epoch 066:     40 / 64 loss=6.868, ppl=116.84, wps=6249.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.57, train_wall=494, gb_free=6.1, wall=22489
2022-02-02 12:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:24:39 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.473 | ppl 710.82 | wps 8229.9 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.263
2022-02-02 12:24:39 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:24:39 | INFO | train | epoch 066 | loss 6.849 | ppl 115.29 | wps 6070.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.567 | train_wall 316 | gb_free 6.1 | wall 22633
KL Stats: Epoch 66 Divergences: Uniform: 2.6703821556651746 Unigram: 3.0304521771467794
2022-02-02 12:24:39 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:24:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:30:23 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.519 | ppl 733.69 | wps 8211.8 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.263
2022-02-02 12:30:23 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:30:23 | INFO | train | epoch 067 | loss 6.809 | ppl 112.13 | wps 6081.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.578 | train_wall 315 | gb_free 6.1 | wall 22977
KL Stats: Epoch 67 Divergences: Uniform: 2.686432374089864 Unigram: 3.0500503619194452
2022-02-02 12:30:23 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:30:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:31:22 | INFO | train_inner | epoch 068:     12 / 64 loss=6.819, ppl=112.89, wps=5954.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.574, train_wall=492, gb_free=6.1, wall=23036
2022-02-02 12:35:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:36:05 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.559 | ppl 754.4 | wps 8275.3 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.263
2022-02-02 12:36:05 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 12:36:05 | INFO | train | epoch 068 | loss 6.77 | ppl 109.1 | wps 6097.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.572 | train_wall 315 | gb_free 6.1 | wall 23319
KL Stats: Epoch 68 Divergences: Uniform: 2.6843772184250887 Unigram: 3.0695076251209867
2022-02-02 12:36:05 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 12:36:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:40:06 | INFO | train_inner | epoch 069:     48 / 64 loss=6.75, ppl=107.6, wps=6240.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.576, train_wall=495, gb_free=6.1, wall=23560
2022-02-02 12:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:41:51 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.503 | ppl 725.47 | wps 8248.9 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.263
2022-02-02 12:41:51 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 12:41:51 | INFO | train | epoch 069 | loss 6.734 | ppl 106.44 | wps 6044.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.576 | train_wall 317 | gb_free 6.1 | wall 23665
KL Stats: Epoch 69 Divergences: Uniform: 2.70509879683263 Unigram: 3.0901328369188032
2022-02-02 12:41:51 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 12:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:47:34 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.578 | ppl 764.34 | wps 8251.5 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.263
2022-02-02 12:47:34 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 12:47:34 | INFO | train | epoch 070 | loss 6.697 | ppl 103.77 | wps 6085.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.584 | train_wall 315 | gb_free 6.1 | wall 24008
KL Stats: Epoch 70 Divergences: Uniform: 2.710767456440729 Unigram: 3.10570538673621
2022-02-02 12:47:34 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 12:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:49:13 | INFO | train_inner | epoch 071:     20 / 64 loss=6.69, ppl=103.25, wps=5955.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.579, train_wall=492, gb_free=6.1, wall=24107
2022-02-02 12:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:53:17 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.547 | ppl 748 | wps 8253.9 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.263
2022-02-02 12:53:17 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 12:53:17 | INFO | train | epoch 071 | loss 6.662 | ppl 101.29 | wps 6090.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.59 | train_wall 315 | gb_free 6.1 | wall 24351
KL Stats: Epoch 71 Divergences: Uniform: 2.71554997080546 Unigram: 3.130890470899268
2022-02-02 12:53:17 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 12:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:57:55 | INFO | train_inner | epoch 072:     56 / 64 loss=6.653, ppl=100.65, wps=6258.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.594, train_wall=493, gb_free=6.1, wall=24629
2022-02-02 12:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:59:00 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.578 | ppl 764.39 | wps 8269.8 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.263
2022-02-02 12:59:00 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 12:59:00 | INFO | train | epoch 072 | loss 6.628 | ppl 98.9 | wps 6081.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.594 | train_wall 315 | gb_free 6.1 | wall 24694
KL Stats: Epoch 72 Divergences: Uniform: 2.7322212295218993 Unigram: 3.1516911817348325
2022-02-02 12:59:00 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 12:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:04:44 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.533 | ppl 740.87 | wps 8202.2 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.263
2022-02-02 13:04:44 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 13:04:44 | INFO | train | epoch 073 | loss 6.592 | ppl 96.48 | wps 6071 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.603 | train_wall 316 | gb_free 6.1 | wall 25038
KL Stats: Epoch 73 Divergences: Uniform: 2.7447340504307247 Unigram: 3.1699577815999365
2022-02-02 13:04:44 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 13:04:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:07:04 | INFO | train_inner | epoch 074:     28 / 64 loss=6.576, ppl=95.43, wps=5943.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.597, train_wall=493, gb_free=6.1, wall=25178
2022-02-02 13:10:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:10:29 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.578 | ppl 764.2 | wps 8231.5 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.263
2022-02-02 13:10:29 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 13:10:29 | INFO | train | epoch 074 | loss 6.559 | ppl 94.3 | wps 6066.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.58 | train_wall 316 | gb_free 6.1 | wall 25382
KL Stats: Epoch 74 Divergences: Uniform: 2.7541762445960316 Unigram: 3.186188845120162
2022-02-02 13:10:29 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 13:10:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:15:48 | INFO | train_inner | epoch 075:     64 / 64 loss=6.554, ppl=93.95, wps=6224.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.598, train_wall=495, gb_free=6.1, wall=25701
2022-02-02 13:15:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:16:14 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.604 | ppl 778.28 | wps 8266 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.263
2022-02-02 13:16:14 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 13:16:14 | INFO | train | epoch 075 | loss 6.531 | ppl 92.48 | wps 6046.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.606 | train_wall 317 | gb_free 6.1 | wall 25728
KL Stats: Epoch 75 Divergences: Uniform: 2.759589688491144 Unigram: 3.20856107196647
2022-02-02 13:16:14 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 13:16:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:21:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:21:59 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.598 | ppl 774.85 | wps 8220.7 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.263
2022-02-02 13:21:59 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:21:59 | INFO | train | epoch 076 | loss 6.499 | ppl 90.44 | wps 6055.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.604 | train_wall 317 | gb_free 6.1 | wall 26073
KL Stats: Epoch 76 Divergences: Uniform: 2.7644320160772238 Unigram: 3.219251019976904
2022-02-02 13:21:59 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:24:58 | INFO | train_inner | epoch 077:     36 / 64 loss=6.478, ppl=89.13, wps=5934.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.61, train_wall=495, gb_free=6.1, wall=26252
2022-02-02 13:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:27:43 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.621 | ppl 787.32 | wps 8288.1 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.263
2022-02-02 13:27:43 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:27:43 | INFO | train | epoch 077 | loss 6.47 | ppl 88.63 | wps 6074.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.629 | train_wall 316 | gb_free 6.1 | wall 26417
KL Stats: Epoch 77 Divergences: Uniform: 2.7752231071114912 Unigram: 3.23563920726683
2022-02-02 13:27:43 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:27:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:32:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:33:25 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.603 | ppl 777.7 | wps 8285.5 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.263
2022-02-02 13:33:25 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 13:33:25 | INFO | train | epoch 078 | loss 6.441 | ppl 86.86 | wps 6108.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.604 | train_wall 314 | gb_free 6.1 | wall 26759
KL Stats: Epoch 78 Divergences: Uniform: 2.7848253601453488 Unigram: 3.260581489144777
2022-02-02 13:33:25 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 13:33:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:34:04 | INFO | train_inner | epoch 079:      8 / 64 loss=6.452, ppl=87.54, wps=5970.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.619, train_wall=491, gb_free=6.1, wall=26798
2022-02-02 13:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:39:07 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.665 | ppl 811.85 | wps 8184.7 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.263
2022-02-02 13:39:07 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 13:39:07 | INFO | train | epoch 079 | loss 6.413 | ppl 85.21 | wps 6108 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.623 | train_wall 314 | gb_free 6.1 | wall 27101
KL Stats: Epoch 79 Divergences: Uniform: 2.7940861307881537 Unigram: 3.2825536464406713
2022-02-02 13:39:07 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 13:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:42:45 | INFO | train_inner | epoch 080:     44 / 64 loss=6.399, ppl=84.4, wps=6280.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.617, train_wall=491, gb_free=6.1, wall=27318
2022-02-02 13:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:44:48 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.679 | ppl 820 | wps 8291.4 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.263
2022-02-02 13:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 13:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint80.pt
2022-02-02 13:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint80.pt
2022-02-02 13:44:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.679) (writing took 3.376935954205692 seconds)
2022-02-02 13:44:52 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 13:44:52 | INFO | train | epoch 080 | loss 6.387 | ppl 83.67 | wps 6048.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.617 | train_wall 314 | gb_free 6.1 | wall 27446
KL Stats: Epoch 80 Divergences: Uniform: 2.803912330615589 Unigram: 3.2926240985360717
2022-02-02 13:44:52 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 13:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:50:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:50:34 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.658 | ppl 807.71 | wps 8263.5 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.263
2022-02-02 13:50:34 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 13:50:34 | INFO | train | epoch 081 | loss 6.358 | ppl 82.01 | wps 6096 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.622 | train_wall 315 | gb_free 6.1 | wall 27788
KL Stats: Epoch 81 Divergences: Uniform: 2.803924239374932 Unigram: 3.316569044597404
2022-02-02 13:50:34 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 13:50:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:51:54 | INFO | train_inner | epoch 082:     16 / 64 loss=6.358, ppl=82.03, wps=5934, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.626, train_wall=491, gb_free=6.1, wall=27868
2022-02-02 13:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:56:19 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.698 | ppl 830.41 | wps 8255.2 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.263
2022-02-02 13:56:19 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 13:56:19 | INFO | train | epoch 082 | loss 6.333 | ppl 80.6 | wps 6070.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.647 | train_wall 316 | gb_free 6.1 | wall 28132
KL Stats: Epoch 82 Divergences: Uniform: 2.8121477878204835 Unigram: 3.3263363848778074
2022-02-02 13:56:19 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 13:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:00:36 | INFO | train_inner | epoch 083:     52 / 64 loss=6.323, ppl=80.05, wps=6255.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.639, train_wall=493, gb_free=6.1, wall=28390
2022-02-02 14:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:02:01 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.697 | ppl 830.27 | wps 8257.6 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.263
2022-02-02 14:02:01 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 14:02:01 | INFO | train | epoch 083 | loss 6.308 | ppl 79.23 | wps 6098.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.632 | train_wall 314 | gb_free 6.1 | wall 28475
KL Stats: Epoch 83 Divergences: Uniform: 2.8240751384154352 Unigram: 3.347194528558547
2022-02-02 14:02:01 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 14:02:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:07:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:07:44 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.712 | ppl 838.42 | wps 8237 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.263
2022-02-02 14:07:44 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 14:07:44 | INFO | train | epoch 084 | loss 6.283 | ppl 77.87 | wps 6087.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.634 | train_wall 315 | gb_free 6.1 | wall 28818
KL Stats: Epoch 84 Divergences: Uniform: 2.8322472206180063 Unigram: 3.3684717153793855
2022-02-02 14:07:44 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 14:07:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:09:43 | INFO | train_inner | epoch 085:     24 / 64 loss=6.275, ppl=77.47, wps=5958.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.643, train_wall=492, gb_free=6.1, wall=28937
2022-02-02 14:13:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:13:27 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.686 | ppl 823.96 | wps 8254 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.263
2022-02-02 14:13:27 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 14:13:27 | INFO | train | epoch 085 | loss 6.259 | ppl 76.61 | wps 6090.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.654 | train_wall 315 | gb_free 6.1 | wall 29161
KL Stats: Epoch 85 Divergences: Uniform: 2.8384092468925437 Unigram: 3.376320074888213
2022-02-02 14:13:27 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 14:13:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:18:25 | INFO | train_inner | epoch 086:     60 / 64 loss=6.251, ppl=76.17, wps=6259.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.644, train_wall=493, gb_free=6.1, wall=29459
2022-02-02 14:18:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:19:11 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.71 | ppl 837.39 | wps 8255.7 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.263
2022-02-02 14:19:11 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 14:19:11 | INFO | train | epoch 086 | loss 6.235 | ppl 75.3 | wps 6080.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.651 | train_wall 315 | gb_free 6.1 | wall 29505
KL Stats: Epoch 86 Divergences: Uniform: 2.8383477886570754 Unigram: 3.3920570937358585
2022-02-02 14:19:11 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 14:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:24:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:24:53 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.684 | ppl 822.82 | wps 8251.4 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.263
2022-02-02 14:24:53 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:24:53 | INFO | train | epoch 087 | loss 6.212 | ppl 74.14 | wps 6094.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.649 | train_wall 315 | gb_free 6.1 | wall 29847
KL Stats: Epoch 87 Divergences: Uniform: 2.8522402907920528 Unigram: 3.410232776755288
2022-02-02 14:24:53 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:24:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:27:32 | INFO | train_inner | epoch 088:     32 / 64 loss=6.199, ppl=73.46, wps=5964.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.649, train_wall=491, gb_free=6.1, wall=30006
2022-02-02 14:30:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:30:36 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.74 | ppl 855.26 | wps 8254.5 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.263
2022-02-02 14:30:36 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 14:30:36 | INFO | train | epoch 088 | loss 6.189 | ppl 72.96 | wps 6089.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.65 | train_wall 315 | gb_free 6.1 | wall 30190
KL Stats: Epoch 88 Divergences: Uniform: 2.852502912084526 Unigram: 3.4287357278469135
2022-02-02 14:30:36 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 14:30:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:35:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:36:25 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.754 | ppl 863.49 | wps 8060.7 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.263
2022-02-02 14:36:25 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 14:36:25 | INFO | train | epoch 089 | loss 6.169 | ppl 71.96 | wps 5994.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.669 | train_wall 320 | gb_free 6.1 | wall 30539
KL Stats: Epoch 89 Divergences: Uniform: 2.861588434066129 Unigram: 3.442545143064794
2022-02-02 14:36:25 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 14:36:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:36:45 | INFO | train_inner | epoch 090:      4 / 64 loss=6.185, ppl=72.73, wps=5900.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.666, train_wall=496, gb_free=6.1, wall=30558
2022-02-02 14:41:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:42:09 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.764 | ppl 869.72 | wps 8244 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.263
2022-02-02 14:42:09 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 14:42:09 | INFO | train | epoch 090 | loss 6.147 | ppl 70.88 | wps 6061.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.66 | train_wall 316 | gb_free 6.1 | wall 30883
KL Stats: Epoch 90 Divergences: Uniform: 2.867293596056055 Unigram: 3.4563603962044476
2022-02-02 14:42:09 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 14:42:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:45:28 | INFO | train_inner | epoch 091:     40 / 64 loss=6.129, ppl=70, wps=6245.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.66, train_wall=494, gb_free=6.1, wall=31082
2022-02-02 14:47:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:47:52 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.767 | ppl 871.35 | wps 8295.8 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.263
2022-02-02 14:47:52 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 14:47:52 | INFO | train | epoch 091 | loss 6.125 | ppl 69.81 | wps 6091.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.675 | train_wall 315 | gb_free 6.1 | wall 31226
KL Stats: Epoch 91 Divergences: Uniform: 2.871254022842082 Unigram: 3.474419387456739
2022-02-02 14:47:52 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 14:47:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:53:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:53:37 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.797 | ppl 889.29 | wps 8260.3 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.263
2022-02-02 14:53:37 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 14:53:37 | INFO | train | epoch 092 | loss 6.106 | ppl 68.9 | wps 6057.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.697 | train_wall 317 | gb_free 6.1 | wall 31571
KL Stats: Epoch 92 Divergences: Uniform: 2.877796631837177 Unigram: 3.484902860215649
2022-02-02 14:53:37 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 14:53:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:54:36 | INFO | train_inner | epoch 093:     12 / 64 loss=6.109, ppl=69.04, wps=5942.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.694, train_wall=493, gb_free=6.1, wall=31630
2022-02-02 14:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:59:21 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.777 | ppl 877.31 | wps 8119.1 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.263
2022-02-02 14:59:21 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 14:59:21 | INFO | train | epoch 093 | loss 6.086 | ppl 67.93 | wps 6066.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.686 | train_wall 316 | gb_free 6.1 | wall 31915
KL Stats: Epoch 93 Divergences: Uniform: 2.882577106680703 Unigram: 3.495529771221515
2022-02-02 14:59:21 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 14:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:03:21 | INFO | train_inner | epoch 094:     48 / 64 loss=6.079, ppl=67.59, wps=6232.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.687, train_wall=495, gb_free=6.1, wall=32155
2022-02-02 15:04:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:05:05 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.871 | ppl 936.28 | wps 8233.6 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.263
2022-02-02 15:05:05 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 15:05:05 | INFO | train | epoch 094 | loss 6.065 | ppl 66.97 | wps 6067.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.683 | train_wall 316 | gb_free 6.1 | wall 32259
KL Stats: Epoch 94 Divergences: Uniform: 2.8853819828482137 Unigram: 3.5124783272537927
2022-02-02 15:05:05 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 15:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:10:48 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.823 | ppl 905.91 | wps 8278.8 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.263
2022-02-02 15:10:48 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 15:10:48 | INFO | train | epoch 095 | loss 6.047 | ppl 66.12 | wps 6098.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.687 | train_wall 315 | gb_free 6.1 | wall 32602
KL Stats: Epoch 95 Divergences: Uniform: 2.895920893270812 Unigram: 3.5249466870659676
2022-02-02 15:10:48 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 15:10:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:12:27 | INFO | train_inner | epoch 096:     20 / 64 loss=6.043, ppl=65.94, wps=5964.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.687, train_wall=491, gb_free=6.1, wall=32701
2022-02-02 15:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:16:31 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.822 | ppl 904.87 | wps 8255.2 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.263
2022-02-02 15:16:31 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 15:16:31 | INFO | train | epoch 096 | loss 6.027 | ppl 65.19 | wps 6096.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.691 | train_wall 315 | gb_free 6.1 | wall 32945
KL Stats: Epoch 96 Divergences: Uniform: 2.896635290680067 Unigram: 3.5359825474179907
2022-02-02 15:16:31 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 15:16:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:21:09 | INFO | train_inner | epoch 097:     56 / 64 loss=6.019, ppl=64.87, wps=6269, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.691, train_wall=492, gb_free=6.1, wall=33223
2022-02-02 15:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:22:13 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.867 | ppl 933.68 | wps 8252.5 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.263
2022-02-02 15:22:13 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 15:22:13 | INFO | train | epoch 097 | loss 6.009 | ppl 64.39 | wps 6092.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.694 | train_wall 315 | gb_free 6.1 | wall 33287
KL Stats: Epoch 97 Divergences: Uniform: 2.9082576421118818 Unigram: 3.5558387423641036
2022-02-02 15:22:13 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 15:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:27:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:27:55 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.873 | ppl 937.93 | wps 8299.7 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.263
2022-02-02 15:27:55 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 15:27:55 | INFO | train | epoch 098 | loss 5.992 | ppl 63.66 | wps 6108 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.716 | train_wall 314 | gb_free 6.1 | wall 33629
KL Stats: Epoch 98 Divergences: Uniform: 2.911668483913606 Unigram: 3.566802504853148
2022-02-02 15:27:55 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 15:27:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:30:14 | INFO | train_inner | epoch 099:     28 / 64 loss=5.982, ppl=63.22, wps=5976.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.713, train_wall=490, gb_free=6.1, wall=33768
2022-02-02 15:33:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:33:37 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.907 | ppl 960.34 | wps 8281.8 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.263
2022-02-02 15:33:37 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 15:33:37 | INFO | train | epoch 099 | loss 5.974 | ppl 62.87 | wps 6109.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.711 | train_wall 314 | gb_free 6.1 | wall 33971
KL Stats: Epoch 99 Divergences: Uniform: 2.9105747907996653 Unigram: 3.576895602903946
2022-02-02 15:33:37 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 15:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:38:53 | INFO | train_inner | epoch 100:     64 / 64 loss=5.976, ppl=62.95, wps=6279.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.714, train_wall=490, gb_free=6.1, wall=34287
2022-02-02 15:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:39:20 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.887 | ppl 946.81 | wps 8226.1 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.263
2022-02-02 15:39:20 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 15:39:20 | INFO | train | epoch 100 | loss 5.957 | ppl 62.13 | wps 6099.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.715 | train_wall 314 | gb_free 6.1 | wall 34314
KL Stats: Epoch 100 Divergences: Uniform: 2.9147984176226 Unigram: 3.592630616622769
2022-02-02 15:39:20 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 15:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:44:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:45:03 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.86 | ppl 929.61 | wps 8286.3 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.263
2022-02-02 15:45:03 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 15:45:03 | INFO | train | epoch 101 | loss 5.94 | ppl 61.4 | wps 6087.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.729 | train_wall 315 | gb_free 6.1 | wall 34657
KL Stats: Epoch 101 Divergences: Uniform: 2.9174380204014074 Unigram: 3.6103702514265783
2022-02-02 15:45:03 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 15:45:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:48:01 | INFO | train_inner | epoch 102:     36 / 64 loss=5.925, ppl=60.74, wps=5962.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.721, train_wall=493, gb_free=6.1, wall=34835
2022-02-02 15:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:50:45 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.923 | ppl 971.06 | wps 8243.7 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.263
2022-02-02 15:50:45 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 15:50:45 | INFO | train | epoch 102 | loss 5.924 | ppl 60.7 | wps 6095 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.721 | train_wall 315 | gb_free 6.1 | wall 34999
KL Stats: Epoch 102 Divergences: Uniform: 2.926292123764925 Unigram: 3.6194818602950107
2022-02-02 15:50:45 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 15:50:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:56:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:56:28 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.899 | ppl 954.82 | wps 8279.3 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.263
2022-02-02 15:56:28 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 15:56:28 | INFO | train | epoch 103 | loss 5.909 | ppl 60.08 | wps 6091.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.733 | train_wall 315 | gb_free 6.1 | wall 35342
KL Stats: Epoch 103 Divergences: Uniform: 2.9297487726224247 Unigram: 3.6253189151677563
2022-02-02 15:56:28 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 15:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:57:08 | INFO | train_inner | epoch 104:      8 / 64 loss=5.916, ppl=60.4, wps=5961.7, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.734, train_wall=491, gb_free=6.1, wall=35382
2022-02-02 16:01:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:02:11 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.911 | ppl 962.59 | wps 8265 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.263
2022-02-02 16:02:11 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 16:02:11 | INFO | train | epoch 104 | loss 5.892 | ppl 59.4 | wps 6097.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.742 | train_wall 315 | gb_free 6.1 | wall 35685
KL Stats: Epoch 104 Divergences: Uniform: 2.929857542183576 Unigram: 3.6398020857342392
2022-02-02 16:02:11 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 16:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:05:49 | INFO | train_inner | epoch 105:     44 / 64 loss=5.879, ppl=58.85, wps=6272.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.736, train_wall=492, gb_free=6.1, wall=35903
2022-02-02 16:07:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:07:53 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.886 | ppl 946.1 | wps 8275.9 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.263
2022-02-02 16:07:53 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 16:07:53 | INFO | train | epoch 105 | loss 5.875 | ppl 58.69 | wps 6101.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.732 | train_wall 314 | gb_free 6.1 | wall 36027
KL Stats: Epoch 105 Divergences: Uniform: 2.9355676761479894 Unigram: 3.6560630988820733
2022-02-02 16:07:53 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 16:07:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:13:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:13:36 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.94 | ppl 982.18 | wps 8268.7 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.263
2022-02-02 16:13:36 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 16:13:36 | INFO | train | epoch 106 | loss 5.859 | ppl 58.03 | wps 6091.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.737 | train_wall 315 | gb_free 6.1 | wall 36370
KL Stats: Epoch 106 Divergences: Uniform: 2.945172378554431 Unigram: 3.6679482305520805
2022-02-02 16:13:36 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 16:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:14:56 | INFO | train_inner | epoch 107:     16 / 64 loss=5.861, ppl=58.1, wps=5964.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.739, train_wall=491, gb_free=6.1, wall=36450
2022-02-02 16:18:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:19:19 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.893 | ppl 950.51 | wps 8271.6 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.263
2022-02-02 16:19:19 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 16:19:19 | INFO | train | epoch 107 | loss 5.849 | ppl 57.63 | wps 6091.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.779 | train_wall 315 | gb_free 6.1 | wall 36713
KL Stats: Epoch 107 Divergences: Uniform: 2.949138620827815 Unigram: 3.6787384262203484
2022-02-02 16:19:19 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 16:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:23:36 | INFO | train_inner | epoch 108:     52 / 64 loss=5.842, ppl=57.38, wps=6275.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.771, train_wall=492, gb_free=6.1, wall=36970
2022-02-02 16:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:25:01 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.962 | ppl 997.15 | wps 8282.1 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.263
2022-02-02 16:25:01 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 16:25:01 | INFO | train | epoch 108 | loss 5.83 | ppl 56.88 | wps 6109.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.744 | train_wall 314 | gb_free 6.1 | wall 37055
KL Stats: Epoch 108 Divergences: Uniform: 2.943050712254436 Unigram: 3.6880388473649584
2022-02-02 16:25:01 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 16:25:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:30:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:30:44 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.004 | ppl 1027.2 | wps 8232.9 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.263
2022-02-02 16:30:44 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 16:30:44 | INFO | train | epoch 109 | loss 5.817 | ppl 56.36 | wps 6094.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.763 | train_wall 315 | gb_free 6.1 | wall 37398
KL Stats: Epoch 109 Divergences: Uniform: 2.9431716124851652 Unigram: 3.700067655594678
2022-02-02 16:30:44 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 16:30:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:32:43 | INFO | train_inner | epoch 110:     24 / 64 loss=5.809, ppl=56.06, wps=5967.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.762, train_wall=491, gb_free=6.1, wall=37517
2022-02-02 16:36:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:36:26 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.955 | ppl 992.4 | wps 8237.7 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.263
2022-02-02 16:36:26 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 16:36:26 | INFO | train | epoch 110 | loss 5.802 | ppl 55.81 | wps 6098.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.755 | train_wall 314 | gb_free 6.1 | wall 37740
KL Stats: Epoch 110 Divergences: Uniform: 2.9570736935865702 Unigram: 3.7123549182416067
2022-02-02 16:36:26 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 16:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:41:23 | INFO | train_inner | epoch 111:     60 / 64 loss=5.804, ppl=55.88, wps=6276.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.77, train_wall=492, gb_free=6.1, wall=38037
2022-02-02 16:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:42:08 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.991 | ppl 1017.65 | wps 8252.4 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.263
2022-02-02 16:42:08 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 16:42:08 | INFO | train | epoch 111 | loss 5.79 | ppl 55.32 | wps 6101.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.787 | train_wall 314 | gb_free 6.1 | wall 38082
KL Stats: Epoch 111 Divergences: Uniform: 2.958093860971626 Unigram: 3.7281230741535563
2022-02-02 16:42:08 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 16:42:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:47:50 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.021 | ppl 1038.84 | wps 8270.1 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.263
2022-02-02 16:47:50 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 16:47:50 | INFO | train | epoch 112 | loss 5.775 | ppl 54.76 | wps 6108.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.773 | train_wall 314 | gb_free 6.1 | wall 38424
KL Stats: Epoch 112 Divergences: Uniform: 2.966727498368163 Unigram: 3.7342561583385647
2022-02-02 16:47:50 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 16:47:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:50:29 | INFO | train_inner | epoch 113:     32 / 64 loss=5.765, ppl=54.37, wps=5977.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.767, train_wall=490, gb_free=6.1, wall=38583
2022-02-02 16:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:53:32 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.047 | ppl 1057.93 | wps 8301.9 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.263
2022-02-02 16:53:32 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 16:53:32 | INFO | train | epoch 113 | loss 5.761 | ppl 54.21 | wps 6111.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.771 | train_wall 314 | gb_free 6.1 | wall 38766
KL Stats: Epoch 113 Divergences: Uniform: 2.961106369985351 Unigram: 3.7482484988091103
2022-02-02 16:53:32 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 16:53:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:58:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:59:15 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.947 | ppl 986.97 | wps 8293.8 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.263
2022-02-02 16:59:15 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 16:59:15 | INFO | train | epoch 114 | loss 5.749 | ppl 53.77 | wps 6093.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.797 | train_wall 315 | gb_free 6.1 | wall 39109
KL Stats: Epoch 114 Divergences: Uniform: 2.970454406484307 Unigram: 3.7509536440511093
2022-02-02 16:59:15 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 16:59:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:59:35 | INFO | train_inner | epoch 115:      4 / 64 loss=5.758, ppl=54.13, wps=5971.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.792, train_wall=491, gb_free=6.1, wall=39129
2022-02-02 17:04:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:04:58 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.983 | ppl 1012.24 | wps 8214.3 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.263
2022-02-02 17:04:58 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 17:04:58 | INFO | train | epoch 115 | loss 5.736 | ppl 53.3 | wps 6088.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.786 | train_wall 315 | gb_free 6.1 | wall 39452
KL Stats: Epoch 115 Divergences: Uniform: 2.9760433874075223 Unigram: 3.764813000712456
2022-02-02 17:04:58 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 17:04:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:08:16 | INFO | train_inner | epoch 116:     40 / 64 loss=5.723, ppl=52.81, wps=6262.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.79, train_wall=493, gb_free=6.1, wall=39650
2022-02-02 17:10:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:10:41 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.093 | ppl 1092.56 | wps 8293.5 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.263
2022-02-02 17:10:41 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 17:10:41 | INFO | train | epoch 116 | loss 5.724 | ppl 52.85 | wps 6093.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.783 | train_wall 315 | gb_free 6.1 | wall 39794
KL Stats: Epoch 116 Divergences: Uniform: 2.9759455376924326 Unigram: 3.7750709627238686
2022-02-02 17:10:41 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 17:10:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:15:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:16:23 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 9.98 | ppl 1010.23 | wps 8266.3 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.263
2022-02-02 17:16:23 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 17:16:23 | INFO | train | epoch 117 | loss 5.712 | ppl 52.42 | wps 6094.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.81 | train_wall 315 | gb_free 6.1 | wall 40137
KL Stats: Epoch 117 Divergences: Uniform: 2.9767349280625304 Unigram: 3.779241468130722
2022-02-02 17:16:23 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 17:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:17:23 | INFO | train_inner | epoch 118:     12 / 64 loss=5.717, ppl=52.6, wps=5965.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.8, train_wall=491, gb_free=6.1, wall=40197
2022-02-02 17:21:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:22:06 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.037 | ppl 1050.63 | wps 8254.8 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.263
2022-02-02 17:22:06 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 17:22:06 | INFO | train | epoch 118 | loss 5.698 | ppl 51.92 | wps 6089.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.81 | train_wall 315 | gb_free 6.1 | wall 40480
KL Stats: Epoch 118 Divergences: Uniform: 2.9807783656791216 Unigram: 3.7967633902629747
2022-02-02 17:22:06 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 17:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:26:04 | INFO | train_inner | epoch 119:     48 / 64 loss=5.693, ppl=51.73, wps=6266.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.828, train_wall=493, gb_free=6.1, wall=40718
2022-02-02 17:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:27:49 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.017 | ppl 1036.42 | wps 8283.5 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.263
2022-02-02 17:27:49 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 17:27:49 | INFO | train | epoch 119 | loss 5.688 | ppl 51.55 | wps 6096.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.843 | train_wall 315 | gb_free 6.1 | wall 40823
KL Stats: Epoch 119 Divergences: Uniform: 2.985451890794743 Unigram: 3.807019599215274
2022-02-02 17:27:49 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 17:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:33:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:33:31 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.049 | ppl 1059.34 | wps 8245.9 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.263
2022-02-02 17:33:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 17:33:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint120.pt
2022-02-02 17:33:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint120.pt
2022-02-02 17:33:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.049) (writing took 3.1026075473055243 seconds)
2022-02-02 17:33:34 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 17:33:34 | INFO | train | epoch 120 | loss 5.677 | ppl 51.17 | wps 6048.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.839 | train_wall 314 | gb_free 6.1 | wall 41168
KL Stats: Epoch 120 Divergences: Uniform: 2.9877884148810634 Unigram: 3.810428083075241
2022-02-02 17:33:34 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 17:33:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:35:13 | INFO | train_inner | epoch 121:     20 / 64 loss=5.675, ppl=51.08, wps=5937.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.829, train_wall=490, gb_free=6.1, wall=41267
2022-02-02 17:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:39:17 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.11 | ppl 1105.18 | wps 8237.5 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.263
2022-02-02 17:39:17 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 17:39:17 | INFO | train | epoch 121 | loss 5.663 | ppl 50.67 | wps 6088.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.817 | train_wall 315 | gb_free 6.1 | wall 41511
KL Stats: Epoch 121 Divergences: Uniform: 2.988168097896889 Unigram: 3.8255706550913073
2022-02-02 17:39:17 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 17:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:43:55 | INFO | train_inner | epoch 122:     56 / 64 loss=5.662, ppl=50.64, wps=6260.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.834, train_wall=493, gb_free=6.1, wall=41789
2022-02-02 17:44:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:45:00 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.018 | ppl 1036.75 | wps 8286.7 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.263
2022-02-02 17:45:00 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 17:45:00 | INFO | train | epoch 122 | loss 5.654 | ppl 50.34 | wps 6089.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.84 | train_wall 315 | gb_free 6.1 | wall 41854
KL Stats: Epoch 122 Divergences: Uniform: 2.9921564274875525 Unigram: 3.8324755236036876
2022-02-02 17:45:00 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 17:45:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:50:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:50:43 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.108 | ppl 1103.57 | wps 8236.4 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.263
2022-02-02 17:50:43 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 17:50:43 | INFO | train | epoch 123 | loss 5.641 | ppl 49.9 | wps 6088.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.831 | train_wall 315 | gb_free 6.1 | wall 42197
KL Stats: Epoch 123 Divergences: Uniform: 2.993951509647564 Unigram: 3.8412269686679017
2022-02-02 17:50:43 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 17:50:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:53:02 | INFO | train_inner | epoch 124:     28 / 64 loss=5.632, ppl=49.61, wps=5960, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.834, train_wall=492, gb_free=6.1, wall=42336
2022-02-02 17:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:56:27 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.072 | ppl 1076.58 | wps 8225.7 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.263
2022-02-02 17:56:27 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 17:56:27 | INFO | train | epoch 124 | loss 5.63 | ppl 49.53 | wps 6079.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.847 | train_wall 315 | gb_free 6.1 | wall 42541
KL Stats: Epoch 124 Divergences: Uniform: 3.0037683875519487 Unigram: 3.8494776809580635
2022-02-02 17:56:27 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 17:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:01:44 | INFO | train_inner | epoch 125:     64 / 64 loss=5.635, ppl=49.68, wps=6252.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.84, train_wall=492, gb_free=6.1, wall=42858
2022-02-02 18:01:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:02:10 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.114 | ppl 1108.19 | wps 8271.7 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.263
2022-02-02 18:02:10 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 18:02:10 | INFO | train | epoch 125 | loss 5.619 | ppl 49.16 | wps 6082.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.836 | train_wall 315 | gb_free 6.1 | wall 42884
KL Stats: Epoch 125 Divergences: Uniform: 2.996448849340677 Unigram: 3.861713796946614
2022-02-02 18:02:10 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 18:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:07:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:07:53 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.11 | ppl 1105.31 | wps 8240.6 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.263
2022-02-02 18:07:53 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 18:07:53 | INFO | train | epoch 126 | loss 5.611 | ppl 48.89 | wps 6094.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.895 | train_wall 315 | gb_free 6.1 | wall 43227
KL Stats: Epoch 126 Divergences: Uniform: 3.00272415491723 Unigram: 3.8642360915409637
2022-02-02 18:07:53 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 18:07:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:10:51 | INFO | train_inner | epoch 127:     36 / 64 loss=5.595, ppl=48.34, wps=5967.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.869, train_wall=492, gb_free=6.1, wall=43405
2022-02-02 18:13:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:13:36 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.153 | ppl 1138.89 | wps 8257.6 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.263
2022-02-02 18:13:36 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 18:13:36 | INFO | train | epoch 127 | loss 5.6 | ppl 48.49 | wps 6092.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.847 | train_wall 315 | gb_free 6.1 | wall 43570
KL Stats: Epoch 127 Divergences: Uniform: 3.0013521498592493 Unigram: 3.8767481269277684
2022-02-02 18:13:36 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 18:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:18:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:19:19 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.141 | ppl 1129.49 | wps 8218 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.263
2022-02-02 18:19:19 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 18:19:19 | INFO | train | epoch 128 | loss 5.589 | ppl 48.13 | wps 6084.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.871 | train_wall 315 | gb_free 6.1 | wall 43913
KL Stats: Epoch 128 Divergences: Uniform: 3.009617841249035 Unigram: 3.8788644153173375
2022-02-02 18:19:19 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 18:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:19:59 | INFO | train_inner | epoch 129:      8 / 64 loss=5.6, ppl=48.49, wps=5955.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.873, train_wall=492, gb_free=6.1, wall=43953
2022-02-02 18:24:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:25:03 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.124 | ppl 1116.22 | wps 8186.7 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.263
2022-02-02 18:25:03 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 18:25:03 | INFO | train | epoch 129 | loss 5.578 | ppl 47.77 | wps 6072.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.88 | train_wall 316 | gb_free 6.1 | wall 44257
KL Stats: Epoch 129 Divergences: Uniform: 3.0101974339576176 Unigram: 3.8947476593589867
2022-02-02 18:25:03 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 18:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:28:41 | INFO | train_inner | epoch 130:     44 / 64 loss=5.571, ppl=47.55, wps=6253.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.873, train_wall=493, gb_free=6.1, wall=44475
2022-02-02 18:30:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:30:46 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.101 | ppl 1098.57 | wps 8225.9 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.263
2022-02-02 18:30:46 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 18:30:46 | INFO | train | epoch 130 | loss 5.569 | ppl 47.46 | wps 6087.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.883 | train_wall 315 | gb_free 6.1 | wall 44600
KL Stats: Epoch 130 Divergences: Uniform: 3.0090554516102754 Unigram: 3.899590235522626
2022-02-02 18:30:46 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 18:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:36:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:36:29 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.09 | ppl 1090.01 | wps 8266.2 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.263
2022-02-02 18:36:29 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 18:36:29 | INFO | train | epoch 131 | loss 5.558 | ppl 47.12 | wps 6088.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.883 | train_wall 315 | gb_free 6.1 | wall 44943
KL Stats: Epoch 131 Divergences: Uniform: 3.0168287240818668 Unigram: 3.9056722005631626
2022-02-02 18:36:29 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 18:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:37:49 | INFO | train_inner | epoch 132:     16 / 64 loss=5.553, ppl=46.94, wps=5957.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.886, train_wall=492, gb_free=6.1, wall=45023
2022-02-02 18:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:42:12 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.054 | ppl 1062.88 | wps 8266.3 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.263
2022-02-02 18:42:12 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 18:42:12 | INFO | train | epoch 132 | loss 5.548 | ppl 46.78 | wps 6085 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.875 | train_wall 315 | gb_free 6.1 | wall 45286
KL Stats: Epoch 132 Divergences: Uniform: 3.023490179182951 Unigram: 3.9216787132537476
2022-02-02 18:42:12 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 18:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:46:31 | INFO | train_inner | epoch 133:     52 / 64 loss=5.55, ppl=46.86, wps=6258.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.881, train_wall=493, gb_free=6.1, wall=45545
2022-02-02 18:47:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:47:56 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.08 | ppl 1082.13 | wps 8264.7 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.263
2022-02-02 18:47:56 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 18:47:56 | INFO | train | epoch 133 | loss 5.54 | ppl 46.52 | wps 6086.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.883 | train_wall 315 | gb_free 6.1 | wall 45629
KL Stats: Epoch 133 Divergences: Uniform: 3.0228400943652822 Unigram: 3.9197706342325493
2022-02-02 18:47:56 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 18:47:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:53:39 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.12 | ppl 1112.67 | wps 8225.9 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.263
2022-02-02 18:53:39 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 18:53:39 | INFO | train | epoch 134 | loss 5.531 | ppl 46.23 | wps 6080.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.9 | train_wall 315 | gb_free 6.1 | wall 45973
KL Stats: Epoch 134 Divergences: Uniform: 3.0309680132563255 Unigram: 3.9367232796778637
2022-02-02 18:53:39 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 18:53:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:55:38 | INFO | train_inner | epoch 135:     24 / 64 loss=5.524, ppl=46.02, wps=5954.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.903, train_wall=492, gb_free=6.1, wall=46092
2022-02-02 18:58:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:59:22 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.098 | ppl 1095.65 | wps 8227.1 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.263
2022-02-02 18:59:22 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 18:59:22 | INFO | train | epoch 135 | loss 5.522 | ppl 45.94 | wps 6092.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.9 | train_wall 315 | gb_free 6.1 | wall 46316
KL Stats: Epoch 135 Divergences: Uniform: 3.0260867617472087 Unigram: 3.938737109032304
2022-02-02 18:59:22 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 18:59:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:04:20 | INFO | train_inner | epoch 136:     60 / 64 loss=5.524, ppl=46.01, wps=6258.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.903, train_wall=493, gb_free=6.1, wall=46614
2022-02-02 19:04:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:05:05 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.083 | ppl 1084.68 | wps 8262 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.263
2022-02-02 19:05:05 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 19:05:05 | INFO | train | epoch 136 | loss 5.511 | ppl 45.6 | wps 6077.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.907 | train_wall 316 | gb_free 6.1 | wall 46659
KL Stats: Epoch 136 Divergences: Uniform: 3.0328647021553117 Unigram: 3.9580820636436034
2022-02-02 19:05:05 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 19:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:10:49 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.106 | ppl 1102.16 | wps 8220.4 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.263
2022-02-02 19:10:49 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 19:10:49 | INFO | train | epoch 137 | loss 5.502 | ppl 45.33 | wps 6080.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.911 | train_wall 315 | gb_free 6.1 | wall 47003
KL Stats: Epoch 137 Divergences: Uniform: 3.0331568491495933 Unigram: 3.9637276331583657
2022-02-02 19:10:49 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 19:10:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:13:28 | INFO | train_inner | epoch 138:     32 / 64 loss=5.488, ppl=44.87, wps=5952.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.911, train_wall=492, gb_free=6.1, wall=47162
2022-02-02 19:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:16:32 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.189 | ppl 1167.37 | wps 8251.4 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.263
2022-02-02 19:16:32 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 19:16:32 | INFO | train | epoch 138 | loss 5.494 | ppl 45.06 | wps 6080.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.925 | train_wall 315 | gb_free 6.1 | wall 47346
KL Stats: Epoch 138 Divergences: Uniform: 3.030814252109248 Unigram: 3.9625214895459213
2022-02-02 19:16:32 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 19:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:22:16 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.187 | ppl 1165.48 | wps 8251.3 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.263
2022-02-02 19:22:16 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 19:22:16 | INFO | train | epoch 139 | loss 5.485 | ppl 44.79 | wps 6080.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.927 | train_wall 315 | gb_free 6.1 | wall 47690
KL Stats: Epoch 139 Divergences: Uniform: 3.0318663846213605 Unigram: 3.972517713461248
2022-02-02 19:22:16 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 19:22:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:22:36 | INFO | train_inner | epoch 140:      4 / 64 loss=5.499, ppl=45.23, wps=5950.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.929, train_wall=492, gb_free=6.1, wall=47710
2022-02-02 19:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:27:59 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.162 | ppl 1146.05 | wps 8265.9 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.263
2022-02-02 19:27:59 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 19:27:59 | INFO | train | epoch 140 | loss 5.476 | ppl 44.5 | wps 6082 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.951 | train_wall 315 | gb_free 6.1 | wall 48033
KL Stats: Epoch 140 Divergences: Uniform: 3.0370358895895695 Unigram: 3.979135794159152
2022-02-02 19:27:59 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 19:27:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:31:18 | INFO | train_inner | epoch 141:     40 / 64 loss=5.467, ppl=44.22, wps=6260.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.958, train_wall=493, gb_free=6.1, wall=48232
2022-02-02 19:33:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:33:42 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.2 | ppl 1176.38 | wps 8246 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.263
2022-02-02 19:33:42 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 19:33:42 | INFO | train | epoch 141 | loss 5.47 | ppl 44.31 | wps 6092.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.972 | train_wall 315 | gb_free 6.1 | wall 48376
KL Stats: Epoch 141 Divergences: Uniform: 3.035366676989207 Unigram: 3.991336903569966
2022-02-02 19:33:42 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 19:33:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:39:26 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.134 | ppl 1123.85 | wps 8260.8 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.263
2022-02-02 19:39:26 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 19:39:26 | INFO | train | epoch 142 | loss 5.46 | ppl 44 | wps 6074.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.919 | train_wall 316 | gb_free 6.1 | wall 48720
KL Stats: Epoch 142 Divergences: Uniform: 3.0412919887478385 Unigram: 3.996752054279664
2022-02-02 19:39:26 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 19:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:40:26 | INFO | train_inner | epoch 143:     12 / 64 loss=5.464, ppl=44.13, wps=5951.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.939, train_wall=492, gb_free=6.1, wall=48780
2022-02-02 19:44:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:45:09 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.229 | ppl 1200.4 | wps 8286.5 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.263
2022-02-02 19:45:09 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 19:45:09 | INFO | train | epoch 143 | loss 5.454 | ppl 43.82 | wps 6095.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.98 | train_wall 315 | gb_free 6.1 | wall 49063
KL Stats: Epoch 143 Divergences: Uniform: 3.038528144174399 Unigram: 4.000387053779639
2022-02-02 19:45:09 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 19:45:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:49:07 | INFO | train_inner | epoch 144:     48 / 64 loss=5.451, ppl=43.75, wps=6267.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.968, train_wall=493, gb_free=6.1, wall=49301
2022-02-02 19:50:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:50:52 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.198 | ppl 1174.57 | wps 8218.7 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.263
2022-02-02 19:50:52 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 19:50:52 | INFO | train | epoch 144 | loss 5.444 | ppl 43.53 | wps 6090.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.961 | train_wall 315 | gb_free 6.1 | wall 49406
KL Stats: Epoch 144 Divergences: Uniform: 3.03777895733562 Unigram: 4.009803437361228
2022-02-02 19:50:52 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 19:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:56:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:56:35 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.155 | ppl 1140.04 | wps 8256.9 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.263
2022-02-02 19:56:35 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 19:56:35 | INFO | train | epoch 145 | loss 5.436 | ppl 43.28 | wps 6089.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.976 | train_wall 315 | gb_free 6.1 | wall 49749
KL Stats: Epoch 145 Divergences: Uniform: 3.043664673831904 Unigram: 4.015900777172524
2022-02-02 19:56:35 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 19:56:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:58:14 | INFO | train_inner | epoch 146:     20 / 64 loss=5.43, ppl=43.11, wps=5958.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.97, train_wall=492, gb_free=6.1, wall=49848
2022-02-02 20:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:02:18 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.152 | ppl 1138.03 | wps 8281.5 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.263
2022-02-02 20:02:18 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 20:02:18 | INFO | train | epoch 146 | loss 5.427 | ppl 43.02 | wps 6080.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.959 | train_wall 316 | gb_free 6.1 | wall 50092
KL Stats: Epoch 146 Divergences: Uniform: 3.044446042734308 Unigram: 4.023272409578773
2022-02-02 20:02:18 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 20:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:06:56 | INFO | train_inner | epoch 147:     56 / 64 loss=5.43, ppl=43.11, wps=6257.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.996, train_wall=493, gb_free=6.1, wall=50370
2022-02-02 20:07:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:08:01 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.206 | ppl 1180.99 | wps 8231.4 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.263
2022-02-02 20:08:01 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 20:08:01 | INFO | train | epoch 147 | loss 5.423 | ppl 42.89 | wps 6083.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 1.011 | train_wall 315 | gb_free 6.1 | wall 50435
KL Stats: Epoch 147 Divergences: Uniform: 3.0446883138952074 Unigram: 4.023834724400872
2022-02-02 20:08:01 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 20:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:13:44 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.279 | ppl 1242.43 | wps 8274.6 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.263
2022-02-02 20:13:44 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 20:13:44 | INFO | train | epoch 148 | loss 5.412 | ppl 42.58 | wps 6097.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.992 | train_wall 315 | gb_free 6.1 | wall 50778
KL Stats: Epoch 148 Divergences: Uniform: 3.0435524293702283 Unigram: 4.032355249695285
2022-02-02 20:13:44 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 20:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:16:03 | INFO | train_inner | epoch 149:     28 / 64 loss=5.406, ppl=42.39, wps=5964.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.995, train_wall=491, gb_free=6.1, wall=50917
2022-02-02 20:19:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:19:27 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.237 | ppl 1207.2 | wps 8265.5 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.263
2022-02-02 20:19:27 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 20:19:27 | INFO | train | epoch 149 | loss 5.407 | ppl 42.42 | wps 6092.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.983 | train_wall 315 | gb_free 6.1 | wall 51121
KL Stats: Epoch 149 Divergences: Uniform: 3.0484479037698407 Unigram: 4.041948836801108
2022-02-02 20:19:27 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 20:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:24:43 | INFO | train_inner | epoch 150:     64 / 64 loss=5.411, ppl=42.55, wps=6266.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.984, train_wall=491, gb_free=6.1, wall=51437
2022-02-02 20:24:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:25:10 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.254 | ppl 1221.19 | wps 8248.4 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.263
2022-02-02 20:25:10 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 20:25:10 | INFO | train | epoch 150 | loss 5.398 | ppl 42.17 | wps 6092.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.992 | train_wall 315 | gb_free 6.1 | wall 51464
KL Stats: Epoch 150 Divergences: Uniform: 3.049530188030949 Unigram: 4.050389819604473
2022-02-02 20:25:10 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 20:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:30:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:30:52 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.265 | ppl 1230.28 | wps 8290.4 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.263
2022-02-02 20:30:52 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 20:30:52 | INFO | train | epoch 151 | loss 5.392 | ppl 41.98 | wps 6108.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.02 | train_wall 314 | gb_free 6.1 | wall 51806
KL Stats: Epoch 151 Divergences: Uniform: 3.0521546459917595 Unigram: 4.0551798467471025
2022-02-02 20:30:52 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 20:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:33:50 | INFO | train_inner | epoch 152:     36 / 64 loss=5.381, ppl=41.67, wps=5975, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.014, train_wall=492, gb_free=6.1, wall=51984
2022-02-02 20:36:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:36:34 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.195 | ppl 1172.35 | wps 8248.1 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.263
2022-02-02 20:36:34 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 20:36:34 | INFO | train | epoch 152 | loss 5.384 | ppl 41.75 | wps 6097.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.039 | train_wall 314 | gb_free 6.1 | wall 52148
KL Stats: Epoch 152 Divergences: Uniform: 3.0582321842564406 Unigram: 4.062248972855935
2022-02-02 20:36:34 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 20:36:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:41:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:42:17 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.254 | ppl 1220.75 | wps 8227.6 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.263
2022-02-02 20:42:17 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 20:42:17 | INFO | train | epoch 153 | loss 5.376 | ppl 41.52 | wps 6097.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.996 | train_wall 314 | gb_free 6.1 | wall 52491
KL Stats: Epoch 153 Divergences: Uniform: 3.0561260770703758 Unigram: 4.066441196470434
2022-02-02 20:42:17 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 20:42:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:42:56 | INFO | train_inner | epoch 154:      8 / 64 loss=5.382, ppl=41.69, wps=5967.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=1.026, train_wall=491, gb_free=6.1, wall=52530
2022-02-02 20:47:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:48:00 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.261 | ppl 1227.07 | wps 8254.5 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.263
2022-02-02 20:48:00 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 20:48:00 | INFO | train | epoch 154 | loss 5.371 | ppl 41.39 | wps 6089.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.016 | train_wall 315 | gb_free 6.1 | wall 52834
KL Stats: Epoch 154 Divergences: Uniform: 3.058992391155394 Unigram: 4.074230503305773
2022-02-02 20:48:00 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 20:48:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:51:38 | INFO | train_inner | epoch 155:     44 / 64 loss=5.361, ppl=41.1, wps=6265.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.044, train_wall=493, gb_free=6.1, wall=53052
2022-02-02 20:53:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:53:43 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.201 | ppl 1177.2 | wps 8243 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.263
2022-02-02 20:53:43 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 20:53:43 | INFO | train | epoch 155 | loss 5.363 | ppl 41.16 | wps 6090 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.077 | train_wall 315 | gb_free 6.1 | wall 53177
KL Stats: Epoch 155 Divergences: Uniform: 3.0561088992921817 Unigram: 4.080368934924265
2022-02-02 20:53:43 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 20:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:58:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:59:25 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.248 | ppl 1215.81 | wps 8286 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.263
2022-02-02 20:59:25 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 20:59:25 | INFO | train | epoch 156 | loss 5.356 | ppl 40.95 | wps 6097.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.059 | train_wall 315 | gb_free 6.1 | wall 53519
KL Stats: Epoch 156 Divergences: Uniform: 3.058789168365045 Unigram: 4.0836265941117
2022-02-02 20:59:25 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 20:59:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:00:44 | INFO | train_inner | epoch 157:     16 / 64 loss=5.363, ppl=41.16, wps=5964.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.058, train_wall=491, gb_free=6.1, wall=53598
2022-02-02 21:04:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:05:08 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.294 | ppl 1255.21 | wps 8236 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.263
2022-02-02 21:05:08 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 21:05:08 | INFO | train | epoch 157 | loss 5.35 | ppl 40.79 | wps 6099.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.047 | train_wall 314 | gb_free 6.1 | wall 53862
KL Stats: Epoch 157 Divergences: Uniform: 3.0643361377758396 Unigram: 4.0923121050628515
2022-02-02 21:05:08 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 21:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:09:25 | INFO | train_inner | epoch 158:     52 / 64 loss=5.345, ppl=40.64, wps=6273.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.046, train_wall=492, gb_free=6.1, wall=54119
2022-02-02 21:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:10:50 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.28 | ppl 1242.93 | wps 8288.5 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.263
2022-02-02 21:10:50 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 21:10:50 | INFO | train | epoch 158 | loss 5.344 | ppl 40.61 | wps 6099.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.048 | train_wall 314 | gb_free 6.1 | wall 54204
KL Stats: Epoch 158 Divergences: Uniform: 3.063007871574473 Unigram: 4.098680023399925
2022-02-02 21:10:50 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 21:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:16:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:16:33 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.266 | ppl 1231.38 | wps 8248.6 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.263
2022-02-02 21:16:33 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 21:16:33 | INFO | train | epoch 159 | loss 5.339 | ppl 40.48 | wps 6084.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.075 | train_wall 315 | gb_free 6.1 | wall 54547
KL Stats: Epoch 159 Divergences: Uniform: 3.0649290751521976 Unigram: 4.104171250483432
2022-02-02 21:16:33 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 21:16:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:18:32 | INFO | train_inner | epoch 160:     24 / 64 loss=5.332, ppl=40.28, wps=5960.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.073, train_wall=492, gb_free=6.1, wall=54666
2022-02-02 21:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:22:16 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.21 | ppl 1184.61 | wps 8276.5 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.263
2022-02-02 21:22:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 21:22:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint160.pt
2022-02-02 21:22:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint160.pt
2022-02-02 21:22:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.21) (writing took 3.088079488836229 seconds)
2022-02-02 21:22:19 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 21:22:19 | INFO | train | epoch 160 | loss 5.331 | ppl 40.25 | wps 6042.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.082 | train_wall 315 | gb_free 6.1 | wall 54893
KL Stats: Epoch 160 Divergences: Uniform: 3.0668996004755638 Unigram: 4.1146371788942595
2022-02-02 21:22:19 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 21:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:27:17 | INFO | train_inner | epoch 161:     60 / 64 loss=5.335, ppl=40.36, wps=6231.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.079, train_wall=492, gb_free=6.1, wall=55191
2022-02-02 21:27:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:28:02 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.256 | ppl 1223.07 | wps 8238 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.263
2022-02-02 21:28:02 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 21:28:02 | INFO | train | epoch 161 | loss 5.324 | ppl 40.06 | wps 6091.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.078 | train_wall 315 | gb_free 6.1 | wall 55236
KL Stats: Epoch 161 Divergences: Uniform: 3.06791492752959 Unigram: 4.111662040537746
2022-02-02 21:28:02 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 21:28:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:33:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:33:44 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.287 | ppl 1249.58 | wps 8263.5 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.263
2022-02-02 21:33:44 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 21:33:44 | INFO | train | epoch 162 | loss 5.317 | ppl 39.87 | wps 6097.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.07 | train_wall 315 | gb_free 6.1 | wall 55578
KL Stats: Epoch 162 Divergences: Uniform: 3.0674641628663273 Unigram: 4.117579812956978
2022-02-02 21:33:44 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 21:33:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:36:23 | INFO | train_inner | epoch 163:     32 / 64 loss=5.31, ppl=39.68, wps=5967, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.076, train_wall=491, gb_free=6.1, wall=55737
2022-02-02 21:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:39:27 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.319 | ppl 1277.38 | wps 8247.2 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.263
2022-02-02 21:39:27 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 21:39:27 | INFO | train | epoch 163 | loss 5.31 | ppl 39.68 | wps 6099.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.084 | train_wall 314 | gb_free 6.1 | wall 55921
KL Stats: Epoch 163 Divergences: Uniform: 3.0679643419759306 Unigram: 4.124607820379644
2022-02-02 21:39:27 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 21:39:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:45:10 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.311 | ppl 1270 | wps 8245.1 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.263
2022-02-02 21:45:10 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 21:45:10 | INFO | train | epoch 164 | loss 5.307 | ppl 39.6 | wps 6094.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.144 | train_wall 315 | gb_free 6.1 | wall 56263
KL Stats: Epoch 164 Divergences: Uniform: 3.0783977346636164 Unigram: 4.13380259553221
2022-02-02 21:45:10 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 21:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:45:29 | INFO | train_inner | epoch 165:      4 / 64 loss=5.314, ppl=39.77, wps=5967.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.122, train_wall=491, gb_free=6.1, wall=56283
2022-02-02 21:50:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:50:52 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.259 | ppl 1225.45 | wps 8273.9 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.263
2022-02-02 21:50:52 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 21:50:52 | INFO | train | epoch 165 | loss 5.297 | ppl 39.32 | wps 6096.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.054 | train_wall 315 | gb_free 6.1 | wall 56606
KL Stats: Epoch 165 Divergences: Uniform: 3.0734225148049874 Unigram: 4.138067992591774
2022-02-02 21:50:52 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 21:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:54:11 | INFO | train_inner | epoch 166:     40 / 64 loss=5.286, ppl=39, wps=6270.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.064, train_wall=492, gb_free=6.1, wall=56805
2022-02-02 21:56:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:56:34 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.278 | ppl 1241.72 | wps 8274.6 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.263
2022-02-02 21:56:34 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 21:56:34 | INFO | train | epoch 166 | loss 5.292 | ppl 39.18 | wps 6101.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.085 | train_wall 314 | gb_free 6.1 | wall 56948
KL Stats: Epoch 166 Divergences: Uniform: 3.0709363145400723 Unigram: 4.142485466418243
2022-02-02 21:56:34 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 21:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:01:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:02:16 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.323 | ppl 1281 | wps 8269.6 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.263
2022-02-02 22:02:16 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 22:02:16 | INFO | train | epoch 167 | loss 5.29 | ppl 39.11 | wps 6119.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.134 | train_wall 313 | gb_free 6.1 | wall 57290
KL Stats: Epoch 167 Divergences: Uniform: 3.074552533894288 Unigram: 4.15095160264626
2022-02-02 22:02:16 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 22:02:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:03:15 | INFO | train_inner | epoch 168:     12 / 64 loss=5.296, ppl=39.29, wps=5986.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.115, train_wall=489, gb_free=6.1, wall=57349
2022-02-02 22:07:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:07:57 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.276 | ppl 1240.2 | wps 8299.3 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.263
2022-02-02 22:07:57 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 22:07:57 | INFO | train | epoch 168 | loss 5.28 | ppl 38.86 | wps 6123 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.076 | train_wall 313 | gb_free 6.1 | wall 57631
KL Stats: Epoch 168 Divergences: Uniform: 3.0766573140634943 Unigram: 4.155138789311124
2022-02-02 22:07:57 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 22:07:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:11:54 | INFO | train_inner | epoch 169:     48 / 64 loss=5.276, ppl=38.75, wps=6300.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.097, train_wall=490, gb_free=6.1, wall=57868
2022-02-02 22:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:13:38 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.336 | ppl 1292.51 | wps 8328.5 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.263
2022-02-02 22:13:38 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 22:13:38 | INFO | train | epoch 169 | loss 5.276 | ppl 38.75 | wps 6128.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.123 | train_wall 313 | gb_free 6.1 | wall 57972
KL Stats: Epoch 169 Divergences: Uniform: 3.0761195427039123 Unigram: 4.156817084251909
2022-02-02 22:13:38 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 22:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:18:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:19:19 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.365 | ppl 1319.12 | wps 8311.9 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.263
2022-02-02 22:19:19 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 22:19:19 | INFO | train | epoch 170 | loss 5.27 | ppl 38.59 | wps 6126.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.13 | train_wall 313 | gb_free 6.1 | wall 58312
KL Stats: Epoch 170 Divergences: Uniform: 3.074024201920971 Unigram: 4.166379379157326
2022-02-02 22:19:19 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 22:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:20:57 | INFO | train_inner | epoch 171:     20 / 64 loss=5.272, ppl=38.65, wps=5996.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.129, train_wall=489, gb_free=6.1, wall=58411
2022-02-02 22:24:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:25:00 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.328 | ppl 1285.15 | wps 8284.5 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.263
2022-02-02 22:25:00 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 22:25:00 | INFO | train | epoch 171 | loss 5.266 | ppl 38.49 | wps 6119.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.155 | train_wall 313 | gb_free 6.1 | wall 58654
KL Stats: Epoch 171 Divergences: Uniform: 3.0710800060207877 Unigram: 4.160613739802686
2022-02-02 22:25:00 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 22:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:29:36 | INFO | train_inner | epoch 172:     56 / 64 loss=5.262, ppl=38.37, wps=6297.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.159, train_wall=490, gb_free=6.1, wall=58930
2022-02-02 22:30:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:30:41 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.307 | ppl 1267.05 | wps 8315.5 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.263
2022-02-02 22:30:41 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 22:30:41 | INFO | train | epoch 172 | loss 5.26 | ppl 38.33 | wps 6125.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.147 | train_wall 313 | gb_free 6.1 | wall 58995
KL Stats: Epoch 172 Divergences: Uniform: 3.078637662168825 Unigram: 4.174525928031694
2022-02-02 22:30:41 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 22:30:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:36:22 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.331 | ppl 1287.74 | wps 8280.4 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.263
2022-02-02 22:36:22 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 22:36:22 | INFO | train | epoch 173 | loss 5.254 | ppl 38.16 | wps 6124.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.206 | train_wall 313 | gb_free 6.1 | wall 59336
KL Stats: Epoch 173 Divergences: Uniform: 3.0785535066539427 Unigram: 4.178173106033115
2022-02-02 22:36:22 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 22:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:38:40 | INFO | train_inner | epoch 174:     28 / 64 loss=5.248, ppl=38, wps=5996.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.187, train_wall=488, gb_free=6.1, wall=59474
2022-02-02 22:41:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:42:03 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.355 | ppl 1310 | wps 8270.9 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.263
2022-02-02 22:42:03 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 22:42:03 | INFO | train | epoch 174 | loss 5.249 | ppl 38.04 | wps 6125.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.199 | train_wall 313 | gb_free 6.1 | wall 59677
KL Stats: Epoch 174 Divergences: Uniform: 3.086661678285425 Unigram: 4.183951280300108
2022-02-02 22:42:03 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 22:42:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:47:17 | INFO | train_inner | epoch 175:     64 / 64 loss=5.257, ppl=38.23, wps=6306, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.198, train_wall=488, gb_free=6.1, wall=59991
2022-02-02 22:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:47:43 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.373 | ppl 1325.98 | wps 8303.3 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.263
2022-02-02 22:47:43 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 22:47:43 | INFO | train | epoch 175 | loss 5.243 | ppl 37.88 | wps 6134.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.177 | train_wall 313 | gb_free 6.1 | wall 60017
KL Stats: Epoch 175 Divergences: Uniform: 3.0786775416709875 Unigram: 4.183553617581547
2022-02-02 22:47:43 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 22:47:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:52:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:53:25 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.36 | ppl 1313.99 | wps 8288.9 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.263
2022-02-02 22:53:25 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 22:53:25 | INFO | train | epoch 176 | loss 5.238 | ppl 37.74 | wps 6120.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.193 | train_wall 313 | gb_free 6.1 | wall 60358
KL Stats: Epoch 176 Divergences: Uniform: 3.085881026437745 Unigram: 4.191658534952867
2022-02-02 22:53:25 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 22:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:56:22 | INFO | train_inner | epoch 177:     36 / 64 loss=5.226, ppl=37.44, wps=5991.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.193, train_wall=490, gb_free=6.1, wall=60536
2022-02-02 22:58:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:59:05 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.345 | ppl 1300.91 | wps 8319.2 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.263
2022-02-02 22:59:05 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 22:59:05 | INFO | train | epoch 177 | loss 5.233 | ppl 37.6 | wps 6127.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.205 | train_wall 313 | gb_free 6.1 | wall 60699
KL Stats: Epoch 177 Divergences: Uniform: 3.0795535306850117 Unigram: 4.193767847720644
2022-02-02 22:59:05 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 22:59:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:04:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:04:47 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.361 | ppl 1315.36 | wps 8282.3 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.263
2022-02-02 23:04:47 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-02 23:04:47 | INFO | train | epoch 178 | loss 5.226 | ppl 37.42 | wps 6121.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.212 | train_wall 313 | gb_free 6.1 | wall 61041
KL Stats: Epoch 178 Divergences: Uniform: 3.0882751991417585 Unigram: 4.200780834032068
2022-02-02 23:04:47 | INFO | fairseq.trainer | begin training epoch 179
2022-02-02 23:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:05:26 | INFO | train_inner | epoch 179:      8 / 64 loss=5.232, ppl=37.6, wps=5993.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.213, train_wall=489, gb_free=6.1, wall=61080
2022-02-02 23:10:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:10:28 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.374 | ppl 1326.77 | wps 8304.1 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.263
2022-02-02 23:10:28 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-02 23:10:28 | INFO | train | epoch 179 | loss 5.222 | ppl 37.31 | wps 6119.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.217 | train_wall 313 | gb_free 6.1 | wall 61382
KL Stats: Epoch 179 Divergences: Uniform: 3.0861693374643946 Unigram: 4.205292308272333
2022-02-02 23:10:28 | INFO | fairseq.trainer | begin training epoch 180
2022-02-02 23:10:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:14:05 | INFO | train_inner | epoch 180:     44 / 64 loss=5.216, ppl=37.17, wps=6298.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.21, train_wall=490, gb_free=6.1, wall=61599
2022-02-02 23:15:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:16:09 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.303 | ppl 1263.64 | wps 8323.8 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.263
2022-02-02 23:16:09 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-02 23:16:09 | INFO | train | epoch 180 | loss 5.217 | ppl 37.19 | wps 6130.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.2 | train_wall 313 | gb_free 6.1 | wall 61723
KL Stats: Epoch 180 Divergences: Uniform: 3.0901378739742613 Unigram: 4.206479028971842
2022-02-02 23:16:09 | INFO | fairseq.trainer | begin training epoch 181
2022-02-02 23:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:21:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:21:50 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.384 | ppl 1336.44 | wps 8300.6 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.263
2022-02-02 23:21:50 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-02 23:21:50 | INFO | train | epoch 181 | loss 5.214 | ppl 37.11 | wps 6126.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.238 | train_wall 313 | gb_free 6.1 | wall 62063
KL Stats: Epoch 181 Divergences: Uniform: 3.088632050906612 Unigram: 4.216450049090904
2022-02-02 23:21:50 | INFO | fairseq.trainer | begin training epoch 182
2022-02-02 23:21:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:23:09 | INFO | train_inner | epoch 182:     16 / 64 loss=5.215, ppl=37.15, wps=5997.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.234, train_wall=489, gb_free=6.1, wall=62143
2022-02-02 23:27:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:27:31 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.304 | ppl 1263.86 | wps 8288.5 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.263
2022-02-02 23:27:31 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-02 23:27:31 | INFO | train | epoch 182 | loss 5.206 | ppl 36.92 | wps 6119.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.229 | train_wall 313 | gb_free 6.1 | wall 62405
KL Stats: Epoch 182 Divergences: Uniform: 3.091002148519449 Unigram: 4.218993712043
2022-02-02 23:27:31 | INFO | fairseq.trainer | begin training epoch 183
2022-02-02 23:27:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:31:47 | INFO | train_inner | epoch 183:     52 / 64 loss=5.202, ppl=36.82, wps=6300.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.213, train_wall=490, gb_free=6.1, wall=62661
2022-02-02 23:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:33:11 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.395 | ppl 1346.43 | wps 8331.2 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.263
2022-02-02 23:33:11 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-02 23:33:11 | INFO | train | epoch 183 | loss 5.203 | ppl 36.83 | wps 6135.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.221 | train_wall 313 | gb_free 6.1 | wall 62745
KL Stats: Epoch 183 Divergences: Uniform: 3.0880972011005725 Unigram: 4.226559168489255
2022-02-02 23:33:11 | INFO | fairseq.trainer | begin training epoch 184
2022-02-02 23:33:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:38:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:38:52 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.364 | ppl 1317.88 | wps 8339.2 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.263
2022-02-02 23:38:52 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-02 23:38:52 | INFO | train | epoch 184 | loss 5.198 | ppl 36.7 | wps 6136.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.286 | train_wall 313 | gb_free 6.1 | wall 63086
KL Stats: Epoch 184 Divergences: Uniform: 3.090660657345111 Unigram: 4.225708702856099
2022-02-02 23:38:52 | INFO | fairseq.trainer | begin training epoch 185
2022-02-02 23:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:40:50 | INFO | train_inner | epoch 185:     24 / 64 loss=5.194, ppl=36.61, wps=6006.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.275, train_wall=488, gb_free=6.1, wall=63204
2022-02-02 23:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:44:32 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.344 | ppl 1300 | wps 8343.6 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.263
2022-02-02 23:44:32 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-02 23:44:32 | INFO | train | epoch 185 | loss 5.193 | ppl 36.59 | wps 6140.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.25 | train_wall 312 | gb_free 6.1 | wall 63426
KL Stats: Epoch 185 Divergences: Uniform: 3.0911417180995544 Unigram: 4.228488800846308
2022-02-02 23:44:32 | INFO | fairseq.trainer | begin training epoch 186
2022-02-02 23:44:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:49:27 | INFO | train_inner | epoch 186:     60 / 64 loss=5.199, ppl=36.74, wps=6317.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.267, train_wall=489, gb_free=6.1, wall=63721
2022-02-02 23:49:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:50:12 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.376 | ppl 1328.92 | wps 8321.8 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.263
2022-02-02 23:50:12 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-02 23:50:12 | INFO | train | epoch 186 | loss 5.188 | ppl 36.46 | wps 6136.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.278 | train_wall 313 | gb_free 6.1 | wall 63766
KL Stats: Epoch 186 Divergences: Uniform: 3.087595952546602 Unigram: 4.234224862116895
2022-02-02 23:50:12 | INFO | fairseq.trainer | begin training epoch 187
2022-02-02 23:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:55:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:55:52 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.349 | ppl 1303.99 | wps 8297.7 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.263
2022-02-02 23:55:52 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-02 23:55:52 | INFO | train | epoch 187 | loss 5.183 | ppl 36.32 | wps 6147.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.275 | train_wall 312 | gb_free 6.1 | wall 64106
KL Stats: Epoch 187 Divergences: Uniform: 3.0954422493590497 Unigram: 4.242226623081389
2022-02-02 23:55:52 | INFO | fairseq.trainer | begin training epoch 188
2022-02-02 23:55:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:58:30 | INFO | train_inner | epoch 188:     32 / 64 loss=5.17, ppl=36, wps=6009, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.277, train_wall=487, gb_free=6.1, wall=64264
2022-02-03 00:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:01:33 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.337 | ppl 1293.25 | wps 8314.2 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.263
2022-02-03 00:01:33 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-03 00:01:33 | INFO | train | epoch 188 | loss 5.177 | ppl 36.18 | wps 6123.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.295 | train_wall 313 | gb_free 6.1 | wall 64447
KL Stats: Epoch 188 Divergences: Uniform: 3.0949755277942668 Unigram: 4.242736639259023
2022-02-03 00:01:33 | INFO | fairseq.trainer | begin training epoch 189
2022-02-03 00:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:07:14 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.365 | ppl 1318.42 | wps 8325.8 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.263
2022-02-03 00:07:14 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-03 00:07:14 | INFO | train | epoch 189 | loss 5.174 | ppl 36.1 | wps 6131.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.298 | train_wall 313 | gb_free 6.1 | wall 64788
KL Stats: Epoch 189 Divergences: Uniform: 3.0929895642065124 Unigram: 4.250545109318353
2022-02-03 00:07:14 | INFO | fairseq.trainer | begin training epoch 190
2022-02-03 00:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:07:33 | INFO | train_inner | epoch 190:      4 / 64 loss=5.186, ppl=36.41, wps=5997.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.305, train_wall=489, gb_free=6.1, wall=64807
2022-02-03 00:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:12:55 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.381 | ppl 1333.93 | wps 8305.8 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.263
2022-02-03 00:12:55 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-03 00:12:55 | INFO | train | epoch 190 | loss 5.169 | ppl 35.98 | wps 6119.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.298 | train_wall 313 | gb_free 6.1 | wall 65129
KL Stats: Epoch 190 Divergences: Uniform: 3.0935907807288783 Unigram: 4.253879877709306
2022-02-03 00:12:55 | INFO | fairseq.trainer | begin training epoch 191
2022-02-03 00:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:16:12 | INFO | train_inner | epoch 191:     40 / 64 loss=5.161, ppl=35.78, wps=6297.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.31, train_wall=490, gb_free=6.1, wall=65326
2022-02-03 00:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:18:36 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.359 | ppl 1313.15 | wps 8316.9 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.263
2022-02-03 00:18:36 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-03 00:18:36 | INFO | train | epoch 191 | loss 5.168 | ppl 35.96 | wps 6125.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.332 | train_wall 313 | gb_free 6.1 | wall 65470
KL Stats: Epoch 191 Divergences: Uniform: 3.0990303832586217 Unigram: 4.256779403618797
2022-02-03 00:18:36 | INFO | fairseq.trainer | begin training epoch 192
2022-02-03 00:18:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:23:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:24:16 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.408 | ppl 1359.1 | wps 8312.2 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.263
2022-02-03 00:24:16 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-03 00:24:16 | INFO | train | epoch 192 | loss 5.161 | ppl 35.78 | wps 6137.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.329 | train_wall 312 | gb_free 6.1 | wall 65810
KL Stats: Epoch 192 Divergences: Uniform: 3.097611948801473 Unigram: 4.258912300671994
2022-02-03 00:24:16 | INFO | fairseq.trainer | begin training epoch 193
2022-02-03 00:24:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:25:15 | INFO | train_inner | epoch 193:     12 / 64 loss=5.167, ppl=35.92, wps=6004.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.334, train_wall=488, gb_free=6.1, wall=65869
2022-02-03 00:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:29:57 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.41 | ppl 1360.81 | wps 8306.1 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.263
2022-02-03 00:29:57 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-03 00:29:57 | INFO | train | epoch 193 | loss 5.156 | ppl 35.64 | wps 6131.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.323 | train_wall 313 | gb_free 6.1 | wall 66151
KL Stats: Epoch 193 Divergences: Uniform: 3.09650574066985 Unigram: 4.263265498204068
2022-02-03 00:29:57 | INFO | fairseq.trainer | begin training epoch 194
2022-02-03 00:29:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:33:54 | INFO | train_inner | epoch 194:     48 / 64 loss=5.151, ppl=35.52, wps=6303.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.343, train_wall=490, gb_free=6.1, wall=66388
2022-02-03 00:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:35:38 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.413 | ppl 1363.44 | wps 8318.9 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.263
2022-02-03 00:35:38 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-03 00:35:38 | INFO | train | epoch 194 | loss 5.154 | ppl 35.6 | wps 6129.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.394 | train_wall 313 | gb_free 6.1 | wall 66492
KL Stats: Epoch 194 Divergences: Uniform: 3.0971584654468143 Unigram: 4.270410073581294
2022-02-03 00:35:38 | INFO | fairseq.trainer | begin training epoch 195
2022-02-03 00:35:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:41:19 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.462 | ppl 1410.98 | wps 8322.7 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.263
2022-02-03 00:41:19 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-03 00:41:19 | INFO | train | epoch 195 | loss 5.146 | ppl 35.42 | wps 6125.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.296 | train_wall 313 | gb_free 6.1 | wall 66832
KL Stats: Epoch 195 Divergences: Uniform: 3.0982891555579566 Unigram: 4.273819165286942
2022-02-03 00:41:19 | INFO | fairseq.trainer | begin training epoch 196
2022-02-03 00:41:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:42:57 | INFO | train_inner | epoch 196:     20 / 64 loss=5.147, ppl=35.44, wps=6000, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.331, train_wall=488, gb_free=6.1, wall=66931
2022-02-03 00:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:46:59 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.415 | ppl 1365.25 | wps 8330.8 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.263
2022-02-03 00:46:59 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 00:46:59 | INFO | train | epoch 196 | loss 5.143 | ppl 35.33 | wps 6140.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.344 | train_wall 312 | gb_free 6.1 | wall 67173
KL Stats: Epoch 196 Divergences: Uniform: 3.094418494372277 Unigram: 4.278660391787661
2022-02-03 00:46:59 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 00:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:51:35 | INFO | train_inner | epoch 197:     56 / 64 loss=5.145, ppl=35.38, wps=6312.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.35, train_wall=489, gb_free=6.1, wall=67449
2022-02-03 00:52:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:52:39 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.433 | ppl 1382.47 | wps 8352.8 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.263
2022-02-03 00:52:39 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 00:52:39 | INFO | train | epoch 197 | loss 5.138 | ppl 35.22 | wps 6136.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.348 | train_wall 313 | gb_free 6.1 | wall 67513
KL Stats: Epoch 197 Divergences: Uniform: 3.0999518190020727 Unigram: 4.279492407653579
2022-02-03 00:52:39 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 00:52:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:57:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:58:19 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.398 | ppl 1349.53 | wps 8338.5 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.263
2022-02-03 00:58:19 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 00:58:19 | INFO | train | epoch 198 | loss 5.134 | ppl 35.13 | wps 6139.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.378 | train_wall 312 | gb_free 6.1 | wall 67853
KL Stats: Epoch 198 Divergences: Uniform: 3.1043239302281744 Unigram: 4.281981430316152
2022-02-03 00:58:19 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 00:58:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:00:37 | INFO | train_inner | epoch 199:     28 / 64 loss=5.127, ppl=34.94, wps=6010.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.364, train_wall=488, gb_free=6.1, wall=67991
2022-02-03 01:03:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:03:59 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.422 | ppl 1371.55 | wps 8327.7 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.263
2022-02-03 01:03:59 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 01:03:59 | INFO | train | epoch 199 | loss 5.131 | ppl 35.03 | wps 6145.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.372 | train_wall 312 | gb_free 6.1 | wall 68193
KL Stats: Epoch 199 Divergences: Uniform: 3.1007639533194022 Unigram: 4.290705910059171
2022-02-03 01:03:59 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 01:03:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:09:13 | INFO | train_inner | epoch 200:     64 / 64 loss=5.14, ppl=35.26, wps=6314.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.401, train_wall=488, gb_free=6.1, wall=68507
2022-02-03 01:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:09:40 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.443 | ppl 1392.53 | wps 8307.4 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.263
2022-02-03 01:09:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-03 01:09:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint200.pt
2022-02-03 01:09:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint200.pt
2022-02-03 01:09:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#2/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.443) (writing took 3.0879434989765286 seconds)
2022-02-03 01:09:43 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-03 01:09:43 | INFO | train | epoch 200 | loss 5.128 | ppl 34.97 | wps 6077.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.406 | train_wall 313 | gb_free 6.1 | wall 68537
KL Stats: Epoch 200 Divergences: Uniform: 3.10371541246752 Unigram: 4.288886921277747
2022-02-03 01:09:43 | INFO | fairseq.trainer | begin training epoch 201
2022-02-03 01:09:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:14:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:15:24 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.389 | ppl 1340.5 | wps 8328.1 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.263
2022-02-03 01:15:24 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-03 01:15:24 | INFO | train | epoch 201 | loss 5.122 | ppl 34.83 | wps 6128.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.392 | train_wall 313 | gb_free 6.1 | wall 68878
KL Stats: Epoch 201 Divergences: Uniform: 3.1053936822224975 Unigram: 4.297168823331925
2022-02-03 01:15:24 | INFO | fairseq.trainer | begin training epoch 202
2022-02-03 01:15:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:18:21 | INFO | train_inner | epoch 202:     36 / 64 loss=5.111, ppl=34.56, wps=5968.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.421, train_wall=489, gb_free=6.1, wall=69055
2022-02-03 01:20:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:21:04 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.438 | ppl 1387.21 | wps 8310.3 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.263
2022-02-03 01:21:04 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-03 01:21:04 | INFO | train | epoch 202 | loss 5.121 | ppl 34.81 | wps 6137 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.451 | train_wall 312 | gb_free 6.1 | wall 69218
KL Stats: Epoch 202 Divergences: Uniform: 3.1047661110818305 Unigram: 4.297903059643214
2022-02-03 01:21:04 | INFO | fairseq.trainer | begin training epoch 203
2022-02-03 01:21:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:26:44 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.464 | ppl 1412.3 | wps 8320.9 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.263
2022-02-03 01:26:44 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-03 01:26:44 | INFO | train | epoch 203 | loss 5.118 | ppl 34.72 | wps 6136.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.473 | train_wall 313 | gb_free 6.1 | wall 69558
KL Stats: Epoch 203 Divergences: Uniform: 3.1024473131470187 Unigram: 4.302626656999178
2022-02-03 01:26:44 | INFO | fairseq.trainer | begin training epoch 204
2022-02-03 01:26:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:27:24 | INFO | train_inner | epoch 204:      8 / 64 loss=5.123, ppl=34.86, wps=6004.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.458, train_wall=488, gb_free=6.1, wall=69598
2022-02-03 01:31:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:32:25 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.324 | ppl 1281.9 | wps 8300.5 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.263
2022-02-03 01:32:25 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-03 01:32:25 | INFO | train | epoch 204 | loss 5.111 | ppl 34.55 | wps 6128.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.462 | train_wall 313 | gb_free 6.1 | wall 69899
KL Stats: Epoch 204 Divergences: Uniform: 3.108195895255538 Unigram: 4.308012575665105
2022-02-03 01:32:25 | INFO | fairseq.trainer | begin training epoch 205
2022-02-03 01:32:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:36:02 | INFO | train_inner | epoch 205:     44 / 64 loss=5.107, ppl=34.46, wps=6306.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.472, train_wall=489, gb_free=6.1, wall=70116
2022-02-03 01:37:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:38:06 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.445 | ppl 1393.66 | wps 8325.2 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.263
2022-02-03 01:38:06 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-03 01:38:06 | INFO | train | epoch 205 | loss 5.111 | ppl 34.57 | wps 6135.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.487 | train_wall 313 | gb_free 6.1 | wall 70240
KL Stats: Epoch 205 Divergences: Uniform: 3.1102214486028585 Unigram: 4.314308477411045
2022-02-03 01:38:06 | INFO | fairseq.trainer | begin training epoch 206
2022-02-03 01:38:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:43:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:43:46 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.449 | ppl 1398.13 | wps 8332.7 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.263
2022-02-03 01:43:46 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-03 01:43:46 | INFO | train | epoch 206 | loss 5.103 | ppl 34.37 | wps 6132.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.456 | train_wall 313 | gb_free 6.1 | wall 70580
KL Stats: Epoch 206 Divergences: Uniform: 3.1081714638592772 Unigram: 4.3202987919370175
2022-02-03 01:43:46 | INFO | fairseq.trainer | begin training epoch 207
2022-02-03 01:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:45:05 | INFO | train_inner | epoch 207:     16 / 64 loss=5.108, ppl=34.49, wps=6001.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.455, train_wall=488, gb_free=6.1, wall=70659
2022-02-03 01:49:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:49:27 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.44 | ppl 1388.86 | wps 8312.5 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.263
2022-02-03 01:49:27 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-02-03 01:49:27 | INFO | train | epoch 207 | loss 5.101 | ppl 34.31 | wps 6118.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.492 | train_wall 314 | gb_free 6.1 | wall 70921
KL Stats: Epoch 207 Divergences: Uniform: 3.1107240385655768 Unigram: 4.31873659298148
2022-02-03 01:49:27 | INFO | fairseq.trainer | begin training epoch 208
2022-02-03 01:49:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:53:44 | INFO | train_inner | epoch 208:     52 / 64 loss=5.1, ppl=34.3, wps=6301.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.496, train_wall=490, gb_free=6.1, wall=71178
2022-02-03 01:54:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:55:08 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 10.429 | ppl 1378.88 | wps 8304.7 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.263
2022-02-03 01:55:08 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-02-03 01:55:08 | INFO | train | epoch 208 | loss 5.097 | ppl 34.23 | wps 6132.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.475 | train_wall 313 | gb_free 6.1 | wall 71262
KL Stats: Epoch 208 Divergences: Uniform: 3.111190773358199 Unigram: 4.324341189845424
2022-02-03 01:55:08 | INFO | fairseq.trainer | begin training epoch 209
2022-02-03 01:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:00:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:00:49 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 10.445 | ppl 1393.69 | wps 8327.6 | wpb 2034.1 | bsz 4 | num_updates 13376 | best_loss 9.263
2022-02-03 02:00:49 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-02-03 02:00:49 | INFO | train | epoch 209 | loss 5.095 | ppl 34.18 | wps 6131.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13376 | lr 0.000273424 | gnorm 1.55 | train_wall 313 | gb_free 6.1 | wall 71603
KL Stats: Epoch 209 Divergences: Uniform: 3.10780495185615 Unigram: 4.321254810438228
2022-02-03 02:00:49 | INFO | fairseq.trainer | begin training epoch 210
2022-02-03 02:00:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:02:47 | INFO | train_inner | epoch 210:     24 / 64 loss=5.092, ppl=34.11, wps=6000.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13400, lr=0.000273179, gnorm=1.529, train_wall=488, gb_free=6.1, wall=71721
2022-02-03 02:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:06:29 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 10.483 | ppl 1430.84 | wps 8306 | wpb 2034.1 | bsz 4 | num_updates 13440 | best_loss 9.263
2022-02-03 02:06:29 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-02-03 02:06:29 | INFO | train | epoch 210 | loss 5.09 | ppl 34.07 | wps 6135.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13440 | lr 0.000272772 | gnorm 1.512 | train_wall 313 | gb_free 6.1 | wall 71943
KL Stats: Epoch 210 Divergences: Uniform: 3.1110097641316297 Unigram: 4.326966714710857
2022-02-03 02:06:29 | INFO | fairseq.trainer | begin training epoch 211
2022-02-03 02:06:29 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
