Sender: LSF System <lsfadmin@eu-g3-028>
Subject: Job 207345556: <w103_size_0.0625_fp16_label_smoothing_0.08_#2> in cluster <euler> Done

Job <w103_size_0.0625_fp16_label_smoothing_0.08_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 12:51:02 2022
Job was executed on host(s) <eu-g3-028>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 12:51:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 12:51:15 2022
Terminated at Tue Mar  8 05:59:17 2022
Results reported at Tue Mar  8 05:59:17 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.08 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575612 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   147953.86 sec.
    Max Memory :                                 8115 MB
    Average Memory :                             3765.92 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               11885.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   148081 sec.
    Turnaround time :                            148095 sec.

The output (if any) follows:

2022-03-06 12:51:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575612, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.08, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 12:51:23 | INFO | fairseq.tasks.language_modeling | dictionary: 138136 types
2022-03-06 12:51:25 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(138136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=138136, bias=False)
  )
)
2022-03-06 12:51:25 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 12:51:25 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 12:51:25 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 12:51:25 | INFO | fairseq_cli.train | num. shared model params: 89,639,936 (num. trained: 89,639,936)
2022-03-06 12:51:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 12:51:25 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.0625/valid
2022-03-06 12:51:28 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 12:51:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:28 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-06 12:51:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:28 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 12:51:28 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 12:51:28 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 12:51:28 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 12:51:28 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 12:51:28 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-raw-size-0.0625/train
2022-03-06 12:51:28 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 12:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:51:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 12:51:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 12:51:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 12:51:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 12:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 12:56:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.791 | nll_loss 14.527 | ppl 23601.2 | wps 41857.1 | wpb 510.9 | bsz 1 | num_updates 93
2022-03-06 12:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 93 updates
2022-03-06 12:56:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 12:56:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 12:56:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 1 @ 93 updates, score 14.791) (writing took 5.0971685303375125 seconds)
2022-03-06 12:56:39 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 12:56:39 | INFO | train | epoch 001 | loss 16.349 | nll_loss 16.22 | ppl 76317.2 | wps 22044.2 | ups 0.34 | wpb 65489.7 | bsz 127.9 | num_updates 93 | lr 1.17227e-05 | gnorm 3.274 | loss_scale 8 | train_wall 278 | gb_free 8.1 | wall 311
2022-03-06 12:56:39 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 12:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:56:59 | INFO | train_inner | epoch 002:      7 / 97 loss=16.244, nll_loss=16.106, ppl=70544.5, wps=22091.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=100, lr=1.25975e-05, gnorm=3.162, loss_scale=8, train_wall=296, gb_free=8.1, wall=331
2022-03-06 12:58:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 13:01:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:01:22 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.174 | nll_loss 12.767 | ppl 6971.94 | wps 41527.4 | wpb 510.9 | bsz 1 | num_updates 189 | best_loss 13.174
2022-03-06 13:01:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 189 updates
2022-03-06 13:01:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:01:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 2 @ 189 updates, score 13.174) (writing took 4.8867338872514665 seconds)
2022-03-06 13:01:26 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:01:26 | INFO | train | epoch 002 | loss 14.171 | nll_loss 13.857 | ppl 14835.5 | wps 21859 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 189 | lr 2.37203e-05 | gnorm 1.497 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 598
2022-03-06 13:01:27 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:01:58 | INFO | train_inner | epoch 003:     11 / 97 loss=14.015, nll_loss=13.687, ppl=13190.5, wps=21905.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=200, lr=2.5095e-05, gnorm=1.456, loss_scale=8, train_wall=265, gb_free=8.1, wall=630
2022-03-06 13:06:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:06:09 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.664 | nll_loss 11.084 | ppl 2171.12 | wps 41501.3 | wpb 510.9 | bsz 1 | num_updates 286 | best_loss 11.664
2022-03-06 13:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 286 updates
2022-03-06 13:06:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:06:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 3 @ 286 updates, score 11.664) (writing took 4.780581320170313 seconds)
2022-03-06 13:06:14 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:06:14 | INFO | train | epoch 003 | loss 12.466 | nll_loss 11.986 | ppl 4055.96 | wps 22103.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 286 | lr 3.58429e-05 | gnorm 0.981 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 886
2022-03-06 13:06:14 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:06:54 | INFO | train_inner | epoch 004:     14 / 97 loss=12.271, nll_loss=11.769, ppl=3490.36, wps=22125.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=300, lr=3.75925e-05, gnorm=0.92, loss_scale=16, train_wall=263, gb_free=8.1, wall=926
2022-03-06 13:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:10:57 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.972 | nll_loss 10.264 | ppl 1230.01 | wps 40644.4 | wpb 510.9 | bsz 1 | num_updates 383 | best_loss 10.972
2022-03-06 13:10:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 383 updates
2022-03-06 13:10:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:10:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:11:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 4 @ 383 updates, score 10.972) (writing took 4.748743713833392 seconds)
2022-03-06 13:11:01 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:11:01 | INFO | train | epoch 004 | loss 11.299 | nll_loss 10.66 | ppl 1617.84 | wps 22088.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 383 | lr 4.79654e-05 | gnorm 0.564 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 1173
2022-03-06 13:11:02 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:11:50 | INFO | train_inner | epoch 005:     17 / 97 loss=11.193, nll_loss=10.535, ppl=1483.48, wps=22108.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=400, lr=5.009e-05, gnorm=0.515, loss_scale=32, train_wall=263, gb_free=8.1, wall=1222
2022-03-06 13:15:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:15:44 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.66 | nll_loss 9.885 | ppl 945.64 | wps 41688 | wpb 510.9 | bsz 1 | num_updates 480 | best_loss 10.66
2022-03-06 13:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 480 updates
2022-03-06 13:15:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:15:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 5 @ 480 updates, score 10.66) (writing took 4.701899294741452 seconds)
2022-03-06 13:15:49 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:15:49 | INFO | train | epoch 005 | loss 10.819 | nll_loss 10.081 | ppl 1083.34 | wps 22084.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 480 | lr 6.0088e-05 | gnorm 0.464 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 1461
2022-03-06 13:15:49 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:15:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:16:47 | INFO | train_inner | epoch 006:     20 / 97 loss=10.753, nll_loss=10.003, ppl=1026.03, wps=22105.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=500, lr=6.25875e-05, gnorm=0.478, loss_scale=32, train_wall=263, gb_free=8.1, wall=1518
2022-03-06 13:17:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:20:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:20:32 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.405 | nll_loss 9.592 | ppl 771.63 | wps 41750.2 | wpb 510.9 | bsz 1 | num_updates 576 | best_loss 10.405
2022-03-06 13:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 576 updates
2022-03-06 13:20:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:20:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:20:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 6 @ 576 updates, score 10.405) (writing took 5.314069726970047 seconds)
2022-03-06 13:20:37 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:20:37 | INFO | train | epoch 006 | loss 10.521 | nll_loss 9.734 | ppl 851.76 | wps 21804.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 576 | lr 7.20856e-05 | gnorm 0.512 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 1749
2022-03-06 13:20:38 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:20:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:21:46 | INFO | train_inner | epoch 007:     24 / 97 loss=10.46, nll_loss=9.664, ppl=811.36, wps=21848.4, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=600, lr=7.5085e-05, gnorm=0.523, loss_scale=32, train_wall=266, gb_free=8.1, wall=1818
2022-03-06 13:24:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:25:20 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.167 | nll_loss 9.331 | ppl 644.03 | wps 42142.3 | wpb 510.9 | bsz 1 | num_updates 672 | best_loss 10.167
2022-03-06 13:25:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 672 updates
2022-03-06 13:25:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:25:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:25:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 7 @ 672 updates, score 10.167) (writing took 4.842520349193364 seconds)
2022-03-06 13:25:25 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:25:25 | INFO | train | epoch 007 | loss 10.261 | nll_loss 9.442 | ppl 695.38 | wps 21856.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 672 | lr 8.40832e-05 | gnorm 0.562 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 2037
2022-03-06 13:25:25 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:25:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:26:45 | INFO | train_inner | epoch 008:     28 / 97 loss=10.195, nll_loss=9.367, ppl=660.49, wps=21899.8, ups=0.33, wpb=65495, bsz=127.9, num_updates=700, lr=8.75825e-05, gnorm=0.595, loss_scale=32, train_wall=266, gb_free=8.1, wall=2117
2022-03-06 13:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:30:08 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.961 | nll_loss 9.094 | ppl 546.64 | wps 41927.1 | wpb 510.9 | bsz 1 | num_updates 769 | best_loss 9.961
2022-03-06 13:30:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 769 updates
2022-03-06 13:30:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:30:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:30:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 8 @ 769 updates, score 9.961) (writing took 4.868129529990256 seconds)
2022-03-06 13:30:13 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 13:30:13 | INFO | train | epoch 008 | loss 10.022 | nll_loss 9.174 | ppl 577.66 | wps 22080 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 769 | lr 9.62058e-05 | gnorm 0.648 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 2325
2022-03-06 13:30:13 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 13:30:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:30:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:31:44 | INFO | train_inner | epoch 009:     32 / 97 loss=9.952, nll_loss=9.095, ppl=546.89, wps=21894, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=800, lr=0.00010008, gnorm=0.667, loss_scale=32, train_wall=266, gb_free=8.1, wall=2416
2022-03-06 13:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:34:56 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.774 | nll_loss 8.888 | ppl 473.86 | wps 42196.6 | wpb 510.9 | bsz 1 | num_updates 865 | best_loss 9.774
2022-03-06 13:34:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 865 updates
2022-03-06 13:34:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:34:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:35:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 9 @ 865 updates, score 9.774) (writing took 4.657269629184157 seconds)
2022-03-06 13:35:00 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 13:35:00 | INFO | train | epoch 009 | loss 9.803 | nll_loss 8.928 | ppl 486.96 | wps 21879.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 865 | lr 0.000108203 | gnorm 0.732 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 2612
2022-03-06 13:35:00 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 13:35:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:36:41 | INFO | train_inner | epoch 010:     35 / 97 loss=9.732, nll_loss=8.847, ppl=460.62, wps=22124.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=900, lr=0.000112578, gnorm=0.755, loss_scale=32, train_wall=263, gb_free=8.1, wall=2712
2022-03-06 13:37:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:39:43 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.601 | nll_loss 8.683 | ppl 411.07 | wps 41738.3 | wpb 510.9 | bsz 1 | num_updates 961 | best_loss 9.601
2022-03-06 13:39:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 961 updates
2022-03-06 13:39:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:39:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 10 @ 961 updates, score 9.601) (writing took 4.567707332782447 seconds)
2022-03-06 13:39:48 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 13:39:48 | INFO | train | epoch 010 | loss 9.602 | nll_loss 8.701 | ppl 416.25 | wps 21862.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 961 | lr 0.000120201 | gnorm 0.761 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 2900
2022-03-06 13:39:48 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 13:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:40:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 13:41:42 | INFO | train_inner | epoch 011:     40 / 97 loss=9.53, nll_loss=8.621, ppl=393.72, wps=21699.3, ups=0.33, wpb=65495, bsz=127.9, num_updates=1000, lr=0.000125075, gnorm=0.808, loss_scale=16, train_wall=269, gb_free=8.1, wall=3014
2022-03-06 13:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:44:31 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.465 | nll_loss 8.525 | ppl 368.45 | wps 41858 | wpb 510.9 | bsz 1 | num_updates 1057 | best_loss 9.465
2022-03-06 13:44:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1057 updates
2022-03-06 13:44:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:44:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:44:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 11 @ 1057 updates, score 9.465) (writing took 4.569262150675058 seconds)
2022-03-06 13:44:35 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 13:44:35 | INFO | train | epoch 011 | loss 9.42 | nll_loss 8.497 | ppl 361.35 | wps 21866.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1057 | lr 0.000132199 | gnorm 0.867 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 3187
2022-03-06 13:44:35 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 13:44:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:46:39 | INFO | train_inner | epoch 012:     43 / 97 loss=9.344, nll_loss=8.411, ppl=340.36, wps=22113, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=1100, lr=0.000137573, gnorm=0.829, loss_scale=16, train_wall=263, gb_free=8.1, wall=3310
2022-03-06 13:49:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:49:18 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.326 | nll_loss 8.374 | ppl 331.77 | wps 41636.7 | wpb 510.9 | bsz 1 | num_updates 1154 | best_loss 9.326
2022-03-06 13:49:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1154 updates
2022-03-06 13:49:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:49:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 12 @ 1154 updates, score 9.326) (writing took 4.554102239198983 seconds)
2022-03-06 13:49:23 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 13:49:23 | INFO | train | epoch 012 | loss 9.251 | nll_loss 8.307 | ppl 316.73 | wps 22085 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1154 | lr 0.000144321 | gnorm 0.828 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 3475
2022-03-06 13:49:23 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 13:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:51:35 | INFO | train_inner | epoch 013:     46 / 97 loss=9.181, nll_loss=8.228, ppl=299.78, wps=22100.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=1200, lr=0.00015007, gnorm=0.826, loss_scale=32, train_wall=264, gb_free=8.1, wall=3607
2022-03-06 13:53:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:54:06 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.205 | nll_loss 8.235 | ppl 301.31 | wps 41410.2 | wpb 510.9 | bsz 1 | num_updates 1250 | best_loss 9.205
2022-03-06 13:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1250 updates
2022-03-06 13:54:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:54:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:54:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 13 @ 1250 updates, score 9.205) (writing took 4.5273053222335875 seconds)
2022-03-06 13:54:11 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 13:54:11 | INFO | train | epoch 013 | loss 9.095 | nll_loss 8.131 | ppl 280.33 | wps 21849.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1250 | lr 0.000156319 | gnorm 0.836 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 3763
2022-03-06 13:54:11 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 13:54:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:56:34 | INFO | train_inner | epoch 014:     50 / 97 loss=9.013, nll_loss=8.038, ppl=262.89, wps=21906.2, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=1300, lr=0.000162568, gnorm=0.856, loss_scale=32, train_wall=266, gb_free=8.1, wall=3906
2022-03-06 13:58:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:58:53 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.101 | nll_loss 8.117 | ppl 277.58 | wps 41737.9 | wpb 510.9 | bsz 1 | num_updates 1347 | best_loss 9.101
2022-03-06 13:58:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1347 updates
2022-03-06 13:58:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:58:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:58:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 14 @ 1347 updates, score 9.101) (writing took 4.596739488188177 seconds)
2022-03-06 13:58:58 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 13:58:58 | INFO | train | epoch 014 | loss 8.946 | nll_loss 7.963 | ppl 249.44 | wps 22108.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1347 | lr 0.000168441 | gnorm 0.87 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 4050
2022-03-06 13:58:58 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 13:58:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:00:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:01:32 | INFO | train_inner | epoch 015:     54 / 97 loss=8.873, nll_loss=7.88, ppl=235.56, wps=21926.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=1400, lr=0.000175065, gnorm=0.87, loss_scale=32, train_wall=266, gb_free=8.1, wall=4204
2022-03-06 14:03:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:03:41 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.001 | nll_loss 8.008 | ppl 257.39 | wps 41733.4 | wpb 510.9 | bsz 1 | num_updates 1443 | best_loss 9.001
2022-03-06 14:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1443 updates
2022-03-06 14:03:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:03:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:03:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 15 @ 1443 updates, score 9.001) (writing took 4.582186633255333 seconds)
2022-03-06 14:03:45 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 14:03:45 | INFO | train | epoch 015 | loss 8.8 | nll_loss 7.798 | ppl 222.59 | wps 21890.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1443 | lr 0.000180439 | gnorm 0.869 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 4337
2022-03-06 14:03:45 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 14:03:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:06:28 | INFO | train_inner | epoch 016:     57 / 97 loss=8.715, nll_loss=7.703, ppl=208.36, wps=22130.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1500, lr=0.000187563, gnorm=0.874, loss_scale=32, train_wall=263, gb_free=8.1, wall=4500
2022-03-06 14:07:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:08:28 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.918 | nll_loss 7.903 | ppl 239.33 | wps 41923.4 | wpb 510.9 | bsz 1 | num_updates 1539 | best_loss 8.918
2022-03-06 14:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1539 updates
2022-03-06 14:08:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:08:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:08:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 16 @ 1539 updates, score 8.918) (writing took 4.590239362791181 seconds)
2022-03-06 14:08:33 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 14:08:33 | INFO | train | epoch 016 | loss 8.658 | nll_loss 7.638 | ppl 199.17 | wps 21883.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1539 | lr 0.000192437 | gnorm 0.868 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 4624
2022-03-06 14:08:33 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 14:08:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:11:27 | INFO | train_inner | epoch 017:     61 / 97 loss=8.569, nll_loss=7.538, ppl=185.83, wps=21911.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=1600, lr=0.00020006, gnorm=0.892, loss_scale=32, train_wall=266, gb_free=8.1, wall=4799
2022-03-06 14:13:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:13:16 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.851 | nll_loss 7.829 | ppl 227.44 | wps 42081.7 | wpb 510.9 | bsz 1 | num_updates 1636 | best_loss 8.851
2022-03-06 14:13:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1636 updates
2022-03-06 14:13:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:13:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 17 @ 1636 updates, score 8.851) (writing took 4.775405341293663 seconds)
2022-03-06 14:13:20 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 14:13:20 | INFO | train | epoch 017 | loss 8.519 | nll_loss 7.482 | ppl 178.76 | wps 22072.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1636 | lr 0.000204559 | gnorm 0.894 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 4912
2022-03-06 14:13:20 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 14:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:13:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:16:27 | INFO | train_inner | epoch 018:     65 / 97 loss=8.43, nll_loss=7.381, ppl=166.7, wps=21881, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=1700, lr=0.000212558, gnorm=0.884, loss_scale=32, train_wall=266, gb_free=8.1, wall=5099
2022-03-06 14:17:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:18:03 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.758 | nll_loss 7.71 | ppl 209.36 | wps 42187.1 | wpb 510.9 | bsz 1 | num_updates 1732 | best_loss 8.758
2022-03-06 14:18:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1732 updates
2022-03-06 14:18:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:18:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:18:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 18 @ 1732 updates, score 8.758) (writing took 4.611416107043624 seconds)
2022-03-06 14:18:08 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 14:18:08 | INFO | train | epoch 018 | loss 8.382 | nll_loss 7.327 | ppl 160.52 | wps 21858.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1732 | lr 0.000216557 | gnorm 0.877 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 5200
2022-03-06 14:18:08 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 14:18:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:20:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:21:26 | INFO | train_inner | epoch 019:     69 / 97 loss=8.291, nll_loss=7.224, ppl=149.53, wps=21890.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=1800, lr=0.000225055, gnorm=0.853, loss_scale=32, train_wall=266, gb_free=8.1, wall=5398
2022-03-06 14:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:22:51 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.713 | nll_loss 7.661 | ppl 202.32 | wps 42599.2 | wpb 510.9 | bsz 1 | num_updates 1828 | best_loss 8.713
2022-03-06 14:22:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1828 updates
2022-03-06 14:22:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:22:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:22:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 19 @ 1828 updates, score 8.713) (writing took 4.507509952876717 seconds)
2022-03-06 14:22:56 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 14:22:56 | INFO | train | epoch 019 | loss 8.247 | nll_loss 7.175 | ppl 144.47 | wps 21858.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1828 | lr 0.000228554 | gnorm 0.861 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 5488
2022-03-06 14:22:56 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 14:22:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:26:22 | INFO | train_inner | epoch 020:     72 / 97 loss=8.153, nll_loss=7.068, ppl=134.21, wps=22138.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=1900, lr=0.000237553, gnorm=0.887, loss_scale=32, train_wall=263, gb_free=8.1, wall=5694
2022-03-06 14:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:27:38 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.644 | nll_loss 7.578 | ppl 191.02 | wps 42533.6 | wpb 510.9 | bsz 1 | num_updates 1925 | best_loss 8.644
2022-03-06 14:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 1925 updates
2022-03-06 14:27:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:27:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:27:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 20 @ 1925 updates, score 8.644) (writing took 4.526974351145327 seconds)
2022-03-06 14:27:43 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 14:27:43 | INFO | train | epoch 020 | loss 8.117 | nll_loss 7.027 | ppl 130.44 | wps 22120.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1925 | lr 0.000240677 | gnorm 0.884 | loss_scale 64 | train_wall 255 | gb_free 8.1 | wall 5775
2022-03-06 14:27:43 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 14:27:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:28:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:31:20 | INFO | train_inner | epoch 021:     76 / 97 loss=8.018, nll_loss=6.915, ppl=120.7, wps=21925.7, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=2000, lr=0.00025005, gnorm=0.865, loss_scale=32, train_wall=266, gb_free=8.1, wall=5992
2022-03-06 14:32:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:32:26 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.613 | nll_loss 7.555 | ppl 188.11 | wps 42635.9 | wpb 510.9 | bsz 1 | num_updates 2021 | best_loss 8.613
2022-03-06 14:32:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2021 updates
2022-03-06 14:32:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:32:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:32:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 21 @ 2021 updates, score 8.613) (writing took 4.778055239003152 seconds)
2022-03-06 14:32:30 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 14:32:30 | INFO | train | epoch 021 | loss 7.987 | nll_loss 6.88 | ppl 117.8 | wps 21864.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 2021 | lr 0.000252674 | gnorm 0.852 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 6062
2022-03-06 14:32:30 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 14:32:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:34:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:36:19 | INFO | train_inner | epoch 022:     80 / 97 loss=7.894, nll_loss=6.775, ppl=109.49, wps=21907.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=2100, lr=0.000262548, gnorm=0.885, loss_scale=32, train_wall=266, gb_free=8.1, wall=6291
2022-03-06 14:37:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:37:13 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.534 | nll_loss 7.455 | ppl 175.41 | wps 42743.7 | wpb 510.9 | bsz 1 | num_updates 2117 | best_loss 8.534
2022-03-06 14:37:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2117 updates
2022-03-06 14:37:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:37:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:37:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 22 @ 2117 updates, score 8.534) (writing took 4.517668584361672 seconds)
2022-03-06 14:37:18 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 14:37:18 | INFO | train | epoch 022 | loss 7.867 | nll_loss 6.744 | ppl 107.18 | wps 21889 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 2117 | lr 0.000264672 | gnorm 0.899 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 6349
2022-03-06 14:37:18 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 14:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:41:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:41:18 | INFO | train_inner | epoch 023:     84 / 97 loss=7.765, nll_loss=6.628, ppl=98.91, wps=21922.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=2200, lr=0.000275045, gnorm=0.867, loss_scale=32, train_wall=266, gb_free=8.1, wall=6590
2022-03-06 14:41:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:42:00 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.535 | nll_loss 7.46 | ppl 176.05 | wps 42473.1 | wpb 510.9 | bsz 1 | num_updates 2213 | best_loss 8.534
2022-03-06 14:42:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2213 updates
2022-03-06 14:42:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:42:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:42:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 23 @ 2213 updates, score 8.535) (writing took 2.1014183601364493 seconds)
2022-03-06 14:42:03 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 14:42:03 | INFO | train | epoch 023 | loss 7.746 | nll_loss 6.607 | ppl 97.47 | wps 22062.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2213 | lr 0.00027667 | gnorm 0.863 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 6634
2022-03-06 14:42:03 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 14:42:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:43:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:46:15 | INFO | train_inner | epoch 024:     88 / 97 loss=7.648, nll_loss=6.496, ppl=90.23, wps=22082.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2300, lr=0.000287543, gnorm=0.869, loss_scale=16, train_wall=266, gb_free=8.1, wall=6887
2022-03-06 14:46:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:46:46 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.481 | nll_loss 7.383 | ppl 166.96 | wps 42040.2 | wpb 510.9 | bsz 1 | num_updates 2309 | best_loss 8.481
2022-03-06 14:46:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2309 updates
2022-03-06 14:46:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:46:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:46:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 24 @ 2309 updates, score 8.481) (writing took 4.523551142774522 seconds)
2022-03-06 14:46:50 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 14:46:50 | INFO | train | epoch 024 | loss 7.631 | nll_loss 6.476 | ppl 89.03 | wps 21866.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 2309 | lr 0.000288667 | gnorm 0.878 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 6922
2022-03-06 14:46:50 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 14:46:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:51:11 | INFO | train_inner | epoch 025:     91 / 97 loss=7.525, nll_loss=6.355, ppl=81.85, wps=22124.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2400, lr=0.00030004, gnorm=0.902, loss_scale=32, train_wall=263, gb_free=8.1, wall=7183
2022-03-06 14:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:51:33 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.498 | nll_loss 7.404 | ppl 169.4 | wps 42479.5 | wpb 510.9 | bsz 1 | num_updates 2406 | best_loss 8.481
2022-03-06 14:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2406 updates
2022-03-06 14:51:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 25 @ 2406 updates, score 8.498) (writing took 2.0986804850399494 seconds)
2022-03-06 14:51:35 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 14:51:35 | INFO | train | epoch 025 | loss 7.519 | nll_loss 6.349 | ppl 81.52 | wps 22298.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2406 | lr 0.00030079 | gnorm 0.897 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 7207
2022-03-06 14:51:35 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 14:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:54:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:56:07 | INFO | train_inner | epoch 026:     95 / 97 loss=7.416, nll_loss=6.232, ppl=75.15, wps=22110.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2500, lr=0.000312538, gnorm=0.896, loss_scale=16, train_wall=266, gb_free=8.1, wall=7479
2022-03-06 14:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:56:18 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.497 | nll_loss 7.399 | ppl 168.82 | wps 41648.8 | wpb 510.9 | bsz 1 | num_updates 2502 | best_loss 8.481
2022-03-06 14:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2502 updates
2022-03-06 14:56:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:56:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:56:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 26 @ 2502 updates, score 8.497) (writing took 2.0882034772075713 seconds)
2022-03-06 14:56:20 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 14:56:20 | INFO | train | epoch 026 | loss 7.408 | nll_loss 6.223 | ppl 74.7 | wps 22072.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2502 | lr 0.000312787 | gnorm 0.896 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 7492
2022-03-06 14:56:20 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 14:56:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:00:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:01:03 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.504 | nll_loss 7.409 | ppl 169.93 | wps 41953.1 | wpb 510.9 | bsz 1 | num_updates 2599 | best_loss 8.481
2022-03-06 15:01:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2599 updates
2022-03-06 15:01:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:01:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 27 @ 2599 updates, score 8.504) (writing took 2.126104726921767 seconds)
2022-03-06 15:01:05 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 15:01:05 | INFO | train | epoch 027 | loss 7.303 | nll_loss 6.103 | ppl 68.73 | wps 22276.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2599 | lr 0.00032491 | gnorm 0.907 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 7777
2022-03-06 15:01:05 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 15:01:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:01:08 | INFO | train_inner | epoch 028:      1 / 97 loss=7.305, nll_loss=6.106, ppl=68.86, wps=21740.7, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=2600, lr=0.000325035, gnorm=0.904, loss_scale=16, train_wall=263, gb_free=8.1, wall=7780
2022-03-06 15:05:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:05:48 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.51 | nll_loss 7.409 | ppl 169.99 | wps 41685.4 | wpb 510.9 | bsz 1 | num_updates 2696 | best_loss 8.481
2022-03-06 15:05:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2696 updates
2022-03-06 15:05:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:05:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:05:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 28 @ 2696 updates, score 8.51) (writing took 2.1302008680067956 seconds)
2022-03-06 15:05:50 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 15:05:50 | INFO | train | epoch 028 | loss 7.196 | nll_loss 5.981 | ppl 63.18 | wps 22299.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2696 | lr 0.000337033 | gnorm 0.887 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 8062
2022-03-06 15:05:50 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 15:05:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:06:01 | INFO | train_inner | epoch 029:      4 / 97 loss=7.19, nll_loss=5.975, ppl=62.9, wps=22316, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2700, lr=0.000337533, gnorm=0.884, loss_scale=32, train_wall=263, gb_free=8.1, wall=8073
2022-03-06 15:07:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:10:33 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.573 | nll_loss 7.475 | ppl 177.89 | wps 42581.3 | wpb 510.9 | bsz 1 | num_updates 2792 | best_loss 8.481
2022-03-06 15:10:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2792 updates
2022-03-06 15:10:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:10:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:10:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 29 @ 2792 updates, score 8.573) (writing took 2.2179516591131687 seconds)
2022-03-06 15:10:35 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 15:10:35 | INFO | train | epoch 029 | loss 7.096 | nll_loss 5.868 | ppl 58.39 | wps 22054.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2792 | lr 0.00034903 | gnorm 0.924 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 8347
2022-03-06 15:10:35 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 15:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:10:58 | INFO | train_inner | epoch 030:      8 / 97 loss=7.087, nll_loss=5.857, ppl=57.98, wps=22087.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2800, lr=0.00035003, gnorm=0.923, loss_scale=32, train_wall=266, gb_free=8.1, wall=8370
2022-03-06 15:14:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:15:18 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.581 | nll_loss 7.488 | ppl 179.48 | wps 41833.1 | wpb 510.9 | bsz 1 | num_updates 2888 | best_loss 8.481
2022-03-06 15:15:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 2888 updates
2022-03-06 15:15:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:15:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:15:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 30 @ 2888 updates, score 8.581) (writing took 2.216880849096924 seconds)
2022-03-06 15:15:20 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 15:15:20 | INFO | train | epoch 030 | loss 6.996 | nll_loss 5.753 | ppl 53.94 | wps 22024.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2888 | lr 0.000361028 | gnorm 0.901 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 8632
2022-03-06 15:15:20 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 15:15:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:15:55 | INFO | train_inner | epoch 031:     12 / 97 loss=6.981, nll_loss=5.736, ppl=53.31, wps=22055.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2900, lr=0.000362528, gnorm=0.919, loss_scale=32, train_wall=266, gb_free=8.1, wall=8667
2022-03-06 15:19:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:20:04 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.598 | nll_loss 7.504 | ppl 181.55 | wps 41630.5 | wpb 510.9 | bsz 1 | num_updates 2985 | best_loss 8.481
2022-03-06 15:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 2985 updates
2022-03-06 15:20:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:20:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:20:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 31 @ 2985 updates, score 8.598) (writing took 2.17063309205696 seconds)
2022-03-06 15:20:06 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 15:20:06 | INFO | train | epoch 031 | loss 6.899 | nll_loss 5.642 | ppl 49.94 | wps 22257.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2985 | lr 0.00037315 | gnorm 0.94 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 8918
2022-03-06 15:20:06 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 15:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:20:49 | INFO | train_inner | epoch 032:     15 / 97 loss=6.885, nll_loss=5.626, ppl=49.4, wps=22280.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3000, lr=0.000375025, gnorm=0.934, loss_scale=64, train_wall=263, gb_free=8.1, wall=8961
2022-03-06 15:21:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:21:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:24:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:24:49 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.658 | nll_loss 7.563 | ppl 189.06 | wps 42001.5 | wpb 510.9 | bsz 1 | num_updates 3080 | best_loss 8.481
2022-03-06 15:24:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3080 updates
2022-03-06 15:24:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:24:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:24:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 32 @ 3080 updates, score 8.658) (writing took 2.135672504082322 seconds)
2022-03-06 15:24:51 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 15:24:51 | INFO | train | epoch 032 | loss 6.8 | nll_loss 5.53 | ppl 46.21 | wps 21840.3 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 3080 | lr 0.000385023 | gnorm 0.953 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 9203
2022-03-06 15:24:51 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 15:24:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:25:48 | INFO | train_inner | epoch 033:     20 / 97 loss=6.779, nll_loss=5.506, ppl=45.45, wps=21891.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=3100, lr=0.000387523, gnorm=0.939, loss_scale=16, train_wall=268, gb_free=8.1, wall=9260
2022-03-06 15:29:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:29:33 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.651 | nll_loss 7.533 | ppl 185.22 | wps 41694.4 | wpb 510.9 | bsz 1 | num_updates 3177 | best_loss 8.481
2022-03-06 15:29:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3177 updates
2022-03-06 15:29:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:29:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:29:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 33 @ 3177 updates, score 8.651) (writing took 2.1848192838951945 seconds)
2022-03-06 15:29:36 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 15:29:36 | INFO | train | epoch 033 | loss 6.71 | nll_loss 5.426 | ppl 43.01 | wps 22291.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3177 | lr 0.000397146 | gnorm 0.954 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 9488
2022-03-06 15:29:36 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 15:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:29:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:30:44 | INFO | train_inner | epoch 034:     24 / 97 loss=6.686, nll_loss=5.399, ppl=42.19, wps=22090.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3200, lr=0.00040002, gnorm=0.967, loss_scale=16, train_wall=266, gb_free=8.1, wall=9556
2022-03-06 15:34:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:34:19 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.689 | nll_loss 7.574 | ppl 190.57 | wps 42004.2 | wpb 510.9 | bsz 1 | num_updates 3273 | best_loss 8.481
2022-03-06 15:34:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3273 updates
2022-03-06 15:34:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:34:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:34:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 34 @ 3273 updates, score 8.689) (writing took 2.1662903297692537 seconds)
2022-03-06 15:34:21 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 15:34:21 | INFO | train | epoch 034 | loss 6.618 | nll_loss 5.321 | ppl 39.97 | wps 22055.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3273 | lr 0.000409143 | gnorm 0.994 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 9773
2022-03-06 15:34:21 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 15:34:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:35:38 | INFO | train_inner | epoch 035:     27 / 97 loss=6.586, nll_loss=5.284, ppl=38.97, wps=22301.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3300, lr=0.000412518, gnorm=0.963, loss_scale=16, train_wall=263, gb_free=8.1, wall=9850
2022-03-06 15:36:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:39:04 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.709 | nll_loss 7.572 | ppl 190.23 | wps 41662.5 | wpb 510.9 | bsz 1 | num_updates 3369 | best_loss 8.481
2022-03-06 15:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3369 updates
2022-03-06 15:39:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:39:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:39:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 35 @ 3369 updates, score 8.709) (writing took 2.119948617182672 seconds)
2022-03-06 15:39:06 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 15:39:06 | INFO | train | epoch 035 | loss 6.524 | nll_loss 5.213 | ppl 37.1 | wps 22049.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3369 | lr 0.000421141 | gnorm 0.941 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 10058
2022-03-06 15:39:06 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 15:39:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:40:35 | INFO | train_inner | epoch 036:     31 / 97 loss=6.501, nll_loss=5.187, ppl=36.43, wps=22086.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3400, lr=0.000425015, gnorm=0.974, loss_scale=16, train_wall=266, gb_free=8.1, wall=10147
2022-03-06 15:43:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:43:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:43:49 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.787 | nll_loss 7.659 | ppl 202.11 | wps 41795.3 | wpb 510.9 | bsz 1 | num_updates 3465 | best_loss 8.481
2022-03-06 15:43:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3465 updates
2022-03-06 15:43:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:43:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:43:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 36 @ 3465 updates, score 8.787) (writing took 2.1224091039039195 seconds)
2022-03-06 15:43:51 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 15:43:51 | INFO | train | epoch 036 | loss 6.433 | nll_loss 5.109 | ppl 34.52 | wps 22035.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3465 | lr 0.000433138 | gnorm 0.995 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 10343
2022-03-06 15:43:51 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 15:43:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:45:32 | INFO | train_inner | epoch 037:     35 / 97 loss=6.4, nll_loss=5.071, ppl=33.61, wps=22063.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3500, lr=0.000437513, gnorm=0.976, loss_scale=16, train_wall=266, gb_free=8.1, wall=10443
2022-03-06 15:48:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:48:34 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.826 | nll_loss 7.695 | ppl 207.22 | wps 41856.5 | wpb 510.9 | bsz 1 | num_updates 3562 | best_loss 8.481
2022-03-06 15:48:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3562 updates
2022-03-06 15:48:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:48:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:48:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 37 @ 3562 updates, score 8.826) (writing took 2.1270179841667414 seconds)
2022-03-06 15:48:36 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 15:48:36 | INFO | train | epoch 037 | loss 6.345 | nll_loss 5.009 | ppl 32.19 | wps 22279.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3562 | lr 0.000445261 | gnorm 0.962 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 10628
2022-03-06 15:48:36 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 15:48:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:50:25 | INFO | train_inner | epoch 038:     38 / 97 loss=6.308, nll_loss=4.965, ppl=31.24, wps=22309.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3600, lr=0.00045001, gnorm=1.002, loss_scale=32, train_wall=263, gb_free=8.1, wall=10737
2022-03-06 15:51:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:53:19 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.875 | nll_loss 7.75 | ppl 215.32 | wps 42115.7 | wpb 510.9 | bsz 1 | num_updates 3658 | best_loss 8.481
2022-03-06 15:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3658 updates
2022-03-06 15:53:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:53:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 38 @ 3658 updates, score 8.875) (writing took 2.1297484557144344 seconds)
2022-03-06 15:53:21 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 15:53:21 | INFO | train | epoch 038 | loss 6.256 | nll_loss 4.906 | ppl 29.98 | wps 22076.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3658 | lr 0.000457259 | gnorm 1.022 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 10913
2022-03-06 15:53:21 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 15:53:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:55:21 | INFO | train_inner | epoch 039:     42 / 97 loss=6.225, nll_loss=4.87, ppl=29.24, wps=22102, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=3700, lr=0.000462508, gnorm=1.019, loss_scale=16, train_wall=266, gb_free=8.1, wall=11033
2022-03-06 15:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:58:04 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.893 | nll_loss 7.757 | ppl 216.32 | wps 42245.9 | wpb 510.9 | bsz 1 | num_updates 3755 | best_loss 8.481
2022-03-06 15:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 3755 updates
2022-03-06 15:58:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:58:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:58:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 39 @ 3755 updates, score 8.893) (writing took 2.1316896942444146 seconds)
2022-03-06 15:58:06 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 15:58:06 | INFO | train | epoch 039 | loss 6.172 | nll_loss 4.808 | ppl 28.02 | wps 22294.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3755 | lr 0.000469381 | gnorm 1.023 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 11198
2022-03-06 15:58:06 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 15:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:59:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:00:18 | INFO | train_inner | epoch 040:     46 / 97 loss=6.126, nll_loss=4.756, ppl=27.02, wps=22100.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3800, lr=0.000475005, gnorm=1.013, loss_scale=16, train_wall=266, gb_free=8.1, wall=11330
2022-03-06 16:02:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:02:49 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.946 | nll_loss 7.804 | ppl 223.5 | wps 42169.9 | wpb 510.9 | bsz 1 | num_updates 3851 | best_loss 8.481
2022-03-06 16:02:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 3851 updates
2022-03-06 16:02:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:02:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:02:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 40 @ 3851 updates, score 8.946) (writing took 2.125169734004885 seconds)
2022-03-06 16:02:51 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 16:02:51 | INFO | train | epoch 040 | loss 6.084 | nll_loss 4.708 | ppl 26.14 | wps 22069 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3851 | lr 0.000481379 | gnorm 1.014 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 11483
2022-03-06 16:02:51 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 16:02:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:05:11 | INFO | train_inner | epoch 041:     49 / 97 loss=6.046, nll_loss=4.664, ppl=25.34, wps=22308.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3900, lr=0.000487503, gnorm=1.046, loss_scale=16, train_wall=263, gb_free=8.1, wall=11623
2022-03-06 16:06:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:07:34 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.028 | nll_loss 7.901 | ppl 239.1 | wps 42136.6 | wpb 510.9 | bsz 1 | num_updates 3947 | best_loss 8.481
2022-03-06 16:07:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 3947 updates
2022-03-06 16:07:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:07:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:07:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 41 @ 3947 updates, score 9.028) (writing took 2.10463427612558 seconds)
2022-03-06 16:07:36 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 16:07:36 | INFO | train | epoch 041 | loss 6.002 | nll_loss 4.613 | ppl 24.47 | wps 22056.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3947 | lr 0.000493376 | gnorm 1.053 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 11768
2022-03-06 16:07:36 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 16:07:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:10:08 | INFO | train_inner | epoch 042:     53 / 97 loss=5.956, nll_loss=4.56, ppl=23.58, wps=22081.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=4000, lr=0.0005, gnorm=1.01, loss_scale=16, train_wall=266, gb_free=8.1, wall=11920
2022-03-06 16:12:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:12:19 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.119 | nll_loss 8.004 | ppl 256.77 | wps 42217 | wpb 510.9 | bsz 1 | num_updates 4044 | best_loss 8.481
2022-03-06 16:12:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4044 updates
2022-03-06 16:12:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:12:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 42 @ 4044 updates, score 9.119) (writing took 2.1290403278544545 seconds)
2022-03-06 16:12:21 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 16:12:21 | INFO | train | epoch 042 | loss 5.916 | nll_loss 4.514 | ppl 22.84 | wps 22258.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4044 | lr 0.000497272 | gnorm 1.008 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 12053
2022-03-06 16:12:21 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 16:12:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:12:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:15:05 | INFO | train_inner | epoch 043:     57 / 97 loss=5.864, nll_loss=4.454, ppl=21.92, wps=22072.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4100, lr=0.000493865, gnorm=1.024, loss_scale=16, train_wall=266, gb_free=8.1, wall=12217
2022-03-06 16:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:17:04 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.136 | nll_loss 8.014 | ppl 258.56 | wps 42715.7 | wpb 510.9 | bsz 1 | num_updates 4140 | best_loss 8.481
2022-03-06 16:17:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4140 updates
2022-03-06 16:17:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:17:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:17:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 43 @ 4140 updates, score 9.136) (writing took 2.1768552400171757 seconds)
2022-03-06 16:17:06 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 16:17:06 | INFO | train | epoch 043 | loss 5.824 | nll_loss 4.409 | ppl 21.24 | wps 22058.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4140 | lr 0.000491473 | gnorm 1.008 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 12338
2022-03-06 16:17:06 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 16:17:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:18:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:20:01 | INFO | train_inner | epoch 044:     61 / 97 loss=5.776, nll_loss=4.353, ppl=20.43, wps=22096.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=4200, lr=0.00048795, gnorm=1.02, loss_scale=8, train_wall=266, gb_free=8.1, wall=12513
2022-03-06 16:21:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:21:49 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.204 | nll_loss 8.068 | ppl 268.28 | wps 42861.8 | wpb 510.9 | bsz 1 | num_updates 4236 | best_loss 8.481
2022-03-06 16:21:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4236 updates
2022-03-06 16:21:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:21:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:21:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 44 @ 4236 updates, score 9.204) (writing took 2.150305981282145 seconds)
2022-03-06 16:21:51 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 16:21:51 | INFO | train | epoch 044 | loss 5.74 | nll_loss 4.311 | ppl 19.85 | wps 22058.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4236 | lr 0.000485872 | gnorm 1.025 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 12623
2022-03-06 16:21:51 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 16:21:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:24:55 | INFO | train_inner | epoch 045:     64 / 97 loss=5.685, nll_loss=4.247, ppl=18.99, wps=22295.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4300, lr=0.000482243, gnorm=1.022, loss_scale=16, train_wall=263, gb_free=8.1, wall=12807
2022-03-06 16:26:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:26:34 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.281 | nll_loss 8.143 | ppl 282.76 | wps 42740.3 | wpb 510.9 | bsz 1 | num_updates 4333 | best_loss 8.481
2022-03-06 16:26:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4333 updates
2022-03-06 16:26:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:26:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:26:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 45 @ 4333 updates, score 9.281) (writing took 2.13544499874115 seconds)
2022-03-06 16:26:37 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 16:26:37 | INFO | train | epoch 045 | loss 5.653 | nll_loss 4.211 | ppl 18.52 | wps 22283.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4333 | lr 0.000480403 | gnorm 1.007 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 12908
2022-03-06 16:26:37 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 16:26:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:29:48 | INFO | train_inner | epoch 046:     67 / 97 loss=5.597, nll_loss=4.146, ppl=17.71, wps=22302.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4400, lr=0.000476731, gnorm=1.012, loss_scale=16, train_wall=263, gb_free=8.1, wall=13100
2022-03-06 16:30:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:31:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:31:19 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.392 | nll_loss 8.269 | ppl 308.43 | wps 42751.7 | wpb 510.9 | bsz 1 | num_updates 4429 | best_loss 8.481
2022-03-06 16:31:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4429 updates
2022-03-06 16:31:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:31:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:31:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 46 @ 4429 updates, score 9.392) (writing took 2.1413332200609148 seconds)
2022-03-06 16:31:22 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 16:31:22 | INFO | train | epoch 046 | loss 5.57 | nll_loss 4.115 | ppl 17.33 | wps 22060.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4429 | lr 0.000475168 | gnorm 1.008 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 13193
2022-03-06 16:31:22 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 16:31:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:32:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:34:48 | INFO | train_inner | epoch 047:     72 / 97 loss=5.513, nll_loss=4.049, ppl=16.56, wps=21888.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=4500, lr=0.000471405, gnorm=0.986, loss_scale=8, train_wall=268, gb_free=8.1, wall=13400
2022-03-06 16:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:36:04 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.479 | nll_loss 8.373 | ppl 331.48 | wps 42935.7 | wpb 510.9 | bsz 1 | num_updates 4525 | best_loss 8.481
2022-03-06 16:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4525 updates
2022-03-06 16:36:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:36:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:36:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 47 @ 4525 updates, score 9.479) (writing took 2.125593404751271 seconds)
2022-03-06 16:36:07 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 16:36:07 | INFO | train | epoch 047 | loss 5.488 | nll_loss 4.02 | ppl 16.23 | wps 22059.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4525 | lr 0.0004701 | gnorm 0.997 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 13478
2022-03-06 16:36:07 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 16:36:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:39:41 | INFO | train_inner | epoch 048:     75 / 97 loss=5.435, nll_loss=3.959, ppl=15.55, wps=22302, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4600, lr=0.000466252, gnorm=0.992, loss_scale=16, train_wall=263, gb_free=8.1, wall=13693
2022-03-06 16:39:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:40:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:40:49 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.552 | nll_loss 8.424 | ppl 343.49 | wps 43149.4 | wpb 510.9 | bsz 1 | num_updates 4621 | best_loss 8.481
2022-03-06 16:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4621 updates
2022-03-06 16:40:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:40:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 48 @ 4621 updates, score 9.552) (writing took 2.1096580396406353 seconds)
2022-03-06 16:40:51 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 16:40:51 | INFO | train | epoch 048 | loss 5.413 | nll_loss 3.934 | ppl 15.28 | wps 22066.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4621 | lr 0.000465192 | gnorm 0.998 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 13763
2022-03-06 16:40:51 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 16:40:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:44:38 | INFO | train_inner | epoch 049:     79 / 97 loss=5.356, nll_loss=3.868, ppl=14.6, wps=22092.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4700, lr=0.000461266, gnorm=1.024, loss_scale=8, train_wall=266, gb_free=8.1, wall=13990
2022-03-06 16:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:45:34 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.586 | nll_loss 8.477 | ppl 356.28 | wps 42989.7 | wpb 510.9 | bsz 1 | num_updates 4718 | best_loss 8.481
2022-03-06 16:45:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 4718 updates
2022-03-06 16:45:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:45:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:45:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 49 @ 4718 updates, score 9.586) (writing took 2.1551961130462587 seconds)
2022-03-06 16:45:36 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 16:45:36 | INFO | train | epoch 049 | loss 5.341 | nll_loss 3.85 | ppl 14.42 | wps 22291.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4718 | lr 0.000460385 | gnorm 1.011 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 14048
2022-03-06 16:45:36 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 16:45:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:46:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:49:34 | INFO | train_inner | epoch 050:     83 / 97 loss=5.278, nll_loss=3.778, ppl=13.72, wps=22111.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=4800, lr=0.000456435, gnorm=0.997, loss_scale=8, train_wall=266, gb_free=8.1, wall=14286
2022-03-06 16:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:50:19 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.69 | nll_loss 8.588 | ppl 384.75 | wps 42808.7 | wpb 510.9 | bsz 1 | num_updates 4814 | best_loss 8.481
2022-03-06 16:50:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 4814 updates
2022-03-06 16:50:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:50:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:50:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 50 @ 4814 updates, score 9.69) (writing took 2.112582210917026 seconds)
2022-03-06 16:50:21 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 16:50:21 | INFO | train | epoch 050 | loss 5.264 | nll_loss 3.761 | ppl 13.56 | wps 22077.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4814 | lr 0.000455771 | gnorm 1 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 14333
2022-03-06 16:50:21 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 16:50:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:53:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:54:31 | INFO | train_inner | epoch 051:     87 / 97 loss=5.213, nll_loss=3.701, ppl=13.01, wps=22080.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=4900, lr=0.000451754, gnorm=0.992, loss_scale=8, train_wall=266, gb_free=8.1, wall=14582
2022-03-06 16:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:55:04 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.735 | nll_loss 8.627 | ppl 395.49 | wps 43021.6 | wpb 510.9 | bsz 1 | num_updates 4910 | best_loss 8.481
2022-03-06 16:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 4910 updates
2022-03-06 16:55:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:55:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:55:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 51 @ 4910 updates, score 9.735) (writing took 2.444626742042601 seconds)
2022-03-06 16:55:07 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 16:55:07 | INFO | train | epoch 051 | loss 5.197 | nll_loss 3.684 | ppl 12.85 | wps 22027.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4910 | lr 0.000451294 | gnorm 0.994 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 14619
2022-03-06 16:55:07 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 16:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:59:24 | INFO | train_inner | epoch 052:     90 / 97 loss=5.138, nll_loss=3.615, ppl=12.25, wps=22283.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5000, lr=0.000447214, gnorm=1.008, loss_scale=8, train_wall=263, gb_free=8.1, wall=14876
2022-03-06 16:59:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:59:50 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.853 | nll_loss 8.761 | ppl 433.87 | wps 42651.8 | wpb 510.9 | bsz 1 | num_updates 5007 | best_loss 8.481
2022-03-06 16:59:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5007 updates
2022-03-06 16:59:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:59:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:59:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 52 @ 5007 updates, score 9.853) (writing took 2.2574841999448836 seconds)
2022-03-06 16:59:52 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 16:59:52 | INFO | train | epoch 052 | loss 5.131 | nll_loss 3.607 | ppl 12.18 | wps 22275.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5007 | lr 0.000446901 | gnorm 1.009 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 14904
2022-03-06 16:59:52 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 16:59:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:01:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:04:21 | INFO | train_inner | epoch 053:     94 / 97 loss=5.071, nll_loss=3.538, ppl=11.61, wps=22069.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5100, lr=0.000442807, gnorm=1.007, loss_scale=8, train_wall=266, gb_free=8.1, wall=15173
2022-03-06 17:04:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:04:35 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.858 | nll_loss 8.751 | ppl 430.81 | wps 42357.4 | wpb 510.9 | bsz 1 | num_updates 5103 | best_loss 8.481
2022-03-06 17:04:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5103 updates
2022-03-06 17:04:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:04:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:04:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 53 @ 5103 updates, score 9.858) (writing took 2.3172823856584728 seconds)
2022-03-06 17:04:37 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 17:04:37 | INFO | train | epoch 053 | loss 5.064 | nll_loss 3.53 | ppl 11.55 | wps 22029.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5103 | lr 0.000442677 | gnorm 1.005 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 15189
2022-03-06 17:04:37 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 17:04:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:08:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:09:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:09:21 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.957 | nll_loss 8.856 | ppl 463.49 | wps 42983.1 | wpb 510.9 | bsz 1 | num_updates 5199 | best_loss 8.481
2022-03-06 17:09:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5199 updates
2022-03-06 17:09:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:09:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:09:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 54 @ 5199 updates, score 9.957) (writing took 2.306881145108491 seconds)
2022-03-06 17:09:23 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 17:09:23 | INFO | train | epoch 054 | loss 5.001 | nll_loss 3.456 | ppl 10.97 | wps 22008.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5199 | lr 0.000438571 | gnorm 0.997 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 15475
2022-03-06 17:09:23 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 17:09:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:09:26 | INFO | train_inner | epoch 055:      1 / 97 loss=5.003, nll_loss=3.459, ppl=10.99, wps=21488, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=5200, lr=0.000438529, gnorm=0.993, loss_scale=8, train_wall=266, gb_free=8.1, wall=15478
2022-03-06 17:14:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:14:06 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 10.004 | nll_loss 8.91 | ppl 480.93 | wps 42673.8 | wpb 510.9 | bsz 1 | num_updates 5296 | best_loss 8.481
2022-03-06 17:14:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5296 updates
2022-03-06 17:14:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:14:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:14:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 55 @ 5296 updates, score 10.004) (writing took 2.2948888959363103 seconds)
2022-03-06 17:14:09 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 17:14:09 | INFO | train | epoch 055 | loss 4.941 | nll_loss 3.387 | ppl 10.46 | wps 22237 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5296 | lr 0.000434536 | gnorm 0.995 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 15760
2022-03-06 17:14:09 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 17:14:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:14:20 | INFO | train_inner | epoch 056:      4 / 97 loss=4.936, nll_loss=3.381, ppl=10.42, wps=22256.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5300, lr=0.000434372, gnorm=0.993, loss_scale=8, train_wall=264, gb_free=8.1, wall=15772
2022-03-06 17:15:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:18:51 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 10.135 | nll_loss 9.067 | ppl 536.49 | wps 42778.8 | wpb 510.9 | bsz 1 | num_updates 5392 | best_loss 8.481
2022-03-06 17:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5392 updates
2022-03-06 17:18:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:18:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:18:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 56 @ 5392 updates, score 10.135) (writing took 2.3108169129118323 seconds)
2022-03-06 17:18:54 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 17:18:54 | INFO | train | epoch 056 | loss 4.88 | nll_loss 3.317 | ppl 9.96 | wps 22041.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5392 | lr 0.000430651 | gnorm 0.999 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 16046
2022-03-06 17:18:54 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 17:18:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:19:17 | INFO | train_inner | epoch 057:      8 / 97 loss=4.875, nll_loss=3.31, ppl=9.92, wps=22077.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5400, lr=0.000430331, gnorm=1.004, loss_scale=8, train_wall=266, gb_free=8.1, wall=16069
2022-03-06 17:23:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:23:37 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 10.222 | nll_loss 9.12 | ppl 556.57 | wps 43235.5 | wpb 510.9 | bsz 1 | num_updates 5489 | best_loss 8.481
2022-03-06 17:23:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5489 updates
2022-03-06 17:23:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:23:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:23:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 57 @ 5489 updates, score 10.222) (writing took 2.2909972639754415 seconds)
2022-03-06 17:23:39 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 17:23:39 | INFO | train | epoch 057 | loss 4.825 | nll_loss 3.253 | ppl 9.53 | wps 22289.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5489 | lr 0.000426828 | gnorm 0.997 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 16331
2022-03-06 17:23:39 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 17:23:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:23:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:24:13 | INFO | train_inner | epoch 058:     12 / 97 loss=4.817, nll_loss=3.243, ppl=9.47, wps=22086.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5500, lr=0.000426401, gnorm=0.993, loss_scale=8, train_wall=266, gb_free=8.1, wall=16365
2022-03-06 17:28:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:28:22 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 10.246 | nll_loss 9.165 | ppl 573.88 | wps 42838.2 | wpb 510.9 | bsz 1 | num_updates 5585 | best_loss 8.481
2022-03-06 17:28:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5585 updates
2022-03-06 17:28:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:28:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:28:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 58 @ 5585 updates, score 10.246) (writing took 2.3078109822236 seconds)
2022-03-06 17:28:24 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 17:28:24 | INFO | train | epoch 058 | loss 4.771 | nll_loss 3.189 | ppl 9.12 | wps 22047 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5585 | lr 0.000423144 | gnorm 1.004 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 16616
2022-03-06 17:28:24 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 17:28:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:29:07 | INFO | train_inner | epoch 059:     15 / 97 loss=4.763, nll_loss=3.18, ppl=9.06, wps=22295.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=5600, lr=0.000422577, gnorm=1.003, loss_scale=8, train_wall=263, gb_free=8.1, wall=16659
2022-03-06 17:33:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:33:07 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 10.366 | nll_loss 9.3 | ppl 630.21 | wps 42750.8 | wpb 510.9 | bsz 1 | num_updates 5682 | best_loss 8.481
2022-03-06 17:33:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 5682 updates
2022-03-06 17:33:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:33:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:33:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 59 @ 5682 updates, score 10.366) (writing took 2.2980416202917695 seconds)
2022-03-06 17:33:10 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 17:33:10 | INFO | train | epoch 059 | loss 4.719 | nll_loss 3.129 | ppl 8.75 | wps 22248.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5682 | lr 0.000419517 | gnorm 1.003 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 16901
2022-03-06 17:33:10 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 17:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:33:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:34:04 | INFO | train_inner | epoch 060:     19 / 97 loss=4.705, nll_loss=3.113, ppl=8.65, wps=22048.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=5700, lr=0.000418854, gnorm=1.01, loss_scale=8, train_wall=266, gb_free=8.1, wall=16956
2022-03-06 17:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:37:53 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 10.37 | nll_loss 9.283 | ppl 622.92 | wps 42643.1 | wpb 510.9 | bsz 1 | num_updates 5778 | best_loss 8.481
2022-03-06 17:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 5778 updates
2022-03-06 17:37:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 60 @ 5778 updates, score 10.37) (writing took 2.3513813028112054 seconds)
2022-03-06 17:37:55 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 17:37:55 | INFO | train | epoch 060 | loss 4.667 | nll_loss 3.069 | ppl 8.39 | wps 22003.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5778 | lr 0.000416017 | gnorm 1.016 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 17187
2022-03-06 17:37:55 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 17:37:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:38:58 | INFO | train_inner | epoch 061:     22 / 97 loss=4.657, nll_loss=3.057, ppl=8.32, wps=22249.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5800, lr=0.000415227, gnorm=1.006, loss_scale=8, train_wall=264, gb_free=8.1, wall=17250
2022-03-06 17:42:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:42:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:42:39 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 10.433 | nll_loss 9.336 | ppl 646.33 | wps 42758.3 | wpb 510.9 | bsz 1 | num_updates 5874 | best_loss 8.481
2022-03-06 17:42:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 5874 updates
2022-03-06 17:42:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:42:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:42:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 61 @ 5874 updates, score 10.433) (writing took 2.3042196477763355 seconds)
2022-03-06 17:42:41 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 17:42:41 | INFO | train | epoch 061 | loss 4.619 | nll_loss 3.012 | ppl 8.07 | wps 22007.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5874 | lr 0.000412604 | gnorm 1 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 17473
2022-03-06 17:42:41 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 17:42:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:43:56 | INFO | train_inner | epoch 062:     26 / 97 loss=4.6, nll_loss=2.991, ppl=7.95, wps=22043.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=5900, lr=0.000411693, gnorm=1.009, loss_scale=8, train_wall=266, gb_free=8.1, wall=17547
2022-03-06 17:47:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:47:24 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 10.523 | nll_loss 9.443 | ppl 695.93 | wps 42769.4 | wpb 510.9 | bsz 1 | num_updates 5971 | best_loss 8.481
2022-03-06 17:47:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 5971 updates
2022-03-06 17:47:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 62 @ 5971 updates, score 10.523) (writing took 2.451221819035709 seconds)
2022-03-06 17:47:26 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 17:47:26 | INFO | train | epoch 062 | loss 4.574 | nll_loss 2.96 | ppl 7.78 | wps 22252.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5971 | lr 0.000409238 | gnorm 1.011 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 17758
2022-03-06 17:47:26 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 17:47:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:48:50 | INFO | train_inner | epoch 063:     29 / 97 loss=4.558, nll_loss=2.942, ppl=7.69, wps=22274.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=6000, lr=0.000408248, gnorm=0.998, loss_scale=16, train_wall=263, gb_free=8.1, wall=17841
2022-03-06 17:49:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:52:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:52:09 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 10.606 | nll_loss 9.541 | ppl 744.76 | wps 42630 | wpb 510.9 | bsz 1 | num_updates 6067 | best_loss 8.481
2022-03-06 17:52:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6067 updates
2022-03-06 17:52:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:52:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:52:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 63 @ 6067 updates, score 10.606) (writing took 2.3189319488592446 seconds)
2022-03-06 17:52:12 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 17:52:12 | INFO | train | epoch 063 | loss 4.524 | nll_loss 2.902 | ppl 7.47 | wps 22035 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6067 | lr 0.000405988 | gnorm 0.993 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 18044
2022-03-06 17:52:12 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 17:52:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:53:46 | INFO | train_inner | epoch 064:     33 / 97 loss=4.51, nll_loss=2.886, ppl=7.39, wps=22071.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6100, lr=0.000404888, gnorm=0.999, loss_scale=8, train_wall=266, gb_free=8.1, wall=18138
2022-03-06 17:56:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:56:55 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 10.625 | nll_loss 9.55 | ppl 749.73 | wps 42877.3 | wpb 510.9 | bsz 1 | num_updates 6163 | best_loss 8.481
2022-03-06 17:56:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6163 updates
2022-03-06 17:56:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:56:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:56:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 64 @ 6163 updates, score 10.625) (writing took 2.3176762009970844 seconds)
2022-03-06 17:56:57 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 17:56:57 | INFO | train | epoch 064 | loss 4.484 | nll_loss 2.856 | ppl 7.24 | wps 22051.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6163 | lr 0.000402813 | gnorm 1.016 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 18329
2022-03-06 17:56:57 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 17:56:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:58:43 | INFO | train_inner | epoch 065:     37 / 97 loss=4.463, nll_loss=2.831, ppl=7.12, wps=22079.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6200, lr=0.00040161, gnorm=1.013, loss_scale=8, train_wall=266, gb_free=8.1, wall=18435
2022-03-06 18:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:01:40 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.683 | nll_loss 9.612 | ppl 782.45 | wps 42476.5 | wpb 510.9 | bsz 1 | num_updates 6260 | best_loss 8.481
2022-03-06 18:01:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6260 updates
2022-03-06 18:01:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:01:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:01:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 65 @ 6260 updates, score 10.683) (writing took 2.309048881288618 seconds)
2022-03-06 18:01:42 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 18:01:42 | INFO | train | epoch 065 | loss 4.439 | nll_loss 2.804 | ppl 6.98 | wps 22244.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6260 | lr 0.00039968 | gnorm 1.006 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 18614
2022-03-06 18:01:42 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 18:01:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:03:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:03:40 | INFO | train_inner | epoch 066:     41 / 97 loss=4.424, nll_loss=2.786, ppl=6.9, wps=22047.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=6300, lr=0.00039841, gnorm=1.006, loss_scale=8, train_wall=266, gb_free=8.1, wall=18732
2022-03-06 18:06:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:06:26 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.753 | nll_loss 9.681 | ppl 821.11 | wps 42876.2 | wpb 510.9 | bsz 1 | num_updates 6356 | best_loss 8.481
2022-03-06 18:06:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6356 updates
2022-03-06 18:06:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:06:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:06:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 66 @ 6356 updates, score 10.753) (writing took 2.3120016548782587 seconds)
2022-03-06 18:06:28 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 18:06:28 | INFO | train | epoch 066 | loss 4.397 | nll_loss 2.755 | ppl 6.75 | wps 22023.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6356 | lr 0.000396651 | gnorm 1.003 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 18900
2022-03-06 18:06:28 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 18:06:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:08:34 | INFO | train_inner | epoch 067:     44 / 97 loss=4.382, nll_loss=2.737, ppl=6.67, wps=22266.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6400, lr=0.000395285, gnorm=1.01, loss_scale=8, train_wall=264, gb_free=8.1, wall=19026
2022-03-06 18:09:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:11:11 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.811 | nll_loss 9.746 | ppl 858.54 | wps 42625.9 | wpb 510.9 | bsz 1 | num_updates 6452 | best_loss 8.481
2022-03-06 18:11:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6452 updates
2022-03-06 18:11:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:11:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:11:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 67 @ 6452 updates, score 10.811) (writing took 2.301757261622697 seconds)
2022-03-06 18:11:13 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 18:11:13 | INFO | train | epoch 067 | loss 4.361 | nll_loss 2.712 | ppl 6.55 | wps 22023 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6452 | lr 0.000393689 | gnorm 1.021 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 19185
2022-03-06 18:11:13 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 18:11:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:13:31 | INFO | train_inner | epoch 068:     48 / 97 loss=4.342, nll_loss=2.69, ppl=6.45, wps=22051.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6500, lr=0.000392232, gnorm=1.015, loss_scale=8, train_wall=266, gb_free=8.1, wall=19323
2022-03-06 18:15:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:15:57 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.866 | nll_loss 9.815 | ppl 900.92 | wps 42279 | wpb 510.9 | bsz 1 | num_updates 6549 | best_loss 8.481
2022-03-06 18:15:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6549 updates
2022-03-06 18:15:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:15:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:15:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 68 @ 6549 updates, score 10.866) (writing took 2.32145326025784 seconds)
2022-03-06 18:15:59 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 18:15:59 | INFO | train | epoch 068 | loss 4.32 | nll_loss 2.665 | ppl 6.34 | wps 22251.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6549 | lr 0.000390762 | gnorm 1.01 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 19471
2022-03-06 18:15:59 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 18:15:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:17:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:18:28 | INFO | train_inner | epoch 069:     52 / 97 loss=4.302, nll_loss=2.644, ppl=6.25, wps=22077.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=6600, lr=0.000389249, gnorm=1.015, loss_scale=8, train_wall=266, gb_free=8.1, wall=19620
2022-03-06 18:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:20:42 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.96 | nll_loss 9.916 | ppl 966.06 | wps 42698.7 | wpb 510.9 | bsz 1 | num_updates 6645 | best_loss 8.481
2022-03-06 18:20:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 6645 updates
2022-03-06 18:20:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:20:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:20:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 69 @ 6645 updates, score 10.96) (writing took 2.452111870981753 seconds)
2022-03-06 18:20:44 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 18:20:44 | INFO | train | epoch 069 | loss 4.282 | nll_loss 2.62 | ppl 6.15 | wps 22038.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6645 | lr 0.000387929 | gnorm 1.011 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 19756
2022-03-06 18:20:44 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 18:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:23:22 | INFO | train_inner | epoch 070:     55 / 97 loss=4.263, nll_loss=2.598, ppl=6.06, wps=22276.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=6700, lr=0.000386334, gnorm=1.004, loss_scale=8, train_wall=263, gb_free=8.1, wall=19914
2022-03-06 18:25:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:25:27 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.998 | nll_loss 9.95 | ppl 989.42 | wps 42810.1 | wpb 510.9 | bsz 1 | num_updates 6742 | best_loss 8.481
2022-03-06 18:25:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 6742 updates
2022-03-06 18:25:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:25:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:25:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 70 @ 6742 updates, score 10.998) (writing took 2.338268811814487 seconds)
2022-03-06 18:25:30 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 18:25:30 | INFO | train | epoch 070 | loss 4.246 | nll_loss 2.579 | ppl 5.98 | wps 22262 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6742 | lr 0.000385128 | gnorm 0.999 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 20041
2022-03-06 18:25:30 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 18:25:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:26:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:28:18 | INFO | train_inner | epoch 071:     59 / 97 loss=4.23, nll_loss=2.561, ppl=5.9, wps=22078, ups=0.34, wpb=65495, bsz=127.9, num_updates=6800, lr=0.000383482, gnorm=1.013, loss_scale=8, train_wall=266, gb_free=8.1, wall=20210
2022-03-06 18:30:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:30:13 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 11.002 | nll_loss 9.939 | ppl 981.63 | wps 42787.9 | wpb 510.9 | bsz 1 | num_updates 6838 | best_loss 8.481
2022-03-06 18:30:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 6838 updates
2022-03-06 18:30:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:30:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:30:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 71 @ 6838 updates, score 11.002) (writing took 2.3609356679953635 seconds)
2022-03-06 18:30:15 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 18:30:15 | INFO | train | epoch 071 | loss 4.212 | nll_loss 2.54 | ppl 5.82 | wps 22033.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6838 | lr 0.000382415 | gnorm 1.016 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 20327
2022-03-06 18:30:15 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 18:30:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:32:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:33:16 | INFO | train_inner | epoch 072:     63 / 97 loss=4.188, nll_loss=2.512, ppl=5.7, wps=22043.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6900, lr=0.000380693, gnorm=1.008, loss_scale=8, train_wall=266, gb_free=8.1, wall=20508
2022-03-06 18:34:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:34:58 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 11.066 | nll_loss 10.024 | ppl 1041.48 | wps 42695.2 | wpb 510.9 | bsz 1 | num_updates 6934 | best_loss 8.481
2022-03-06 18:34:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 6934 updates
2022-03-06 18:34:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:35:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:35:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 72 @ 6934 updates, score 11.066) (writing took 2.3347063283436 seconds)
2022-03-06 18:35:00 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 18:35:00 | INFO | train | epoch 072 | loss 4.178 | nll_loss 2.499 | ppl 5.65 | wps 22012.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6934 | lr 0.000379759 | gnorm 1.005 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 20612
2022-03-06 18:35:01 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 18:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:38:10 | INFO | train_inner | epoch 073:     66 / 97 loss=4.159, nll_loss=2.478, ppl=5.57, wps=22247, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7000, lr=0.000377964, gnorm=1.006, loss_scale=8, train_wall=264, gb_free=8.1, wall=20802
2022-03-06 18:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:39:44 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 11.142 | nll_loss 10.109 | ppl 1104.3 | wps 42388.5 | wpb 510.9 | bsz 1 | num_updates 7031 | best_loss 8.481
2022-03-06 18:39:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7031 updates
2022-03-06 18:39:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:39:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:39:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 73 @ 7031 updates, score 11.142) (writing took 2.388188944198191 seconds)
2022-03-06 18:39:46 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 18:39:46 | INFO | train | epoch 073 | loss 4.146 | nll_loss 2.463 | ppl 5.51 | wps 22211.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7031 | lr 0.00037713 | gnorm 1.009 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 20898
2022-03-06 18:39:47 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 18:39:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:40:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:43:08 | INFO | train_inner | epoch 074:     70 / 97 loss=4.123, nll_loss=2.437, ppl=5.41, wps=22012.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7100, lr=0.000375293, gnorm=1.016, loss_scale=8, train_wall=266, gb_free=8.1, wall=21099
2022-03-06 18:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:44:30 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 11.142 | nll_loss 10.112 | ppl 1106.84 | wps 43021.4 | wpb 510.9 | bsz 1 | num_updates 7127 | best_loss 8.481
2022-03-06 18:44:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7127 updates
2022-03-06 18:44:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:44:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:44:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 74 @ 7127 updates, score 11.142) (writing took 2.3743775081820786 seconds)
2022-03-06 18:44:32 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 18:44:32 | INFO | train | epoch 074 | loss 4.113 | nll_loss 2.425 | ppl 5.37 | wps 21993.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7127 | lr 0.000374582 | gnorm 1.01 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 21184
2022-03-06 18:44:32 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 18:44:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:46:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:48:05 | INFO | train_inner | epoch 075:     74 / 97 loss=4.095, nll_loss=2.404, ppl=5.29, wps=22047.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=7200, lr=0.000372678, gnorm=1.001, loss_scale=8, train_wall=266, gb_free=8.1, wall=21396
2022-03-06 18:49:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:49:17 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 11.232 | nll_loss 10.192 | ppl 1169.92 | wps 40032 | wpb 510.9 | bsz 1 | num_updates 7223 | best_loss 8.481
2022-03-06 18:49:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7223 updates
2022-03-06 18:49:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:49:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:49:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 75 @ 7223 updates, score 11.232) (writing took 2.4576875106431544 seconds)
2022-03-06 18:49:19 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 18:49:19 | INFO | train | epoch 075 | loss 4.084 | nll_loss 2.391 | ppl 5.25 | wps 21899.2 | ups 0.33 | wpb 65493.3 | bsz 127.9 | num_updates 7223 | lr 0.000372084 | gnorm 0.999 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 21471
2022-03-06 18:49:19 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 18:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:53:03 | INFO | train_inner | epoch 076:     77 / 97 loss=4.062, nll_loss=2.366, ppl=5.15, wps=21925.4, ups=0.33, wpb=65495, bsz=127.9, num_updates=7300, lr=0.000370117, gnorm=0.992, loss_scale=8, train_wall=266, gb_free=8.1, wall=21695
2022-03-06 18:53:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:54:06 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 11.218 | nll_loss 10.188 | ppl 1166.35 | wps 42813.2 | wpb 510.9 | bsz 1 | num_updates 7319 | best_loss 8.481
2022-03-06 18:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7319 updates
2022-03-06 18:54:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:54:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 76 @ 7319 updates, score 11.218) (writing took 2.4739713575690985 seconds)
2022-03-06 18:54:08 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 18:54:08 | INFO | train | epoch 076 | loss 4.054 | nll_loss 2.356 | ppl 5.12 | wps 21772 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 7319 | lr 0.000369636 | gnorm 0.995 | loss_scale 8 | train_wall 258 | gb_free 8.1 | wall 21760
2022-03-06 18:54:08 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 18:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:58:01 | INFO | train_inner | epoch 077:     81 / 97 loss=4.031, nll_loss=2.33, ppl=5.03, wps=22014.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7400, lr=0.000367607, gnorm=0.999, loss_scale=8, train_wall=266, gb_free=8.1, wall=21993
2022-03-06 18:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:58:52 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 11.27 | nll_loss 10.229 | ppl 1200.22 | wps 42293.4 | wpb 510.9 | bsz 1 | num_updates 7416 | best_loss 8.481
2022-03-06 18:58:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7416 updates
2022-03-06 18:58:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:58:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 77 @ 7416 updates, score 11.27) (writing took 2.6360215982422233 seconds)
2022-03-06 18:58:54 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 18:58:54 | INFO | train | epoch 077 | loss 4.027 | nll_loss 2.325 | ppl 5.01 | wps 22196.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7416 | lr 0.000367211 | gnorm 1.01 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 22046
2022-03-06 18:58:54 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 18:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:02:56 | INFO | train_inner | epoch 078:     84 / 97 loss=4.006, nll_loss=2.3, ppl=4.92, wps=22196, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7500, lr=0.000365148, gnorm=1.01, loss_scale=16, train_wall=264, gb_free=8.1, wall=22288
2022-03-06 19:03:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:03:38 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.385 | nll_loss 10.362 | ppl 1316.45 | wps 42422.8 | wpb 510.9 | bsz 1 | num_updates 7513 | best_loss 8.481
2022-03-06 19:03:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 7513 updates
2022-03-06 19:03:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:03:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:03:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 78 @ 7513 updates, score 11.385) (writing took 2.6551535790786147 seconds)
2022-03-06 19:03:41 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 19:03:41 | INFO | train | epoch 078 | loss 3.997 | nll_loss 2.29 | ppl 4.89 | wps 22172.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7513 | lr 0.000364832 | gnorm 1.002 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 22333
2022-03-06 19:03:41 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 19:03:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:04:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:07:54 | INFO | train_inner | epoch 079:     88 / 97 loss=3.975, nll_loss=2.265, ppl=4.81, wps=21976.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=7600, lr=0.000362738, gnorm=1.002, loss_scale=8, train_wall=267, gb_free=8.1, wall=22586
2022-03-06 19:08:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:08:25 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.375 | nll_loss 10.342 | ppl 1297.72 | wps 42775.6 | wpb 510.9 | bsz 1 | num_updates 7609 | best_loss 8.481
2022-03-06 19:08:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 7609 updates
2022-03-06 19:08:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:08:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 79 @ 7609 updates, score 11.375) (writing took 2.567579068709165 seconds)
2022-03-06 19:08:27 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 19:08:27 | INFO | train | epoch 079 | loss 3.969 | nll_loss 2.257 | ppl 4.78 | wps 21960.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7609 | lr 0.000362524 | gnorm 0.997 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 22619
2022-03-06 19:08:27 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 19:08:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:12:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:12:51 | INFO | train_inner | epoch 080:     92 / 97 loss=3.951, nll_loss=2.237, ppl=4.71, wps=22028.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7700, lr=0.000360375, gnorm=1.016, loss_scale=8, train_wall=266, gb_free=8.1, wall=22883
2022-03-06 19:13:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:13:10 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.409 | nll_loss 10.386 | ppl 1338.51 | wps 42849.2 | wpb 510.9 | bsz 1 | num_updates 7705 | best_loss 8.481
2022-03-06 19:13:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 7705 updates
2022-03-06 19:13:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:13:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:13:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 80 @ 7705 updates, score 11.409) (writing took 2.3604388968087733 seconds)
2022-03-06 19:13:13 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 19:13:13 | INFO | train | epoch 080 | loss 3.946 | nll_loss 2.231 | ppl 4.69 | wps 22016 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7705 | lr 0.000360258 | gnorm 1.021 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 22905
2022-03-06 19:13:13 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 19:13:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:17:45 | INFO | train_inner | epoch 081:     95 / 97 loss=3.923, nll_loss=2.204, ppl=4.61, wps=22266.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7800, lr=0.000358057, gnorm=1.014, loss_scale=8, train_wall=263, gb_free=8.1, wall=23177
2022-03-06 19:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:17:56 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.462 | nll_loss 10.439 | ppl 1387.72 | wps 42637.4 | wpb 510.9 | bsz 1 | num_updates 7802 | best_loss 8.481
2022-03-06 19:17:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 7802 updates
2022-03-06 19:17:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:17:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:17:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 81 @ 7802 updates, score 11.462) (writing took 2.3979796459898353 seconds)
2022-03-06 19:17:58 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 19:17:58 | INFO | train | epoch 081 | loss 3.919 | nll_loss 2.2 | ppl 4.6 | wps 22242 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7802 | lr 0.000358012 | gnorm 1.014 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 23190
2022-03-06 19:17:58 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 19:17:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:22:43 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.515 | nll_loss 10.507 | ppl 1455.08 | wps 42570.5 | wpb 510.9 | bsz 1 | num_updates 7899 | best_loss 8.481
2022-03-06 19:22:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 7899 updates
2022-03-06 19:22:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:22:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:22:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 82 @ 7899 updates, score 11.515) (writing took 2.5778724988922477 seconds)
2022-03-06 19:22:45 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 19:22:45 | INFO | train | epoch 082 | loss 3.894 | nll_loss 2.172 | ppl 4.51 | wps 22153.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7899 | lr 0.000355807 | gnorm 1.005 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 23477
2022-03-06 19:22:45 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 19:22:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:22:48 | INFO | train_inner | epoch 083:      1 / 97 loss=3.895, nll_loss=2.173, ppl=4.51, wps=21612.7, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=7900, lr=0.000355784, gnorm=1.006, loss_scale=16, train_wall=264, gb_free=8.1, wall=23480
2022-03-06 19:23:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:27:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:27:29 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.517 | nll_loss 10.508 | ppl 1455.9 | wps 42245.8 | wpb 510.9 | bsz 1 | num_updates 7995 | best_loss 8.481
2022-03-06 19:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 7995 updates
2022-03-06 19:27:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:27:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:27:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 83 @ 7995 updates, score 11.517) (writing took 2.631715439260006 seconds)
2022-03-06 19:27:31 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 19:27:31 | INFO | train | epoch 083 | loss 3.869 | nll_loss 2.142 | ppl 4.41 | wps 21968.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7995 | lr 0.000353664 | gnorm 1.003 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 23763
2022-03-06 19:27:31 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 19:27:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:27:46 | INFO | train_inner | epoch 084:      5 / 97 loss=3.864, nll_loss=2.137, ppl=4.4, wps=22002.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8000, lr=0.000353553, gnorm=1.006, loss_scale=8, train_wall=266, gb_free=8.1, wall=23778
2022-03-06 19:30:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:32:15 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.541 | nll_loss 10.523 | ppl 1471.61 | wps 42784.6 | wpb 510.9 | bsz 1 | num_updates 8091 | best_loss 8.481
2022-03-06 19:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8091 updates
2022-03-06 19:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:32:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 84 @ 8091 updates, score 11.541) (writing took 2.6173110269010067 seconds)
2022-03-06 19:32:18 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 19:32:18 | INFO | train | epoch 084 | loss 3.847 | nll_loss 2.117 | ppl 4.34 | wps 21961 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8091 | lr 0.00035156 | gnorm 1.016 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 24050
2022-03-06 19:32:18 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 19:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:32:44 | INFO | train_inner | epoch 085:      9 / 97 loss=3.843, nll_loss=2.112, ppl=4.32, wps=21990.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8100, lr=0.000351364, gnorm=1.009, loss_scale=8, train_wall=266, gb_free=8.1, wall=24076
2022-03-06 19:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:37:01 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.594 | nll_loss 10.58 | ppl 1531.05 | wps 42495.1 | wpb 510.9 | bsz 1 | num_updates 8188 | best_loss 8.481
2022-03-06 19:37:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8188 updates
2022-03-06 19:37:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:37:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:37:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 85 @ 8188 updates, score 11.594) (writing took 2.559975354000926 seconds)
2022-03-06 19:37:04 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 19:37:04 | INFO | train | epoch 085 | loss 3.824 | nll_loss 2.09 | ppl 4.26 | wps 22186.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8188 | lr 0.000349471 | gnorm 1.002 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 24336
2022-03-06 19:37:04 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 19:37:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:37:38 | INFO | train_inner | epoch 086:     12 / 97 loss=3.817, nll_loss=2.083, ppl=4.24, wps=22214.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8200, lr=0.000349215, gnorm=1, loss_scale=16, train_wall=264, gb_free=8.1, wall=24370
2022-03-06 19:39:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:41:47 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.645 | nll_loss 10.638 | ppl 1594.05 | wps 42847.6 | wpb 510.9 | bsz 1 | num_updates 8284 | best_loss 8.481
2022-03-06 19:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8284 updates
2022-03-06 19:41:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:41:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:41:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 86 @ 8284 updates, score 11.645) (writing took 2.480433076620102 seconds)
2022-03-06 19:41:50 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 19:41:50 | INFO | train | epoch 086 | loss 3.802 | nll_loss 2.066 | ppl 4.19 | wps 22018.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8284 | lr 0.00034744 | gnorm 1.008 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 24621
2022-03-06 19:41:50 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 19:41:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:42:36 | INFO | train_inner | epoch 087:     16 / 97 loss=3.798, nll_loss=2.061, ppl=4.17, wps=22048.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8300, lr=0.000347105, gnorm=1.003, loss_scale=8, train_wall=266, gb_free=8.1, wall=24667
2022-03-06 19:46:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:46:33 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.695 | nll_loss 10.693 | ppl 1655.23 | wps 42837.9 | wpb 510.9 | bsz 1 | num_updates 8381 | best_loss 8.481
2022-03-06 19:46:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8381 updates
2022-03-06 19:46:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:46:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:46:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 87 @ 8381 updates, score 11.695) (writing took 2.4175379890948534 seconds)
2022-03-06 19:46:35 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 19:46:35 | INFO | train | epoch 087 | loss 3.78 | nll_loss 2.04 | ppl 4.11 | wps 22248.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8381 | lr 0.000345424 | gnorm 0.996 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 24907
2022-03-06 19:46:35 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 19:46:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:47:30 | INFO | train_inner | epoch 088:     19 / 97 loss=3.773, nll_loss=2.032, ppl=4.09, wps=22269.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8400, lr=0.000345033, gnorm=0.997, loss_scale=16, train_wall=263, gb_free=8.1, wall=24962
2022-03-06 19:49:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:51:18 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.65 | nll_loss 10.639 | ppl 1594.74 | wps 41720.6 | wpb 510.9 | bsz 1 | num_updates 8477 | best_loss 8.481
2022-03-06 19:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 8477 updates
2022-03-06 19:51:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:51:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:51:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 88 @ 8477 updates, score 11.65) (writing took 2.514617837034166 seconds)
2022-03-06 19:51:21 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 19:51:21 | INFO | train | epoch 088 | loss 3.759 | nll_loss 2.016 | ppl 4.04 | wps 21994.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8477 | lr 0.000343462 | gnorm 1.004 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 25193
2022-03-06 19:51:21 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 19:51:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:52:27 | INFO | train_inner | epoch 089:     23 / 97 loss=3.754, nll_loss=2.009, ppl=4.03, wps=22022.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8500, lr=0.000342997, gnorm=1.002, loss_scale=8, train_wall=266, gb_free=8.1, wall=25259
2022-03-06 19:55:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:56:05 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.75 | nll_loss 10.756 | ppl 1729.13 | wps 42255.1 | wpb 510.9 | bsz 1 | num_updates 8574 | best_loss 8.481
2022-03-06 19:56:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 8574 updates
2022-03-06 19:56:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:56:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:56:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 89 @ 8574 updates, score 11.75) (writing took 2.655754319857806 seconds)
2022-03-06 19:56:07 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 19:56:07 | INFO | train | epoch 089 | loss 3.74 | nll_loss 1.994 | ppl 3.98 | wps 22194.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8574 | lr 0.000341514 | gnorm 0.99 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 25479
2022-03-06 19:56:07 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 19:56:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:57:22 | INFO | train_inner | epoch 090:     26 / 97 loss=3.734, nll_loss=1.988, ppl=3.97, wps=22200.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8600, lr=0.000340997, gnorm=0.991, loss_scale=16, train_wall=264, gb_free=8.1, wall=25554
2022-03-06 19:57:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:00:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:00:51 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.769 | nll_loss 10.775 | ppl 1752.64 | wps 42285.9 | wpb 510.9 | bsz 1 | num_updates 8670 | best_loss 8.481
2022-03-06 20:00:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 8670 updates
2022-03-06 20:00:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:00:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:00:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 90 @ 8670 updates, score 11.769) (writing took 2.631255499087274 seconds)
2022-03-06 20:00:54 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 20:00:54 | INFO | train | epoch 090 | loss 3.72 | nll_loss 1.971 | ppl 3.92 | wps 21934.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 8670 | lr 0.000339618 | gnorm 0.999 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 25766
2022-03-06 20:00:54 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 20:00:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:02:20 | INFO | train_inner | epoch 091:     30 / 97 loss=3.712, nll_loss=1.962, ppl=3.9, wps=21967.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=8700, lr=0.000339032, gnorm=1.003, loss_scale=8, train_wall=267, gb_free=8.1, wall=25852
2022-03-06 20:05:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:05:38 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.808 | nll_loss 10.815 | ppl 1801.5 | wps 42690.8 | wpb 510.9 | bsz 1 | num_updates 8767 | best_loss 8.481
2022-03-06 20:05:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 8767 updates
2022-03-06 20:05:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:05:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 91 @ 8767 updates, score 11.808) (writing took 2.614699357189238 seconds)
2022-03-06 20:05:40 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 20:05:40 | INFO | train | epoch 091 | loss 3.701 | nll_loss 1.95 | ppl 3.86 | wps 22166.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8767 | lr 0.000337734 | gnorm 1.003 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 26052
2022-03-06 20:05:40 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 20:05:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:07:15 | INFO | train_inner | epoch 092:     33 / 97 loss=3.696, nll_loss=1.943, ppl=3.85, wps=22192.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=8800, lr=0.0003371, gnorm=1.001, loss_scale=16, train_wall=264, gb_free=8.1, wall=26147
2022-03-06 20:07:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:10:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:10:24 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.795 | nll_loss 10.797 | ppl 1779.78 | wps 43047.1 | wpb 510.9 | bsz 1 | num_updates 8863 | best_loss 8.481
2022-03-06 20:10:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 8863 updates
2022-03-06 20:10:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:10:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:10:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 92 @ 8863 updates, score 11.795) (writing took 2.452441783156246 seconds)
2022-03-06 20:10:26 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 20:10:26 | INFO | train | epoch 092 | loss 3.681 | nll_loss 1.927 | ppl 3.8 | wps 21984.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8863 | lr 0.0003359 | gnorm 0.997 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 26338
2022-03-06 20:10:26 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 20:10:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:12:13 | INFO | train_inner | epoch 093:     37 / 97 loss=3.673, nll_loss=1.917, ppl=3.78, wps=22028.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=8900, lr=0.000335201, gnorm=0.988, loss_scale=8, train_wall=266, gb_free=8.1, wall=26444
2022-03-06 20:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:15:10 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.865 | nll_loss 10.875 | ppl 1878.02 | wps 42576.1 | wpb 510.9 | bsz 1 | num_updates 8960 | best_loss 8.481
2022-03-06 20:15:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 8960 updates
2022-03-06 20:15:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:15:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:15:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 93 @ 8960 updates, score 11.865) (writing took 2.366519250907004 seconds)
2022-03-06 20:15:12 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 20:15:12 | INFO | train | epoch 093 | loss 3.664 | nll_loss 1.907 | ppl 3.75 | wps 22228.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8960 | lr 0.000334077 | gnorm 0.99 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 26624
2022-03-06 20:15:12 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 20:15:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:17:07 | INFO | train_inner | epoch 094:     40 / 97 loss=3.655, nll_loss=1.896, ppl=3.72, wps=22252.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=9000, lr=0.000333333, gnorm=0.997, loss_scale=16, train_wall=264, gb_free=8.1, wall=26739
2022-03-06 20:17:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:19:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:19:55 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.855 | nll_loss 10.86 | ppl 1858.86 | wps 42492 | wpb 510.9 | bsz 1 | num_updates 9056 | best_loss 8.481
2022-03-06 20:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9056 updates
2022-03-06 20:19:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:19:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 94 @ 9056 updates, score 11.855) (writing took 2.465950033161789 seconds)
2022-03-06 20:19:58 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 20:19:58 | INFO | train | epoch 094 | loss 3.647 | nll_loss 1.887 | ppl 3.7 | wps 22002.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9056 | lr 0.000332301 | gnorm 1.003 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 26910
2022-03-06 20:19:58 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 20:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:22:04 | INFO | train_inner | epoch 095:     44 / 97 loss=3.641, nll_loss=1.88, ppl=3.68, wps=22023.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=9100, lr=0.000331497, gnorm=1.002, loss_scale=8, train_wall=266, gb_free=8.1, wall=27036
2022-03-06 20:24:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:24:42 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.85 | nll_loss 10.864 | ppl 1864.07 | wps 42308.5 | wpb 510.9 | bsz 1 | num_updates 9153 | best_loss 8.481
2022-03-06 20:24:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9153 updates
2022-03-06 20:24:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:24:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:24:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 95 @ 9153 updates, score 11.85) (writing took 2.612726646941155 seconds)
2022-03-06 20:24:44 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 20:24:44 | INFO | train | epoch 095 | loss 3.628 | nll_loss 1.866 | ppl 3.64 | wps 22172.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9153 | lr 0.000330536 | gnorm 0.99 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 27196
2022-03-06 20:24:44 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 20:24:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:27:00 | INFO | train_inner | epoch 096:     47 / 97 loss=3.622, nll_loss=1.859, ppl=3.63, wps=22181.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=9200, lr=0.00032969, gnorm=0.983, loss_scale=16, train_wall=264, gb_free=8.1, wall=27331
2022-03-06 20:29:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:29:28 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.93 | nll_loss 10.946 | ppl 1973.17 | wps 42272.9 | wpb 510.9 | bsz 1 | num_updates 9250 | best_loss 8.481
2022-03-06 20:29:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9250 updates
2022-03-06 20:29:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:29:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:29:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 96 @ 9250 updates, score 11.93) (writing took 2.6920433859340847 seconds)
2022-03-06 20:29:31 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 20:29:31 | INFO | train | epoch 096 | loss 3.612 | nll_loss 1.847 | ppl 3.6 | wps 22161.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9250 | lr 0.000328798 | gnorm 0.971 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 27483
2022-03-06 20:29:31 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 20:29:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:30:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:30:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:32:00 | INFO | train_inner | epoch 097:     52 / 97 loss=3.603, nll_loss=1.838, ppl=3.57, wps=21762.5, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=9300, lr=0.000327913, gnorm=0.983, loss_scale=8, train_wall=269, gb_free=8.1, wall=27632
2022-03-06 20:34:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:34:15 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 11.985 | nll_loss 11.015 | ppl 2069.61 | wps 42098.3 | wpb 510.9 | bsz 1 | num_updates 9345 | best_loss 8.481
2022-03-06 20:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9345 updates
2022-03-06 20:34:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:34:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:34:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 97 @ 9345 updates, score 11.985) (writing took 2.6073935301974416 seconds)
2022-03-06 20:34:18 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 20:34:18 | INFO | train | epoch 097 | loss 3.596 | nll_loss 1.829 | ppl 3.55 | wps 21715.1 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 9345 | lr 0.000327122 | gnorm 0.999 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 27769
2022-03-06 20:34:18 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 20:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:36:56 | INFO | train_inner | epoch 098:     55 / 97 loss=3.589, nll_loss=1.822, ppl=3.53, wps=22181.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9400, lr=0.000326164, gnorm=0.999, loss_scale=16, train_wall=264, gb_free=8.1, wall=27928
2022-03-06 20:38:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:38:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:39:02 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 11.962 | nll_loss 10.996 | ppl 2043.02 | wps 41996.3 | wpb 510.9 | bsz 1 | num_updates 9441 | best_loss 8.481
2022-03-06 20:39:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 9441 updates
2022-03-06 20:39:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:39:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:39:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 98 @ 9441 updates, score 11.962) (writing took 2.4683144348673522 seconds)
2022-03-06 20:39:04 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 20:39:04 | INFO | train | epoch 098 | loss 3.58 | nll_loss 1.811 | ppl 3.51 | wps 21944.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9441 | lr 0.000325455 | gnorm 0.984 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 28056
2022-03-06 20:39:04 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 20:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:41:53 | INFO | train_inner | epoch 099:     59 / 97 loss=3.568, nll_loss=1.797, ppl=3.47, wps=22003.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=9500, lr=0.000324443, gnorm=0.985, loss_scale=8, train_wall=266, gb_free=8.1, wall=28225
2022-03-06 20:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:43:47 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 11.994 | nll_loss 11.01 | ppl 2062.61 | wps 42942.1 | wpb 510.9 | bsz 1 | num_updates 9538 | best_loss 8.481
2022-03-06 20:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 9538 updates
2022-03-06 20:43:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:43:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:43:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 99 @ 9538 updates, score 11.994) (writing took 2.560327270999551 seconds)
2022-03-06 20:43:50 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 20:43:50 | INFO | train | epoch 099 | loss 3.565 | nll_loss 1.794 | ppl 3.47 | wps 22223.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9538 | lr 0.000323796 | gnorm 1 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 28342
2022-03-06 20:43:50 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 20:43:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:45:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:46:51 | INFO | train_inner | epoch 100:     63 / 97 loss=3.558, nll_loss=1.786, ppl=3.45, wps=22033.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9600, lr=0.000322749, gnorm=0.994, loss_scale=8, train_wall=266, gb_free=8.1, wall=28523
2022-03-06 20:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:48:33 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 11.977 | nll_loss 10.996 | ppl 2043 | wps 42598.1 | wpb 510.9 | bsz 1 | num_updates 9634 | best_loss 8.481
2022-03-06 20:48:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 9634 updates
2022-03-06 20:48:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:48:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:48:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 100 @ 9634 updates, score 11.977) (writing took 2.5068536875769496 seconds)
2022-03-06 20:48:36 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 20:48:36 | INFO | train | epoch 100 | loss 3.548 | nll_loss 1.775 | ppl 3.42 | wps 22003 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9634 | lr 0.000322179 | gnorm 0.982 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 28628
2022-03-06 20:48:36 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 20:48:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:51:45 | INFO | train_inner | epoch 101:     66 / 97 loss=3.537, nll_loss=1.762, ppl=3.39, wps=22254.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9700, lr=0.000321081, gnorm=0.987, loss_scale=16, train_wall=263, gb_free=8.1, wall=28817
2022-03-06 20:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:53:19 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.041 | nll_loss 11.069 | ppl 2148.34 | wps 42068.3 | wpb 510.9 | bsz 1 | num_updates 9731 | best_loss 8.481
2022-03-06 20:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 9731 updates
2022-03-06 20:53:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 101 @ 9731 updates, score 12.041) (writing took 2.6081595378927886 seconds)
2022-03-06 20:53:22 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 20:53:22 | INFO | train | epoch 101 | loss 3.534 | nll_loss 1.759 | ppl 3.39 | wps 22221.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9731 | lr 0.000320569 | gnorm 0.99 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 28913
2022-03-06 20:53:22 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 20:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:56:40 | INFO | train_inner | epoch 102:     69 / 97 loss=3.528, nll_loss=1.752, ppl=3.37, wps=22208.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=9800, lr=0.000319438, gnorm=0.98, loss_scale=16, train_wall=264, gb_free=8.1, wall=29112
2022-03-06 20:57:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:58:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:58:05 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.048 | nll_loss 11.074 | ppl 2156.43 | wps 42407.9 | wpb 510.9 | bsz 1 | num_updates 9827 | best_loss 8.481
2022-03-06 20:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 9827 updates
2022-03-06 20:58:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:58:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:58:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 102 @ 9827 updates, score 12.048) (writing took 2.6957534728571773 seconds)
2022-03-06 20:58:08 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 20:58:08 | INFO | train | epoch 102 | loss 3.519 | nll_loss 1.741 | ppl 3.34 | wps 21949.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9827 | lr 0.000318999 | gnorm 0.98 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 29200
2022-03-06 20:58:08 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 20:58:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:58:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:01:41 | INFO | train_inner | epoch 103:     74 / 97 loss=3.508, nll_loss=1.729, ppl=3.32, wps=21755.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=9900, lr=0.000317821, gnorm=0.99, loss_scale=8, train_wall=269, gb_free=8.1, wall=29413
2022-03-06 21:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:02:52 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.084 | nll_loss 11.114 | ppl 2217.03 | wps 42300.5 | wpb 510.9 | bsz 1 | num_updates 9923 | best_loss 8.481
2022-03-06 21:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 9923 updates
2022-03-06 21:02:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 103 @ 9923 updates, score 12.084) (writing took 2.6353213931433856 seconds)
2022-03-06 21:02:55 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 21:02:55 | INFO | train | epoch 103 | loss 3.505 | nll_loss 1.726 | ppl 3.31 | wps 21933.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 9923 | lr 0.000317452 | gnorm 0.992 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 29487
2022-03-06 21:02:55 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 21:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:06:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:06:39 | INFO | train_inner | epoch 104:     78 / 97 loss=3.497, nll_loss=1.717, ppl=3.29, wps=21968.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10000, lr=0.000316228, gnorm=0.991, loss_scale=8, train_wall=267, gb_free=8.1, wall=29711
2022-03-06 21:07:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:07:39 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.066 | nll_loss 11.093 | ppl 2183.98 | wps 42447.8 | wpb 510.9 | bsz 1 | num_updates 10019 | best_loss 8.481
2022-03-06 21:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10019 updates
2022-03-06 21:07:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:07:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:07:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 104 @ 10019 updates, score 12.066) (writing took 2.6013629739172757 seconds)
2022-03-06 21:07:41 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 21:07:41 | INFO | train | epoch 104 | loss 3.491 | nll_loss 1.71 | ppl 3.27 | wps 21934.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 10019 | lr 0.000315928 | gnorm 0.99 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 29773
2022-03-06 21:07:41 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 21:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:11:34 | INFO | train_inner | epoch 105:     81 / 97 loss=3.481, nll_loss=1.698, ppl=3.25, wps=22206.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=10100, lr=0.000314658, gnorm=0.987, loss_scale=8, train_wall=264, gb_free=8.1, wall=30006
2022-03-06 21:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:12:25 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.072 | nll_loss 11.102 | ppl 2198.25 | wps 42634.9 | wpb 510.9 | bsz 1 | num_updates 10116 | best_loss 8.481
2022-03-06 21:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10116 updates
2022-03-06 21:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 105 @ 10116 updates, score 12.072) (writing took 2.460930739995092 seconds)
2022-03-06 21:12:27 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 21:12:27 | INFO | train | epoch 105 | loss 3.48 | nll_loss 1.697 | ppl 3.24 | wps 22212 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10116 | lr 0.000314409 | gnorm 0.993 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 30059
2022-03-06 21:12:27 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 21:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:16:29 | INFO | train_inner | epoch 106:     84 / 97 loss=3.471, nll_loss=1.687, ppl=3.22, wps=22230.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=10200, lr=0.000313112, gnorm=1.006, loss_scale=16, train_wall=264, gb_free=8.1, wall=30300
2022-03-06 21:16:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:17:11 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.149 | nll_loss 11.188 | ppl 2332.46 | wps 42487.7 | wpb 510.9 | bsz 1 | num_updates 10212 | best_loss 8.481
2022-03-06 21:17:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10212 updates
2022-03-06 21:17:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:17:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:17:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 106 @ 10212 updates, score 12.149) (writing took 2.5485247527249157 seconds)
2022-03-06 21:17:13 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 21:17:13 | INFO | train | epoch 106 | loss 3.464 | nll_loss 1.679 | ppl 3.2 | wps 21976.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10212 | lr 0.000312928 | gnorm 1.005 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 30345
2022-03-06 21:17:13 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 21:17:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:21:26 | INFO | train_inner | epoch 107:     88 / 97 loss=3.452, nll_loss=1.666, ppl=3.17, wps=22007.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10300, lr=0.000311588, gnorm=0.992, loss_scale=8, train_wall=266, gb_free=8.1, wall=30598
2022-03-06 21:21:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:21:57 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.152 | nll_loss 11.193 | ppl 2340.42 | wps 42883.6 | wpb 510.9 | bsz 1 | num_updates 10309 | best_loss 8.481
2022-03-06 21:21:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 10309 updates
2022-03-06 21:21:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:21:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 107 @ 10309 updates, score 12.152) (writing took 2.4184891171753407 seconds)
2022-03-06 21:21:59 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 21:21:59 | INFO | train | epoch 107 | loss 3.451 | nll_loss 1.665 | ppl 3.17 | wps 22213.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10309 | lr 0.000311452 | gnorm 0.986 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 30631
2022-03-06 21:21:59 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 21:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:26:21 | INFO | train_inner | epoch 108:     91 / 97 loss=3.44, nll_loss=1.653, ppl=3.14, wps=22198, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10400, lr=0.000310087, gnorm=0.978, loss_scale=16, train_wall=264, gb_free=8.1, wall=30893
2022-03-06 21:26:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:26:43 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.128 | nll_loss 11.168 | ppl 2301.7 | wps 42445.5 | wpb 510.9 | bsz 1 | num_updates 10406 | best_loss 8.481
2022-03-06 21:26:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 10406 updates
2022-03-06 21:26:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:26:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 108 @ 10406 updates, score 12.128) (writing took 2.6105004344135523 seconds)
2022-03-06 21:26:46 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 21:26:46 | INFO | train | epoch 108 | loss 3.439 | nll_loss 1.652 | ppl 3.14 | wps 22159.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10406 | lr 0.000309997 | gnorm 0.979 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 30918
2022-03-06 21:26:46 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 21:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:29:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:31:19 | INFO | train_inner | epoch 109:     95 / 97 loss=3.43, nll_loss=1.642, ppl=3.12, wps=21984, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10500, lr=0.000308607, gnorm=0.977, loss_scale=16, train_wall=267, gb_free=8.1, wall=31191
2022-03-06 21:31:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:31:30 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.271 | nll_loss 11.322 | ppl 2560.86 | wps 42194.6 | wpb 510.9 | bsz 1 | num_updates 10502 | best_loss 8.481
2022-03-06 21:31:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 10502 updates
2022-03-06 21:31:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:31:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:31:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 109 @ 10502 updates, score 12.271) (writing took 2.777299269102514 seconds)
2022-03-06 21:31:33 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 21:31:33 | INFO | train | epoch 109 | loss 3.425 | nll_loss 1.636 | ppl 3.11 | wps 21935.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 10502 | lr 0.000308577 | gnorm 0.973 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 31205
2022-03-06 21:31:33 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 21:31:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:35:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:36:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:36:16 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.203 | nll_loss 11.257 | ppl 2448.06 | wps 42589.7 | wpb 510.9 | bsz 1 | num_updates 10598 | best_loss 8.481
2022-03-06 21:36:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 10598 updates
2022-03-06 21:36:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:36:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:36:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 110 @ 10598 updates, score 12.203) (writing took 2.739647652953863 seconds)
2022-03-06 21:36:19 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 21:36:19 | INFO | train | epoch 110 | loss 3.414 | nll_loss 1.623 | ppl 3.08 | wps 21949.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10598 | lr 0.000307177 | gnorm 0.984 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 31491
2022-03-06 21:36:19 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 21:36:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:36:25 | INFO | train_inner | epoch 111:      2 / 97 loss=3.413, nll_loss=1.622, ppl=3.08, wps=21400.9, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=10600, lr=0.000307148, gnorm=0.984, loss_scale=16, train_wall=266, gb_free=8.1, wall=31497
2022-03-06 21:36:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:41:03 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.283 | nll_loss 11.343 | ppl 2596.96 | wps 42440.8 | wpb 510.9 | bsz 1 | num_updates 10694 | best_loss 8.481
2022-03-06 21:41:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 10694 updates
2022-03-06 21:41:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:41:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:41:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 111 @ 10694 updates, score 12.283) (writing took 2.5485103060491383 seconds)
2022-03-06 21:41:05 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 21:41:05 | INFO | train | epoch 111 | loss 3.401 | nll_loss 1.609 | ppl 3.05 | wps 21975.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10694 | lr 0.000305795 | gnorm 0.983 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 31777
2022-03-06 21:41:05 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 21:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:41:23 | INFO | train_inner | epoch 112:      6 / 97 loss=3.399, nll_loss=1.606, ppl=3.04, wps=22005.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10700, lr=0.000305709, gnorm=0.982, loss_scale=8, train_wall=266, gb_free=8.1, wall=31794
2022-03-06 21:45:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:45:49 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.242 | nll_loss 11.298 | ppl 2517.32 | wps 42715.1 | wpb 510.9 | bsz 1 | num_updates 10791 | best_loss 8.481
2022-03-06 21:45:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 10791 updates
2022-03-06 21:45:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:45:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:45:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 112 @ 10791 updates, score 12.242) (writing took 2.495451937895268 seconds)
2022-03-06 21:45:51 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 21:45:51 | INFO | train | epoch 112 | loss 3.389 | nll_loss 1.595 | ppl 3.02 | wps 22213.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10791 | lr 0.000304417 | gnorm 0.985 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 32063
2022-03-06 21:45:51 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 21:45:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:46:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:46:20 | INFO | train_inner | epoch 113:     10 / 97 loss=3.386, nll_loss=1.591, ppl=3.01, wps=22025.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10800, lr=0.00030429, gnorm=0.985, loss_scale=8, train_wall=266, gb_free=8.1, wall=32092
2022-03-06 21:50:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:50:34 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 12.271 | nll_loss 11.323 | ppl 2561.55 | wps 42534.2 | wpb 510.9 | bsz 1 | num_updates 10887 | best_loss 8.481
2022-03-06 21:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 10887 updates
2022-03-06 21:50:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 113 @ 10887 updates, score 12.271) (writing took 2.444589275866747 seconds)
2022-03-06 21:50:37 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 21:50:37 | INFO | train | epoch 113 | loss 3.377 | nll_loss 1.582 | ppl 2.99 | wps 22016 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10887 | lr 0.000303072 | gnorm 0.975 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 32349
2022-03-06 21:50:37 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 21:50:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:51:14 | INFO | train_inner | epoch 114:     13 / 97 loss=3.374, nll_loss=1.578, ppl=2.99, wps=22262.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=10900, lr=0.000302891, gnorm=0.971, loss_scale=8, train_wall=263, gb_free=8.1, wall=32386
2022-03-06 21:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:55:20 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 12.251 | nll_loss 11.306 | ppl 2531.48 | wps 42716.5 | wpb 510.9 | bsz 1 | num_updates 10984 | best_loss 8.481
2022-03-06 21:55:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 10984 updates
2022-03-06 21:55:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:55:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:55:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 114 @ 10984 updates, score 12.251) (writing took 2.4427526220679283 seconds)
2022-03-06 21:55:23 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 21:55:23 | INFO | train | epoch 114 | loss 3.368 | nll_loss 1.572 | ppl 2.97 | wps 22213.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10984 | lr 0.000301731 | gnorm 0.969 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 32635
2022-03-06 21:55:23 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 21:55:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:56:09 | INFO | train_inner | epoch 115:     16 / 97 loss=3.365, nll_loss=1.568, ppl=2.96, wps=22230.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11000, lr=0.000301511, gnorm=0.973, loss_scale=16, train_wall=264, gb_free=8.1, wall=32681
2022-03-06 21:56:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:00:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:00:06 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 12.27 | nll_loss 11.317 | ppl 2551.13 | wps 42290.4 | wpb 510.9 | bsz 1 | num_updates 11080 | best_loss 8.481
2022-03-06 22:00:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11080 updates
2022-03-06 22:00:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:00:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:00:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 115 @ 11080 updates, score 12.27) (writing took 2.6347789699211717 seconds)
2022-03-06 22:00:09 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 22:00:09 | INFO | train | epoch 115 | loss 3.356 | nll_loss 1.558 | ppl 2.94 | wps 21952.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11080 | lr 0.000300421 | gnorm 0.977 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 32921
2022-03-06 22:00:09 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 22:00:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:01:07 | INFO | train_inner | epoch 116:     20 / 97 loss=3.353, nll_loss=1.554, ppl=2.94, wps=21975.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=11100, lr=0.00030015, gnorm=0.975, loss_scale=8, train_wall=267, gb_free=8.1, wall=32979
2022-03-06 22:04:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:04:53 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 12.356 | nll_loss 11.42 | ppl 2739.13 | wps 42124.8 | wpb 510.9 | bsz 1 | num_updates 11177 | best_loss 8.481
2022-03-06 22:04:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11177 updates
2022-03-06 22:04:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:04:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 116 @ 11177 updates, score 12.356) (writing took 2.6623163651674986 seconds)
2022-03-06 22:04:56 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 22:04:56 | INFO | train | epoch 116 | loss 3.348 | nll_loss 1.55 | ppl 2.93 | wps 22150.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11177 | lr 0.000299114 | gnorm 0.975 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 33208
2022-03-06 22:04:56 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 22:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:06:02 | INFO | train_inner | epoch 117:     23 / 97 loss=3.347, nll_loss=1.549, ppl=2.93, wps=22176.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11200, lr=0.000298807, gnorm=0.978, loss_scale=16, train_wall=264, gb_free=8.1, wall=33274
2022-03-06 22:09:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:09:39 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 12.3 | nll_loss 11.37 | ppl 2646.22 | wps 42576.4 | wpb 510.9 | bsz 1 | num_updates 11273 | best_loss 8.481
2022-03-06 22:09:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 11273 updates
2022-03-06 22:09:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:09:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:09:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 117 @ 11273 updates, score 12.3) (writing took 2.6572277629747987 seconds)
2022-03-06 22:09:42 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 22:09:42 | INFO | train | epoch 117 | loss 3.335 | nll_loss 1.534 | ppl 2.9 | wps 21969.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11273 | lr 0.000297838 | gnorm 0.972 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 33494
2022-03-06 22:09:42 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 22:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:10:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:11:03 | INFO | train_inner | epoch 118:     28 / 97 loss=3.328, nll_loss=1.527, ppl=2.88, wps=21794.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=11300, lr=0.000297482, gnorm=0.972, loss_scale=8, train_wall=269, gb_free=8.1, wall=33574
2022-03-06 22:14:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:14:26 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 12.351 | nll_loss 11.424 | ppl 2746.83 | wps 42792.7 | wpb 510.9 | bsz 1 | num_updates 11369 | best_loss 8.481
2022-03-06 22:14:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 11369 updates
2022-03-06 22:14:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:14:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:14:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 118 @ 11369 updates, score 12.351) (writing took 2.515616285149008 seconds)
2022-03-06 22:14:28 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 22:14:28 | INFO | train | epoch 118 | loss 3.325 | nll_loss 1.524 | ppl 2.88 | wps 21978.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11369 | lr 0.000296578 | gnorm 0.971 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 33780
2022-03-06 22:14:28 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 22:14:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:15:57 | INFO | train_inner | epoch 119:     31 / 97 loss=3.321, nll_loss=1.52, ppl=2.87, wps=22233.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11400, lr=0.000296174, gnorm=0.963, loss_scale=8, train_wall=264, gb_free=8.1, wall=33869
2022-03-06 22:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:19:11 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 12.41 | nll_loss 11.483 | ppl 2862.44 | wps 42894.4 | wpb 510.9 | bsz 1 | num_updates 11466 | best_loss 8.481
2022-03-06 22:19:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 11466 updates
2022-03-06 22:19:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:19:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:19:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 119 @ 11466 updates, score 12.41) (writing took 2.443495153915137 seconds)
2022-03-06 22:19:14 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 22:19:14 | INFO | train | epoch 119 | loss 3.315 | nll_loss 1.512 | ppl 2.85 | wps 22259.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11466 | lr 0.000295321 | gnorm 0.962 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 34065
2022-03-06 22:19:14 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 22:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:20:51 | INFO | train_inner | epoch 120:     34 / 97 loss=3.312, nll_loss=1.51, ppl=2.85, wps=22280.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=11500, lr=0.000294884, gnorm=0.957, loss_scale=16, train_wall=263, gb_free=8.1, wall=34163
2022-03-06 22:22:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:23:57 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 12.292 | nll_loss 11.344 | ppl 2600.2 | wps 42049.5 | wpb 510.9 | bsz 1 | num_updates 11562 | best_loss 8.481
2022-03-06 22:23:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 11562 updates
2022-03-06 22:23:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:23:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:23:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 120 @ 11562 updates, score 12.292) (writing took 2.274743013083935 seconds)
2022-03-06 22:23:59 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 22:23:59 | INFO | train | epoch 120 | loss 3.304 | nll_loss 1.501 | ppl 2.83 | wps 22009.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11562 | lr 0.000294092 | gnorm 0.963 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 34351
2022-03-06 22:23:59 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 22:23:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:25:48 | INFO | train_inner | epoch 121:     38 / 97 loss=3.299, nll_loss=1.495, ppl=2.82, wps=22028.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=11600, lr=0.00029361, gnorm=0.969, loss_scale=16, train_wall=266, gb_free=8.1, wall=34460
2022-03-06 22:28:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:28:43 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 12.374 | nll_loss 11.446 | ppl 2789.37 | wps 42514.2 | wpb 510.9 | bsz 1 | num_updates 11659 | best_loss 8.481
2022-03-06 22:28:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 11659 updates
2022-03-06 22:28:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:28:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:28:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 121 @ 11659 updates, score 12.374) (writing took 2.287095244973898 seconds)
2022-03-06 22:28:45 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 22:28:45 | INFO | train | epoch 121 | loss 3.297 | nll_loss 1.492 | ppl 2.81 | wps 22226.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11659 | lr 0.000292866 | gnorm 0.967 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 34637
2022-03-06 22:28:45 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 22:28:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:29:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:30:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:30:48 | INFO | train_inner | epoch 122:     43 / 97 loss=3.294, nll_loss=1.489, ppl=2.81, wps=21826.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=11700, lr=0.000292353, gnorm=0.973, loss_scale=8, train_wall=269, gb_free=8.1, wall=34760
2022-03-06 22:33:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:33:28 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 12.362 | nll_loss 11.438 | ppl 2774.2 | wps 42491.3 | wpb 510.9 | bsz 1 | num_updates 11754 | best_loss 8.481
2022-03-06 22:33:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 11754 updates
2022-03-06 22:33:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:33:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:33:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 122 @ 11754 updates, score 12.362) (writing took 2.2752430411055684 seconds)
2022-03-06 22:33:31 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 22:33:31 | INFO | train | epoch 122 | loss 3.285 | nll_loss 1.479 | ppl 2.79 | wps 21773 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 11754 | lr 0.00029168 | gnorm 0.974 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 34923
2022-03-06 22:33:31 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 22:33:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:35:43 | INFO | train_inner | epoch 123:     46 / 97 loss=3.279, nll_loss=1.473, ppl=2.78, wps=22239.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=11800, lr=0.000291111, gnorm=0.963, loss_scale=8, train_wall=264, gb_free=8.1, wall=35055
2022-03-06 22:38:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:38:14 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 12.427 | nll_loss 11.506 | ppl 2907.64 | wps 42959.9 | wpb 510.9 | bsz 1 | num_updates 11851 | best_loss 8.481
2022-03-06 22:38:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 11851 updates
2022-03-06 22:38:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:38:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 123 @ 11851 updates, score 12.427) (writing took 2.2864586249925196 seconds)
2022-03-06 22:38:17 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 22:38:17 | INFO | train | epoch 123 | loss 3.276 | nll_loss 1.47 | ppl 2.77 | wps 22222.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11851 | lr 0.000290484 | gnorm 0.963 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 35209
2022-03-06 22:38:17 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 22:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:40:37 | INFO | train_inner | epoch 124:     49 / 97 loss=3.273, nll_loss=1.466, ppl=2.76, wps=22245.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=11900, lr=0.000289886, gnorm=0.967, loss_scale=16, train_wall=264, gb_free=8.1, wall=35349
2022-03-06 22:41:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:42:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:43:00 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 12.422 | nll_loss 11.5 | ppl 2896.56 | wps 42333.2 | wpb 510.9 | bsz 1 | num_updates 11947 | best_loss 8.481
2022-03-06 22:43:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 11947 updates
2022-03-06 22:43:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:43:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:43:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 124 @ 11947 updates, score 12.422) (writing took 2.2797354059293866 seconds)
2022-03-06 22:43:02 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 22:43:02 | INFO | train | epoch 124 | loss 3.266 | nll_loss 1.458 | ppl 2.75 | wps 22002.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11947 | lr 0.000289315 | gnorm 0.97 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 35494
2022-03-06 22:43:02 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 22:43:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:45:35 | INFO | train_inner | epoch 125:     53 / 97 loss=3.262, nll_loss=1.454, ppl=2.74, wps=22032.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=12000, lr=0.000288675, gnorm=0.967, loss_scale=8, train_wall=266, gb_free=8.1, wall=35646
2022-03-06 22:47:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:47:46 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 12.348 | nll_loss 11.413 | ppl 2726.56 | wps 42658.7 | wpb 510.9 | bsz 1 | num_updates 12044 | best_loss 8.481
2022-03-06 22:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12044 updates
2022-03-06 22:47:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:47:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:47:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 125 @ 12044 updates, score 12.348) (writing took 2.2323152627795935 seconds)
2022-03-06 22:47:48 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 22:47:48 | INFO | train | epoch 125 | loss 3.258 | nll_loss 1.45 | ppl 2.73 | wps 22230.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12044 | lr 0.000288147 | gnorm 0.956 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 35780
2022-03-06 22:47:48 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 22:47:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:50:29 | INFO | train_inner | epoch 126:     56 / 97 loss=3.253, nll_loss=1.443, ppl=2.72, wps=22247.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12100, lr=0.00028748, gnorm=0.962, loss_scale=16, train_wall=264, gb_free=8.1, wall=35941
2022-03-06 22:52:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:52:32 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 12.446 | nll_loss 11.521 | ppl 2938.14 | wps 42531.6 | wpb 510.9 | bsz 1 | num_updates 12140 | best_loss 8.481
2022-03-06 22:52:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12140 updates
2022-03-06 22:52:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:52:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:52:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 126 @ 12140 updates, score 12.446) (writing took 2.2884798920713365 seconds)
2022-03-06 22:52:34 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 22:52:34 | INFO | train | epoch 126 | loss 3.249 | nll_loss 1.44 | ppl 2.71 | wps 21999.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12140 | lr 0.000287006 | gnorm 0.969 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 36066
2022-03-06 22:52:34 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 22:52:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:55:26 | INFO | train_inner | epoch 127:     60 / 97 loss=3.243, nll_loss=1.433, ppl=2.7, wps=22029.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12200, lr=0.000286299, gnorm=0.964, loss_scale=8, train_wall=266, gb_free=8.1, wall=36238
2022-03-06 22:57:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:57:17 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 12.508 | nll_loss 11.588 | ppl 3078.33 | wps 42537.7 | wpb 510.9 | bsz 1 | num_updates 12237 | best_loss 8.481
2022-03-06 22:57:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 12237 updates
2022-03-06 22:57:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:57:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:57:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 127 @ 12237 updates, score 12.508) (writing took 2.218324691057205 seconds)
2022-03-06 22:57:20 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 22:57:20 | INFO | train | epoch 127 | loss 3.24 | nll_loss 1.429 | ppl 2.69 | wps 22237.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12237 | lr 0.000285866 | gnorm 0.957 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 36352
2022-03-06 22:57:20 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 22:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:00:21 | INFO | train_inner | epoch 128:     63 / 97 loss=3.238, nll_loss=1.427, ppl=2.69, wps=22242.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12300, lr=0.000285133, gnorm=0.958, loss_scale=16, train_wall=264, gb_free=8.1, wall=36533
2022-03-06 23:01:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:02:03 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 12.412 | nll_loss 11.48 | ppl 2855.7 | wps 42538 | wpb 510.9 | bsz 1 | num_updates 12334 | best_loss 8.481
2022-03-06 23:02:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 12334 updates
2022-03-06 23:02:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:02:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:02:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 128 @ 12334 updates, score 12.412) (writing took 2.3122703242115676 seconds)
2022-03-06 23:02:06 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 23:02:06 | INFO | train | epoch 128 | loss 3.232 | nll_loss 1.421 | ppl 2.68 | wps 22208 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12334 | lr 0.00028474 | gnorm 0.963 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 36638
2022-03-06 23:02:06 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 23:02:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:04:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:05:18 | INFO | train_inner | epoch 129:     67 / 97 loss=3.226, nll_loss=1.414, ppl=2.67, wps=22028.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12400, lr=0.000283981, gnorm=0.974, loss_scale=16, train_wall=266, gb_free=8.1, wall=36830
2022-03-06 23:06:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:06:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:06:49 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 12.511 | nll_loss 11.597 | ppl 3098.43 | wps 42807.7 | wpb 510.9 | bsz 1 | num_updates 12429 | best_loss 8.481
2022-03-06 23:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 12429 updates
2022-03-06 23:06:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:06:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 129 @ 12429 updates, score 12.511) (writing took 2.3440926391631365 seconds)
2022-03-06 23:06:51 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 23:06:51 | INFO | train | epoch 129 | loss 3.221 | nll_loss 1.409 | ppl 2.65 | wps 21772 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 12429 | lr 0.000283649 | gnorm 0.972 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 36923
2022-03-06 23:06:51 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 23:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:10:15 | INFO | train_inner | epoch 130:     71 / 97 loss=3.219, nll_loss=1.406, ppl=2.65, wps=22036.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12500, lr=0.000282843, gnorm=0.965, loss_scale=8, train_wall=266, gb_free=8.1, wall=37127
2022-03-06 23:11:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:11:35 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 12.494 | nll_loss 11.579 | ppl 3059.79 | wps 43026.9 | wpb 510.9 | bsz 1 | num_updates 12526 | best_loss 8.481
2022-03-06 23:11:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 12526 updates
2022-03-06 23:11:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:11:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:11:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 130 @ 12526 updates, score 12.494) (writing took 2.277992847841233 seconds)
2022-03-06 23:11:37 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 23:11:37 | INFO | train | epoch 130 | loss 3.217 | nll_loss 1.405 | ppl 2.65 | wps 22240 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12526 | lr 0.000282549 | gnorm 0.97 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 37209
2022-03-06 23:11:37 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 23:11:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:15:09 | INFO | train_inner | epoch 131:     74 / 97 loss=3.209, nll_loss=1.395, ppl=2.63, wps=22263.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12600, lr=0.000281718, gnorm=0.957, loss_scale=16, train_wall=264, gb_free=8.1, wall=37421
2022-03-06 23:16:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:16:20 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 12.527 | nll_loss 11.621 | ppl 3149.61 | wps 42690.8 | wpb 510.9 | bsz 1 | num_updates 12623 | best_loss 8.481
2022-03-06 23:16:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 12623 updates
2022-03-06 23:16:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:16:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 131 @ 12623 updates, score 12.527) (writing took 2.2300631408579648 seconds)
2022-03-06 23:16:23 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 23:16:23 | INFO | train | epoch 131 | loss 3.207 | nll_loss 1.393 | ppl 2.63 | wps 22251.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12623 | lr 0.000281461 | gnorm 0.95 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 37494
2022-03-06 23:16:23 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 23:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:19:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:20:06 | INFO | train_inner | epoch 132:     78 / 97 loss=3.201, nll_loss=1.387, ppl=2.62, wps=22048.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12700, lr=0.000280607, gnorm=0.952, loss_scale=16, train_wall=266, gb_free=8.1, wall=37718
2022-03-06 23:21:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:21:06 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 12.482 | nll_loss 11.555 | ppl 3009.15 | wps 42433.5 | wpb 510.9 | bsz 1 | num_updates 12719 | best_loss 8.481
2022-03-06 23:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 12719 updates
2022-03-06 23:21:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:21:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:21:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 132 @ 12719 updates, score 12.482) (writing took 2.4166761161759496 seconds)
2022-03-06 23:21:08 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 23:21:08 | INFO | train | epoch 132 | loss 3.199 | nll_loss 1.384 | ppl 2.61 | wps 21990.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12719 | lr 0.000280397 | gnorm 0.953 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 37780
2022-03-06 23:21:08 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 23:21:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:24:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:25:04 | INFO | train_inner | epoch 133:     82 / 97 loss=3.195, nll_loss=1.381, ppl=2.6, wps=22017, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12800, lr=0.000279508, gnorm=0.955, loss_scale=8, train_wall=266, gb_free=8.1, wall=38016
2022-03-06 23:25:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:25:52 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 12.525 | nll_loss 11.617 | ppl 3141.14 | wps 42537.3 | wpb 510.9 | bsz 1 | num_updates 12815 | best_loss 8.481
2022-03-06 23:25:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 12815 updates
2022-03-06 23:25:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:25:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:25:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 133 @ 12815 updates, score 12.525) (writing took 2.292098530102521 seconds)
2022-03-06 23:25:54 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 23:25:54 | INFO | train | epoch 133 | loss 3.191 | nll_loss 1.376 | ppl 2.59 | wps 21995.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12815 | lr 0.000279345 | gnorm 0.954 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 38066
2022-03-06 23:25:54 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 23:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:29:59 | INFO | train_inner | epoch 134:     85 / 97 loss=3.186, nll_loss=1.37, ppl=2.58, wps=22217.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12900, lr=0.000278423, gnorm=0.952, loss_scale=8, train_wall=264, gb_free=8.1, wall=38311
2022-03-06 23:30:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:30:38 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 12.534 | nll_loss 11.628 | ppl 3165.68 | wps 42228.4 | wpb 510.9 | bsz 1 | num_updates 12912 | best_loss 8.481
2022-03-06 23:30:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 12912 updates
2022-03-06 23:30:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:30:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 134 @ 12912 updates, score 12.534) (writing took 2.316599797923118 seconds)
2022-03-06 23:30:40 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 23:30:40 | INFO | train | epoch 134 | loss 3.184 | nll_loss 1.367 | ppl 2.58 | wps 22200.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12912 | lr 0.000278294 | gnorm 0.946 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 38352
2022-03-06 23:30:40 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 23:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:34:53 | INFO | train_inner | epoch 135:     88 / 97 loss=3.179, nll_loss=1.363, ppl=2.57, wps=22238, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13000, lr=0.00027735, gnorm=0.951, loss_scale=16, train_wall=264, gb_free=8.1, wall=38605
2022-03-06 23:35:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:35:24 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 12.491 | nll_loss 11.582 | ppl 3065.25 | wps 42848.1 | wpb 510.9 | bsz 1 | num_updates 13009 | best_loss 8.481
2022-03-06 23:35:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13009 updates
2022-03-06 23:35:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:35:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:35:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 135 @ 13009 updates, score 12.491) (writing took 2.2269703997299075 seconds)
2022-03-06 23:35:26 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 23:35:26 | INFO | train | epoch 135 | loss 3.177 | nll_loss 1.36 | ppl 2.57 | wps 22235.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13009 | lr 0.000277254 | gnorm 0.953 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 38638
2022-03-06 23:35:26 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 23:35:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:38:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:39:50 | INFO | train_inner | epoch 136:     92 / 97 loss=3.17, nll_loss=1.352, ppl=2.55, wps=22053.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13100, lr=0.000276289, gnorm=0.952, loss_scale=16, train_wall=266, gb_free=8.1, wall=38902
2022-03-06 23:40:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:40:09 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 12.469 | nll_loss 11.559 | ppl 3017.55 | wps 42589.2 | wpb 510.9 | bsz 1 | num_updates 13105 | best_loss 8.481
2022-03-06 23:40:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13105 updates
2022-03-06 23:40:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:40:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:40:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 136 @ 13105 updates, score 12.469) (writing took 2.2260318407788873 seconds)
2022-03-06 23:40:12 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 23:40:12 | INFO | train | epoch 136 | loss 3.168 | nll_loss 1.351 | ppl 2.55 | wps 22016.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13105 | lr 0.000276237 | gnorm 0.951 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 38924
2022-03-06 23:40:12 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 23:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:44:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:44:47 | INFO | train_inner | epoch 137:     96 / 97 loss=3.164, nll_loss=1.346, ppl=2.54, wps=22048.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13200, lr=0.000275241, gnorm=0.941, loss_scale=16, train_wall=266, gb_free=8.1, wall=39199
2022-03-06 23:44:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:44:55 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 12.539 | nll_loss 11.64 | ppl 3191.85 | wps 42663.5 | wpb 510.9 | bsz 1 | num_updates 13201 | best_loss 8.481
2022-03-06 23:44:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 13201 updates
2022-03-06 23:44:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:44:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:44:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 137 @ 13201 updates, score 12.539) (writing took 2.244369139894843 seconds)
2022-03-06 23:44:57 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 23:44:57 | INFO | train | epoch 137 | loss 3.16 | nll_loss 1.342 | ppl 2.53 | wps 22015.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13201 | lr 0.000275231 | gnorm 0.941 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 39209
2022-03-06 23:44:57 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 23:44:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:49:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:49:41 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 12.548 | nll_loss 11.643 | ppl 3199.05 | wps 42286.3 | wpb 510.9 | bsz 1 | num_updates 13298 | best_loss 8.481
2022-03-06 23:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 13298 updates
2022-03-06 23:49:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:49:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:49:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 138 @ 13298 updates, score 12.548) (writing took 2.2469841889105737 seconds)
2022-03-06 23:49:43 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 23:49:43 | INFO | train | epoch 138 | loss 3.156 | nll_loss 1.337 | ppl 2.53 | wps 22225.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13298 | lr 0.000274225 | gnorm 0.953 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 39495
2022-03-06 23:49:43 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 23:49:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:49:49 | INFO | train_inner | epoch 139:      2 / 97 loss=3.155, nll_loss=1.336, ppl=2.52, wps=21690, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=13300, lr=0.000274204, gnorm=0.953, loss_scale=16, train_wall=264, gb_free=8.1, wall=39501
2022-03-06 23:51:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:54:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:54:27 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 12.544 | nll_loss 11.624 | ppl 3156.55 | wps 42540.2 | wpb 510.9 | bsz 1 | num_updates 13394 | best_loss 8.481
2022-03-06 23:54:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 13394 updates
2022-03-06 23:54:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:54:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:54:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 139 @ 13394 updates, score 12.544) (writing took 2.229822142980993 seconds)
2022-03-06 23:54:29 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 23:54:29 | INFO | train | epoch 139 | loss 3.147 | nll_loss 1.327 | ppl 2.51 | wps 22005.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13394 | lr 0.00027324 | gnorm 0.953 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 39781
2022-03-06 23:54:29 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 23:54:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:54:46 | INFO | train_inner | epoch 140:      6 / 97 loss=3.144, nll_loss=1.324, ppl=2.5, wps=22037.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13400, lr=0.000273179, gnorm=0.952, loss_scale=16, train_wall=266, gb_free=8.1, wall=39798
2022-03-06 23:57:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:59:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:59:12 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 12.542 | nll_loss 11.647 | ppl 3206.19 | wps 42833.1 | wpb 510.9 | bsz 1 | num_updates 13490 | best_loss 8.481
2022-03-06 23:59:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 13490 updates
2022-03-06 23:59:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:59:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:59:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 140 @ 13490 updates, score 12.542) (writing took 2.2679453529417515 seconds)
2022-03-06 23:59:15 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 23:59:15 | INFO | train | epoch 140 | loss 3.139 | nll_loss 1.319 | ppl 2.49 | wps 21995.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13490 | lr 0.000272266 | gnorm 0.94 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 40067
2022-03-06 23:59:15 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 23:59:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:59:43 | INFO | train_inner | epoch 141:     10 / 97 loss=3.138, nll_loss=1.318, ppl=2.49, wps=22029.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13500, lr=0.000272166, gnorm=0.937, loss_scale=16, train_wall=266, gb_free=8.1, wall=40095
2022-03-07 00:03:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:03:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:03:58 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 12.507 | nll_loss 11.603 | ppl 3110.37 | wps 42484.1 | wpb 510.9 | bsz 1 | num_updates 13586 | best_loss 8.481
2022-03-07 00:03:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 13586 updates
2022-03-07 00:03:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:04:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:04:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 141 @ 13586 updates, score 12.507) (writing took 2.272484048269689 seconds)
2022-03-07 00:04:00 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-07 00:04:00 | INFO | train | epoch 141 | loss 3.133 | nll_loss 1.312 | ppl 2.48 | wps 22008.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13586 | lr 0.000271303 | gnorm 0.947 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 40352
2022-03-07 00:04:00 | INFO | fairseq.trainer | begin training epoch 142
2022-03-07 00:04:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:04:41 | INFO | train_inner | epoch 142:     14 / 97 loss=3.129, nll_loss=1.307, ppl=2.47, wps=22037.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13600, lr=0.000271163, gnorm=0.946, loss_scale=16, train_wall=266, gb_free=8.1, wall=40393
2022-03-07 00:07:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:08:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:08:44 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 12.533 | nll_loss 11.624 | ppl 3157.28 | wps 42566.1 | wpb 510.9 | bsz 1 | num_updates 13682 | best_loss 8.481
2022-03-07 00:08:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 13682 updates
2022-03-07 00:08:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:08:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:08:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 142 @ 13682 updates, score 12.533) (writing took 2.278572521172464 seconds)
2022-03-07 00:08:46 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-07 00:08:46 | INFO | train | epoch 142 | loss 3.127 | nll_loss 1.306 | ppl 2.47 | wps 21995.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13682 | lr 0.000270349 | gnorm 0.958 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 40638
2022-03-07 00:08:46 | INFO | fairseq.trainer | begin training epoch 143
2022-03-07 00:08:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:09:38 | INFO | train_inner | epoch 143:     18 / 97 loss=3.126, nll_loss=1.304, ppl=2.47, wps=22034, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13700, lr=0.000270172, gnorm=0.961, loss_scale=8, train_wall=266, gb_free=8.1, wall=40690
2022-03-07 00:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:13:30 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 12.549 | nll_loss 11.648 | ppl 3210.13 | wps 42972.5 | wpb 510.9 | bsz 1 | num_updates 13779 | best_loss 8.481
2022-03-07 00:13:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 13779 updates
2022-03-07 00:13:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:13:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:13:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 143 @ 13779 updates, score 12.549) (writing took 2.322387876920402 seconds)
2022-03-07 00:13:32 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-07 00:13:32 | INFO | train | epoch 143 | loss 3.121 | nll_loss 1.299 | ppl 2.46 | wps 22236.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13779 | lr 0.000269396 | gnorm 0.942 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 40924
2022-03-07 00:13:32 | INFO | fairseq.trainer | begin training epoch 144
2022-03-07 00:13:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:14:32 | INFO | train_inner | epoch 144:     21 / 97 loss=3.118, nll_loss=1.295, ppl=2.45, wps=22250.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13800, lr=0.000269191, gnorm=0.942, loss_scale=16, train_wall=264, gb_free=8.1, wall=40984
2022-03-07 00:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:18:15 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 12.606 | nll_loss 11.715 | ppl 3362.56 | wps 42518.3 | wpb 510.9 | bsz 1 | num_updates 13876 | best_loss 8.481
2022-03-07 00:18:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 13876 updates
2022-03-07 00:18:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:18:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 144 @ 13876 updates, score 12.606) (writing took 2.2783281560987234 seconds)
2022-03-07 00:18:18 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-07 00:18:18 | INFO | train | epoch 144 | loss 3.115 | nll_loss 1.292 | ppl 2.45 | wps 22229.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13876 | lr 0.000268453 | gnorm 0.961 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 41210
2022-03-07 00:18:18 | INFO | fairseq.trainer | begin training epoch 145
2022-03-07 00:18:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:19:27 | INFO | train_inner | epoch 145:     24 / 97 loss=3.112, nll_loss=1.289, ppl=2.44, wps=22242.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13900, lr=0.000268221, gnorm=0.963, loss_scale=16, train_wall=264, gb_free=8.1, wall=41279
2022-03-07 00:20:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:22:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:23:01 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 12.611 | nll_loss 11.714 | ppl 3360.42 | wps 42407.2 | wpb 510.9 | bsz 1 | num_updates 13972 | best_loss 8.481
2022-03-07 00:23:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 13972 updates
2022-03-07 00:23:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:23:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:23:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 145 @ 13972 updates, score 12.611) (writing took 2.2168547376058996 seconds)
2022-03-07 00:23:04 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-07 00:23:04 | INFO | train | epoch 145 | loss 3.107 | nll_loss 1.284 | ppl 2.44 | wps 21992.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13972 | lr 0.000267529 | gnorm 0.953 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 41495
2022-03-07 00:23:04 | INFO | fairseq.trainer | begin training epoch 146
2022-03-07 00:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:24:24 | INFO | train_inner | epoch 146:     28 / 97 loss=3.106, nll_loss=1.282, ppl=2.43, wps=22030.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14000, lr=0.000267261, gnorm=0.944, loss_scale=16, train_wall=266, gb_free=8.1, wall=41576
2022-03-07 00:26:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:27:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:27:47 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 12.607 | nll_loss 11.711 | ppl 3351.81 | wps 42694.7 | wpb 510.9 | bsz 1 | num_updates 14068 | best_loss 8.481
2022-03-07 00:27:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 14068 updates
2022-03-07 00:27:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:27:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:27:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 146 @ 14068 updates, score 12.607) (writing took 2.279276137240231 seconds)
2022-03-07 00:27:49 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-07 00:27:49 | INFO | train | epoch 146 | loss 3.101 | nll_loss 1.277 | ppl 2.42 | wps 22002.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14068 | lr 0.000266615 | gnorm 0.941 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 41781
2022-03-07 00:27:49 | INFO | fairseq.trainer | begin training epoch 147
2022-03-07 00:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:29:21 | INFO | train_inner | epoch 147:     32 / 97 loss=3.098, nll_loss=1.273, ppl=2.42, wps=22027.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14100, lr=0.000266312, gnorm=0.946, loss_scale=16, train_wall=266, gb_free=8.1, wall=41873
2022-03-07 00:32:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:32:33 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 12.553 | nll_loss 11.654 | ppl 3221.79 | wps 42771.9 | wpb 510.9 | bsz 1 | num_updates 14165 | best_loss 8.481
2022-03-07 00:32:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 14165 updates
2022-03-07 00:32:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:32:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:32:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 147 @ 14165 updates, score 12.553) (writing took 2.4730349821038544 seconds)
2022-03-07 00:32:35 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-07 00:32:35 | INFO | train | epoch 147 | loss 3.094 | nll_loss 1.27 | ppl 2.41 | wps 22216.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14165 | lr 0.0002657 | gnorm 0.945 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 42067
2022-03-07 00:32:35 | INFO | fairseq.trainer | begin training epoch 148
2022-03-07 00:32:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:32:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:34:19 | INFO | train_inner | epoch 148:     36 / 97 loss=3.091, nll_loss=1.267, ppl=2.41, wps=22029.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14200, lr=0.000265372, gnorm=0.935, loss_scale=16, train_wall=266, gb_free=8.1, wall=42170
2022-03-07 00:37:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:37:19 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 12.592 | nll_loss 11.703 | ppl 3334.22 | wps 42440.7 | wpb 510.9 | bsz 1 | num_updates 14261 | best_loss 8.481
2022-03-07 00:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 14261 updates
2022-03-07 00:37:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:37:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:37:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 148 @ 14261 updates, score 12.592) (writing took 2.2833662000484765 seconds)
2022-03-07 00:37:21 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-07 00:37:21 | INFO | train | epoch 148 | loss 3.088 | nll_loss 1.263 | ppl 2.4 | wps 21997.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14261 | lr 0.000264804 | gnorm 0.931 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 42353
2022-03-07 00:37:21 | INFO | fairseq.trainer | begin training epoch 149
2022-03-07 00:37:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:39:13 | INFO | train_inner | epoch 149:     39 / 97 loss=3.087, nll_loss=1.261, ppl=2.4, wps=22234.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14300, lr=0.000264443, gnorm=0.931, loss_scale=32, train_wall=264, gb_free=8.1, wall=42465
2022-03-07 00:39:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:42:05 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 12.62 | nll_loss 11.727 | ppl 3390.34 | wps 42424.8 | wpb 510.9 | bsz 1 | num_updates 14357 | best_loss 8.481
2022-03-07 00:42:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 14357 updates
2022-03-07 00:42:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:42:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:42:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 149 @ 14357 updates, score 12.62) (writing took 2.327097152825445 seconds)
2022-03-07 00:42:07 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-07 00:42:07 | INFO | train | epoch 149 | loss 3.083 | nll_loss 1.258 | ppl 2.39 | wps 21994.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14357 | lr 0.000263917 | gnorm 0.926 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 42639
2022-03-07 00:42:07 | INFO | fairseq.trainer | begin training epoch 150
2022-03-07 00:42:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:44:10 | INFO | train_inner | epoch 150:     43 / 97 loss=3.081, nll_loss=1.256, ppl=2.39, wps=22028.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=14400, lr=0.000263523, gnorm=0.938, loss_scale=16, train_wall=267, gb_free=8.1, wall=42762
2022-03-07 00:46:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:46:50 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 12.6 | nll_loss 11.707 | ppl 3343.52 | wps 42376.8 | wpb 510.9 | bsz 1 | num_updates 14453 | best_loss 8.481
2022-03-07 00:46:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 14453 updates
2022-03-07 00:46:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:46:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:46:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 150 @ 14453 updates, score 12.6) (writing took 2.378902753815055 seconds)
2022-03-07 00:46:53 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-07 00:46:53 | INFO | train | epoch 150 | loss 3.078 | nll_loss 1.252 | ppl 2.38 | wps 21986.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14453 | lr 0.00026304 | gnorm 0.946 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 42925
2022-03-07 00:46:53 | INFO | fairseq.trainer | begin training epoch 151
2022-03-07 00:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:49:08 | INFO | train_inner | epoch 151:     47 / 97 loss=3.073, nll_loss=1.247, ppl=2.37, wps=22013.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14500, lr=0.000262613, gnorm=0.942, loss_scale=16, train_wall=267, gb_free=8.1, wall=43060
2022-03-07 00:51:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:51:36 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 12.593 | nll_loss 11.705 | ppl 3337.82 | wps 42520.1 | wpb 510.9 | bsz 1 | num_updates 14550 | best_loss 8.481
2022-03-07 00:51:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 14550 updates
2022-03-07 00:51:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:51:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:51:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 151 @ 14550 updates, score 12.593) (writing took 2.2748637716285884 seconds)
2022-03-07 00:51:39 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-07 00:51:39 | INFO | train | epoch 151 | loss 3.072 | nll_loss 1.246 | ppl 2.37 | wps 22224.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14550 | lr 0.000262161 | gnorm 0.946 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 43211
2022-03-07 00:51:39 | INFO | fairseq.trainer | begin training epoch 152
2022-03-07 00:51:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:53:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:54:05 | INFO | train_inner | epoch 152:     51 / 97 loss=3.068, nll_loss=1.242, ppl=2.36, wps=22025.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=14600, lr=0.000261712, gnorm=0.939, loss_scale=16, train_wall=266, gb_free=8.1, wall=43357
2022-03-07 00:56:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:56:22 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 12.63 | nll_loss 11.751 | ppl 3447.56 | wps 42649 | wpb 510.9 | bsz 1 | num_updates 14646 | best_loss 8.481
2022-03-07 00:56:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 14646 updates
2022-03-07 00:56:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:56:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 152 @ 14646 updates, score 12.63) (writing took 2.321113422047347 seconds)
2022-03-07 00:56:25 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-07 00:56:25 | INFO | train | epoch 152 | loss 3.064 | nll_loss 1.237 | ppl 2.36 | wps 21984.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14646 | lr 0.000261301 | gnorm 0.925 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 43497
2022-03-07 00:56:25 | INFO | fairseq.trainer | begin training epoch 153
2022-03-07 00:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:59:00 | INFO | train_inner | epoch 153:     54 / 97 loss=3.063, nll_loss=1.236, ppl=2.35, wps=22234.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14700, lr=0.00026082, gnorm=0.934, loss_scale=16, train_wall=264, gb_free=8.1, wall=43652
2022-03-07 01:00:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:01:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:01:08 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 12.559 | nll_loss 11.668 | ppl 3254.52 | wps 42728.1 | wpb 510.9 | bsz 1 | num_updates 14742 | best_loss 8.481
2022-03-07 01:01:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 14742 updates
2022-03-07 01:01:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:01:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:01:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 153 @ 14742 updates, score 12.559) (writing took 2.280696349684149 seconds)
2022-03-07 01:01:11 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-07 01:01:11 | INFO | train | epoch 153 | loss 3.06 | nll_loss 1.233 | ppl 2.35 | wps 21991.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14742 | lr 0.000260448 | gnorm 0.94 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 43782
2022-03-07 01:01:11 | INFO | fairseq.trainer | begin training epoch 154
2022-03-07 01:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:03:57 | INFO | train_inner | epoch 154:     58 / 97 loss=3.057, nll_loss=1.229, ppl=2.34, wps=22035.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14800, lr=0.000259938, gnorm=0.925, loss_scale=16, train_wall=266, gb_free=8.1, wall=43949
2022-03-07 01:05:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:05:54 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 12.671 | nll_loss 11.783 | ppl 3523.12 | wps 42149.6 | wpb 510.9 | bsz 1 | num_updates 14839 | best_loss 8.481
2022-03-07 01:05:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 14839 updates
2022-03-07 01:05:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:05:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 154 @ 14839 updates, score 12.671) (writing took 2.256068713031709 seconds)
2022-03-07 01:05:56 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-07 01:05:56 | INFO | train | epoch 154 | loss 3.055 | nll_loss 1.227 | ppl 2.34 | wps 22237.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14839 | lr 0.000259596 | gnorm 0.924 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 44068
2022-03-07 01:05:56 | INFO | fairseq.trainer | begin training epoch 155
2022-03-07 01:05:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:07:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:08:54 | INFO | train_inner | epoch 155:     62 / 97 loss=3.052, nll_loss=1.224, ppl=2.34, wps=22043.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14900, lr=0.000259064, gnorm=0.935, loss_scale=16, train_wall=266, gb_free=8.1, wall=44246
2022-03-07 01:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:10:40 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 12.64 | nll_loss 11.755 | ppl 3455.26 | wps 42500.4 | wpb 510.9 | bsz 1 | num_updates 14935 | best_loss 8.481
2022-03-07 01:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 14935 updates
2022-03-07 01:10:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 155 @ 14935 updates, score 12.64) (writing took 2.3264009971171618 seconds)
2022-03-07 01:10:42 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-07 01:10:42 | INFO | train | epoch 155 | loss 3.049 | nll_loss 1.221 | ppl 2.33 | wps 22009.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14935 | lr 0.00025876 | gnorm 0.949 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 44354
2022-03-07 01:10:42 | INFO | fairseq.trainer | begin training epoch 156
2022-03-07 01:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:13:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:13:51 | INFO | train_inner | epoch 156:     66 / 97 loss=3.044, nll_loss=1.216, ppl=2.32, wps=22038.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15000, lr=0.000258199, gnorm=0.937, loss_scale=16, train_wall=266, gb_free=8.1, wall=44543
2022-03-07 01:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:15:25 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 12.635 | nll_loss 11.745 | ppl 3432.09 | wps 42552.3 | wpb 510.9 | bsz 1 | num_updates 15031 | best_loss 8.481
2022-03-07 01:15:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 15031 updates
2022-03-07 01:15:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 156 @ 15031 updates, score 12.635) (writing took 2.239852446131408 seconds)
2022-03-07 01:15:28 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-07 01:15:28 | INFO | train | epoch 156 | loss 3.042 | nll_loss 1.214 | ppl 2.32 | wps 22004.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15031 | lr 0.000257932 | gnorm 0.93 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 44640
2022-03-07 01:15:28 | INFO | fairseq.trainer | begin training epoch 157
2022-03-07 01:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:18:46 | INFO | train_inner | epoch 157:     69 / 97 loss=3.04, nll_loss=1.212, ppl=2.32, wps=22235.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=15100, lr=0.000257343, gnorm=0.946, loss_scale=16, train_wall=264, gb_free=8.1, wall=44838
2022-03-07 01:19:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:20:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:20:11 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 12.661 | nll_loss 11.777 | ppl 3508.96 | wps 42755.1 | wpb 510.9 | bsz 1 | num_updates 15127 | best_loss 8.481
2022-03-07 01:20:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 15127 updates
2022-03-07 01:20:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:20:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:20:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 157 @ 15127 updates, score 12.661) (writing took 2.2650186480022967 seconds)
2022-03-07 01:20:13 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-07 01:20:13 | INFO | train | epoch 157 | loss 3.037 | nll_loss 1.208 | ppl 2.31 | wps 21992.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15127 | lr 0.000257113 | gnorm 0.938 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 44925
2022-03-07 01:20:13 | INFO | fairseq.trainer | begin training epoch 158
2022-03-07 01:20:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:23:43 | INFO | train_inner | epoch 158:     73 / 97 loss=3.036, nll_loss=1.207, ppl=2.31, wps=22022, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=15200, lr=0.000256495, gnorm=0.926, loss_scale=16, train_wall=267, gb_free=8.1, wall=45135
2022-03-07 01:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:24:57 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 12.645 | nll_loss 11.762 | ppl 3472.02 | wps 42381.3 | wpb 510.9 | bsz 1 | num_updates 15224 | best_loss 8.481
2022-03-07 01:24:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 15224 updates
2022-03-07 01:24:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:24:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:24:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 158 @ 15224 updates, score 12.645) (writing took 2.223367123864591 seconds)
2022-03-07 01:24:59 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-07 01:24:59 | INFO | train | epoch 158 | loss 3.033 | nll_loss 1.204 | ppl 2.3 | wps 22218 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15224 | lr 0.000256292 | gnorm 0.925 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 45211
2022-03-07 01:24:59 | INFO | fairseq.trainer | begin training epoch 159
2022-03-07 01:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:26:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:28:40 | INFO | train_inner | epoch 159:     77 / 97 loss=3.03, nll_loss=1.2, ppl=2.3, wps=22034.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=15300, lr=0.000255655, gnorm=0.92, loss_scale=16, train_wall=266, gb_free=8.1, wall=45432
2022-03-07 01:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:29:43 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 12.643 | nll_loss 11.76 | ppl 3468.49 | wps 42564.5 | wpb 510.9 | bsz 1 | num_updates 15320 | best_loss 8.481
2022-03-07 01:29:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 15320 updates
2022-03-07 01:29:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:29:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:29:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 159 @ 15320 updates, score 12.643) (writing took 2.253056292887777 seconds)
2022-03-07 01:29:45 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-07 01:29:45 | INFO | train | epoch 159 | loss 3.028 | nll_loss 1.198 | ppl 2.29 | wps 22002.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15320 | lr 0.000255488 | gnorm 0.921 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 45497
2022-03-07 01:29:45 | INFO | fairseq.trainer | begin training epoch 160
2022-03-07 01:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:32:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:33:38 | INFO | train_inner | epoch 160:     81 / 97 loss=3.022, nll_loss=1.192, ppl=2.28, wps=22020.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=15400, lr=0.000254824, gnorm=0.927, loss_scale=16, train_wall=266, gb_free=8.1, wall=45730
2022-03-07 01:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:34:29 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 12.672 | nll_loss 11.79 | ppl 3541.99 | wps 42573 | wpb 510.9 | bsz 1 | num_updates 15416 | best_loss 8.481
2022-03-07 01:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 15416 updates
2022-03-07 01:34:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:34:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:34:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 160 @ 15416 updates, score 12.672) (writing took 2.2704101921990514 seconds)
2022-03-07 01:34:31 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-07 01:34:31 | INFO | train | epoch 160 | loss 3.021 | nll_loss 1.191 | ppl 2.28 | wps 21986.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15416 | lr 0.000254691 | gnorm 0.922 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 45783
2022-03-07 01:34:31 | INFO | fairseq.trainer | begin training epoch 161
2022-03-07 01:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:38:32 | INFO | train_inner | epoch 161:     84 / 97 loss=3.021, nll_loss=1.191, ppl=2.28, wps=22238.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15500, lr=0.000254, gnorm=0.928, loss_scale=16, train_wall=264, gb_free=8.1, wall=46024
2022-03-07 01:39:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:39:15 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 12.654 | nll_loss 11.764 | ppl 3478.2 | wps 42474 | wpb 510.9 | bsz 1 | num_updates 15513 | best_loss 8.481
2022-03-07 01:39:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 15513 updates
2022-03-07 01:39:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:39:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:39:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 161 @ 15513 updates, score 12.654) (writing took 2.2716982890851796 seconds)
2022-03-07 01:39:17 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-07 01:39:17 | INFO | train | epoch 161 | loss 3.018 | nll_loss 1.187 | ppl 2.28 | wps 22225.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15513 | lr 0.000253894 | gnorm 0.926 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 46069
2022-03-07 01:39:17 | INFO | fairseq.trainer | begin training epoch 162
2022-03-07 01:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:40:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:43:30 | INFO | train_inner | epoch 162:     88 / 97 loss=3.013, nll_loss=1.183, ppl=2.27, wps=22043.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15600, lr=0.000253185, gnorm=0.923, loss_scale=16, train_wall=266, gb_free=8.1, wall=46321
2022-03-07 01:43:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:44:00 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 12.675 | nll_loss 11.803 | ppl 3573.43 | wps 42291.5 | wpb 510.9 | bsz 1 | num_updates 15609 | best_loss 8.481
2022-03-07 01:44:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 15609 updates
2022-03-07 01:44:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:44:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:44:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 162 @ 15609 updates, score 12.675) (writing took 2.2834864179603755 seconds)
2022-03-07 01:44:03 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-07 01:44:03 | INFO | train | epoch 162 | loss 3.011 | nll_loss 1.18 | ppl 2.27 | wps 22007.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15609 | lr 0.000253112 | gnorm 0.925 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 46355
2022-03-07 01:44:03 | INFO | fairseq.trainer | begin training epoch 163
2022-03-07 01:44:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:46:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:48:27 | INFO | train_inner | epoch 163:     92 / 97 loss=3.009, nll_loss=1.178, ppl=2.26, wps=22029.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15700, lr=0.000252377, gnorm=0.921, loss_scale=16, train_wall=266, gb_free=8.1, wall=46619
2022-03-07 01:48:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:48:46 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 12.655 | nll_loss 11.781 | ppl 3520.16 | wps 42513.1 | wpb 510.9 | bsz 1 | num_updates 15705 | best_loss 8.481
2022-03-07 01:48:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 15705 updates
2022-03-07 01:48:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:48:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:48:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 163 @ 15705 updates, score 12.655) (writing took 2.302148347720504 seconds)
2022-03-07 01:48:48 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-07 01:48:48 | INFO | train | epoch 163 | loss 3.006 | nll_loss 1.175 | ppl 2.26 | wps 21995.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15705 | lr 0.000252337 | gnorm 0.921 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 46640
2022-03-07 01:48:48 | INFO | fairseq.trainer | begin training epoch 164
2022-03-07 01:48:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:52:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:53:24 | INFO | train_inner | epoch 164:     96 / 97 loss=3.003, nll_loss=1.172, ppl=2.25, wps=22003.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15800, lr=0.000251577, gnorm=0.926, loss_scale=16, train_wall=267, gb_free=8.1, wall=46916
2022-03-07 01:53:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:53:32 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 12.679 | nll_loss 11.8 | ppl 3565.01 | wps 42656.3 | wpb 510.9 | bsz 1 | num_updates 15801 | best_loss 8.481
2022-03-07 01:53:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 15801 updates
2022-03-07 01:53:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:53:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:53:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 164 @ 15801 updates, score 12.679) (writing took 2.2409373531118035 seconds)
2022-03-07 01:53:35 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-07 01:53:35 | INFO | train | epoch 164 | loss 3.002 | nll_loss 1.171 | ppl 2.25 | wps 21976.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15801 | lr 0.000251569 | gnorm 0.925 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 46926
2022-03-07 01:53:35 | INFO | fairseq.trainer | begin training epoch 165
2022-03-07 01:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:58:18 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 12.722 | nll_loss 11.861 | ppl 3721.05 | wps 43121.4 | wpb 510.9 | bsz 1 | num_updates 15898 | best_loss 8.481
2022-03-07 01:58:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 15898 updates
2022-03-07 01:58:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:58:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:58:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 165 @ 15898 updates, score 12.722) (writing took 2.361055309418589 seconds)
2022-03-07 01:58:20 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-07 01:58:20 | INFO | train | epoch 165 | loss 2.997 | nll_loss 1.164 | ppl 2.24 | wps 22226.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15898 | lr 0.000250801 | gnorm 0.924 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 47212
2022-03-07 01:58:20 | INFO | fairseq.trainer | begin training epoch 166
2022-03-07 01:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:58:26 | INFO | train_inner | epoch 166:      2 / 97 loss=2.996, nll_loss=1.164, ppl=2.24, wps=21691.2, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=15900, lr=0.000250785, gnorm=0.925, loss_scale=16, train_wall=264, gb_free=8.1, wall=47218
2022-03-07 01:59:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:03:04 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 12.727 | nll_loss 11.859 | ppl 3714.66 | wps 42721.8 | wpb 510.9 | bsz 1 | num_updates 15994 | best_loss 8.481
2022-03-07 02:03:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 15994 updates
2022-03-07 02:03:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:03:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:03:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 166 @ 15994 updates, score 12.727) (writing took 2.315437477082014 seconds)
2022-03-07 02:03:06 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-07 02:03:06 | INFO | train | epoch 166 | loss 2.99 | nll_loss 1.157 | ppl 2.23 | wps 22010.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15994 | lr 0.000250047 | gnorm 0.91 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 47498
2022-03-07 02:03:06 | INFO | fairseq.trainer | begin training epoch 167
2022-03-07 02:03:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:03:23 | INFO | train_inner | epoch 167:      6 / 97 loss=2.989, nll_loss=1.156, ppl=2.23, wps=22045.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16000, lr=0.00025, gnorm=0.909, loss_scale=16, train_wall=266, gb_free=8.1, wall=47515
2022-03-07 02:06:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:07:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:07:50 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 12.666 | nll_loss 11.789 | ppl 3539.68 | wps 41808.8 | wpb 510.9 | bsz 1 | num_updates 16090 | best_loss 8.481
2022-03-07 02:07:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 16090 updates
2022-03-07 02:07:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:07:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:07:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 167 @ 16090 updates, score 12.666) (writing took 2.3073128322139382 seconds)
2022-03-07 02:07:52 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-07 02:07:52 | INFO | train | epoch 167 | loss 2.989 | nll_loss 1.156 | ppl 2.23 | wps 21989.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16090 | lr 0.0002493 | gnorm 0.922 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 47784
2022-03-07 02:07:52 | INFO | fairseq.trainer | begin training epoch 168
2022-03-07 02:07:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:08:21 | INFO | train_inner | epoch 168:     10 / 97 loss=2.986, nll_loss=1.153, ppl=2.22, wps=22019.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16100, lr=0.000249222, gnorm=0.921, loss_scale=16, train_wall=266, gb_free=8.1, wall=47813
2022-03-07 02:12:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:12:35 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 12.756 | nll_loss 11.888 | ppl 3791.29 | wps 42533.5 | wpb 510.9 | bsz 1 | num_updates 16187 | best_loss 8.481
2022-03-07 02:12:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 16187 updates
2022-03-07 02:12:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:12:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:12:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 168 @ 16187 updates, score 12.756) (writing took 2.328072232194245 seconds)
2022-03-07 02:12:38 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-07 02:12:38 | INFO | train | epoch 168 | loss 2.984 | nll_loss 1.151 | ppl 2.22 | wps 22236.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16187 | lr 0.000248552 | gnorm 0.929 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 48070
2022-03-07 02:12:38 | INFO | fairseq.trainer | begin training epoch 169
2022-03-07 02:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:13:15 | INFO | train_inner | epoch 169:     13 / 97 loss=2.982, nll_loss=1.148, ppl=2.22, wps=22254.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16200, lr=0.000248452, gnorm=0.924, loss_scale=32, train_wall=264, gb_free=8.1, wall=48107
2022-03-07 02:13:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:17:21 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 12.708 | nll_loss 11.838 | ppl 3660.29 | wps 42353.2 | wpb 510.9 | bsz 1 | num_updates 16283 | best_loss 8.481
2022-03-07 02:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 16283 updates
2022-03-07 02:17:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:17:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:17:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 169 @ 16283 updates, score 12.708) (writing took 2.26972729107365 seconds)
2022-03-07 02:17:23 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-07 02:17:23 | INFO | train | epoch 169 | loss 2.978 | nll_loss 1.145 | ppl 2.21 | wps 22000.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16283 | lr 0.000247818 | gnorm 0.912 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 48355
2022-03-07 02:17:23 | INFO | fairseq.trainer | begin training epoch 170
2022-03-07 02:17:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:18:12 | INFO | train_inner | epoch 170:     17 / 97 loss=2.976, nll_loss=1.142, ppl=2.21, wps=22030.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=16300, lr=0.000247689, gnorm=0.914, loss_scale=16, train_wall=266, gb_free=8.1, wall=48404
2022-03-07 02:20:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:22:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:22:07 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 12.735 | nll_loss 11.861 | ppl 3720.78 | wps 42523.9 | wpb 510.9 | bsz 1 | num_updates 16379 | best_loss 8.481
2022-03-07 02:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 16379 updates
2022-03-07 02:22:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:22:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:22:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 170 @ 16379 updates, score 12.735) (writing took 2.229723499622196 seconds)
2022-03-07 02:22:09 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-07 02:22:09 | INFO | train | epoch 170 | loss 2.974 | nll_loss 1.14 | ppl 2.2 | wps 22005.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16379 | lr 0.000247091 | gnorm 0.912 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 48641
2022-03-07 02:22:09 | INFO | fairseq.trainer | begin training epoch 171
2022-03-07 02:22:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:23:09 | INFO | train_inner | epoch 171:     21 / 97 loss=2.974, nll_loss=1.14, ppl=2.2, wps=22041.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=16400, lr=0.000246932, gnorm=0.91, loss_scale=16, train_wall=266, gb_free=8.1, wall=48701
2022-03-07 02:26:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:26:53 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 12.727 | nll_loss 11.863 | ppl 3723.79 | wps 43031.1 | wpb 510.9 | bsz 1 | num_updates 16476 | best_loss 8.481
2022-03-07 02:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 16476 updates
2022-03-07 02:26:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:26:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:26:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 171 @ 16476 updates, score 12.727) (writing took 2.241677945945412 seconds)
2022-03-07 02:26:55 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-07 02:26:55 | INFO | train | epoch 171 | loss 2.97 | nll_loss 1.136 | ppl 2.2 | wps 22235.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16476 | lr 0.000246362 | gnorm 0.922 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 48927
2022-03-07 02:26:55 | INFO | fairseq.trainer | begin training epoch 172
2022-03-07 02:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:27:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:28:07 | INFO | train_inner | epoch 172:     25 / 97 loss=2.967, nll_loss=1.133, ppl=2.19, wps=22036.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16500, lr=0.000246183, gnorm=0.926, loss_scale=16, train_wall=266, gb_free=8.1, wall=48999
2022-03-07 02:31:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:31:38 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 12.689 | nll_loss 11.817 | ppl 3608.84 | wps 42575.4 | wpb 510.9 | bsz 1 | num_updates 16572 | best_loss 8.481
2022-03-07 02:31:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 16572 updates
2022-03-07 02:31:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:31:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:31:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 172 @ 16572 updates, score 12.689) (writing took 2.2420148430392146 seconds)
2022-03-07 02:31:40 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-07 02:31:40 | INFO | train | epoch 172 | loss 2.966 | nll_loss 1.131 | ppl 2.19 | wps 22007.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16572 | lr 0.000245648 | gnorm 0.909 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 49212
2022-03-07 02:31:40 | INFO | fairseq.trainer | begin training epoch 173
2022-03-07 02:31:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:33:01 | INFO | train_inner | epoch 173:     28 / 97 loss=2.964, nll_loss=1.129, ppl=2.19, wps=22250.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16600, lr=0.00024544, gnorm=0.905, loss_scale=16, train_wall=264, gb_free=8.1, wall=49293
2022-03-07 02:33:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:36:24 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 12.652 | nll_loss 11.777 | ppl 3509.32 | wps 42737.4 | wpb 510.9 | bsz 1 | num_updates 16668 | best_loss 8.481
2022-03-07 02:36:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 16668 updates
2022-03-07 02:36:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:36:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:36:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 173 @ 16668 updates, score 12.652) (writing took 2.2804913469590247 seconds)
2022-03-07 02:36:26 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-07 02:36:26 | INFO | train | epoch 173 | loss 2.961 | nll_loss 1.127 | ppl 2.18 | wps 22010.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16668 | lr 0.000244939 | gnorm 0.913 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 49498
2022-03-07 02:36:26 | INFO | fairseq.trainer | begin training epoch 174
2022-03-07 02:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:37:58 | INFO | train_inner | epoch 174:     32 / 97 loss=2.959, nll_loss=1.124, ppl=2.18, wps=22051.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16700, lr=0.000244704, gnorm=0.918, loss_scale=16, train_wall=266, gb_free=8.1, wall=49590
2022-03-07 02:40:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:41:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:41:09 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 12.684 | nll_loss 11.819 | ppl 3612.96 | wps 42364.9 | wpb 510.9 | bsz 1 | num_updates 16764 | best_loss 8.481
2022-03-07 02:41:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 16764 updates
2022-03-07 02:41:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 174 @ 16764 updates, score 12.684) (writing took 2.256174252834171 seconds)
2022-03-07 02:41:12 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-07 02:41:12 | INFO | train | epoch 174 | loss 2.956 | nll_loss 1.121 | ppl 2.17 | wps 22014.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16764 | lr 0.000244237 | gnorm 0.921 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 49784
2022-03-07 02:41:12 | INFO | fairseq.trainer | begin training epoch 175
2022-03-07 02:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:42:55 | INFO | train_inner | epoch 175:     36 / 97 loss=2.952, nll_loss=1.116, ppl=2.17, wps=22030.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=16800, lr=0.000243975, gnorm=0.916, loss_scale=16, train_wall=266, gb_free=8.1, wall=49887
2022-03-07 02:45:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:45:55 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 12.662 | nll_loss 11.791 | ppl 3543.84 | wps 42843.4 | wpb 510.9 | bsz 1 | num_updates 16861 | best_loss 8.481
2022-03-07 02:45:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 16861 updates
2022-03-07 02:45:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:45:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:45:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 175 @ 16861 updates, score 12.662) (writing took 2.330027251970023 seconds)
2022-03-07 02:45:58 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-07 02:45:58 | INFO | train | epoch 175 | loss 2.953 | nll_loss 1.118 | ppl 2.17 | wps 22212.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16861 | lr 0.000243533 | gnorm 0.916 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 50070
2022-03-07 02:45:58 | INFO | fairseq.trainer | begin training epoch 176
2022-03-07 02:45:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:47:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:47:53 | INFO | train_inner | epoch 176:     40 / 97 loss=2.952, nll_loss=1.117, ppl=2.17, wps=22022.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=16900, lr=0.000243252, gnorm=0.919, loss_scale=16, train_wall=266, gb_free=8.1, wall=50185
2022-03-07 02:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:50:41 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 12.667 | nll_loss 11.799 | ppl 3563.24 | wps 42570.8 | wpb 510.9 | bsz 1 | num_updates 16957 | best_loss 8.481
2022-03-07 02:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 16957 updates
2022-03-07 02:50:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:50:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:50:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 176 @ 16957 updates, score 12.667) (writing took 2.2366833579726517 seconds)
2022-03-07 02:50:43 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-07 02:50:43 | INFO | train | epoch 176 | loss 2.948 | nll_loss 1.113 | ppl 2.16 | wps 21998.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16957 | lr 0.000242843 | gnorm 0.919 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 50355
2022-03-07 02:50:44 | INFO | fairseq.trainer | begin training epoch 177
2022-03-07 02:50:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:52:47 | INFO | train_inner | epoch 177:     43 / 97 loss=2.949, nll_loss=1.113, ppl=2.16, wps=22250.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=17000, lr=0.000242536, gnorm=0.915, loss_scale=16, train_wall=264, gb_free=8.1, wall=50479
2022-03-07 02:53:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:55:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:55:27 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 12.715 | nll_loss 11.852 | ppl 3697.59 | wps 42671 | wpb 510.9 | bsz 1 | num_updates 17053 | best_loss 8.481
2022-03-07 02:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 17053 updates
2022-03-07 02:55:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:55:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:55:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 177 @ 17053 updates, score 12.715) (writing took 2.2667859536595643 seconds)
2022-03-07 02:55:29 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-07 02:55:29 | INFO | train | epoch 177 | loss 2.944 | nll_loss 1.109 | ppl 2.16 | wps 22004.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17053 | lr 0.000242158 | gnorm 0.907 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 50641
2022-03-07 02:55:29 | INFO | fairseq.trainer | begin training epoch 178
2022-03-07 02:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:57:44 | INFO | train_inner | epoch 178:     47 / 97 loss=2.941, nll_loss=1.105, ppl=2.15, wps=22036.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17100, lr=0.000241825, gnorm=0.909, loss_scale=16, train_wall=266, gb_free=8.1, wall=50776
2022-03-07 03:00:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:00:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:00:13 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 12.802 | nll_loss 11.94 | ppl 3930.09 | wps 42721.5 | wpb 510.9 | bsz 1 | num_updates 17149 | best_loss 8.481
2022-03-07 03:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 17149 updates
2022-03-07 03:00:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 178 @ 17149 updates, score 12.802) (writing took 2.2944156797602773 seconds)
2022-03-07 03:00:15 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-07 03:00:15 | INFO | train | epoch 178 | loss 2.94 | nll_loss 1.104 | ppl 2.15 | wps 21994.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17149 | lr 0.00024148 | gnorm 0.915 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 50927
2022-03-07 03:00:15 | INFO | fairseq.trainer | begin training epoch 179
2022-03-07 03:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:02:41 | INFO | train_inner | epoch 179:     51 / 97 loss=2.939, nll_loss=1.104, ppl=2.15, wps=22033.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17200, lr=0.000241121, gnorm=0.912, loss_scale=16, train_wall=266, gb_free=8.1, wall=51073
2022-03-07 03:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:04:58 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 12.729 | nll_loss 11.867 | ppl 3736.19 | wps 42557 | wpb 510.9 | bsz 1 | num_updates 17246 | best_loss 8.481
2022-03-07 03:04:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 17246 updates
2022-03-07 03:04:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:05:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:05:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 179 @ 17246 updates, score 12.729) (writing took 2.256245655938983 seconds)
2022-03-07 03:05:01 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-07 03:05:01 | INFO | train | epoch 179 | loss 2.936 | nll_loss 1.1 | ppl 2.14 | wps 22245.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17246 | lr 0.0002408 | gnorm 0.909 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 51213
2022-03-07 03:05:01 | INFO | fairseq.trainer | begin training epoch 180
2022-03-07 03:05:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:06:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:07:39 | INFO | train_inner | epoch 180:     55 / 97 loss=2.933, nll_loss=1.097, ppl=2.14, wps=22043, ups=0.34, wpb=65495, bsz=127.9, num_updates=17300, lr=0.000240424, gnorm=0.91, loss_scale=16, train_wall=266, gb_free=8.1, wall=51370
2022-03-07 03:09:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:09:44 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 12.741 | nll_loss 11.871 | ppl 3746.27 | wps 41973.5 | wpb 510.9 | bsz 1 | num_updates 17342 | best_loss 8.481
2022-03-07 03:09:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 17342 updates
2022-03-07 03:09:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:09:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 180 @ 17342 updates, score 12.741) (writing took 2.427051871083677 seconds)
2022-03-07 03:09:47 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-07 03:09:47 | INFO | train | epoch 180 | loss 2.933 | nll_loss 1.097 | ppl 2.14 | wps 21992.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17342 | lr 0.000240132 | gnorm 0.918 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 51498
2022-03-07 03:09:47 | INFO | fairseq.trainer | begin training epoch 181
2022-03-07 03:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:12:33 | INFO | train_inner | epoch 181:     58 / 97 loss=2.929, nll_loss=1.092, ppl=2.13, wps=22226.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=17400, lr=0.000239732, gnorm=0.909, loss_scale=16, train_wall=264, gb_free=8.1, wall=51665
2022-03-07 03:13:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:14:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:14:30 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 12.721 | nll_loss 11.863 | ppl 3726.12 | wps 42590.9 | wpb 510.9 | bsz 1 | num_updates 17438 | best_loss 8.481
2022-03-07 03:14:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 17438 updates
2022-03-07 03:14:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:14:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:14:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 181 @ 17438 updates, score 12.721) (writing took 2.262567325029522 seconds)
2022-03-07 03:14:32 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-07 03:14:32 | INFO | train | epoch 181 | loss 2.927 | nll_loss 1.09 | ppl 2.13 | wps 21987.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17438 | lr 0.00023947 | gnorm 0.901 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 51784
2022-03-07 03:14:32 | INFO | fairseq.trainer | begin training epoch 182
2022-03-07 03:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:17:31 | INFO | train_inner | epoch 182:     62 / 97 loss=2.929, nll_loss=1.093, ppl=2.13, wps=22016, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17500, lr=0.000239046, gnorm=0.91, loss_scale=16, train_wall=267, gb_free=8.1, wall=51963
2022-03-07 03:19:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:19:16 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 12.756 | nll_loss 11.899 | ppl 3820.03 | wps 42502.1 | wpb 510.9 | bsz 1 | num_updates 17535 | best_loss 8.481
2022-03-07 03:19:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 17535 updates
2022-03-07 03:19:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:19:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:19:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 182 @ 17535 updates, score 12.756) (writing took 2.256408961955458 seconds)
2022-03-07 03:19:18 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-07 03:19:18 | INFO | train | epoch 182 | loss 2.924 | nll_loss 1.087 | ppl 2.12 | wps 22215.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17535 | lr 0.000238807 | gnorm 0.906 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 52070
2022-03-07 03:19:18 | INFO | fairseq.trainer | begin training epoch 183
2022-03-07 03:19:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:20:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:22:28 | INFO | train_inner | epoch 183:     66 / 97 loss=2.922, nll_loss=1.085, ppl=2.12, wps=22033.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17600, lr=0.000238366, gnorm=0.899, loss_scale=16, train_wall=266, gb_free=8.1, wall=52260
2022-03-07 03:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:24:02 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 12.704 | nll_loss 11.847 | ppl 3683.01 | wps 42623.5 | wpb 510.9 | bsz 1 | num_updates 17631 | best_loss 8.481
2022-03-07 03:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 17631 updates
2022-03-07 03:24:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:24:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 183 @ 17631 updates, score 12.704) (writing took 2.399399367161095 seconds)
2022-03-07 03:24:04 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-07 03:24:04 | INFO | train | epoch 183 | loss 2.921 | nll_loss 1.084 | ppl 2.12 | wps 21992.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17631 | lr 0.000238156 | gnorm 0.902 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 52356
2022-03-07 03:24:04 | INFO | fairseq.trainer | begin training epoch 184
2022-03-07 03:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:27:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:27:25 | INFO | train_inner | epoch 184:     70 / 97 loss=2.918, nll_loss=1.081, ppl=2.12, wps=22025.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17700, lr=0.000237691, gnorm=0.909, loss_scale=16, train_wall=266, gb_free=8.1, wall=52557
2022-03-07 03:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:28:48 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 12.76 | nll_loss 11.907 | ppl 3840.13 | wps 42561.9 | wpb 510.9 | bsz 1 | num_updates 17727 | best_loss 8.481
2022-03-07 03:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 17727 updates
2022-03-07 03:28:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:28:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 184 @ 17727 updates, score 12.76) (writing took 2.238779452163726 seconds)
2022-03-07 03:28:50 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-07 03:28:50 | INFO | train | epoch 184 | loss 2.916 | nll_loss 1.079 | ppl 2.11 | wps 22003 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17727 | lr 0.00023751 | gnorm 0.903 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 52642
2022-03-07 03:28:50 | INFO | fairseq.trainer | begin training epoch 185
2022-03-07 03:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:32:20 | INFO | train_inner | epoch 185:     73 / 97 loss=2.914, nll_loss=1.077, ppl=2.11, wps=22243.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17800, lr=0.000237023, gnorm=0.904, loss_scale=16, train_wall=264, gb_free=8.1, wall=52852
2022-03-07 03:33:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:33:33 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 12.712 | nll_loss 11.859 | ppl 3714.35 | wps 43159.6 | wpb 510.9 | bsz 1 | num_updates 17824 | best_loss 8.481
2022-03-07 03:33:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 17824 updates
2022-03-07 03:33:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:33:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 185 @ 17824 updates, score 12.712) (writing took 2.245194958988577 seconds)
2022-03-07 03:33:36 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-07 03:33:36 | INFO | train | epoch 185 | loss 2.913 | nll_loss 1.075 | ppl 2.11 | wps 22235.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17824 | lr 0.000236863 | gnorm 0.907 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 52928
2022-03-07 03:33:36 | INFO | fairseq.trainer | begin training epoch 186
2022-03-07 03:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:33:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:37:17 | INFO | train_inner | epoch 186:     77 / 97 loss=2.912, nll_loss=1.075, ppl=2.11, wps=22040.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=17900, lr=0.00023636, gnorm=0.906, loss_scale=16, train_wall=266, gb_free=8.1, wall=53149
2022-03-07 03:38:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:38:19 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 12.789 | nll_loss 11.939 | ppl 3925.34 | wps 42555.6 | wpb 510.9 | bsz 1 | num_updates 17920 | best_loss 8.481
2022-03-07 03:38:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 17920 updates
2022-03-07 03:38:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:38:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 186 @ 17920 updates, score 12.789) (writing took 2.2770863911136985 seconds)
2022-03-07 03:38:22 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-07 03:38:22 | INFO | train | epoch 186 | loss 2.91 | nll_loss 1.072 | ppl 2.1 | wps 21997.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17920 | lr 0.000236228 | gnorm 0.904 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 53213
2022-03-07 03:38:22 | INFO | fairseq.trainer | begin training epoch 187
2022-03-07 03:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:40:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:42:14 | INFO | train_inner | epoch 187:     81 / 97 loss=2.906, nll_loss=1.068, ppl=2.1, wps=22023.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18000, lr=0.000235702, gnorm=0.913, loss_scale=16, train_wall=266, gb_free=8.1, wall=53446
2022-03-07 03:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:05 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 12.799 | nll_loss 11.948 | ppl 3951.22 | wps 42870.2 | wpb 510.9 | bsz 1 | num_updates 18016 | best_loss 8.481
2022-03-07 03:43:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 18016 updates
2022-03-07 03:43:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:43:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:43:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 187 @ 18016 updates, score 12.799) (writing took 2.244228362105787 seconds)
2022-03-07 03:43:07 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-07 03:43:07 | INFO | train | epoch 187 | loss 2.906 | nll_loss 1.068 | ppl 2.1 | wps 21998 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18016 | lr 0.000235598 | gnorm 0.912 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 53499
2022-03-07 03:43:07 | INFO | fairseq.trainer | begin training epoch 188
2022-03-07 03:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:46:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:47:11 | INFO | train_inner | epoch 188:     85 / 97 loss=2.904, nll_loss=1.066, ppl=2.09, wps=22042.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18100, lr=0.00023505, gnorm=0.901, loss_scale=16, train_wall=266, gb_free=8.1, wall=53743
2022-03-07 03:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:47:51 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 12.76 | nll_loss 11.905 | ppl 3835.02 | wps 42454.3 | wpb 510.9 | bsz 1 | num_updates 18112 | best_loss 8.481
2022-03-07 03:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 18112 updates
2022-03-07 03:47:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 188 @ 18112 updates, score 12.76) (writing took 2.2551807994022965 seconds)
2022-03-07 03:47:53 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-07 03:47:53 | INFO | train | epoch 188 | loss 2.9 | nll_loss 1.062 | ppl 2.09 | wps 22005.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18112 | lr 0.000234972 | gnorm 0.902 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 53785
2022-03-07 03:47:53 | INFO | fairseq.trainer | begin training epoch 189
2022-03-07 03:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:52:06 | INFO | train_inner | epoch 189:     88 / 97 loss=2.898, nll_loss=1.059, ppl=2.08, wps=22236.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=18200, lr=0.000234404, gnorm=0.899, loss_scale=16, train_wall=264, gb_free=8.1, wall=54038
2022-03-07 03:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:52:37 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 12.731 | nll_loss 11.871 | ppl 3745.24 | wps 42592.6 | wpb 510.9 | bsz 1 | num_updates 18209 | best_loss 8.481
2022-03-07 03:52:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 18209 updates
2022-03-07 03:52:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:52:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:52:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 189 @ 18209 updates, score 12.731) (writing took 2.3056912599131465 seconds)
2022-03-07 03:52:39 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-07 03:52:39 | INFO | train | epoch 189 | loss 2.898 | nll_loss 1.06 | ppl 2.08 | wps 22220.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18209 | lr 0.000234346 | gnorm 0.898 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 54071
2022-03-07 03:52:39 | INFO | fairseq.trainer | begin training epoch 190
2022-03-07 03:52:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:53:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:57:03 | INFO | train_inner | epoch 190:     92 / 97 loss=2.898, nll_loss=1.06, ppl=2.09, wps=22039.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18300, lr=0.000233762, gnorm=0.907, loss_scale=16, train_wall=266, gb_free=8.1, wall=54335
2022-03-07 03:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:57:22 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 12.77 | nll_loss 11.916 | ppl 3864.59 | wps 42402.8 | wpb 510.9 | bsz 1 | num_updates 18305 | best_loss 8.481
2022-03-07 03:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 18305 updates
2022-03-07 03:57:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:57:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:57:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 190 @ 18305 updates, score 12.77) (writing took 2.3518050550483167 seconds)
2022-03-07 03:57:25 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-07 03:57:25 | INFO | train | epoch 190 | loss 2.895 | nll_loss 1.057 | ppl 2.08 | wps 21998.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18305 | lr 0.00023373 | gnorm 0.905 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 54357
2022-03-07 03:57:25 | INFO | fairseq.trainer | begin training epoch 191
2022-03-07 03:57:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:01:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:02:00 | INFO | train_inner | epoch 191:     96 / 97 loss=2.892, nll_loss=1.053, ppl=2.07, wps=22026, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18400, lr=0.000233126, gnorm=0.903, loss_scale=16, train_wall=266, gb_free=8.1, wall=54632
2022-03-07 04:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:02:08 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 12.784 | nll_loss 11.935 | ppl 3914.33 | wps 42876.7 | wpb 510.9 | bsz 1 | num_updates 18401 | best_loss 8.481
2022-03-07 04:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 18401 updates
2022-03-07 04:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 191 @ 18401 updates, score 12.784) (writing took 2.2402716050855815 seconds)
2022-03-07 04:02:10 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-07 04:02:10 | INFO | train | epoch 191 | loss 2.891 | nll_loss 1.052 | ppl 2.07 | wps 22006.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18401 | lr 0.00023312 | gnorm 0.903 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 54642
2022-03-07 04:02:10 | INFO | fairseq.trainer | begin training epoch 192
2022-03-07 04:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:06:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:06:54 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 12.807 | nll_loss 11.956 | ppl 3973.19 | wps 42309.5 | wpb 510.9 | bsz 1 | num_updates 18498 | best_loss 8.481
2022-03-07 04:06:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 18498 updates
2022-03-07 04:06:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:06:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:06:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 192 @ 18498 updates, score 12.807) (writing took 2.299252464901656 seconds)
2022-03-07 04:06:56 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-07 04:06:56 | INFO | train | epoch 192 | loss 2.888 | nll_loss 1.05 | ppl 2.07 | wps 22242.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18498 | lr 0.000232508 | gnorm 0.893 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 54928
2022-03-07 04:06:56 | INFO | fairseq.trainer | begin training epoch 193
2022-03-07 04:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:07:02 | INFO | train_inner | epoch 193:      2 / 97 loss=2.888, nll_loss=1.049, ppl=2.07, wps=21709, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=18500, lr=0.000232495, gnorm=0.893, loss_scale=16, train_wall=263, gb_free=8.1, wall=54934
2022-03-07 04:08:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:11:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:11:40 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 12.84 | nll_loss 11.991 | ppl 4069.99 | wps 42554.5 | wpb 510.9 | bsz 1 | num_updates 18594 | best_loss 8.481
2022-03-07 04:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 18594 updates
2022-03-07 04:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 193 @ 18594 updates, score 12.84) (writing took 2.245189320296049 seconds)
2022-03-07 04:11:42 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-07 04:11:42 | INFO | train | epoch 193 | loss 2.884 | nll_loss 1.046 | ppl 2.06 | wps 21995.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18594 | lr 0.000231907 | gnorm 0.888 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 55214
2022-03-07 04:11:42 | INFO | fairseq.trainer | begin training epoch 194
2022-03-07 04:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:11:59 | INFO | train_inner | epoch 194:      6 / 97 loss=2.883, nll_loss=1.044, ppl=2.06, wps=22028.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18600, lr=0.000231869, gnorm=0.887, loss_scale=16, train_wall=266, gb_free=8.1, wall=55231
2022-03-07 04:16:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:16:25 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 12.823 | nll_loss 11.984 | ppl 4049.63 | wps 42597.5 | wpb 510.9 | bsz 1 | num_updates 18690 | best_loss 8.481
2022-03-07 04:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 18690 updates
2022-03-07 04:16:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:16:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:16:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 194 @ 18690 updates, score 12.823) (writing took 2.3658067188225687 seconds)
2022-03-07 04:16:28 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-07 04:16:28 | INFO | train | epoch 194 | loss 2.881 | nll_loss 1.042 | ppl 2.06 | wps 21991.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18690 | lr 0.000231311 | gnorm 0.888 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 55500
2022-03-07 04:16:28 | INFO | fairseq.trainer | begin training epoch 195
2022-03-07 04:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:16:57 | INFO | train_inner | epoch 195:     10 / 97 loss=2.88, nll_loss=1.04, ppl=2.06, wps=22024.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18700, lr=0.000231249, gnorm=0.884, loss_scale=16, train_wall=266, gb_free=8.1, wall=55528
2022-03-07 04:21:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:21:11 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 12.784 | nll_loss 11.936 | ppl 3918.66 | wps 42533.3 | wpb 510.9 | bsz 1 | num_updates 18787 | best_loss 8.481
2022-03-07 04:21:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 18787 updates
2022-03-07 04:21:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:21:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:21:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 195 @ 18787 updates, score 12.784) (writing took 2.233467078767717 seconds)
2022-03-07 04:21:14 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-07 04:21:14 | INFO | train | epoch 195 | loss 2.879 | nll_loss 1.04 | ppl 2.06 | wps 22234 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18787 | lr 0.000230713 | gnorm 0.896 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 55785
2022-03-07 04:21:14 | INFO | fairseq.trainer | begin training epoch 196
2022-03-07 04:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:21:51 | INFO | train_inner | epoch 196:     13 / 97 loss=2.877, nll_loss=1.038, ppl=2.05, wps=22252.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18800, lr=0.000230633, gnorm=0.898, loss_scale=16, train_wall=264, gb_free=8.1, wall=55823
2022-03-07 04:22:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:25:57 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 12.758 | nll_loss 11.907 | ppl 3840.52 | wps 42622.2 | wpb 510.9 | bsz 1 | num_updates 18883 | best_loss 8.481
2022-03-07 04:25:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 18883 updates
2022-03-07 04:25:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:25:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:25:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 196 @ 18883 updates, score 12.758) (writing took 2.259898565709591 seconds)
2022-03-07 04:25:59 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-07 04:25:59 | INFO | train | epoch 196 | loss 2.874 | nll_loss 1.035 | ppl 2.05 | wps 22010 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18883 | lr 0.000230125 | gnorm 0.899 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 56071
2022-03-07 04:25:59 | INFO | fairseq.trainer | begin training epoch 197
2022-03-07 04:25:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:26:48 | INFO | train_inner | epoch 197:     17 / 97 loss=2.871, nll_loss=1.032, ppl=2.04, wps=22032.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18900, lr=0.000230022, gnorm=0.897, loss_scale=16, train_wall=266, gb_free=8.1, wall=56120
2022-03-07 04:29:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:30:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:30:43 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 12.73 | nll_loss 11.877 | ppl 3762.41 | wps 43031.1 | wpb 510.9 | bsz 1 | num_updates 18979 | best_loss 8.481
2022-03-07 04:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 18979 updates
2022-03-07 04:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:30:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:30:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 197 @ 18979 updates, score 12.73) (writing took 2.2306421450339258 seconds)
2022-03-07 04:30:45 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-07 04:30:45 | INFO | train | epoch 197 | loss 2.87 | nll_loss 1.03 | ppl 2.04 | wps 22009.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18979 | lr 0.000229543 | gnorm 0.894 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 56357
2022-03-07 04:30:45 | INFO | fairseq.trainer | begin training epoch 198
2022-03-07 04:30:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:31:45 | INFO | train_inner | epoch 198:     21 / 97 loss=2.87, nll_loss=1.03, ppl=2.04, wps=22040.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19000, lr=0.000229416, gnorm=0.898, loss_scale=16, train_wall=266, gb_free=8.1, wall=56417
2022-03-07 04:35:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:35:29 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 12.882 | nll_loss 12.048 | ppl 4234.06 | wps 41984.1 | wpb 510.9 | bsz 1 | num_updates 19076 | best_loss 8.481
2022-03-07 04:35:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 19076 updates
2022-03-07 04:35:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:35:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:35:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 198 @ 19076 updates, score 12.882) (writing took 2.218137952964753 seconds)
2022-03-07 04:35:31 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-07 04:35:31 | INFO | train | epoch 198 | loss 2.869 | nll_loss 1.029 | ppl 2.04 | wps 22209 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19076 | lr 0.000228958 | gnorm 0.893 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 56643
2022-03-07 04:35:31 | INFO | fairseq.trainer | begin training epoch 199
2022-03-07 04:35:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:36:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:36:43 | INFO | train_inner | epoch 199:     25 / 97 loss=2.867, nll_loss=1.027, ppl=2.04, wps=22022.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=19100, lr=0.000228814, gnorm=0.887, loss_scale=16, train_wall=266, gb_free=8.1, wall=56715
2022-03-07 04:40:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:40:14 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 12.821 | nll_loss 11.978 | ppl 4035.39 | wps 42657.8 | wpb 510.9 | bsz 1 | num_updates 19172 | best_loss 8.481
2022-03-07 04:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 19172 updates
2022-03-07 04:40:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:40:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 199 @ 19172 updates, score 12.821) (writing took 2.261953996028751 seconds)
2022-03-07 04:40:17 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-07 04:40:17 | INFO | train | epoch 199 | loss 2.864 | nll_loss 1.025 | ppl 2.03 | wps 22008.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19172 | lr 0.000228384 | gnorm 0.883 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 56928
2022-03-07 04:40:17 | INFO | fairseq.trainer | begin training epoch 200
2022-03-07 04:40:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:41:37 | INFO | train_inner | epoch 200:     28 / 97 loss=2.862, nll_loss=1.023, ppl=2.03, wps=22247.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19200, lr=0.000228218, gnorm=0.887, loss_scale=16, train_wall=264, gb_free=8.1, wall=57009
2022-03-07 04:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:45:00 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 12.816 | nll_loss 11.979 | ppl 4037.21 | wps 42617.9 | wpb 510.9 | bsz 1 | num_updates 19269 | best_loss 8.481
2022-03-07 04:45:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 19269 updates
2022-03-07 04:45:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:45:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:45:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 200 @ 19269 updates, score 12.816) (writing took 2.378564632963389 seconds)
2022-03-07 04:45:02 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-07 04:45:02 | INFO | train | epoch 200 | loss 2.862 | nll_loss 1.022 | ppl 2.03 | wps 22222.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19269 | lr 0.000227809 | gnorm 0.893 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 57214
2022-03-07 04:45:02 | INFO | fairseq.trainer | begin training epoch 201
2022-03-07 04:45:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:46:31 | INFO | train_inner | epoch 201:     31 / 97 loss=2.861, nll_loss=1.021, ppl=2.03, wps=22242.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=19300, lr=0.000227626, gnorm=0.884, loss_scale=32, train_wall=264, gb_free=8.1, wall=57303
2022-03-07 04:47:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:49:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:49:46 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 12.869 | nll_loss 12.032 | ppl 4188.15 | wps 42541.4 | wpb 510.9 | bsz 1 | num_updates 19365 | best_loss 8.481
2022-03-07 04:49:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 19365 updates
2022-03-07 04:49:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:49:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 201 @ 19365 updates, score 12.869) (writing took 2.2814792059361935 seconds)
2022-03-07 04:49:48 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-07 04:49:48 | INFO | train | epoch 201 | loss 2.858 | nll_loss 1.018 | ppl 2.03 | wps 22001.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19365 | lr 0.000227243 | gnorm 0.884 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 57500
2022-03-07 04:49:48 | INFO | fairseq.trainer | begin training epoch 202
2022-03-07 04:49:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:51:29 | INFO | train_inner | epoch 202:     35 / 97 loss=2.857, nll_loss=1.016, ppl=2.02, wps=22042.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19400, lr=0.000227038, gnorm=0.891, loss_scale=16, train_wall=266, gb_free=8.1, wall=57601
2022-03-07 04:53:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:54:32 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 12.84 | nll_loss 12.003 | ppl 4104.15 | wps 42860.9 | wpb 510.9 | bsz 1 | num_updates 19461 | best_loss 8.481
2022-03-07 04:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 19461 updates
2022-03-07 04:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 202 @ 19461 updates, score 12.84) (writing took 2.2354401759803295 seconds)
2022-03-07 04:54:34 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-07 04:54:34 | INFO | train | epoch 202 | loss 2.855 | nll_loss 1.015 | ppl 2.02 | wps 22011.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19461 | lr 0.000226682 | gnorm 0.884 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 57786
2022-03-07 04:54:34 | INFO | fairseq.trainer | begin training epoch 203
2022-03-07 04:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:56:26 | INFO | train_inner | epoch 203:     39 / 97 loss=2.853, nll_loss=1.012, ppl=2.02, wps=22041.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19500, lr=0.000226455, gnorm=0.886, loss_scale=16, train_wall=266, gb_free=8.1, wall=57898
2022-03-07 04:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:59:17 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 12.728 | nll_loss 11.882 | ppl 3773.13 | wps 42644.6 | wpb 510.9 | bsz 1 | num_updates 19558 | best_loss 8.481
2022-03-07 04:59:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 19558 updates
2022-03-07 04:59:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:59:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:59:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 203 @ 19558 updates, score 12.728) (writing took 2.2404757970944047 seconds)
2022-03-07 04:59:19 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-07 04:59:19 | INFO | train | epoch 203 | loss 2.852 | nll_loss 1.012 | ppl 2.02 | wps 22243.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19558 | lr 0.000226119 | gnorm 0.89 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 58071
2022-03-07 04:59:19 | INFO | fairseq.trainer | begin training epoch 204
2022-03-07 04:59:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:01:20 | INFO | train_inner | epoch 204:     42 / 97 loss=2.852, nll_loss=1.011, ppl=2.02, wps=22251.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19600, lr=0.000225877, gnorm=0.881, loss_scale=32, train_wall=264, gb_free=8.1, wall=58192
2022-03-07 05:03:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:04:03 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 12.815 | nll_loss 11.972 | ppl 4017.79 | wps 42870.3 | wpb 510.9 | bsz 1 | num_updates 19654 | best_loss 8.481
2022-03-07 05:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 19654 updates
2022-03-07 05:04:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:04:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 204 @ 19654 updates, score 12.815) (writing took 2.2345065511763096 seconds)
2022-03-07 05:04:05 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-07 05:04:05 | INFO | train | epoch 204 | loss 2.848 | nll_loss 1.008 | ppl 2.01 | wps 22007.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19654 | lr 0.000225566 | gnorm 0.875 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 58357
2022-03-07 05:04:05 | INFO | fairseq.trainer | begin training epoch 205
2022-03-07 05:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:06:17 | INFO | train_inner | epoch 205:     46 / 97 loss=2.845, nll_loss=1.005, ppl=2.01, wps=22039.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19700, lr=0.000225303, gnorm=0.878, loss_scale=16, train_wall=266, gb_free=8.1, wall=58489
2022-03-07 05:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:08:49 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 12.86 | nll_loss 12.02 | ppl 4152.82 | wps 42701.6 | wpb 510.9 | bsz 1 | num_updates 19751 | best_loss 8.481
2022-03-07 05:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 19751 updates
2022-03-07 05:08:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:08:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:08:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 205 @ 19751 updates, score 12.86) (writing took 2.2777798981405795 seconds)
2022-03-07 05:08:51 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-07 05:08:51 | INFO | train | epoch 205 | loss 2.846 | nll_loss 1.005 | ppl 2.01 | wps 22210.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19751 | lr 0.000225012 | gnorm 0.883 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 58643
2022-03-07 05:08:51 | INFO | fairseq.trainer | begin training epoch 206
2022-03-07 05:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:11:12 | INFO | train_inner | epoch 206:     49 / 97 loss=2.845, nll_loss=1.004, ppl=2.01, wps=22231.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=19800, lr=0.000224733, gnorm=0.883, loss_scale=32, train_wall=264, gb_free=8.1, wall=58784
2022-03-07 05:11:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:13:35 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 12.83 | nll_loss 11.987 | ppl 4058.32 | wps 42409.6 | wpb 510.9 | bsz 1 | num_updates 19847 | best_loss 8.481
2022-03-07 05:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 19847 updates
2022-03-07 05:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:13:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:13:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 206 @ 19847 updates, score 12.83) (writing took 2.248771457001567 seconds)
2022-03-07 05:13:37 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-07 05:13:37 | INFO | train | epoch 206 | loss 2.842 | nll_loss 1.001 | ppl 2 | wps 21986.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19847 | lr 0.000224467 | gnorm 0.883 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 58929
2022-03-07 05:13:37 | INFO | fairseq.trainer | begin training epoch 207
2022-03-07 05:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:16:09 | INFO | train_inner | epoch 207:     53 / 97 loss=2.841, nll_loss=1, ppl=2, wps=22017.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19900, lr=0.000224168, gnorm=0.881, loss_scale=16, train_wall=267, gb_free=8.1, wall=59081
2022-03-07 05:17:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:18:21 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 12.799 | nll_loss 11.961 | ppl 3987.31 | wps 42616.3 | wpb 510.9 | bsz 1 | num_updates 19943 | best_loss 8.481
2022-03-07 05:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 19943 updates
2022-03-07 05:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 207 @ 19943 updates, score 12.799) (writing took 2.3127244762144983 seconds)
2022-03-07 05:18:23 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-07 05:18:23 | INFO | train | epoch 207 | loss 2.839 | nll_loss 0.998 | ppl 2 | wps 21995 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19943 | lr 0.000223926 | gnorm 0.884 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 59215
2022-03-07 05:18:23 | INFO | fairseq.trainer | begin training epoch 208
2022-03-07 05:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:21:07 | INFO | train_inner | epoch 208:     57 / 97 loss=2.839, nll_loss=0.998, ppl=2, wps=22033.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20000, lr=0.000223607, gnorm=0.877, loss_scale=16, train_wall=266, gb_free=8.1, wall=59378
2022-03-07 05:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:23:06 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 12.905 | nll_loss 12.074 | ppl 4311.4 | wps 42631.7 | wpb 510.9 | bsz 1 | num_updates 20040 | best_loss 8.481
2022-03-07 05:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 20040 updates
2022-03-07 05:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:23:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:23:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 208 @ 20040 updates, score 12.905) (writing took 2.2409080709330738 seconds)
2022-03-07 05:23:09 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-07 05:23:09 | INFO | train | epoch 208 | loss 2.837 | nll_loss 0.997 | ppl 2 | wps 22239.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20040 | lr 0.000223384 | gnorm 0.873 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 59500
2022-03-07 05:23:09 | INFO | fairseq.trainer | begin training epoch 209
2022-03-07 05:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:24:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:26:04 | INFO | train_inner | epoch 209:     61 / 97 loss=2.838, nll_loss=0.997, ppl=2, wps=22053, ups=0.34, wpb=65495, bsz=127.9, num_updates=20100, lr=0.00022305, gnorm=0.887, loss_scale=16, train_wall=266, gb_free=8.1, wall=59675
2022-03-07 05:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:27:52 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 12.867 | nll_loss 12.032 | ppl 4188.78 | wps 42598.3 | wpb 510.9 | bsz 1 | num_updates 20136 | best_loss 8.481
2022-03-07 05:27:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 20136 updates
2022-03-07 05:27:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:27:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:27:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 209 @ 20136 updates, score 12.867) (writing took 2.2580283279530704 seconds)
2022-03-07 05:27:54 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-07 05:27:54 | INFO | train | epoch 209 | loss 2.834 | nll_loss 0.993 | ppl 1.99 | wps 22017.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20136 | lr 0.00022285 | gnorm 0.885 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 59786
2022-03-07 05:27:54 | INFO | fairseq.trainer | begin training epoch 210
2022-03-07 05:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:30:58 | INFO | train_inner | epoch 210:     64 / 97 loss=2.829, nll_loss=0.988, ppl=1.98, wps=22267.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=20200, lr=0.000222497, gnorm=0.871, loss_scale=32, train_wall=264, gb_free=8.1, wall=59970
2022-03-07 05:31:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:32:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:32:37 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 12.837 | nll_loss 11.996 | ppl 4085.38 | wps 42713.7 | wpb 510.9 | bsz 1 | num_updates 20232 | best_loss 8.481
2022-03-07 05:32:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 20232 updates
2022-03-07 05:32:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:32:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 210 @ 20232 updates, score 12.837) (writing took 2.257101994007826 seconds)
2022-03-07 05:32:40 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-07 05:32:40 | INFO | train | epoch 210 | loss 2.829 | nll_loss 0.988 | ppl 1.98 | wps 22028.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20232 | lr 0.000222321 | gnorm 0.873 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 60071
2022-03-07 05:32:40 | INFO | fairseq.trainer | begin training epoch 211
2022-03-07 05:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:35:55 | INFO | train_inner | epoch 211:     68 / 97 loss=2.829, nll_loss=0.988, ppl=1.98, wps=22050, ups=0.34, wpb=65495, bsz=127.9, num_updates=20300, lr=0.000221948, gnorm=0.89, loss_scale=16, train_wall=266, gb_free=8.1, wall=60267
2022-03-07 05:37:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:37:23 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 12.817 | nll_loss 11.975 | ppl 4026.26 | wps 42612.5 | wpb 510.9 | bsz 1 | num_updates 20329 | best_loss 8.481
2022-03-07 05:37:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 20329 updates
2022-03-07 05:37:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:37:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:37:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 211 @ 20329 updates, score 12.817) (writing took 2.2373106167651713 seconds)
2022-03-07 05:37:25 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-07 05:37:25 | INFO | train | epoch 211 | loss 2.828 | nll_loss 0.987 | ppl 1.98 | wps 22242.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20329 | lr 0.00022179 | gnorm 0.887 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 60357
2022-03-07 05:37:25 | INFO | fairseq.trainer | begin training epoch 212
2022-03-07 05:37:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:37:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:40:52 | INFO | train_inner | epoch 212:     72 / 97 loss=2.826, nll_loss=0.985, ppl=1.98, wps=22026.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20400, lr=0.000221404, gnorm=0.879, loss_scale=16, train_wall=267, gb_free=8.1, wall=60564
2022-03-07 05:42:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:42:09 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 12.858 | nll_loss 12.026 | ppl 4171.03 | wps 42699 | wpb 510.9 | bsz 1 | num_updates 20425 | best_loss 8.481
2022-03-07 05:42:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 20425 updates
2022-03-07 05:42:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:42:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:42:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 212 @ 20425 updates, score 12.858) (writing took 2.1993183502927423 seconds)
2022-03-07 05:42:11 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-07 05:42:11 | INFO | train | epoch 212 | loss 2.824 | nll_loss 0.983 | ppl 1.98 | wps 21996.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20425 | lr 0.000221268 | gnorm 0.879 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 60643
2022-03-07 05:42:11 | INFO | fairseq.trainer | begin training epoch 213
2022-03-07 05:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:45:47 | INFO | train_inner | epoch 213:     75 / 97 loss=2.823, nll_loss=0.981, ppl=1.97, wps=22235.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=20500, lr=0.000220863, gnorm=0.87, loss_scale=32, train_wall=264, gb_free=8.1, wall=60858
2022-03-07 05:46:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:46:55 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 12.834 | nll_loss 11.998 | ppl 4090.37 | wps 42649.5 | wpb 510.9 | bsz 1 | num_updates 20522 | best_loss 8.481
2022-03-07 05:46:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 20522 updates
2022-03-07 05:46:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:46:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 213 @ 20522 updates, score 12.834) (writing took 2.2685594698414207 seconds)
2022-03-07 05:46:57 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-07 05:46:57 | INFO | train | epoch 213 | loss 2.822 | nll_loss 0.98 | ppl 1.97 | wps 22216.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20522 | lr 0.000220745 | gnorm 0.864 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 60929
2022-03-07 05:46:57 | INFO | fairseq.trainer | begin training epoch 214
2022-03-07 05:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:48:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:50:44 | INFO | train_inner | epoch 214:     79 / 97 loss=2.822, nll_loss=0.98, ppl=1.97, wps=22047.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20600, lr=0.000220326, gnorm=0.88, loss_scale=16, train_wall=266, gb_free=8.1, wall=61156
2022-03-07 05:51:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:51:40 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 12.805 | nll_loss 11.963 | ppl 3993.15 | wps 42858.8 | wpb 510.9 | bsz 1 | num_updates 20618 | best_loss 8.481
2022-03-07 05:51:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 20618 updates
2022-03-07 05:51:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:51:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:51:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 214 @ 20618 updates, score 12.805) (writing took 2.353118938859552 seconds)
2022-03-07 05:51:43 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-07 05:51:43 | INFO | train | epoch 214 | loss 2.82 | nll_loss 0.979 | ppl 1.97 | wps 22007 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20618 | lr 0.00022023 | gnorm 0.883 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 61215
2022-03-07 05:51:43 | INFO | fairseq.trainer | begin training epoch 215
2022-03-07 05:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:54:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:55:41 | INFO | train_inner | epoch 215:     83 / 97 loss=2.82, nll_loss=0.978, ppl=1.97, wps=22035.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=20700, lr=0.000219793, gnorm=0.893, loss_scale=16, train_wall=266, gb_free=8.1, wall=61453
2022-03-07 05:56:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:56:26 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 12.815 | nll_loss 11.976 | ppl 4027.74 | wps 42417 | wpb 510.9 | bsz 1 | num_updates 20714 | best_loss 8.481
2022-03-07 05:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 20714 updates
2022-03-07 05:56:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:56:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:56:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 215 @ 20714 updates, score 12.815) (writing took 2.257356070447713 seconds)
2022-03-07 05:56:28 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-07 05:56:28 | INFO | train | epoch 215 | loss 2.818 | nll_loss 0.976 | ppl 1.97 | wps 22010 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 20714 | lr 0.000219719 | gnorm 0.891 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 61500
2022-03-07 05:56:28 | INFO | fairseq.trainer | begin training epoch 216
2022-03-07 05:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:00:35 | INFO | train_inner | epoch 216:     86 / 97 loss=2.814, nll_loss=0.972, ppl=1.96, wps=22254.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20800, lr=0.000219265, gnorm=0.871, loss_scale=16, train_wall=264, gb_free=8.1, wall=61747
2022-03-07 06:00:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:01:12 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 12.788 | nll_loss 11.948 | ppl 3950.29 | wps 42471.6 | wpb 510.9 | bsz 1 | num_updates 20810 | best_loss 8.481
2022-03-07 06:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 20810 updates
2022-03-07 06:01:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:01:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 216 @ 20810 updates, score 12.788) (writing took 2.2725650211796165 seconds)
2022-03-07 06:01:14 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-07 06:01:14 | INFO | train | epoch 216 | loss 2.814 | nll_loss 0.972 | ppl 1.96 | wps 22007.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20810 | lr 0.000219212 | gnorm 0.871 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 61786
2022-03-07 06:01:14 | INFO | fairseq.trainer | begin training epoch 217
2022-03-07 06:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:05:33 | INFO | train_inner | epoch 217:     90 / 97 loss=2.814, nll_loss=0.972, ppl=1.96, wps=22014.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20900, lr=0.000218739, gnorm=0.875, loss_scale=16, train_wall=266, gb_free=8.1, wall=62045
2022-03-07 06:05:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:05:58 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 12.89 | nll_loss 12.056 | ppl 4257.47 | wps 42542.4 | wpb 510.9 | bsz 1 | num_updates 20907 | best_loss 8.481
2022-03-07 06:05:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 20907 updates
2022-03-07 06:05:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:06:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:06:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 217 @ 20907 updates, score 12.89) (writing took 2.2540970449335873 seconds)
2022-03-07 06:06:00 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-07 06:06:00 | INFO | train | epoch 217 | loss 2.812 | nll_loss 0.971 | ppl 1.96 | wps 22210.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20907 | lr 0.000218703 | gnorm 0.874 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 62072
2022-03-07 06:06:00 | INFO | fairseq.trainer | begin training epoch 218
2022-03-07 06:06:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:07:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:10:30 | INFO | train_inner | epoch 218:     94 / 97 loss=2.811, nll_loss=0.969, ppl=1.96, wps=22031.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21000, lr=0.000218218, gnorm=0.873, loss_scale=16, train_wall=266, gb_free=8.1, wall=62342
2022-03-07 06:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:10:43 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 12.802 | nll_loss 11.966 | ppl 4000.19 | wps 42453.5 | wpb 510.9 | bsz 1 | num_updates 21003 | best_loss 8.481
2022-03-07 06:10:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 21003 updates
2022-03-07 06:10:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 218 @ 21003 updates, score 12.802) (writing took 2.3547487589530647 seconds)
2022-03-07 06:10:46 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-07 06:10:46 | INFO | train | epoch 218 | loss 2.809 | nll_loss 0.967 | ppl 1.95 | wps 21991.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21003 | lr 0.000218202 | gnorm 0.875 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 62358
2022-03-07 06:10:46 | INFO | fairseq.trainer | begin training epoch 219
2022-03-07 06:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:14:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:15:30 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 12.824 | nll_loss 11.989 | ppl 4063.55 | wps 42649.4 | wpb 510.9 | bsz 1 | num_updates 21099 | best_loss 8.481
2022-03-07 06:15:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 21099 updates
2022-03-07 06:15:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:15:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 219 @ 21099 updates, score 12.824) (writing took 2.2829150310717523 seconds)
2022-03-07 06:15:32 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-07 06:15:32 | INFO | train | epoch 219 | loss 2.807 | nll_loss 0.964 | ppl 1.95 | wps 21971.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21099 | lr 0.000217705 | gnorm 0.887 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 62644
2022-03-07 06:15:32 | INFO | fairseq.trainer | begin training epoch 220
2022-03-07 06:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:15:35 | INFO | train_inner | epoch 220:      1 / 97 loss=2.807, nll_loss=0.965, ppl=1.95, wps=21451.5, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=21100, lr=0.0002177, gnorm=0.888, loss_scale=16, train_wall=267, gb_free=8.1, wall=62647
2022-03-07 06:20:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:20:16 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 12.824 | nll_loss 11.988 | ppl 4061.43 | wps 42287.7 | wpb 510.9 | bsz 1 | num_updates 21196 | best_loss 8.481
2022-03-07 06:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 21196 updates
2022-03-07 06:20:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:20:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:20:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 220 @ 21196 updates, score 12.824) (writing took 2.2073016758076847 seconds)
2022-03-07 06:20:18 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-07 06:20:18 | INFO | train | epoch 220 | loss 2.804 | nll_loss 0.962 | ppl 1.95 | wps 22231.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21196 | lr 0.000217207 | gnorm 0.871 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 62930
2022-03-07 06:20:18 | INFO | fairseq.trainer | begin training epoch 221
2022-03-07 06:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:20:29 | INFO | train_inner | epoch 221:      4 / 97 loss=2.803, nll_loss=0.961, ppl=1.95, wps=22250, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21200, lr=0.000217186, gnorm=0.871, loss_scale=16, train_wall=264, gb_free=8.1, wall=62941
2022-03-07 06:21:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:24:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:25:01 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 12.84 | nll_loss 12.004 | ppl 4107.61 | wps 42476 | wpb 510.9 | bsz 1 | num_updates 21292 | best_loss 8.481
2022-03-07 06:25:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 21292 updates
2022-03-07 06:25:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:25:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:25:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 221 @ 21292 updates, score 12.84) (writing took 2.2624974669888616 seconds)
2022-03-07 06:25:03 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-07 06:25:03 | INFO | train | epoch 221 | loss 2.8 | nll_loss 0.958 | ppl 1.94 | wps 22005 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21292 | lr 0.000216716 | gnorm 0.865 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 63215
2022-03-07 06:25:03 | INFO | fairseq.trainer | begin training epoch 222
2022-03-07 06:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:25:27 | INFO | train_inner | epoch 222:      8 / 97 loss=2.799, nll_loss=0.956, ppl=1.94, wps=22037.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21300, lr=0.000216676, gnorm=0.865, loss_scale=16, train_wall=266, gb_free=8.1, wall=63238
2022-03-07 06:28:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:29:47 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 12.858 | nll_loss 12.025 | ppl 4168.7 | wps 42710.7 | wpb 510.9 | bsz 1 | num_updates 21388 | best_loss 8.481
2022-03-07 06:29:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 21388 updates
2022-03-07 06:29:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:29:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 222 @ 21388 updates, score 12.858) (writing took 2.256311138626188 seconds)
2022-03-07 06:29:49 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-07 06:29:49 | INFO | train | epoch 222 | loss 2.798 | nll_loss 0.955 | ppl 1.94 | wps 22015.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21388 | lr 0.000216229 | gnorm 0.877 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 63501
2022-03-07 06:29:49 | INFO | fairseq.trainer | begin training epoch 223
2022-03-07 06:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:30:24 | INFO | train_inner | epoch 223:     12 / 97 loss=2.796, nll_loss=0.953, ppl=1.94, wps=22047.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21400, lr=0.000216169, gnorm=0.872, loss_scale=16, train_wall=266, gb_free=8.1, wall=63536
2022-03-07 06:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:34:32 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 12.857 | nll_loss 12.028 | ppl 4177.52 | wps 42696.8 | wpb 510.9 | bsz 1 | num_updates 21485 | best_loss 8.481
2022-03-07 06:34:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 21485 updates
2022-03-07 06:34:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:34:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:34:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 223 @ 21485 updates, score 12.857) (writing took 2.2315084361471236 seconds)
2022-03-07 06:34:35 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-07 06:34:35 | INFO | train | epoch 223 | loss 2.797 | nll_loss 0.954 | ppl 1.94 | wps 22236.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21485 | lr 0.000215741 | gnorm 0.879 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 63787
2022-03-07 06:34:35 | INFO | fairseq.trainer | begin training epoch 224
2022-03-07 06:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:35:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:35:21 | INFO | train_inner | epoch 224:     16 / 97 loss=2.796, nll_loss=0.953, ppl=1.94, wps=22041.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21500, lr=0.000215666, gnorm=0.882, loss_scale=16, train_wall=266, gb_free=8.1, wall=63833
2022-03-07 06:39:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:39:18 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 12.827 | nll_loss 11.997 | ppl 4086.43 | wps 42620.7 | wpb 510.9 | bsz 1 | num_updates 21581 | best_loss 8.481
2022-03-07 06:39:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 21581 updates
2022-03-07 06:39:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 224 @ 21581 updates, score 12.827) (writing took 2.2568427016958594 seconds)
2022-03-07 06:39:20 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-07 06:39:20 | INFO | train | epoch 224 | loss 2.793 | nll_loss 0.951 | ppl 1.93 | wps 22012.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21581 | lr 0.00021526 | gnorm 0.864 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 64072
2022-03-07 06:39:20 | INFO | fairseq.trainer | begin training epoch 225
2022-03-07 06:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:40:15 | INFO | train_inner | epoch 225:     19 / 97 loss=2.79, nll_loss=0.947, ppl=1.93, wps=22256.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21600, lr=0.000215166, gnorm=0.859, loss_scale=16, train_wall=264, gb_free=8.1, wall=64127
2022-03-07 06:41:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:43:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:44:04 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 12.861 | nll_loss 12.029 | ppl 4179.93 | wps 42644.5 | wpb 510.9 | bsz 1 | num_updates 21677 | best_loss 8.481
2022-03-07 06:44:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 21677 updates
2022-03-07 06:44:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:44:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:44:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 225 @ 21677 updates, score 12.861) (writing took 2.285544004291296 seconds)
2022-03-07 06:44:06 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-07 06:44:06 | INFO | train | epoch 225 | loss 2.791 | nll_loss 0.949 | ppl 1.93 | wps 22000.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21677 | lr 0.000214783 | gnorm 0.878 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 64358
2022-03-07 06:44:06 | INFO | fairseq.trainer | begin training epoch 226
2022-03-07 06:44:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:45:12 | INFO | train_inner | epoch 226:     23 / 97 loss=2.791, nll_loss=0.948, ppl=1.93, wps=22028.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21700, lr=0.000214669, gnorm=0.877, loss_scale=16, train_wall=266, gb_free=8.1, wall=64424
2022-03-07 06:48:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:48:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:48:50 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 12.874 | nll_loss 12.046 | ppl 4229.07 | wps 42745.2 | wpb 510.9 | bsz 1 | num_updates 21773 | best_loss 8.481
2022-03-07 06:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 21773 updates
2022-03-07 06:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:48:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:48:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 226 @ 21773 updates, score 12.874) (writing took 2.423471658024937 seconds)
2022-03-07 06:48:52 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-07 06:48:52 | INFO | train | epoch 226 | loss 2.788 | nll_loss 0.945 | ppl 1.93 | wps 21991.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21773 | lr 0.000214309 | gnorm 0.864 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 64644
2022-03-07 06:48:52 | INFO | fairseq.trainer | begin training epoch 227
2022-03-07 06:48:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:50:10 | INFO | train_inner | epoch 227:     27 / 97 loss=2.787, nll_loss=0.944, ppl=1.92, wps=22029.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21800, lr=0.000214176, gnorm=0.868, loss_scale=16, train_wall=266, gb_free=8.1, wall=64722
2022-03-07 06:53:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:53:35 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 12.891 | nll_loss 12.062 | ppl 4276.81 | wps 42714.8 | wpb 510.9 | bsz 1 | num_updates 21870 | best_loss 8.481
2022-03-07 06:53:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 21870 updates
2022-03-07 06:53:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:53:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:53:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 227 @ 21870 updates, score 12.891) (writing took 2.1867318339645863 seconds)
2022-03-07 06:53:38 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-07 06:53:38 | INFO | train | epoch 227 | loss 2.785 | nll_loss 0.942 | ppl 1.92 | wps 22250.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21870 | lr 0.000213833 | gnorm 0.866 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 64929
2022-03-07 06:53:38 | INFO | fairseq.trainer | begin training epoch 228
2022-03-07 06:53:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:55:04 | INFO | train_inner | epoch 228:     30 / 97 loss=2.782, nll_loss=0.939, ppl=1.92, wps=22270.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21900, lr=0.000213687, gnorm=0.874, loss_scale=32, train_wall=264, gb_free=8.1, wall=65016
2022-03-07 06:55:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:58:21 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 12.919 | nll_loss 12.098 | ppl 4383.25 | wps 41893.4 | wpb 510.9 | bsz 1 | num_updates 21966 | best_loss 8.481
2022-03-07 06:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 21966 updates
2022-03-07 06:58:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:58:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:58:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 228 @ 21966 updates, score 12.919) (writing took 2.254661363083869 seconds)
2022-03-07 06:58:23 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-07 06:58:23 | INFO | train | epoch 228 | loss 2.783 | nll_loss 0.94 | ppl 1.92 | wps 22009.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21966 | lr 0.000213366 | gnorm 0.878 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 65215
2022-03-07 06:58:23 | INFO | fairseq.trainer | begin training epoch 229
2022-03-07 06:58:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:00:01 | INFO | train_inner | epoch 229:     34 / 97 loss=2.782, nll_loss=0.94, ppl=1.92, wps=22045.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22000, lr=0.000213201, gnorm=0.868, loss_scale=16, train_wall=266, gb_free=8.1, wall=65313
2022-03-07 07:02:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:03:07 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 12.866 | nll_loss 12.034 | ppl 4193.66 | wps 42433.2 | wpb 510.9 | bsz 1 | num_updates 22062 | best_loss 8.481
2022-03-07 07:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 22062 updates
2022-03-07 07:03:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:03:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:03:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 229 @ 22062 updates, score 12.866) (writing took 2.3643729221075773 seconds)
2022-03-07 07:03:09 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-07 07:03:09 | INFO | train | epoch 229 | loss 2.78 | nll_loss 0.937 | ppl 1.92 | wps 22005.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22062 | lr 0.000212901 | gnorm 0.856 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 65501
2022-03-07 07:03:09 | INFO | fairseq.trainer | begin training epoch 230
2022-03-07 07:03:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:04:58 | INFO | train_inner | epoch 230:     38 / 97 loss=2.778, nll_loss=0.936, ppl=1.91, wps=22035.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=22100, lr=0.000212718, gnorm=0.855, loss_scale=16, train_wall=266, gb_free=8.1, wall=65610
2022-03-07 07:07:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:07:52 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 12.859 | nll_loss 12.036 | ppl 4200.37 | wps 41899.9 | wpb 510.9 | bsz 1 | num_updates 22159 | best_loss 8.481
2022-03-07 07:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 22159 updates
2022-03-07 07:07:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:07:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 230 @ 22159 updates, score 12.859) (writing took 2.376554738264531 seconds)
2022-03-07 07:07:55 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-07 07:07:55 | INFO | train | epoch 230 | loss 2.778 | nll_loss 0.936 | ppl 1.91 | wps 22217.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22159 | lr 0.000212434 | gnorm 0.868 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 65787
2022-03-07 07:07:55 | INFO | fairseq.trainer | begin training epoch 231
2022-03-07 07:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:09:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:09:56 | INFO | train_inner | epoch 231:     42 / 97 loss=2.779, nll_loss=0.937, ppl=1.91, wps=22005.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22200, lr=0.000212238, gnorm=0.874, loss_scale=16, train_wall=267, gb_free=8.1, wall=65907
2022-03-07 07:12:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:12:39 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 12.866 | nll_loss 12.036 | ppl 4200.53 | wps 41459.6 | wpb 510.9 | bsz 1 | num_updates 22255 | best_loss 8.481
2022-03-07 07:12:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 22255 updates
2022-03-07 07:12:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:12:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:12:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 231 @ 22255 updates, score 12.866) (writing took 2.2926835771650076 seconds)
2022-03-07 07:12:41 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-07 07:12:41 | INFO | train | epoch 231 | loss 2.777 | nll_loss 0.934 | ppl 1.91 | wps 21978.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22255 | lr 0.000211976 | gnorm 0.876 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 66073
2022-03-07 07:12:41 | INFO | fairseq.trainer | begin training epoch 232
2022-03-07 07:12:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:14:50 | INFO | train_inner | epoch 232:     45 / 97 loss=2.773, nll_loss=0.93, ppl=1.9, wps=22239.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22300, lr=0.000211762, gnorm=0.861, loss_scale=16, train_wall=264, gb_free=8.1, wall=66202
2022-03-07 07:16:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:17:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:17:24 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 12.829 | nll_loss 11.994 | ppl 4077.65 | wps 41566 | wpb 510.9 | bsz 1 | num_updates 22351 | best_loss 8.481
2022-03-07 07:17:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 22351 updates
2022-03-07 07:17:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:17:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:17:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 232 @ 22351 updates, score 12.829) (writing took 2.325515449978411 seconds)
2022-03-07 07:17:27 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-07 07:17:27 | INFO | train | epoch 232 | loss 2.773 | nll_loss 0.93 | ppl 1.91 | wps 21993.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22351 | lr 0.00021152 | gnorm 0.858 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 66359
2022-03-07 07:17:27 | INFO | fairseq.trainer | begin training epoch 233
2022-03-07 07:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:19:48 | INFO | train_inner | epoch 233:     49 / 97 loss=2.774, nll_loss=0.932, ppl=1.91, wps=22018.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=22400, lr=0.000211289, gnorm=0.873, loss_scale=16, train_wall=266, gb_free=8.1, wall=66499
2022-03-07 07:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:22:10 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 12.843 | nll_loss 12.01 | ppl 4123.76 | wps 41888.8 | wpb 510.9 | bsz 1 | num_updates 22448 | best_loss 8.481
2022-03-07 07:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 22448 updates
2022-03-07 07:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:22:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 233 @ 22448 updates, score 12.843) (writing took 2.225120426621288 seconds)
2022-03-07 07:22:13 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-07 07:22:13 | INFO | train | epoch 233 | loss 2.772 | nll_loss 0.93 | ppl 1.9 | wps 22228.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22448 | lr 0.000211063 | gnorm 0.864 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 66644
2022-03-07 07:22:13 | INFO | fairseq.trainer | begin training epoch 234
2022-03-07 07:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:23:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:24:45 | INFO | train_inner | epoch 234:     53 / 97 loss=2.77, nll_loss=0.927, ppl=1.9, wps=22037.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22500, lr=0.000210819, gnorm=0.862, loss_scale=16, train_wall=266, gb_free=8.1, wall=66797
2022-03-07 07:26:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:26:56 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 12.93 | nll_loss 12.114 | ppl 4433.51 | wps 42116 | wpb 510.9 | bsz 1 | num_updates 22544 | best_loss 8.481
2022-03-07 07:26:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 22544 updates
2022-03-07 07:26:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:26:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:26:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 234 @ 22544 updates, score 12.93) (writing took 2.317089464981109 seconds)
2022-03-07 07:26:58 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-07 07:26:58 | INFO | train | epoch 234 | loss 2.769 | nll_loss 0.926 | ppl 1.9 | wps 21991.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22544 | lr 0.000210613 | gnorm 0.871 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 66930
2022-03-07 07:26:58 | INFO | fairseq.trainer | begin training epoch 235
2022-03-07 07:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:29:39 | INFO | train_inner | epoch 235:     56 / 97 loss=2.768, nll_loss=0.925, ppl=1.9, wps=22238.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=22600, lr=0.000210352, gnorm=0.862, loss_scale=32, train_wall=264, gb_free=8.1, wall=67091
2022-03-07 07:30:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:31:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:31:42 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 12.901 | nll_loss 12.078 | ppl 4322.28 | wps 42702.1 | wpb 510.9 | bsz 1 | num_updates 22640 | best_loss 8.481
2022-03-07 07:31:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 22640 updates
2022-03-07 07:31:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:31:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:31:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 235 @ 22640 updates, score 12.901) (writing took 2.207833741325885 seconds)
2022-03-07 07:31:44 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-07 07:31:44 | INFO | train | epoch 235 | loss 2.767 | nll_loss 0.924 | ppl 1.9 | wps 22009.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22640 | lr 0.000210166 | gnorm 0.859 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 67216
2022-03-07 07:31:44 | INFO | fairseq.trainer | begin training epoch 236
2022-03-07 07:31:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:34:36 | INFO | train_inner | epoch 236:     60 / 97 loss=2.766, nll_loss=0.923, ppl=1.9, wps=22031.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22700, lr=0.000209888, gnorm=0.871, loss_scale=16, train_wall=266, gb_free=8.1, wall=67388
2022-03-07 07:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:36:28 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 12.899 | nll_loss 12.075 | ppl 4314.9 | wps 42749.7 | wpb 510.9 | bsz 1 | num_updates 22737 | best_loss 8.481
2022-03-07 07:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 22737 updates
2022-03-07 07:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:36:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:36:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 236 @ 22737 updates, score 12.899) (writing took 2.282717448659241 seconds)
2022-03-07 07:36:30 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-07 07:36:30 | INFO | train | epoch 236 | loss 2.766 | nll_loss 0.923 | ppl 1.9 | wps 22215.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22737 | lr 0.000209717 | gnorm 0.869 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 67502
2022-03-07 07:36:30 | INFO | fairseq.trainer | begin training epoch 237
2022-03-07 07:36:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:39:31 | INFO | train_inner | epoch 237:     63 / 97 loss=2.765, nll_loss=0.922, ppl=1.89, wps=22246.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=22800, lr=0.000209427, gnorm=0.847, loss_scale=32, train_wall=264, gb_free=8.1, wall=67683
2022-03-07 07:41:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:41:13 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 12.862 | nll_loss 12.035 | ppl 4196.53 | wps 42329.4 | wpb 510.9 | bsz 1 | num_updates 22833 | best_loss 8.481
2022-03-07 07:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 22833 updates
2022-03-07 07:41:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:41:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:41:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 237 @ 22833 updates, score 12.862) (writing took 2.22560824919492 seconds)
2022-03-07 07:41:16 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-07 07:41:16 | INFO | train | epoch 237 | loss 2.761 | nll_loss 0.918 | ppl 1.89 | wps 22009.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22833 | lr 0.000209276 | gnorm 0.84 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 67788
2022-03-07 07:41:16 | INFO | fairseq.trainer | begin training epoch 238
2022-03-07 07:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:44:28 | INFO | train_inner | epoch 238:     67 / 97 loss=2.761, nll_loss=0.918, ppl=1.89, wps=22047.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22900, lr=0.000208969, gnorm=0.853, loss_scale=16, train_wall=266, gb_free=8.1, wall=67980
2022-03-07 07:45:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:45:59 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 12.895 | nll_loss 12.077 | ppl 4320.24 | wps 42479.4 | wpb 510.9 | bsz 1 | num_updates 22930 | best_loss 8.481
2022-03-07 07:45:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 22930 updates
2022-03-07 07:45:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:46:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:46:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 238 @ 22930 updates, score 12.895) (writing took 2.276129893027246 seconds)
2022-03-07 07:46:01 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-07 07:46:01 | INFO | train | epoch 238 | loss 2.761 | nll_loss 0.918 | ppl 1.89 | wps 22236.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22930 | lr 0.000208832 | gnorm 0.859 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 68073
2022-03-07 07:46:01 | INFO | fairseq.trainer | begin training epoch 239
2022-03-07 07:46:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:48:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:49:25 | INFO | train_inner | epoch 239:     71 / 97 loss=2.76, nll_loss=0.917, ppl=1.89, wps=22039.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=23000, lr=0.000208514, gnorm=0.855, loss_scale=16, train_wall=266, gb_free=8.1, wall=68277
2022-03-07 07:50:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:50:45 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 12.856 | nll_loss 12.036 | ppl 4198.75 | wps 42394.2 | wpb 510.9 | bsz 1 | num_updates 23026 | best_loss 8.481
2022-03-07 07:50:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 23026 updates
2022-03-07 07:50:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:50:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:50:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 239 @ 23026 updates, score 12.856) (writing took 2.259909128770232 seconds)
2022-03-07 07:50:47 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 07:50:47 | INFO | train | epoch 239 | loss 2.759 | nll_loss 0.916 | ppl 1.89 | wps 22014.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23026 | lr 0.000208397 | gnorm 0.851 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 68359
2022-03-07 07:50:47 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 07:50:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:54:19 | INFO | train_inner | epoch 240:     74 / 97 loss=2.756, nll_loss=0.913, ppl=1.88, wps=22258.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23100, lr=0.000208063, gnorm=0.849, loss_scale=16, train_wall=264, gb_free=8.1, wall=68571
2022-03-07 07:54:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:55:30 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 12.901 | nll_loss 12.088 | ppl 4354.79 | wps 42460.8 | wpb 510.9 | bsz 1 | num_updates 23122 | best_loss 8.481
2022-03-07 07:55:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 23122 updates
2022-03-07 07:55:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:55:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:55:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 240 @ 23122 updates, score 12.901) (writing took 2.168270348571241 seconds)
2022-03-07 07:55:32 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 07:55:32 | INFO | train | epoch 240 | loss 2.755 | nll_loss 0.912 | ppl 1.88 | wps 22023.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23122 | lr 0.000207964 | gnorm 0.852 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 68644
2022-03-07 07:55:32 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 07:55:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:59:16 | INFO | train_inner | epoch 241:     78 / 97 loss=2.755, nll_loss=0.912, ppl=1.88, wps=22048.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23200, lr=0.000207614, gnorm=0.86, loss_scale=16, train_wall=266, gb_free=8.1, wall=68868
2022-03-07 08:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:00:16 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 12.86 | nll_loss 12.033 | ppl 4190.03 | wps 42406.2 | wpb 510.9 | bsz 1 | num_updates 23219 | best_loss 8.481
2022-03-07 08:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 23219 updates
2022-03-07 08:00:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:00:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:00:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 241 @ 23219 updates, score 12.86) (writing took 2.2620143769308925 seconds)
2022-03-07 08:00:18 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 08:00:18 | INFO | train | epoch 241 | loss 2.754 | nll_loss 0.911 | ppl 1.88 | wps 22227 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23219 | lr 0.000207529 | gnorm 0.86 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 68930
2022-03-07 08:00:18 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 08:00:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:01:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:04:14 | INFO | train_inner | epoch 242:     82 / 97 loss=2.754, nll_loss=0.911, ppl=1.88, wps=22016.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23300, lr=0.000207168, gnorm=0.86, loss_scale=16, train_wall=267, gb_free=8.1, wall=69166
2022-03-07 08:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:05:02 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 12.953 | nll_loss 12.142 | ppl 4519.29 | wps 42571 | wpb 510.9 | bsz 1 | num_updates 23315 | best_loss 8.481
2022-03-07 08:05:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 23315 updates
2022-03-07 08:05:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:05:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:05:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 242 @ 23315 updates, score 12.953) (writing took 2.2220729188993573 seconds)
2022-03-07 08:05:04 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 08:05:04 | INFO | train | epoch 242 | loss 2.752 | nll_loss 0.909 | ppl 1.88 | wps 21989.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23315 | lr 0.000207101 | gnorm 0.86 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 69216
2022-03-07 08:05:04 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 08:05:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:09:08 | INFO | train_inner | epoch 243:     85 / 97 loss=2.75, nll_loss=0.907, ppl=1.88, wps=22228.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23400, lr=0.000206725, gnorm=0.857, loss_scale=32, train_wall=264, gb_free=8.1, wall=69460
2022-03-07 08:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:09:48 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 12.905 | nll_loss 12.085 | ppl 4345.51 | wps 42700.8 | wpb 510.9 | bsz 1 | num_updates 23412 | best_loss 8.481
2022-03-07 08:09:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 23412 updates
2022-03-07 08:09:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:09:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:09:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 243 @ 23412 updates, score 12.905) (writing took 2.383007898926735 seconds)
2022-03-07 08:09:50 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 08:09:50 | INFO | train | epoch 243 | loss 2.749 | nll_loss 0.906 | ppl 1.87 | wps 22195.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23412 | lr 0.000206672 | gnorm 0.856 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 69502
2022-03-07 08:09:50 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 08:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:10:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:14:06 | INFO | train_inner | epoch 244:     89 / 97 loss=2.748, nll_loss=0.904, ppl=1.87, wps=22029.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23500, lr=0.000206284, gnorm=0.853, loss_scale=16, train_wall=266, gb_free=8.1, wall=69758
2022-03-07 08:14:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:14:34 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 12.857 | nll_loss 12.03 | ppl 4181.9 | wps 42492.6 | wpb 510.9 | bsz 1 | num_updates 23508 | best_loss 8.481
2022-03-07 08:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 23508 updates
2022-03-07 08:14:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:14:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 244 @ 23508 updates, score 12.857) (writing took 2.2074790578335524 seconds)
2022-03-07 08:14:36 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 08:14:36 | INFO | train | epoch 244 | loss 2.747 | nll_loss 0.903 | ppl 1.87 | wps 22015.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23508 | lr 0.000206249 | gnorm 0.854 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 69788
2022-03-07 08:14:36 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 08:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:19:00 | INFO | train_inner | epoch 245:     92 / 97 loss=2.746, nll_loss=0.903, ppl=1.87, wps=22257.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23600, lr=0.000205847, gnorm=0.863, loss_scale=32, train_wall=264, gb_free=8.1, wall=70052
2022-03-07 08:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:19:19 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 12.858 | nll_loss 12.031 | ppl 4186.06 | wps 42829.3 | wpb 510.9 | bsz 1 | num_updates 23605 | best_loss 8.481
2022-03-07 08:19:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 23605 updates
2022-03-07 08:19:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:19:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:19:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 245 @ 23605 updates, score 12.858) (writing took 2.2474466459825635 seconds)
2022-03-07 08:19:22 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 08:19:22 | INFO | train | epoch 245 | loss 2.745 | nll_loss 0.902 | ppl 1.87 | wps 22239.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23605 | lr 0.000205825 | gnorm 0.859 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 70074
2022-03-07 08:19:22 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 08:19:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:20:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:23:57 | INFO | train_inner | epoch 246:     96 / 97 loss=2.743, nll_loss=0.9, ppl=1.87, wps=22037.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23700, lr=0.000205412, gnorm=0.852, loss_scale=16, train_wall=266, gb_free=8.1, wall=70349
2022-03-07 08:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:24:05 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 12.958 | nll_loss 12.149 | ppl 4540.78 | wps 42635.7 | wpb 510.9 | bsz 1 | num_updates 23701 | best_loss 8.481
2022-03-07 08:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 23701 updates
2022-03-07 08:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:24:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 246 @ 23701 updates, score 12.958) (writing took 2.2557753808796406 seconds)
2022-03-07 08:24:07 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 08:24:07 | INFO | train | epoch 246 | loss 2.742 | nll_loss 0.898 | ppl 1.86 | wps 22007.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23701 | lr 0.000205408 | gnorm 0.851 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 70359
2022-03-07 08:24:07 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 08:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:26:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:28:51 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 12.88 | nll_loss 12.058 | ppl 4264.67 | wps 42564.9 | wpb 510.9 | bsz 1 | num_updates 23797 | best_loss 8.481
2022-03-07 08:28:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 23797 updates
2022-03-07 08:28:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:28:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:28:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 247 @ 23797 updates, score 12.88) (writing took 2.2657054062001407 seconds)
2022-03-07 08:28:53 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 08:28:53 | INFO | train | epoch 247 | loss 2.74 | nll_loss 0.896 | ppl 1.86 | wps 22019.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23797 | lr 0.000204993 | gnorm 0.843 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 70645
2022-03-07 08:28:53 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 08:28:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:29:02 | INFO | train_inner | epoch 248:      3 / 97 loss=2.739, nll_loss=0.896, ppl=1.86, wps=21506.8, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=23800, lr=0.00020498, gnorm=0.843, loss_scale=16, train_wall=266, gb_free=8.1, wall=70653
2022-03-07 08:33:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:33:36 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 12.892 | nll_loss 12.074 | ppl 4310.99 | wps 42400.3 | wpb 510.9 | bsz 1 | num_updates 23893 | best_loss 8.481
2022-03-07 08:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 23893 updates
2022-03-07 08:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:33:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 248 @ 23893 updates, score 12.892) (writing took 2.234155156649649 seconds)
2022-03-07 08:33:39 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 08:33:39 | INFO | train | epoch 248 | loss 2.74 | nll_loss 0.896 | ppl 1.86 | wps 21999.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23893 | lr 0.000204581 | gnorm 0.86 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 70931
2022-03-07 08:33:39 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 08:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:33:59 | INFO | train_inner | epoch 249:      7 / 97 loss=2.738, nll_loss=0.895, ppl=1.86, wps=22031.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23900, lr=0.000204551, gnorm=0.859, loss_scale=16, train_wall=266, gb_free=8.1, wall=70951
2022-03-07 08:38:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:38:22 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 12.857 | nll_loss 12.028 | ppl 4176.59 | wps 42271.9 | wpb 510.9 | bsz 1 | num_updates 23990 | best_loss 8.481
2022-03-07 08:38:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 23990 updates
2022-03-07 08:38:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:38:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:38:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 249 @ 23990 updates, score 12.857) (writing took 2.319961007218808 seconds)
2022-03-07 08:38:24 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 08:38:24 | INFO | train | epoch 249 | loss 2.737 | nll_loss 0.894 | ppl 1.86 | wps 22223.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23990 | lr 0.000204167 | gnorm 0.858 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 71216
2022-03-07 08:38:24 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 08:38:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:38:53 | INFO | train_inner | epoch 250:     10 / 97 loss=2.737, nll_loss=0.894, ppl=1.86, wps=22238.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24000, lr=0.000204124, gnorm=0.857, loss_scale=16, train_wall=264, gb_free=8.1, wall=71245
2022-03-07 08:40:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:43:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:43:08 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 12.941 | nll_loss 12.128 | ppl 4475.78 | wps 42692.6 | wpb 510.9 | bsz 1 | num_updates 24086 | best_loss 8.481
2022-03-07 08:43:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 24086 updates
2022-03-07 08:43:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:43:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:43:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 250 @ 24086 updates, score 12.941) (writing took 2.262434057891369 seconds)
2022-03-07 08:43:10 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 08:43:10 | INFO | train | epoch 250 | loss 2.734 | nll_loss 0.891 | ppl 1.85 | wps 21981.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24086 | lr 0.000203759 | gnorm 0.849 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 71502
2022-03-07 08:43:10 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 08:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:43:51 | INFO | train_inner | epoch 251:     14 / 97 loss=2.733, nll_loss=0.889, ppl=1.85, wps=22014.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24100, lr=0.0002037, gnorm=0.851, loss_scale=16, train_wall=267, gb_free=8.1, wall=71543
2022-03-07 08:47:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:47:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:47:54 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 12.889 | nll_loss 12.07 | ppl 4299.93 | wps 42608 | wpb 510.9 | bsz 1 | num_updates 24182 | best_loss 8.481
2022-03-07 08:47:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 24182 updates
2022-03-07 08:47:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:47:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:47:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 251 @ 24182 updates, score 12.889) (writing took 2.2083633430302143 seconds)
2022-03-07 08:47:56 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 08:47:56 | INFO | train | epoch 251 | loss 2.732 | nll_loss 0.888 | ppl 1.85 | wps 22009.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24182 | lr 0.000203355 | gnorm 0.855 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 71788
2022-03-07 08:47:56 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 08:47:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:48:48 | INFO | train_inner | epoch 252:     18 / 97 loss=2.731, nll_loss=0.887, ppl=1.85, wps=22044.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24200, lr=0.000203279, gnorm=0.847, loss_scale=16, train_wall=266, gb_free=8.1, wall=71840
2022-03-07 08:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:52:40 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 12.872 | nll_loss 12.056 | ppl 4258.13 | wps 42138.4 | wpb 510.9 | bsz 1 | num_updates 24279 | best_loss 8.481
2022-03-07 08:52:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 24279 updates
2022-03-07 08:52:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:52:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:52:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 252 @ 24279 updates, score 12.872) (writing took 2.2717262879014015 seconds)
2022-03-07 08:52:42 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 08:52:42 | INFO | train | epoch 252 | loss 2.73 | nll_loss 0.886 | ppl 1.85 | wps 22237.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24279 | lr 0.000202948 | gnorm 0.848 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 72074
2022-03-07 08:52:42 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 08:52:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:53:42 | INFO | train_inner | epoch 253:     21 / 97 loss=2.729, nll_loss=0.885, ppl=1.85, wps=22257.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=24300, lr=0.00020286, gnorm=0.853, loss_scale=16, train_wall=264, gb_free=8.1, wall=72134
2022-03-07 08:54:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:57:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:57:25 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 12.89 | nll_loss 12.074 | ppl 4311.46 | wps 42282.9 | wpb 510.9 | bsz 1 | num_updates 24375 | best_loss 8.481
2022-03-07 08:57:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 24375 updates
2022-03-07 08:57:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:57:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:57:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 253 @ 24375 updates, score 12.89) (writing took 2.290249059908092 seconds)
2022-03-07 08:57:28 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 08:57:28 | INFO | train | epoch 253 | loss 2.73 | nll_loss 0.886 | ppl 1.85 | wps 22003 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24375 | lr 0.000202548 | gnorm 0.851 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 72359
2022-03-07 08:57:28 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 08:57:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:58:39 | INFO | train_inner | epoch 254:     25 / 97 loss=2.728, nll_loss=0.885, ppl=1.85, wps=22028.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24400, lr=0.000202444, gnorm=0.852, loss_scale=16, train_wall=266, gb_free=8.1, wall=72431
2022-03-07 09:02:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:02:11 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 12.898 | nll_loss 12.079 | ppl 4326.69 | wps 42512.1 | wpb 510.9 | bsz 1 | num_updates 24472 | best_loss 8.481
2022-03-07 09:02:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 24472 updates
2022-03-07 09:02:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:02:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:02:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 254 @ 24472 updates, score 12.898) (writing took 2.2396560767665505 seconds)
2022-03-07 09:02:14 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 09:02:14 | INFO | train | epoch 254 | loss 2.726 | nll_loss 0.883 | ppl 1.84 | wps 22213.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24472 | lr 0.000202146 | gnorm 0.847 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 72645
2022-03-07 09:02:14 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 09:02:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:02:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:03:37 | INFO | train_inner | epoch 255:     29 / 97 loss=2.725, nll_loss=0.882, ppl=1.84, wps=22018.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24500, lr=0.000202031, gnorm=0.841, loss_scale=16, train_wall=267, gb_free=8.1, wall=72729
2022-03-07 09:06:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:06:57 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 12.875 | nll_loss 12.061 | ppl 4273.22 | wps 42351.6 | wpb 510.9 | bsz 1 | num_updates 24568 | best_loss 8.481
2022-03-07 09:06:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 24568 updates
2022-03-07 09:06:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:06:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:06:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 255 @ 24568 updates, score 12.875) (writing took 2.177928989287466 seconds)
2022-03-07 09:06:59 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 09:06:59 | INFO | train | epoch 255 | loss 2.724 | nll_loss 0.88 | ppl 1.84 | wps 22006 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24568 | lr 0.000201751 | gnorm 0.854 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 72931
2022-03-07 09:06:59 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 09:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:08:31 | INFO | train_inner | epoch 256:     32 / 97 loss=2.724, nll_loss=0.88, ppl=1.84, wps=22255.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=24600, lr=0.000201619, gnorm=0.856, loss_scale=16, train_wall=264, gb_free=8.1, wall=73023
2022-03-07 09:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:11:43 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 12.948 | nll_loss 12.137 | ppl 4503.16 | wps 42810.3 | wpb 510.9 | bsz 1 | num_updates 24665 | best_loss 8.481
2022-03-07 09:11:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 24665 updates
2022-03-07 09:11:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:11:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:11:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 256 @ 24665 updates, score 12.948) (writing took 2.2191477566957474 seconds)
2022-03-07 09:11:45 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 09:11:45 | INFO | train | epoch 256 | loss 2.723 | nll_loss 0.88 | ppl 1.84 | wps 22240.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24665 | lr 0.000201354 | gnorm 0.853 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 73217
2022-03-07 09:11:45 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 09:11:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:11:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:13:28 | INFO | train_inner | epoch 257:     36 / 97 loss=2.723, nll_loss=0.879, ppl=1.84, wps=22058.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24700, lr=0.000201211, gnorm=0.851, loss_scale=16, train_wall=266, gb_free=8.1, wall=73320
2022-03-07 09:16:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:16:28 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 12.916 | nll_loss 12.099 | ppl 4388.07 | wps 42599.6 | wpb 510.9 | bsz 1 | num_updates 24761 | best_loss 8.481
2022-03-07 09:16:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 24761 updates
2022-03-07 09:16:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:16:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:16:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 257 @ 24761 updates, score 12.916) (writing took 2.2659423570148647 seconds)
2022-03-07 09:16:30 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 09:16:30 | INFO | train | epoch 257 | loss 2.721 | nll_loss 0.877 | ppl 1.84 | wps 22021.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24761 | lr 0.000200963 | gnorm 0.856 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 73502
2022-03-07 09:16:30 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 09:16:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:18:22 | INFO | train_inner | epoch 258:     39 / 97 loss=2.72, nll_loss=0.876, ppl=1.83, wps=22259.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=24800, lr=0.000200805, gnorm=0.85, loss_scale=32, train_wall=264, gb_free=8.1, wall=73614
2022-03-07 09:19:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:21:14 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 12.917 | nll_loss 12.107 | ppl 4410.64 | wps 42390.6 | wpb 510.9 | bsz 1 | num_updates 24857 | best_loss 8.481
2022-03-07 09:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 24857 updates
2022-03-07 09:21:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:21:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:21:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 258 @ 24857 updates, score 12.917) (writing took 2.2138317953795195 seconds)
2022-03-07 09:21:16 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 09:21:16 | INFO | train | epoch 258 | loss 2.717 | nll_loss 0.873 | ppl 1.83 | wps 22019 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24857 | lr 0.000200574 | gnorm 0.836 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 73788
2022-03-07 09:21:16 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 09:21:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:23:19 | INFO | train_inner | epoch 259:     43 / 97 loss=2.716, nll_loss=0.872, ppl=1.83, wps=22051, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24900, lr=0.000200401, gnorm=0.839, loss_scale=16, train_wall=266, gb_free=8.1, wall=73911
2022-03-07 09:25:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:25:59 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 12.876 | nll_loss 12.059 | ppl 4268.3 | wps 42479.8 | wpb 510.9 | bsz 1 | num_updates 24954 | best_loss 8.481
2022-03-07 09:25:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 24954 updates
2022-03-07 09:25:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:26:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:26:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 259 @ 24954 updates, score 12.876) (writing took 2.203419405966997 seconds)
2022-03-07 09:26:01 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 09:26:01 | INFO | train | epoch 259 | loss 2.717 | nll_loss 0.874 | ppl 1.83 | wps 22249.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24954 | lr 0.000200184 | gnorm 0.847 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 74073
2022-03-07 09:26:01 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 09:26:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:26:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:28:16 | INFO | train_inner | epoch 260:     47 / 97 loss=2.717, nll_loss=0.873, ppl=1.83, wps=22040.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25000, lr=0.0002, gnorm=0.855, loss_scale=16, train_wall=266, gb_free=8.1, wall=74208
2022-03-07 09:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:30:45 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 12.829 | nll_loss 12.013 | ppl 4132.99 | wps 42456 | wpb 510.9 | bsz 1 | num_updates 25050 | best_loss 8.481
2022-03-07 09:30:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 25050 updates
2022-03-07 09:30:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:30:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 260 @ 25050 updates, score 12.829) (writing took 2.249984207097441 seconds)
2022-03-07 09:30:47 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 09:30:47 | INFO | train | epoch 260 | loss 2.715 | nll_loss 0.871 | ppl 1.83 | wps 21997.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25050 | lr 0.0001998 | gnorm 0.858 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 74359
2022-03-07 09:30:47 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 09:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:33:11 | INFO | train_inner | epoch 261:     50 / 97 loss=2.714, nll_loss=0.871, ppl=1.83, wps=22245.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25100, lr=0.000199601, gnorm=0.858, loss_scale=32, train_wall=264, gb_free=8.1, wall=74503
2022-03-07 09:33:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:35:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:35:31 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 12.882 | nll_loss 12.073 | ppl 4309.63 | wps 42399.6 | wpb 510.9 | bsz 1 | num_updates 25146 | best_loss 8.481
2022-03-07 09:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 25146 updates
2022-03-07 09:35:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:35:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:35:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 261 @ 25146 updates, score 12.882) (writing took 2.3068877938203514 seconds)
2022-03-07 09:35:33 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 09:35:33 | INFO | train | epoch 261 | loss 2.713 | nll_loss 0.87 | ppl 1.83 | wps 21998.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25146 | lr 0.000199419 | gnorm 0.848 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 74645
2022-03-07 09:35:33 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 09:35:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:38:08 | INFO | train_inner | epoch 262:     54 / 97 loss=2.712, nll_loss=0.869, ppl=1.83, wps=22043.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25200, lr=0.000199205, gnorm=0.844, loss_scale=16, train_wall=266, gb_free=8.1, wall=74800
2022-03-07 09:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:40:16 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 12.915 | nll_loss 12.106 | ppl 4409.41 | wps 42699 | wpb 510.9 | bsz 1 | num_updates 25243 | best_loss 8.481
2022-03-07 09:40:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 25243 updates
2022-03-07 09:40:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:40:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:40:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 262 @ 25243 updates, score 12.915) (writing took 2.347240380011499 seconds)
2022-03-07 09:40:19 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 09:40:19 | INFO | train | epoch 262 | loss 2.711 | nll_loss 0.867 | ppl 1.82 | wps 22246.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25243 | lr 0.000199035 | gnorm 0.847 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 74931
2022-03-07 09:40:19 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 09:40:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:41:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:43:05 | INFO | train_inner | epoch 263:     58 / 97 loss=2.711, nll_loss=0.867, ppl=1.82, wps=22049.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=25300, lr=0.000198811, gnorm=0.851, loss_scale=16, train_wall=266, gb_free=8.1, wall=75097
2022-03-07 09:44:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:45:02 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 12.901 | nll_loss 12.087 | ppl 4349.49 | wps 42634 | wpb 510.9 | bsz 1 | num_updates 25339 | best_loss 8.481
2022-03-07 09:45:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 25339 updates
2022-03-07 09:45:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:45:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:45:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 263 @ 25339 updates, score 12.901) (writing took 2.229325466789305 seconds)
2022-03-07 09:45:04 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 09:45:04 | INFO | train | epoch 263 | loss 2.709 | nll_loss 0.865 | ppl 1.82 | wps 22023 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25339 | lr 0.000198658 | gnorm 0.846 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 75216
2022-03-07 09:45:04 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 09:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:47:59 | INFO | train_inner | epoch 264:     61 / 97 loss=2.708, nll_loss=0.864, ppl=1.82, wps=22278.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25400, lr=0.000198419, gnorm=0.842, loss_scale=32, train_wall=264, gb_free=8.1, wall=75391
2022-03-07 09:48:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:49:47 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 12.935 | nll_loss 12.125 | ppl 4466.85 | wps 42889.1 | wpb 510.9 | bsz 1 | num_updates 25435 | best_loss 8.481
2022-03-07 09:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 25435 updates
2022-03-07 09:49:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:49:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:49:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 264 @ 25435 updates, score 12.935) (writing took 2.220510906074196 seconds)
2022-03-07 09:49:49 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 09:49:49 | INFO | train | epoch 264 | loss 2.708 | nll_loss 0.864 | ppl 1.82 | wps 22040.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25435 | lr 0.000198282 | gnorm 0.844 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 75501
2022-03-07 09:49:49 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 09:49:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:52:56 | INFO | train_inner | epoch 265:     65 / 97 loss=2.706, nll_loss=0.862, ppl=1.82, wps=22069.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=25500, lr=0.00019803, gnorm=0.838, loss_scale=16, train_wall=266, gb_free=8.1, wall=75688
2022-03-07 09:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:54:33 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 12.912 | nll_loss 12.099 | ppl 4387.04 | wps 42592.9 | wpb 510.9 | bsz 1 | num_updates 25532 | best_loss 8.481
2022-03-07 09:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 25532 updates
2022-03-07 09:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 265 @ 25532 updates, score 12.912) (writing took 2.3075357880443335 seconds)
2022-03-07 09:54:35 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 09:54:35 | INFO | train | epoch 265 | loss 2.706 | nll_loss 0.862 | ppl 1.82 | wps 22251.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25532 | lr 0.000197905 | gnorm 0.841 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 75787
2022-03-07 09:54:35 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 09:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:55:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:57:53 | INFO | train_inner | epoch 266:     69 / 97 loss=2.707, nll_loss=0.863, ppl=1.82, wps=22040.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=25600, lr=0.000197642, gnorm=0.847, loss_scale=16, train_wall=266, gb_free=8.1, wall=75985
2022-03-07 09:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:59:18 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 12.866 | nll_loss 12.05 | ppl 4241.69 | wps 42624.1 | wpb 510.9 | bsz 1 | num_updates 25628 | best_loss 8.481
2022-03-07 09:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 25628 updates
2022-03-07 09:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:59:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 266 @ 25628 updates, score 12.866) (writing took 2.238146204035729 seconds)
2022-03-07 09:59:21 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 09:59:21 | INFO | train | epoch 266 | loss 2.705 | nll_loss 0.861 | ppl 1.82 | wps 22005.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25628 | lr 0.000197534 | gnorm 0.847 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 76072
2022-03-07 09:59:21 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 09:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:02:47 | INFO | train_inner | epoch 267:     72 / 97 loss=2.703, nll_loss=0.859, ppl=1.81, wps=22238.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=25700, lr=0.000197257, gnorm=0.843, loss_scale=32, train_wall=264, gb_free=8.1, wall=76279
2022-03-07 10:03:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:04:04 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 12.903 | nll_loss 12.094 | ppl 4371.85 | wps 42316.1 | wpb 510.9 | bsz 1 | num_updates 25724 | best_loss 8.481
2022-03-07 10:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 25724 updates
2022-03-07 10:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:04:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:04:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 267 @ 25724 updates, score 12.903) (writing took 2.2496675648726523 seconds)
2022-03-07 10:04:06 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 10:04:06 | INFO | train | epoch 267 | loss 2.702 | nll_loss 0.858 | ppl 1.81 | wps 21991.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25724 | lr 0.000197165 | gnorm 0.841 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 76358
2022-03-07 10:04:06 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 10:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:07:44 | INFO | train_inner | epoch 268:     76 / 97 loss=2.701, nll_loss=0.857, ppl=1.81, wps=22042.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25800, lr=0.000196875, gnorm=0.839, loss_scale=16, train_wall=266, gb_free=8.1, wall=76576
2022-03-07 10:08:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:08:50 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 12.946 | nll_loss 12.137 | ppl 4504 | wps 43010.5 | wpb 510.9 | bsz 1 | num_updates 25821 | best_loss 8.481
2022-03-07 10:08:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 25821 updates
2022-03-07 10:08:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:08:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:08:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 268 @ 25821 updates, score 12.946) (writing took 2.1769562447443604 seconds)
2022-03-07 10:08:52 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 10:08:52 | INFO | train | epoch 268 | loss 2.701 | nll_loss 0.857 | ppl 1.81 | wps 22252.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25821 | lr 0.000196795 | gnorm 0.839 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 76644
2022-03-07 10:08:52 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 10:08:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:09:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:12:41 | INFO | train_inner | epoch 269:     80 / 97 loss=2.701, nll_loss=0.857, ppl=1.81, wps=22057.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25900, lr=0.000196494, gnorm=0.847, loss_scale=16, train_wall=266, gb_free=8.1, wall=76873
2022-03-07 10:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:13:35 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 12.927 | nll_loss 12.122 | ppl 4458.21 | wps 42610.9 | wpb 510.9 | bsz 1 | num_updates 25917 | best_loss 8.481
2022-03-07 10:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 25917 updates
2022-03-07 10:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:13:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:13:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 269 @ 25917 updates, score 12.927) (writing took 2.2114485991187394 seconds)
2022-03-07 10:13:37 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 10:13:37 | INFO | train | epoch 269 | loss 2.698 | nll_loss 0.854 | ppl 1.81 | wps 22020.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25917 | lr 0.00019643 | gnorm 0.841 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 76929
2022-03-07 10:13:37 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 10:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:16:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:17:38 | INFO | train_inner | epoch 270:     84 / 97 loss=2.699, nll_loss=0.855, ppl=1.81, wps=22056.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26000, lr=0.000196116, gnorm=0.837, loss_scale=16, train_wall=266, gb_free=8.1, wall=77170
2022-03-07 10:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:18:21 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 12.92 | nll_loss 12.11 | ppl 4419.73 | wps 42642.9 | wpb 510.9 | bsz 1 | num_updates 26013 | best_loss 8.481
2022-03-07 10:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 26013 updates
2022-03-07 10:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 270 @ 26013 updates, score 12.92) (writing took 2.1738605513237417 seconds)
2022-03-07 10:18:23 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 10:18:23 | INFO | train | epoch 270 | loss 2.697 | nll_loss 0.853 | ppl 1.81 | wps 22034.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26013 | lr 0.000196067 | gnorm 0.839 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 77215
2022-03-07 10:18:23 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 10:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:22:32 | INFO | train_inner | epoch 271:     87 / 97 loss=2.695, nll_loss=0.852, ppl=1.8, wps=22279.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26100, lr=0.00019574, gnorm=0.832, loss_scale=16, train_wall=264, gb_free=8.1, wall=77464
2022-03-07 10:22:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:23:06 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 12.916 | nll_loss 12.105 | ppl 4406.08 | wps 42486.7 | wpb 510.9 | bsz 1 | num_updates 26109 | best_loss 8.481
2022-03-07 10:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 26109 updates
2022-03-07 10:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:23:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:23:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 271 @ 26109 updates, score 12.916) (writing took 2.349760035984218 seconds)
2022-03-07 10:23:08 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 10:23:08 | INFO | train | epoch 271 | loss 2.695 | nll_loss 0.851 | ppl 1.8 | wps 22020.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26109 | lr 0.000195706 | gnorm 0.835 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 77500
2022-03-07 10:23:08 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 10:23:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:27:30 | INFO | train_inner | epoch 272:     91 / 97 loss=2.694, nll_loss=0.851, ppl=1.8, wps=22034.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26200, lr=0.000195366, gnorm=0.841, loss_scale=16, train_wall=266, gb_free=8.1, wall=77761
2022-03-07 10:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:27:52 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 12.976 | nll_loss 12.168 | ppl 4602.6 | wps 42944.9 | wpb 510.9 | bsz 1 | num_updates 26206 | best_loss 8.481
2022-03-07 10:27:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 26206 updates
2022-03-07 10:27:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:27:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:27:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 272 @ 26206 updates, score 12.976) (writing took 2.205980719998479 seconds)
2022-03-07 10:27:54 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 10:27:54 | INFO | train | epoch 272 | loss 2.694 | nll_loss 0.85 | ppl 1.8 | wps 22240.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26206 | lr 0.000195344 | gnorm 0.839 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 77786
2022-03-07 10:27:54 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 10:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:30:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:32:27 | INFO | train_inner | epoch 273:     95 / 97 loss=2.692, nll_loss=0.848, ppl=1.8, wps=22049.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26300, lr=0.000194994, gnorm=0.839, loss_scale=16, train_wall=266, gb_free=8.1, wall=78058
2022-03-07 10:32:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:32:37 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 12.922 | nll_loss 12.108 | ppl 4414.66 | wps 42689.1 | wpb 510.9 | bsz 1 | num_updates 26302 | best_loss 8.481
2022-03-07 10:32:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 26302 updates
2022-03-07 10:32:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 273 @ 26302 updates, score 12.922) (writing took 2.212544667068869 seconds)
2022-03-07 10:32:39 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 10:32:39 | INFO | train | epoch 273 | loss 2.691 | nll_loss 0.847 | ppl 1.8 | wps 22015.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26302 | lr 0.000194987 | gnorm 0.838 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 78071
2022-03-07 10:32:39 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 10:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:36:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:37:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:37:23 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 12.973 | nll_loss 12.169 | ppl 4604.81 | wps 42533.4 | wpb 510.9 | bsz 1 | num_updates 26398 | best_loss 8.481
2022-03-07 10:37:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 26398 updates
2022-03-07 10:37:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:37:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:37:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 274 @ 26398 updates, score 12.973) (writing took 2.2349168909713626 seconds)
2022-03-07 10:37:25 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 10:37:25 | INFO | train | epoch 274 | loss 2.69 | nll_loss 0.847 | ppl 1.8 | wps 22017.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26398 | lr 0.000194632 | gnorm 0.842 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 78357
2022-03-07 10:37:25 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 10:37:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:37:31 | INFO | train_inner | epoch 275:      2 / 97 loss=2.691, nll_loss=0.847, ppl=1.8, wps=21508.5, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=26400, lr=0.000194625, gnorm=0.842, loss_scale=16, train_wall=266, gb_free=8.1, wall=78363
2022-03-07 10:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:42:08 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 12.985 | nll_loss 12.184 | ppl 4652.6 | wps 42671.8 | wpb 510.9 | bsz 1 | num_updates 26495 | best_loss 8.481
2022-03-07 10:42:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 26495 updates
2022-03-07 10:42:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:42:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 275 @ 26495 updates, score 12.985) (writing took 2.272093676030636 seconds)
2022-03-07 10:42:11 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 10:42:11 | INFO | train | epoch 275 | loss 2.689 | nll_loss 0.845 | ppl 1.8 | wps 22250.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26495 | lr 0.000194276 | gnorm 0.835 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 78642
2022-03-07 10:42:11 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 10:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:42:25 | INFO | train_inner | epoch 276:      5 / 97 loss=2.688, nll_loss=0.844, ppl=1.79, wps=22268.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26500, lr=0.000194257, gnorm=0.834, loss_scale=16, train_wall=264, gb_free=8.1, wall=78657
2022-03-07 10:43:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:46:53 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 12.911 | nll_loss 12.103 | ppl 4398.09 | wps 42748.5 | wpb 510.9 | bsz 1 | num_updates 26591 | best_loss 8.481
2022-03-07 10:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 26591 updates
2022-03-07 10:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:46:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 276 @ 26591 updates, score 12.911) (writing took 2.3304645088501275 seconds)
2022-03-07 10:46:56 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 10:46:56 | INFO | train | epoch 276 | loss 2.687 | nll_loss 0.843 | ppl 1.79 | wps 22056.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26591 | lr 0.000193924 | gnorm 0.836 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 78927
2022-03-07 10:46:56 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 10:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:47:21 | INFO | train_inner | epoch 277:      9 / 97 loss=2.686, nll_loss=0.842, ppl=1.79, wps=22094.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26600, lr=0.000193892, gnorm=0.834, loss_scale=16, train_wall=266, gb_free=8.1, wall=78953
2022-03-07 10:50:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:51:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:51:38 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 12.873 | nll_loss 12.065 | ppl 4285.18 | wps 42932.8 | wpb 510.9 | bsz 1 | num_updates 26687 | best_loss 8.481
2022-03-07 10:51:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 26687 updates
2022-03-07 10:51:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:51:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:51:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 277 @ 26687 updates, score 12.873) (writing took 2.3183857910335064 seconds)
2022-03-07 10:51:40 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 10:51:40 | INFO | train | epoch 277 | loss 2.686 | nll_loss 0.842 | ppl 1.79 | wps 22071.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26687 | lr 0.000193575 | gnorm 0.839 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 79212
2022-03-07 10:51:40 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 10:51:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:52:18 | INFO | train_inner | epoch 278:     13 / 97 loss=2.685, nll_loss=0.841, ppl=1.79, wps=22096.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26700, lr=0.000193528, gnorm=0.839, loss_scale=16, train_wall=266, gb_free=8.1, wall=79250
2022-03-07 10:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:56:24 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 12.91 | nll_loss 12.103 | ppl 4398.3 | wps 42629.6 | wpb 510.9 | bsz 1 | num_updates 26784 | best_loss 8.481
2022-03-07 10:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 26784 updates
2022-03-07 10:56:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 278 @ 26784 updates, score 12.91) (writing took 2.2968736803159118 seconds)
2022-03-07 10:56:26 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 10:56:26 | INFO | train | epoch 278 | loss 2.684 | nll_loss 0.84 | ppl 1.79 | wps 22258.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26784 | lr 0.000193225 | gnorm 0.843 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 79498
2022-03-07 10:56:26 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 10:56:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:57:12 | INFO | train_inner | epoch 279:     16 / 97 loss=2.684, nll_loss=0.84, ppl=1.79, wps=22277.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26800, lr=0.000193167, gnorm=0.84, loss_scale=32, train_wall=263, gb_free=8.1, wall=79544
2022-03-07 10:57:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:01:09 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 12.956 | nll_loss 12.152 | ppl 4551.85 | wps 42839.7 | wpb 510.9 | bsz 1 | num_updates 26880 | best_loss 8.481
2022-03-07 11:01:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 26880 updates
2022-03-07 11:01:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:01:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:01:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 279 @ 26880 updates, score 12.956) (writing took 2.216374200768769 seconds)
2022-03-07 11:01:11 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 11:01:11 | INFO | train | epoch 279 | loss 2.682 | nll_loss 0.838 | ppl 1.79 | wps 22033.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26880 | lr 0.000192879 | gnorm 0.829 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 79783
2022-03-07 11:01:11 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 11:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:02:09 | INFO | train_inner | epoch 280:     20 / 97 loss=2.68, nll_loss=0.836, ppl=1.79, wps=22067.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26900, lr=0.000192807, gnorm=0.831, loss_scale=16, train_wall=266, gb_free=8.1, wall=79840
2022-03-07 11:04:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:05:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:05:54 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 12.911 | nll_loss 12.105 | ppl 4406.58 | wps 42875.8 | wpb 510.9 | bsz 1 | num_updates 26976 | best_loss 8.481
2022-03-07 11:05:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 26976 updates
2022-03-07 11:05:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:05:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 280 @ 26976 updates, score 12.911) (writing took 2.282212659250945 seconds)
2022-03-07 11:05:56 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 11:05:56 | INFO | train | epoch 280 | loss 2.681 | nll_loss 0.837 | ppl 1.79 | wps 22043.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26976 | lr 0.000192536 | gnorm 0.834 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 80068
2022-03-07 11:05:56 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 11:05:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:07:05 | INFO | train_inner | epoch 281:     24 / 97 loss=2.68, nll_loss=0.836, ppl=1.79, wps=22084.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27000, lr=0.00019245, gnorm=0.843, loss_scale=16, train_wall=266, gb_free=8.1, wall=80137
2022-03-07 11:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:10:39 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 12.904 | nll_loss 12.096 | ppl 4377.34 | wps 42610.4 | wpb 510.9 | bsz 1 | num_updates 27073 | best_loss 8.481
2022-03-07 11:10:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 27073 updates
2022-03-07 11:10:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 281 @ 27073 updates, score 12.904) (writing took 2.3381750341504812 seconds)
2022-03-07 11:10:42 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 11:10:42 | INFO | train | epoch 281 | loss 2.679 | nll_loss 0.835 | ppl 1.78 | wps 22267.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27073 | lr 0.00019219 | gnorm 0.848 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 80354
2022-03-07 11:10:42 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 11:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:11:59 | INFO | train_inner | epoch 282:     27 / 97 loss=2.677, nll_loss=0.833, ppl=1.78, wps=22279.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=27100, lr=0.000192095, gnorm=0.834, loss_scale=32, train_wall=263, gb_free=8.1, wall=80431
2022-03-07 11:13:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:15:24 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 12.957 | nll_loss 12.157 | ppl 4566.28 | wps 43369.6 | wpb 510.9 | bsz 1 | num_updates 27169 | best_loss 8.481
2022-03-07 11:15:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 27169 updates
2022-03-07 11:15:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:15:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:15:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 282 @ 27169 updates, score 12.957) (writing took 2.2513090227730572 seconds)
2022-03-07 11:15:26 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 11:15:26 | INFO | train | epoch 282 | loss 2.677 | nll_loss 0.833 | ppl 1.78 | wps 22110.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27169 | lr 0.000191851 | gnorm 0.821 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 80638
2022-03-07 11:15:26 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 11:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:16:55 | INFO | train_inner | epoch 283:     31 / 97 loss=2.677, nll_loss=0.834, ppl=1.78, wps=22165.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27200, lr=0.000191741, gnorm=0.826, loss_scale=16, train_wall=265, gb_free=8.1, wall=80726
2022-03-07 11:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:20:08 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 12.867 | nll_loss 12.059 | ppl 4267.42 | wps 43232.2 | wpb 510.9 | bsz 1 | num_updates 27266 | best_loss 8.481
2022-03-07 11:20:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 27266 updates
2022-03-07 11:20:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:20:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:20:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 283 @ 27266 updates, score 12.867) (writing took 2.2449686327017844 seconds)
2022-03-07 11:20:10 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 11:20:10 | INFO | train | epoch 283 | loss 2.676 | nll_loss 0.832 | ppl 1.78 | wps 22369.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27266 | lr 0.000191509 | gnorm 0.839 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 80922
2022-03-07 11:20:10 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 11:20:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:21:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:21:50 | INFO | train_inner | epoch 284:     35 / 97 loss=2.674, nll_loss=0.83, ppl=1.78, wps=22165.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27300, lr=0.00019139, gnorm=0.838, loss_scale=16, train_wall=265, gb_free=8.1, wall=81022
2022-03-07 11:24:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:24:52 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 12.951 | nll_loss 12.147 | ppl 4533.85 | wps 43265.5 | wpb 510.9 | bsz 1 | num_updates 27362 | best_loss 8.481
2022-03-07 11:24:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 27362 updates
2022-03-07 11:24:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:24:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:24:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 284 @ 27362 updates, score 12.951) (writing took 2.2565580708906054 seconds)
2022-03-07 11:24:54 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 11:24:54 | INFO | train | epoch 284 | loss 2.673 | nll_loss 0.829 | ppl 1.78 | wps 22125.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27362 | lr 0.000191173 | gnorm 0.831 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 81206
2022-03-07 11:24:54 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 11:24:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:26:43 | INFO | train_inner | epoch 285:     38 / 97 loss=2.672, nll_loss=0.828, ppl=1.78, wps=22384.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27400, lr=0.00019104, gnorm=0.828, loss_scale=16, train_wall=263, gb_free=8.1, wall=81314
2022-03-07 11:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:29:36 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 12.892 | nll_loss 12.083 | ppl 4339.46 | wps 43295.8 | wpb 510.9 | bsz 1 | num_updates 27459 | best_loss 8.481
2022-03-07 11:29:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 27459 updates
2022-03-07 11:29:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:29:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:29:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 285 @ 27459 updates, score 12.892) (writing took 2.2810387830249965 seconds)
2022-03-07 11:29:38 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 11:29:38 | INFO | train | epoch 285 | loss 2.672 | nll_loss 0.828 | ppl 1.78 | wps 22380.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27459 | lr 0.000190835 | gnorm 0.828 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 81490
2022-03-07 11:29:38 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 11:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:30:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:31:38 | INFO | train_inner | epoch 286:     42 / 97 loss=2.673, nll_loss=0.829, ppl=1.78, wps=22183.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27500, lr=0.000190693, gnorm=0.83, loss_scale=16, train_wall=265, gb_free=8.1, wall=81610
2022-03-07 11:34:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:34:20 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 12.925 | nll_loss 12.12 | ppl 4450.73 | wps 43168.9 | wpb 510.9 | bsz 1 | num_updates 27555 | best_loss 8.481
2022-03-07 11:34:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 27555 updates
2022-03-07 11:34:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:34:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:34:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 286 @ 27555 updates, score 12.925) (writing took 2.2244027368724346 seconds)
2022-03-07 11:34:22 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 11:34:22 | INFO | train | epoch 286 | loss 2.669 | nll_loss 0.825 | ppl 1.77 | wps 22146.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27555 | lr 0.000190502 | gnorm 0.832 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 81774
2022-03-07 11:34:22 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 11:34:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:36:30 | INFO | train_inner | epoch 287:     45 / 97 loss=2.667, nll_loss=0.823, ppl=1.77, wps=22391.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27600, lr=0.000190347, gnorm=0.835, loss_scale=16, train_wall=262, gb_free=8.1, wall=81902
2022-03-07 11:37:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:39:04 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 12.939 | nll_loss 12.132 | ppl 4489.32 | wps 43111.6 | wpb 510.9 | bsz 1 | num_updates 27651 | best_loss 8.481
2022-03-07 11:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 27651 updates
2022-03-07 11:39:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:39:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:39:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 287 @ 27651 updates, score 12.939) (writing took 2.184923213906586 seconds)
2022-03-07 11:39:06 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 11:39:06 | INFO | train | epoch 287 | loss 2.67 | nll_loss 0.826 | ppl 1.77 | wps 22151.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27651 | lr 0.000190171 | gnorm 0.838 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 82058
2022-03-07 11:39:06 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 11:39:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:26 | INFO | train_inner | epoch 288:     49 / 97 loss=2.669, nll_loss=0.825, ppl=1.77, wps=22185.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=27700, lr=0.000190003, gnorm=0.837, loss_scale=16, train_wall=265, gb_free=8.1, wall=82197
2022-03-07 11:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:43:47 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 12.876 | nll_loss 12.067 | ppl 4291 | wps 43297.3 | wpb 510.9 | bsz 1 | num_updates 27748 | best_loss 8.481
2022-03-07 11:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 27748 updates
2022-03-07 11:43:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:43:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:43:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 288 @ 27748 updates, score 12.876) (writing took 2.193139063194394 seconds)
2022-03-07 11:43:50 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 11:43:50 | INFO | train | epoch 288 | loss 2.668 | nll_loss 0.824 | ppl 1.77 | wps 22383.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27748 | lr 0.000189838 | gnorm 0.843 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 82341
2022-03-07 11:43:50 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 11:43:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:46:18 | INFO | train_inner | epoch 289:     52 / 97 loss=2.668, nll_loss=0.824, ppl=1.77, wps=22405.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27800, lr=0.000189661, gnorm=0.833, loss_scale=32, train_wall=262, gb_free=8.1, wall=82490
2022-03-07 11:46:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:48:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:48:31 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 12.94 | nll_loss 12.135 | ppl 4496.53 | wps 43136 | wpb 510.9 | bsz 1 | num_updates 27844 | best_loss 8.481
2022-03-07 11:48:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 27844 updates
2022-03-07 11:48:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:48:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:48:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 289 @ 27844 updates, score 12.94) (writing took 2.2090160083025694 seconds)
2022-03-07 11:48:33 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 11:48:33 | INFO | train | epoch 289 | loss 2.666 | nll_loss 0.822 | ppl 1.77 | wps 22157.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27844 | lr 0.000189511 | gnorm 0.819 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 82625
2022-03-07 11:48:33 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 11:48:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:51:13 | INFO | train_inner | epoch 290:     56 / 97 loss=2.665, nll_loss=0.822, ppl=1.77, wps=22185.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27900, lr=0.000189321, gnorm=0.836, loss_scale=16, train_wall=265, gb_free=8.1, wall=82785
2022-03-07 11:52:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:53:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:53:15 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 12.975 | nll_loss 12.181 | ppl 4644.95 | wps 43301.1 | wpb 510.9 | bsz 1 | num_updates 27940 | best_loss 8.481
2022-03-07 11:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 27940 updates
2022-03-07 11:53:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:53:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 290 @ 27940 updates, score 12.975) (writing took 2.2436882709152997 seconds)
2022-03-07 11:53:17 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 11:53:17 | INFO | train | epoch 290 | loss 2.664 | nll_loss 0.82 | ppl 1.77 | wps 22151.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27940 | lr 0.000189185 | gnorm 0.84 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 82909
2022-03-07 11:53:17 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 11:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:56:08 | INFO | train_inner | epoch 291:     60 / 97 loss=2.662, nll_loss=0.818, ppl=1.76, wps=22181.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=28000, lr=0.000188982, gnorm=0.824, loss_scale=16, train_wall=265, gb_free=8.1, wall=83080
2022-03-07 11:57:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:57:59 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 12.912 | nll_loss 12.108 | ppl 4413.41 | wps 43300 | wpb 510.9 | bsz 1 | num_updates 28037 | best_loss 8.481
2022-03-07 11:57:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 28037 updates
2022-03-07 11:57:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:58:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:58:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 291 @ 28037 updates, score 12.912) (writing took 2.219387087970972 seconds)
2022-03-07 11:58:01 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 11:58:01 | INFO | train | epoch 291 | loss 2.663 | nll_loss 0.819 | ppl 1.76 | wps 22381.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28037 | lr 0.000188857 | gnorm 0.823 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 83193
2022-03-07 11:58:01 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 11:58:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:01:01 | INFO | train_inner | epoch 292:     63 / 97 loss=2.663, nll_loss=0.819, ppl=1.76, wps=22397, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=28100, lr=0.000188646, gnorm=0.821, loss_scale=32, train_wall=262, gb_free=8.1, wall=83373
2022-03-07 12:01:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:02:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:02:43 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 12.9 | nll_loss 12.093 | ppl 4369.8 | wps 43208.1 | wpb 510.9 | bsz 1 | num_updates 28133 | best_loss 8.481
2022-03-07 12:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 28133 updates
2022-03-07 12:02:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:02:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 292 @ 28133 updates, score 12.9) (writing took 2.195142023265362 seconds)
2022-03-07 12:02:45 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 12:02:45 | INFO | train | epoch 292 | loss 2.661 | nll_loss 0.817 | ppl 1.76 | wps 22153.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28133 | lr 0.000188535 | gnorm 0.814 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 83477
2022-03-07 12:02:45 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 12:02:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:05:56 | INFO | train_inner | epoch 293:     67 / 97 loss=2.662, nll_loss=0.818, ppl=1.76, wps=22180.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28200, lr=0.000188311, gnorm=0.827, loss_scale=16, train_wall=265, gb_free=8.1, wall=83668
2022-03-07 12:07:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:07:26 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 12.934 | nll_loss 12.135 | ppl 4497.18 | wps 43230.4 | wpb 510.9 | bsz 1 | num_updates 28230 | best_loss 8.481
2022-03-07 12:07:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 28230 updates
2022-03-07 12:07:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:07:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:07:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 293 @ 28230 updates, score 12.934) (writing took 2.1868649292737246 seconds)
2022-03-07 12:07:29 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 12:07:29 | INFO | train | epoch 293 | loss 2.66 | nll_loss 0.817 | ppl 1.76 | wps 22378.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28230 | lr 0.000188211 | gnorm 0.833 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 83761
2022-03-07 12:07:29 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 12:07:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:08:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:10:51 | INFO | train_inner | epoch 294:     71 / 97 loss=2.659, nll_loss=0.815, ppl=1.76, wps=22179.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28300, lr=0.000187978, gnorm=0.842, loss_scale=16, train_wall=265, gb_free=8.1, wall=83963
2022-03-07 12:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:12:10 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 12.926 | nll_loss 12.126 | ppl 4468.49 | wps 43205.6 | wpb 510.9 | bsz 1 | num_updates 28326 | best_loss 8.481
2022-03-07 12:12:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 28326 updates
2022-03-07 12:12:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:12:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:12:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 294 @ 28326 updates, score 12.926) (writing took 2.1906503569334745 seconds)
2022-03-07 12:12:12 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 12:12:12 | INFO | train | epoch 294 | loss 2.658 | nll_loss 0.814 | ppl 1.76 | wps 22149.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28326 | lr 0.000187892 | gnorm 0.838 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 84044
2022-03-07 12:12:13 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 12:12:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:15:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:15:47 | INFO | train_inner | epoch 295:     75 / 97 loss=2.657, nll_loss=0.813, ppl=1.76, wps=22182.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28400, lr=0.000187647, gnorm=0.835, loss_scale=16, train_wall=265, gb_free=8.1, wall=84258
2022-03-07 12:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:16:54 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 12.954 | nll_loss 12.153 | ppl 4553.19 | wps 43572.6 | wpb 510.9 | bsz 1 | num_updates 28422 | best_loss 8.481
2022-03-07 12:16:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 28422 updates
2022-03-07 12:16:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:16:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:16:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 295 @ 28422 updates, score 12.954) (writing took 2.227200253866613 seconds)
2022-03-07 12:16:56 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 12:16:56 | INFO | train | epoch 295 | loss 2.657 | nll_loss 0.813 | ppl 1.76 | wps 22150.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28422 | lr 0.000187574 | gnorm 0.839 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 84328
2022-03-07 12:16:56 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 12:16:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:20:39 | INFO | train_inner | epoch 296:     78 / 97 loss=2.657, nll_loss=0.814, ppl=1.76, wps=22407.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28500, lr=0.000187317, gnorm=0.825, loss_scale=16, train_wall=262, gb_free=8.1, wall=84551
2022-03-07 12:21:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:21:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:21:38 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 12.967 | nll_loss 12.168 | ppl 4601.56 | wps 43201.6 | wpb 510.9 | bsz 1 | num_updates 28518 | best_loss 8.481
2022-03-07 12:21:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 28518 updates
2022-03-07 12:21:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:21:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:21:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 296 @ 28518 updates, score 12.967) (writing took 2.235953531228006 seconds)
2022-03-07 12:21:40 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 12:21:40 | INFO | train | epoch 296 | loss 2.655 | nll_loss 0.811 | ppl 1.75 | wps 22161.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28518 | lr 0.000187258 | gnorm 0.824 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 84612
2022-03-07 12:21:40 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 12:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:25:34 | INFO | train_inner | epoch 297:     82 / 97 loss=2.654, nll_loss=0.811, ppl=1.75, wps=22190.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28600, lr=0.000186989, gnorm=0.826, loss_scale=16, train_wall=265, gb_free=8.1, wall=84846
2022-03-07 12:26:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:26:22 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 12.922 | nll_loss 12.122 | ppl 4456.65 | wps 43122.5 | wpb 510.9 | bsz 1 | num_updates 28615 | best_loss 8.481
2022-03-07 12:26:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 28615 updates
2022-03-07 12:26:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:26:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:26:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 297 @ 28615 updates, score 12.922) (writing took 2.24000315181911 seconds)
2022-03-07 12:26:24 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 12:26:24 | INFO | train | epoch 297 | loss 2.655 | nll_loss 0.811 | ppl 1.75 | wps 22382.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28615 | lr 0.00018694 | gnorm 0.825 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 84896
2022-03-07 12:26:24 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 12:26:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:30:26 | INFO | train_inner | epoch 298:     85 / 97 loss=2.655, nll_loss=0.811, ppl=1.75, wps=22388.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28700, lr=0.000186663, gnorm=0.828, loss_scale=32, train_wall=263, gb_free=8.1, wall=85138
2022-03-07 12:31:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:31:06 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 12.911 | nll_loss 12.11 | ppl 4419.09 | wps 43246.8 | wpb 510.9 | bsz 1 | num_updates 28712 | best_loss 8.481
2022-03-07 12:31:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 28712 updates
2022-03-07 12:31:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:31:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:31:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 298 @ 28712 updates, score 12.911) (writing took 2.39135809103027 seconds)
2022-03-07 12:31:08 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 12:31:08 | INFO | train | epoch 298 | loss 2.653 | nll_loss 0.809 | ppl 1.75 | wps 22358.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28712 | lr 0.000186624 | gnorm 0.825 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 85180
2022-03-07 12:31:08 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 12:31:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:31:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:35:22 | INFO | train_inner | epoch 299:     89 / 97 loss=2.652, nll_loss=0.809, ppl=1.75, wps=22172.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28800, lr=0.000186339, gnorm=0.817, loss_scale=16, train_wall=265, gb_free=8.1, wall=85434
2022-03-07 12:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:35:50 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 12.934 | nll_loss 12.134 | ppl 4493.25 | wps 43238.6 | wpb 510.9 | bsz 1 | num_updates 28808 | best_loss 8.481
2022-03-07 12:35:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 28808 updates
2022-03-07 12:35:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:35:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:35:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 299 @ 28808 updates, score 12.934) (writing took 2.278503268957138 seconds)
2022-03-07 12:35:52 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 12:35:52 | INFO | train | epoch 299 | loss 2.651 | nll_loss 0.807 | ppl 1.75 | wps 22149.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28808 | lr 0.000186313 | gnorm 0.818 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 85464
2022-03-07 12:35:52 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 12:35:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:38:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:40:17 | INFO | train_inner | epoch 300:     93 / 97 loss=2.651, nll_loss=0.808, ppl=1.75, wps=22180.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28900, lr=0.000186016, gnorm=0.829, loss_scale=16, train_wall=265, gb_free=8.1, wall=85729
2022-03-07 12:40:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:40:33 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 12.885 | nll_loss 12.08 | ppl 4329.68 | wps 43029.2 | wpb 510.9 | bsz 1 | num_updates 28904 | best_loss 8.481
2022-03-07 12:40:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 28904 updates
2022-03-07 12:40:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:40:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:40:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 300 @ 28904 updates, score 12.885) (writing took 2.291226200759411 seconds)
2022-03-07 12:40:36 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 12:40:36 | INFO | train | epoch 300 | loss 2.65 | nll_loss 0.806 | ppl 1.75 | wps 22146.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28904 | lr 0.000186003 | gnorm 0.829 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 85748
2022-03-07 12:40:36 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 12:40:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:45:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:45:12 | INFO | train_inner | epoch 301:     97 / 97 loss=2.649, nll_loss=0.806, ppl=1.75, wps=22167.9, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=29000, lr=0.000185695, gnorm=0.815, loss_scale=16, train_wall=265, gb_free=8.1, wall=86024
2022-03-07 12:45:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:45:17 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 12.956 | nll_loss 12.16 | ppl 4576.38 | wps 43095.6 | wpb 510.9 | bsz 1 | num_updates 29000 | best_loss 8.481
2022-03-07 12:45:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 29000 updates
2022-03-07 12:45:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:45:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:45:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 301 @ 29000 updates, score 12.956) (writing took 2.2985897972248495 seconds)
2022-03-07 12:45:20 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 12:45:20 | INFO | train | epoch 301 | loss 2.649 | nll_loss 0.805 | ppl 1.75 | wps 22134.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29000 | lr 0.000185695 | gnorm 0.815 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 86032
2022-03-07 12:45:20 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 12:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:49:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:50:01 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 12.968 | nll_loss 12.169 | ppl 4604.57 | wps 42851 | wpb 510.9 | bsz 1 | num_updates 29097 | best_loss 8.481
2022-03-07 12:50:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 29097 updates
2022-03-07 12:50:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:50:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:50:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 302 @ 29097 updates, score 12.968) (writing took 2.325199281796813 seconds)
2022-03-07 12:50:04 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 12:50:04 | INFO | train | epoch 302 | loss 2.648 | nll_loss 0.805 | ppl 1.75 | wps 22368.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29097 | lr 0.000185386 | gnorm 0.826 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 86316
2022-03-07 12:50:04 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 12:50:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:50:12 | INFO | train_inner | epoch 303:      3 / 97 loss=2.647, nll_loss=0.803, ppl=1.75, wps=21827, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=29100, lr=0.000185376, gnorm=0.825, loss_scale=16, train_wall=262, gb_free=8.1, wall=86324
2022-03-07 12:51:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:54:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:54:45 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 12.947 | nll_loss 12.149 | ppl 4542.94 | wps 43313.5 | wpb 510.9 | bsz 1 | num_updates 29193 | best_loss 8.481
2022-03-07 12:54:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 29193 updates
2022-03-07 12:54:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:54:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:54:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 303 @ 29193 updates, score 12.947) (writing took 2.267921274062246 seconds)
2022-03-07 12:54:48 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 12:54:48 | INFO | train | epoch 303 | loss 2.646 | nll_loss 0.802 | ppl 1.74 | wps 22149.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29193 | lr 0.00018508 | gnorm 0.818 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 86600
2022-03-07 12:54:48 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 12:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:55:08 | INFO | train_inner | epoch 304:      7 / 97 loss=2.645, nll_loss=0.801, ppl=1.74, wps=22183.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29200, lr=0.000185058, gnorm=0.818, loss_scale=16, train_wall=265, gb_free=8.1, wall=86620
2022-03-07 12:58:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:59:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:59:29 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 12.942 | nll_loss 12.146 | ppl 4532.08 | wps 43433.1 | wpb 510.9 | bsz 1 | num_updates 29289 | best_loss 8.481
2022-03-07 12:59:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 29289 updates
2022-03-07 12:59:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:59:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 304 @ 29289 updates, score 12.942) (writing took 2.2368387482129037 seconds)
2022-03-07 12:59:31 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 12:59:31 | INFO | train | epoch 304 | loss 2.645 | nll_loss 0.801 | ppl 1.74 | wps 22148.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29289 | lr 0.000184777 | gnorm 0.817 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 86883
2022-03-07 12:59:31 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 12:59:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:00:03 | INFO | train_inner | epoch 305:     11 / 97 loss=2.644, nll_loss=0.801, ppl=1.74, wps=22181, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29300, lr=0.000184742, gnorm=0.815, loss_scale=16, train_wall=265, gb_free=8.1, wall=86915
2022-03-07 13:04:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:04:13 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 12.94 | nll_loss 12.139 | ppl 4510.11 | wps 43480.7 | wpb 510.9 | bsz 1 | num_updates 29386 | best_loss 8.481
2022-03-07 13:04:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 29386 updates
2022-03-07 13:04:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:04:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 305 @ 29386 updates, score 12.94) (writing took 2.233829690143466 seconds)
2022-03-07 13:04:15 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 13:04:15 | INFO | train | epoch 305 | loss 2.643 | nll_loss 0.8 | ppl 1.74 | wps 22382.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29386 | lr 0.000184472 | gnorm 0.817 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 87167
2022-03-07 13:04:15 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 13:04:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:04:55 | INFO | train_inner | epoch 306:     14 / 97 loss=2.642, nll_loss=0.798, ppl=1.74, wps=22402, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29400, lr=0.000184428, gnorm=0.823, loss_scale=32, train_wall=262, gb_free=8.1, wall=87207
2022-03-07 13:05:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:08:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:08:57 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 12.876 | nll_loss 12.076 | ppl 4318.43 | wps 42812.7 | wpb 510.9 | bsz 1 | num_updates 29482 | best_loss 8.481
2022-03-07 13:08:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 29482 updates
2022-03-07 13:08:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:08:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:08:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 306 @ 29482 updates, score 12.876) (writing took 2.238233990035951 seconds)
2022-03-07 13:08:59 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 13:08:59 | INFO | train | epoch 306 | loss 2.643 | nll_loss 0.799 | ppl 1.74 | wps 22146.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29482 | lr 0.000184171 | gnorm 0.835 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 87451
2022-03-07 13:08:59 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 13:08:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:09:51 | INFO | train_inner | epoch 307:     18 / 97 loss=2.642, nll_loss=0.798, ppl=1.74, wps=22178.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29500, lr=0.000184115, gnorm=0.826, loss_scale=16, train_wall=265, gb_free=8.1, wall=87502
2022-03-07 13:13:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:13:41 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 12.908 | nll_loss 12.114 | ppl 4432.19 | wps 43100.6 | wpb 510.9 | bsz 1 | num_updates 29579 | best_loss 8.481
2022-03-07 13:13:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 29579 updates
2022-03-07 13:13:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:13:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:13:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 307 @ 29579 updates, score 12.908) (writing took 2.237554918974638 seconds)
2022-03-07 13:13:43 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 13:13:43 | INFO | train | epoch 307 | loss 2.64 | nll_loss 0.797 | ppl 1.74 | wps 22384.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29579 | lr 0.000183869 | gnorm 0.811 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 87735
2022-03-07 13:13:43 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 13:13:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:14:43 | INFO | train_inner | epoch 308:     21 / 97 loss=2.64, nll_loss=0.797, ppl=1.74, wps=22401.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=29600, lr=0.000183804, gnorm=0.81, loss_scale=32, train_wall=262, gb_free=8.1, wall=87795
2022-03-07 13:16:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:18:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:18:25 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 12.999 | nll_loss 12.2 | ppl 4706.4 | wps 43248.8 | wpb 510.9 | bsz 1 | num_updates 29675 | best_loss 8.481
2022-03-07 13:18:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 29675 updates
2022-03-07 13:18:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:18:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:18:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 308 @ 29675 updates, score 12.999) (writing took 2.249398068059236 seconds)
2022-03-07 13:18:27 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 13:18:27 | INFO | train | epoch 308 | loss 2.64 | nll_loss 0.796 | ppl 1.74 | wps 22148.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29675 | lr 0.000183571 | gnorm 0.814 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 88019
2022-03-07 13:18:27 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 13:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:19:38 | INFO | train_inner | epoch 309:     25 / 97 loss=2.639, nll_loss=0.796, ppl=1.74, wps=22179.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29700, lr=0.000183494, gnorm=0.817, loss_scale=16, train_wall=265, gb_free=8.1, wall=88090
2022-03-07 13:22:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:23:08 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 12.963 | nll_loss 12.174 | ppl 4621.72 | wps 43471.9 | wpb 510.9 | bsz 1 | num_updates 29771 | best_loss 8.481
2022-03-07 13:23:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 29771 updates
2022-03-07 13:23:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:23:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:23:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 309 @ 29771 updates, score 12.963) (writing took 2.2611197480000556 seconds)
2022-03-07 13:23:11 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 13:23:11 | INFO | train | epoch 309 | loss 2.638 | nll_loss 0.794 | ppl 1.73 | wps 22151.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29771 | lr 0.000183275 | gnorm 0.824 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 88303
2022-03-07 13:23:11 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 13:23:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:24:33 | INFO | train_inner | epoch 310:     29 / 97 loss=2.637, nll_loss=0.794, ppl=1.73, wps=22187.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=29800, lr=0.000183186, gnorm=0.831, loss_scale=16, train_wall=265, gb_free=8.1, wall=88385
2022-03-07 13:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:27:52 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 12.89 | nll_loss 12.094 | ppl 4370.85 | wps 43466.4 | wpb 510.9 | bsz 1 | num_updates 29868 | best_loss 8.481
2022-03-07 13:27:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 29868 updates
2022-03-07 13:27:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:27:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:27:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 310 @ 29868 updates, score 12.89) (writing took 2.257691971026361 seconds)
2022-03-07 13:27:54 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 13:27:54 | INFO | train | epoch 310 | loss 2.637 | nll_loss 0.794 | ppl 1.73 | wps 22390 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29868 | lr 0.000182977 | gnorm 0.833 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 88586
2022-03-07 13:27:54 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 13:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:29:26 | INFO | train_inner | epoch 311:     32 / 97 loss=2.636, nll_loss=0.792, ppl=1.73, wps=22402.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29900, lr=0.000182879, gnorm=0.824, loss_scale=32, train_wall=262, gb_free=8.1, wall=88678
2022-03-07 13:30:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:32:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:32:36 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 12.984 | nll_loss 12.195 | ppl 4687.48 | wps 43169.5 | wpb 510.9 | bsz 1 | num_updates 29964 | best_loss 8.481
2022-03-07 13:32:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 29964 updates
2022-03-07 13:32:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:32:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:32:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 311 @ 29964 updates, score 12.984) (writing took 2.283766819164157 seconds)
2022-03-07 13:32:38 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 13:32:38 | INFO | train | epoch 311 | loss 2.634 | nll_loss 0.79 | ppl 1.73 | wps 22143.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29964 | lr 0.000182684 | gnorm 0.807 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 88870
2022-03-07 13:32:38 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 13:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:34:21 | INFO | train_inner | epoch 312:     36 / 97 loss=2.634, nll_loss=0.79, ppl=1.73, wps=22180.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30000, lr=0.000182574, gnorm=0.812, loss_scale=16, train_wall=265, gb_free=8.1, wall=88973
2022-03-07 13:37:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:37:20 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 12.913 | nll_loss 12.116 | ppl 4439.85 | wps 43515.2 | wpb 510.9 | bsz 1 | num_updates 30061 | best_loss 8.481
2022-03-07 13:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 30061 updates
2022-03-07 13:37:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:37:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 312 @ 30061 updates, score 12.913) (writing took 2.246926144231111 seconds)
2022-03-07 13:37:22 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 13:37:22 | INFO | train | epoch 312 | loss 2.634 | nll_loss 0.791 | ppl 1.73 | wps 22376.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30061 | lr 0.000182389 | gnorm 0.824 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 89154
2022-03-07 13:37:22 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 13:37:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:38:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:39:16 | INFO | train_inner | epoch 313:     40 / 97 loss=2.633, nll_loss=0.789, ppl=1.73, wps=22176.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30100, lr=0.000182271, gnorm=0.821, loss_scale=16, train_wall=265, gb_free=8.1, wall=89268
2022-03-07 13:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:42:04 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 12.882 | nll_loss 12.082 | ppl 4336.78 | wps 43214 | wpb 510.9 | bsz 1 | num_updates 30157 | best_loss 8.481
2022-03-07 13:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 30157 updates
2022-03-07 13:42:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:42:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 313 @ 30157 updates, score 12.882) (writing took 2.225971871986985 seconds)
2022-03-07 13:42:06 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 13:42:06 | INFO | train | epoch 313 | loss 2.633 | nll_loss 0.789 | ppl 1.73 | wps 22147.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30157 | lr 0.000182098 | gnorm 0.807 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 89438
2022-03-07 13:42:06 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 13:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:44:09 | INFO | train_inner | epoch 314:     43 / 97 loss=2.632, nll_loss=0.788, ppl=1.73, wps=22392.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=30200, lr=0.000181969, gnorm=0.806, loss_scale=16, train_wall=262, gb_free=8.1, wall=89561
2022-03-07 13:44:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:46:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:46:48 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.023 | nll_loss 12.235 | ppl 4819.8 | wps 43394.7 | wpb 510.9 | bsz 1 | num_updates 30253 | best_loss 8.481
2022-03-07 13:46:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 30253 updates
2022-03-07 13:46:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:46:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:46:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 314 @ 30253 updates, score 13.023) (writing took 2.228514396119863 seconds)
2022-03-07 13:46:50 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 13:46:50 | INFO | train | epoch 314 | loss 2.632 | nll_loss 0.788 | ppl 1.73 | wps 22142.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30253 | lr 0.000181809 | gnorm 0.812 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 89722
2022-03-07 13:46:50 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 13:46:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:49:04 | INFO | train_inner | epoch 315:     47 / 97 loss=2.631, nll_loss=0.788, ppl=1.73, wps=22179.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30300, lr=0.000181668, gnorm=0.812, loss_scale=16, train_wall=265, gb_free=8.1, wall=89856
2022-03-07 13:51:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:51:32 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 12.935 | nll_loss 12.144 | ppl 4525.1 | wps 43293.6 | wpb 510.9 | bsz 1 | num_updates 30350 | best_loss 8.481
2022-03-07 13:51:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 30350 updates
2022-03-07 13:51:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:51:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 315 @ 30350 updates, score 12.935) (writing took 2.2306623412296176 seconds)
2022-03-07 13:51:34 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 13:51:34 | INFO | train | epoch 315 | loss 2.631 | nll_loss 0.787 | ppl 1.73 | wps 22378.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30350 | lr 0.000181518 | gnorm 0.817 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 90006
2022-03-07 13:51:34 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 13:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:53:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:53:59 | INFO | train_inner | epoch 316:     51 / 97 loss=2.63, nll_loss=0.786, ppl=1.72, wps=22178.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30400, lr=0.000181369, gnorm=0.81, loss_scale=16, train_wall=265, gb_free=8.1, wall=90151
2022-03-07 13:56:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:56:15 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 12.959 | nll_loss 12.169 | ppl 4604.15 | wps 43458.3 | wpb 510.9 | bsz 1 | num_updates 30446 | best_loss 8.481
2022-03-07 13:56:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 30446 updates
2022-03-07 13:56:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:56:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:56:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 316 @ 30446 updates, score 12.959) (writing took 2.2981156297028065 seconds)
2022-03-07 13:56:18 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 13:56:18 | INFO | train | epoch 316 | loss 2.629 | nll_loss 0.786 | ppl 1.72 | wps 22153.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30446 | lr 0.000181232 | gnorm 0.814 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 90290
2022-03-07 13:56:18 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 13:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:58:52 | INFO | train_inner | epoch 317:     54 / 97 loss=2.627, nll_loss=0.784, ppl=1.72, wps=22397.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=30500, lr=0.000181071, gnorm=0.817, loss_scale=16, train_wall=262, gb_free=8.1, wall=90444
2022-03-07 14:00:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:00:59 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 12.998 | nll_loss 12.211 | ppl 4741.16 | wps 43247 | wpb 510.9 | bsz 1 | num_updates 30542 | best_loss 8.481
2022-03-07 14:00:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 30542 updates
2022-03-07 14:00:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 317 @ 30542 updates, score 12.998) (writing took 2.2290617832913995 seconds)
2022-03-07 14:01:02 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 14:01:02 | INFO | train | epoch 317 | loss 2.628 | nll_loss 0.784 | ppl 1.72 | wps 22145.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30542 | lr 0.000180947 | gnorm 0.809 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 90574
2022-03-07 14:01:02 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 14:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:03:47 | INFO | train_inner | epoch 318:     58 / 97 loss=2.627, nll_loss=0.784, ppl=1.72, wps=22180.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30600, lr=0.000180775, gnorm=0.817, loss_scale=16, train_wall=265, gb_free=8.1, wall=90739
2022-03-07 14:05:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:05:43 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 12.925 | nll_loss 12.133 | ppl 4491.29 | wps 43230.9 | wpb 510.9 | bsz 1 | num_updates 30639 | best_loss 8.481
2022-03-07 14:05:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 30639 updates
2022-03-07 14:05:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:05:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:05:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 318 @ 30639 updates, score 12.925) (writing took 2.277172270230949 seconds)
2022-03-07 14:05:46 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 14:05:46 | INFO | train | epoch 318 | loss 2.627 | nll_loss 0.784 | ppl 1.72 | wps 22376.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30639 | lr 0.00018066 | gnorm 0.818 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 90857
2022-03-07 14:05:46 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 14:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:07:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:08:42 | INFO | train_inner | epoch 319:     62 / 97 loss=2.627, nll_loss=0.784, ppl=1.72, wps=22180.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30700, lr=0.000180481, gnorm=0.816, loss_scale=16, train_wall=265, gb_free=8.1, wall=91034
2022-03-07 14:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:10:27 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 12.892 | nll_loss 12.093 | ppl 4370.04 | wps 43165.5 | wpb 510.9 | bsz 1 | num_updates 30735 | best_loss 8.481
2022-03-07 14:10:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 30735 updates
2022-03-07 14:10:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:10:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:10:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 319 @ 30735 updates, score 12.892) (writing took 2.245937662664801 seconds)
2022-03-07 14:10:29 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 14:10:29 | INFO | train | epoch 319 | loss 2.625 | nll_loss 0.782 | ppl 1.72 | wps 22155.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30735 | lr 0.000180378 | gnorm 0.821 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 91141
2022-03-07 14:10:29 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 14:10:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:13:35 | INFO | train_inner | epoch 320:     65 / 97 loss=2.625, nll_loss=0.781, ppl=1.72, wps=22396.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30800, lr=0.000180187, gnorm=0.817, loss_scale=16, train_wall=262, gb_free=8.1, wall=91327
2022-03-07 14:14:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:15:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:15:11 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 12.928 | nll_loss 12.135 | ppl 4499.27 | wps 43196.6 | wpb 510.9 | bsz 1 | num_updates 30831 | best_loss 8.481
2022-03-07 14:15:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 30831 updates
2022-03-07 14:15:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:15:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:15:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 320 @ 30831 updates, score 12.928) (writing took 2.2196488711051643 seconds)
2022-03-07 14:15:13 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 14:15:13 | INFO | train | epoch 320 | loss 2.623 | nll_loss 0.78 | ppl 1.72 | wps 22153.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30831 | lr 0.000180097 | gnorm 0.806 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 91425
2022-03-07 14:15:13 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 14:15:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:18:30 | INFO | train_inner | epoch 321:     69 / 97 loss=2.624, nll_loss=0.78, ppl=1.72, wps=22186.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30900, lr=0.000179896, gnorm=0.811, loss_scale=16, train_wall=265, gb_free=8.1, wall=91622
2022-03-07 14:19:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:19:55 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 12.965 | nll_loss 12.172 | ppl 4615.15 | wps 43323.7 | wpb 510.9 | bsz 1 | num_updates 30928 | best_loss 8.481
2022-03-07 14:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 30928 updates
2022-03-07 14:19:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:19:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:19:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 321 @ 30928 updates, score 12.965) (writing took 2.1958492971025407 seconds)
2022-03-07 14:19:57 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 14:19:57 | INFO | train | epoch 321 | loss 2.624 | nll_loss 0.78 | ppl 1.72 | wps 22385.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30928 | lr 0.000179814 | gnorm 0.82 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 91709
2022-03-07 14:19:57 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 14:19:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:21:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:23:25 | INFO | train_inner | epoch 322:     73 / 97 loss=2.622, nll_loss=0.778, ppl=1.72, wps=22195.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31000, lr=0.000179605, gnorm=0.82, loss_scale=16, train_wall=265, gb_free=8.1, wall=91917
2022-03-07 14:24:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:24:38 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 12.928 | nll_loss 12.134 | ppl 4494.62 | wps 43139.9 | wpb 510.9 | bsz 1 | num_updates 31024 | best_loss 8.481
2022-03-07 14:24:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 31024 updates
2022-03-07 14:24:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:24:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:24:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 322 @ 31024 updates, score 12.928) (writing took 2.2414483870379627 seconds)
2022-03-07 14:24:41 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 14:24:41 | INFO | train | epoch 322 | loss 2.62 | nll_loss 0.777 | ppl 1.71 | wps 22152.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31024 | lr 0.000179536 | gnorm 0.811 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 91993
2022-03-07 14:24:41 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 14:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:27:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:28:20 | INFO | train_inner | epoch 323:     77 / 97 loss=2.621, nll_loss=0.778, ppl=1.71, wps=22171.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31100, lr=0.000179316, gnorm=0.819, loss_scale=16, train_wall=265, gb_free=8.1, wall=92212
2022-03-07 14:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:29:22 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 12.953 | nll_loss 12.16 | ppl 4575.86 | wps 43313.3 | wpb 510.9 | bsz 1 | num_updates 31120 | best_loss 8.481
2022-03-07 14:29:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 31120 updates
2022-03-07 14:29:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:29:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:29:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 323 @ 31120 updates, score 12.953) (writing took 2.262615022715181 seconds)
2022-03-07 14:29:25 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 14:29:25 | INFO | train | epoch 323 | loss 2.62 | nll_loss 0.777 | ppl 1.71 | wps 22144.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31120 | lr 0.000179259 | gnorm 0.823 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 92277
2022-03-07 14:29:25 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 14:29:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:33:13 | INFO | train_inner | epoch 324:     80 / 97 loss=2.619, nll_loss=0.775, ppl=1.71, wps=22394.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31200, lr=0.000179029, gnorm=0.81, loss_scale=16, train_wall=262, gb_free=8.1, wall=92505
2022-03-07 14:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:34:06 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 12.923 | nll_loss 12.132 | ppl 4489.07 | wps 42805.5 | wpb 510.9 | bsz 1 | num_updates 31217 | best_loss 8.481
2022-03-07 14:34:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 31217 updates
2022-03-07 14:34:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:34:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:34:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 324 @ 31217 updates, score 12.923) (writing took 2.235967369750142 seconds)
2022-03-07 14:34:09 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 14:34:09 | INFO | train | epoch 324 | loss 2.618 | nll_loss 0.775 | ppl 1.71 | wps 22371.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31217 | lr 0.00017898 | gnorm 0.806 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 92560
2022-03-07 14:34:09 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 14:34:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:37:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:38:08 | INFO | train_inner | epoch 325:     84 / 97 loss=2.619, nll_loss=0.776, ppl=1.71, wps=22173.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31300, lr=0.000178743, gnorm=0.812, loss_scale=16, train_wall=265, gb_free=8.1, wall=92800
2022-03-07 14:38:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:38:50 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 12.953 | nll_loss 12.163 | ppl 4586.34 | wps 43469.1 | wpb 510.9 | bsz 1 | num_updates 31313 | best_loss 8.481
2022-03-07 14:38:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 31313 updates
2022-03-07 14:38:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:38:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:38:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 325 @ 31313 updates, score 12.953) (writing took 2.2053359150886536 seconds)
2022-03-07 14:38:52 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 14:38:52 | INFO | train | epoch 325 | loss 2.618 | nll_loss 0.775 | ppl 1.71 | wps 22151.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31313 | lr 0.000178705 | gnorm 0.815 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 92844
2022-03-07 14:38:52 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 14:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:43:01 | INFO | train_inner | epoch 326:     87 / 97 loss=2.617, nll_loss=0.774, ppl=1.71, wps=22393.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31400, lr=0.000178458, gnorm=0.813, loss_scale=16, train_wall=262, gb_free=8.1, wall=93093
2022-03-07 14:43:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:43:34 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.008 | nll_loss 12.218 | ppl 4765.32 | wps 43028.9 | wpb 510.9 | bsz 1 | num_updates 31410 | best_loss 8.481
2022-03-07 14:43:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 31410 updates
2022-03-07 14:43:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:43:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:43:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 326 @ 31410 updates, score 13.008) (writing took 2.253911281004548 seconds)
2022-03-07 14:43:36 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 14:43:36 | INFO | train | epoch 326 | loss 2.617 | nll_loss 0.774 | ppl 1.71 | wps 22366.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31410 | lr 0.000178429 | gnorm 0.814 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 93128
2022-03-07 14:43:36 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 14:43:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:44:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:47:56 | INFO | train_inner | epoch 327:     91 / 97 loss=2.616, nll_loss=0.773, ppl=1.71, wps=22174.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31500, lr=0.000178174, gnorm=0.821, loss_scale=16, train_wall=265, gb_free=8.1, wall=93388
2022-03-07 14:48:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:48:18 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 12.962 | nll_loss 12.171 | ppl 4610.43 | wps 43183.5 | wpb 510.9 | bsz 1 | num_updates 31506 | best_loss 8.481
2022-03-07 14:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 31506 updates
2022-03-07 14:48:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:48:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:48:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 327 @ 31506 updates, score 12.962) (writing took 2.2895060782320797 seconds)
2022-03-07 14:48:20 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 14:48:20 | INFO | train | epoch 327 | loss 2.615 | nll_loss 0.772 | ppl 1.71 | wps 22142.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31506 | lr 0.000178157 | gnorm 0.821 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 93412
2022-03-07 14:48:20 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 14:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:51:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:52:51 | INFO | train_inner | epoch 328:     95 / 97 loss=2.615, nll_loss=0.772, ppl=1.71, wps=22175, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31600, lr=0.000177892, gnorm=0.815, loss_scale=16, train_wall=265, gb_free=8.1, wall=93683
2022-03-07 14:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:53:02 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 12.975 | nll_loss 12.189 | ppl 4669.09 | wps 43258.9 | wpb 510.9 | bsz 1 | num_updates 31602 | best_loss 8.481
2022-03-07 14:53:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 31602 updates
2022-03-07 14:53:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:53:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:53:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 328 @ 31602 updates, score 12.975) (writing took 2.3504871921613812 seconds)
2022-03-07 14:53:04 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 14:53:04 | INFO | train | epoch 328 | loss 2.614 | nll_loss 0.771 | ppl 1.71 | wps 22136.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31602 | lr 0.000177886 | gnorm 0.813 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 93696
2022-03-07 14:53:04 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 14:53:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:57:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:57:46 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 12.98 | nll_loss 12.195 | ppl 4688.79 | wps 43522.1 | wpb 510.9 | bsz 1 | num_updates 31699 | best_loss 8.481
2022-03-07 14:57:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 31699 updates
2022-03-07 14:57:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:57:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:57:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 329 @ 31699 updates, score 12.98) (writing took 2.2802702109329402 seconds)
2022-03-07 14:57:48 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 14:57:48 | INFO | train | epoch 329 | loss 2.613 | nll_loss 0.77 | ppl 1.7 | wps 22374.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31699 | lr 0.000177614 | gnorm 0.82 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 93980
2022-03-07 14:57:48 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 14:57:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:57:51 | INFO | train_inner | epoch 330:      1 / 97 loss=2.613, nll_loss=0.77, ppl=1.7, wps=21829.4, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=31700, lr=0.000177611, gnorm=0.82, loss_scale=16, train_wall=262, gb_free=8.1, wall=93983
2022-03-07 15:00:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:02:30 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 12.969 | nll_loss 12.184 | ppl 4651.96 | wps 43269 | wpb 510.9 | bsz 1 | num_updates 31795 | best_loss 8.481
2022-03-07 15:02:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 31795 updates
2022-03-07 15:02:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:02:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 330 @ 31795 updates, score 12.969) (writing took 2.337804446928203 seconds)
2022-03-07 15:02:32 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 15:02:32 | INFO | train | epoch 330 | loss 2.611 | nll_loss 0.768 | ppl 1.7 | wps 22137.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31795 | lr 0.000177346 | gnorm 0.813 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 94264
2022-03-07 15:02:32 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 15:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:02:47 | INFO | train_inner | epoch 331:      5 / 97 loss=2.611, nll_loss=0.768, ppl=1.7, wps=22169.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31800, lr=0.000177332, gnorm=0.813, loss_scale=16, train_wall=265, gb_free=8.1, wall=94279
2022-03-07 15:06:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:07:14 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 12.981 | nll_loss 12.188 | ppl 4666.96 | wps 43298.8 | wpb 510.9 | bsz 1 | num_updates 31891 | best_loss 8.481
2022-03-07 15:07:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 31891 updates
2022-03-07 15:07:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:07:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:07:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 331 @ 31891 updates, score 12.981) (writing took 2.3284522029571235 seconds)
2022-03-07 15:07:16 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 15:07:16 | INFO | train | epoch 331 | loss 2.61 | nll_loss 0.767 | ppl 1.7 | wps 22145.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31891 | lr 0.000177079 | gnorm 0.812 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 94548
2022-03-07 15:07:16 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 15:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:07:42 | INFO | train_inner | epoch 332:      9 / 97 loss=2.609, nll_loss=0.766, ppl=1.7, wps=22176.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31900, lr=0.000177054, gnorm=0.811, loss_scale=16, train_wall=265, gb_free=8.1, wall=94574
2022-03-07 15:11:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:11:58 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 12.925 | nll_loss 12.131 | ppl 4486.36 | wps 43263.2 | wpb 510.9 | bsz 1 | num_updates 31988 | best_loss 8.481
2022-03-07 15:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 31988 updates
2022-03-07 15:11:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:12:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:12:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 332 @ 31988 updates, score 12.925) (writing took 2.254475314170122 seconds)
2022-03-07 15:12:00 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 15:12:00 | INFO | train | epoch 332 | loss 2.609 | nll_loss 0.766 | ppl 1.7 | wps 22371.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31988 | lr 0.00017681 | gnorm 0.808 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 94832
2022-03-07 15:12:00 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 15:12:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:12:35 | INFO | train_inner | epoch 333:     12 / 97 loss=2.608, nll_loss=0.765, ppl=1.7, wps=22386.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32000, lr=0.000176777, gnorm=0.807, loss_scale=16, train_wall=262, gb_free=8.1, wall=94866
2022-03-07 15:13:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:16:42 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 12.957 | nll_loss 12.166 | ppl 4595.78 | wps 43068.6 | wpb 510.9 | bsz 1 | num_updates 32084 | best_loss 8.481
2022-03-07 15:16:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 32084 updates
2022-03-07 15:16:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:16:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 333 @ 32084 updates, score 12.957) (writing took 2.3176722782664 seconds)
2022-03-07 15:16:44 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 15:16:44 | INFO | train | epoch 333 | loss 2.608 | nll_loss 0.764 | ppl 1.7 | wps 22136.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32084 | lr 0.000176545 | gnorm 0.81 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 95116
2022-03-07 15:16:44 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 15:16:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:17:30 | INFO | train_inner | epoch 334:     16 / 97 loss=2.607, nll_loss=0.763, ppl=1.7, wps=22172.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32100, lr=0.000176501, gnorm=0.808, loss_scale=16, train_wall=265, gb_free=8.1, wall=95162
2022-03-07 15:19:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:21:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:21:26 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 12.948 | nll_loss 12.158 | ppl 4571.1 | wps 43484.8 | wpb 510.9 | bsz 1 | num_updates 32180 | best_loss 8.481
2022-03-07 15:21:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 32180 updates
2022-03-07 15:21:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:21:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:21:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 334 @ 32180 updates, score 12.948) (writing took 2.2723940503783524 seconds)
2022-03-07 15:21:28 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 15:21:28 | INFO | train | epoch 334 | loss 2.607 | nll_loss 0.764 | ppl 1.7 | wps 22146.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32180 | lr 0.000176282 | gnorm 0.8 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 95400
2022-03-07 15:21:28 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 15:21:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:22:25 | INFO | train_inner | epoch 335:     20 / 97 loss=2.607, nll_loss=0.764, ppl=1.7, wps=22181.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32200, lr=0.000176227, gnorm=0.801, loss_scale=16, train_wall=265, gb_free=8.1, wall=95457
2022-03-07 15:26:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:26:10 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 12.979 | nll_loss 12.192 | ppl 4679.7 | wps 43171.9 | wpb 510.9 | bsz 1 | num_updates 32277 | best_loss 8.481
2022-03-07 15:26:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 32277 updates
2022-03-07 15:26:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:26:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:26:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 335 @ 32277 updates, score 12.979) (writing took 2.246230711694807 seconds)
2022-03-07 15:26:12 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 15:26:12 | INFO | train | epoch 335 | loss 2.606 | nll_loss 0.763 | ppl 1.7 | wps 22382.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32277 | lr 0.000176017 | gnorm 0.807 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 95684
2022-03-07 15:26:12 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 15:26:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:27:18 | INFO | train_inner | epoch 336:     23 / 97 loss=2.605, nll_loss=0.762, ppl=1.7, wps=22394.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32300, lr=0.000175954, gnorm=0.808, loss_scale=32, train_wall=262, gb_free=8.1, wall=95750
2022-03-07 15:27:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:30:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:30:54 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 12.972 | nll_loss 12.189 | ppl 4668.91 | wps 43241.8 | wpb 510.9 | bsz 1 | num_updates 32373 | best_loss 8.481
2022-03-07 15:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 32373 updates
2022-03-07 15:30:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:30:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:30:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 336 @ 32373 updates, score 12.972) (writing took 2.25847042305395 seconds)
2022-03-07 15:30:56 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 15:30:56 | INFO | train | epoch 336 | loss 2.605 | nll_loss 0.762 | ppl 1.7 | wps 22145.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32373 | lr 0.000175755 | gnorm 0.815 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 95968
2022-03-07 15:30:56 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 15:30:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:32:13 | INFO | train_inner | epoch 337:     27 / 97 loss=2.604, nll_loss=0.761, ppl=1.69, wps=22181.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32400, lr=0.000175682, gnorm=0.813, loss_scale=16, train_wall=265, gb_free=8.1, wall=96045
2022-03-07 15:34:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:35:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:35:37 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 12.974 | nll_loss 12.184 | ppl 4654.01 | wps 43200.7 | wpb 510.9 | bsz 1 | num_updates 32469 | best_loss 8.481
2022-03-07 15:35:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 32469 updates
2022-03-07 15:35:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:35:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 337 @ 32469 updates, score 12.974) (writing took 2.2663849662058055 seconds)
2022-03-07 15:35:40 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 15:35:40 | INFO | train | epoch 337 | loss 2.604 | nll_loss 0.761 | ppl 1.69 | wps 22142.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32469 | lr 0.000175495 | gnorm 0.806 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 96252
2022-03-07 15:35:40 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 15:35:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:37:08 | INFO | train_inner | epoch 338:     31 / 97 loss=2.604, nll_loss=0.761, ppl=1.69, wps=22180.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32500, lr=0.000175412, gnorm=0.804, loss_scale=16, train_wall=265, gb_free=8.1, wall=96340
2022-03-07 15:40:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:40:21 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 12.995 | nll_loss 12.207 | ppl 4728.11 | wps 43243.9 | wpb 510.9 | bsz 1 | num_updates 32566 | best_loss 8.481
2022-03-07 15:40:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 32566 updates
2022-03-07 15:40:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:40:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:40:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 338 @ 32566 updates, score 12.995) (writing took 2.2849398548714817 seconds)
2022-03-07 15:40:24 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 15:40:24 | INFO | train | epoch 338 | loss 2.604 | nll_loss 0.761 | ppl 1.69 | wps 22378.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32566 | lr 0.000175234 | gnorm 0.819 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 96536
2022-03-07 15:40:24 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 15:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:42:01 | INFO | train_inner | epoch 339:     34 / 97 loss=2.603, nll_loss=0.76, ppl=1.69, wps=22391.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=32600, lr=0.000175142, gnorm=0.819, loss_scale=32, train_wall=262, gb_free=8.1, wall=96633
2022-03-07 15:43:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:45:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:45:05 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 12.946 | nll_loss 12.158 | ppl 4568.89 | wps 43339.6 | wpb 510.9 | bsz 1 | num_updates 32662 | best_loss 8.481
2022-03-07 15:45:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 32662 updates
2022-03-07 15:45:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:45:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 339 @ 32662 updates, score 12.946) (writing took 2.2605148530565202 seconds)
2022-03-07 15:45:08 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 15:45:08 | INFO | train | epoch 339 | loss 2.6 | nll_loss 0.757 | ppl 1.69 | wps 22146.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32662 | lr 0.000174976 | gnorm 0.801 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 96819
2022-03-07 15:45:08 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 15:45:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:46:56 | INFO | train_inner | epoch 340:     38 / 97 loss=2.599, nll_loss=0.756, ppl=1.69, wps=22176.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=32700, lr=0.000174874, gnorm=0.798, loss_scale=16, train_wall=265, gb_free=8.1, wall=96928
2022-03-07 15:49:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:49:49 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 12.945 | nll_loss 12.157 | ppl 4567.2 | wps 43075.7 | wpb 510.9 | bsz 1 | num_updates 32759 | best_loss 8.481
2022-03-07 15:49:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 32759 updates
2022-03-07 15:49:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:49:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:49:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 340 @ 32759 updates, score 12.945) (writing took 2.27637631399557 seconds)
2022-03-07 15:49:52 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 15:49:52 | INFO | train | epoch 340 | loss 2.601 | nll_loss 0.758 | ppl 1.69 | wps 22369.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32759 | lr 0.000174717 | gnorm 0.809 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 97103
2022-03-07 15:49:52 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 15:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:51:48 | INFO | train_inner | epoch 341:     41 / 97 loss=2.602, nll_loss=0.759, ppl=1.69, wps=22391.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=32800, lr=0.000174608, gnorm=0.809, loss_scale=32, train_wall=262, gb_free=8.1, wall=97220
2022-03-07 15:54:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:54:33 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 12.963 | nll_loss 12.174 | ppl 4620.71 | wps 43199.5 | wpb 510.9 | bsz 1 | num_updates 32855 | best_loss 8.481
2022-03-07 15:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 32855 updates
2022-03-07 15:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 341 @ 32855 updates, score 12.963) (writing took 2.2303929370827973 seconds)
2022-03-07 15:54:35 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 15:54:35 | INFO | train | epoch 341 | loss 2.598 | nll_loss 0.755 | ppl 1.69 | wps 22146 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32855 | lr 0.000174461 | gnorm 0.802 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 97387
2022-03-07 15:54:35 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 15:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:56:44 | INFO | train_inner | epoch 342:     45 / 97 loss=2.596, nll_loss=0.753, ppl=1.69, wps=22179, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32900, lr=0.000174342, gnorm=0.807, loss_scale=16, train_wall=265, gb_free=8.1, wall=97516
2022-03-07 15:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:59:17 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 12.992 | nll_loss 12.205 | ppl 4720.16 | wps 43586.6 | wpb 510.9 | bsz 1 | num_updates 32952 | best_loss 8.481
2022-03-07 15:59:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 32952 updates
2022-03-07 15:59:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:59:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:59:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 342 @ 32952 updates, score 12.992) (writing took 2.2550146216526628 seconds)
2022-03-07 15:59:19 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 15:59:19 | INFO | train | epoch 342 | loss 2.598 | nll_loss 0.755 | ppl 1.69 | wps 22375.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32952 | lr 0.000174204 | gnorm 0.802 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 97671
2022-03-07 15:59:19 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 15:59:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:00:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:01:39 | INFO | train_inner | epoch 343:     49 / 97 loss=2.598, nll_loss=0.755, ppl=1.69, wps=22173.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=33000, lr=0.000174078, gnorm=0.803, loss_scale=16, train_wall=265, gb_free=8.1, wall=97811
2022-03-07 16:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:04:01 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 12.96 | nll_loss 12.171 | ppl 4610.31 | wps 43267.8 | wpb 510.9 | bsz 1 | num_updates 33048 | best_loss 8.481
2022-03-07 16:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 33048 updates
2022-03-07 16:04:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:04:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 343 @ 33048 updates, score 12.96) (writing took 2.2427496085874736 seconds)
2022-03-07 16:04:03 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 16:04:03 | INFO | train | epoch 343 | loss 2.597 | nll_loss 0.754 | ppl 1.69 | wps 22151.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33048 | lr 0.000173951 | gnorm 0.808 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 97955
2022-03-07 16:04:03 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 16:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:06:32 | INFO | train_inner | epoch 344:     52 / 97 loss=2.596, nll_loss=0.753, ppl=1.69, wps=22393.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33100, lr=0.000173814, gnorm=0.799, loss_scale=16, train_wall=262, gb_free=8.1, wall=98104
2022-03-07 16:07:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:08:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:08:45 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.01 | nll_loss 12.226 | ppl 4789.04 | wps 43435.5 | wpb 510.9 | bsz 1 | num_updates 33144 | best_loss 8.481
2022-03-07 16:08:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 33144 updates
2022-03-07 16:08:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:08:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:08:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 344 @ 33144 updates, score 13.01) (writing took 2.2578198690898716 seconds)
2022-03-07 16:08:47 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 16:08:47 | INFO | train | epoch 344 | loss 2.595 | nll_loss 0.753 | ppl 1.68 | wps 22138.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33144 | lr 0.000173699 | gnorm 0.806 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 98239
2022-03-07 16:08:47 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 16:08:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:11:27 | INFO | train_inner | epoch 345:     56 / 97 loss=2.597, nll_loss=0.754, ppl=1.69, wps=22171.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33200, lr=0.000173553, gnorm=0.816, loss_scale=16, train_wall=265, gb_free=8.1, wall=98399
2022-03-07 16:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:13:29 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 12.988 | nll_loss 12.2 | ppl 4703.84 | wps 43156.2 | wpb 510.9 | bsz 1 | num_updates 33241 | best_loss 8.481
2022-03-07 16:13:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 33241 updates
2022-03-07 16:13:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:13:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:13:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 345 @ 33241 updates, score 12.988) (writing took 2.285504219122231 seconds)
2022-03-07 16:13:31 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 16:13:31 | INFO | train | epoch 345 | loss 2.595 | nll_loss 0.752 | ppl 1.68 | wps 22372 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33241 | lr 0.000173445 | gnorm 0.803 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 98523
2022-03-07 16:13:31 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 16:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:16:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:16:22 | INFO | train_inner | epoch 346:     60 / 97 loss=2.594, nll_loss=0.751, ppl=1.68, wps=22168.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=33300, lr=0.000173292, gnorm=0.795, loss_scale=16, train_wall=265, gb_free=8.1, wall=98694
2022-03-07 16:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:18:13 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 12.994 | nll_loss 12.21 | ppl 4736.65 | wps 43153.9 | wpb 510.9 | bsz 1 | num_updates 33337 | best_loss 8.481
2022-03-07 16:18:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 33337 updates
2022-03-07 16:18:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:18:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:18:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 346 @ 33337 updates, score 12.994) (writing took 2.2425956139340997 seconds)
2022-03-07 16:18:15 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 16:18:15 | INFO | train | epoch 346 | loss 2.594 | nll_loss 0.752 | ppl 1.68 | wps 22137.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33337 | lr 0.000173196 | gnorm 0.806 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 98807
2022-03-07 16:18:15 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 16:18:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:21:15 | INFO | train_inner | epoch 347:     63 / 97 loss=2.593, nll_loss=0.75, ppl=1.68, wps=22395.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33400, lr=0.000173032, gnorm=0.81, loss_scale=16, train_wall=262, gb_free=8.1, wall=98987
2022-03-07 16:22:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:22:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:22:57 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 12.975 | nll_loss 12.192 | ppl 4679.2 | wps 43227.7 | wpb 510.9 | bsz 1 | num_updates 33433 | best_loss 8.481
2022-03-07 16:22:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 33433 updates
2022-03-07 16:22:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:22:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:22:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 347 @ 33433 updates, score 12.975) (writing took 2.2822959651239216 seconds)
2022-03-07 16:22:59 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 16:22:59 | INFO | train | epoch 347 | loss 2.593 | nll_loss 0.75 | ppl 1.68 | wps 22148 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33433 | lr 0.000172947 | gnorm 0.811 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 99091
2022-03-07 16:22:59 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 16:22:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:26:10 | INFO | train_inner | epoch 348:     67 / 97 loss=2.592, nll_loss=0.749, ppl=1.68, wps=22176.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=33500, lr=0.000172774, gnorm=0.804, loss_scale=16, train_wall=265, gb_free=8.1, wall=99282
2022-03-07 16:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:27:41 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 12.951 | nll_loss 12.163 | ppl 4586.8 | wps 43221.7 | wpb 510.9 | bsz 1 | num_updates 33530 | best_loss 8.481
2022-03-07 16:27:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 33530 updates
2022-03-07 16:27:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:27:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:27:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 348 @ 33530 updates, score 12.951) (writing took 2.255668807774782 seconds)
2022-03-07 16:27:43 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 16:27:43 | INFO | train | epoch 348 | loss 2.591 | nll_loss 0.748 | ppl 1.68 | wps 22374.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33530 | lr 0.000172696 | gnorm 0.796 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 99375
2022-03-07 16:27:43 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 16:27:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:29:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:31:05 | INFO | train_inner | epoch 349:     71 / 97 loss=2.591, nll_loss=0.748, ppl=1.68, wps=22180.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33600, lr=0.000172516, gnorm=0.807, loss_scale=16, train_wall=265, gb_free=8.1, wall=99577
2022-03-07 16:32:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:32:24 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 12.973 | nll_loss 12.19 | ppl 4673.26 | wps 43564.8 | wpb 510.9 | bsz 1 | num_updates 33626 | best_loss 8.481
2022-03-07 16:32:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 33626 updates
2022-03-07 16:32:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:32:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:32:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 349 @ 33626 updates, score 12.973) (writing took 2.3003549119457603 seconds)
2022-03-07 16:32:27 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 16:32:27 | INFO | train | epoch 349 | loss 2.59 | nll_loss 0.748 | ppl 1.68 | wps 22147.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33626 | lr 0.00017245 | gnorm 0.804 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 99659
2022-03-07 16:32:27 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 16:32:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:35:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:36:01 | INFO | train_inner | epoch 350:     75 / 97 loss=2.591, nll_loss=0.748, ppl=1.68, wps=22179.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33700, lr=0.00017226, gnorm=0.808, loss_scale=16, train_wall=265, gb_free=8.1, wall=99873
2022-03-07 16:37:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:37:08 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.052 | nll_loss 12.273 | ppl 4949.23 | wps 43319.1 | wpb 510.9 | bsz 1 | num_updates 33722 | best_loss 8.481
2022-03-07 16:37:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 33722 updates
2022-03-07 16:37:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:37:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:37:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 350 @ 33722 updates, score 13.052) (writing took 2.285998093895614 seconds)
2022-03-07 16:37:11 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 16:37:11 | INFO | train | epoch 350 | loss 2.59 | nll_loss 0.747 | ppl 1.68 | wps 22143 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33722 | lr 0.000172204 | gnorm 0.812 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 99943
2022-03-07 16:37:11 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 16:37:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:40:53 | INFO | train_inner | epoch 351:     78 / 97 loss=2.589, nll_loss=0.746, ppl=1.68, wps=22396.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=33800, lr=0.000172005, gnorm=0.798, loss_scale=16, train_wall=262, gb_free=8.1, wall=100165
2022-03-07 16:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:41:52 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 12.984 | nll_loss 12.197 | ppl 4694.06 | wps 43101.2 | wpb 510.9 | bsz 1 | num_updates 33819 | best_loss 8.481
2022-03-07 16:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 33819 updates
2022-03-07 16:41:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:41:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 351 @ 33819 updates, score 12.984) (writing took 2.2457119720056653 seconds)
2022-03-07 16:41:55 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 16:41:55 | INFO | train | epoch 351 | loss 2.588 | nll_loss 0.745 | ppl 1.68 | wps 22377.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33819 | lr 0.000171957 | gnorm 0.797 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 100226
2022-03-07 16:41:55 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 16:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:42:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:45:49 | INFO | train_inner | epoch 352:     82 / 97 loss=2.588, nll_loss=0.745, ppl=1.68, wps=22174.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33900, lr=0.000171751, gnorm=0.801, loss_scale=16, train_wall=265, gb_free=8.1, wall=100460
2022-03-07 16:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:46:36 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 12.97 | nll_loss 12.183 | ppl 4649.77 | wps 43448.4 | wpb 510.9 | bsz 1 | num_updates 33915 | best_loss 8.481
2022-03-07 16:46:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 33915 updates
2022-03-07 16:46:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:46:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:46:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 352 @ 33915 updates, score 12.97) (writing took 2.2394070541486144 seconds)
2022-03-07 16:46:38 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 16:46:38 | INFO | train | epoch 352 | loss 2.587 | nll_loss 0.744 | ppl 1.68 | wps 22152.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33915 | lr 0.000171713 | gnorm 0.799 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 100510
2022-03-07 16:46:38 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 16:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:50:41 | INFO | train_inner | epoch 353:     85 / 97 loss=2.587, nll_loss=0.745, ppl=1.68, wps=22399.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34000, lr=0.000171499, gnorm=0.796, loss_scale=32, train_wall=262, gb_free=8.1, wall=100753
2022-03-07 16:51:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:51:20 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 12.943 | nll_loss 12.156 | ppl 4565.15 | wps 43397.9 | wpb 510.9 | bsz 1 | num_updates 34012 | best_loss 8.481
2022-03-07 16:51:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 34012 updates
2022-03-07 16:51:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:51:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:51:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 353 @ 34012 updates, score 12.943) (writing took 2.2480160840786994 seconds)
2022-03-07 16:51:22 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 16:51:22 | INFO | train | epoch 353 | loss 2.587 | nll_loss 0.744 | ppl 1.68 | wps 22379.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34012 | lr 0.000171468 | gnorm 0.797 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 100794
2022-03-07 16:51:22 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 16:51:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:52:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:55:36 | INFO | train_inner | epoch 354:     89 / 97 loss=2.586, nll_loss=0.744, ppl=1.67, wps=22184.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34100, lr=0.000171247, gnorm=0.81, loss_scale=16, train_wall=265, gb_free=8.1, wall=101048
2022-03-07 16:55:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:56:04 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 12.934 | nll_loss 12.143 | ppl 4523.09 | wps 43327.5 | wpb 510.9 | bsz 1 | num_updates 34108 | best_loss 8.481
2022-03-07 16:56:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 34108 updates
2022-03-07 16:56:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:56:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:56:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 354 @ 34108 updates, score 12.934) (writing took 2.208389556966722 seconds)
2022-03-07 16:56:06 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 16:56:06 | INFO | train | epoch 354 | loss 2.586 | nll_loss 0.743 | ppl 1.67 | wps 22154 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34108 | lr 0.000171227 | gnorm 0.813 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 101078
2022-03-07 16:56:06 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 16:56:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:00:29 | INFO | train_inner | epoch 355:     92 / 97 loss=2.585, nll_loss=0.743, ppl=1.67, wps=22395.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34200, lr=0.000170996, gnorm=0.803, loss_scale=32, train_wall=262, gb_free=8.1, wall=101340
2022-03-07 17:00:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:00:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:00:48 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 12.99 | nll_loss 12.207 | ppl 4728.83 | wps 43274.5 | wpb 510.9 | bsz 1 | num_updates 34204 | best_loss 8.481
2022-03-07 17:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 34204 updates
2022-03-07 17:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 355 @ 34204 updates, score 12.99) (writing took 2.235327106900513 seconds)
2022-03-07 17:00:50 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 17:00:50 | INFO | train | epoch 355 | loss 2.584 | nll_loss 0.741 | ppl 1.67 | wps 22145.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34204 | lr 0.000170986 | gnorm 0.802 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 101362
2022-03-07 17:00:50 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 17:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:05:24 | INFO | train_inner | epoch 356:     96 / 97 loss=2.584, nll_loss=0.741, ppl=1.67, wps=22179.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34300, lr=0.000170747, gnorm=0.804, loss_scale=16, train_wall=265, gb_free=8.1, wall=101636
2022-03-07 17:05:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:05:32 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 12.922 | nll_loss 12.137 | ppl 4504.34 | wps 43390.6 | wpb 510.9 | bsz 1 | num_updates 34301 | best_loss 8.481
2022-03-07 17:05:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 34301 updates
2022-03-07 17:05:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:05:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:05:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 356 @ 34301 updates, score 12.922) (writing took 2.1542724813334644 seconds)
2022-03-07 17:05:34 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 17:05:34 | INFO | train | epoch 356 | loss 2.583 | nll_loss 0.741 | ppl 1.67 | wps 22385.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34301 | lr 0.000170744 | gnorm 0.801 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 101646
2022-03-07 17:05:34 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 17:05:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:07:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:10:15 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.004 | nll_loss 12.226 | ppl 4790.97 | wps 43489.6 | wpb 510.9 | bsz 1 | num_updates 34397 | best_loss 8.481
2022-03-07 17:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 34397 updates
2022-03-07 17:10:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:10:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:10:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 357 @ 34397 updates, score 13.004) (writing took 2.2176512172445655 seconds)
2022-03-07 17:10:18 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 17:10:18 | INFO | train | epoch 357 | loss 2.582 | nll_loss 0.739 | ppl 1.67 | wps 22141.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34397 | lr 0.000170506 | gnorm 0.796 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 101930
2022-03-07 17:10:18 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 17:10:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:10:26 | INFO | train_inner | epoch 358:      3 / 97 loss=2.581, nll_loss=0.738, ppl=1.67, wps=21637.5, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=34400, lr=0.000170499, gnorm=0.795, loss_scale=16, train_wall=265, gb_free=8.1, wall=101938
2022-03-07 17:13:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:14:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:14:59 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.012 | nll_loss 12.234 | ppl 4817.26 | wps 43140.1 | wpb 510.9 | bsz 1 | num_updates 34493 | best_loss 8.481
2022-03-07 17:14:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 34493 updates
2022-03-07 17:14:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:15:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:15:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 358 @ 34493 updates, score 13.012) (writing took 2.2031892221421003 seconds)
2022-03-07 17:15:01 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 17:15:01 | INFO | train | epoch 358 | loss 2.581 | nll_loss 0.738 | ppl 1.67 | wps 22159.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34493 | lr 0.000170269 | gnorm 0.792 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 102213
2022-03-07 17:15:01 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 17:15:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:15:22 | INFO | train_inner | epoch 359:      7 / 97 loss=2.581, nll_loss=0.738, ppl=1.67, wps=22187, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34500, lr=0.000170251, gnorm=0.792, loss_scale=16, train_wall=265, gb_free=8.1, wall=102233
2022-03-07 17:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:19:43 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.001 | nll_loss 12.224 | ppl 4783.79 | wps 43565.2 | wpb 510.9 | bsz 1 | num_updates 34590 | best_loss 8.481
2022-03-07 17:19:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 34590 updates
2022-03-07 17:19:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:19:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:19:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 359 @ 34590 updates, score 13.001) (writing took 2.2532018590718508 seconds)
2022-03-07 17:19:45 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 17:19:45 | INFO | train | epoch 359 | loss 2.58 | nll_loss 0.738 | ppl 1.67 | wps 22367 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34590 | lr 0.00017003 | gnorm 0.789 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 102497
2022-03-07 17:19:45 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 17:19:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:20:14 | INFO | train_inner | epoch 360:     10 / 97 loss=2.579, nll_loss=0.736, ppl=1.67, wps=22389.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34600, lr=0.000170005, gnorm=0.79, loss_scale=32, train_wall=262, gb_free=8.1, wall=102526
2022-03-07 17:20:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:24:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:24:27 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.016 | nll_loss 12.241 | ppl 4840.18 | wps 43224.5 | wpb 510.9 | bsz 1 | num_updates 34686 | best_loss 8.481
2022-03-07 17:24:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 34686 updates
2022-03-07 17:24:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:24:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:24:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 360 @ 34686 updates, score 13.016) (writing took 2.200398704968393 seconds)
2022-03-07 17:24:29 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 17:24:29 | INFO | train | epoch 360 | loss 2.579 | nll_loss 0.737 | ppl 1.67 | wps 22142 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34686 | lr 0.000169794 | gnorm 0.804 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 102781
2022-03-07 17:24:29 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 17:24:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:25:09 | INFO | train_inner | epoch 361:     14 / 97 loss=2.578, nll_loss=0.736, ppl=1.67, wps=22176.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34700, lr=0.00016976, gnorm=0.8, loss_scale=16, train_wall=265, gb_free=8.1, wall=102821
2022-03-07 17:28:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:29:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:29:11 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.056 | nll_loss 12.276 | ppl 4958.48 | wps 43341.5 | wpb 510.9 | bsz 1 | num_updates 34782 | best_loss 8.481
2022-03-07 17:29:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 34782 updates
2022-03-07 17:29:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:29:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:29:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 361 @ 34782 updates, score 13.056) (writing took 2.2036089566536248 seconds)
2022-03-07 17:29:13 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 17:29:13 | INFO | train | epoch 361 | loss 2.578 | nll_loss 0.736 | ppl 1.67 | wps 22156.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34782 | lr 0.00016956 | gnorm 0.795 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 103065
2022-03-07 17:29:13 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 17:29:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:30:05 | INFO | train_inner | epoch 362:     18 / 97 loss=2.578, nll_loss=0.736, ppl=1.67, wps=22186.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34800, lr=0.000169516, gnorm=0.799, loss_scale=16, train_wall=265, gb_free=8.1, wall=103116
2022-03-07 17:33:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:33:55 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 12.904 | nll_loss 12.114 | ppl 4432.08 | wps 43195.4 | wpb 510.9 | bsz 1 | num_updates 34879 | best_loss 8.481
2022-03-07 17:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 34879 updates
2022-03-07 17:33:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:33:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 362 @ 34879 updates, score 12.904) (writing took 2.216342276893556 seconds)
2022-03-07 17:33:57 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 17:33:57 | INFO | train | epoch 362 | loss 2.577 | nll_loss 0.734 | ppl 1.66 | wps 22373.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34879 | lr 0.000169324 | gnorm 0.801 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 103349
2022-03-07 17:33:57 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 17:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:34:57 | INFO | train_inner | epoch 363:     21 / 97 loss=2.576, nll_loss=0.734, ppl=1.66, wps=22393.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34900, lr=0.000169273, gnorm=0.801, loss_scale=32, train_wall=262, gb_free=8.1, wall=103409
2022-03-07 17:37:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:38:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:38:39 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.028 | nll_loss 12.258 | ppl 4898.96 | wps 43158.2 | wpb 510.9 | bsz 1 | num_updates 34975 | best_loss 8.481
2022-03-07 17:38:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 34975 updates
2022-03-07 17:38:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:38:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:38:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 363 @ 34975 updates, score 13.028) (writing took 2.161084581166506 seconds)
2022-03-07 17:38:41 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 17:38:41 | INFO | train | epoch 363 | loss 2.576 | nll_loss 0.734 | ppl 1.66 | wps 22156.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34975 | lr 0.000169091 | gnorm 0.8 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 103633
2022-03-07 17:38:41 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 17:38:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:39:52 | INFO | train_inner | epoch 364:     25 / 97 loss=2.576, nll_loss=0.734, ppl=1.66, wps=22186.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35000, lr=0.000169031, gnorm=0.802, loss_scale=16, train_wall=265, gb_free=8.1, wall=103704
2022-03-07 17:43:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:43:22 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 12.989 | nll_loss 12.21 | ppl 4737.23 | wps 43305.7 | wpb 510.9 | bsz 1 | num_updates 35072 | best_loss 8.481
2022-03-07 17:43:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 35072 updates
2022-03-07 17:43:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:43:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 364 @ 35072 updates, score 12.989) (writing took 2.2167241163551807 seconds)
2022-03-07 17:43:25 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 17:43:25 | INFO | train | epoch 364 | loss 2.575 | nll_loss 0.733 | ppl 1.66 | wps 22380.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35072 | lr 0.000168857 | gnorm 0.795 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 103917
2022-03-07 17:43:25 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 17:43:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:44:45 | INFO | train_inner | epoch 365:     28 / 97 loss=2.574, nll_loss=0.732, ppl=1.66, wps=22397.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35100, lr=0.00016879, gnorm=0.788, loss_scale=32, train_wall=263, gb_free=8.1, wall=103997
2022-03-07 17:45:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:48:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:48:06 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.019 | nll_loss 12.239 | ppl 4832.97 | wps 43172.1 | wpb 510.9 | bsz 1 | num_updates 35168 | best_loss 8.481
2022-03-07 17:48:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 35168 updates
2022-03-07 17:48:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:48:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:48:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 365 @ 35168 updates, score 13.019) (writing took 2.1931016221642494 seconds)
2022-03-07 17:48:08 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 17:48:08 | INFO | train | epoch 365 | loss 2.575 | nll_loss 0.733 | ppl 1.66 | wps 22153.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35168 | lr 0.000168627 | gnorm 0.795 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 104200
2022-03-07 17:48:09 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 17:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:49:40 | INFO | train_inner | epoch 366:     32 / 97 loss=2.575, nll_loss=0.732, ppl=1.66, wps=22187.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35200, lr=0.00016855, gnorm=0.801, loss_scale=16, train_wall=265, gb_free=8.1, wall=104292
2022-03-07 17:51:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:52:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:52:50 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.019 | nll_loss 12.244 | ppl 4849.75 | wps 43282.9 | wpb 510.9 | bsz 1 | num_updates 35264 | best_loss 8.481
2022-03-07 17:52:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 35264 updates
2022-03-07 17:52:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:52:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:52:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 366 @ 35264 updates, score 13.019) (writing took 7.867313061840832 seconds)
2022-03-07 17:52:58 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 17:52:58 | INFO | train | epoch 366 | loss 2.573 | nll_loss 0.731 | ppl 1.66 | wps 21722.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 35264 | lr 0.000168397 | gnorm 0.8 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 104490
2022-03-07 17:52:58 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 17:52:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:54:41 | INFO | train_inner | epoch 367:     36 / 97 loss=2.572, nll_loss=0.73, ppl=1.66, wps=21769.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=35300, lr=0.000168311, gnorm=0.794, loss_scale=16, train_wall=265, gb_free=8.1, wall=104593
2022-03-07 17:57:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:57:40 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 12.983 | nll_loss 12.203 | ppl 4714.15 | wps 43484.5 | wpb 510.9 | bsz 1 | num_updates 35361 | best_loss 8.481
2022-03-07 17:57:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 35361 updates
2022-03-07 17:57:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:57:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 367 @ 35361 updates, score 12.983) (writing took 2.2063209861516953 seconds)
2022-03-07 17:57:42 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 17:57:42 | INFO | train | epoch 367 | loss 2.574 | nll_loss 0.731 | ppl 1.66 | wps 22384.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35361 | lr 0.000168166 | gnorm 0.807 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 104774
2022-03-07 17:57:42 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 17:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:58:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:59:37 | INFO | train_inner | epoch 368:     40 / 97 loss=2.573, nll_loss=0.731, ppl=1.66, wps=22125.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35400, lr=0.000168073, gnorm=0.809, loss_scale=16, train_wall=266, gb_free=8.1, wall=104889
2022-03-07 18:02:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:02:24 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.012 | nll_loss 12.235 | ppl 4820.54 | wps 42794.9 | wpb 510.9 | bsz 1 | num_updates 35457 | best_loss 8.481
2022-03-07 18:02:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 35457 updates
2022-03-07 18:02:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:02:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:02:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 368 @ 35457 updates, score 13.012) (writing took 2.2206117711029947 seconds)
2022-03-07 18:02:27 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 18:02:27 | INFO | train | epoch 368 | loss 2.571 | nll_loss 0.729 | ppl 1.66 | wps 22073.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35457 | lr 0.000167938 | gnorm 0.794 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 105058
2022-03-07 18:02:27 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 18:02:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:04:29 | INFO | train_inner | epoch 369:     43 / 97 loss=2.573, nll_loss=0.731, ppl=1.66, wps=22370.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35500, lr=0.000167836, gnorm=0.793, loss_scale=16, train_wall=263, gb_free=8.1, wall=105181
2022-03-07 18:05:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:07:08 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 12.97 | nll_loss 12.193 | ppl 4682.22 | wps 43226.1 | wpb 510.9 | bsz 1 | num_updates 35553 | best_loss 8.481
2022-03-07 18:07:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 35553 updates
2022-03-07 18:07:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:07:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:07:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 369 @ 35553 updates, score 12.97) (writing took 2.2106950441375375 seconds)
2022-03-07 18:07:11 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 18:07:11 | INFO | train | epoch 369 | loss 2.572 | nll_loss 0.729 | ppl 1.66 | wps 22133 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35553 | lr 0.000167711 | gnorm 0.797 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 105343
2022-03-07 18:07:11 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 18:07:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:09:25 | INFO | train_inner | epoch 370:     47 / 97 loss=2.571, nll_loss=0.729, ppl=1.66, wps=22165.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35600, lr=0.0001676, gnorm=0.805, loss_scale=16, train_wall=265, gb_free=8.1, wall=105477
2022-03-07 18:11:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:11:53 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.008 | nll_loss 12.23 | ppl 4805.13 | wps 43239.5 | wpb 510.9 | bsz 1 | num_updates 35650 | best_loss 8.481
2022-03-07 18:11:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 35650 updates
2022-03-07 18:11:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:11:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:11:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 370 @ 35650 updates, score 13.008) (writing took 2.2158000729978085 seconds)
2022-03-07 18:11:55 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 18:11:55 | INFO | train | epoch 370 | loss 2.57 | nll_loss 0.728 | ppl 1.66 | wps 22357.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35650 | lr 0.000167483 | gnorm 0.797 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 105627
2022-03-07 18:11:55 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 18:11:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:14:18 | INFO | train_inner | epoch 371:     50 / 97 loss=2.568, nll_loss=0.726, ppl=1.65, wps=22375, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=35700, lr=0.000167365, gnorm=0.776, loss_scale=32, train_wall=263, gb_free=8.1, wall=105770
2022-03-07 18:15:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:16:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:16:37 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 12.999 | nll_loss 12.223 | ppl 4780.11 | wps 42978.2 | wpb 510.9 | bsz 1 | num_updates 35746 | best_loss 8.481
2022-03-07 18:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 35746 updates
2022-03-07 18:16:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:16:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:16:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 371 @ 35746 updates, score 12.999) (writing took 2.1762113608419895 seconds)
2022-03-07 18:16:39 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 18:16:39 | INFO | train | epoch 371 | loss 2.568 | nll_loss 0.726 | ppl 1.65 | wps 22140.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35746 | lr 0.000167258 | gnorm 0.782 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 105911
2022-03-07 18:16:39 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 18:16:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:19:13 | INFO | train_inner | epoch 372:     54 / 97 loss=2.568, nll_loss=0.726, ppl=1.65, wps=22164.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=35800, lr=0.000167132, gnorm=0.8, loss_scale=16, train_wall=265, gb_free=8.1, wall=106065
2022-03-07 18:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:21:21 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.008 | nll_loss 12.229 | ppl 4802.18 | wps 42891.6 | wpb 510.9 | bsz 1 | num_updates 35843 | best_loss 8.481
2022-03-07 18:21:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 35843 updates
2022-03-07 18:21:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 372 @ 35843 updates, score 13.008) (writing took 2.3459098949097097 seconds)
2022-03-07 18:21:23 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 18:21:23 | INFO | train | epoch 372 | loss 2.569 | nll_loss 0.727 | ppl 1.66 | wps 22316.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35843 | lr 0.000167031 | gnorm 0.804 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 106195
2022-03-07 18:21:23 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 18:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:23:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:24:09 | INFO | train_inner | epoch 373:     58 / 97 loss=2.569, nll_loss=0.727, ppl=1.65, wps=22119.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=35900, lr=0.000166899, gnorm=0.805, loss_scale=16, train_wall=266, gb_free=8.1, wall=106361
2022-03-07 18:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:26:05 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 12.951 | nll_loss 12.169 | ppl 4603.98 | wps 43306.7 | wpb 510.9 | bsz 1 | num_updates 35939 | best_loss 8.481
2022-03-07 18:26:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 35939 updates
2022-03-07 18:26:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:26:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:26:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 373 @ 35939 updates, score 12.951) (writing took 2.1962099368683994 seconds)
2022-03-07 18:26:08 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 18:26:08 | INFO | train | epoch 373 | loss 2.567 | nll_loss 0.725 | ppl 1.65 | wps 22119.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35939 | lr 0.000166808 | gnorm 0.802 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 106480
2022-03-07 18:26:08 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 18:26:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:29:02 | INFO | train_inner | epoch 374:     61 / 97 loss=2.566, nll_loss=0.724, ppl=1.65, wps=22368.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=36000, lr=0.000166667, gnorm=0.787, loss_scale=16, train_wall=263, gb_free=8.1, wall=106654
2022-03-07 18:30:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:30:50 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.027 | nll_loss 12.248 | ppl 4862.92 | wps 43321.5 | wpb 510.9 | bsz 1 | num_updates 36035 | best_loss 8.481
2022-03-07 18:30:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 36035 updates
2022-03-07 18:30:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 374 @ 36035 updates, score 13.027) (writing took 2.237382892984897 seconds)
2022-03-07 18:30:52 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 18:30:52 | INFO | train | epoch 374 | loss 2.566 | nll_loss 0.724 | ppl 1.65 | wps 22119 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36035 | lr 0.000166586 | gnorm 0.79 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 106764
2022-03-07 18:30:52 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 18:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:33:58 | INFO | train_inner | epoch 375:     65 / 97 loss=2.565, nll_loss=0.723, ppl=1.65, wps=22160.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36100, lr=0.000166436, gnorm=0.794, loss_scale=16, train_wall=265, gb_free=8.1, wall=106949
2022-03-07 18:35:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:35:34 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.016 | nll_loss 12.24 | ppl 4838.8 | wps 42721.8 | wpb 510.9 | bsz 1 | num_updates 36132 | best_loss 8.481
2022-03-07 18:35:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 36132 updates
2022-03-07 18:35:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:35:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 375 @ 36132 updates, score 13.016) (writing took 2.2647816510871053 seconds)
2022-03-07 18:35:36 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 18:35:36 | INFO | train | epoch 375 | loss 2.565 | nll_loss 0.723 | ppl 1.65 | wps 22357.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36132 | lr 0.000166362 | gnorm 0.794 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 107048
2022-03-07 18:35:36 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 18:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:37:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:38:53 | INFO | train_inner | epoch 376:     69 / 97 loss=2.565, nll_loss=0.723, ppl=1.65, wps=22135.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36200, lr=0.000166206, gnorm=0.794, loss_scale=16, train_wall=266, gb_free=8.1, wall=107245
2022-03-07 18:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:40:18 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.03 | nll_loss 12.259 | ppl 4899.98 | wps 43048.7 | wpb 510.9 | bsz 1 | num_updates 36228 | best_loss 8.481
2022-03-07 18:40:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 36228 updates
2022-03-07 18:40:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:40:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:40:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 376 @ 36228 updates, score 13.03) (writing took 2.160789310000837 seconds)
2022-03-07 18:40:21 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 18:40:21 | INFO | train | epoch 376 | loss 2.564 | nll_loss 0.722 | ppl 1.65 | wps 22099.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36228 | lr 0.000166141 | gnorm 0.792 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 107332
2022-03-07 18:40:21 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 18:40:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:43:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:43:49 | INFO | train_inner | epoch 377:     73 / 97 loss=2.564, nll_loss=0.722, ppl=1.65, wps=22143.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=36300, lr=0.000165977, gnorm=0.789, loss_scale=16, train_wall=265, gb_free=8.1, wall=107541
2022-03-07 18:44:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:45:03 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.048 | nll_loss 12.273 | ppl 4950.47 | wps 43395.6 | wpb 510.9 | bsz 1 | num_updates 36324 | best_loss 8.481
2022-03-07 18:45:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 36324 updates
2022-03-07 18:45:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:45:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:45:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 377 @ 36324 updates, score 13.048) (writing took 2.238435270730406 seconds)
2022-03-07 18:45:05 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 18:45:05 | INFO | train | epoch 377 | loss 2.563 | nll_loss 0.721 | ppl 1.65 | wps 22118.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36324 | lr 0.000165922 | gnorm 0.788 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 107617
2022-03-07 18:45:05 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 18:45:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:48:42 | INFO | train_inner | epoch 378:     76 / 97 loss=2.562, nll_loss=0.72, ppl=1.65, wps=22383.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36400, lr=0.000165748, gnorm=0.791, loss_scale=16, train_wall=263, gb_free=8.1, wall=107834
2022-03-07 18:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:49:47 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.047 | nll_loss 12.277 | ppl 4963.27 | wps 43272.8 | wpb 510.9 | bsz 1 | num_updates 36421 | best_loss 8.481
2022-03-07 18:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 36421 updates
2022-03-07 18:49:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:49:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:49:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 378 @ 36421 updates, score 13.047) (writing took 2.2627804880030453 seconds)
2022-03-07 18:49:49 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 18:49:49 | INFO | train | epoch 378 | loss 2.562 | nll_loss 0.719 | ppl 1.65 | wps 22360.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36421 | lr 0.000165701 | gnorm 0.788 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 107901
2022-03-07 18:49:49 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 18:49:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:51:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:53:37 | INFO | train_inner | epoch 379:     80 / 97 loss=2.563, nll_loss=0.721, ppl=1.65, wps=22165.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36500, lr=0.000165521, gnorm=0.795, loss_scale=16, train_wall=265, gb_free=8.1, wall=108129
2022-03-07 18:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:54:31 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 12.999 | nll_loss 12.223 | ppl 4782.18 | wps 43454.3 | wpb 510.9 | bsz 1 | num_updates 36517 | best_loss 8.481
2022-03-07 18:54:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 36517 updates
2022-03-07 18:54:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:54:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:54:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 379 @ 36517 updates, score 12.999) (writing took 2.2290194146335125 seconds)
2022-03-07 18:54:33 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 18:54:33 | INFO | train | epoch 379 | loss 2.562 | nll_loss 0.72 | ppl 1.65 | wps 22134.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36517 | lr 0.000165483 | gnorm 0.795 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 108185
2022-03-07 18:54:33 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 18:54:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:58:30 | INFO | train_inner | epoch 380:     83 / 97 loss=2.56, nll_loss=0.719, ppl=1.65, wps=22370.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36600, lr=0.000165295, gnorm=0.785, loss_scale=32, train_wall=263, gb_free=8.1, wall=108422
2022-03-07 18:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:59:15 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 12.944 | nll_loss 12.159 | ppl 4574.04 | wps 42834 | wpb 510.9 | bsz 1 | num_updates 36614 | best_loss 8.481
2022-03-07 18:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 36614 updates
2022-03-07 18:59:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:59:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 380 @ 36614 updates, score 12.944) (writing took 2.3201542431488633 seconds)
2022-03-07 18:59:17 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 18:59:17 | INFO | train | epoch 380 | loss 2.561 | nll_loss 0.719 | ppl 1.65 | wps 22345 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36614 | lr 0.000165263 | gnorm 0.785 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 108469
2022-03-07 18:59:17 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 18:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:59:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:03:27 | INFO | train_inner | epoch 381:     87 / 97 loss=2.561, nll_loss=0.719, ppl=1.65, wps=22061.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36700, lr=0.00016507, gnorm=0.787, loss_scale=16, train_wall=266, gb_free=8.1, wall=108719
2022-03-07 19:03:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:04:00 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.015 | nll_loss 12.241 | ppl 4841.88 | wps 42328.5 | wpb 510.9 | bsz 1 | num_updates 36710 | best_loss 8.481
2022-03-07 19:04:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 36710 updates
2022-03-07 19:04:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:04:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 381 @ 36710 updates, score 13.015) (writing took 2.2398588731884956 seconds)
2022-03-07 19:04:03 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 19:04:03 | INFO | train | epoch 381 | loss 2.559 | nll_loss 0.717 | ppl 1.64 | wps 22017.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36710 | lr 0.000165047 | gnorm 0.786 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 108755
2022-03-07 19:04:03 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 19:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:06:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:08:23 | INFO | train_inner | epoch 382:     91 / 97 loss=2.559, nll_loss=0.718, ppl=1.64, wps=22085.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36800, lr=0.000164845, gnorm=0.785, loss_scale=16, train_wall=266, gb_free=8.1, wall=109015
2022-03-07 19:08:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:08:46 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.006 | nll_loss 12.227 | ppl 4795.56 | wps 42428 | wpb 510.9 | bsz 1 | num_updates 36806 | best_loss 8.481
2022-03-07 19:08:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 36806 updates
2022-03-07 19:08:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:08:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:08:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 382 @ 36806 updates, score 13.006) (writing took 2.320165373850614 seconds)
2022-03-07 19:08:48 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 19:08:48 | INFO | train | epoch 382 | loss 2.559 | nll_loss 0.717 | ppl 1.64 | wps 22038.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36806 | lr 0.000164832 | gnorm 0.784 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 109040
2022-03-07 19:08:48 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 19:08:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:12:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:13:21 | INFO | train_inner | epoch 383:     95 / 97 loss=2.559, nll_loss=0.718, ppl=1.64, wps=22041, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36900, lr=0.000164622, gnorm=0.793, loss_scale=16, train_wall=266, gb_free=8.1, wall=109312
2022-03-07 19:13:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:13:31 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 12.944 | nll_loss 12.164 | ppl 4590.04 | wps 42745.4 | wpb 510.9 | bsz 1 | num_updates 36902 | best_loss 8.481
2022-03-07 19:13:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 36902 updates
2022-03-07 19:13:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:13:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:13:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 383 @ 36902 updates, score 12.944) (writing took 2.233720686752349 seconds)
2022-03-07 19:13:33 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 19:13:33 | INFO | train | epoch 383 | loss 2.558 | nll_loss 0.717 | ppl 1.64 | wps 22024 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36902 | lr 0.000164617 | gnorm 0.791 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 109325
2022-03-07 19:13:34 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 19:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:18:17 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 12.977 | nll_loss 12.198 | ppl 4697.79 | wps 42625.8 | wpb 510.9 | bsz 1 | num_updates 36999 | best_loss 8.481
2022-03-07 19:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 36999 updates
2022-03-07 19:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 384 @ 36999 updates, score 12.977) (writing took 2.246606028173119 seconds)
2022-03-07 19:18:19 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 19:18:19 | INFO | train | epoch 384 | loss 2.558 | nll_loss 0.717 | ppl 1.64 | wps 22247.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36999 | lr 0.000164401 | gnorm 0.791 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 109611
2022-03-07 19:18:19 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 19:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:18:22 | INFO | train_inner | epoch 385:      1 / 97 loss=2.558, nll_loss=0.717, ppl=1.64, wps=21711.4, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=37000, lr=0.000164399, gnorm=0.79, loss_scale=16, train_wall=264, gb_free=8.1, wall=109614
2022-03-07 19:21:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:23:02 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 12.946 | nll_loss 12.17 | ppl 4608.09 | wps 42965.5 | wpb 510.9 | bsz 1 | num_updates 37095 | best_loss 8.481
2022-03-07 19:23:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 37095 updates
2022-03-07 19:23:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:23:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:23:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 385 @ 37095 updates, score 12.946) (writing took 2.191387575119734 seconds)
2022-03-07 19:23:04 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 19:23:04 | INFO | train | epoch 385 | loss 2.556 | nll_loss 0.714 | ppl 1.64 | wps 22042.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37095 | lr 0.000164188 | gnorm 0.786 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 109896
2022-03-07 19:23:04 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 19:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:23:19 | INFO | train_inner | epoch 386:      5 / 97 loss=2.555, nll_loss=0.714, ppl=1.64, wps=22072.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37100, lr=0.000164177, gnorm=0.787, loss_scale=16, train_wall=266, gb_free=8.1, wall=109911
2022-03-07 19:27:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:27:47 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 12.995 | nll_loss 12.22 | ppl 4771.04 | wps 42736.2 | wpb 510.9 | bsz 1 | num_updates 37192 | best_loss 8.481
2022-03-07 19:27:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 37192 updates
2022-03-07 19:27:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:27:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:27:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 386 @ 37192 updates, score 12.995) (writing took 2.193851875141263 seconds)
2022-03-07 19:27:50 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 19:27:50 | INFO | train | epoch 386 | loss 2.556 | nll_loss 0.714 | ppl 1.64 | wps 22256.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37192 | lr 0.000163974 | gnorm 0.787 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 110182
2022-03-07 19:27:50 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 19:27:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:28:13 | INFO | train_inner | epoch 387:      8 / 97 loss=2.556, nll_loss=0.714, ppl=1.64, wps=22276.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=37200, lr=0.000163956, gnorm=0.789, loss_scale=32, train_wall=264, gb_free=8.1, wall=110205
2022-03-07 19:29:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:32:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:32:33 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.022 | nll_loss 12.248 | ppl 4862.85 | wps 42639.2 | wpb 510.9 | bsz 1 | num_updates 37288 | best_loss 8.481
2022-03-07 19:32:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 37288 updates
2022-03-07 19:32:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:32:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:32:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 387 @ 37288 updates, score 13.022) (writing took 2.2382659884169698 seconds)
2022-03-07 19:32:35 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 19:32:35 | INFO | train | epoch 387 | loss 2.555 | nll_loss 0.714 | ppl 1.64 | wps 22038.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37288 | lr 0.000163763 | gnorm 0.792 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 110467
2022-03-07 19:32:35 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 19:32:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:33:09 | INFO | train_inner | epoch 388:     12 / 97 loss=2.554, nll_loss=0.712, ppl=1.64, wps=22073.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=37300, lr=0.000163737, gnorm=0.787, loss_scale=16, train_wall=266, gb_free=8.1, wall=110501
2022-03-07 19:36:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:37:18 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.063 | nll_loss 12.291 | ppl 5012.58 | wps 42824 | wpb 510.9 | bsz 1 | num_updates 37384 | best_loss 8.481
2022-03-07 19:37:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 37384 updates
2022-03-07 19:37:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:37:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:37:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 388 @ 37384 updates, score 13.063) (writing took 2.291035046800971 seconds)
2022-03-07 19:37:20 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 19:37:20 | INFO | train | epoch 388 | loss 2.554 | nll_loss 0.712 | ppl 1.64 | wps 22036.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37384 | lr 0.000163552 | gnorm 0.788 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 110752
2022-03-07 19:37:20 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 19:37:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:38:06 | INFO | train_inner | epoch 389:     16 / 97 loss=2.553, nll_loss=0.712, ppl=1.64, wps=22067.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37400, lr=0.000163517, gnorm=0.791, loss_scale=16, train_wall=266, gb_free=8.1, wall=110798
2022-03-07 19:41:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:42:03 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 12.976 | nll_loss 12.207 | ppl 4728.58 | wps 43076 | wpb 510.9 | bsz 1 | num_updates 37481 | best_loss 8.481
2022-03-07 19:42:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 37481 updates
2022-03-07 19:42:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:42:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:42:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 389 @ 37481 updates, score 12.976) (writing took 2.31393443280831 seconds)
2022-03-07 19:42:05 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 19:42:05 | INFO | train | epoch 389 | loss 2.553 | nll_loss 0.711 | ppl 1.64 | wps 22279.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37481 | lr 0.000163341 | gnorm 0.788 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 111037
2022-03-07 19:42:05 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 19:42:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:43:00 | INFO | train_inner | epoch 390:     19 / 97 loss=2.552, nll_loss=0.711, ppl=1.64, wps=22315.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37500, lr=0.000163299, gnorm=0.786, loss_scale=16, train_wall=263, gb_free=8.1, wall=111092
2022-03-07 19:45:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:46:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:46:47 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 12.952 | nll_loss 12.182 | ppl 4648.27 | wps 43297.1 | wpb 510.9 | bsz 1 | num_updates 37577 | best_loss 8.481
2022-03-07 19:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 37577 updates
2022-03-07 19:46:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:46:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:46:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 390 @ 37577 updates, score 12.952) (writing took 2.2703681220300496 seconds)
2022-03-07 19:46:50 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 19:46:50 | INFO | train | epoch 390 | loss 2.552 | nll_loss 0.711 | ppl 1.64 | wps 22126.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37577 | lr 0.000163132 | gnorm 0.792 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 111321
2022-03-07 19:46:50 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 19:46:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:47:55 | INFO | train_inner | epoch 391:     23 / 97 loss=2.551, nll_loss=0.709, ppl=1.64, wps=22150.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=37600, lr=0.000163082, gnorm=0.786, loss_scale=16, train_wall=265, gb_free=8.1, wall=111387
2022-03-07 19:51:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:51:31 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.019 | nll_loss 12.247 | ppl 4859.8 | wps 43341.4 | wpb 510.9 | bsz 1 | num_updates 37674 | best_loss 8.481
2022-03-07 19:51:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 37674 updates
2022-03-07 19:51:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:51:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 391 @ 37674 updates, score 13.019) (writing took 2.271004525013268 seconds)
2022-03-07 19:51:34 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 19:51:34 | INFO | train | epoch 391 | loss 2.551 | nll_loss 0.709 | ppl 1.63 | wps 22352.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37674 | lr 0.000162922 | gnorm 0.777 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 111606
2022-03-07 19:51:34 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 19:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:52:48 | INFO | train_inner | epoch 392:     26 / 97 loss=2.55, nll_loss=0.708, ppl=1.63, wps=22374.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=37700, lr=0.000162866, gnorm=0.777, loss_scale=32, train_wall=263, gb_free=8.1, wall=111680
2022-03-07 19:52:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:56:16 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 12.968 | nll_loss 12.194 | ppl 4684.92 | wps 43156.6 | wpb 510.9 | bsz 1 | num_updates 37770 | best_loss 8.481
2022-03-07 19:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 37770 updates
2022-03-07 19:56:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:56:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:56:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 392 @ 37770 updates, score 12.968) (writing took 2.2580082891508937 seconds)
2022-03-07 19:56:18 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 19:56:18 | INFO | train | epoch 392 | loss 2.551 | nll_loss 0.709 | ppl 1.64 | wps 22122.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37770 | lr 0.000162715 | gnorm 0.79 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 111890
2022-03-07 19:56:18 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 19:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:57:44 | INFO | train_inner | epoch 393:     30 / 97 loss=2.551, nll_loss=0.71, ppl=1.64, wps=22155.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37800, lr=0.00016265, gnorm=0.792, loss_scale=16, train_wall=265, gb_free=8.1, wall=111976
2022-03-07 19:59:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:01:00 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.033 | nll_loss 12.267 | ppl 4927.46 | wps 43230 | wpb 510.9 | bsz 1 | num_updates 37866 | best_loss 8.481
2022-03-07 20:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 37866 updates
2022-03-07 20:01:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 393 @ 37866 updates, score 13.033) (writing took 2.264750318136066 seconds)
2022-03-07 20:01:02 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 20:01:02 | INFO | train | epoch 393 | loss 2.549 | nll_loss 0.708 | ppl 1.63 | wps 22130.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37866 | lr 0.000162508 | gnorm 0.786 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 112174
2022-03-07 20:01:02 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 20:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:02:39 | INFO | train_inner | epoch 394:     34 / 97 loss=2.549, nll_loss=0.707, ppl=1.63, wps=22162.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37900, lr=0.000162435, gnorm=0.785, loss_scale=16, train_wall=265, gb_free=8.1, wall=112271
2022-03-07 20:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:05:44 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.048 | nll_loss 12.276 | ppl 4958.81 | wps 43299.5 | wpb 510.9 | bsz 1 | num_updates 37963 | best_loss 8.481
2022-03-07 20:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 37963 updates
2022-03-07 20:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:05:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 394 @ 37963 updates, score 13.048) (writing took 2.1353421360254288 seconds)
2022-03-07 20:05:46 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 20:05:46 | INFO | train | epoch 394 | loss 2.549 | nll_loss 0.708 | ppl 1.63 | wps 22349.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37963 | lr 0.0001623 | gnorm 0.786 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 112458
2022-03-07 20:05:46 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 20:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:06:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:07:35 | INFO | train_inner | epoch 395:     38 / 97 loss=2.548, nll_loss=0.707, ppl=1.63, wps=22137.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38000, lr=0.000162221, gnorm=0.789, loss_scale=16, train_wall=266, gb_free=8.1, wall=112567
2022-03-07 20:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:10:29 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 12.964 | nll_loss 12.189 | ppl 4668.65 | wps 43024.2 | wpb 510.9 | bsz 1 | num_updates 38059 | best_loss 8.481
2022-03-07 20:10:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 38059 updates
2022-03-07 20:10:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:10:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:10:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 395 @ 38059 updates, score 12.964) (writing took 2.30324693210423 seconds)
2022-03-07 20:10:31 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 20:10:31 | INFO | train | epoch 395 | loss 2.548 | nll_loss 0.706 | ppl 1.63 | wps 22087.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38059 | lr 0.000162096 | gnorm 0.791 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 112743
2022-03-07 20:10:31 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 20:10:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:12:28 | INFO | train_inner | epoch 396:     41 / 97 loss=2.547, nll_loss=0.706, ppl=1.63, wps=22327.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38100, lr=0.000162008, gnorm=0.791, loss_scale=16, train_wall=263, gb_free=8.1, wall=112860
2022-03-07 20:14:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:15:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:15:13 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 12.947 | nll_loss 12.164 | ppl 4588.54 | wps 43078.1 | wpb 510.9 | bsz 1 | num_updates 38155 | best_loss 8.481
2022-03-07 20:15:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 38155 updates
2022-03-07 20:15:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:15:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:15:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 396 @ 38155 updates, score 12.947) (writing took 2.349853744264692 seconds)
2022-03-07 20:15:16 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 20:15:16 | INFO | train | epoch 396 | loss 2.548 | nll_loss 0.706 | ppl 1.63 | wps 22068.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38155 | lr 0.000161892 | gnorm 0.786 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 113028
2022-03-07 20:15:16 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 20:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:17:25 | INFO | train_inner | epoch 397:     45 / 97 loss=2.548, nll_loss=0.707, ppl=1.63, wps=22099.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=38200, lr=0.000161796, gnorm=0.782, loss_scale=16, train_wall=266, gb_free=8.1, wall=113157
2022-03-07 20:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:19:58 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 12.961 | nll_loss 12.176 | ppl 4628.2 | wps 43056 | wpb 510.9 | bsz 1 | num_updates 38252 | best_loss 8.481
2022-03-07 20:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 38252 updates
2022-03-07 20:19:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:20:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:20:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 397 @ 38252 updates, score 12.961) (writing took 2.2862843410111964 seconds)
2022-03-07 20:20:01 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 20:20:01 | INFO | train | epoch 397 | loss 2.546 | nll_loss 0.705 | ppl 1.63 | wps 22300.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38252 | lr 0.000161686 | gnorm 0.78 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 113313
2022-03-07 20:20:01 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 20:20:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:20:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:22:21 | INFO | train_inner | epoch 398:     49 / 97 loss=2.545, nll_loss=0.704, ppl=1.63, wps=22089.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38300, lr=0.000161585, gnorm=0.788, loss_scale=16, train_wall=266, gb_free=8.1, wall=113453
2022-03-07 20:24:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:24:44 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.026 | nll_loss 12.255 | ppl 4887.52 | wps 43054.1 | wpb 510.9 | bsz 1 | num_updates 38348 | best_loss 8.481
2022-03-07 20:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 38348 updates
2022-03-07 20:24:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:24:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 398 @ 38348 updates, score 13.026) (writing took 2.3191105099394917 seconds)
2022-03-07 20:24:46 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 20:24:46 | INFO | train | epoch 398 | loss 2.545 | nll_loss 0.703 | ppl 1.63 | wps 22029.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38348 | lr 0.000161484 | gnorm 0.787 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 113598
2022-03-07 20:24:46 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 20:24:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:27:15 | INFO | train_inner | epoch 399:     52 / 97 loss=2.544, nll_loss=0.703, ppl=1.63, wps=22275.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=38400, lr=0.000161374, gnorm=0.783, loss_scale=32, train_wall=264, gb_free=8.1, wall=113747
2022-03-07 20:27:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:29:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:29:29 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 12.967 | nll_loss 12.19 | ppl 4671.83 | wps 43394.8 | wpb 510.9 | bsz 1 | num_updates 38444 | best_loss 8.481
2022-03-07 20:29:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 38444 updates
2022-03-07 20:29:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:29:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:29:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 399 @ 38444 updates, score 12.967) (writing took 2.278134270105511 seconds)
2022-03-07 20:29:31 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 20:29:31 | INFO | train | epoch 399 | loss 2.544 | nll_loss 0.703 | ppl 1.63 | wps 22053.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38444 | lr 0.000161282 | gnorm 0.786 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 113883
2022-03-07 20:29:31 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 20:29:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:32:12 | INFO | train_inner | epoch 400:     56 / 97 loss=2.544, nll_loss=0.703, ppl=1.63, wps=22086.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38500, lr=0.000161165, gnorm=0.778, loss_scale=16, train_wall=266, gb_free=8.1, wall=114044
2022-03-07 20:34:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:34:14 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.01 | nll_loss 12.24 | ppl 4838.21 | wps 43081.8 | wpb 510.9 | bsz 1 | num_updates 38541 | best_loss 8.481
2022-03-07 20:34:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 38541 updates
2022-03-07 20:34:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:34:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:34:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 400 @ 38541 updates, score 13.01) (writing took 2.3450415739789605 seconds)
2022-03-07 20:34:16 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 20:34:16 | INFO | train | epoch 400 | loss 2.544 | nll_loss 0.703 | ppl 1.63 | wps 22272.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38541 | lr 0.000161079 | gnorm 0.78 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 114168
2022-03-07 20:34:16 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 20:34:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:36:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:37:08 | INFO | train_inner | epoch 401:     60 / 97 loss=2.543, nll_loss=0.702, ppl=1.63, wps=22076.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=38600, lr=0.000160956, gnorm=0.783, loss_scale=16, train_wall=266, gb_free=8.1, wall=114340
2022-03-07 20:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:38:59 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 12.998 | nll_loss 12.225 | ppl 4785.96 | wps 42984.9 | wpb 510.9 | bsz 1 | num_updates 38637 | best_loss 8.481
2022-03-07 20:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 38637 updates
2022-03-07 20:38:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:39:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:39:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 401 @ 38637 updates, score 12.998) (writing took 2.3452317188493907 seconds)
2022-03-07 20:39:02 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 20:39:02 | INFO | train | epoch 401 | loss 2.543 | nll_loss 0.701 | ppl 1.63 | wps 22036.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38637 | lr 0.000160879 | gnorm 0.779 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 114454
2022-03-07 20:39:02 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 20:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:42:02 | INFO | train_inner | epoch 402:     63 / 97 loss=2.542, nll_loss=0.7, ppl=1.63, wps=22276.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38700, lr=0.000160748, gnorm=0.775, loss_scale=16, train_wall=264, gb_free=8.1, wall=114634
2022-03-07 20:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:43:45 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.015 | nll_loss 12.242 | ppl 4843.51 | wps 43281.4 | wpb 510.9 | bsz 1 | num_updates 38734 | best_loss 8.481
2022-03-07 20:43:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 38734 updates
2022-03-07 20:43:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:43:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:43:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 402 @ 38734 updates, score 13.015) (writing took 2.292924091219902 seconds)
2022-03-07 20:43:47 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 20:43:47 | INFO | train | epoch 402 | loss 2.542 | nll_loss 0.701 | ppl 1.63 | wps 22267.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38734 | lr 0.000160677 | gnorm 0.779 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 114739
2022-03-07 20:43:47 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 20:43:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:43:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:46:59 | INFO | train_inner | epoch 403:     67 / 97 loss=2.543, nll_loss=0.702, ppl=1.63, wps=22080.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38800, lr=0.00016054, gnorm=0.789, loss_scale=16, train_wall=266, gb_free=8.1, wall=114931
2022-03-07 20:48:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:48:30 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 12.91 | nll_loss 12.13 | ppl 4482.06 | wps 43140.6 | wpb 510.9 | bsz 1 | num_updates 38830 | best_loss 8.481
2022-03-07 20:48:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 38830 updates
2022-03-07 20:48:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:48:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:48:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 403 @ 38830 updates, score 12.91) (writing took 2.319105619098991 seconds)
2022-03-07 20:48:32 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 20:48:32 | INFO | train | epoch 403 | loss 2.542 | nll_loss 0.701 | ppl 1.63 | wps 22046.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38830 | lr 0.000160478 | gnorm 0.793 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 115024
2022-03-07 20:48:32 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 20:48:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:51:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:51:56 | INFO | train_inner | epoch 404:     71 / 97 loss=2.541, nll_loss=0.7, ppl=1.62, wps=22058.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38900, lr=0.000160334, gnorm=0.782, loss_scale=16, train_wall=266, gb_free=8.1, wall=115228
2022-03-07 20:53:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:53:15 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.003 | nll_loss 12.229 | ppl 4802.18 | wps 43261 | wpb 510.9 | bsz 1 | num_updates 38926 | best_loss 8.481
2022-03-07 20:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 38926 updates
2022-03-07 20:53:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:53:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:53:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 404 @ 38926 updates, score 13.003) (writing took 2.3059774469584227 seconds)
2022-03-07 20:53:18 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 20:53:18 | INFO | train | epoch 404 | loss 2.54 | nll_loss 0.699 | ppl 1.62 | wps 22023.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38926 | lr 0.00016028 | gnorm 0.772 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 115310
2022-03-07 20:53:18 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 20:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:56:50 | INFO | train_inner | epoch 405:     74 / 97 loss=2.542, nll_loss=0.701, ppl=1.63, wps=22275.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39000, lr=0.000160128, gnorm=0.786, loss_scale=16, train_wall=264, gb_free=8.1, wall=115522
2022-03-07 20:57:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:58:01 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 12.999 | nll_loss 12.223 | ppl 4779.2 | wps 43009.9 | wpb 510.9 | bsz 1 | num_updates 39023 | best_loss 8.481
2022-03-07 20:58:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 39023 updates
2022-03-07 20:58:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:58:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:58:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 405 @ 39023 updates, score 12.999) (writing took 2.2850424009375274 seconds)
2022-03-07 20:58:03 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 20:58:03 | INFO | train | epoch 405 | loss 2.541 | nll_loss 0.7 | ppl 1.62 | wps 22258.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39023 | lr 0.000160081 | gnorm 0.787 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 115595
2022-03-07 20:58:03 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 20:58:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:58:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:01:47 | INFO | train_inner | epoch 406:     78 / 97 loss=2.539, nll_loss=0.698, ppl=1.62, wps=22068.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39100, lr=0.000159923, gnorm=0.782, loss_scale=16, train_wall=266, gb_free=8.1, wall=115819
2022-03-07 21:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:02:46 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.031 | nll_loss 12.26 | ppl 4905.23 | wps 43104.1 | wpb 510.9 | bsz 1 | num_updates 39119 | best_loss 8.481
2022-03-07 21:02:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 39119 updates
2022-03-07 21:02:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:02:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:02:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 406 @ 39119 updates, score 13.031) (writing took 2.346167542040348 seconds)
2022-03-07 21:02:48 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 21:02:48 | INFO | train | epoch 406 | loss 2.539 | nll_loss 0.698 | ppl 1.62 | wps 22031.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39119 | lr 0.000159884 | gnorm 0.784 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 115880
2022-03-07 21:02:48 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 21:02:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:05:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:06:43 | INFO | train_inner | epoch 407:     82 / 97 loss=2.539, nll_loss=0.698, ppl=1.62, wps=22070, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39200, lr=0.000159719, gnorm=0.781, loss_scale=16, train_wall=266, gb_free=8.1, wall=116115
2022-03-07 21:07:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:07:31 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.059 | nll_loss 12.286 | ppl 4993.64 | wps 43093.6 | wpb 510.9 | bsz 1 | num_updates 39215 | best_loss 8.481
2022-03-07 21:07:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 39215 updates
2022-03-07 21:07:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:07:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:07:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 407 @ 39215 updates, score 13.059) (writing took 2.3092469801194966 seconds)
2022-03-07 21:07:34 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 21:07:34 | INFO | train | epoch 407 | loss 2.538 | nll_loss 0.697 | ppl 1.62 | wps 22043.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39215 | lr 0.000159689 | gnorm 0.78 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 116166
2022-03-07 21:07:34 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 21:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:11:37 | INFO | train_inner | epoch 408:     85 / 97 loss=2.538, nll_loss=0.697, ppl=1.62, wps=22292.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=39300, lr=0.000159516, gnorm=0.787, loss_scale=32, train_wall=263, gb_free=8.1, wall=116409
2022-03-07 21:12:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:12:17 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 12.989 | nll_loss 12.221 | ppl 4772.45 | wps 42957.5 | wpb 510.9 | bsz 1 | num_updates 39312 | best_loss 8.481
2022-03-07 21:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 39312 updates
2022-03-07 21:12:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:12:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:12:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 408 @ 39312 updates, score 12.989) (writing took 2.317333459854126 seconds)
2022-03-07 21:12:19 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 21:12:19 | INFO | train | epoch 408 | loss 2.537 | nll_loss 0.696 | ppl 1.62 | wps 22268.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39312 | lr 0.000159491 | gnorm 0.787 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 116451
2022-03-07 21:12:19 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 21:12:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:12:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:16:34 | INFO | train_inner | epoch 409:     89 / 97 loss=2.536, nll_loss=0.695, ppl=1.62, wps=22062.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=39400, lr=0.000159313, gnorm=0.783, loss_scale=16, train_wall=266, gb_free=8.1, wall=116706
2022-03-07 21:16:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:17:02 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 12.934 | nll_loss 12.157 | ppl 4568.1 | wps 43034.6 | wpb 510.9 | bsz 1 | num_updates 39408 | best_loss 8.481
2022-03-07 21:17:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 39408 updates
2022-03-07 21:17:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:17:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:17:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 409 @ 39408 updates, score 12.934) (writing took 2.3253769581206143 seconds)
2022-03-07 21:17:04 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 21:17:04 | INFO | train | epoch 409 | loss 2.536 | nll_loss 0.695 | ppl 1.62 | wps 22030.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39408 | lr 0.000159297 | gnorm 0.78 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 116736
2022-03-07 21:17:04 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 21:17:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:21:28 | INFO | train_inner | epoch 410:     92 / 97 loss=2.537, nll_loss=0.696, ppl=1.62, wps=22272.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39500, lr=0.000159111, gnorm=0.777, loss_scale=32, train_wall=264, gb_free=8.1, wall=117000
2022-03-07 21:21:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:21:47 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 12.952 | nll_loss 12.174 | ppl 4622.18 | wps 43276.5 | wpb 510.9 | bsz 1 | num_updates 39505 | best_loss 8.481
2022-03-07 21:21:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 39505 updates
2022-03-07 21:21:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:21:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:21:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 410 @ 39505 updates, score 12.952) (writing took 2.295721092261374 seconds)
2022-03-07 21:21:50 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 21:21:50 | INFO | train | epoch 410 | loss 2.536 | nll_loss 0.695 | ppl 1.62 | wps 22259.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39505 | lr 0.000159101 | gnorm 0.776 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 117022
2022-03-07 21:21:50 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 21:21:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:21:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:26:25 | INFO | train_inner | epoch 411:     96 / 97 loss=2.536, nll_loss=0.695, ppl=1.62, wps=22064.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39600, lr=0.00015891, gnorm=0.784, loss_scale=16, train_wall=266, gb_free=8.1, wall=117297
2022-03-07 21:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:26:33 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.064 | nll_loss 12.302 | ppl 5049.1 | wps 43278.1 | wpb 510.9 | bsz 1 | num_updates 39601 | best_loss 8.481
2022-03-07 21:26:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 39601 updates
2022-03-07 21:26:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:26:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:26:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 411 @ 39601 updates, score 13.064) (writing took 2.3322679731063545 seconds)
2022-03-07 21:26:35 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 21:26:35 | INFO | train | epoch 411 | loss 2.535 | nll_loss 0.694 | ppl 1.62 | wps 22025.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39601 | lr 0.000158908 | gnorm 0.785 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 117307
2022-03-07 21:26:35 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 21:26:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:28:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:31:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:31:18 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.006 | nll_loss 12.237 | ppl 4827.11 | wps 42944.2 | wpb 510.9 | bsz 1 | num_updates 39697 | best_loss 8.481
2022-03-07 21:31:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 39697 updates
2022-03-07 21:31:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:31:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:31:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 412 @ 39697 updates, score 13.006) (writing took 2.2577577708289027 seconds)
2022-03-07 21:31:20 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 21:31:20 | INFO | train | epoch 412 | loss 2.534 | nll_loss 0.693 | ppl 1.62 | wps 22038.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39697 | lr 0.000158716 | gnorm 0.773 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 117592
2022-03-07 21:31:20 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 21:31:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:31:29 | INFO | train_inner | epoch 413:      3 / 97 loss=2.534, nll_loss=0.693, ppl=1.62, wps=21518.3, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=39700, lr=0.00015871, gnorm=0.774, loss_scale=16, train_wall=266, gb_free=8.1, wall=117601
2022-03-07 21:35:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:36:04 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 12.988 | nll_loss 12.216 | ppl 4759.02 | wps 43284.1 | wpb 510.9 | bsz 1 | num_updates 39793 | best_loss 8.481
2022-03-07 21:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 39793 updates
2022-03-07 21:36:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:36:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:36:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 413 @ 39793 updates, score 12.988) (writing took 2.312839773017913 seconds)
2022-03-07 21:36:06 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 21:36:06 | INFO | train | epoch 413 | loss 2.534 | nll_loss 0.693 | ppl 1.62 | wps 22021.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39793 | lr 0.000158525 | gnorm 0.792 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 117878
2022-03-07 21:36:06 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 21:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:36:26 | INFO | train_inner | epoch 414:      7 / 97 loss=2.533, nll_loss=0.693, ppl=1.62, wps=22056.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39800, lr=0.000158511, gnorm=0.791, loss_scale=16, train_wall=266, gb_free=8.1, wall=117898
2022-03-07 21:40:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:40:49 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 12.979 | nll_loss 12.205 | ppl 4720.56 | wps 43393.6 | wpb 510.9 | bsz 1 | num_updates 39890 | best_loss 8.481
2022-03-07 21:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 39890 updates
2022-03-07 21:40:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:40:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 414 @ 39890 updates, score 12.979) (writing took 2.287955502048135 seconds)
2022-03-07 21:40:51 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 21:40:51 | INFO | train | epoch 414 | loss 2.532 | nll_loss 0.692 | ppl 1.62 | wps 22244.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39890 | lr 0.000158332 | gnorm 0.774 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 118163
2022-03-07 21:40:52 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 21:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:41:20 | INFO | train_inner | epoch 415:     10 / 97 loss=2.532, nll_loss=0.691, ppl=1.61, wps=22267.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39900, lr=0.000158312, gnorm=0.772, loss_scale=16, train_wall=264, gb_free=8.1, wall=118192
2022-03-07 21:44:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:45:34 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.005 | nll_loss 12.231 | ppl 4808.84 | wps 43276.1 | wpb 510.9 | bsz 1 | num_updates 39986 | best_loss 8.481
2022-03-07 21:45:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 39986 updates
2022-03-07 21:45:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:45:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:45:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 415 @ 39986 updates, score 13.005) (writing took 2.2853755741380155 seconds)
2022-03-07 21:45:37 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 21:45:37 | INFO | train | epoch 415 | loss 2.532 | nll_loss 0.692 | ppl 1.61 | wps 22044.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39986 | lr 0.000158142 | gnorm 0.785 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 118449
2022-03-07 21:45:37 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 21:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:46:17 | INFO | train_inner | epoch 416:     14 / 97 loss=2.532, nll_loss=0.691, ppl=1.61, wps=22072, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40000, lr=0.000158114, gnorm=0.788, loss_scale=16, train_wall=266, gb_free=8.1, wall=118489
2022-03-07 21:50:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:50:20 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 12.988 | nll_loss 12.218 | ppl 4764.56 | wps 43124.3 | wpb 510.9 | bsz 1 | num_updates 40083 | best_loss 8.481
2022-03-07 21:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 40083 updates
2022-03-07 21:50:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 416 @ 40083 updates, score 12.988) (writing took 2.35748442215845 seconds)
2022-03-07 21:50:22 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 21:50:22 | INFO | train | epoch 416 | loss 2.532 | nll_loss 0.691 | ppl 1.61 | wps 22245.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40083 | lr 0.00015795 | gnorm 0.781 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 118734
2022-03-07 21:50:22 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 21:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:51:11 | INFO | train_inner | epoch 417:     17 / 97 loss=2.531, nll_loss=0.69, ppl=1.61, wps=22258.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=40100, lr=0.000157917, gnorm=0.781, loss_scale=32, train_wall=264, gb_free=8.1, wall=118783
2022-03-07 21:53:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:55:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:55:05 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.016 | nll_loss 12.244 | ppl 4850.32 | wps 43308 | wpb 510.9 | bsz 1 | num_updates 40179 | best_loss 8.481
2022-03-07 21:55:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 40179 updates
2022-03-07 21:55:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:55:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:55:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 417 @ 40179 updates, score 13.016) (writing took 2.336799630895257 seconds)
2022-03-07 21:55:08 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 21:55:08 | INFO | train | epoch 417 | loss 2.531 | nll_loss 0.691 | ppl 1.61 | wps 22020.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40179 | lr 0.000157761 | gnorm 0.787 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 119020
2022-03-07 21:55:08 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 21:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:56:08 | INFO | train_inner | epoch 418:     21 / 97 loss=2.531, nll_loss=0.69, ppl=1.61, wps=22053.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40200, lr=0.00015772, gnorm=0.786, loss_scale=16, train_wall=266, gb_free=8.1, wall=119080
2022-03-07 21:59:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:59:51 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.032 | nll_loss 12.259 | ppl 4902.94 | wps 43085.2 | wpb 510.9 | bsz 1 | num_updates 40276 | best_loss 8.481
2022-03-07 21:59:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 40276 updates
2022-03-07 21:59:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:59:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:59:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 418 @ 40276 updates, score 13.032) (writing took 2.282523789908737 seconds)
2022-03-07 21:59:53 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 21:59:53 | INFO | train | epoch 418 | loss 2.531 | nll_loss 0.69 | ppl 1.61 | wps 22244 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40276 | lr 0.000157571 | gnorm 0.783 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 119305
2022-03-07 21:59:53 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 21:59:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:00:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:01:05 | INFO | train_inner | epoch 419:     25 / 97 loss=2.529, nll_loss=0.689, ppl=1.61, wps=22059, ups=0.34, wpb=65495, bsz=127.9, num_updates=40300, lr=0.000157524, gnorm=0.78, loss_scale=16, train_wall=266, gb_free=8.1, wall=119377
2022-03-07 22:04:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:04:36 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.028 | nll_loss 12.26 | ppl 4905.37 | wps 43271 | wpb 510.9 | bsz 1 | num_updates 40372 | best_loss 8.481
2022-03-07 22:04:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 40372 updates
2022-03-07 22:04:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:04:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:04:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 419 @ 40372 updates, score 13.028) (writing took 2.277035328093916 seconds)
2022-03-07 22:04:39 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 22:04:39 | INFO | train | epoch 419 | loss 2.529 | nll_loss 0.688 | ppl 1.61 | wps 22038.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40372 | lr 0.000157384 | gnorm 0.786 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 119591
2022-03-07 22:04:39 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 22:04:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:05:59 | INFO | train_inner | epoch 420:     28 / 97 loss=2.528, nll_loss=0.688, ppl=1.61, wps=22277.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=40400, lr=0.000157329, gnorm=0.787, loss_scale=16, train_wall=264, gb_free=8.1, wall=119671
2022-03-07 22:09:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:09:22 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 12.998 | nll_loss 12.229 | ppl 4800.99 | wps 43141.6 | wpb 510.9 | bsz 1 | num_updates 40469 | best_loss 8.481
2022-03-07 22:09:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 40469 updates
2022-03-07 22:09:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:09:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:09:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 420 @ 40469 updates, score 12.998) (writing took 2.2827258757315576 seconds)
2022-03-07 22:09:24 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 22:09:24 | INFO | train | epoch 420 | loss 2.529 | nll_loss 0.688 | ppl 1.61 | wps 22269.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40469 | lr 0.000157195 | gnorm 0.777 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 119876
2022-03-07 22:09:24 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 22:09:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:10:53 | INFO | train_inner | epoch 421:     31 / 97 loss=2.528, nll_loss=0.688, ppl=1.61, wps=22285.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40500, lr=0.000157135, gnorm=0.772, loss_scale=32, train_wall=264, gb_free=8.1, wall=119965
2022-03-07 22:12:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:14:07 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.02 | nll_loss 12.247 | ppl 4862.3 | wps 43202.4 | wpb 510.9 | bsz 1 | num_updates 40565 | best_loss 8.481
2022-03-07 22:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 40565 updates
2022-03-07 22:14:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:14:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:14:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 421 @ 40565 updates, score 13.02) (writing took 2.335776633117348 seconds)
2022-03-07 22:14:09 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 22:14:09 | INFO | train | epoch 421 | loss 2.528 | nll_loss 0.687 | ppl 1.61 | wps 22020.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40565 | lr 0.000157009 | gnorm 0.774 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 120161
2022-03-07 22:14:09 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 22:14:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:15:50 | INFO | train_inner | epoch 422:     35 / 97 loss=2.528, nll_loss=0.688, ppl=1.61, wps=22055.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=40600, lr=0.000156941, gnorm=0.782, loss_scale=32, train_wall=266, gb_free=8.1, wall=120262
2022-03-07 22:17:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:18:52 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.025 | nll_loss 12.255 | ppl 4889.51 | wps 43251.6 | wpb 510.9 | bsz 1 | num_updates 40661 | best_loss 8.481
2022-03-07 22:18:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 40661 updates
2022-03-07 22:18:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:18:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:18:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 422 @ 40661 updates, score 13.025) (writing took 2.2741245212964714 seconds)
2022-03-07 22:18:55 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 22:18:55 | INFO | train | epoch 422 | loss 2.526 | nll_loss 0.686 | ppl 1.61 | wps 22040.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40661 | lr 0.000156823 | gnorm 0.779 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 120447
2022-03-07 22:18:55 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 22:18:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:20:47 | INFO | train_inner | epoch 423:     39 / 97 loss=2.526, nll_loss=0.686, ppl=1.61, wps=22071.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=40700, lr=0.000156748, gnorm=0.769, loss_scale=16, train_wall=266, gb_free=8.1, wall=120559
2022-03-07 22:23:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:23:38 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.067 | nll_loss 12.302 | ppl 5050.74 | wps 43216.6 | wpb 510.9 | bsz 1 | num_updates 40758 | best_loss 8.481
2022-03-07 22:23:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 40758 updates
2022-03-07 22:23:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:23:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:23:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 423 @ 40758 updates, score 13.067) (writing took 2.302936620078981 seconds)
2022-03-07 22:23:40 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 22:23:40 | INFO | train | epoch 423 | loss 2.527 | nll_loss 0.687 | ppl 1.61 | wps 22260.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40758 | lr 0.000156637 | gnorm 0.778 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 120732
2022-03-07 22:23:40 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 22:23:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:25:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:25:43 | INFO | train_inner | epoch 424:     43 / 97 loss=2.526, nll_loss=0.686, ppl=1.61, wps=22062.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=40800, lr=0.000156556, gnorm=0.786, loss_scale=16, train_wall=266, gb_free=8.1, wall=120855
2022-03-07 22:28:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:28:23 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.006 | nll_loss 12.242 | ppl 4842.85 | wps 43487.3 | wpb 510.9 | bsz 1 | num_updates 40854 | best_loss 8.481
2022-03-07 22:28:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 40854 updates
2022-03-07 22:28:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:28:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:28:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 424 @ 40854 updates, score 13.006) (writing took 2.2836596677079797 seconds)
2022-03-07 22:28:25 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 22:28:25 | INFO | train | epoch 424 | loss 2.525 | nll_loss 0.685 | ppl 1.61 | wps 22030.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40854 | lr 0.000156453 | gnorm 0.778 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 121017
2022-03-07 22:28:25 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 22:28:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:30:37 | INFO | train_inner | epoch 425:     46 / 97 loss=2.525, nll_loss=0.685, ppl=1.61, wps=22275, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40900, lr=0.000156365, gnorm=0.779, loss_scale=16, train_wall=264, gb_free=8.1, wall=121149
2022-03-07 22:31:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:33:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:33:09 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.035 | nll_loss 12.271 | ppl 4943.14 | wps 42848.1 | wpb 510.9 | bsz 1 | num_updates 40950 | best_loss 8.481
2022-03-07 22:33:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 40950 updates
2022-03-07 22:33:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:33:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:33:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 425 @ 40950 updates, score 13.035) (writing took 2.3153749289922416 seconds)
2022-03-07 22:33:11 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 22:33:11 | INFO | train | epoch 425 | loss 2.524 | nll_loss 0.684 | ppl 1.61 | wps 22030.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40950 | lr 0.000156269 | gnorm 0.779 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 121303
2022-03-07 22:33:11 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 22:33:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:35:34 | INFO | train_inner | epoch 426:     50 / 97 loss=2.523, nll_loss=0.682, ppl=1.6, wps=22070, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41000, lr=0.000156174, gnorm=0.775, loss_scale=16, train_wall=266, gb_free=8.1, wall=121446
2022-03-07 22:37:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:37:54 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.052 | nll_loss 12.283 | ppl 4982.65 | wps 42965.8 | wpb 510.9 | bsz 1 | num_updates 41047 | best_loss 8.481
2022-03-07 22:37:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 41047 updates
2022-03-07 22:37:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:37:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:37:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 426 @ 41047 updates, score 13.052) (writing took 2.2535900389775634 seconds)
2022-03-07 22:37:56 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 22:37:56 | INFO | train | epoch 426 | loss 2.524 | nll_loss 0.684 | ppl 1.61 | wps 22262.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41047 | lr 0.000156084 | gnorm 0.782 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 121588
2022-03-07 22:37:56 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 22:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:38:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:40:31 | INFO | train_inner | epoch 427:     54 / 97 loss=2.525, nll_loss=0.685, ppl=1.61, wps=22060.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41100, lr=0.000155984, gnorm=0.784, loss_scale=16, train_wall=266, gb_free=8.1, wall=121743
2022-03-07 22:42:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:42:39 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 12.989 | nll_loss 12.225 | ppl 4786.44 | wps 43142.9 | wpb 510.9 | bsz 1 | num_updates 41143 | best_loss 8.481
2022-03-07 22:42:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 41143 updates
2022-03-07 22:42:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:42:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:42:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 427 @ 41143 updates, score 12.989) (writing took 2.362968696746975 seconds)
2022-03-07 22:42:42 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 22:42:42 | INFO | train | epoch 427 | loss 2.523 | nll_loss 0.682 | ppl 1.6 | wps 22026.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41143 | lr 0.000155902 | gnorm 0.774 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 121874
2022-03-07 22:42:42 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 22:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:44:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:45:28 | INFO | train_inner | epoch 428:     58 / 97 loss=2.522, nll_loss=0.682, ppl=1.6, wps=22065.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41200, lr=0.000155794, gnorm=0.776, loss_scale=16, train_wall=266, gb_free=8.1, wall=122040
2022-03-07 22:47:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:47:24 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.048 | nll_loss 12.285 | ppl 4989.53 | wps 43663.3 | wpb 510.9 | bsz 1 | num_updates 41239 | best_loss 8.481
2022-03-07 22:47:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 41239 updates
2022-03-07 22:47:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:47:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:47:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 428 @ 41239 updates, score 13.048) (writing took 2.27558237593621 seconds)
2022-03-07 22:47:27 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 22:47:27 | INFO | train | epoch 428 | loss 2.522 | nll_loss 0.682 | ppl 1.6 | wps 22053.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41239 | lr 0.000155721 | gnorm 0.782 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 122159
2022-03-07 22:47:27 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 22:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:50:22 | INFO | train_inner | epoch 429:     61 / 97 loss=2.522, nll_loss=0.682, ppl=1.6, wps=22288.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41300, lr=0.000155606, gnorm=0.772, loss_scale=16, train_wall=264, gb_free=8.1, wall=122334
2022-03-07 22:51:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:52:10 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 12.955 | nll_loss 12.181 | ppl 4643.35 | wps 43066.5 | wpb 510.9 | bsz 1 | num_updates 41335 | best_loss 8.481
2022-03-07 22:52:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 41335 updates
2022-03-07 22:52:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:52:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:52:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 429 @ 41335 updates, score 12.955) (writing took 2.321076115127653 seconds)
2022-03-07 22:52:12 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 22:52:12 | INFO | train | epoch 429 | loss 2.522 | nll_loss 0.682 | ppl 1.6 | wps 22025.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41335 | lr 0.00015554 | gnorm 0.77 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 122444
2022-03-07 22:52:12 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 22:52:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:55:19 | INFO | train_inner | epoch 430:     65 / 97 loss=2.52, nll_loss=0.68, ppl=1.6, wps=22065.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41400, lr=0.000155417, gnorm=0.771, loss_scale=16, train_wall=266, gb_free=8.1, wall=122630
2022-03-07 22:56:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:56:55 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.011 | nll_loss 12.24 | ppl 4835.81 | wps 43081.6 | wpb 510.9 | bsz 1 | num_updates 41432 | best_loss 8.481
2022-03-07 22:56:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 41432 updates
2022-03-07 22:56:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:56:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:56:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 430 @ 41432 updates, score 13.011) (writing took 2.2753559201955795 seconds)
2022-03-07 22:56:57 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 22:56:57 | INFO | train | epoch 430 | loss 2.521 | nll_loss 0.681 | ppl 1.6 | wps 22268.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41432 | lr 0.000155357 | gnorm 0.776 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 122729
2022-03-07 22:56:57 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 22:56:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:59:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:00:15 | INFO | train_inner | epoch 431:     69 / 97 loss=2.522, nll_loss=0.682, ppl=1.6, wps=22063.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41500, lr=0.00015523, gnorm=0.776, loss_scale=16, train_wall=266, gb_free=8.1, wall=122927
2022-03-07 23:01:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:01:41 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.003 | nll_loss 12.236 | ppl 4822.51 | wps 43030.1 | wpb 510.9 | bsz 1 | num_updates 41528 | best_loss 8.481
2022-03-07 23:01:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 41528 updates
2022-03-07 23:01:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:01:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:01:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 431 @ 41528 updates, score 13.003) (writing took 2.2790792360901833 seconds)
2022-03-07 23:01:43 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 23:01:43 | INFO | train | epoch 431 | loss 2.52 | nll_loss 0.68 | ppl 1.6 | wps 22024.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41528 | lr 0.000155178 | gnorm 0.769 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 123015
2022-03-07 23:01:43 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 23:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:05:09 | INFO | train_inner | epoch 432:     72 / 97 loss=2.519, nll_loss=0.679, ppl=1.6, wps=22273.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=41600, lr=0.000155043, gnorm=0.771, loss_scale=16, train_wall=264, gb_free=8.1, wall=123221
2022-03-07 23:05:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:06:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:06:26 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.046 | nll_loss 12.277 | ppl 4961.77 | wps 43319.6 | wpb 510.9 | bsz 1 | num_updates 41624 | best_loss 8.481
2022-03-07 23:06:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 41624 updates
2022-03-07 23:06:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:06:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:06:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 432 @ 41624 updates, score 13.046) (writing took 2.2513413690030575 seconds)
2022-03-07 23:06:28 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 23:06:28 | INFO | train | epoch 432 | loss 2.52 | nll_loss 0.68 | ppl 1.6 | wps 22039.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41624 | lr 0.000154999 | gnorm 0.779 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 123300
2022-03-07 23:06:28 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 23:06:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:10:06 | INFO | train_inner | epoch 433:     76 / 97 loss=2.52, nll_loss=0.68, ppl=1.6, wps=22070.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41700, lr=0.000154857, gnorm=0.78, loss_scale=16, train_wall=266, gb_free=8.1, wall=123518
2022-03-07 23:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:11:11 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.004 | nll_loss 12.237 | ppl 4828.13 | wps 43251.3 | wpb 510.9 | bsz 1 | num_updates 41721 | best_loss 8.481
2022-03-07 23:11:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 41721 updates
2022-03-07 23:11:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:11:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:11:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 433 @ 41721 updates, score 13.004) (writing took 2.333653674926609 seconds)
2022-03-07 23:11:14 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 23:11:14 | INFO | train | epoch 433 | loss 2.519 | nll_loss 0.678 | ppl 1.6 | wps 22261.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41721 | lr 0.000154818 | gnorm 0.774 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 123585
2022-03-07 23:11:14 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 23:11:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:13:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:15:03 | INFO | train_inner | epoch 434:     80 / 97 loss=2.519, nll_loss=0.679, ppl=1.6, wps=22047.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41800, lr=0.000154672, gnorm=0.783, loss_scale=16, train_wall=266, gb_free=8.1, wall=123815
2022-03-07 23:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:15:57 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.017 | nll_loss 12.252 | ppl 4877.16 | wps 43146.7 | wpb 510.9 | bsz 1 | num_updates 41817 | best_loss 8.481
2022-03-07 23:15:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 41817 updates
2022-03-07 23:15:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:15:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:15:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 434 @ 41817 updates, score 13.017) (writing took 2.2304649678990245 seconds)
2022-03-07 23:15:59 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 23:15:59 | INFO | train | epoch 434 | loss 2.518 | nll_loss 0.678 | ppl 1.6 | wps 22010.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41817 | lr 0.000154641 | gnorm 0.785 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 123871
2022-03-07 23:15:59 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 23:15:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:19:57 | INFO | train_inner | epoch 435:     83 / 97 loss=2.519, nll_loss=0.679, ppl=1.6, wps=22269.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41900, lr=0.000154487, gnorm=0.778, loss_scale=32, train_wall=264, gb_free=8.1, wall=124109
2022-03-07 23:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:20:43 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.036 | nll_loss 12.274 | ppl 4952.1 | wps 43063.3 | wpb 510.9 | bsz 1 | num_updates 41914 | best_loss 8.481
2022-03-07 23:20:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 41914 updates
2022-03-07 23:20:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:20:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:20:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 435 @ 41914 updates, score 13.036) (writing took 2.230734243057668 seconds)
2022-03-07 23:20:45 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 23:20:45 | INFO | train | epoch 435 | loss 2.518 | nll_loss 0.678 | ppl 1.6 | wps 22248.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41914 | lr 0.000154462 | gnorm 0.778 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 124157
2022-03-07 23:20:45 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 23:20:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:20:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:24:54 | INFO | train_inner | epoch 436:     87 / 97 loss=2.517, nll_loss=0.677, ppl=1.6, wps=22052.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=42000, lr=0.000154303, gnorm=0.776, loss_scale=16, train_wall=266, gb_free=8.1, wall=124406
2022-03-07 23:25:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:25:28 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.071 | nll_loss 12.31 | ppl 5077.4 | wps 43392 | wpb 510.9 | bsz 1 | num_updates 42010 | best_loss 8.481
2022-03-07 23:25:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 42010 updates
2022-03-07 23:25:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:25:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:25:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 436 @ 42010 updates, score 13.071) (writing took 2.259005050174892 seconds)
2022-03-07 23:25:30 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 23:25:30 | INFO | train | epoch 436 | loss 2.517 | nll_loss 0.677 | ppl 1.6 | wps 22025.8 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 42010 | lr 0.000154285 | gnorm 0.774 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 124442
2022-03-07 23:25:30 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 23:25:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:27:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:29:51 | INFO | train_inner | epoch 437:     91 / 97 loss=2.516, nll_loss=0.676, ppl=1.6, wps=22068.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42100, lr=0.00015412, gnorm=0.772, loss_scale=16, train_wall=266, gb_free=8.1, wall=124703
2022-03-07 23:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:30:13 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.105 | nll_loss 12.347 | ppl 5209.73 | wps 43365.3 | wpb 510.9 | bsz 1 | num_updates 42106 | best_loss 8.481
2022-03-07 23:30:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 42106 updates
2022-03-07 23:30:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:30:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:30:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 437 @ 42106 updates, score 13.105) (writing took 2.238143459893763 seconds)
2022-03-07 23:30:15 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 23:30:15 | INFO | train | epoch 437 | loss 2.516 | nll_loss 0.676 | ppl 1.6 | wps 22042.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42106 | lr 0.000154109 | gnorm 0.773 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 124727
2022-03-07 23:30:15 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 23:30:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:34:45 | INFO | train_inner | epoch 438:     94 / 97 loss=2.516, nll_loss=0.677, ppl=1.6, wps=22277.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42200, lr=0.000153937, gnorm=0.769, loss_scale=32, train_wall=264, gb_free=8.1, wall=124997
2022-03-07 23:34:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:34:59 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.087 | nll_loss 12.33 | ppl 5147.59 | wps 43254.1 | wpb 510.9 | bsz 1 | num_updates 42203 | best_loss 8.481
2022-03-07 23:34:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 42203 updates
2022-03-07 23:34:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:35:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:35:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 438 @ 42203 updates, score 13.087) (writing took 2.296816456131637 seconds)
2022-03-07 23:35:01 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 23:35:01 | INFO | train | epoch 438 | loss 2.515 | nll_loss 0.675 | ppl 1.6 | wps 22253.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42203 | lr 0.000153932 | gnorm 0.768 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 125013
2022-03-07 23:35:01 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 23:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:35:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:39:44 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.041 | nll_loss 12.274 | ppl 4953.23 | wps 43368.4 | wpb 510.9 | bsz 1 | num_updates 42299 | best_loss 8.481
2022-03-07 23:39:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 42299 updates
2022-03-07 23:39:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:39:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:39:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 439 @ 42299 updates, score 13.041) (writing took 2.250275431666523 seconds)
2022-03-07 23:39:46 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 23:39:46 | INFO | train | epoch 439 | loss 2.514 | nll_loss 0.674 | ppl 1.6 | wps 22035.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42299 | lr 0.000153757 | gnorm 0.78 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 125298
2022-03-07 23:39:46 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 23:39:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:39:49 | INFO | train_inner | epoch 440:      1 / 97 loss=2.514, nll_loss=0.674, ppl=1.6, wps=21523.4, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=42300, lr=0.000153755, gnorm=0.78, loss_scale=16, train_wall=266, gb_free=8.1, wall=125301
2022-03-07 23:43:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:44:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:44:29 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 13.066 | nll_loss 12.304 | ppl 5057.82 | wps 43182 | wpb 510.9 | bsz 1 | num_updates 42395 | best_loss 8.481
2022-03-07 23:44:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 42395 updates
2022-03-07 23:44:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:44:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:44:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 440 @ 42395 updates, score 13.066) (writing took 2.2257650392130017 seconds)
2022-03-07 23:44:31 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 23:44:31 | INFO | train | epoch 440 | loss 2.514 | nll_loss 0.674 | ppl 1.6 | wps 22050 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42395 | lr 0.000153583 | gnorm 0.763 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 125583
2022-03-07 23:44:31 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 23:44:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:44:46 | INFO | train_inner | epoch 441:      5 / 97 loss=2.513, nll_loss=0.673, ppl=1.59, wps=22083.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42400, lr=0.000153574, gnorm=0.763, loss_scale=16, train_wall=266, gb_free=8.1, wall=125598
2022-03-07 23:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:49:14 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.091 | nll_loss 12.331 | ppl 5152.09 | wps 43389.6 | wpb 510.9 | bsz 1 | num_updates 42492 | best_loss 8.481
2022-03-07 23:49:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 42492 updates
2022-03-07 23:49:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:49:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:49:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 441 @ 42492 updates, score 13.091) (writing took 2.3510501482523978 seconds)
2022-03-07 23:49:17 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 23:49:17 | INFO | train | epoch 441 | loss 2.514 | nll_loss 0.675 | ppl 1.6 | wps 22257.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42492 | lr 0.000153407 | gnorm 0.779 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 125869
2022-03-07 23:49:17 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 23:49:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:49:40 | INFO | train_inner | epoch 442:      8 / 97 loss=2.514, nll_loss=0.674, ppl=1.6, wps=22270, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42500, lr=0.000153393, gnorm=0.778, loss_scale=16, train_wall=264, gb_free=8.1, wall=125892
2022-03-07 23:50:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:53:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:54:00 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.118 | nll_loss 12.36 | ppl 5255.62 | wps 43474.5 | wpb 510.9 | bsz 1 | num_updates 42588 | best_loss 8.481
2022-03-07 23:54:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 42588 updates
2022-03-07 23:54:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:54:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:54:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 442 @ 42588 updates, score 13.118) (writing took 2.2617631191387773 seconds)
2022-03-07 23:54:02 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 23:54:02 | INFO | train | epoch 442 | loss 2.512 | nll_loss 0.672 | ppl 1.59 | wps 22020 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42588 | lr 0.000153234 | gnorm 0.772 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 126154
2022-03-07 23:54:02 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 23:54:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:54:37 | INFO | train_inner | epoch 443:     12 / 97 loss=2.511, nll_loss=0.672, ppl=1.59, wps=22055.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42600, lr=0.000153213, gnorm=0.774, loss_scale=16, train_wall=266, gb_free=8.1, wall=126189
2022-03-07 23:58:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:58:45 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.009 | nll_loss 12.247 | ppl 4859.95 | wps 43407.4 | wpb 510.9 | bsz 1 | num_updates 42685 | best_loss 8.481
2022-03-07 23:58:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 42685 updates
2022-03-07 23:58:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 443 @ 42685 updates, score 13.009) (writing took 2.3050914178602397 seconds)
2022-03-07 23:58:48 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 23:58:48 | INFO | train | epoch 443 | loss 2.512 | nll_loss 0.672 | ppl 1.59 | wps 22263 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42685 | lr 0.00015306 | gnorm 0.772 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 126440
2022-03-07 23:58:48 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 23:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:59:31 | INFO | train_inner | epoch 444:     15 / 97 loss=2.512, nll_loss=0.672, ppl=1.59, wps=22276.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42700, lr=0.000153033, gnorm=0.768, loss_scale=32, train_wall=264, gb_free=8.1, wall=126483
2022-03-08 00:02:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:03:31 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.043 | nll_loss 12.278 | ppl 4965.6 | wps 42706.3 | wpb 510.9 | bsz 1 | num_updates 42781 | best_loss 8.481
2022-03-08 00:03:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 42781 updates
2022-03-08 00:03:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:03:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 444 @ 42781 updates, score 13.043) (writing took 2.2232151911593974 seconds)
2022-03-08 00:03:33 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-08 00:03:33 | INFO | train | epoch 444 | loss 2.512 | nll_loss 0.672 | ppl 1.59 | wps 22020.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42781 | lr 0.000152888 | gnorm 0.769 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 126725
2022-03-08 00:03:33 | INFO | fairseq.trainer | begin training epoch 445
2022-03-08 00:03:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:04:28 | INFO | train_inner | epoch 445:     19 / 97 loss=2.511, nll_loss=0.671, ppl=1.59, wps=22059.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42800, lr=0.000152854, gnorm=0.771, loss_scale=32, train_wall=266, gb_free=8.1, wall=126780
2022-03-08 00:04:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:08:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:08:16 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.055 | nll_loss 12.296 | ppl 5027.86 | wps 42889.9 | wpb 510.9 | bsz 1 | num_updates 42877 | best_loss 8.481
2022-03-08 00:08:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 42877 updates
2022-03-08 00:08:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:08:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:08:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 445 @ 42877 updates, score 13.055) (writing took 2.2297004172578454 seconds)
2022-03-08 00:08:19 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-08 00:08:19 | INFO | train | epoch 445 | loss 2.51 | nll_loss 0.671 | ppl 1.59 | wps 22030.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42877 | lr 0.000152717 | gnorm 0.767 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 127010
2022-03-08 00:08:19 | INFO | fairseq.trainer | begin training epoch 446
2022-03-08 00:08:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:09:25 | INFO | train_inner | epoch 446:     23 / 97 loss=2.509, nll_loss=0.669, ppl=1.59, wps=22049.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42900, lr=0.000152676, gnorm=0.765, loss_scale=16, train_wall=266, gb_free=8.1, wall=127077
2022-03-08 00:12:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:12:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:13:02 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.008 | nll_loss 12.238 | ppl 4831.43 | wps 43129.6 | wpb 510.9 | bsz 1 | num_updates 42973 | best_loss 8.481
2022-03-08 00:13:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 42973 updates
2022-03-08 00:13:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:13:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:13:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 446 @ 42973 updates, score 13.008) (writing took 2.2521490398794413 seconds)
2022-03-08 00:13:04 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-08 00:13:04 | INFO | train | epoch 446 | loss 2.511 | nll_loss 0.671 | ppl 1.59 | wps 22011 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42973 | lr 0.000152546 | gnorm 0.772 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 127296
2022-03-08 00:13:04 | INFO | fairseq.trainer | begin training epoch 447
2022-03-08 00:13:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:14:22 | INFO | train_inner | epoch 447:     27 / 97 loss=2.511, nll_loss=0.671, ppl=1.59, wps=22045.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43000, lr=0.000152499, gnorm=0.775, loss_scale=16, train_wall=266, gb_free=8.1, wall=127374
2022-03-08 00:17:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:17:47 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.042 | nll_loss 12.28 | ppl 4973.05 | wps 43447.3 | wpb 510.9 | bsz 1 | num_updates 43070 | best_loss 8.481
2022-03-08 00:17:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 43070 updates
2022-03-08 00:17:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:17:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:17:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 447 @ 43070 updates, score 13.042) (writing took 2.226274536922574 seconds)
2022-03-08 00:17:50 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-08 00:17:50 | INFO | train | epoch 447 | loss 2.509 | nll_loss 0.67 | ppl 1.59 | wps 22257.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43070 | lr 0.000152375 | gnorm 0.762 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 127581
2022-03-08 00:17:50 | INFO | fairseq.trainer | begin training epoch 448
2022-03-08 00:17:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:19:16 | INFO | train_inner | epoch 448:     30 / 97 loss=2.509, nll_loss=0.669, ppl=1.59, wps=22277, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43100, lr=0.000152322, gnorm=0.76, loss_scale=32, train_wall=264, gb_free=8.1, wall=127668
2022-03-08 00:19:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:22:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:22:33 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.055 | nll_loss 12.294 | ppl 5022.08 | wps 42963.2 | wpb 510.9 | bsz 1 | num_updates 43166 | best_loss 8.481
2022-03-08 00:22:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 43166 updates
2022-03-08 00:22:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:22:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:22:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 448 @ 43166 updates, score 13.055) (writing took 2.268997097853571 seconds)
2022-03-08 00:22:35 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-08 00:22:35 | INFO | train | epoch 448 | loss 2.509 | nll_loss 0.67 | ppl 1.59 | wps 22010.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43166 | lr 0.000152205 | gnorm 0.771 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 127867
2022-03-08 00:22:35 | INFO | fairseq.trainer | begin training epoch 449
2022-03-08 00:22:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:24:13 | INFO | train_inner | epoch 449:     34 / 97 loss=2.508, nll_loss=0.669, ppl=1.59, wps=22044.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=43200, lr=0.000152145, gnorm=0.771, loss_scale=16, train_wall=266, gb_free=8.1, wall=127965
2022-03-08 00:26:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:27:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:27:18 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.073 | nll_loss 12.311 | ppl 5083.05 | wps 43148 | wpb 510.9 | bsz 1 | num_updates 43262 | best_loss 8.481
2022-03-08 00:27:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 43262 updates
2022-03-08 00:27:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:27:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:27:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 449 @ 43262 updates, score 13.073) (writing took 2.215519585646689 seconds)
2022-03-08 00:27:21 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-08 00:27:21 | INFO | train | epoch 449 | loss 2.508 | nll_loss 0.669 | ppl 1.59 | wps 22028.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43262 | lr 0.000152036 | gnorm 0.771 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 128153
2022-03-08 00:27:21 | INFO | fairseq.trainer | begin training epoch 450
2022-03-08 00:27:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:29:10 | INFO | train_inner | epoch 450:     38 / 97 loss=2.508, nll_loss=0.669, ppl=1.59, wps=22053.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43300, lr=0.000151969, gnorm=0.77, loss_scale=16, train_wall=266, gb_free=8.1, wall=128262
2022-03-08 00:31:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:32:04 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.044 | nll_loss 12.287 | ppl 4998.9 | wps 43232.9 | wpb 510.9 | bsz 1 | num_updates 43359 | best_loss 8.481
2022-03-08 00:32:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 43359 updates
2022-03-08 00:32:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:32:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:32:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 450 @ 43359 updates, score 13.044) (writing took 2.2550325361080468 seconds)
2022-03-08 00:32:06 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-08 00:32:06 | INFO | train | epoch 450 | loss 2.507 | nll_loss 0.668 | ppl 1.59 | wps 22242.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43359 | lr 0.000151866 | gnorm 0.769 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 128438
2022-03-08 00:32:06 | INFO | fairseq.trainer | begin training epoch 451
2022-03-08 00:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:34:04 | INFO | train_inner | epoch 451:     41 / 97 loss=2.507, nll_loss=0.668, ppl=1.59, wps=22269.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43400, lr=0.000151794, gnorm=0.768, loss_scale=32, train_wall=264, gb_free=8.1, wall=128556
2022-03-08 00:35:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:36:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:36:49 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.07 | nll_loss 12.311 | ppl 5082.32 | wps 43239.7 | wpb 510.9 | bsz 1 | num_updates 43455 | best_loss 8.481
2022-03-08 00:36:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 43455 updates
2022-03-08 00:36:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:36:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:36:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 451 @ 43455 updates, score 13.07) (writing took 2.2651280211284757 seconds)
2022-03-08 00:36:52 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-08 00:36:52 | INFO | train | epoch 451 | loss 2.507 | nll_loss 0.668 | ppl 1.59 | wps 22034.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43455 | lr 0.000151698 | gnorm 0.769 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 128723
2022-03-08 00:36:52 | INFO | fairseq.trainer | begin training epoch 452
2022-03-08 00:36:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:39:01 | INFO | train_inner | epoch 452:     45 / 97 loss=2.506, nll_loss=0.666, ppl=1.59, wps=22063.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43500, lr=0.00015162, gnorm=0.771, loss_scale=16, train_wall=266, gb_free=8.1, wall=128853
2022-03-08 00:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:41:35 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.112 | nll_loss 12.361 | ppl 5261.33 | wps 43059.4 | wpb 510.9 | bsz 1 | num_updates 43552 | best_loss 8.481
2022-03-08 00:41:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 43552 updates
2022-03-08 00:41:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:41:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 452 @ 43552 updates, score 13.112) (writing took 2.2838522819802165 seconds)
2022-03-08 00:41:37 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-08 00:41:37 | INFO | train | epoch 452 | loss 2.506 | nll_loss 0.667 | ppl 1.59 | wps 22259.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43552 | lr 0.000151529 | gnorm 0.771 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 129009
2022-03-08 00:41:37 | INFO | fairseq.trainer | begin training epoch 453
2022-03-08 00:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:42:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:43:58 | INFO | train_inner | epoch 453:     49 / 97 loss=2.506, nll_loss=0.666, ppl=1.59, wps=22059, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43600, lr=0.000151446, gnorm=0.768, loss_scale=16, train_wall=266, gb_free=8.1, wall=129150
2022-03-08 00:46:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:46:20 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.105 | nll_loss 12.35 | ppl 5221.46 | wps 43142.4 | wpb 510.9 | bsz 1 | num_updates 43648 | best_loss 8.481
2022-03-08 00:46:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 43648 updates
2022-03-08 00:46:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:46:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 453 @ 43648 updates, score 13.105) (writing took 2.31720380904153 seconds)
2022-03-08 00:46:22 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-08 00:46:22 | INFO | train | epoch 453 | loss 2.506 | nll_loss 0.666 | ppl 1.59 | wps 22025.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43648 | lr 0.000151362 | gnorm 0.769 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 129294
2022-03-08 00:46:22 | INFO | fairseq.trainer | begin training epoch 454
2022-03-08 00:46:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:48:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:48:54 | INFO | train_inner | epoch 454:     53 / 97 loss=2.505, nll_loss=0.666, ppl=1.59, wps=22071.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=43700, lr=0.000151272, gnorm=0.761, loss_scale=16, train_wall=266, gb_free=8.1, wall=129446
2022-03-08 00:51:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:51:05 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.071 | nll_loss 12.316 | ppl 5097.96 | wps 43138.8 | wpb 510.9 | bsz 1 | num_updates 43744 | best_loss 8.481
2022-03-08 00:51:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 43744 updates
2022-03-08 00:51:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:51:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:51:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 454 @ 43744 updates, score 13.071) (writing took 2.288771204184741 seconds)
2022-03-08 00:51:08 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-08 00:51:08 | INFO | train | epoch 454 | loss 2.504 | nll_loss 0.665 | ppl 1.59 | wps 22033.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43744 | lr 0.000151196 | gnorm 0.757 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 129580
2022-03-08 00:51:08 | INFO | fairseq.trainer | begin training epoch 455
2022-03-08 00:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:53:48 | INFO | train_inner | epoch 455:     56 / 97 loss=2.505, nll_loss=0.666, ppl=1.59, wps=22278.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43800, lr=0.000151099, gnorm=0.767, loss_scale=16, train_wall=264, gb_free=8.1, wall=129740
2022-03-08 00:55:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:55:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:55:51 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.046 | nll_loss 12.287 | ppl 4997.63 | wps 42964.7 | wpb 510.9 | bsz 1 | num_updates 43840 | best_loss 8.481
2022-03-08 00:55:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 43840 updates
2022-03-08 00:55:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:55:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:55:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 455 @ 43840 updates, score 13.046) (writing took 2.2353179310448468 seconds)
2022-03-08 00:55:53 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-08 00:55:53 | INFO | train | epoch 455 | loss 2.505 | nll_loss 0.666 | ppl 1.59 | wps 22045.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43840 | lr 0.000151031 | gnorm 0.774 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 129865
2022-03-08 00:55:53 | INFO | fairseq.trainer | begin training epoch 456
2022-03-08 00:55:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:58:45 | INFO | train_inner | epoch 456:     60 / 97 loss=2.506, nll_loss=0.666, ppl=1.59, wps=22087.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=43900, lr=0.000150927, gnorm=0.773, loss_scale=16, train_wall=266, gb_free=8.1, wall=130037
2022-03-08 01:00:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:00:36 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 12.93 | nll_loss 12.158 | ppl 4568.57 | wps 43176.6 | wpb 510.9 | bsz 1 | num_updates 43937 | best_loss 8.481
2022-03-08 01:00:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 43937 updates
2022-03-08 01:00:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:00:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:00:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 456 @ 43937 updates, score 12.93) (writing took 2.2670519961975515 seconds)
2022-03-08 01:00:38 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-08 01:00:38 | INFO | train | epoch 456 | loss 2.504 | nll_loss 0.664 | ppl 1.58 | wps 22286.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43937 | lr 0.000150864 | gnorm 0.766 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 130150
2022-03-08 01:00:38 | INFO | fairseq.trainer | begin training epoch 457
2022-03-08 01:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:02:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:03:41 | INFO | train_inner | epoch 457:     64 / 97 loss=2.503, nll_loss=0.663, ppl=1.58, wps=22090, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44000, lr=0.000150756, gnorm=0.762, loss_scale=16, train_wall=266, gb_free=8.1, wall=130333
2022-03-08 01:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:05:21 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.105 | nll_loss 12.348 | ppl 5212.01 | wps 43512 | wpb 510.9 | bsz 1 | num_updates 44033 | best_loss 8.481
2022-03-08 01:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 44033 updates
2022-03-08 01:05:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:05:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:05:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 457 @ 44033 updates, score 13.105) (writing took 2.321350202895701 seconds)
2022-03-08 01:05:23 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-08 01:05:23 | INFO | train | epoch 457 | loss 2.503 | nll_loss 0.664 | ppl 1.58 | wps 22057.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44033 | lr 0.000150699 | gnorm 0.765 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 130435
2022-03-08 01:05:23 | INFO | fairseq.trainer | begin training epoch 458
2022-03-08 01:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:08:35 | INFO | train_inner | epoch 458:     67 / 97 loss=2.501, nll_loss=0.662, ppl=1.58, wps=22297.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=44100, lr=0.000150585, gnorm=0.759, loss_scale=32, train_wall=263, gb_free=8.1, wall=130627
2022-03-08 01:10:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:10:06 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.11 | nll_loss 12.356 | ppl 5240.55 | wps 43073.3 | wpb 510.9 | bsz 1 | num_updates 44130 | best_loss 8.481
2022-03-08 01:10:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 44130 updates
2022-03-08 01:10:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:10:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:10:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 458 @ 44130 updates, score 13.11) (writing took 2.3189664338715374 seconds)
2022-03-08 01:10:08 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-08 01:10:08 | INFO | train | epoch 458 | loss 2.502 | nll_loss 0.663 | ppl 1.58 | wps 22268.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44130 | lr 0.000150533 | gnorm 0.757 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 130720
2022-03-08 01:10:08 | INFO | fairseq.trainer | begin training epoch 459
2022-03-08 01:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:10:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:13:32 | INFO | train_inner | epoch 459:     71 / 97 loss=2.504, nll_loss=0.665, ppl=1.59, wps=22078.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44200, lr=0.000150414, gnorm=0.769, loss_scale=16, train_wall=266, gb_free=8.1, wall=130924
2022-03-08 01:14:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:14:51 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.082 | nll_loss 12.323 | ppl 5125.1 | wps 43234.3 | wpb 510.9 | bsz 1 | num_updates 44226 | best_loss 8.481
2022-03-08 01:14:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 44226 updates
2022-03-08 01:14:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:14:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:14:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 459 @ 44226 updates, score 13.082) (writing took 2.2742689047008753 seconds)
2022-03-08 01:14:53 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-08 01:14:53 | INFO | train | epoch 459 | loss 2.502 | nll_loss 0.663 | ppl 1.58 | wps 22056 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44226 | lr 0.00015037 | gnorm 0.771 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 131005
2022-03-08 01:14:53 | INFO | fairseq.trainer | begin training epoch 460
2022-03-08 01:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:18:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:18:28 | INFO | train_inner | epoch 460:     75 / 97 loss=2.503, nll_loss=0.664, ppl=1.58, wps=22081.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44300, lr=0.000150244, gnorm=0.768, loss_scale=16, train_wall=266, gb_free=8.1, wall=131220
2022-03-08 01:19:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:19:36 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.009 | nll_loss 12.245 | ppl 4855.22 | wps 43137 | wpb 510.9 | bsz 1 | num_updates 44322 | best_loss 8.481
2022-03-08 01:19:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 44322 updates
2022-03-08 01:19:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:19:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:19:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 460 @ 44322 updates, score 13.009) (writing took 2.2753514093346894 seconds)
2022-03-08 01:19:38 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-08 01:19:38 | INFO | train | epoch 460 | loss 2.502 | nll_loss 0.663 | ppl 1.58 | wps 22049.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44322 | lr 0.000150207 | gnorm 0.768 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 131290
2022-03-08 01:19:38 | INFO | fairseq.trainer | begin training epoch 461
2022-03-08 01:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:23:22 | INFO | train_inner | epoch 461:     78 / 97 loss=2.5, nll_loss=0.661, ppl=1.58, wps=22298.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44400, lr=0.000150075, gnorm=0.765, loss_scale=16, train_wall=264, gb_free=8.1, wall=131514
2022-03-08 01:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:24:21 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.041 | nll_loss 12.281 | ppl 4977.73 | wps 43267.7 | wpb 510.9 | bsz 1 | num_updates 44419 | best_loss 8.481
2022-03-08 01:24:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 44419 updates
2022-03-08 01:24:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:24:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:24:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 461 @ 44419 updates, score 13.041) (writing took 2.321744173299521 seconds)
2022-03-08 01:24:24 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-08 01:24:24 | INFO | train | epoch 461 | loss 2.5 | nll_loss 0.661 | ppl 1.58 | wps 22276.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44419 | lr 0.000150043 | gnorm 0.759 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 131576
2022-03-08 01:24:24 | INFO | fairseq.trainer | begin training epoch 462
2022-03-08 01:24:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:25:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:28:19 | INFO | train_inner | epoch 462:     82 / 97 loss=2.5, nll_loss=0.661, ppl=1.58, wps=22084.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44500, lr=0.000149906, gnorm=0.76, loss_scale=16, train_wall=266, gb_free=8.1, wall=131811
2022-03-08 01:29:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:29:06 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 12.999 | nll_loss 12.234 | ppl 4815.78 | wps 43264.3 | wpb 510.9 | bsz 1 | num_updates 44515 | best_loss 8.481
2022-03-08 01:29:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 44515 updates
2022-03-08 01:29:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:29:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:29:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 462 @ 44515 updates, score 12.999) (writing took 2.332363066729158 seconds)
2022-03-08 01:29:09 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-08 01:29:09 | INFO | train | epoch 462 | loss 2.5 | nll_loss 0.661 | ppl 1.58 | wps 22047.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44515 | lr 0.000149881 | gnorm 0.763 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 131861
2022-03-08 01:29:09 | INFO | fairseq.trainer | begin training epoch 463
2022-03-08 01:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:32:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:33:15 | INFO | train_inner | epoch 463:     86 / 97 loss=2.502, nll_loss=0.663, ppl=1.58, wps=22077.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44600, lr=0.000149738, gnorm=0.774, loss_scale=16, train_wall=266, gb_free=8.1, wall=132107
2022-03-08 01:33:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:33:52 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.182 | nll_loss 12.433 | ppl 5531.45 | wps 43106.3 | wpb 510.9 | bsz 1 | num_updates 44611 | best_loss 8.481
2022-03-08 01:33:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 44611 updates
2022-03-08 01:33:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:33:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:33:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 463 @ 44611 updates, score 13.182) (writing took 2.282316700089723 seconds)
2022-03-08 01:33:54 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-08 01:33:54 | INFO | train | epoch 463 | loss 2.5 | nll_loss 0.662 | ppl 1.58 | wps 22052.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44611 | lr 0.00014972 | gnorm 0.773 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 132146
2022-03-08 01:33:54 | INFO | fairseq.trainer | begin training epoch 464
2022-03-08 01:33:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:38:09 | INFO | train_inner | epoch 464:     89 / 97 loss=2.498, nll_loss=0.659, ppl=1.58, wps=22296.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=44700, lr=0.000149571, gnorm=0.761, loss_scale=16, train_wall=264, gb_free=8.1, wall=132401
2022-03-08 01:38:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:38:37 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.04 | nll_loss 12.275 | ppl 4957.04 | wps 43252 | wpb 510.9 | bsz 1 | num_updates 44708 | best_loss 8.481
2022-03-08 01:38:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 44708 updates
2022-03-08 01:38:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:38:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 464 @ 44708 updates, score 13.04) (writing took 2.314836753066629 seconds)
2022-03-08 01:38:39 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-08 01:38:39 | INFO | train | epoch 464 | loss 2.498 | nll_loss 0.659 | ppl 1.58 | wps 22273.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44708 | lr 0.000149557 | gnorm 0.758 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 132431
2022-03-08 01:38:39 | INFO | fairseq.trainer | begin training epoch 465
2022-03-08 01:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:39:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:43:06 | INFO | train_inner | epoch 465:     93 / 97 loss=2.499, nll_loss=0.66, ppl=1.58, wps=22083.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=44800, lr=0.000149404, gnorm=0.768, loss_scale=16, train_wall=266, gb_free=8.1, wall=132697
2022-03-08 01:43:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:43:22 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.028 | nll_loss 12.268 | ppl 4933.54 | wps 43108.6 | wpb 510.9 | bsz 1 | num_updates 44804 | best_loss 8.481
2022-03-08 01:43:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 44804 updates
2022-03-08 01:43:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:43:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:43:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 465 @ 44804 updates, score 13.028) (writing took 2.2630966743454337 seconds)
2022-03-08 01:43:24 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-08 01:43:24 | INFO | train | epoch 465 | loss 2.498 | nll_loss 0.659 | ppl 1.58 | wps 22053.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44804 | lr 0.000149397 | gnorm 0.768 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 132716
2022-03-08 01:43:24 | INFO | fairseq.trainer | begin training epoch 466
2022-03-08 01:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:46:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:48:02 | INFO | train_inner | epoch 466:     97 / 97 loss=2.497, nll_loss=0.658, ppl=1.58, wps=22096.9, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=44900, lr=0.000149237, gnorm=0.761, loss_scale=16, train_wall=266, gb_free=8.1, wall=132994
2022-03-08 01:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:48:07 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.104 | nll_loss 12.347 | ppl 5210.85 | wps 43027.3 | wpb 510.9 | bsz 1 | num_updates 44900 | best_loss 8.481
2022-03-08 01:48:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 44900 updates
2022-03-08 01:48:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 466 @ 44900 updates, score 13.104) (writing took 4.833664193749428 seconds)
2022-03-08 01:48:12 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-08 01:48:12 | INFO | train | epoch 466 | loss 2.497 | nll_loss 0.658 | ppl 1.58 | wps 21868.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 44900 | lr 0.000149237 | gnorm 0.76 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133004
2022-03-08 01:48:12 | INFO | fairseq.trainer | begin training epoch 467
2022-03-08 01:48:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:52:55 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.056 | nll_loss 12.298 | ppl 5037.44 | wps 42925.1 | wpb 510.9 | bsz 1 | num_updates 44997 | best_loss 8.481
2022-03-08 01:52:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 44997 updates
2022-03-08 01:52:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:52:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:52:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 467 @ 44997 updates, score 13.056) (writing took 2.32286397786811 seconds)
2022-03-08 01:52:57 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-08 01:52:57 | INFO | train | epoch 467 | loss 2.498 | nll_loss 0.659 | ppl 1.58 | wps 22248.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44997 | lr 0.000149076 | gnorm 0.763 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 133289
2022-03-08 01:52:57 | INFO | fairseq.trainer | begin training epoch 468
2022-03-08 01:52:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:53:06 | INFO | train_inner | epoch 468:      3 / 97 loss=2.497, nll_loss=0.658, ppl=1.58, wps=21533.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=45000, lr=0.000149071, gnorm=0.762, loss_scale=16, train_wall=264, gb_free=8.1, wall=133298
2022-03-08 01:54:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:57:40 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.036 | nll_loss 12.279 | ppl 4970.45 | wps 42943.2 | wpb 510.9 | bsz 1 | num_updates 45093 | best_loss 8.481
2022-03-08 01:57:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 45093 updates
2022-03-08 01:57:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:57:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 468 @ 45093 updates, score 13.036) (writing took 2.279408846050501 seconds)
2022-03-08 01:57:43 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-08 01:57:43 | INFO | train | epoch 468 | loss 2.496 | nll_loss 0.657 | ppl 1.58 | wps 22039.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45093 | lr 0.000148917 | gnorm 0.757 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 133574
2022-03-08 01:57:43 | INFO | fairseq.trainer | begin training epoch 469
2022-03-08 01:57:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:58:03 | INFO | train_inner | epoch 469:      7 / 97 loss=2.495, nll_loss=0.656, ppl=1.58, wps=22071.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45100, lr=0.000148906, gnorm=0.757, loss_scale=16, train_wall=266, gb_free=8.1, wall=133595
2022-03-08 02:00:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:02:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:02:25 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.024 | nll_loss 12.267 | ppl 4928.89 | wps 42981.1 | wpb 510.9 | bsz 1 | num_updates 45189 | best_loss 8.481
2022-03-08 02:02:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 45189 updates
2022-03-08 02:02:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:02:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:02:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 469 @ 45189 updates, score 13.024) (writing took 2.2687790393829346 seconds)
2022-03-08 02:02:28 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-08 02:02:28 | INFO | train | epoch 469 | loss 2.496 | nll_loss 0.657 | ppl 1.58 | wps 22058.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45189 | lr 0.000148759 | gnorm 0.773 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133859
2022-03-08 02:02:28 | INFO | fairseq.trainer | begin training epoch 470
2022-03-08 02:02:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:02:59 | INFO | train_inner | epoch 470:     11 / 97 loss=2.496, nll_loss=0.658, ppl=1.58, wps=22081.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=45200, lr=0.000148741, gnorm=0.773, loss_scale=16, train_wall=266, gb_free=8.1, wall=133891
2022-03-08 02:07:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:07:11 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.124 | nll_loss 12.372 | ppl 5300.3 | wps 43213.4 | wpb 510.9 | bsz 1 | num_updates 45286 | best_loss 8.481
2022-03-08 02:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 45286 updates
2022-03-08 02:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:07:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:07:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 470 @ 45286 updates, score 13.124) (writing took 2.433835133910179 seconds)
2022-03-08 02:07:13 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-08 02:07:13 | INFO | train | epoch 470 | loss 2.495 | nll_loss 0.657 | ppl 1.58 | wps 22250 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45286 | lr 0.0001486 | gnorm 0.767 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 134145
2022-03-08 02:07:13 | INFO | fairseq.trainer | begin training epoch 471
2022-03-08 02:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:07:53 | INFO | train_inner | epoch 471:     14 / 97 loss=2.495, nll_loss=0.656, ppl=1.58, wps=22277, ups=0.34, wpb=65495, bsz=127.9, num_updates=45300, lr=0.000148577, gnorm=0.764, loss_scale=32, train_wall=264, gb_free=8.1, wall=134185
2022-03-08 02:10:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:11:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:11:56 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 12.994 | nll_loss 12.234 | ppl 4817.98 | wps 43356.9 | wpb 510.9 | bsz 1 | num_updates 45382 | best_loss 8.481
2022-03-08 02:11:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 45382 updates
2022-03-08 02:11:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:11:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:11:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 471 @ 45382 updates, score 12.994) (writing took 2.2842115880921483 seconds)
2022-03-08 02:11:58 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-08 02:11:58 | INFO | train | epoch 471 | loss 2.495 | nll_loss 0.656 | ppl 1.58 | wps 22054.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45382 | lr 0.000148442 | gnorm 0.766 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 134430
2022-03-08 02:11:58 | INFO | fairseq.trainer | begin training epoch 472
2022-03-08 02:11:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:12:50 | INFO | train_inner | epoch 472:     18 / 97 loss=2.493, nll_loss=0.655, ppl=1.57, wps=22084.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45400, lr=0.000148413, gnorm=0.766, loss_scale=16, train_wall=266, gb_free=8.1, wall=134482
2022-03-08 02:16:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:16:41 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.067 | nll_loss 12.312 | ppl 5084.98 | wps 43038.2 | wpb 510.9 | bsz 1 | num_updates 45479 | best_loss 8.481
2022-03-08 02:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 45479 updates
2022-03-08 02:16:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:16:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:16:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 472 @ 45479 updates, score 13.067) (writing took 2.2590544777922332 seconds)
2022-03-08 02:16:43 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-08 02:16:43 | INFO | train | epoch 472 | loss 2.494 | nll_loss 0.655 | ppl 1.57 | wps 22273.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45479 | lr 0.000148284 | gnorm 0.762 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 134715
2022-03-08 02:16:43 | INFO | fairseq.trainer | begin training epoch 473
2022-03-08 02:16:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:17:44 | INFO | train_inner | epoch 473:     21 / 97 loss=2.494, nll_loss=0.656, ppl=1.58, wps=22289.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45500, lr=0.00014825, gnorm=0.76, loss_scale=32, train_wall=264, gb_free=8.1, wall=134776
2022-03-08 02:20:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:21:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:21:26 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.048 | nll_loss 12.291 | ppl 5010.56 | wps 43313.9 | wpb 510.9 | bsz 1 | num_updates 45575 | best_loss 8.481
2022-03-08 02:21:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 45575 updates
2022-03-08 02:21:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:21:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:21:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 473 @ 45575 updates, score 13.048) (writing took 2.247554838191718 seconds)
2022-03-08 02:21:29 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-08 02:21:29 | INFO | train | epoch 473 | loss 2.494 | nll_loss 0.655 | ppl 1.58 | wps 22046.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45575 | lr 0.000148128 | gnorm 0.758 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 135000
2022-03-08 02:21:29 | INFO | fairseq.trainer | begin training epoch 474
2022-03-08 02:21:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:22:40 | INFO | train_inner | epoch 474:     25 / 97 loss=2.493, nll_loss=0.654, ppl=1.57, wps=22082.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45600, lr=0.000148087, gnorm=0.757, loss_scale=16, train_wall=266, gb_free=8.1, wall=135072
2022-03-08 02:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:26:11 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.005 | nll_loss 12.248 | ppl 4865.42 | wps 43198.6 | wpb 510.9 | bsz 1 | num_updates 45672 | best_loss 8.481
2022-03-08 02:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 45672 updates
2022-03-08 02:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:26:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 474 @ 45672 updates, score 13.005) (writing took 2.332073860336095 seconds)
2022-03-08 02:26:14 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-08 02:26:14 | INFO | train | epoch 474 | loss 2.493 | nll_loss 0.654 | ppl 1.57 | wps 22281.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45672 | lr 0.00014797 | gnorm 0.754 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 135286
2022-03-08 02:26:14 | INFO | fairseq.trainer | begin training epoch 475
2022-03-08 02:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:27:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:27:37 | INFO | train_inner | epoch 475:     29 / 97 loss=2.493, nll_loss=0.655, ppl=1.57, wps=22083.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45700, lr=0.000147925, gnorm=0.759, loss_scale=16, train_wall=266, gb_free=8.1, wall=135369
2022-03-08 02:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:30:56 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.056 | nll_loss 12.301 | ppl 5046.5 | wps 43231.6 | wpb 510.9 | bsz 1 | num_updates 45768 | best_loss 8.481
2022-03-08 02:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 45768 updates
2022-03-08 02:30:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 475 @ 45768 updates, score 13.056) (writing took 2.336945666000247 seconds)
2022-03-08 02:30:59 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-08 02:30:59 | INFO | train | epoch 475 | loss 2.492 | nll_loss 0.654 | ppl 1.57 | wps 22052.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45768 | lr 0.000147815 | gnorm 0.773 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 135571
2022-03-08 02:30:59 | INFO | fairseq.trainer | begin training epoch 476
2022-03-08 02:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:32:31 | INFO | train_inner | epoch 476:     32 / 97 loss=2.491, nll_loss=0.652, ppl=1.57, wps=22294.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45800, lr=0.000147764, gnorm=0.77, loss_scale=16, train_wall=263, gb_free=8.1, wall=135662
2022-03-08 02:35:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:35:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:35:42 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.015 | nll_loss 12.255 | ppl 4887.54 | wps 43267.1 | wpb 510.9 | bsz 1 | num_updates 45864 | best_loss 8.481
2022-03-08 02:35:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 45864 updates
2022-03-08 02:35:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:35:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:35:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 476 @ 45864 updates, score 13.015) (writing took 2.2741142851300538 seconds)
2022-03-08 02:35:44 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-08 02:35:44 | INFO | train | epoch 476 | loss 2.491 | nll_loss 0.652 | ppl 1.57 | wps 22047.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45864 | lr 0.00014766 | gnorm 0.756 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135856
2022-03-08 02:35:44 | INFO | fairseq.trainer | begin training epoch 477
2022-03-08 02:35:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:37:27 | INFO | train_inner | epoch 477:     36 / 97 loss=2.491, nll_loss=0.652, ppl=1.57, wps=22082.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45900, lr=0.000147602, gnorm=0.761, loss_scale=16, train_wall=266, gb_free=8.1, wall=135959
2022-03-08 02:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:40:27 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.025 | nll_loss 12.265 | ppl 4922.15 | wps 43364.7 | wpb 510.9 | bsz 1 | num_updates 45961 | best_loss 8.481
2022-03-08 02:40:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 45961 updates
2022-03-08 02:40:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:40:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:40:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 477 @ 45961 updates, score 13.025) (writing took 2.2559001208283007 seconds)
2022-03-08 02:40:29 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-08 02:40:29 | INFO | train | epoch 477 | loss 2.492 | nll_loss 0.654 | ppl 1.57 | wps 22292.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45961 | lr 0.000147504 | gnorm 0.769 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 136141
2022-03-08 02:40:29 | INFO | fairseq.trainer | begin training epoch 478
2022-03-08 02:40:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:41:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:42:23 | INFO | train_inner | epoch 478:     40 / 97 loss=2.491, nll_loss=0.652, ppl=1.57, wps=22098.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46000, lr=0.000147442, gnorm=0.765, loss_scale=16, train_wall=266, gb_free=8.1, wall=136255
2022-03-08 02:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:45:12 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.018 | nll_loss 12.259 | ppl 4902.93 | wps 43147.2 | wpb 510.9 | bsz 1 | num_updates 46057 | best_loss 8.481
2022-03-08 02:45:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 46057 updates
2022-03-08 02:45:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:45:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 478 @ 46057 updates, score 13.018) (writing took 2.292499748058617 seconds)
2022-03-08 02:45:14 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-08 02:45:14 | INFO | train | epoch 478 | loss 2.49 | nll_loss 0.652 | ppl 1.57 | wps 22063.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46057 | lr 0.000147351 | gnorm 0.766 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 136426
2022-03-08 02:45:14 | INFO | fairseq.trainer | begin training epoch 479
2022-03-08 02:45:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:47:17 | INFO | train_inner | epoch 479:     43 / 97 loss=2.49, nll_loss=0.651, ppl=1.57, wps=22300.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=46100, lr=0.000147282, gnorm=0.763, loss_scale=16, train_wall=263, gb_free=8.1, wall=136549
2022-03-08 02:48:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:49:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:49:57 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.021 | nll_loss 12.261 | ppl 4907.78 | wps 43102.6 | wpb 510.9 | bsz 1 | num_updates 46153 | best_loss 8.481
2022-03-08 02:49:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 46153 updates
2022-03-08 02:49:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:49:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:49:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 479 @ 46153 updates, score 13.021) (writing took 2.266004509758204 seconds)
2022-03-08 02:49:59 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-08 02:49:59 | INFO | train | epoch 479 | loss 2.489 | nll_loss 0.651 | ppl 1.57 | wps 22053.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46153 | lr 0.000147197 | gnorm 0.759 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 136711
2022-03-08 02:49:59 | INFO | fairseq.trainer | begin training epoch 480
2022-03-08 02:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:52:14 | INFO | train_inner | epoch 480:     47 / 97 loss=2.489, nll_loss=0.651, ppl=1.57, wps=22085.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46200, lr=0.000147122, gnorm=0.759, loss_scale=16, train_wall=266, gb_free=8.1, wall=136846
2022-03-08 02:54:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:54:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:54:42 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.128 | nll_loss 12.378 | ppl 5322.6 | wps 43222.1 | wpb 510.9 | bsz 1 | num_updates 46249 | best_loss 8.481
2022-03-08 02:54:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 46249 updates
2022-03-08 02:54:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:54:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:54:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 480 @ 46249 updates, score 13.128) (writing took 2.3336446629837155 seconds)
2022-03-08 02:54:44 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-08 02:54:44 | INFO | train | epoch 480 | loss 2.49 | nll_loss 0.651 | ppl 1.57 | wps 22045.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46249 | lr 0.000147045 | gnorm 0.768 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 136996
2022-03-08 02:54:44 | INFO | fairseq.trainer | begin training epoch 481
2022-03-08 02:54:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:57:10 | INFO | train_inner | epoch 481:     51 / 97 loss=2.489, nll_loss=0.651, ppl=1.57, wps=22086.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46300, lr=0.000146964, gnorm=0.764, loss_scale=16, train_wall=266, gb_free=8.1, wall=137142
2022-03-08 02:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:59:27 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.047 | nll_loss 12.295 | ppl 5026.03 | wps 43194.8 | wpb 510.9 | bsz 1 | num_updates 46346 | best_loss 8.481
2022-03-08 02:59:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 46346 updates
2022-03-08 02:59:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:59:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:59:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 481 @ 46346 updates, score 13.047) (writing took 2.2667897301726043 seconds)
2022-03-08 02:59:29 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-08 02:59:29 | INFO | train | epoch 481 | loss 2.488 | nll_loss 0.649 | ppl 1.57 | wps 22293.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46346 | lr 0.000146891 | gnorm 0.751 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 137281
2022-03-08 02:59:29 | INFO | fairseq.trainer | begin training epoch 482
2022-03-08 02:59:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:02:04 | INFO | train_inner | epoch 482:     54 / 97 loss=2.487, nll_loss=0.649, ppl=1.57, wps=22311.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46400, lr=0.000146805, gnorm=0.757, loss_scale=32, train_wall=263, gb_free=8.1, wall=137436
2022-03-08 03:03:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:04:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:04:12 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 12.998 | nll_loss 12.24 | ppl 4836.98 | wps 43234.6 | wpb 510.9 | bsz 1 | num_updates 46442 | best_loss 8.481
2022-03-08 03:04:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 46442 updates
2022-03-08 03:04:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:04:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 482 @ 46442 updates, score 12.998) (writing took 2.940354194957763 seconds)
2022-03-08 03:04:15 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-08 03:04:15 | INFO | train | epoch 482 | loss 2.488 | nll_loss 0.65 | ppl 1.57 | wps 22015.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46442 | lr 0.000146739 | gnorm 0.764 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 137567
2022-03-08 03:04:15 | INFO | fairseq.trainer | begin training epoch 483
2022-03-08 03:04:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:07:01 | INFO | train_inner | epoch 483:     58 / 97 loss=2.488, nll_loss=0.65, ppl=1.57, wps=22039.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=46500, lr=0.000146647, gnorm=0.766, loss_scale=16, train_wall=266, gb_free=8.1, wall=137733
2022-03-08 03:08:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:08:58 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.074 | nll_loss 12.319 | ppl 5108.33 | wps 43394.2 | wpb 510.9 | bsz 1 | num_updates 46539 | best_loss 8.481
2022-03-08 03:08:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 46539 updates
2022-03-08 03:08:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:09:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:09:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 483 @ 46539 updates, score 13.074) (writing took 2.2510472452268004 seconds)
2022-03-08 03:09:00 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-08 03:09:00 | INFO | train | epoch 483 | loss 2.488 | nll_loss 0.649 | ppl 1.57 | wps 22271.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46539 | lr 0.000146586 | gnorm 0.768 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 137852
2022-03-08 03:09:00 | INFO | fairseq.trainer | begin training epoch 484
2022-03-08 03:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:10:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:11:58 | INFO | train_inner | epoch 484:     62 / 97 loss=2.487, nll_loss=0.649, ppl=1.57, wps=22080.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46600, lr=0.00014649, gnorm=0.76, loss_scale=16, train_wall=266, gb_free=8.1, wall=138029
2022-03-08 03:13:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:13:43 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.073 | nll_loss 12.323 | ppl 5122.46 | wps 43202.2 | wpb 510.9 | bsz 1 | num_updates 46635 | best_loss 8.481
2022-03-08 03:13:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 46635 updates
2022-03-08 03:13:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 484 @ 46635 updates, score 13.073) (writing took 2.262533323839307 seconds)
2022-03-08 03:13:45 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-08 03:13:45 | INFO | train | epoch 484 | loss 2.487 | nll_loss 0.648 | ppl 1.57 | wps 22052.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46635 | lr 0.000146435 | gnorm 0.76 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 138137
2022-03-08 03:13:45 | INFO | fairseq.trainer | begin training epoch 485
2022-03-08 03:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:16:51 | INFO | train_inner | epoch 485:     65 / 97 loss=2.487, nll_loss=0.649, ppl=1.57, wps=22297.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=46700, lr=0.000146333, gnorm=0.763, loss_scale=16, train_wall=263, gb_free=8.1, wall=138323
2022-03-08 03:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:18:28 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.091 | nll_loss 12.338 | ppl 5177.4 | wps 43017 | wpb 510.9 | bsz 1 | num_updates 46732 | best_loss 8.481
2022-03-08 03:18:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 46732 updates
2022-03-08 03:18:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 485 @ 46732 updates, score 13.091) (writing took 2.354923734907061 seconds)
2022-03-08 03:18:30 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-08 03:18:30 | INFO | train | epoch 485 | loss 2.487 | nll_loss 0.649 | ppl 1.57 | wps 22276.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46732 | lr 0.000146283 | gnorm 0.761 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 138422
2022-03-08 03:18:30 | INFO | fairseq.trainer | begin training epoch 486
2022-03-08 03:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:18:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:21:48 | INFO | train_inner | epoch 486:     69 / 97 loss=2.487, nll_loss=0.648, ppl=1.57, wps=22081.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46800, lr=0.000146176, gnorm=0.761, loss_scale=16, train_wall=266, gb_free=8.1, wall=138620
2022-03-08 03:23:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:23:13 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 13.153 | nll_loss 12.407 | ppl 5429.36 | wps 43166.4 | wpb 510.9 | bsz 1 | num_updates 46828 | best_loss 8.481
2022-03-08 03:23:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 46828 updates
2022-03-08 03:23:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:23:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:23:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 486 @ 46828 updates, score 13.153) (writing took 2.2977144699543715 seconds)
2022-03-08 03:23:15 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-08 03:23:15 | INFO | train | epoch 486 | loss 2.485 | nll_loss 0.647 | ppl 1.57 | wps 22049.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46828 | lr 0.000146133 | gnorm 0.755 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 138707
2022-03-08 03:23:15 | INFO | fairseq.trainer | begin training epoch 487
2022-03-08 03:23:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:26:42 | INFO | train_inner | epoch 487:     72 / 97 loss=2.485, nll_loss=0.647, ppl=1.57, wps=22299.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46900, lr=0.00014602, gnorm=0.755, loss_scale=32, train_wall=263, gb_free=8.1, wall=138913
2022-03-08 03:27:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:27:58 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.043 | nll_loss 12.286 | ppl 4993.43 | wps 43006.4 | wpb 510.9 | bsz 1 | num_updates 46925 | best_loss 8.481
2022-03-08 03:27:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 46925 updates
2022-03-08 03:27:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:28:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 487 @ 46925 updates, score 13.043) (writing took 2.2841214518994093 seconds)
2022-03-08 03:28:00 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-08 03:28:00 | INFO | train | epoch 487 | loss 2.485 | nll_loss 0.647 | ppl 1.57 | wps 22279.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46925 | lr 0.000145982 | gnorm 0.753 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 138992
2022-03-08 03:28:00 | INFO | fairseq.trainer | begin training epoch 488
2022-03-08 03:28:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:29:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:31:38 | INFO | train_inner | epoch 488:     76 / 97 loss=2.486, nll_loss=0.647, ppl=1.57, wps=22065.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47000, lr=0.000145865, gnorm=0.755, loss_scale=16, train_wall=266, gb_free=8.1, wall=139210
2022-03-08 03:32:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:32:43 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.051 | nll_loss 12.295 | ppl 5026.2 | wps 43151.7 | wpb 510.9 | bsz 1 | num_updates 47021 | best_loss 8.481
2022-03-08 03:32:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 47021 updates
2022-03-08 03:32:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:32:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:32:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 488 @ 47021 updates, score 13.051) (writing took 2.2912520389072597 seconds)
2022-03-08 03:32:46 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-08 03:32:46 | INFO | train | epoch 488 | loss 2.484 | nll_loss 0.646 | ppl 1.57 | wps 22036 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47021 | lr 0.000145832 | gnorm 0.757 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 139278
2022-03-08 03:32:46 | INFO | fairseq.trainer | begin training epoch 489
2022-03-08 03:32:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:36:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:36:35 | INFO | train_inner | epoch 489:     80 / 97 loss=2.485, nll_loss=0.647, ppl=1.57, wps=22093.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47100, lr=0.00014571, gnorm=0.765, loss_scale=16, train_wall=266, gb_free=8.1, wall=139507
2022-03-08 03:37:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:37:28 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.079 | nll_loss 12.324 | ppl 5129.08 | wps 43055.3 | wpb 510.9 | bsz 1 | num_updates 47117 | best_loss 8.481
2022-03-08 03:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 47117 updates
2022-03-08 03:37:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:37:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:37:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 489 @ 47117 updates, score 13.079) (writing took 2.2365256999619305 seconds)
2022-03-08 03:37:31 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-08 03:37:31 | INFO | train | epoch 489 | loss 2.485 | nll_loss 0.647 | ppl 1.57 | wps 22068 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47117 | lr 0.000145684 | gnorm 0.767 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139563
2022-03-08 03:37:31 | INFO | fairseq.trainer | begin training epoch 490
2022-03-08 03:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:41:28 | INFO | train_inner | epoch 490:     83 / 97 loss=2.485, nll_loss=0.647, ppl=1.57, wps=22339.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=47200, lr=0.000145556, gnorm=0.763, loss_scale=16, train_wall=263, gb_free=8.1, wall=139800
2022-03-08 03:42:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:42:13 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.01 | nll_loss 12.254 | ppl 4884.89 | wps 43618 | wpb 510.9 | bsz 1 | num_updates 47214 | best_loss 8.481
2022-03-08 03:42:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 47214 updates
2022-03-08 03:42:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:42:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:42:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 490 @ 47214 updates, score 13.01) (writing took 2.380423415917903 seconds)
2022-03-08 03:42:15 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-08 03:42:15 | INFO | train | epoch 490 | loss 2.484 | nll_loss 0.646 | ppl 1.56 | wps 22315.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47214 | lr 0.000145534 | gnorm 0.76 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139847
2022-03-08 03:42:15 | INFO | fairseq.trainer | begin training epoch 491
2022-03-08 03:42:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:43:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:46:24 | INFO | train_inner | epoch 491:     87 / 97 loss=2.483, nll_loss=0.645, ppl=1.56, wps=22112.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=47300, lr=0.000145402, gnorm=0.753, loss_scale=16, train_wall=266, gb_free=8.1, wall=140096
2022-03-08 03:46:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:46:58 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.139 | nll_loss 12.392 | ppl 5373.2 | wps 43285.1 | wpb 510.9 | bsz 1 | num_updates 47310 | best_loss 8.481
2022-03-08 03:46:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 47310 updates
2022-03-08 03:46:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:47:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:47:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 491 @ 47310 updates, score 13.139) (writing took 2.252613634802401 seconds)
2022-03-08 03:47:00 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-08 03:47:00 | INFO | train | epoch 491 | loss 2.483 | nll_loss 0.645 | ppl 1.56 | wps 22087.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47310 | lr 0.000145386 | gnorm 0.753 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 140132
2022-03-08 03:47:00 | INFO | fairseq.trainer | begin training epoch 492
2022-03-08 03:47:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:50:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:51:20 | INFO | train_inner | epoch 492:     91 / 97 loss=2.483, nll_loss=0.645, ppl=1.56, wps=22113.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47400, lr=0.000145248, gnorm=0.756, loss_scale=16, train_wall=266, gb_free=8.1, wall=140392
2022-03-08 03:51:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:51:42 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.064 | nll_loss 12.303 | ppl 5053.55 | wps 43489 | wpb 510.9 | bsz 1 | num_updates 47406 | best_loss 8.481
2022-03-08 03:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 47406 updates
2022-03-08 03:51:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:51:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:51:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 492 @ 47406 updates, score 13.064) (writing took 2.2784760310314596 seconds)
2022-03-08 03:51:45 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-08 03:51:45 | INFO | train | epoch 492 | loss 2.483 | nll_loss 0.644 | ppl 1.56 | wps 22078.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47406 | lr 0.000145239 | gnorm 0.757 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 140417
2022-03-08 03:51:45 | INFO | fairseq.trainer | begin training epoch 493
2022-03-08 03:51:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:56:14 | INFO | train_inner | epoch 493:     94 / 97 loss=2.482, nll_loss=0.644, ppl=1.56, wps=22320.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47500, lr=0.000145095, gnorm=0.763, loss_scale=16, train_wall=263, gb_free=8.1, wall=140686
2022-03-08 03:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:56:27 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.108 | nll_loss 12.359 | ppl 5254.5 | wps 43209.7 | wpb 510.9 | bsz 1 | num_updates 47503 | best_loss 8.481
2022-03-08 03:56:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 47503 updates
2022-03-08 03:56:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:56:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 03:56:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 493 @ 47503 updates, score 13.108) (writing took 2.2933366070501506 seconds)
2022-03-08 03:56:30 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-08 03:56:30 | INFO | train | epoch 493 | loss 2.482 | nll_loss 0.644 | ppl 1.56 | wps 22301.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47503 | lr 0.000145091 | gnorm 0.763 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 140701
2022-03-08 03:56:30 | INFO | fairseq.trainer | begin training epoch 494
2022-03-08 03:56:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:58:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:01:12 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.119 | nll_loss 12.365 | ppl 5275.96 | wps 42981.6 | wpb 510.9 | bsz 1 | num_updates 47599 | best_loss 8.481
2022-03-08 04:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 47599 updates
2022-03-08 04:01:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:01:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 494 @ 47599 updates, score 13.119) (writing took 2.25759616214782 seconds)
2022-03-08 04:01:14 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-08 04:01:14 | INFO | train | epoch 494 | loss 2.482 | nll_loss 0.644 | ppl 1.56 | wps 22077.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47599 | lr 0.000144944 | gnorm 0.76 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 140986
2022-03-08 04:01:14 | INFO | fairseq.trainer | begin training epoch 495
2022-03-08 04:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:01:17 | INFO | train_inner | epoch 495:      1 / 97 loss=2.482, nll_loss=0.644, ppl=1.56, wps=21564.6, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=47600, lr=0.000144943, gnorm=0.761, loss_scale=16, train_wall=266, gb_free=8.1, wall=140989
2022-03-08 04:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:05:57 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 12.955 | nll_loss 12.196 | ppl 4693.45 | wps 43262.7 | wpb 510.9 | bsz 1 | num_updates 47696 | best_loss 8.481
2022-03-08 04:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 47696 updates
2022-03-08 04:05:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 495 @ 47696 updates, score 12.955) (writing took 2.379022765904665 seconds)
2022-03-08 04:05:59 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-08 04:05:59 | INFO | train | epoch 495 | loss 2.481 | nll_loss 0.642 | ppl 1.56 | wps 22322.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47696 | lr 0.000144797 | gnorm 0.76 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 141271
2022-03-08 04:05:59 | INFO | fairseq.trainer | begin training epoch 496
2022-03-08 04:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:06:10 | INFO | train_inner | epoch 496:      4 / 97 loss=2.48, nll_loss=0.642, ppl=1.56, wps=22337.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47700, lr=0.000144791, gnorm=0.76, loss_scale=32, train_wall=263, gb_free=8.1, wall=141282
2022-03-08 04:06:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:10:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:10:41 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.087 | nll_loss 12.342 | ppl 5190.51 | wps 43203.3 | wpb 510.9 | bsz 1 | num_updates 47792 | best_loss 8.481
2022-03-08 04:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 47792 updates
2022-03-08 04:10:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:10:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 496 @ 47792 updates, score 13.087) (writing took 2.2659276188351214 seconds)
2022-03-08 04:10:44 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-08 04:10:44 | INFO | train | epoch 496 | loss 2.48 | nll_loss 0.642 | ppl 1.56 | wps 22074.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47792 | lr 0.000144651 | gnorm 0.763 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 141556
2022-03-08 04:10:44 | INFO | fairseq.trainer | begin training epoch 497
2022-03-08 04:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:11:07 | INFO | train_inner | epoch 497:      8 / 97 loss=2.48, nll_loss=0.642, ppl=1.56, wps=22104.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47800, lr=0.000144639, gnorm=0.761, loss_scale=16, train_wall=266, gb_free=8.1, wall=141579
2022-03-08 04:14:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:15:26 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.124 | nll_loss 12.376 | ppl 5315.35 | wps 42811.8 | wpb 510.9 | bsz 1 | num_updates 47888 | best_loss 8.481
2022-03-08 04:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 47888 updates
2022-03-08 04:15:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 497 @ 47888 updates, score 13.124) (writing took 2.246581247076392 seconds)
2022-03-08 04:15:28 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-08 04:15:28 | INFO | train | epoch 497 | loss 2.48 | nll_loss 0.642 | ppl 1.56 | wps 22093.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47888 | lr 0.000144506 | gnorm 0.756 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 141840
2022-03-08 04:15:28 | INFO | fairseq.trainer | begin training epoch 498
2022-03-08 04:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:16:03 | INFO | train_inner | epoch 498:     12 / 97 loss=2.479, nll_loss=0.641, ppl=1.56, wps=22133.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47900, lr=0.000144488, gnorm=0.759, loss_scale=16, train_wall=265, gb_free=8.1, wall=141875
2022-03-08 04:20:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:20:10 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.081 | nll_loss 12.329 | ppl 5146.34 | wps 43239.9 | wpb 510.9 | bsz 1 | num_updates 47985 | best_loss 8.481
2022-03-08 04:20:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 47985 updates
2022-03-08 04:20:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:20:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:20:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 498 @ 47985 updates, score 13.081) (writing took 2.3324673040769994 seconds)
2022-03-08 04:20:13 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-08 04:20:13 | INFO | train | epoch 498 | loss 2.479 | nll_loss 0.642 | ppl 1.56 | wps 22330.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47985 | lr 0.00014436 | gnorm 0.761 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 142125
2022-03-08 04:20:13 | INFO | fairseq.trainer | begin training epoch 499
2022-03-08 04:20:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:20:56 | INFO | train_inner | epoch 499:     15 / 97 loss=2.479, nll_loss=0.641, ppl=1.56, wps=22347.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48000, lr=0.000144338, gnorm=0.758, loss_scale=16, train_wall=263, gb_free=8.1, wall=142168
2022-03-08 04:22:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:24:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:24:55 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.091 | nll_loss 12.339 | ppl 5181.32 | wps 43284.8 | wpb 510.9 | bsz 1 | num_updates 48081 | best_loss 8.481
2022-03-08 04:24:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 48081 updates
2022-03-08 04:24:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:24:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:24:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 499 @ 48081 updates, score 13.091) (writing took 2.3026461410336196 seconds)
2022-03-08 04:24:57 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-08 04:24:57 | INFO | train | epoch 499 | loss 2.479 | nll_loss 0.641 | ppl 1.56 | wps 22108.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48081 | lr 0.000144216 | gnorm 0.761 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 142409
2022-03-08 04:24:57 | INFO | fairseq.trainer | begin training epoch 500
2022-03-08 04:24:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:25:52 | INFO | train_inner | epoch 500:     19 / 97 loss=2.478, nll_loss=0.64, ppl=1.56, wps=22139.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48100, lr=0.000144187, gnorm=0.758, loss_scale=16, train_wall=265, gb_free=8.1, wall=142463
2022-03-08 04:29:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:29:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:29:39 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.066 | nll_loss 12.314 | ppl 5092.33 | wps 43140.6 | wpb 510.9 | bsz 1 | num_updates 48177 | best_loss 8.481
2022-03-08 04:29:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 48177 updates
2022-03-08 04:29:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:29:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:29:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 500 @ 48177 updates, score 13.066) (writing took 2.354381110984832 seconds)
2022-03-08 04:29:42 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-08 04:29:42 | INFO | train | epoch 500 | loss 2.478 | nll_loss 0.64 | ppl 1.56 | wps 22095.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48177 | lr 0.000144072 | gnorm 0.757 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 142694
2022-03-08 04:29:42 | INFO | fairseq.trainer | begin training epoch 501
2022-03-08 04:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:30:47 | INFO | train_inner | epoch 501:     23 / 97 loss=2.477, nll_loss=0.639, ppl=1.56, wps=22131.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48200, lr=0.000144038, gnorm=0.756, loss_scale=16, train_wall=265, gb_free=8.1, wall=142759
2022-03-08 04:34:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:34:24 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.061 | nll_loss 12.307 | ppl 5066.43 | wps 43364.7 | wpb 510.9 | bsz 1 | num_updates 48274 | best_loss 8.481
2022-03-08 04:34:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 48274 updates
2022-03-08 04:34:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:34:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 501 @ 48274 updates, score 13.061) (writing took 2.297086979262531 seconds)
2022-03-08 04:34:26 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-08 04:34:26 | INFO | train | epoch 501 | loss 2.477 | nll_loss 0.64 | ppl 1.56 | wps 22353.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48274 | lr 0.000143927 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 142978
2022-03-08 04:34:26 | INFO | fairseq.trainer | begin training epoch 502
2022-03-08 04:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:35:40 | INFO | train_inner | epoch 502:     26 / 97 loss=2.476, nll_loss=0.638, ppl=1.56, wps=22357.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48300, lr=0.000143889, gnorm=0.759, loss_scale=32, train_wall=263, gb_free=8.1, wall=143052
2022-03-08 04:36:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:39:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:39:08 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.089 | nll_loss 12.334 | ppl 5163.15 | wps 43446.4 | wpb 510.9 | bsz 1 | num_updates 48370 | best_loss 8.481
2022-03-08 04:39:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 48370 updates
2022-03-08 04:39:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:39:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 502 @ 48370 updates, score 13.089) (writing took 2.3609128138050437 seconds)
2022-03-08 04:39:10 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-08 04:39:10 | INFO | train | epoch 502 | loss 2.477 | nll_loss 0.639 | ppl 1.56 | wps 22092.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48370 | lr 0.000143784 | gnorm 0.757 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 143262
2022-03-08 04:39:10 | INFO | fairseq.trainer | begin training epoch 503
2022-03-08 04:39:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:40:36 | INFO | train_inner | epoch 503:     30 / 97 loss=2.477, nll_loss=0.639, ppl=1.56, wps=22131.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48400, lr=0.00014374, gnorm=0.752, loss_scale=16, train_wall=265, gb_free=8.1, wall=143348
2022-03-08 04:43:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:43:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:43:53 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.072 | nll_loss 12.319 | ppl 5109.43 | wps 43222.6 | wpb 510.9 | bsz 1 | num_updates 48466 | best_loss 8.481
2022-03-08 04:43:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 48466 updates
2022-03-08 04:43:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:43:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:43:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 503 @ 48466 updates, score 13.072) (writing took 2.3009035559371114 seconds)
2022-03-08 04:43:55 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-08 04:43:55 | INFO | train | epoch 503 | loss 2.476 | nll_loss 0.639 | ppl 1.56 | wps 22107.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48466 | lr 0.000143642 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 143547
2022-03-08 04:43:55 | INFO | fairseq.trainer | begin training epoch 504
2022-03-08 04:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:45:32 | INFO | train_inner | epoch 504:     34 / 97 loss=2.477, nll_loss=0.639, ppl=1.56, wps=22132.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48500, lr=0.000143592, gnorm=0.759, loss_scale=16, train_wall=266, gb_free=8.1, wall=143644
2022-03-08 04:48:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:48:37 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.102 | nll_loss 12.352 | ppl 5228.01 | wps 43260.8 | wpb 510.9 | bsz 1 | num_updates 48563 | best_loss 8.481
2022-03-08 04:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 48563 updates
2022-03-08 04:48:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:48:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:48:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 504 @ 48563 updates, score 13.102) (writing took 2.3571858159266412 seconds)
2022-03-08 04:48:39 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-08 04:48:39 | INFO | train | epoch 504 | loss 2.476 | nll_loss 0.639 | ppl 1.56 | wps 22323.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48563 | lr 0.000143498 | gnorm 0.759 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 143831
2022-03-08 04:48:39 | INFO | fairseq.trainer | begin training epoch 505
2022-03-08 04:48:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:50:25 | INFO | train_inner | epoch 505:     37 / 97 loss=2.475, nll_loss=0.638, ppl=1.56, wps=22347.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48600, lr=0.000143444, gnorm=0.755, loss_scale=32, train_wall=263, gb_free=8.1, wall=143937
2022-03-08 04:51:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:53:22 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.058 | nll_loss 12.298 | ppl 5037.18 | wps 43197.8 | wpb 510.9 | bsz 1 | num_updates 48659 | best_loss 8.481
2022-03-08 04:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 48659 updates
2022-03-08 04:53:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:53:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:53:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 505 @ 48659 updates, score 13.058) (writing took 2.356340087018907 seconds)
2022-03-08 04:53:24 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-08 04:53:24 | INFO | train | epoch 505 | loss 2.475 | nll_loss 0.638 | ppl 1.56 | wps 22095 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48659 | lr 0.000143357 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 144116
2022-03-08 04:53:24 | INFO | fairseq.trainer | begin training epoch 506
2022-03-08 04:53:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:55:21 | INFO | train_inner | epoch 506:     41 / 97 loss=2.476, nll_loss=0.639, ppl=1.56, wps=22129.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=48700, lr=0.000143296, gnorm=0.769, loss_scale=16, train_wall=265, gb_free=8.1, wall=144233
2022-03-08 04:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:58:06 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.074 | nll_loss 12.318 | ppl 5107.66 | wps 42975.7 | wpb 510.9 | bsz 1 | num_updates 48756 | best_loss 8.481
2022-03-08 04:58:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 48756 updates
2022-03-08 04:58:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:58:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 04:58:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 506 @ 48756 updates, score 13.074) (writing took 2.369936072267592 seconds)
2022-03-08 04:58:08 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-08 04:58:08 | INFO | train | epoch 506 | loss 2.476 | nll_loss 0.639 | ppl 1.56 | wps 22335.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48756 | lr 0.000143214 | gnorm 0.763 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 144400
2022-03-08 04:58:08 | INFO | fairseq.trainer | begin training epoch 507
2022-03-08 04:58:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:58:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:00:17 | INFO | train_inner | epoch 507:     45 / 97 loss=2.475, nll_loss=0.638, ppl=1.56, wps=22141.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48800, lr=0.00014315, gnorm=0.753, loss_scale=16, train_wall=265, gb_free=8.1, wall=144529
2022-03-08 05:02:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:02:50 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.131 | nll_loss 12.386 | ppl 5351.81 | wps 43452 | wpb 510.9 | bsz 1 | num_updates 48852 | best_loss 8.481
2022-03-08 05:02:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 48852 updates
2022-03-08 05:02:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:02:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:02:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 507 @ 48852 updates, score 13.131) (writing took 2.348844585940242 seconds)
2022-03-08 05:02:53 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-08 05:02:53 | INFO | train | epoch 507 | loss 2.474 | nll_loss 0.636 | ppl 1.55 | wps 22115.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48852 | lr 0.000143073 | gnorm 0.749 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 144685
2022-03-08 05:02:53 | INFO | fairseq.trainer | begin training epoch 508
2022-03-08 05:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:04:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:05:13 | INFO | train_inner | epoch 508:     49 / 97 loss=2.473, nll_loss=0.636, ppl=1.55, wps=22158.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48900, lr=0.000143003, gnorm=0.756, loss_scale=16, train_wall=265, gb_free=8.1, wall=144825
2022-03-08 05:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:07:35 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.147 | nll_loss 12.402 | ppl 5412.8 | wps 42996.1 | wpb 510.9 | bsz 1 | num_updates 48948 | best_loss 8.481
2022-03-08 05:07:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 48948 updates
2022-03-08 05:07:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:07:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:07:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 508 @ 48948 updates, score 13.147) (writing took 2.2625761749222875 seconds)
2022-03-08 05:07:37 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-08 05:07:37 | INFO | train | epoch 508 | loss 2.474 | nll_loss 0.637 | ppl 1.56 | wps 22131.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48948 | lr 0.000142933 | gnorm 0.769 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 144969
2022-03-08 05:07:37 | INFO | fairseq.trainer | begin training epoch 509
2022-03-08 05:07:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:10:05 | INFO | train_inner | epoch 509:     52 / 97 loss=2.475, nll_loss=0.638, ppl=1.56, wps=22365.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49000, lr=0.000142857, gnorm=0.768, loss_scale=16, train_wall=263, gb_free=8.1, wall=145117
2022-03-08 05:12:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:12:19 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.129 | nll_loss 12.386 | ppl 5353.41 | wps 43118.2 | wpb 510.9 | bsz 1 | num_updates 49045 | best_loss 8.481
2022-03-08 05:12:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 49045 updates
2022-03-08 05:12:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:12:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 509 @ 49045 updates, score 13.129) (writing took 2.2433459870517254 seconds)
2022-03-08 05:12:21 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-08 05:12:21 | INFO | train | epoch 509 | loss 2.474 | nll_loss 0.637 | ppl 1.55 | wps 22350.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49045 | lr 0.000142792 | gnorm 0.761 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 145253
2022-03-08 05:12:21 | INFO | fairseq.trainer | begin training epoch 510
2022-03-08 05:12:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:12:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:15:01 | INFO | train_inner | epoch 510:     56 / 97 loss=2.472, nll_loss=0.635, ppl=1.55, wps=22157.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49100, lr=0.000142712, gnorm=0.757, loss_scale=16, train_wall=265, gb_free=8.1, wall=145413
2022-03-08 05:16:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:17:03 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.081 | nll_loss 12.329 | ppl 5145.28 | wps 43141.2 | wpb 510.9 | bsz 1 | num_updates 49141 | best_loss 8.481
2022-03-08 05:17:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 49141 updates
2022-03-08 05:17:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:17:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 510 @ 49141 updates, score 13.081) (writing took 2.265325389802456 seconds)
2022-03-08 05:17:05 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-08 05:17:05 | INFO | train | epoch 510 | loss 2.472 | nll_loss 0.635 | ppl 1.55 | wps 22122 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49141 | lr 0.000142652 | gnorm 0.751 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 145537
2022-03-08 05:17:05 | INFO | fairseq.trainer | begin training epoch 511
2022-03-08 05:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:19:54 | INFO | train_inner | epoch 511:     59 / 97 loss=2.472, nll_loss=0.635, ppl=1.55, wps=22335.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49200, lr=0.000142566, gnorm=0.752, loss_scale=32, train_wall=263, gb_free=8.1, wall=145706
2022-03-08 05:21:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:21:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:21:48 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.087 | nll_loss 12.335 | ppl 5168.02 | wps 42915.5 | wpb 510.9 | bsz 1 | num_updates 49237 | best_loss 8.481
2022-03-08 05:21:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 49237 updates
2022-03-08 05:21:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:21:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:21:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 511 @ 49237 updates, score 13.087) (writing took 2.2918846723623574 seconds)
2022-03-08 05:21:50 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-08 05:21:50 | INFO | train | epoch 511 | loss 2.472 | nll_loss 0.634 | ppl 1.55 | wps 22080.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49237 | lr 0.000142513 | gnorm 0.753 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 145822
2022-03-08 05:21:50 | INFO | fairseq.trainer | begin training epoch 512
2022-03-08 05:21:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:24:50 | INFO | train_inner | epoch 512:     63 / 97 loss=2.473, nll_loss=0.635, ppl=1.55, wps=22141.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=49300, lr=0.000142422, gnorm=0.757, loss_scale=16, train_wall=266, gb_free=8.1, wall=146002
2022-03-08 05:26:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:26:32 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.074 | nll_loss 12.323 | ppl 5124.61 | wps 43357.2 | wpb 510.9 | bsz 1 | num_updates 49334 | best_loss 8.481
2022-03-08 05:26:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 49334 updates
2022-03-08 05:26:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:26:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:26:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 512 @ 49334 updates, score 13.074) (writing took 2.258926148992032 seconds)
2022-03-08 05:26:34 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-08 05:26:34 | INFO | train | epoch 512 | loss 2.473 | nll_loss 0.635 | ppl 1.55 | wps 22336.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49334 | lr 0.000142373 | gnorm 0.755 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 146106
2022-03-08 05:26:34 | INFO | fairseq.trainer | begin training epoch 513
2022-03-08 05:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:27:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:29:46 | INFO | train_inner | epoch 513:     67 / 97 loss=2.472, nll_loss=0.634, ppl=1.55, wps=22133.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49400, lr=0.000142278, gnorm=0.757, loss_scale=16, train_wall=266, gb_free=8.1, wall=146298
2022-03-08 05:31:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:31:17 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.092 | nll_loss 12.339 | ppl 5181.52 | wps 42776.3 | wpb 510.9 | bsz 1 | num_updates 49430 | best_loss 8.481
2022-03-08 05:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 49430 updates
2022-03-08 05:31:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:31:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:31:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 513 @ 49430 updates, score 13.092) (writing took 2.319124965928495 seconds)
2022-03-08 05:31:19 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-08 05:31:19 | INFO | train | epoch 513 | loss 2.471 | nll_loss 0.634 | ppl 1.55 | wps 22094.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49430 | lr 0.000142234 | gnorm 0.762 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 146391
2022-03-08 05:31:19 | INFO | fairseq.trainer | begin training epoch 514
2022-03-08 05:31:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:34:39 | INFO | train_inner | epoch 514:     70 / 97 loss=2.471, nll_loss=0.634, ppl=1.55, wps=22352.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49500, lr=0.000142134, gnorm=0.754, loss_scale=32, train_wall=263, gb_free=8.1, wall=146591
2022-03-08 05:34:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:35:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:36:01 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.105 | nll_loss 12.359 | ppl 5251.83 | wps 42383.5 | wpb 510.9 | bsz 1 | num_updates 49526 | best_loss 8.481
2022-03-08 05:36:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 49526 updates
2022-03-08 05:36:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:36:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:36:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 514 @ 49526 updates, score 13.105) (writing took 2.2230093027465045 seconds)
2022-03-08 05:36:03 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-08 05:36:03 | INFO | train | epoch 514 | loss 2.472 | nll_loss 0.634 | ppl 1.55 | wps 22105.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49526 | lr 0.000142096 | gnorm 0.753 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 146675
2022-03-08 05:36:03 | INFO | fairseq.trainer | begin training epoch 515
2022-03-08 05:36:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:39:35 | INFO | train_inner | epoch 515:     74 / 97 loss=2.471, nll_loss=0.634, ppl=1.55, wps=22116.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=49600, lr=0.00014199, gnorm=0.756, loss_scale=16, train_wall=266, gb_free=8.1, wall=146887
2022-03-08 05:40:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:40:46 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.06 | nll_loss 12.3 | ppl 5043.98 | wps 42135.8 | wpb 510.9 | bsz 1 | num_updates 49623 | best_loss 8.481
2022-03-08 05:40:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 49623 updates
2022-03-08 05:40:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:40:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:40:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 515 @ 49623 updates, score 13.06) (writing took 2.228610455058515 seconds)
2022-03-08 05:40:48 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-08 05:40:48 | INFO | train | epoch 515 | loss 2.47 | nll_loss 0.632 | ppl 1.55 | wps 22316.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49623 | lr 0.000141958 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 146960
2022-03-08 05:40:48 | INFO | fairseq.trainer | begin training epoch 516
2022-03-08 05:40:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:44:28 | INFO | train_inner | epoch 516:     77 / 97 loss=2.47, nll_loss=0.632, ppl=1.55, wps=22368.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49700, lr=0.000141848, gnorm=0.753, loss_scale=32, train_wall=263, gb_free=8.1, wall=147180
2022-03-08 05:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:45:30 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.059 | nll_loss 12.305 | ppl 5060.71 | wps 42212.6 | wpb 510.9 | bsz 1 | num_updates 49720 | best_loss 8.481
2022-03-08 05:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 49720 updates
2022-03-08 05:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:45:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 516 @ 49720 updates, score 13.059) (writing took 2.2579648960381746 seconds)
2022-03-08 05:45:32 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-08 05:45:32 | INFO | train | epoch 516 | loss 2.469 | nll_loss 0.632 | ppl 1.55 | wps 22351.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49720 | lr 0.000141819 | gnorm 0.752 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 147244
2022-03-08 05:45:32 | INFO | fairseq.trainer | begin training epoch 517
2022-03-08 05:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:46:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:49:23 | INFO | train_inner | epoch 517:     81 / 97 loss=2.469, nll_loss=0.632, ppl=1.55, wps=22166.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49800, lr=0.000141705, gnorm=0.747, loss_scale=16, train_wall=265, gb_free=8.1, wall=147475
2022-03-08 05:50:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:50:14 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.096 | nll_loss 12.346 | ppl 5206.22 | wps 42410.6 | wpb 510.9 | bsz 1 | num_updates 49816 | best_loss 8.481
2022-03-08 05:50:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 49816 updates
2022-03-08 05:50:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:50:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:50:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 517 @ 49816 updates, score 13.096) (writing took 2.1757693430408835 seconds)
2022-03-08 05:50:16 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-08 05:50:16 | INFO | train | epoch 517 | loss 2.469 | nll_loss 0.631 | ppl 1.55 | wps 22144.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49816 | lr 0.000141682 | gnorm 0.745 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 147528
2022-03-08 05:50:16 | INFO | fairseq.trainer | begin training epoch 518
2022-03-08 05:50:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:54:15 | INFO | train_inner | epoch 518:     84 / 97 loss=2.469, nll_loss=0.632, ppl=1.55, wps=22444.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49900, lr=0.000141563, gnorm=0.759, loss_scale=32, train_wall=262, gb_free=8.1, wall=147767
2022-03-08 05:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:54:57 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.119 | nll_loss 12.369 | ppl 5288.48 | wps 43590.8 | wpb 510.9 | bsz 1 | num_updates 49913 | best_loss 8.481
2022-03-08 05:54:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 49913 updates
2022-03-08 05:54:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:54:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:54:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 518 @ 49913 updates, score 13.119) (writing took 2.298527436796576 seconds)
2022-03-08 05:54:59 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-08 05:54:59 | INFO | train | epoch 518 | loss 2.469 | nll_loss 0.632 | ppl 1.55 | wps 22442.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49913 | lr 0.000141545 | gnorm 0.761 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 147811
2022-03-08 05:54:59 | INFO | fairseq.trainer | begin training epoch 519
2022-03-08 05:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:55:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:59:09 | INFO | train_inner | epoch 519:     88 / 97 loss=2.469, nll_loss=0.632, ppl=1.55, wps=22312.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=50000, lr=0.000141421, gnorm=0.758, loss_scale=16, train_wall=264, gb_free=8.1, wall=148061
2022-03-08 05:59:09 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 05:59:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:59:14 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.098 | nll_loss 12.35 | ppl 5219.14 | wps 44193.9 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 8.481
2022-03-08 05:59:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 50000 updates
2022-03-08 05:59:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:59:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 05:59:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 519 @ 50000 updates, score 13.098) (writing took 2.2332450598478317 seconds)
2022-03-08 05:59:16 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-08 05:59:16 | INFO | train | epoch 519 | loss 2.467 | nll_loss 0.63 | ppl 1.55 | wps 22212.4 | ups 0.34 | wpb 65533.6 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.756 | loss_scale 16 | train_wall 230 | gb_free 8.1 | wall 148068
2022-03-08 05:59:16 | INFO | fairseq_cli.train | done training in 148067.6 seconds
