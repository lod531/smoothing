Sender: LSF System <lsfadmin@eu-g3-067>
Subject: Job 207263919: <w103_size_0.03125_fp16_label_smoothing_0.1_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.1_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:18:34 2022
Job was executed on host(s) <eu-g3-067>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:18:46 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:18:46 2022
Terminated at Sat Mar  5 14:18:55 2022
Results reported at Sat Mar  5 14:18:55 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   3.24 sec.
    Max Memory :                                 294 MB
    Average Memory :                             95.67 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               19706.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   10 sec.
    Turnaround time :                            21 sec.

The output (if any) follows:

2022-03-05 14:18:54 | ERROR | fairseq.dataclass.utils | Error when composing. Overrides: ['common.no_progress_bar=False', 'common.log_interval=100', 'common.log_format=null', 'common.log_file=null', 'common.tensorboard_logdir=null', 'common.wandb_project=null', 'common.azureml_logging=False', 'common.seed=66575611', 'common.cpu=False', 'common.tpu=False', 'common.bf16=False', 'common.memory_efficient_bf16=False', 'common.fp16=True', 'common.memory_efficient_fp16=False', 'common.fp16_no_flatten_grads=False', 'common.fp16_init_scale=128', 'common.fp16_scale_window=null', 'common.fp16_scale_tolerance=0.0', 'common.on_cpu_convert_precision=False', 'common.min_loss_scale=0.0001', 'common.threshold_loss_scale=null', 'common.amp=False', 'common.amp_batch_retries=2', 'common.amp_init_scale=128', 'common.amp_scale_window=null', 'common.user_dir=null', 'common.empty_cache_freq=0', 'common.all_gather_list_size=16384', 'common.model_parallel_size=1', 'common.quantization_config_path=null', 'common.profile=False', 'common.reset_logging=False', 'common.suppress_crashes=False', 'common.use_plasma_view=False', "common.plasma_path='/tmp/plasma'", 'common_eval.path=null', 'common_eval.post_process=null', 'common_eval.quiet=False', "common_eval.model_overrides='{}'", 'common_eval.results_path=null', 'distributed_training.distributed_world_size=1', 'distributed_training.distributed_num_procs=1', 'distributed_training.distributed_rank=0', "distributed_training.distributed_backend='nccl'", 'distributed_training.distributed_init_method=null', 'distributed_training.distributed_port=-1', 'distributed_training.device_id=0', 'distributed_training.distributed_no_spawn=False', "distributed_training.ddp_backend='pytorch_ddp'", "distributed_training.ddp_comm_hook='none'", 'distributed_training.bucket_cap_mb=25', 'distributed_training.fix_batches_to_gpus=False', 'distributed_training.find_unused_parameters=False', 'distributed_training.gradient_as_bucket_view=False', 'distributed_training.fast_stat_sync=False', 'distributed_training.heartbeat_timeout=-1', 'distributed_training.broadcast_buffers=False', 'distributed_training.slowmo_momentum=null', "distributed_training.slowmo_algorithm='LocalSGD'", 'distributed_training.localsgd_frequency=3', 'distributed_training.nprocs_per_node=1', 'distributed_training.pipeline_model_parallel=False', 'distributed_training.pipeline_balance=null', 'distributed_training.pipeline_devices=null', 'distributed_training.pipeline_chunks=0', 'distributed_training.pipeline_encoder_balance=null', 'distributed_training.pipeline_encoder_devices=null', 'distributed_training.pipeline_decoder_balance=null', 'distributed_training.pipeline_decoder_devices=null', "distributed_training.pipeline_checkpoint='never'", "distributed_training.zero_sharding='none'", 'distributed_training.fp16=True', 'distributed_training.memory_efficient_fp16=False', 'distributed_training.tpu=False', 'distributed_training.no_reshard_after_forward=False', 'distributed_training.fp32_reduce_scatter=False', 'distributed_training.cpu_offload=False', 'distributed_training.use_sharded_state=False', 'dataset.num_workers=1', 'dataset.skip_invalid_size_inputs_valid_test=False', 'dataset.max_tokens=512', 'dataset.batch_size=null', 'dataset.required_batch_size_multiple=8', 'dataset.required_seq_len_multiple=1', 'dataset.dataset_impl=null', 'dataset.data_buffer_size=10', "dataset.train_subset='train'", "dataset.valid_subset='valid'", 'dataset.combine_valid_subsets=null', 'dataset.ignore_unused_valid_subsets=False', 'dataset.validate_interval=1', 'dataset.validate_interval_updates=0', 'dataset.validate_after_updates=0', 'dataset.fixed_validation_seed=null', 'dataset.disable_validation=False', 'dataset.max_tokens_valid=512', 'dataset.batch_size_valid=null', 'dataset.max_valid_steps=null', 'dataset.curriculum=0', "dataset.gen_subset='test'", 'dataset.num_shards=1', 'dataset.shard_id=0', 'optimization.max_epoch=0', 'optimization.max_update=50000', 'optimization.stop_time_hours=0.0', 'optimization.clip_norm=0.0', 'optimization.sentence_avg=False', 'optimization.update_freq=[128]', 'optimization.lr=[0.0005]', 'optimization.stop_min_lr=-1.0', 'optimization.use_bmuf=False', "checkpoint.save_dir='/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1'", "checkpoint.restore_file='checkpoint_last.pt'", 'checkpoint.finetune_from_model=null', 'checkpoint.reset_dataloader=False', 'checkpoint.reset_lr_scheduler=False', 'checkpoint.reset_meters=False', 'checkpoint.reset_optimizer=False', "checkpoint.optimizer_overrides='{}'", 'checkpoint.save_interval=1', 'checkpoint.save_interval_updates=0', 'checkpoint.keep_interval_updates=-1', 'checkpoint.keep_interval_updates_pattern=-1', 'checkpoint.keep_last_epochs=-1', 'checkpoint.keep_best_checkpoints=-1', 'checkpoint.no_save=False', 'checkpoint.no_epoch_checkpoints=True', 'checkpoint.no_last_checkpoints=False', 'checkpoint.no_save_optimizer_state=False', "checkpoint.best_checkpoint_metric='loss'", 'checkpoint.maximize_best_checkpoint_metric=False', 'checkpoint.patience=-1', "checkpoint.checkpoint_suffix=''", 'checkpoint.checkpoint_shard_count=1', 'checkpoint.load_checkpoint_on_all_dp_ranks=False', 'checkpoint.write_checkpoints_asynchronously=False', 'checkpoint.model_parallel_size=1', 'bmuf.block_lr=1.0', 'bmuf.block_momentum=0.875', 'bmuf.global_sync_iter=50', 'bmuf.warmup_iterations=500', 'bmuf.use_nbm=False', 'bmuf.average_sync=False', 'bmuf.distributed_world_size=1', 'generation.beam=5', 'generation.nbest=1', 'generation.max_len_a=0.0', 'generation.max_len_b=200', 'generation.min_len=1', 'generation.match_source_len=False', 'generation.unnormalized=False', 'generation.no_early_stop=False', 'generation.no_beamable_mm=False', 'generation.lenpen=1.0', 'generation.unkpen=0.0', 'generation.replace_unk=null', 'generation.sacrebleu=False', 'generation.score_reference=False', 'generation.prefix_size=0', 'generation.no_repeat_ngram_size=0', 'generation.sampling=False', 'generation.sampling_topk=-1', 'generation.sampling_topp=-1.0', 'generation.constraints=null', 'generation.temperature=1.0', 'generation.diverse_beam_groups=-1', 'generation.diverse_beam_strength=0.5', 'generation.diversity_rate=-1.0', 'generation.print_alignment=null', 'generation.print_step=False', 'generation.lm_path=null', 'generation.lm_weight=0.0', 'generation.iter_decode_eos_penalty=0.0', 'generation.iter_decode_max_iter=10', 'generation.iter_decode_force_max_iter=False', 'generation.iter_decode_with_beam=1', 'generation.iter_decode_with_external_reranker=False', 'generation.retain_iter_history=False', 'generation.retain_dropout=False', 'generation.retain_dropout_modules=null', 'generation.decoding_format=null', 'generation.no_seed_provided=False', 'eval_lm.output_word_probs=False', 'eval_lm.output_word_stats=False', 'eval_lm.context_window=0', 'eval_lm.softmax_batch=9223372036854775807', 'interactive.buffer_size=0', "interactive.input='-'", 'ema.store_ema=False', 'ema.ema_decay=0.9999', 'ema.ema_start_update=0', 'ema.ema_seed_model=null', 'ema.ema_update_freq=1', 'ema.ema_fp32=False', 'task=language_modeling', 'task._name=language_modeling', "task.data='data-bin/wikitext-103-raw-size-0.0625'", "task.sample_break_mode='none'", 'task.tokens_per_sample=512', 'task.output_dictionary_size=-1', 'task.self_target=False', 'task.future_target=False', 'task.past_target=False', 'task.add_bos_token=False', 'task.max_target_positions=null', "task.shorten_method='none'", "task.shorten_data_split_list=''", 'task.pad_to_fixed_length=False', 'task.pad_to_fixed_bsz=False', 'task.seed=66575611', 'task.batch_size=null', 'task.batch_size_valid=null', 'task.dataset_impl=null', 'task.data_buffer_size=10', 'task.tpu=False', 'task.use_plasma_view=False', "task.plasma_path='/tmp/plasma'", 'criterion=label_smoothed_cross_entropy', 'criterion._name=label_smoothed_cross_entropy', 'criterion.label_smoothing=0.1', 'criterion.report_accuracy=False', 'criterion.ignore_prefix_size=0', 'criterion.sentence_avg=False', 'optimizer=adam', 'optimizer._name=adam', "optimizer.adam_betas='(0.9, 0.98)'", 'optimizer.adam_eps=1e-08', 'optimizer.weight_decay=0.01', 'optimizer.use_old_adam=False', 'optimizer.fp16_adam_stats=False', 'optimizer.tpu=False', 'optimizer.lr=[0.0005]', 'lr_scheduler=inverse_sqrt', 'lr_scheduler._name=inverse_sqrt', 'lr_scheduler.warmup_updates=4000', 'lr_scheduler.warmup_init_lr=1e-07', 'lr_scheduler.lr=[0.0005]', 'scoring=bleu', 'scoring._name=bleu', 'scoring.pad=1', 'scoring.eos=2', 'scoring.unk=3', 'model=transformer_lm', 'model._name=transformer_lm', "model.activation_fn='relu'", 'model.dropout=0.1', 'model.attention_dropout=0.0', 'model.activation_dropout=0.0', 'model.relu_dropout=0.0', 'model.decoder_embed_dim=512', 'model.decoder_output_dim=512', 'model.decoder_input_dim=512', 'model.decoder_ffn_embed_dim=2048', 'model.decoder_layers=6', 'model.decoder_attention_heads=8', 'model.decoder_normalize_before=False', 'model.no_decoder_final_norm=False', 'model.adaptive_softmax_cutoff=null', 'model.adaptive_softmax_dropout=0.0', 'model.adaptive_softmax_factor=4.0', 'model.no_token_positional_embeddings=False', 'model.share_decoder_input_output_embed=True', 'model.character_embeddings=False', "model.character_filters='[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]'", 'model.character_embedding_dim=4', 'model.char_embedder_highway_layers=2', 'model.adaptive_input=False', 'model.adaptive_input_factor=4.0', 'model.adaptive_input_cutoff=null', 'model.tie_adaptive_weights=False', 'model.tie_adaptive_proj=False', 'model.decoder_learned_pos=False', 'model.layernorm_embedding=False', 'model.no_scale_embedding=False', 'model.checkpoint_activations=False', 'model.offload_activations=False', 'model.decoder_layerdrop=0.0', 'model.decoder_layers_to_keep=null', 'model.quant_noise_pq=0.0', 'model.quant_noise_pq_block_size=8', 'model.quant_noise_scalar=0.0', 'model.min_params_to_wrap=100000000', 'model.base_layers=0', 'model.base_sublayers=1', 'model.base_shuffle=1', 'model.scale_fc=False', 'model.scale_attn=False', 'model.scale_heads=False', 'model.scale_resids=False', 'model.add_bos_token=False', 'model.tokens_per_sample=512', 'model.max_target_positions=null', 'model.tpu=False']
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 533, in cli_main
    cfg = convert_namespace_to_omegaconf(args)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/dataclass/utils.py", line 389, in convert_namespace_to_omegaconf
    composed_cfg = compose("config", overrides=overrides, strict=False)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/experimental/compose.py", line 31, in compose
    cfg = gh.hydra.compose_config(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/hydra.py", line 507, in compose_config
    cfg = self.config_loader.load_configuration(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 151, in load_configuration
    return self._load_configuration(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 224, in _load_configuration
    job_cfg, job_cfg_load_trace = self._load_primary_config(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 819, in _load_primary_config
    ret, load_trace = self._load_config_impl(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 614, in _load_config_impl
    schema.config = OmegaConf.merge(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/omegaconf.py", line 321, in merge
    target.merge_with(*others[1:])
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 329, in merge_with
    self._merge_with(*others)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 347, in _merge_with
    BaseContainer._map_merge(self, other)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 312, in _map_merge
    dest[key] = src._get_node(key)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 256, in __setitem__
    self.__set_impl(key=key, value=value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 266, in __set_impl
    self._set_item_impl(key, value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 475, in _set_item_impl
    assign(key, value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 452, in assign
    v = copy.deepcopy(value_to_assign)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/nodes.py", line 222, in __deepcopy__
    self._deepcopy_impl(res, memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/nodes.py", line 76, in _deepcopy_impl
    res.__dict__ = copy.deepcopy(self.__dict__, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 270, in _reconstruct
    state = deepcopy(state, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 161, in deepcopy
    rv = reductor(4)
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g3-082>
Subject: Job 207264070: <w103_size_0.03125_fp16_label_smoothing_0.1_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.1_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:21:50 2022
Job was executed on host(s) <eu-g3-082>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:22:16 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:22:16 2022
Terminated at Sun Mar  6 08:56:02 2022
Results reported at Sun Mar  6 08:56:02 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   66754.32 sec.
    Max Memory :                                 6819 MB
    Average Memory :                             3945.21 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13181.00 MB
    Max Swap :                                   5 MB
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   66826 sec.
    Turnaround time :                            66852 sec.

The output (if any) follows:

2022-03-05 14:22:31 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-05 14:22:31 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-05 14:22:33 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-05 14:22:33 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-05 14:22:33 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-05 14:22:33 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-05 14:22:33 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-05 14:22:33 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-05 14:22:33 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-05 14:22:41 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-05 14:22:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:22:41 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-05 14:22:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:22:41 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-05 14:22:41 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-05 14:22:41 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 14:22:41 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 14:22:41 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-05 14:22:41 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-05 14:22:41 | INFO | fairseq.trainer | begin training epoch 1
2022-03-05 14:22:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:22:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-05 14:22:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:22:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:23:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 14:23:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-05 14:24:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:24:52 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.593 | nll_loss 15.398 | ppl 43177.4 | wps 46717.4 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-05 14:24:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-05 14:24:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:24:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.593) (writing took 3.750025726854801 seconds)
2022-03-05 14:24:56 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-05 14:24:56 | INFO | train | epoch 001 | loss 16.609 | nll_loss 16.527 | ppl 94465 | wps 27053.4 | ups 0.42 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 4.587 | loss_scale 4 | train_wall 115 | gb_free 21.6 | wall 135
2022-03-05 14:24:56 | INFO | fairseq.trainer | begin training epoch 2
2022-03-05 14:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:26:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 14.227 | nll_loss 13.881 | ppl 15087 | wps 46627.8 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 14.227
2022-03-05 14:26:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-05 14:26:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:26:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:26:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 2 @ 93 updates, score 14.227) (writing took 3.8247415171936154 seconds)
2022-03-05 14:26:53 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-05 14:26:53 | INFO | train | epoch 002 | loss 14.863 | nll_loss 14.589 | ppl 24650.5 | wps 27277 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.068 | loss_scale 4 | train_wall 97 | gb_free 21.6 | wall 251
2022-03-05 14:26:53 | INFO | fairseq.trainer | begin training epoch 3
2022-03-05 14:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:27:08 | INFO | train_inner | epoch 003:      7 / 49 loss=15.587, nll_loss=15.394, ppl=43046.2, wps=27307.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.132, loss_scale=4, train_wall=226, gb_free=21.6, wall=267
2022-03-05 14:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:28:45 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.601 | nll_loss 13.191 | ppl 9352.95 | wps 46734.4 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.601
2022-03-05 14:28:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-05 14:28:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:28:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:28:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.601) (writing took 3.935066723264754 seconds)
2022-03-05 14:28:49 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-05 14:28:49 | INFO | train | epoch 003 | loss 13.983 | nll_loss 13.615 | ppl 12549.8 | wps 27215.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.361 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 368
2022-03-05 14:28:49 | INFO | fairseq.trainer | begin training epoch 4
2022-03-05 14:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:30:42 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.825 | nll_loss 12.32 | ppl 5114.9 | wps 46659 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.825
2022-03-05 14:30:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-05 14:30:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:30:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.825) (writing took 3.8851992590352893 seconds)
2022-03-05 14:30:46 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-05 14:30:46 | INFO | train | epoch 004 | loss 13.275 | nll_loss 12.83 | ppl 7280.27 | wps 27210.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.163 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 485
2022-03-05 14:30:46 | INFO | fairseq.trainer | begin training epoch 5
2022-03-05 14:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:31:06 | INFO | train_inner | epoch 005:      9 / 49 loss=13.509, nll_loss=13.088, ppl=8709.54, wps=27256.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.225, loss_scale=8, train_wall=198, gb_free=21.6, wall=505
2022-03-05 14:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:32:39 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 12.125 | nll_loss 11.522 | ppl 2941.78 | wps 46625.9 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 12.125
2022-03-05 14:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-05 14:32:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:32:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:32:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 5 @ 240 updates, score 12.125) (writing took 4.0311633525416255 seconds)
2022-03-05 14:32:43 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-05 14:32:43 | INFO | train | epoch 005 | loss 12.492 | nll_loss 11.947 | ppl 3948.02 | wps 27197.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.879 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 602
2022-03-05 14:32:43 | INFO | fairseq.trainer | begin training epoch 6
2022-03-05 14:32:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:34:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:34:36 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.575 | nll_loss 10.879 | ppl 1883.08 | wps 46549.2 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.575
2022-03-05 14:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-05 14:34:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:34:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:34:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.575) (writing took 3.970390245318413 seconds)
2022-03-05 14:34:40 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-05 14:34:40 | INFO | train | epoch 006 | loss 11.838 | nll_loss 11.196 | ppl 2346.59 | wps 27215.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.679 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 719
2022-03-05 14:34:40 | INFO | fairseq.trainer | begin training epoch 7
2022-03-05 14:34:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:35:05 | INFO | train_inner | epoch 007:     11 / 49 loss=12.033, nll_loss=11.42, ppl=2739.7, wps=27241.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.74, loss_scale=16, train_wall=198, gb_free=21.6, wall=743
2022-03-05 14:36:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:36:33 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.234 | nll_loss 10.462 | ppl 1410.1 | wps 46636.7 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 11.234
2022-03-05 14:36:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-05 14:36:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:36:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:36:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 7 @ 338 updates, score 11.234) (writing took 3.9923907620832324 seconds)
2022-03-05 14:36:37 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-05 14:36:37 | INFO | train | epoch 007 | loss 11.365 | nll_loss 10.634 | ppl 1589.4 | wps 27175.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.556 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 835
2022-03-05 14:36:37 | INFO | fairseq.trainer | begin training epoch 8
2022-03-05 14:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:38:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:38:30 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.028 | nll_loss 10.196 | ppl 1173.34 | wps 46572.9 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 11.028
2022-03-05 14:38:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-05 14:38:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:38:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:38:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 8 @ 387 updates, score 11.028) (writing took 3.81129730399698 seconds)
2022-03-05 14:38:34 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-05 14:38:34 | INFO | train | epoch 008 | loss 11.084 | nll_loss 10.283 | ppl 1245.92 | wps 27221.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.422 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 952
2022-03-05 14:38:34 | INFO | fairseq.trainer | begin training epoch 9
2022-03-05 14:38:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:39:03 | INFO | train_inner | epoch 009:     13 / 49 loss=11.158, nll_loss=10.376, ppl=1328.65, wps=27243.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.467, loss_scale=32, train_wall=198, gb_free=21.6, wall=981
2022-03-05 14:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:40:26 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.87 | nll_loss 9.999 | ppl 1023.31 | wps 46429 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.87
2022-03-05 14:40:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-05 14:40:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:40:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:40:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.87) (writing took 3.8223458491265774 seconds)
2022-03-05 14:40:30 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-05 14:40:30 | INFO | train | epoch 009 | loss 10.901 | nll_loss 10.051 | ppl 1060.52 | wps 27218.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.465 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1069
2022-03-05 14:40:30 | INFO | fairseq.trainer | begin training epoch 10
2022-03-05 14:40:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:42:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:42:23 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.72 | nll_loss 9.821 | ppl 904.35 | wps 46244.9 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.72
2022-03-05 14:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-05 14:42:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:42:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.72) (writing took 3.8715985268354416 seconds)
2022-03-05 14:42:27 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-05 14:42:27 | INFO | train | epoch 010 | loss 10.743 | nll_loss 9.859 | ppl 928.92 | wps 27186.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.483 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1186
2022-03-05 14:42:27 | INFO | fairseq.trainer | begin training epoch 11
2022-03-05 14:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:43:01 | INFO | train_inner | epoch 011:     15 / 49 loss=10.778, nll_loss=9.902, ppl=956.9, wps=27231, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.491, loss_scale=32, train_wall=198, gb_free=21.6, wall=1220
2022-03-05 14:43:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:44:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:44:20 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.589 | nll_loss 9.669 | ppl 814.18 | wps 46399.8 | wpb 510.9 | bsz 1 | num_updates 533 | best_loss 10.589
2022-03-05 14:44:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 533 updates
2022-03-05 14:44:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:44:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:44:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 11 @ 533 updates, score 10.589) (writing took 3.7873743819072843 seconds)
2022-03-05 14:44:24 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-05 14:44:24 | INFO | train | epoch 011 | loss 10.595 | nll_loss 9.686 | ppl 823.43 | wps 26632.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 533 | lr 6.67117e-05 | gnorm 0.514 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1303
2022-03-05 14:44:24 | INFO | fairseq.trainer | begin training epoch 12
2022-03-05 14:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:46:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:46:17 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.461 | nll_loss 9.52 | ppl 733.96 | wps 46818.1 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 10.461
2022-03-05 14:46:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-05 14:46:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:46:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:46:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 12 @ 582 updates, score 10.461) (writing took 3.9030208345502615 seconds)
2022-03-05 14:46:21 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-05 14:46:21 | INFO | train | epoch 012 | loss 10.453 | nll_loss 9.521 | ppl 734.94 | wps 27197.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.574 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1420
2022-03-05 14:46:21 | INFO | fairseq.trainer | begin training epoch 13
2022-03-05 14:46:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:47:01 | INFO | train_inner | epoch 013:     18 / 49 loss=10.473, nll_loss=9.545, ppl=747.19, wps=26992.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.556, loss_scale=32, train_wall=200, gb_free=21.6, wall=1460
2022-03-05 14:48:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:48:14 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.357 | nll_loss 9.402 | ppl 676.61 | wps 46573 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 10.357
2022-03-05 14:48:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-05 14:48:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:48:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 13 @ 631 updates, score 10.357) (writing took 3.9023993089795113 seconds)
2022-03-05 14:48:18 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-05 14:48:18 | INFO | train | epoch 013 | loss 10.319 | nll_loss 9.367 | ppl 660.51 | wps 27187.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.646 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1536
2022-03-05 14:48:18 | INFO | fairseq.trainer | begin training epoch 14
2022-03-05 14:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:48:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:50:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:50:11 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.247 | nll_loss 9.268 | ppl 616.49 | wps 46733.4 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 10.247
2022-03-05 14:50:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-05 14:50:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:50:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 14 @ 679 updates, score 10.247) (writing took 3.9431735165417194 seconds)
2022-03-05 14:50:15 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-05 14:50:15 | INFO | train | epoch 014 | loss 10.195 | nll_loss 9.225 | ppl 598.29 | wps 26630.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.663 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 1653
2022-03-05 14:50:15 | INFO | fairseq.trainer | begin training epoch 15
2022-03-05 14:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:51:02 | INFO | train_inner | epoch 015:     21 / 49 loss=10.207, nll_loss=9.238, ppl=603.98, wps=26982.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.663, loss_scale=16, train_wall=200, gb_free=21.6, wall=1700
2022-03-05 14:52:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:52:08 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.159 | nll_loss 9.169 | ppl 575.47 | wps 46652.1 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 10.159
2022-03-05 14:52:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-05 14:52:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:52:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:52:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 15 @ 728 updates, score 10.159) (writing took 3.7893832502886653 seconds)
2022-03-05 14:52:11 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-05 14:52:11 | INFO | train | epoch 015 | loss 10.075 | nll_loss 9.086 | ppl 543.62 | wps 27213.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.679 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 1770
2022-03-05 14:52:11 | INFO | fairseq.trainer | begin training epoch 16
2022-03-05 14:52:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:54:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:54:04 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.079 | nll_loss 9.071 | ppl 537.83 | wps 46575.8 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 10.079
2022-03-05 14:54:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-05 14:54:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:54:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 16 @ 777 updates, score 10.079) (writing took 3.8314059656113386 seconds)
2022-03-05 14:54:08 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-05 14:54:08 | INFO | train | epoch 016 | loss 9.959 | nll_loss 8.952 | ppl 495.09 | wps 27212.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.756 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1887
2022-03-05 14:54:08 | INFO | fairseq.trainer | begin training epoch 17
2022-03-05 14:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:55:00 | INFO | train_inner | epoch 017:     23 / 49 loss=9.965, nll_loss=8.959, ppl=497.7, wps=27241.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.742, loss_scale=32, train_wall=198, gb_free=21.6, wall=1938
2022-03-05 14:55:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:56:01 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.986 | nll_loss 8.964 | ppl 499.35 | wps 46513.1 | wpb 510.9 | bsz 1 | num_updates 826 | best_loss 9.986
2022-03-05 14:56:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 826 updates
2022-03-05 14:56:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:56:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:56:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 17 @ 826 updates, score 9.986) (writing took 3.8122381921857595 seconds)
2022-03-05 14:56:05 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-05 14:56:05 | INFO | train | epoch 017 | loss 9.843 | nll_loss 8.818 | ppl 451.28 | wps 27190.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 826 | lr 0.000103329 | gnorm 0.751 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2004
2022-03-05 14:56:05 | INFO | fairseq.trainer | begin training epoch 18
2022-03-05 14:56:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:57:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:57:58 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.905 | nll_loss 8.878 | ppl 470.62 | wps 46601 | wpb 510.9 | bsz 1 | num_updates 875 | best_loss 9.905
2022-03-05 14:57:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 875 updates
2022-03-05 14:57:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:58:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:58:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 18 @ 875 updates, score 9.905) (writing took 3.842455882579088 seconds)
2022-03-05 14:58:02 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-05 14:58:02 | INFO | train | epoch 018 | loss 9.734 | nll_loss 8.691 | ppl 413.24 | wps 27187.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 875 | lr 0.000109453 | gnorm 0.834 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2121
2022-03-05 14:58:02 | INFO | fairseq.trainer | begin training epoch 19
2022-03-05 14:58:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:58:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:59:00 | INFO | train_inner | epoch 019:     26 / 49 loss=9.734, nll_loss=8.69, ppl=413.12, wps=26994.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.822, loss_scale=32, train_wall=200, gb_free=21.6, wall=2179
2022-03-05 14:59:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:59:55 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.829 | nll_loss 8.773 | ppl 437.36 | wps 46759.8 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.829
2022-03-05 14:59:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-05 14:59:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:59:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 14:59:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.829) (writing took 3.74667988717556 seconds)
2022-03-05 14:59:59 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-05 14:59:59 | INFO | train | epoch 019 | loss 9.628 | nll_loss 8.568 | ppl 379.48 | wps 26685.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.839 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2237
2022-03-05 14:59:59 | INFO | fairseq.trainer | begin training epoch 20
2022-03-05 14:59:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:01:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:01:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:01:52 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.764 | nll_loss 8.688 | ppl 412.47 | wps 46677.6 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 9.764
2022-03-05 15:01:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-05 15:01:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:01:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 20 @ 971 updates, score 9.764) (writing took 3.8180977376177907 seconds)
2022-03-05 15:01:55 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-05 15:01:55 | INFO | train | epoch 020 | loss 9.525 | nll_loss 8.449 | ppl 349.42 | wps 26669.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.817 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 2354
2022-03-05 15:01:55 | INFO | fairseq.trainer | begin training epoch 21
2022-03-05 15:01:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:03:00 | INFO | train_inner | epoch 021:     29 / 49 loss=9.519, nll_loss=8.442, ppl=347.77, wps=27010.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.819, loss_scale=16, train_wall=200, gb_free=21.6, wall=2419
2022-03-05 15:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:03:49 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.691 | nll_loss 8.61 | ppl 390.71 | wps 46684.6 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 9.691
2022-03-05 15:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-05 15:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:03:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:03:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 21 @ 1020 updates, score 9.691) (writing took 3.7896393928676844 seconds)
2022-03-05 15:03:52 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-05 15:03:52 | INFO | train | epoch 021 | loss 9.426 | nll_loss 8.334 | ppl 322.64 | wps 27171.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.819 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 2471
2022-03-05 15:03:52 | INFO | fairseq.trainer | begin training epoch 22
2022-03-05 15:03:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:05:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:05:45 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.632 | nll_loss 8.543 | ppl 373.11 | wps 46621.9 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 9.632
2022-03-05 15:05:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-05 15:05:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:05:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 22 @ 1069 updates, score 9.632) (writing took 3.7538386220112443 seconds)
2022-03-05 15:05:49 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-05 15:05:49 | INFO | train | epoch 022 | loss 9.328 | nll_loss 8.22 | ppl 298.21 | wps 27237.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.815 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 2588
2022-03-05 15:05:49 | INFO | fairseq.trainer | begin training epoch 23
2022-03-05 15:05:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:06:58 | INFO | train_inner | epoch 023:     31 / 49 loss=9.319, nll_loss=8.209, ppl=295.96, wps=27239.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.838, loss_scale=32, train_wall=198, gb_free=21.6, wall=2657
2022-03-05 15:07:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:07:42 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.571 | nll_loss 8.472 | ppl 355.04 | wps 46559.4 | wpb 510.9 | bsz 1 | num_updates 1118 | best_loss 9.571
2022-03-05 15:07:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1118 updates
2022-03-05 15:07:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:07:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:07:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 23 @ 1118 updates, score 9.571) (writing took 3.762071224860847 seconds)
2022-03-05 15:07:46 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-05 15:07:46 | INFO | train | epoch 023 | loss 9.24 | nll_loss 8.117 | ppl 277.57 | wps 27182.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1118 | lr 0.000139822 | gnorm 0.933 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2705
2022-03-05 15:07:46 | INFO | fairseq.trainer | begin training epoch 24
2022-03-05 15:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:09:39 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.532 | nll_loss 8.413 | ppl 340.81 | wps 46221.8 | wpb 510.9 | bsz 1 | num_updates 1167 | best_loss 9.532
2022-03-05 15:09:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1167 updates
2022-03-05 15:09:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:09:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:09:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 24 @ 1167 updates, score 9.532) (writing took 3.8329527750611305 seconds)
2022-03-05 15:09:43 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-05 15:09:43 | INFO | train | epoch 024 | loss 9.148 | nll_loss 8.01 | ppl 257.75 | wps 27187.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1167 | lr 0.000145946 | gnorm 0.863 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2822
2022-03-05 15:09:43 | INFO | fairseq.trainer | begin training epoch 25
2022-03-05 15:09:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:10:57 | INFO | train_inner | epoch 025:     33 / 49 loss=9.132, nll_loss=7.992, ppl=254.61, wps=27237.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.881, loss_scale=32, train_wall=198, gb_free=21.6, wall=2895
2022-03-05 15:11:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:11:36 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.467 | nll_loss 8.352 | ppl 326.7 | wps 46639.7 | wpb 510.9 | bsz 1 | num_updates 1216 | best_loss 9.467
2022-03-05 15:11:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1216 updates
2022-03-05 15:11:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:11:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:11:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 25 @ 1216 updates, score 9.467) (writing took 3.7976056346669793 seconds)
2022-03-05 15:11:40 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-05 15:11:40 | INFO | train | epoch 025 | loss 9.057 | nll_loss 7.905 | ppl 239.6 | wps 27206.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1216 | lr 0.00015207 | gnorm 0.838 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2938
2022-03-05 15:11:40 | INFO | fairseq.trainer | begin training epoch 26
2022-03-05 15:11:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:12:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:13:33 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.43 | nll_loss 8.3 | ppl 315.21 | wps 46573.8 | wpb 510.9 | bsz 1 | num_updates 1264 | best_loss 9.43
2022-03-05 15:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1264 updates
2022-03-05 15:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:13:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:13:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 26 @ 1264 updates, score 9.43) (writing took 4.181805405765772 seconds)
2022-03-05 15:13:37 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-05 15:13:37 | INFO | train | epoch 026 | loss 8.972 | nll_loss 7.805 | ppl 223.68 | wps 26555.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1264 | lr 0.000158068 | gnorm 0.922 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3056
2022-03-05 15:13:37 | INFO | fairseq.trainer | begin training epoch 27
2022-03-05 15:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:14:57 | INFO | train_inner | epoch 027:     36 / 49 loss=8.955, nll_loss=7.786, ppl=220.68, wps=26964.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.891, loss_scale=32, train_wall=200, gb_free=21.6, wall=3136
2022-03-05 15:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:15:30 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.393 | nll_loss 8.25 | ppl 304.38 | wps 46621.5 | wpb 510.9 | bsz 1 | num_updates 1313 | best_loss 9.393
2022-03-05 15:15:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1313 updates
2022-03-05 15:15:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:15:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 27 @ 1313 updates, score 9.393) (writing took 3.647952238097787 seconds)
2022-03-05 15:15:33 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-05 15:15:33 | INFO | train | epoch 027 | loss 8.886 | nll_loss 7.705 | ppl 208.71 | wps 27273.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1313 | lr 0.000164192 | gnorm 0.889 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3172
2022-03-05 15:15:33 | INFO | fairseq.trainer | begin training epoch 28
2022-03-05 15:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:17:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:17:26 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.359 | nll_loss 8.206 | ppl 295.2 | wps 46653 | wpb 510.9 | bsz 1 | num_updates 1361 | best_loss 9.359
2022-03-05 15:17:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1361 updates
2022-03-05 15:17:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:17:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:17:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 28 @ 1361 updates, score 9.359) (writing took 3.685212823562324 seconds)
2022-03-05 15:17:30 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-05 15:17:30 | INFO | train | epoch 028 | loss 8.803 | nll_loss 7.608 | ppl 195.13 | wps 26680.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1361 | lr 0.000170191 | gnorm 0.927 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3289
2022-03-05 15:17:30 | INFO | fairseq.trainer | begin training epoch 29
2022-03-05 15:17:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:18:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:18:59 | INFO | train_inner | epoch 029:     40 / 49 loss=8.775, nll_loss=7.576, ppl=190.85, wps=26788.6, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.902, loss_scale=16, train_wall=202, gb_free=21.6, wall=3378
2022-03-05 15:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:19:23 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.32 | nll_loss 8.157 | ppl 285.39 | wps 46684.1 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 9.32
2022-03-05 15:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-05 15:19:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:19:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:19:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 29 @ 1409 updates, score 9.32) (writing took 3.7042675921693444 seconds)
2022-03-05 15:19:27 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-05 15:19:27 | INFO | train | epoch 029 | loss 8.713 | nll_loss 7.504 | ppl 181.51 | wps 26669.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 0.877 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 3405
2022-03-05 15:19:27 | INFO | fairseq.trainer | begin training epoch 30
2022-03-05 15:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:21:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:21:20 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.298 | nll_loss 8.128 | ppl 279.72 | wps 46524.4 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 9.298
2022-03-05 15:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-05 15:21:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:21:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 30 @ 1458 updates, score 9.298) (writing took 3.704743618145585 seconds)
2022-03-05 15:21:23 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-05 15:21:23 | INFO | train | epoch 030 | loss 8.628 | nll_loss 7.406 | ppl 169.56 | wps 27247.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 0.911 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 3522
2022-03-05 15:21:23 | INFO | fairseq.trainer | begin training epoch 31
2022-03-05 15:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:22:57 | INFO | train_inner | epoch 031:     42 / 49 loss=8.6, nll_loss=7.372, ppl=165.68, wps=27277.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.93, loss_scale=16, train_wall=198, gb_free=21.6, wall=3616
2022-03-05 15:23:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:23:16 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.258 | nll_loss 8.08 | ppl 270.66 | wps 46635.3 | wpb 510.9 | bsz 1 | num_updates 1507 | best_loss 9.258
2022-03-05 15:23:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1507 updates
2022-03-05 15:23:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:23:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:23:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 31 @ 1507 updates, score 9.258) (writing took 3.7862057154998183 seconds)
2022-03-05 15:23:20 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-05 15:23:20 | INFO | train | epoch 031 | loss 8.544 | nll_loss 7.307 | ppl 158.33 | wps 27221.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1507 | lr 0.000188437 | gnorm 0.963 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3639
2022-03-05 15:23:20 | INFO | fairseq.trainer | begin training epoch 32
2022-03-05 15:23:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:25:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:25:13 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.248 | nll_loss 8.066 | ppl 267.98 | wps 46390.9 | wpb 510.9 | bsz 1 | num_updates 1556 | best_loss 9.248
2022-03-05 15:25:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1556 updates
2022-03-05 15:25:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:25:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:25:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 32 @ 1556 updates, score 9.248) (writing took 3.769579361192882 seconds)
2022-03-05 15:25:17 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-05 15:25:17 | INFO | train | epoch 032 | loss 8.453 | nll_loss 7.201 | ppl 147.16 | wps 27174.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1556 | lr 0.000194561 | gnorm 0.884 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3756
2022-03-05 15:25:17 | INFO | fairseq.trainer | begin training epoch 33
2022-03-05 15:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:26:55 | INFO | train_inner | epoch 033:     44 / 49 loss=8.42, nll_loss=7.164, ppl=143.37, wps=27238.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=0.931, loss_scale=32, train_wall=198, gb_free=21.6, wall=3854
2022-03-05 15:27:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:27:10 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.227 | nll_loss 8.029 | ppl 261.28 | wps 46638.5 | wpb 510.9 | bsz 1 | num_updates 1605 | best_loss 9.227
2022-03-05 15:27:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1605 updates
2022-03-05 15:27:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:27:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:27:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 33 @ 1605 updates, score 9.227) (writing took 3.7558354008942842 seconds)
2022-03-05 15:27:14 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-05 15:27:14 | INFO | train | epoch 033 | loss 8.368 | nll_loss 7.103 | ppl 137.48 | wps 27231 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1605 | lr 0.000200685 | gnorm 0.98 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3872
2022-03-05 15:27:14 | INFO | fairseq.trainer | begin training epoch 34
2022-03-05 15:27:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:28:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:29:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:29:07 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.21 | nll_loss 8.006 | ppl 257.03 | wps 46611.2 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 9.21
2022-03-05 15:29:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-05 15:29:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:29:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 34 @ 1653 updates, score 9.21) (writing took 3.6929254373535514 seconds)
2022-03-05 15:29:10 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-05 15:29:10 | INFO | train | epoch 034 | loss 8.281 | nll_loss 7.002 | ppl 128.15 | wps 26682.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 0.937 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3989
2022-03-05 15:29:10 | INFO | fairseq.trainer | begin training epoch 35
2022-03-05 15:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:30:55 | INFO | train_inner | epoch 035:     47 / 49 loss=8.246, nll_loss=6.961, ppl=124.55, wps=27006.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=0.95, loss_scale=32, train_wall=200, gb_free=21.6, wall=4094
2022-03-05 15:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:31:04 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.212 | nll_loss 8.024 | ppl 260.3 | wps 46543.9 | wpb 510.9 | bsz 1 | num_updates 1702 | best_loss 9.21
2022-03-05 15:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1702 updates
2022-03-05 15:31:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:31:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:31:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 35 @ 1702 updates, score 9.212) (writing took 1.6917232600972056 seconds)
2022-03-05 15:31:05 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-05 15:31:05 | INFO | train | epoch 035 | loss 8.198 | nll_loss 6.904 | ppl 119.77 | wps 27675.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1702 | lr 0.000212807 | gnorm 0.96 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4104
2022-03-05 15:31:05 | INFO | fairseq.trainer | begin training epoch 36
2022-03-05 15:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:32:58 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.178 | nll_loss 7.968 | ppl 250.36 | wps 46754.5 | wpb 510.9 | bsz 1 | num_updates 1751 | best_loss 9.178
2022-03-05 15:32:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1751 updates
2022-03-05 15:32:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:33:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 36 @ 1751 updates, score 9.178) (writing took 3.6570795783773065 seconds)
2022-03-05 15:33:02 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-05 15:33:02 | INFO | train | epoch 036 | loss 8.116 | nll_loss 6.809 | ppl 112.09 | wps 27244.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1751 | lr 0.000218931 | gnorm 0.985 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4221
2022-03-05 15:33:02 | INFO | fairseq.trainer | begin training epoch 37
2022-03-05 15:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:34:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:34:55 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.173 | nll_loss 7.962 | ppl 249.31 | wps 46726.6 | wpb 510.9 | bsz 1 | num_updates 1799 | best_loss 9.173
2022-03-05 15:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1799 updates
2022-03-05 15:34:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:34:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-05 15:34:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_best.pt (epoch 37 @ 1799 updates, score 9.173) (writing took 3.681468359194696 seconds)
2022-03-05 15:34:59 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-05 15:34:59 | INFO | train | epoch 037 | loss 8.03 | nll_loss 6.708 | ppl 104.54 | wps 26680.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1799 | lr 0.00022493 | gnorm 0.986 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4337
2022-03-05 15:34:59 | INFO | fairseq.trainer | begin training epoch 38
2022-03-05 15:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:35:01 | INFO | train_inner | epoch 038:      1 / 49 loss=8.073, nll_loss=6.758, ppl=108.24, wps=26298.7, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=0.984, loss_scale=32, train_wall=199, gb_free=21.6, wall=4340
2022-03-05 15:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:36:52 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.194 | nll_loss 7.979 | ppl 252.31 | wps 46536.7 | wpb 510.9 | bsz 1 | num_updates 1848 | best_loss 9.173
2022-03-05 15:36:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1848 updates
2022-03-05 15:36:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:36:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:36:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 38 @ 1848 updates, score 9.194) (writing took 1.7407523859292269 seconds)
2022-03-05 15:36:53 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-05 15:36:53 | INFO | train | epoch 038 | loss 7.95 | nll_loss 6.615 | ppl 98 | wps 27708.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1848 | lr 0.000231054 | gnorm 1.003 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4452
2022-03-05 15:36:53 | INFO | fairseq.trainer | begin training epoch 39
2022-03-05 15:36:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:38:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:38:46 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.204 | nll_loss 8.004 | ppl 256.67 | wps 46665.6 | wpb 510.9 | bsz 1 | num_updates 1897 | best_loss 9.173
2022-03-05 15:38:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1897 updates
2022-03-05 15:38:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:38:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:38:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 39 @ 1897 updates, score 9.204) (writing took 1.6473716152831912 seconds)
2022-03-05 15:38:48 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-05 15:38:48 | INFO | train | epoch 039 | loss 7.864 | nll_loss 6.514 | ppl 91.4 | wps 27751 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1897 | lr 0.000237178 | gnorm 0.956 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4566
2022-03-05 15:38:48 | INFO | fairseq.trainer | begin training epoch 40
2022-03-05 15:38:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:38:55 | INFO | train_inner | epoch 040:      3 / 49 loss=7.903, nll_loss=6.56, ppl=94.37, wps=27754.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=0.983, loss_scale=32, train_wall=198, gb_free=21.6, wall=4573
2022-03-05 15:39:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:40:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:40:41 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.254 | nll_loss 8.05 | ppl 265.02 | wps 46728.7 | wpb 510.9 | bsz 1 | num_updates 1945 | best_loss 9.173
2022-03-05 15:40:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1945 updates
2022-03-05 15:40:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:40:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 40 @ 1945 updates, score 9.254) (writing took 1.6221456499770284 seconds)
2022-03-05 15:40:42 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-05 15:40:42 | INFO | train | epoch 040 | loss 7.783 | nll_loss 6.419 | ppl 85.59 | wps 27153.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 1945 | lr 0.000243176 | gnorm 1.019 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4681
2022-03-05 15:40:42 | INFO | fairseq.trainer | begin training epoch 41
2022-03-05 15:40:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:42:35 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.251 | nll_loss 8.036 | ppl 262.47 | wps 46734.5 | wpb 510.9 | bsz 1 | num_updates 1994 | best_loss 9.173
2022-03-05 15:42:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1994 updates
2022-03-05 15:42:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:42:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:42:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 41 @ 1994 updates, score 9.251) (writing took 1.639558975584805 seconds)
2022-03-05 15:42:37 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-05 15:42:37 | INFO | train | epoch 041 | loss 7.703 | nll_loss 6.327 | ppl 80.25 | wps 27713.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1994 | lr 0.0002493 | gnorm 0.992 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4796
2022-03-05 15:42:37 | INFO | fairseq.trainer | begin training epoch 42
2022-03-05 15:42:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:42:51 | INFO | train_inner | epoch 042:      6 / 49 loss=7.733, nll_loss=6.361, ppl=82.21, wps=27495.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.007, loss_scale=32, train_wall=200, gb_free=21.6, wall=4809
2022-03-05 15:44:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:44:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:44:30 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.272 | nll_loss 8.053 | ppl 265.55 | wps 46662.8 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 9.173
2022-03-05 15:44:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-05 15:44:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:44:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:44:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 42 @ 2042 updates, score 9.272) (writing took 1.6596183413639665 seconds)
2022-03-05 15:44:32 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-05 15:44:32 | INFO | train | epoch 042 | loss 7.624 | nll_loss 6.234 | ppl 75.25 | wps 27110.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.055 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4911
2022-03-05 15:44:32 | INFO | fairseq.trainer | begin training epoch 43
2022-03-05 15:44:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:46:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:46:25 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.295 | nll_loss 8.089 | ppl 272.31 | wps 46389.8 | wpb 510.9 | bsz 1 | num_updates 2091 | best_loss 9.173
2022-03-05 15:46:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2091 updates
2022-03-05 15:46:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:46:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:46:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 43 @ 2091 updates, score 9.295) (writing took 1.6155293872579932 seconds)
2022-03-05 15:46:27 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-05 15:46:27 | INFO | train | epoch 043 | loss 7.546 | nll_loss 6.142 | ppl 70.62 | wps 27725.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2091 | lr 0.000261423 | gnorm 1.047 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5025
2022-03-05 15:46:27 | INFO | fairseq.trainer | begin training epoch 44
2022-03-05 15:46:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:46:47 | INFO | train_inner | epoch 044:      9 / 49 loss=7.57, nll_loss=6.17, ppl=72.03, wps=27470.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.051, loss_scale=32, train_wall=200, gb_free=21.6, wall=5045
2022-03-05 15:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:48:20 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.311 | nll_loss 8.089 | ppl 272.38 | wps 46710.2 | wpb 510.9 | bsz 1 | num_updates 2140 | best_loss 9.173
2022-03-05 15:48:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2140 updates
2022-03-05 15:48:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:48:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:48:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 44 @ 2140 updates, score 9.311) (writing took 1.672347386367619 seconds)
2022-03-05 15:48:21 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-05 15:48:21 | INFO | train | epoch 044 | loss 7.466 | nll_loss 6.048 | ppl 66.18 | wps 27691.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2140 | lr 0.000267547 | gnorm 1.058 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5140
2022-03-05 15:48:21 | INFO | fairseq.trainer | begin training epoch 45
2022-03-05 15:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:49:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:50:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:50:15 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.384 | nll_loss 8.204 | ppl 294.92 | wps 46710.3 | wpb 510.9 | bsz 1 | num_updates 2188 | best_loss 9.173
2022-03-05 15:50:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2188 updates
2022-03-05 15:50:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:50:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:50:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 45 @ 2188 updates, score 9.384) (writing took 1.6318963430821896 seconds)
2022-03-05 15:50:16 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-05 15:50:16 | INFO | train | epoch 045 | loss 7.382 | nll_loss 5.95 | ppl 61.83 | wps 27102.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2188 | lr 0.000273545 | gnorm 1.037 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5255
2022-03-05 15:50:16 | INFO | fairseq.trainer | begin training epoch 46
2022-03-05 15:50:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:50:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:50:45 | INFO | train_inner | epoch 046:     13 / 49 loss=7.409, nll_loss=5.981, ppl=63.17, wps=27197.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.072, loss_scale=16, train_wall=202, gb_free=21.6, wall=5284
2022-03-05 15:52:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:52:09 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.422 | nll_loss 8.229 | ppl 300.01 | wps 46598.1 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 9.173
2022-03-05 15:52:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-05 15:52:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:52:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:52:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 46 @ 2236 updates, score 9.422) (writing took 1.6842630337923765 seconds)
2022-03-05 15:52:11 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-05 15:52:11 | INFO | train | epoch 046 | loss 7.311 | nll_loss 5.867 | ppl 58.35 | wps 27157.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.129 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5369
2022-03-05 15:52:11 | INFO | fairseq.trainer | begin training epoch 47
2022-03-05 15:52:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:53:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:54:04 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.446 | nll_loss 8.231 | ppl 300.42 | wps 46647.9 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 9.173
2022-03-05 15:54:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-05 15:54:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:54:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:54:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 47 @ 2285 updates, score 9.446) (writing took 1.7191576873883605 seconds)
2022-03-05 15:54:05 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-05 15:54:05 | INFO | train | epoch 047 | loss 7.231 | nll_loss 5.773 | ppl 54.67 | wps 27696.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.062 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5484
2022-03-05 15:54:06 | INFO | fairseq.trainer | begin training epoch 48
2022-03-05 15:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:54:39 | INFO | train_inner | epoch 048:     15 / 49 loss=7.247, nll_loss=5.791, ppl=55.37, wps=27746.3, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.07, loss_scale=16, train_wall=198, gb_free=21.6, wall=5518
2022-03-05 15:55:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:55:58 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.451 | nll_loss 8.251 | ppl 304.62 | wps 46721.3 | wpb 510.9 | bsz 1 | num_updates 2334 | best_loss 9.173
2022-03-05 15:55:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2334 updates
2022-03-05 15:55:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:56:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:56:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 48 @ 2334 updates, score 9.451) (writing took 1.6783089246600866 seconds)
2022-03-05 15:56:00 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-05 15:56:00 | INFO | train | epoch 048 | loss 7.154 | nll_loss 5.682 | ppl 51.36 | wps 27715.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2334 | lr 0.000291792 | gnorm 1.105 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5599
2022-03-05 15:56:00 | INFO | fairseq.trainer | begin training epoch 49
2022-03-05 15:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:57:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:57:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:57:53 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.474 | nll_loss 8.28 | ppl 310.89 | wps 46723.9 | wpb 510.9 | bsz 1 | num_updates 2382 | best_loss 9.173
2022-03-05 15:57:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2382 updates
2022-03-05 15:57:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:57:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:57:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 49 @ 2382 updates, score 9.474) (writing took 1.6778194392099977 seconds)
2022-03-05 15:57:55 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-05 15:57:55 | INFO | train | epoch 049 | loss 7.076 | nll_loss 5.59 | ppl 48.17 | wps 27132.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2382 | lr 0.00029779 | gnorm 1.165 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5714
2022-03-05 15:57:55 | INFO | fairseq.trainer | begin training epoch 50
2022-03-05 15:57:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:58:35 | INFO | train_inner | epoch 050:     18 / 49 loss=7.091, nll_loss=5.608, ppl=48.77, wps=27477.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.136, loss_scale=16, train_wall=200, gb_free=21.6, wall=5754
2022-03-05 15:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:59:48 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.593 | nll_loss 8.406 | ppl 339.09 | wps 46606.1 | wpb 510.9 | bsz 1 | num_updates 2431 | best_loss 9.173
2022-03-05 15:59:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2431 updates
2022-03-05 15:59:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:59:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 15:59:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 50 @ 2431 updates, score 9.593) (writing took 1.6367772053927183 seconds)
2022-03-05 15:59:50 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-05 15:59:50 | INFO | train | epoch 050 | loss 7 | nll_loss 5.5 | ppl 45.27 | wps 27713.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2431 | lr 0.000303914 | gnorm 1.094 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5828
2022-03-05 15:59:50 | INFO | fairseq.trainer | begin training epoch 51
2022-03-05 15:59:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:01:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:01:43 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.558 | nll_loss 8.351 | ppl 326.61 | wps 46523.1 | wpb 510.9 | bsz 1 | num_updates 2480 | best_loss 9.173
2022-03-05 16:01:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2480 updates
2022-03-05 16:01:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:01:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:01:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 51 @ 2480 updates, score 9.558) (writing took 1.6121143382042646 seconds)
2022-03-05 16:01:44 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-05 16:01:44 | INFO | train | epoch 051 | loss 6.926 | nll_loss 5.414 | ppl 42.63 | wps 27707.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2480 | lr 0.000310038 | gnorm 1.184 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5943
2022-03-05 16:01:44 | INFO | fairseq.trainer | begin training epoch 52
2022-03-05 16:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:02:29 | INFO | train_inner | epoch 052:     20 / 49 loss=6.926, nll_loss=5.414, ppl=42.64, wps=27740.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.145, loss_scale=32, train_wall=198, gb_free=21.6, wall=5988
2022-03-05 16:03:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:03:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:03:37 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.633 | nll_loss 8.439 | ppl 346.95 | wps 46456.4 | wpb 510.9 | bsz 1 | num_updates 2528 | best_loss 9.173
2022-03-05 16:03:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2528 updates
2022-03-05 16:03:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:03:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:03:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 52 @ 2528 updates, score 9.633) (writing took 1.662047740072012 seconds)
2022-03-05 16:03:39 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-05 16:03:39 | INFO | train | epoch 052 | loss 6.844 | nll_loss 5.317 | ppl 39.87 | wps 27119.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2528 | lr 0.000316037 | gnorm 1.157 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6058
2022-03-05 16:03:39 | INFO | fairseq.trainer | begin training epoch 53
2022-03-05 16:03:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:05:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:05:32 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.619 | nll_loss 8.409 | ppl 339.89 | wps 46509.6 | wpb 510.9 | bsz 1 | num_updates 2577 | best_loss 9.173
2022-03-05 16:05:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2577 updates
2022-03-05 16:05:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:05:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:05:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 53 @ 2577 updates, score 9.619) (writing took 1.6510507464408875 seconds)
2022-03-05 16:05:34 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-05 16:05:34 | INFO | train | epoch 053 | loss 6.773 | nll_loss 5.234 | ppl 37.62 | wps 27703.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2577 | lr 0.000322161 | gnorm 1.154 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6172
2022-03-05 16:05:34 | INFO | fairseq.trainer | begin training epoch 54
2022-03-05 16:05:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:06:25 | INFO | train_inner | epoch 054:     23 / 49 loss=6.777, nll_loss=5.238, ppl=37.74, wps=27465.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.167, loss_scale=16, train_wall=200, gb_free=21.6, wall=6224
2022-03-05 16:07:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:07:27 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.66 | nll_loss 8.439 | ppl 346.96 | wps 46694.7 | wpb 510.9 | bsz 1 | num_updates 2626 | best_loss 9.173
2022-03-05 16:07:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2626 updates
2022-03-05 16:07:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:07:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:07:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 54 @ 2626 updates, score 9.66) (writing took 1.6210710126906633 seconds)
2022-03-05 16:07:28 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-05 16:07:28 | INFO | train | epoch 054 | loss 6.697 | nll_loss 5.144 | ppl 35.36 | wps 27701.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2626 | lr 0.000328284 | gnorm 1.226 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6287
2022-03-05 16:07:28 | INFO | fairseq.trainer | begin training epoch 55
2022-03-05 16:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:09:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:09:21 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.681 | nll_loss 8.454 | ppl 350.64 | wps 46936.7 | wpb 510.9 | bsz 1 | num_updates 2675 | best_loss 9.173
2022-03-05 16:09:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2675 updates
2022-03-05 16:09:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:09:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:09:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 55 @ 2675 updates, score 9.681) (writing took 1.6342827007174492 seconds)
2022-03-05 16:09:23 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-05 16:09:23 | INFO | train | epoch 055 | loss 6.619 | nll_loss 5.051 | ppl 33.16 | wps 27731.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2675 | lr 0.000334408 | gnorm 1.207 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6402
2022-03-05 16:09:23 | INFO | fairseq.trainer | begin training epoch 56
2022-03-05 16:09:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:09:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:10:21 | INFO | train_inner | epoch 056:     26 / 49 loss=6.622, nll_loss=5.055, ppl=33.25, wps=27494, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.226, loss_scale=16, train_wall=200, gb_free=21.6, wall=6460
2022-03-05 16:11:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:11:16 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.719 | nll_loss 8.501 | ppl 362.17 | wps 46589.4 | wpb 510.9 | bsz 1 | num_updates 2723 | best_loss 9.173
2022-03-05 16:11:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2723 updates
2022-03-05 16:11:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:11:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:11:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 56 @ 2723 updates, score 9.719) (writing took 1.689411879517138 seconds)
2022-03-05 16:11:18 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-05 16:11:18 | INFO | train | epoch 056 | loss 6.547 | nll_loss 4.966 | ppl 31.25 | wps 27147 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2723 | lr 0.000340407 | gnorm 1.257 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6516
2022-03-05 16:11:18 | INFO | fairseq.trainer | begin training epoch 57
2022-03-05 16:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:13:11 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.901 | nll_loss 8.735 | ppl 426.17 | wps 46590.7 | wpb 510.9 | bsz 1 | num_updates 2772 | best_loss 9.173
2022-03-05 16:13:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2772 updates
2022-03-05 16:13:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:13:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:13:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 57 @ 2772 updates, score 9.901) (writing took 1.6332516092807055 seconds)
2022-03-05 16:13:12 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-05 16:13:12 | INFO | train | epoch 057 | loss 6.473 | nll_loss 4.879 | ppl 29.42 | wps 27696.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2772 | lr 0.000346531 | gnorm 1.263 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6631
2022-03-05 16:13:12 | INFO | fairseq.trainer | begin training epoch 58
2022-03-05 16:13:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:14:15 | INFO | train_inner | epoch 058:     28 / 49 loss=6.468, nll_loss=4.873, ppl=29.3, wps=27739.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.251, loss_scale=16, train_wall=198, gb_free=21.6, wall=6694
2022-03-05 16:14:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:15:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:15:05 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.833 | nll_loss 8.622 | ppl 393.87 | wps 46954.6 | wpb 510.9 | bsz 1 | num_updates 2820 | best_loss 9.173
2022-03-05 16:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2820 updates
2022-03-05 16:15:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:15:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 58 @ 2820 updates, score 9.833) (writing took 1.6781721748411655 seconds)
2022-03-05 16:15:07 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-05 16:15:07 | INFO | train | epoch 058 | loss 6.396 | nll_loss 4.788 | ppl 27.63 | wps 27164.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2820 | lr 0.00035253 | gnorm 1.211 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6746
2022-03-05 16:15:07 | INFO | fairseq.trainer | begin training epoch 59
2022-03-05 16:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:16:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:17:00 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.854 | nll_loss 8.65 | ppl 401.74 | wps 46556.5 | wpb 510.9 | bsz 1 | num_updates 2869 | best_loss 9.173
2022-03-05 16:17:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2869 updates
2022-03-05 16:17:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:17:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:17:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 59 @ 2869 updates, score 9.854) (writing took 1.6801952961832285 seconds)
2022-03-05 16:17:02 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-05 16:17:02 | INFO | train | epoch 059 | loss 6.331 | nll_loss 4.71 | ppl 26.18 | wps 27694.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2869 | lr 0.000358653 | gnorm 1.342 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6860
2022-03-05 16:17:02 | INFO | fairseq.trainer | begin training epoch 60
2022-03-05 16:17:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:18:11 | INFO | train_inner | epoch 060:     31 / 49 loss=6.318, nll_loss=4.696, ppl=25.91, wps=27476.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.279, loss_scale=16, train_wall=200, gb_free=21.6, wall=6930
2022-03-05 16:18:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:18:55 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.937 | nll_loss 8.719 | ppl 421.3 | wps 46513 | wpb 510.9 | bsz 1 | num_updates 2918 | best_loss 9.173
2022-03-05 16:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2918 updates
2022-03-05 16:18:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:18:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:18:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 60 @ 2918 updates, score 9.937) (writing took 1.6902231210842729 seconds)
2022-03-05 16:18:57 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-05 16:18:57 | INFO | train | epoch 060 | loss 6.251 | nll_loss 4.616 | ppl 24.52 | wps 27692.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2918 | lr 0.000364777 | gnorm 1.235 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6975
2022-03-05 16:18:57 | INFO | fairseq.trainer | begin training epoch 61
2022-03-05 16:18:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:20:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:20:50 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 10.016 | nll_loss 8.835 | ppl 456.75 | wps 46106.7 | wpb 510.9 | bsz 1 | num_updates 2967 | best_loss 9.173
2022-03-05 16:20:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2967 updates
2022-03-05 16:20:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:20:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:20:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 61 @ 2967 updates, score 10.016) (writing took 1.6731431484222412 seconds)
2022-03-05 16:20:51 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-05 16:20:51 | INFO | train | epoch 061 | loss 6.177 | nll_loss 4.528 | ppl 23.07 | wps 27692 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2967 | lr 0.000370901 | gnorm 1.293 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 7090
2022-03-05 16:20:51 | INFO | fairseq.trainer | begin training epoch 62
2022-03-05 16:20:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:21:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:22:07 | INFO | train_inner | epoch 062:     34 / 49 loss=6.165, nll_loss=4.514, ppl=22.85, wps=27468, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.283, loss_scale=16, train_wall=200, gb_free=21.6, wall=7166
2022-03-05 16:22:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:22:44 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 10.014 | nll_loss 8.794 | ppl 443.84 | wps 46459.4 | wpb 510.9 | bsz 1 | num_updates 3015 | best_loss 9.173
2022-03-05 16:22:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3015 updates
2022-03-05 16:22:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:22:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:22:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 62 @ 3015 updates, score 10.014) (writing took 1.6631294749677181 seconds)
2022-03-05 16:22:46 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-05 16:22:46 | INFO | train | epoch 062 | loss 6.106 | nll_loss 4.444 | ppl 21.76 | wps 27132.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3015 | lr 0.0003769 | gnorm 1.304 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7205
2022-03-05 16:22:46 | INFO | fairseq.trainer | begin training epoch 63
2022-03-05 16:22:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:24:39 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 10.056 | nll_loss 8.83 | ppl 455.15 | wps 46598.9 | wpb 510.9 | bsz 1 | num_updates 3064 | best_loss 9.173
2022-03-05 16:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3064 updates
2022-03-05 16:24:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:24:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:24:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 63 @ 3064 updates, score 10.056) (writing took 1.63627636898309 seconds)
2022-03-05 16:24:41 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-05 16:24:41 | INFO | train | epoch 063 | loss 6.038 | nll_loss 4.363 | ppl 20.58 | wps 27735 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3064 | lr 0.000383023 | gnorm 1.342 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7319
2022-03-05 16:24:41 | INFO | fairseq.trainer | begin training epoch 64
2022-03-05 16:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:26:01 | INFO | train_inner | epoch 064:     36 / 49 loss=6.022, nll_loss=4.344, ppl=20.3, wps=27729.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.323, loss_scale=16, train_wall=198, gb_free=21.6, wall=7400
2022-03-05 16:26:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:26:34 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 10.094 | nll_loss 8.839 | ppl 458.06 | wps 46566 | wpb 510.9 | bsz 1 | num_updates 3113 | best_loss 9.173
2022-03-05 16:26:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3113 updates
2022-03-05 16:26:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:26:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:26:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 64 @ 3113 updates, score 10.094) (writing took 1.6836527325212955 seconds)
2022-03-05 16:26:36 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-05 16:26:36 | INFO | train | epoch 064 | loss 5.966 | nll_loss 4.276 | ppl 19.38 | wps 27648.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3113 | lr 0.000389147 | gnorm 1.327 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7434
2022-03-05 16:26:36 | INFO | fairseq.trainer | begin training epoch 65
2022-03-05 16:26:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:27:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:28:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:28:29 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.174 | nll_loss 8.953 | ppl 495.59 | wps 46555.2 | wpb 510.9 | bsz 1 | num_updates 3161 | best_loss 9.173
2022-03-05 16:28:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3161 updates
2022-03-05 16:28:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:28:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:28:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 65 @ 3161 updates, score 10.174) (writing took 1.688387518748641 seconds)
2022-03-05 16:28:30 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-05 16:28:30 | INFO | train | epoch 065 | loss 5.888 | nll_loss 4.184 | ppl 18.17 | wps 27097 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3161 | lr 0.000395146 | gnorm 1.322 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7549
2022-03-05 16:28:30 | INFO | fairseq.trainer | begin training epoch 66
2022-03-05 16:28:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:29:58 | INFO | train_inner | epoch 066:     39 / 49 loss=5.878, nll_loss=4.171, ppl=18.01, wps=27438.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.367, loss_scale=16, train_wall=200, gb_free=21.6, wall=7636
2022-03-05 16:30:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:30:24 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.181 | nll_loss 8.959 | ppl 497.74 | wps 46444.6 | wpb 510.9 | bsz 1 | num_updates 3210 | best_loss 9.173
2022-03-05 16:30:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3210 updates
2022-03-05 16:30:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:30:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:30:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 66 @ 3210 updates, score 10.181) (writing took 1.650088556110859 seconds)
2022-03-05 16:30:25 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-05 16:30:25 | INFO | train | epoch 066 | loss 5.825 | nll_loss 4.109 | ppl 17.25 | wps 27679.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3210 | lr 0.00040127 | gnorm 1.37 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7664
2022-03-05 16:30:25 | INFO | fairseq.trainer | begin training epoch 67
2022-03-05 16:30:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:32:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:32:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:32:18 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.332 | nll_loss 9.1 | ppl 548.64 | wps 46667.7 | wpb 510.9 | bsz 1 | num_updates 3258 | best_loss 9.173
2022-03-05 16:32:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3258 updates
2022-03-05 16:32:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:32:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:32:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 67 @ 3258 updates, score 10.332) (writing took 1.671305633150041 seconds)
2022-03-05 16:32:20 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-05 16:32:20 | INFO | train | epoch 067 | loss 5.754 | nll_loss 4.023 | ppl 16.26 | wps 27086.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3258 | lr 0.000407269 | gnorm 1.404 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7779
2022-03-05 16:32:20 | INFO | fairseq.trainer | begin training epoch 68
2022-03-05 16:32:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:33:54 | INFO | train_inner | epoch 068:     42 / 49 loss=5.73, nll_loss=3.995, ppl=15.95, wps=27449.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.385, loss_scale=16, train_wall=200, gb_free=21.6, wall=7873
2022-03-05 16:34:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:34:13 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.408 | nll_loss 9.203 | ppl 589.36 | wps 46570.8 | wpb 510.9 | bsz 1 | num_updates 3307 | best_loss 9.173
2022-03-05 16:34:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3307 updates
2022-03-05 16:34:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:34:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:34:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 68 @ 3307 updates, score 10.408) (writing took 1.6741655366495252 seconds)
2022-03-05 16:34:15 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-05 16:34:15 | INFO | train | epoch 068 | loss 5.69 | nll_loss 3.947 | ppl 15.42 | wps 27702.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3307 | lr 0.000413392 | gnorm 1.394 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7894
2022-03-05 16:34:15 | INFO | fairseq.trainer | begin training epoch 69
2022-03-05 16:34:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:36:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:36:08 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.427 | nll_loss 9.204 | ppl 589.87 | wps 46608.1 | wpb 510.9 | bsz 1 | num_updates 3356 | best_loss 9.173
2022-03-05 16:36:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3356 updates
2022-03-05 16:36:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:36:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:36:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 69 @ 3356 updates, score 10.427) (writing took 1.6457995539531112 seconds)
2022-03-05 16:36:10 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-05 16:36:10 | INFO | train | epoch 069 | loss 5.615 | nll_loss 3.858 | ppl 14.5 | wps 27698.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3356 | lr 0.000419516 | gnorm 1.335 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8008
2022-03-05 16:36:10 | INFO | fairseq.trainer | begin training epoch 70
2022-03-05 16:36:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:37:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:37:50 | INFO | train_inner | epoch 070:     45 / 49 loss=5.594, nll_loss=3.832, ppl=14.24, wps=27457.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.37, loss_scale=16, train_wall=200, gb_free=21.6, wall=8109
2022-03-05 16:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:38:03 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.517 | nll_loss 9.324 | ppl 640.76 | wps 46585 | wpb 510.9 | bsz 1 | num_updates 3404 | best_loss 9.173
2022-03-05 16:38:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3404 updates
2022-03-05 16:38:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:38:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:38:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 70 @ 3404 updates, score 10.517) (writing took 1.642255088314414 seconds)
2022-03-05 16:38:04 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-05 16:38:04 | INFO | train | epoch 070 | loss 5.548 | nll_loss 3.777 | ppl 13.71 | wps 27117.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3404 | lr 0.000425515 | gnorm 1.382 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8123
2022-03-05 16:38:04 | INFO | fairseq.trainer | begin training epoch 71
2022-03-05 16:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:38:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 16:39:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:39:57 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.615 | nll_loss 9.425 | ppl 687.42 | wps 46453.1 | wpb 510.9 | bsz 1 | num_updates 3452 | best_loss 9.173
2022-03-05 16:39:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3452 updates
2022-03-05 16:39:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:39:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:39:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 71 @ 3452 updates, score 10.615) (writing took 1.6680570431053638 seconds)
2022-03-05 16:39:59 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-05 16:39:59 | INFO | train | epoch 071 | loss 5.497 | nll_loss 3.714 | ppl 13.13 | wps 27122.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3452 | lr 0.000431514 | gnorm 1.504 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 8238
2022-03-05 16:39:59 | INFO | fairseq.trainer | begin training epoch 72
2022-03-05 16:39:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:41:46 | INFO | train_inner | epoch 072:     48 / 49 loss=5.461, nll_loss=3.672, ppl=12.75, wps=27479.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.419, loss_scale=8, train_wall=200, gb_free=21.6, wall=8345
2022-03-05 16:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:41:52 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.685 | nll_loss 9.517 | ppl 732.41 | wps 46629.5 | wpb 510.9 | bsz 1 | num_updates 3501 | best_loss 9.173
2022-03-05 16:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3501 updates
2022-03-05 16:41:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:41:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:41:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 72 @ 3501 updates, score 10.685) (writing took 1.6571997497230768 seconds)
2022-03-05 16:41:54 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-05 16:41:54 | INFO | train | epoch 072 | loss 5.416 | nll_loss 3.619 | ppl 12.29 | wps 27720.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3501 | lr 0.000437637 | gnorm 1.337 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 8352
2022-03-05 16:41:54 | INFO | fairseq.trainer | begin training epoch 73
2022-03-05 16:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:43:47 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.679 | nll_loss 9.486 | ppl 717.19 | wps 46650.7 | wpb 510.9 | bsz 1 | num_updates 3550 | best_loss 9.173
2022-03-05 16:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3550 updates
2022-03-05 16:43:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:43:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:43:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 73 @ 3550 updates, score 10.679) (writing took 1.6800826480612159 seconds)
2022-03-05 16:43:49 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-05 16:43:49 | INFO | train | epoch 073 | loss 5.354 | nll_loss 3.544 | ppl 11.66 | wps 27707.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3550 | lr 0.000443761 | gnorm 1.409 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8467
2022-03-05 16:43:49 | INFO | fairseq.trainer | begin training epoch 74
2022-03-05 16:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:45:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:45:42 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.749 | nll_loss 9.545 | ppl 747.27 | wps 46498.5 | wpb 510.9 | bsz 1 | num_updates 3599 | best_loss 9.173
2022-03-05 16:45:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3599 updates
2022-03-05 16:45:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:45:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:45:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 74 @ 3599 updates, score 10.749) (writing took 1.6751020168885589 seconds)
2022-03-05 16:45:43 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-05 16:45:43 | INFO | train | epoch 074 | loss 5.29 | nll_loss 3.467 | ppl 11.06 | wps 27671.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3599 | lr 0.000449885 | gnorm 1.408 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8582
2022-03-05 16:45:43 | INFO | fairseq.trainer | begin training epoch 75
2022-03-05 16:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:45:46 | INFO | train_inner | epoch 075:      1 / 49 loss=5.321, nll_loss=3.504, ppl=11.34, wps=26961.9, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.409, loss_scale=16, train_wall=197, gb_free=21.6, wall=8584
2022-03-05 16:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:47:36 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.857 | nll_loss 9.67 | ppl 814.44 | wps 46469.7 | wpb 510.9 | bsz 1 | num_updates 3648 | best_loss 9.173
2022-03-05 16:47:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3648 updates
2022-03-05 16:47:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:47:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:47:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 75 @ 3648 updates, score 10.857) (writing took 1.6358557362109423 seconds)
2022-03-05 16:47:38 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-05 16:47:38 | INFO | train | epoch 075 | loss 5.226 | nll_loss 3.39 | ppl 10.49 | wps 27716.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3648 | lr 0.000456009 | gnorm 1.435 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8697
2022-03-05 16:47:38 | INFO | fairseq.trainer | begin training epoch 76
2022-03-05 16:47:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:48:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:49:31 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.995 | nll_loss 9.841 | ppl 917.33 | wps 46630.8 | wpb 510.9 | bsz 1 | num_updates 3696 | best_loss 9.173
2022-03-05 16:49:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3696 updates
2022-03-05 16:49:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:49:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:49:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 76 @ 3696 updates, score 10.995) (writing took 1.637322905473411 seconds)
2022-03-05 16:49:33 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-05 16:49:33 | INFO | train | epoch 076 | loss 5.165 | nll_loss 3.316 | ppl 9.96 | wps 27145.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3696 | lr 0.000462008 | gnorm 1.483 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8811
2022-03-05 16:49:33 | INFO | fairseq.trainer | begin training epoch 77
2022-03-05 16:49:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:49:42 | INFO | train_inner | epoch 077:      4 / 49 loss=5.191, nll_loss=3.348, ppl=10.18, wps=27485.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.453, loss_scale=16, train_wall=200, gb_free=21.6, wall=8820
2022-03-05 16:49:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 16:51:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:51:26 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 11.042 | nll_loss 9.843 | ppl 918.65 | wps 46203.6 | wpb 510.9 | bsz 1 | num_updates 3744 | best_loss 9.173
2022-03-05 16:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3744 updates
2022-03-05 16:51:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:51:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 77 @ 3744 updates, score 11.042) (writing took 1.6412458503618836 seconds)
2022-03-05 16:51:27 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-05 16:51:27 | INFO | train | epoch 077 | loss 5.095 | nll_loss 3.233 | ppl 9.4 | wps 27139.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3744 | lr 0.000468006 | gnorm 1.331 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 8926
2022-03-05 16:51:27 | INFO | fairseq.trainer | begin training epoch 78
2022-03-05 16:51:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:53:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:53:20 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.147 | nll_loss 10.001 | ppl 1024.38 | wps 46193.4 | wpb 510.9 | bsz 1 | num_updates 3793 | best_loss 9.173
2022-03-05 16:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3793 updates
2022-03-05 16:53:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:53:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 78 @ 3793 updates, score 11.147) (writing took 1.658471935428679 seconds)
2022-03-05 16:53:22 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-05 16:53:22 | INFO | train | epoch 078 | loss 5.064 | nll_loss 3.192 | ppl 9.14 | wps 27718.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3793 | lr 0.00047413 | gnorm 1.504 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 9041
2022-03-05 16:53:22 | INFO | fairseq.trainer | begin training epoch 79
2022-03-05 16:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:53:38 | INFO | train_inner | epoch 079:      7 / 49 loss=5.07, nll_loss=3.202, ppl=9.2, wps=27483, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.42, loss_scale=8, train_wall=200, gb_free=21.6, wall=9056
2022-03-05 16:55:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:55:15 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.17 | nll_loss 9.997 | ppl 1021.96 | wps 46769.4 | wpb 510.9 | bsz 1 | num_updates 3842 | best_loss 9.173
2022-03-05 16:55:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3842 updates
2022-03-05 16:55:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:55:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:55:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 79 @ 3842 updates, score 11.17) (writing took 1.6715490594506264 seconds)
2022-03-05 16:55:17 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-05 16:55:17 | INFO | train | epoch 079 | loss 4.989 | nll_loss 3.103 | ppl 8.59 | wps 27709.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3842 | lr 0.000480254 | gnorm 1.477 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9155
2022-03-05 16:55:17 | INFO | fairseq.trainer | begin training epoch 80
2022-03-05 16:55:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:57:10 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.311 | nll_loss 10.162 | ppl 1145.98 | wps 46546.7 | wpb 510.9 | bsz 1 | num_updates 3891 | best_loss 9.173
2022-03-05 16:57:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3891 updates
2022-03-05 16:57:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:57:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 80 @ 3891 updates, score 11.311) (writing took 1.6356900921091437 seconds)
2022-03-05 16:57:11 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-05 16:57:11 | INFO | train | epoch 080 | loss 4.925 | nll_loss 3.027 | ppl 8.15 | wps 27700.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3891 | lr 0.000486378 | gnorm 1.392 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9270
2022-03-05 16:57:11 | INFO | fairseq.trainer | begin training epoch 81
2022-03-05 16:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:57:32 | INFO | train_inner | epoch 081:      9 / 49 loss=4.944, nll_loss=3.05, ppl=8.28, wps=27736, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.435, loss_scale=16, train_wall=198, gb_free=21.6, wall=9290
2022-03-05 16:59:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:59:04 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.426 | nll_loss 10.297 | ppl 1257.78 | wps 46627.4 | wpb 510.9 | bsz 1 | num_updates 3940 | best_loss 9.173
2022-03-05 16:59:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3940 updates
2022-03-05 16:59:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:59:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 16:59:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 81 @ 3940 updates, score 11.426) (writing took 1.6826437776908278 seconds)
2022-03-05 16:59:06 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-05 16:59:06 | INFO | train | epoch 081 | loss 4.871 | nll_loss 2.961 | ppl 7.79 | wps 27725.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3940 | lr 0.000492502 | gnorm 1.429 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9385
2022-03-05 16:59:06 | INFO | fairseq.trainer | begin training epoch 82
2022-03-05 16:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:59:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:00:59 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.506 | nll_loss 10.402 | ppl 1353.15 | wps 46597 | wpb 510.9 | bsz 1 | num_updates 3988 | best_loss 9.173
2022-03-05 17:00:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3988 updates
2022-03-05 17:00:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:01:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:01:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 82 @ 3988 updates, score 11.506) (writing took 1.632505476474762 seconds)
2022-03-05 17:01:01 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-05 17:01:01 | INFO | train | epoch 082 | loss 4.815 | nll_loss 2.893 | ppl 7.43 | wps 27131.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3988 | lr 0.0004985 | gnorm 1.48 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 9499
2022-03-05 17:01:01 | INFO | fairseq.trainer | begin training epoch 83
2022-03-05 17:01:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:01:28 | INFO | train_inner | epoch 083:     12 / 49 loss=4.829, nll_loss=2.911, ppl=7.52, wps=27484.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.441, loss_scale=8, train_wall=200, gb_free=21.6, wall=9526
2022-03-05 17:02:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:02:54 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.613 | nll_loss 10.503 | ppl 1450.72 | wps 46555.9 | wpb 510.9 | bsz 1 | num_updates 4037 | best_loss 9.173
2022-03-05 17:02:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4037 updates
2022-03-05 17:02:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 83 @ 4037 updates, score 11.613) (writing took 1.6230566734448075 seconds)
2022-03-05 17:02:55 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-05 17:02:55 | INFO | train | epoch 083 | loss 4.76 | nll_loss 2.828 | ppl 7.1 | wps 27722.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4037 | lr 0.000497703 | gnorm 1.399 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 9614
2022-03-05 17:02:55 | INFO | fairseq.trainer | begin training epoch 84
2022-03-05 17:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:04:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:04:48 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.553 | nll_loss 10.397 | ppl 1347.98 | wps 46433.2 | wpb 510.9 | bsz 1 | num_updates 4086 | best_loss 9.173
2022-03-05 17:04:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4086 updates
2022-03-05 17:04:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:04:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:04:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 84 @ 4086 updates, score 11.553) (writing took 1.6683452976867557 seconds)
2022-03-05 17:04:50 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-05 17:04:50 | INFO | train | epoch 084 | loss 4.698 | nll_loss 2.753 | ppl 6.74 | wps 27711.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4086 | lr 0.00049471 | gnorm 1.406 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9729
2022-03-05 17:04:50 | INFO | fairseq.trainer | begin training epoch 85
2022-03-05 17:04:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:05:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:05:24 | INFO | train_inner | epoch 085:     15 / 49 loss=4.714, nll_loss=2.771, ppl=6.83, wps=27481.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.397, loss_scale=8, train_wall=200, gb_free=21.6, wall=9762
2022-03-05 17:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:06:43 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.713 | nll_loss 10.585 | ppl 1536.5 | wps 46631 | wpb 510.9 | bsz 1 | num_updates 4134 | best_loss 9.173
2022-03-05 17:06:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4134 updates
2022-03-05 17:06:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:06:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:06:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 85 @ 4134 updates, score 11.713) (writing took 1.6418612943962216 seconds)
2022-03-05 17:06:45 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-05 17:06:45 | INFO | train | epoch 085 | loss 4.637 | nll_loss 2.679 | ppl 6.41 | wps 27168.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4134 | lr 0.00049183 | gnorm 1.388 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 9843
2022-03-05 17:06:45 | INFO | fairseq.trainer | begin training epoch 86
2022-03-05 17:06:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:08:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:08:38 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.767 | nll_loss 10.653 | ppl 1610.57 | wps 46605.9 | wpb 510.9 | bsz 1 | num_updates 4183 | best_loss 9.173
2022-03-05 17:08:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4183 updates
2022-03-05 17:08:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:08:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:08:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 86 @ 4183 updates, score 11.767) (writing took 1.6110296314582229 seconds)
2022-03-05 17:08:39 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-05 17:08:39 | INFO | train | epoch 086 | loss 4.586 | nll_loss 2.617 | ppl 6.14 | wps 27731.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4183 | lr 0.000488941 | gnorm 1.384 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 9958
2022-03-05 17:08:39 | INFO | fairseq.trainer | begin training epoch 87
2022-03-05 17:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:09:17 | INFO | train_inner | epoch 087:     17 / 49 loss=4.59, nll_loss=2.623, ppl=6.16, wps=27774.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.374, loss_scale=8, train_wall=198, gb_free=21.6, wall=9996
2022-03-05 17:09:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-05 17:10:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:10:32 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.893 | nll_loss 10.809 | ppl 1793.65 | wps 46590.6 | wpb 510.9 | bsz 1 | num_updates 4231 | best_loss 9.173
2022-03-05 17:10:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4231 updates
2022-03-05 17:10:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:10:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:10:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 87 @ 4231 updates, score 11.893) (writing took 1.6768973004072905 seconds)
2022-03-05 17:10:34 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-05 17:10:34 | INFO | train | epoch 087 | loss 4.525 | nll_loss 2.545 | ppl 5.84 | wps 27166.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4231 | lr 0.000486159 | gnorm 1.332 | loss_scale 4 | train_wall 97 | gb_free 21.6 | wall 10073
2022-03-05 17:10:34 | INFO | fairseq.trainer | begin training epoch 88
2022-03-05 17:10:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:12:27 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.993 | nll_loss 10.896 | ppl 1905.11 | wps 46800 | wpb 510.9 | bsz 1 | num_updates 4280 | best_loss 9.173
2022-03-05 17:12:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4280 updates
2022-03-05 17:12:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:12:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:12:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 88 @ 4280 updates, score 11.993) (writing took 1.667159435339272 seconds)
2022-03-05 17:12:28 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-05 17:12:28 | INFO | train | epoch 088 | loss 4.476 | nll_loss 2.486 | ppl 5.6 | wps 27727.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4280 | lr 0.000483368 | gnorm 1.317 | loss_scale 4 | train_wall 97 | gb_free 21.6 | wall 10187
2022-03-05 17:12:28 | INFO | fairseq.trainer | begin training epoch 89
2022-03-05 17:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:13:13 | INFO | train_inner | epoch 089:     20 / 49 loss=4.483, nll_loss=2.493, ppl=5.63, wps=27500.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.347, loss_scale=4, train_wall=200, gb_free=21.6, wall=10232
2022-03-05 17:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:14:21 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 12.106 | nll_loss 11.052 | ppl 2123.21 | wps 46463.4 | wpb 510.9 | bsz 1 | num_updates 4329 | best_loss 9.173
2022-03-05 17:14:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4329 updates
2022-03-05 17:14:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:14:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:14:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 89 @ 4329 updates, score 12.106) (writing took 1.6753893215209246 seconds)
2022-03-05 17:14:23 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-05 17:14:23 | INFO | train | epoch 089 | loss 4.425 | nll_loss 2.424 | ppl 5.37 | wps 27706.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4329 | lr 0.000480625 | gnorm 1.313 | loss_scale 4 | train_wall 97 | gb_free 21.6 | wall 10302
2022-03-05 17:14:23 | INFO | fairseq.trainer | begin training epoch 90
2022-03-05 17:14:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:16:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:16:16 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 12.066 | nll_loss 10.98 | ppl 2019.24 | wps 46632 | wpb 510.9 | bsz 1 | num_updates 4378 | best_loss 9.173
2022-03-05 17:16:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4378 updates
2022-03-05 17:16:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:16:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:16:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 90 @ 4378 updates, score 12.066) (writing took 1.6924342345446348 seconds)
2022-03-05 17:16:18 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-05 17:16:18 | INFO | train | epoch 090 | loss 4.377 | nll_loss 2.366 | ppl 5.16 | wps 27687.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4378 | lr 0.000477928 | gnorm 1.336 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10417
2022-03-05 17:16:18 | INFO | fairseq.trainer | begin training epoch 91
2022-03-05 17:16:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:17:07 | INFO | train_inner | epoch 091:     22 / 49 loss=4.378, nll_loss=2.367, ppl=5.16, wps=27731.3, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.295, loss_scale=8, train_wall=198, gb_free=21.6, wall=10466
2022-03-05 17:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:18:11 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 12.112 | nll_loss 11.014 | ppl 2068.03 | wps 46686.5 | wpb 510.9 | bsz 1 | num_updates 4427 | best_loss 9.173
2022-03-05 17:18:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4427 updates
2022-03-05 17:18:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:18:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:18:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 91 @ 4427 updates, score 12.112) (writing took 1.6815502690151334 seconds)
2022-03-05 17:18:13 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-05 17:18:13 | INFO | train | epoch 091 | loss 4.327 | nll_loss 2.306 | ppl 4.95 | wps 27723.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4427 | lr 0.000475275 | gnorm 1.281 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10531
2022-03-05 17:18:13 | INFO | fairseq.trainer | begin training epoch 92
2022-03-05 17:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:19:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:20:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:20:06 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 12.333 | nll_loss 11.281 | ppl 2488.31 | wps 46632.7 | wpb 510.9 | bsz 1 | num_updates 4475 | best_loss 9.173
2022-03-05 17:20:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4475 updates
2022-03-05 17:20:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:20:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:20:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 92 @ 4475 updates, score 12.333) (writing took 1.6749551137909293 seconds)
2022-03-05 17:20:07 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-05 17:20:07 | INFO | train | epoch 092 | loss 4.278 | nll_loss 2.247 | ppl 4.75 | wps 27129.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4475 | lr 0.000472719 | gnorm 1.285 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10646
2022-03-05 17:20:07 | INFO | fairseq.trainer | begin training epoch 93
2022-03-05 17:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:21:03 | INFO | train_inner | epoch 093:     25 / 49 loss=4.283, nll_loss=2.253, ppl=4.77, wps=27480.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.3, loss_scale=8, train_wall=200, gb_free=21.6, wall=10702
2022-03-05 17:21:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:22:00 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 12.302 | nll_loss 11.208 | ppl 2365.76 | wps 46528.3 | wpb 510.9 | bsz 1 | num_updates 4524 | best_loss 9.173
2022-03-05 17:22:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4524 updates
2022-03-05 17:22:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:22:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:22:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 93 @ 4524 updates, score 12.302) (writing took 1.6716345632448792 seconds)
2022-03-05 17:22:02 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-05 17:22:02 | INFO | train | epoch 093 | loss 4.237 | nll_loss 2.199 | ppl 4.59 | wps 27710.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4524 | lr 0.000470152 | gnorm 1.289 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10761
2022-03-05 17:22:02 | INFO | fairseq.trainer | begin training epoch 94
2022-03-05 17:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:23:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:23:55 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 12.277 | nll_loss 11.208 | ppl 2365.1 | wps 46454.5 | wpb 510.9 | bsz 1 | num_updates 4573 | best_loss 9.173
2022-03-05 17:23:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4573 updates
2022-03-05 17:23:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:23:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:23:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 94 @ 4573 updates, score 12.277) (writing took 1.6957741128280759 seconds)
2022-03-05 17:23:57 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-05 17:23:57 | INFO | train | epoch 094 | loss 4.191 | nll_loss 2.142 | ppl 4.41 | wps 27693.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4573 | lr 0.000467627 | gnorm 1.257 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10875
2022-03-05 17:23:57 | INFO | fairseq.trainer | begin training epoch 95
2022-03-05 17:23:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:24:57 | INFO | train_inner | epoch 095:     27 / 49 loss=4.192, nll_loss=2.143, ppl=4.42, wps=27733.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.285, loss_scale=16, train_wall=198, gb_free=21.6, wall=10936
2022-03-05 17:25:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:25:50 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 12.487 | nll_loss 11.452 | ppl 2800.78 | wps 46480.7 | wpb 510.9 | bsz 1 | num_updates 4622 | best_loss 9.173
2022-03-05 17:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4622 updates
2022-03-05 17:25:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:25:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:25:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 95 @ 4622 updates, score 12.487) (writing took 1.6649070512503386 seconds)
2022-03-05 17:25:51 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-05 17:25:51 | INFO | train | epoch 095 | loss 4.152 | nll_loss 2.096 | ppl 4.27 | wps 27715.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4622 | lr 0.000465141 | gnorm 1.278 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10990
2022-03-05 17:25:51 | INFO | fairseq.trainer | begin training epoch 96
2022-03-05 17:25:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:27:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:27:44 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 12.411 | nll_loss 11.362 | ppl 2632.08 | wps 46529.9 | wpb 510.9 | bsz 1 | num_updates 4670 | best_loss 9.173
2022-03-05 17:27:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4670 updates
2022-03-05 17:27:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:27:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:27:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 96 @ 4670 updates, score 12.411) (writing took 1.6545786019414663 seconds)
2022-03-05 17:27:46 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-05 17:27:46 | INFO | train | epoch 096 | loss 4.106 | nll_loss 2.041 | ppl 4.11 | wps 27133.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4670 | lr 0.000462745 | gnorm 1.214 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11105
2022-03-05 17:27:46 | INFO | fairseq.trainer | begin training epoch 97
2022-03-05 17:27:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:28:53 | INFO | train_inner | epoch 097:     30 / 49 loss=4.105, nll_loss=2.039, ppl=4.11, wps=27479.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.231, loss_scale=8, train_wall=200, gb_free=21.6, wall=11172
2022-03-05 17:29:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:29:39 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 12.499 | nll_loss 11.463 | ppl 2822.66 | wps 46817.1 | wpb 510.9 | bsz 1 | num_updates 4719 | best_loss 9.173
2022-03-05 17:29:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4719 updates
2022-03-05 17:29:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:29:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:29:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 97 @ 4719 updates, score 12.499) (writing took 1.65439332742244 seconds)
2022-03-05 17:29:41 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-05 17:29:41 | INFO | train | epoch 097 | loss 4.074 | nll_loss 2.002 | ppl 4 | wps 27727.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4719 | lr 0.000460336 | gnorm 1.267 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11219
2022-03-05 17:29:41 | INFO | fairseq.trainer | begin training epoch 98
2022-03-05 17:29:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:31:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:31:34 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.556 | nll_loss 11.529 | ppl 2954.34 | wps 46533.3 | wpb 510.9 | bsz 1 | num_updates 4768 | best_loss 9.173
2022-03-05 17:31:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4768 updates
2022-03-05 17:31:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:31:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:31:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 98 @ 4768 updates, score 12.556) (writing took 1.662672569975257 seconds)
2022-03-05 17:31:36 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-05 17:31:36 | INFO | train | epoch 098 | loss 4.031 | nll_loss 1.951 | ppl 3.87 | wps 27682.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4768 | lr 0.000457965 | gnorm 1.196 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11334
2022-03-05 17:31:36 | INFO | fairseq.trainer | begin training epoch 99
2022-03-05 17:31:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:32:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:32:49 | INFO | train_inner | epoch 099:     33 / 49 loss=4.033, nll_loss=1.952, ppl=3.87, wps=27478.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.23, loss_scale=8, train_wall=200, gb_free=21.6, wall=11408
2022-03-05 17:33:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:33:29 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.672 | nll_loss 11.654 | ppl 3223.1 | wps 46697.5 | wpb 510.9 | bsz 1 | num_updates 4816 | best_loss 9.173
2022-03-05 17:33:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4816 updates
2022-03-05 17:33:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:33:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:33:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 99 @ 4816 updates, score 12.672) (writing took 1.6620648661628366 seconds)
2022-03-05 17:33:30 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-05 17:33:30 | INFO | train | epoch 099 | loss 3.998 | nll_loss 1.91 | ppl 3.76 | wps 27143.2 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 4816 | lr 0.000455677 | gnorm 1.233 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11449
2022-03-05 17:33:30 | INFO | fairseq.trainer | begin training epoch 100
2022-03-05 17:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:35:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:35:23 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.689 | nll_loss 11.679 | ppl 3278.86 | wps 46712.4 | wpb 510.9 | bsz 1 | num_updates 4865 | best_loss 9.173
2022-03-05 17:35:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4865 updates
2022-03-05 17:35:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:35:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 100 @ 4865 updates, score 12.689) (writing took 1.6616521393880248 seconds)
2022-03-05 17:35:25 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-05 17:35:25 | INFO | train | epoch 100 | loss 3.965 | nll_loss 1.871 | ppl 3.66 | wps 27718.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4865 | lr 0.000453376 | gnorm 1.226 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11564
2022-03-05 17:35:25 | INFO | fairseq.trainer | begin training epoch 101
2022-03-05 17:35:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:36:43 | INFO | train_inner | epoch 101:     35 / 49 loss=3.954, nll_loss=1.859, ppl=3.63, wps=27740.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.195, loss_scale=8, train_wall=198, gb_free=21.6, wall=11642
2022-03-05 17:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:37:18 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.715 | nll_loss 11.713 | ppl 3356.89 | wps 46713.2 | wpb 510.9 | bsz 1 | num_updates 4914 | best_loss 9.173
2022-03-05 17:37:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4914 updates
2022-03-05 17:37:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:37:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:37:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 101 @ 4914 updates, score 12.715) (writing took 1.6441278057172894 seconds)
2022-03-05 17:37:20 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-05 17:37:20 | INFO | train | epoch 101 | loss 3.928 | nll_loss 1.827 | ppl 3.55 | wps 27714.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4914 | lr 0.00045111 | gnorm 1.19 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11678
2022-03-05 17:37:20 | INFO | fairseq.trainer | begin training epoch 102
2022-03-05 17:37:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:38:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:39:13 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.852 | nll_loss 11.868 | ppl 3739.01 | wps 46643.6 | wpb 510.9 | bsz 1 | num_updates 4962 | best_loss 9.173
2022-03-05 17:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4962 updates
2022-03-05 17:39:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:39:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:39:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 102 @ 4962 updates, score 12.852) (writing took 1.5969013590365648 seconds)
2022-03-05 17:39:14 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-05 17:39:14 | INFO | train | epoch 102 | loss 3.893 | nll_loss 1.785 | ppl 3.45 | wps 27152.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4962 | lr 0.000448923 | gnorm 1.183 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11793
2022-03-05 17:39:14 | INFO | fairseq.trainer | begin training epoch 103
2022-03-05 17:39:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:40:39 | INFO | train_inner | epoch 103:     38 / 49 loss=3.886, nll_loss=1.778, ppl=3.43, wps=27494.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.186, loss_scale=8, train_wall=200, gb_free=21.6, wall=11878
2022-03-05 17:41:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:41:07 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.779 | nll_loss 11.773 | ppl 3500.64 | wps 46477.8 | wpb 510.9 | bsz 1 | num_updates 5011 | best_loss 9.173
2022-03-05 17:41:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5011 updates
2022-03-05 17:41:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:41:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:41:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 103 @ 5011 updates, score 12.779) (writing took 1.6792584583163261 seconds)
2022-03-05 17:41:09 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-05 17:41:09 | INFO | train | epoch 103 | loss 3.863 | nll_loss 1.75 | ppl 3.36 | wps 27701.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5011 | lr 0.000446722 | gnorm 1.148 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11908
2022-03-05 17:41:09 | INFO | fairseq.trainer | begin training epoch 104
2022-03-05 17:41:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:43:02 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.803 | nll_loss 11.804 | ppl 3575.1 | wps 46417 | wpb 510.9 | bsz 1 | num_updates 5060 | best_loss 9.173
2022-03-05 17:43:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5060 updates
2022-03-05 17:43:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:43:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:43:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 104 @ 5060 updates, score 12.803) (writing took 1.6525503937155008 seconds)
2022-03-05 17:43:04 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-05 17:43:04 | INFO | train | epoch 104 | loss 3.833 | nll_loss 1.714 | ppl 3.28 | wps 27714.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5060 | lr 0.000444554 | gnorm 1.181 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12022
2022-03-05 17:43:04 | INFO | fairseq.trainer | begin training epoch 105
2022-03-05 17:43:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:44:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:44:35 | INFO | train_inner | epoch 105:     41 / 49 loss=3.826, nll_loss=1.705, ppl=3.26, wps=27476.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.154, loss_scale=8, train_wall=200, gb_free=21.6, wall=12114
2022-03-05 17:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:44:57 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.858 | nll_loss 11.852 | ppl 3696.16 | wps 46428.7 | wpb 510.9 | bsz 1 | num_updates 5108 | best_loss 9.173
2022-03-05 17:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5108 updates
2022-03-05 17:44:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:44:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:44:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 105 @ 5108 updates, score 12.858) (writing took 1.6217943402007222 seconds)
2022-03-05 17:44:58 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-05 17:44:58 | INFO | train | epoch 105 | loss 3.803 | nll_loss 1.679 | ppl 3.2 | wps 27147.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5108 | lr 0.000442461 | gnorm 1.139 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12137
2022-03-05 17:44:58 | INFO | fairseq.trainer | begin training epoch 106
2022-03-05 17:44:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:46:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:46:51 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.909 | nll_loss 11.938 | ppl 3923.88 | wps 46627.3 | wpb 510.9 | bsz 1 | num_updates 5157 | best_loss 9.173
2022-03-05 17:46:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5157 updates
2022-03-05 17:46:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:46:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:46:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 106 @ 5157 updates, score 12.909) (writing took 1.6322638727724552 seconds)
2022-03-05 17:46:53 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-05 17:46:53 | INFO | train | epoch 106 | loss 3.776 | nll_loss 1.646 | ppl 3.13 | wps 27692 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5157 | lr 0.000440353 | gnorm 1.151 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12252
2022-03-05 17:46:53 | INFO | fairseq.trainer | begin training epoch 107
2022-03-05 17:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:48:29 | INFO | train_inner | epoch 107:     43 / 49 loss=3.768, nll_loss=1.637, ppl=3.11, wps=27738.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.144, loss_scale=8, train_wall=198, gb_free=21.6, wall=12348
2022-03-05 17:48:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:48:46 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.903 | nll_loss 11.894 | ppl 3805.2 | wps 46651.4 | wpb 510.9 | bsz 1 | num_updates 5206 | best_loss 9.173
2022-03-05 17:48:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5206 updates
2022-03-05 17:48:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:48:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:48:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 107 @ 5206 updates, score 12.903) (writing took 1.673366241157055 seconds)
2022-03-05 17:48:48 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-05 17:48:48 | INFO | train | epoch 107 | loss 3.749 | nll_loss 1.614 | ppl 3.06 | wps 27714.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5206 | lr 0.000438276 | gnorm 1.143 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12366
2022-03-05 17:48:48 | INFO | fairseq.trainer | begin training epoch 108
2022-03-05 17:48:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:49:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:50:41 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 13.047 | nll_loss 12.076 | ppl 4318.2 | wps 46554.9 | wpb 510.9 | bsz 1 | num_updates 5254 | best_loss 9.173
2022-03-05 17:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5254 updates
2022-03-05 17:50:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:50:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:50:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 108 @ 5254 updates, score 13.047) (writing took 1.6878888458013535 seconds)
2022-03-05 17:50:42 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-05 17:50:42 | INFO | train | epoch 108 | loss 3.718 | nll_loss 1.578 | ppl 2.98 | wps 27119.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5254 | lr 0.00043627 | gnorm 1.111 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12481
2022-03-05 17:50:42 | INFO | fairseq.trainer | begin training epoch 109
2022-03-05 17:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:52:25 | INFO | train_inner | epoch 109:     46 / 49 loss=3.712, nll_loss=1.57, ppl=2.97, wps=27469.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.125, loss_scale=8, train_wall=200, gb_free=21.6, wall=12584
2022-03-05 17:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:52:36 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.911 | nll_loss 11.927 | ppl 3893.33 | wps 46019.4 | wpb 510.9 | bsz 1 | num_updates 5303 | best_loss 9.173
2022-03-05 17:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5303 updates
2022-03-05 17:52:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:52:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:52:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 109 @ 5303 updates, score 12.911) (writing took 1.6266168868169188 seconds)
2022-03-05 17:52:37 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-05 17:52:37 | INFO | train | epoch 109 | loss 3.697 | nll_loss 1.553 | ppl 2.93 | wps 27700.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5303 | lr 0.000434249 | gnorm 1.132 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12596
2022-03-05 17:52:37 | INFO | fairseq.trainer | begin training epoch 110
2022-03-05 17:52:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:54:30 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 13.104 | nll_loss 12.142 | ppl 4518.72 | wps 46569.1 | wpb 510.9 | bsz 1 | num_updates 5352 | best_loss 9.173
2022-03-05 17:54:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5352 updates
2022-03-05 17:54:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:54:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:54:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 110 @ 5352 updates, score 13.104) (writing took 1.692103642039001 seconds)
2022-03-05 17:54:32 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-05 17:54:32 | INFO | train | epoch 110 | loss 3.672 | nll_loss 1.524 | ppl 2.87 | wps 27693 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5352 | lr 0.000432257 | gnorm 1.109 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12711
2022-03-05 17:54:32 | INFO | fairseq.trainer | begin training epoch 111
2022-03-05 17:54:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:55:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:56:20 | INFO | train_inner | epoch 111:     49 / 49 loss=3.661, nll_loss=1.512, ppl=2.85, wps=27453.6, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=5400, lr=0.000430331, gnorm=1.112, loss_scale=8, train_wall=199, gb_free=21.6, wall=12819
2022-03-05 17:56:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:56:25 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 13.023 | nll_loss 12.058 | ppl 4263.66 | wps 46282 | wpb 510.9 | bsz 1 | num_updates 5400 | best_loss 9.173
2022-03-05 17:56:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5400 updates
2022-03-05 17:56:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:56:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:56:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 111 @ 5400 updates, score 13.023) (writing took 1.6932001495733857 seconds)
2022-03-05 17:56:27 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-05 17:56:27 | INFO | train | epoch 111 | loss 3.647 | nll_loss 1.495 | ppl 2.82 | wps 27115.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5400 | lr 0.000430331 | gnorm 1.109 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12825
2022-03-05 17:56:27 | INFO | fairseq.trainer | begin training epoch 112
2022-03-05 17:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:58:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:58:20 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.979 | nll_loss 11.989 | ppl 4065.37 | wps 46514.6 | wpb 510.9 | bsz 1 | num_updates 5449 | best_loss 9.173
2022-03-05 17:58:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5449 updates
2022-03-05 17:58:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:58:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 17:58:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 112 @ 5449 updates, score 12.979) (writing took 1.7128353305161 seconds)
2022-03-05 17:58:21 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-05 17:58:21 | INFO | train | epoch 112 | loss 3.624 | nll_loss 1.468 | ppl 2.77 | wps 27706.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5449 | lr 0.000428392 | gnorm 1.093 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12940
2022-03-05 17:58:21 | INFO | fairseq.trainer | begin training epoch 113
2022-03-05 17:58:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:00:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:00:14 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 13.172 | nll_loss 12.213 | ppl 4747.94 | wps 46554.6 | wpb 510.9 | bsz 1 | num_updates 5498 | best_loss 9.173
2022-03-05 18:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5498 updates
2022-03-05 18:00:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:00:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 113 @ 5498 updates, score 13.172) (writing took 1.6657367246225476 seconds)
2022-03-05 18:00:16 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-05 18:00:16 | INFO | train | epoch 113 | loss 3.6 | nll_loss 1.44 | ppl 2.71 | wps 27711.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5498 | lr 0.000426479 | gnorm 1.07 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13055
2022-03-05 18:00:16 | INFO | fairseq.trainer | begin training epoch 114
2022-03-05 18:00:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:00:21 | INFO | train_inner | epoch 114:      2 / 49 loss=3.611, nll_loss=1.452, ppl=2.74, wps=26986.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5500, lr=0.000426401, gnorm=1.083, loss_scale=16, train_wall=198, gb_free=21.6, wall=13059
2022-03-05 18:00:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:02:09 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 13.092 | nll_loss 12.114 | ppl 4431.41 | wps 46689 | wpb 510.9 | bsz 1 | num_updates 5546 | best_loss 9.173
2022-03-05 18:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5546 updates
2022-03-05 18:02:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:02:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 114 @ 5546 updates, score 13.092) (writing took 1.6663746628910303 seconds)
2022-03-05 18:02:11 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-05 18:02:11 | INFO | train | epoch 114 | loss 3.578 | nll_loss 1.415 | ppl 2.67 | wps 27152.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5546 | lr 0.000424629 | gnorm 1.066 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13169
2022-03-05 18:02:11 | INFO | fairseq.trainer | begin training epoch 115
2022-03-05 18:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:04:04 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 13.106 | nll_loss 12.126 | ppl 4468.56 | wps 46752.5 | wpb 510.9 | bsz 1 | num_updates 5595 | best_loss 9.173
2022-03-05 18:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5595 updates
2022-03-05 18:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:04:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 115 @ 5595 updates, score 13.106) (writing took 1.6534968689084053 seconds)
2022-03-05 18:04:05 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-05 18:04:05 | INFO | train | epoch 115 | loss 3.561 | nll_loss 1.394 | ppl 2.63 | wps 27712.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5595 | lr 0.000422766 | gnorm 1.064 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13284
2022-03-05 18:04:05 | INFO | fairseq.trainer | begin training epoch 116
2022-03-05 18:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:04:17 | INFO | train_inner | epoch 116:      5 / 49 loss=3.566, nll_loss=1.401, ppl=2.64, wps=27483.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.063, loss_scale=8, train_wall=200, gb_free=21.6, wall=13295
2022-03-05 18:05:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:05:58 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 13.123 | nll_loss 12.149 | ppl 4542.14 | wps 46646.4 | wpb 510.9 | bsz 1 | num_updates 5644 | best_loss 9.173
2022-03-05 18:05:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5644 updates
2022-03-05 18:05:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:06:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:06:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 116 @ 5644 updates, score 13.123) (writing took 1.6474203495308757 seconds)
2022-03-05 18:06:00 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-05 18:06:00 | INFO | train | epoch 116 | loss 3.541 | nll_loss 1.371 | ppl 2.59 | wps 27718.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5644 | lr 0.000420927 | gnorm 1.067 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13399
2022-03-05 18:06:00 | INFO | fairseq.trainer | begin training epoch 117
2022-03-05 18:06:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:06:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:07:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:07:53 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 13.166 | nll_loss 12.207 | ppl 4727.76 | wps 46542 | wpb 510.9 | bsz 1 | num_updates 5692 | best_loss 9.173
2022-03-05 18:07:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5692 updates
2022-03-05 18:07:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:07:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 117 @ 5692 updates, score 13.166) (writing took 1.640513265505433 seconds)
2022-03-05 18:07:55 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-05 18:07:55 | INFO | train | epoch 117 | loss 3.518 | nll_loss 1.345 | ppl 2.54 | wps 27114.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5692 | lr 0.000419148 | gnorm 1.046 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13514
2022-03-05 18:07:55 | INFO | fairseq.trainer | begin training epoch 118
2022-03-05 18:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:08:13 | INFO | train_inner | epoch 118:      8 / 49 loss=3.526, nll_loss=1.355, ppl=2.56, wps=27474.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.052, loss_scale=8, train_wall=200, gb_free=21.6, wall=13532
2022-03-05 18:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:09:48 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.244 | nll_loss 12.314 | ppl 5091.44 | wps 46622.6 | wpb 510.9 | bsz 1 | num_updates 5741 | best_loss 9.173
2022-03-05 18:09:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5741 updates
2022-03-05 18:09:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:09:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:09:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 118 @ 5741 updates, score 13.244) (writing took 1.6741897780448198 seconds)
2022-03-05 18:09:50 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-05 18:09:50 | INFO | train | epoch 118 | loss 3.5 | nll_loss 1.325 | ppl 2.51 | wps 27698.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5741 | lr 0.000417356 | gnorm 1.03 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13628
2022-03-05 18:09:50 | INFO | fairseq.trainer | begin training epoch 119
2022-03-05 18:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:11:43 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 13.226 | nll_loss 12.267 | ppl 4928.74 | wps 46466.4 | wpb 510.9 | bsz 1 | num_updates 5790 | best_loss 9.173
2022-03-05 18:11:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5790 updates
2022-03-05 18:11:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:11:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:11:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 119 @ 5790 updates, score 13.226) (writing took 1.7040077010169625 seconds)
2022-03-05 18:11:44 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-05 18:11:44 | INFO | train | epoch 119 | loss 3.481 | nll_loss 1.304 | ppl 2.47 | wps 27690.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5790 | lr 0.000415586 | gnorm 1.016 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13743
2022-03-05 18:11:44 | INFO | fairseq.trainer | begin training epoch 120
2022-03-05 18:11:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:12:07 | INFO | train_inner | epoch 120:     10 / 49 loss=3.487, nll_loss=1.31, ppl=2.48, wps=27723.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.027, loss_scale=16, train_wall=198, gb_free=21.6, wall=13765
2022-03-05 18:13:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:13:37 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13.21 | nll_loss 12.256 | ppl 4892.44 | wps 46547.5 | wpb 510.9 | bsz 1 | num_updates 5839 | best_loss 9.173
2022-03-05 18:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5839 updates
2022-03-05 18:13:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 120 @ 5839 updates, score 13.21) (writing took 1.7047165697440505 seconds)
2022-03-05 18:13:39 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-05 18:13:39 | INFO | train | epoch 120 | loss 3.466 | nll_loss 1.286 | ppl 2.44 | wps 27715.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5839 | lr 0.000413838 | gnorm 1.039 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13858
2022-03-05 18:13:39 | INFO | fairseq.trainer | begin training epoch 121
2022-03-05 18:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:15:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:15:32 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.255 | nll_loss 12.322 | ppl 5121.91 | wps 46617.8 | wpb 510.9 | bsz 1 | num_updates 5887 | best_loss 9.173
2022-03-05 18:15:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5887 updates
2022-03-05 18:15:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:15:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:15:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 121 @ 5887 updates, score 13.255) (writing took 1.6231155144050717 seconds)
2022-03-05 18:15:34 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-05 18:15:34 | INFO | train | epoch 121 | loss 3.446 | nll_loss 1.264 | ppl 2.4 | wps 27111.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5887 | lr 0.000412148 | gnorm 1.01 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13973
2022-03-05 18:15:34 | INFO | fairseq.trainer | begin training epoch 122
2022-03-05 18:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:16:03 | INFO | train_inner | epoch 122:     13 / 49 loss=3.45, nll_loss=1.268, ppl=2.41, wps=27473.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.017, loss_scale=8, train_wall=200, gb_free=21.6, wall=14002
2022-03-05 18:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:17:27 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.402 | nll_loss 12.5 | ppl 5794.45 | wps 46660.5 | wpb 510.9 | bsz 1 | num_updates 5936 | best_loss 9.173
2022-03-05 18:17:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5936 updates
2022-03-05 18:17:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:17:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 122 @ 5936 updates, score 13.402) (writing took 1.7629951918497682 seconds)
2022-03-05 18:17:29 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-05 18:17:29 | INFO | train | epoch 122 | loss 3.43 | nll_loss 1.246 | ppl 2.37 | wps 27687 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5936 | lr 0.000410443 | gnorm 1.014 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14087
2022-03-05 18:17:29 | INFO | fairseq.trainer | begin training epoch 123
2022-03-05 18:17:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:19:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:19:22 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 13.365 | nll_loss 12.45 | ppl 5593.99 | wps 46601.7 | wpb 510.9 | bsz 1 | num_updates 5985 | best_loss 9.173
2022-03-05 18:19:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5985 updates
2022-03-05 18:19:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:19:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 123 @ 5985 updates, score 13.365) (writing took 1.6601652754470706 seconds)
2022-03-05 18:19:23 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-05 18:19:23 | INFO | train | epoch 123 | loss 3.415 | nll_loss 1.229 | ppl 2.34 | wps 27692.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5985 | lr 0.00040876 | gnorm 0.999 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14202
2022-03-05 18:19:23 | INFO | fairseq.trainer | begin training epoch 124
2022-03-05 18:19:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:19:57 | INFO | train_inner | epoch 124:     15 / 49 loss=3.419, nll_loss=1.234, ppl=2.35, wps=27719.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.007, loss_scale=8, train_wall=198, gb_free=21.6, wall=14236
2022-03-05 18:20:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:21:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:21:16 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.325 | nll_loss 12.404 | ppl 5419.96 | wps 46577.9 | wpb 510.9 | bsz 1 | num_updates 6033 | best_loss 9.173
2022-03-05 18:21:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6033 updates
2022-03-05 18:21:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:21:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:21:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 124 @ 6033 updates, score 13.325) (writing took 1.6651369612663984 seconds)
2022-03-05 18:21:18 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-05 18:21:18 | INFO | train | epoch 124 | loss 3.399 | nll_loss 1.211 | ppl 2.31 | wps 27128.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6033 | lr 0.00040713 | gnorm 0.996 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14317
2022-03-05 18:21:18 | INFO | fairseq.trainer | begin training epoch 125
2022-03-05 18:21:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:23:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:23:11 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.283 | nll_loss 12.341 | ppl 5189.23 | wps 46514.2 | wpb 510.9 | bsz 1 | num_updates 6082 | best_loss 9.173
2022-03-05 18:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6082 updates
2022-03-05 18:23:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:23:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 125 @ 6082 updates, score 13.283) (writing took 1.722485015168786 seconds)
2022-03-05 18:23:13 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-05 18:23:13 | INFO | train | epoch 125 | loss 3.385 | nll_loss 1.196 | ppl 2.29 | wps 27658.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6082 | lr 0.000405487 | gnorm 0.998 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14432
2022-03-05 18:23:13 | INFO | fairseq.trainer | begin training epoch 126
2022-03-05 18:23:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:23:53 | INFO | train_inner | epoch 126:     18 / 49 loss=3.386, nll_loss=1.196, ppl=2.29, wps=27443.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=0.999, loss_scale=8, train_wall=200, gb_free=21.6, wall=14472
2022-03-05 18:25:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:25:06 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.286 | nll_loss 12.361 | ppl 5259.79 | wps 46394.2 | wpb 510.9 | bsz 1 | num_updates 6131 | best_loss 9.173
2022-03-05 18:25:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6131 updates
2022-03-05 18:25:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:25:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:25:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 126 @ 6131 updates, score 13.286) (writing took 1.6492480216547847 seconds)
2022-03-05 18:25:08 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-05 18:25:08 | INFO | train | epoch 126 | loss 3.369 | nll_loss 1.177 | ppl 2.26 | wps 27645.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6131 | lr 0.000403863 | gnorm 0.966 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14547
2022-03-05 18:25:08 | INFO | fairseq.trainer | begin training epoch 127
2022-03-05 18:25:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:26:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:26:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:27:01 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.306 | nll_loss 12.374 | ppl 5308.04 | wps 46733.8 | wpb 510.9 | bsz 1 | num_updates 6179 | best_loss 9.173
2022-03-05 18:27:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6179 updates
2022-03-05 18:27:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:27:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:27:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 127 @ 6179 updates, score 13.306) (writing took 1.6456508580595255 seconds)
2022-03-05 18:27:03 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-05 18:27:03 | INFO | train | epoch 127 | loss 3.357 | nll_loss 1.165 | ppl 2.24 | wps 27145.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6179 | lr 0.000402292 | gnorm 1.013 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14661
2022-03-05 18:27:03 | INFO | fairseq.trainer | begin training epoch 128
2022-03-05 18:27:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:27:50 | INFO | train_inner | epoch 128:     21 / 49 loss=3.357, nll_loss=1.164, ppl=2.24, wps=27457.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=0.976, loss_scale=8, train_wall=200, gb_free=21.6, wall=14708
2022-03-05 18:28:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:28:56 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.383 | nll_loss 12.469 | ppl 5668.68 | wps 46562.3 | wpb 510.9 | bsz 1 | num_updates 6228 | best_loss 9.173
2022-03-05 18:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6228 updates
2022-03-05 18:28:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:28:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:28:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 128 @ 6228 updates, score 13.383) (writing took 1.64959229901433 seconds)
2022-03-05 18:28:57 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-05 18:28:57 | INFO | train | epoch 128 | loss 3.345 | nll_loss 1.151 | ppl 2.22 | wps 27689.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6228 | lr 0.000400706 | gnorm 0.99 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14776
2022-03-05 18:28:57 | INFO | fairseq.trainer | begin training epoch 129
2022-03-05 18:28:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:30:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:30:50 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.355 | nll_loss 12.449 | ppl 5591.19 | wps 46527.4 | wpb 510.9 | bsz 1 | num_updates 6277 | best_loss 9.173
2022-03-05 18:30:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6277 updates
2022-03-05 18:30:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 129 @ 6277 updates, score 13.355) (writing took 1.672082873992622 seconds)
2022-03-05 18:30:52 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-05 18:30:52 | INFO | train | epoch 129 | loss 3.327 | nll_loss 1.131 | ppl 2.19 | wps 27702.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6277 | lr 0.000399139 | gnorm 0.941 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14891
2022-03-05 18:30:52 | INFO | fairseq.trainer | begin training epoch 130
2022-03-05 18:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:31:44 | INFO | train_inner | epoch 130:     23 / 49 loss=3.33, nll_loss=1.134, ppl=2.2, wps=27715.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=0.965, loss_scale=8, train_wall=198, gb_free=21.6, wall=14942
2022-03-05 18:31:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:32:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:32:45 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.263 | nll_loss 12.326 | ppl 5135.58 | wps 46520.5 | wpb 510.9 | bsz 1 | num_updates 6325 | best_loss 9.173
2022-03-05 18:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6325 updates
2022-03-05 18:32:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:32:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 130 @ 6325 updates, score 13.263) (writing took 1.6677794521674514 seconds)
2022-03-05 18:32:47 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-05 18:32:47 | INFO | train | epoch 130 | loss 3.315 | nll_loss 1.118 | ppl 2.17 | wps 27101.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6325 | lr 0.000397621 | gnorm 0.959 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15006
2022-03-05 18:32:47 | INFO | fairseq.trainer | begin training epoch 131
2022-03-05 18:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:34:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:34:40 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.297 | nll_loss 12.381 | ppl 5334.23 | wps 46609.8 | wpb 510.9 | bsz 1 | num_updates 6374 | best_loss 9.173
2022-03-05 18:34:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6374 updates
2022-03-05 18:34:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:34:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:34:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 131 @ 6374 updates, score 13.297) (writing took 1.732532773166895 seconds)
2022-03-05 18:34:42 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-05 18:34:42 | INFO | train | epoch 131 | loss 3.301 | nll_loss 1.102 | ppl 2.15 | wps 27678.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6374 | lr 0.00039609 | gnorm 0.93 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15121
2022-03-05 18:34:42 | INFO | fairseq.trainer | begin training epoch 132
2022-03-05 18:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:35:40 | INFO | train_inner | epoch 132:     26 / 49 loss=3.301, nll_loss=1.102, ppl=2.15, wps=27458.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.934, loss_scale=8, train_wall=200, gb_free=21.6, wall=15179
2022-03-05 18:36:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:36:35 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 13.351 | nll_loss 12.443 | ppl 5569.66 | wps 46492.9 | wpb 510.9 | bsz 1 | num_updates 6423 | best_loss 9.173
2022-03-05 18:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6423 updates
2022-03-05 18:36:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:36:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:36:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 132 @ 6423 updates, score 13.351) (writing took 1.6363788153976202 seconds)
2022-03-05 18:36:37 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-05 18:36:37 | INFO | train | epoch 132 | loss 3.29 | nll_loss 1.091 | ppl 2.13 | wps 27710.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6423 | lr 0.000394576 | gnorm 0.935 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15235
2022-03-05 18:36:37 | INFO | fairseq.trainer | begin training epoch 133
2022-03-05 18:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:38:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:38:30 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 13.326 | nll_loss 12.42 | ppl 5479.58 | wps 46508.6 | wpb 510.9 | bsz 1 | num_updates 6472 | best_loss 9.173
2022-03-05 18:38:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6472 updates
2022-03-05 18:38:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:38:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:38:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 133 @ 6472 updates, score 13.326) (writing took 1.6427121050655842 seconds)
2022-03-05 18:38:31 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-05 18:38:31 | INFO | train | epoch 133 | loss 3.278 | nll_loss 1.077 | ppl 2.11 | wps 27702.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6472 | lr 0.00039308 | gnorm 0.919 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15350
2022-03-05 18:38:31 | INFO | fairseq.trainer | begin training epoch 134
2022-03-05 18:38:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:39:34 | INFO | train_inner | epoch 134:     28 / 49 loss=3.278, nll_loss=1.077, ppl=2.11, wps=27745.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.933, loss_scale=16, train_wall=198, gb_free=21.6, wall=15412
2022-03-05 18:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:40:24 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 13.369 | nll_loss 12.461 | ppl 5639.86 | wps 46629.7 | wpb 510.9 | bsz 1 | num_updates 6521 | best_loss 9.173
2022-03-05 18:40:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6521 updates
2022-03-05 18:40:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:40:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:40:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 134 @ 6521 updates, score 13.369) (writing took 1.6937404489144683 seconds)
2022-03-05 18:40:26 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-05 18:40:26 | INFO | train | epoch 134 | loss 3.265 | nll_loss 1.064 | ppl 2.09 | wps 27698.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6521 | lr 0.0003916 | gnorm 0.919 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15465
2022-03-05 18:40:26 | INFO | fairseq.trainer | begin training epoch 135
2022-03-05 18:40:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:41:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:42:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:42:19 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 13.42 | nll_loss 12.535 | ppl 5935.69 | wps 46454.1 | wpb 510.9 | bsz 1 | num_updates 6569 | best_loss 9.173
2022-03-05 18:42:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6569 updates
2022-03-05 18:42:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:42:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:42:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 135 @ 6569 updates, score 13.42) (writing took 1.6795690637081861 seconds)
2022-03-05 18:42:21 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-05 18:42:21 | INFO | train | epoch 135 | loss 3.255 | nll_loss 1.053 | ppl 2.07 | wps 27144 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6569 | lr 0.000390167 | gnorm 0.933 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15579
2022-03-05 18:42:21 | INFO | fairseq.trainer | begin training epoch 136
2022-03-05 18:42:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:43:30 | INFO | train_inner | epoch 136:     31 / 49 loss=3.253, nll_loss=1.052, ppl=2.07, wps=27464.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.916, loss_scale=8, train_wall=200, gb_free=21.6, wall=15649
2022-03-05 18:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:44:14 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 13.346 | nll_loss 12.441 | ppl 5558.69 | wps 46481 | wpb 510.9 | bsz 1 | num_updates 6618 | best_loss 9.173
2022-03-05 18:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6618 updates
2022-03-05 18:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:44:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 136 @ 6618 updates, score 13.346) (writing took 1.6894016275182366 seconds)
2022-03-05 18:44:15 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-05 18:44:15 | INFO | train | epoch 136 | loss 3.242 | nll_loss 1.04 | ppl 2.06 | wps 27694.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6618 | lr 0.00038872 | gnorm 0.907 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15694
2022-03-05 18:44:15 | INFO | fairseq.trainer | begin training epoch 137
2022-03-05 18:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:46:09 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 13.412 | nll_loss 12.525 | ppl 5892.01 | wps 46359.5 | wpb 510.9 | bsz 1 | num_updates 6667 | best_loss 9.173
2022-03-05 18:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6667 updates
2022-03-05 18:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:46:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 137 @ 6667 updates, score 13.412) (writing took 1.648727223277092 seconds)
2022-03-05 18:46:10 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-05 18:46:10 | INFO | train | epoch 137 | loss 3.232 | nll_loss 1.028 | ppl 2.04 | wps 27676.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6667 | lr 0.000387289 | gnorm 0.899 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15809
2022-03-05 18:46:10 | INFO | fairseq.trainer | begin training epoch 138
2022-03-05 18:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:47:24 | INFO | train_inner | epoch 138:     33 / 49 loss=3.232, nll_loss=1.028, ppl=2.04, wps=27729.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.915, loss_scale=16, train_wall=198, gb_free=21.6, wall=15883
2022-03-05 18:47:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:48:03 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 13.362 | nll_loss 12.452 | ppl 5602.2 | wps 46505.9 | wpb 510.9 | bsz 1 | num_updates 6716 | best_loss 9.173
2022-03-05 18:48:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6716 updates
2022-03-05 18:48:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:48:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:48:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 138 @ 6716 updates, score 13.362) (writing took 1.6450276700779796 seconds)
2022-03-05 18:48:05 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-05 18:48:05 | INFO | train | epoch 138 | loss 3.222 | nll_loss 1.018 | ppl 2.02 | wps 27730.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6716 | lr 0.000385873 | gnorm 0.916 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15924
2022-03-05 18:48:05 | INFO | fairseq.trainer | begin training epoch 139
2022-03-05 18:48:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:49:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:49:58 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 13.357 | nll_loss 12.449 | ppl 5591.05 | wps 46564.2 | wpb 510.9 | bsz 1 | num_updates 6765 | best_loss 9.173
2022-03-05 18:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6765 updates
2022-03-05 18:49:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:50:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:50:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 139 @ 6765 updates, score 13.357) (writing took 1.6582132186740637 seconds)
2022-03-05 18:50:00 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-05 18:50:00 | INFO | train | epoch 139 | loss 3.21 | nll_loss 1.005 | ppl 2.01 | wps 27683.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6765 | lr 0.000384473 | gnorm 0.873 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16038
2022-03-05 18:50:00 | INFO | fairseq.trainer | begin training epoch 140
2022-03-05 18:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:51:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:51:20 | INFO | train_inner | epoch 140:     36 / 49 loss=3.207, nll_loss=1.002, ppl=2, wps=27465, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.878, loss_scale=8, train_wall=200, gb_free=21.6, wall=16119
2022-03-05 18:51:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:51:53 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 13.362 | nll_loss 12.48 | ppl 5712.47 | wps 46351 | wpb 510.9 | bsz 1 | num_updates 6813 | best_loss 9.173
2022-03-05 18:51:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6813 updates
2022-03-05 18:51:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:51:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:51:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 140 @ 6813 updates, score 13.362) (writing took 1.6583804860711098 seconds)
2022-03-05 18:51:54 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-05 18:51:54 | INFO | train | epoch 140 | loss 3.2 | nll_loss 0.993 | ppl 1.99 | wps 27121.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6813 | lr 0.000383116 | gnorm 0.891 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16153
2022-03-05 18:51:54 | INFO | fairseq.trainer | begin training epoch 141
2022-03-05 18:51:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:53:47 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 13.401 | nll_loss 12.509 | ppl 5829.93 | wps 46698.7 | wpb 510.9 | bsz 1 | num_updates 6862 | best_loss 9.173
2022-03-05 18:53:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6862 updates
2022-03-05 18:53:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:53:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:53:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 141 @ 6862 updates, score 13.401) (writing took 1.636558637022972 seconds)
2022-03-05 18:53:49 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-05 18:53:49 | INFO | train | epoch 141 | loss 3.19 | nll_loss 0.985 | ppl 1.98 | wps 27731.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6862 | lr 0.000381746 | gnorm 0.87 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16268
2022-03-05 18:53:49 | INFO | fairseq.trainer | begin training epoch 142
2022-03-05 18:53:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:55:14 | INFO | train_inner | epoch 142:     38 / 49 loss=3.189, nll_loss=0.983, ppl=1.98, wps=27751.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.88, loss_scale=8, train_wall=198, gb_free=21.6, wall=16353
2022-03-05 18:55:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:55:42 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 13.406 | nll_loss 12.517 | ppl 5862.98 | wps 45971.4 | wpb 510.9 | bsz 1 | num_updates 6911 | best_loss 9.173
2022-03-05 18:55:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6911 updates
2022-03-05 18:55:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:55:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:55:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 142 @ 6911 updates, score 13.406) (writing took 1.685696318745613 seconds)
2022-03-05 18:55:44 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-05 18:55:44 | INFO | train | epoch 142 | loss 3.182 | nll_loss 0.976 | ppl 1.97 | wps 27694.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6911 | lr 0.00038039 | gnorm 0.895 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16382
2022-03-05 18:55:44 | INFO | fairseq.trainer | begin training epoch 143
2022-03-05 18:55:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:57:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:57:37 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 13.348 | nll_loss 12.466 | ppl 5658.22 | wps 46516.3 | wpb 510.9 | bsz 1 | num_updates 6960 | best_loss 9.173
2022-03-05 18:57:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6960 updates
2022-03-05 18:57:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:57:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 143 @ 6960 updates, score 13.348) (writing took 1.6904442068189383 seconds)
2022-03-05 18:57:38 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-05 18:57:38 | INFO | train | epoch 143 | loss 3.171 | nll_loss 0.964 | ppl 1.95 | wps 27702.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6960 | lr 0.000379049 | gnorm 0.867 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16497
2022-03-05 18:57:38 | INFO | fairseq.trainer | begin training epoch 144
2022-03-05 18:57:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:59:08 | INFO | train_inner | epoch 144:     40 / 49 loss=3.17, nll_loss=0.963, ppl=1.95, wps=27722.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.88, loss_scale=16, train_wall=198, gb_free=21.6, wall=16587
2022-03-05 18:59:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:59:32 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 13.384 | nll_loss 12.494 | ppl 5768.75 | wps 46393.3 | wpb 510.9 | bsz 1 | num_updates 7009 | best_loss 9.173
2022-03-05 18:59:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7009 updates
2022-03-05 18:59:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:59:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 18:59:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 144 @ 7009 updates, score 13.384) (writing took 1.6295856926590204 seconds)
2022-03-05 18:59:33 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-05 18:59:33 | INFO | train | epoch 144 | loss 3.164 | nll_loss 0.957 | ppl 1.94 | wps 27701.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7009 | lr 0.000377722 | gnorm 0.88 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16612
2022-03-05 18:59:33 | INFO | fairseq.trainer | begin training epoch 145
2022-03-05 18:59:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:01:26 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 13.476 | nll_loss 12.606 | ppl 6233.96 | wps 46259.9 | wpb 510.9 | bsz 1 | num_updates 7058 | best_loss 9.173
2022-03-05 19:01:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7058 updates
2022-03-05 19:01:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:01:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:01:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 145 @ 7058 updates, score 13.476) (writing took 1.6780046597123146 seconds)
2022-03-05 19:01:28 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-05 19:01:28 | INFO | train | epoch 145 | loss 3.153 | nll_loss 0.945 | ppl 1.92 | wps 27681 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7058 | lr 0.000376408 | gnorm 0.854 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 16727
2022-03-05 19:01:28 | INFO | fairseq.trainer | begin training epoch 146
2022-03-05 19:01:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:01:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:03:04 | INFO | train_inner | epoch 146:     43 / 49 loss=3.15, nll_loss=0.942, ppl=1.92, wps=27463.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.849, loss_scale=16, train_wall=200, gb_free=21.6, wall=16823
2022-03-05 19:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:03:21 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 13.506 | nll_loss 12.633 | ppl 6352.88 | wps 46492 | wpb 510.9 | bsz 1 | num_updates 7106 | best_loss 9.173
2022-03-05 19:03:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7106 updates
2022-03-05 19:03:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:03:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:03:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 146 @ 7106 updates, score 13.506) (writing took 1.6598474998027086 seconds)
2022-03-05 19:03:23 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-05 19:03:23 | INFO | train | epoch 146 | loss 3.142 | nll_loss 0.934 | ppl 1.91 | wps 27126 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7106 | lr 0.000375135 | gnorm 0.84 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16841
2022-03-05 19:03:23 | INFO | fairseq.trainer | begin training epoch 147
2022-03-05 19:03:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:05:16 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 13.452 | nll_loss 12.583 | ppl 6133.82 | wps 46515.7 | wpb 510.9 | bsz 1 | num_updates 7155 | best_loss 9.173
2022-03-05 19:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7155 updates
2022-03-05 19:05:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:05:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 147 @ 7155 updates, score 13.452) (writing took 1.6713925059884787 seconds)
2022-03-05 19:05:17 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-05 19:05:17 | INFO | train | epoch 147 | loss 3.137 | nll_loss 0.928 | ppl 1.9 | wps 27704.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7155 | lr 0.000373848 | gnorm 0.833 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16956
2022-03-05 19:05:17 | INFO | fairseq.trainer | begin training epoch 148
2022-03-05 19:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:06:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:07:00 | INFO | train_inner | epoch 148:     46 / 49 loss=3.134, nll_loss=0.926, ppl=1.9, wps=27463.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.839, loss_scale=16, train_wall=200, gb_free=21.6, wall=17059
2022-03-05 19:07:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:07:11 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 13.342 | nll_loss 12.452 | ppl 5604.88 | wps 46575.5 | wpb 510.9 | bsz 1 | num_updates 7203 | best_loss 9.173
2022-03-05 19:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7203 updates
2022-03-05 19:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 148 @ 7203 updates, score 13.342) (writing took 1.6980382520705462 seconds)
2022-03-05 19:07:12 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-05 19:07:12 | INFO | train | epoch 148 | loss 3.128 | nll_loss 0.919 | ppl 1.89 | wps 27101.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7203 | lr 0.0003726 | gnorm 0.844 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17071
2022-03-05 19:07:12 | INFO | fairseq.trainer | begin training epoch 149
2022-03-05 19:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:08:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 19:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:09:05 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 13.427 | nll_loss 12.555 | ppl 6017.62 | wps 46635.2 | wpb 510.9 | bsz 1 | num_updates 7251 | best_loss 9.173
2022-03-05 19:09:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7251 updates
2022-03-05 19:09:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 149 @ 7251 updates, score 13.427) (writing took 1.7069575693458319 seconds)
2022-03-05 19:09:07 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-05 19:09:07 | INFO | train | epoch 149 | loss 3.119 | nll_loss 0.91 | ppl 1.88 | wps 27128 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7251 | lr 0.000371365 | gnorm 0.849 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 17186
2022-03-05 19:09:07 | INFO | fairseq.trainer | begin training epoch 150
2022-03-05 19:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:10:55 | INFO | train_inner | epoch 150:     49 / 49 loss=3.117, nll_loss=0.908, ppl=1.88, wps=27449.1, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.862, loss_scale=8, train_wall=199, gb_free=21.6, wall=17294
2022-03-05 19:10:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:11:00 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 13.386 | nll_loss 12.507 | ppl 5821.99 | wps 46415.9 | wpb 510.9 | bsz 1 | num_updates 7300 | best_loss 9.173
2022-03-05 19:11:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7300 updates
2022-03-05 19:11:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:11:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:11:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 150 @ 7300 updates, score 13.386) (writing took 1.6754055814817548 seconds)
2022-03-05 19:11:02 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-05 19:11:02 | INFO | train | epoch 150 | loss 3.114 | nll_loss 0.905 | ppl 1.87 | wps 27685.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7300 | lr 0.000370117 | gnorm 0.871 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 17301
2022-03-05 19:11:02 | INFO | fairseq.trainer | begin training epoch 151
2022-03-05 19:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:12:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:12:55 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 13.398 | nll_loss 12.514 | ppl 5848.59 | wps 46519.9 | wpb 510.9 | bsz 1 | num_updates 7349 | best_loss 9.173
2022-03-05 19:12:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7349 updates
2022-03-05 19:12:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:12:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:12:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 151 @ 7349 updates, score 13.398) (writing took 1.6198211023584008 seconds)
2022-03-05 19:12:56 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-05 19:12:56 | INFO | train | epoch 151 | loss 3.101 | nll_loss 0.892 | ppl 1.86 | wps 27732.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7349 | lr 0.000368881 | gnorm 0.827 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 17415
2022-03-05 19:12:56 | INFO | fairseq.trainer | begin training epoch 152
2022-03-05 19:12:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:14:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:14:50 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 13.371 | nll_loss 12.499 | ppl 5789.04 | wps 46606.9 | wpb 510.9 | bsz 1 | num_updates 7398 | best_loss 9.173
2022-03-05 19:14:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7398 updates
2022-03-05 19:14:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:14:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:14:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 152 @ 7398 updates, score 13.371) (writing took 1.698687951080501 seconds)
2022-03-05 19:14:51 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-05 19:14:51 | INFO | train | epoch 152 | loss 3.094 | nll_loss 0.884 | ppl 1.85 | wps 27661.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7398 | lr 0.000367657 | gnorm 0.819 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17530
2022-03-05 19:14:51 | INFO | fairseq.trainer | begin training epoch 153
2022-03-05 19:14:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:14:56 | INFO | train_inner | epoch 153:      2 / 49 loss=3.097, nll_loss=0.887, ppl=1.85, wps=26976.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.824, loss_scale=16, train_wall=198, gb_free=21.6, wall=17535
2022-03-05 19:16:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:16:44 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 13.39 | nll_loss 12.53 | ppl 5916.1 | wps 46607.9 | wpb 510.9 | bsz 1 | num_updates 7447 | best_loss 9.173
2022-03-05 19:16:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7447 updates
2022-03-05 19:16:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:16:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:16:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 153 @ 7447 updates, score 13.39) (writing took 1.6416618498042226 seconds)
2022-03-05 19:16:46 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-05 19:16:46 | INFO | train | epoch 153 | loss 3.089 | nll_loss 0.88 | ppl 1.84 | wps 27697.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7447 | lr 0.000366445 | gnorm 0.821 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17645
2022-03-05 19:16:46 | INFO | fairseq.trainer | begin training epoch 154
2022-03-05 19:16:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:18:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:18:39 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 13.485 | nll_loss 12.633 | ppl 6353.88 | wps 46561.3 | wpb 510.9 | bsz 1 | num_updates 7496 | best_loss 9.173
2022-03-05 19:18:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7496 updates
2022-03-05 19:18:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:18:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:18:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 154 @ 7496 updates, score 13.485) (writing took 1.7012154860422015 seconds)
2022-03-05 19:18:41 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-05 19:18:41 | INFO | train | epoch 154 | loss 3.082 | nll_loss 0.873 | ppl 1.83 | wps 27694.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7496 | lr 0.000365246 | gnorm 0.826 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17760
2022-03-05 19:18:41 | INFO | fairseq.trainer | begin training epoch 155
2022-03-05 19:18:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:18:50 | INFO | train_inner | epoch 155:      4 / 49 loss=3.085, nll_loss=0.875, ppl=1.83, wps=27726, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.822, loss_scale=16, train_wall=198, gb_free=21.6, wall=17769
2022-03-05 19:19:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:20:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:20:34 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 13.463 | nll_loss 12.601 | ppl 6213.75 | wps 46612.5 | wpb 510.9 | bsz 1 | num_updates 7544 | best_loss 9.173
2022-03-05 19:20:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7544 updates
2022-03-05 19:20:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:20:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:20:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 155 @ 7544 updates, score 13.463) (writing took 1.6715069599449635 seconds)
2022-03-05 19:20:36 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-05 19:20:36 | INFO | train | epoch 155 | loss 3.074 | nll_loss 0.864 | ppl 1.82 | wps 27139.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7544 | lr 0.000364082 | gnorm 0.817 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17874
2022-03-05 19:20:36 | INFO | fairseq.trainer | begin training epoch 156
2022-03-05 19:20:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:22:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:22:29 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 13.356 | nll_loss 12.488 | ppl 5745.45 | wps 46592.9 | wpb 510.9 | bsz 1 | num_updates 7593 | best_loss 9.173
2022-03-05 19:22:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7593 updates
2022-03-05 19:22:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:22:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:22:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 156 @ 7593 updates, score 13.356) (writing took 1.6609590258449316 seconds)
2022-03-05 19:22:30 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-05 19:22:30 | INFO | train | epoch 156 | loss 3.069 | nll_loss 0.859 | ppl 1.81 | wps 27706.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7593 | lr 0.000362905 | gnorm 0.81 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17989
2022-03-05 19:22:30 | INFO | fairseq.trainer | begin training epoch 157
2022-03-05 19:22:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:22:46 | INFO | train_inner | epoch 157:      7 / 49 loss=3.07, nll_loss=0.86, ppl=1.81, wps=27478.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.813, loss_scale=16, train_wall=200, gb_free=21.6, wall=18005
2022-03-05 19:24:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:24:23 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 13.396 | nll_loss 12.537 | ppl 5944.53 | wps 46740.3 | wpb 510.9 | bsz 1 | num_updates 7642 | best_loss 9.173
2022-03-05 19:24:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7642 updates
2022-03-05 19:24:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:24:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:24:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 157 @ 7642 updates, score 13.396) (writing took 1.6515159895643592 seconds)
2022-03-05 19:24:25 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-05 19:24:25 | INFO | train | epoch 157 | loss 3.06 | nll_loss 0.85 | ppl 1.8 | wps 27677.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7642 | lr 0.00036174 | gnorm 0.796 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18104
2022-03-05 19:24:25 | INFO | fairseq.trainer | begin training epoch 158
2022-03-05 19:24:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:25:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:26:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:26:18 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 13.361 | nll_loss 12.49 | ppl 5751.94 | wps 46678.5 | wpb 510.9 | bsz 1 | num_updates 7690 | best_loss 9.173
2022-03-05 19:26:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7690 updates
2022-03-05 19:26:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:26:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:26:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 158 @ 7690 updates, score 13.361) (writing took 1.6275542955845594 seconds)
2022-03-05 19:26:20 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-05 19:26:20 | INFO | train | epoch 158 | loss 3.054 | nll_loss 0.845 | ppl 1.8 | wps 27158.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7690 | lr 0.000360609 | gnorm 0.807 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18218
2022-03-05 19:26:20 | INFO | fairseq.trainer | begin training epoch 159
2022-03-05 19:26:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:26:42 | INFO | train_inner | epoch 159:     10 / 49 loss=3.056, nll_loss=0.846, ppl=1.8, wps=27472.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.802, loss_scale=16, train_wall=200, gb_free=21.6, wall=18241
2022-03-05 19:28:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:28:13 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 13.407 | nll_loss 12.549 | ppl 5994.53 | wps 46632.4 | wpb 510.9 | bsz 1 | num_updates 7739 | best_loss 9.173
2022-03-05 19:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7739 updates
2022-03-05 19:28:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:28:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:28:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 159 @ 7739 updates, score 13.407) (writing took 1.6424062363803387 seconds)
2022-03-05 19:28:14 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-05 19:28:14 | INFO | train | epoch 159 | loss 3.047 | nll_loss 0.838 | ppl 1.79 | wps 27727 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7739 | lr 0.000359466 | gnorm 0.81 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18333
2022-03-05 19:28:14 | INFO | fairseq.trainer | begin training epoch 160
2022-03-05 19:28:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:30:07 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 13.401 | nll_loss 12.539 | ppl 5950.62 | wps 46557.8 | wpb 510.9 | bsz 1 | num_updates 7788 | best_loss 9.173
2022-03-05 19:30:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7788 updates
2022-03-05 19:30:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:30:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:30:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 160 @ 7788 updates, score 13.401) (writing took 1.6712056528776884 seconds)
2022-03-05 19:30:09 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-05 19:30:09 | INFO | train | epoch 160 | loss 3.039 | nll_loss 0.829 | ppl 1.78 | wps 27707.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7788 | lr 0.000358333 | gnorm 0.774 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18448
2022-03-05 19:30:09 | INFO | fairseq.trainer | begin training epoch 161
2022-03-05 19:30:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:30:36 | INFO | train_inner | epoch 161:     12 / 49 loss=3.042, nll_loss=0.832, ppl=1.78, wps=27753.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.789, loss_scale=16, train_wall=198, gb_free=21.6, wall=18475
2022-03-05 19:31:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:32:02 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 13.347 | nll_loss 12.49 | ppl 5752.44 | wps 46588.4 | wpb 510.9 | bsz 1 | num_updates 7836 | best_loss 9.173
2022-03-05 19:32:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7836 updates
2022-03-05 19:32:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:32:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:32:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 161 @ 7836 updates, score 13.347) (writing took 1.6467355135828257 seconds)
2022-03-05 19:32:04 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-05 19:32:04 | INFO | train | epoch 161 | loss 3.033 | nll_loss 0.824 | ppl 1.77 | wps 27132.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7836 | lr 0.000357234 | gnorm 0.782 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18562
2022-03-05 19:32:04 | INFO | fairseq.trainer | begin training epoch 162
2022-03-05 19:32:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:33:57 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 13.392 | nll_loss 12.541 | ppl 5961.64 | wps 46669.4 | wpb 510.9 | bsz 1 | num_updates 7885 | best_loss 9.173
2022-03-05 19:33:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7885 updates
2022-03-05 19:33:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:33:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:33:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 162 @ 7885 updates, score 13.392) (writing took 1.6424695355817676 seconds)
2022-03-05 19:33:58 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-05 19:33:58 | INFO | train | epoch 162 | loss 3.029 | nll_loss 0.819 | ppl 1.76 | wps 27709.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7885 | lr 0.000356122 | gnorm 0.793 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18677
2022-03-05 19:33:58 | INFO | fairseq.trainer | begin training epoch 163
2022-03-05 19:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:34:32 | INFO | train_inner | epoch 163:     15 / 49 loss=3.029, nll_loss=0.819, ppl=1.76, wps=27473, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.786, loss_scale=16, train_wall=200, gb_free=21.6, wall=18711
2022-03-05 19:35:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:35:51 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 13.349 | nll_loss 12.487 | ppl 5739 | wps 46673.5 | wpb 510.9 | bsz 1 | num_updates 7934 | best_loss 9.173
2022-03-05 19:35:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7934 updates
2022-03-05 19:35:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:35:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:35:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 163 @ 7934 updates, score 13.349) (writing took 1.6199853736907244 seconds)
2022-03-05 19:35:53 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-05 19:35:53 | INFO | train | epoch 163 | loss 3.022 | nll_loss 0.812 | ppl 1.76 | wps 27711.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7934 | lr 0.000355021 | gnorm 0.773 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18792
2022-03-05 19:35:53 | INFO | fairseq.trainer | begin training epoch 164
2022-03-05 19:35:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:36:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:37:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:37:46 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 13.444 | nll_loss 12.598 | ppl 6197.71 | wps 46484.9 | wpb 510.9 | bsz 1 | num_updates 7982 | best_loss 9.173
2022-03-05 19:37:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7982 updates
2022-03-05 19:37:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:37:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:37:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 164 @ 7982 updates, score 13.444) (writing took 1.6878836136311293 seconds)
2022-03-05 19:37:48 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-05 19:37:48 | INFO | train | epoch 164 | loss 3.017 | nll_loss 0.808 | ppl 1.75 | wps 27100.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7982 | lr 0.000353952 | gnorm 0.794 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18907
2022-03-05 19:37:48 | INFO | fairseq.trainer | begin training epoch 165
2022-03-05 19:37:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:38:28 | INFO | train_inner | epoch 165:     18 / 49 loss=3.017, nll_loss=0.807, ppl=1.75, wps=27460.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.782, loss_scale=16, train_wall=200, gb_free=21.6, wall=18947
2022-03-05 19:39:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:39:41 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 13.403 | nll_loss 12.557 | ppl 6026.1 | wps 46537.7 | wpb 510.9 | bsz 1 | num_updates 8031 | best_loss 9.173
2022-03-05 19:39:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8031 updates
2022-03-05 19:39:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:39:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:39:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 165 @ 8031 updates, score 13.403) (writing took 1.6305472813546658 seconds)
2022-03-05 19:39:43 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-05 19:39:43 | INFO | train | epoch 165 | loss 3.01 | nll_loss 0.8 | ppl 1.74 | wps 27710.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8031 | lr 0.00035287 | gnorm 0.76 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19021
2022-03-05 19:39:43 | INFO | fairseq.trainer | begin training epoch 166
2022-03-05 19:39:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:41:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:41:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:41:36 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 13.384 | nll_loss 12.525 | ppl 5895.6 | wps 46512.1 | wpb 510.9 | bsz 1 | num_updates 8079 | best_loss 9.173
2022-03-05 19:41:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8079 updates
2022-03-05 19:41:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:41:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 166 @ 8079 updates, score 13.384) (writing took 1.6566522000357509 seconds)
2022-03-05 19:41:37 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-05 19:41:37 | INFO | train | epoch 166 | loss 3.004 | nll_loss 0.795 | ppl 1.74 | wps 27132.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8079 | lr 0.000351821 | gnorm 0.781 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19136
2022-03-05 19:41:37 | INFO | fairseq.trainer | begin training epoch 167
2022-03-05 19:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:42:24 | INFO | train_inner | epoch 167:     21 / 49 loss=3.005, nll_loss=0.796, ppl=1.74, wps=27469.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.768, loss_scale=16, train_wall=200, gb_free=21.6, wall=19183
2022-03-05 19:43:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:43:30 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 13.433 | nll_loss 12.593 | ppl 6176.9 | wps 46559.7 | wpb 510.9 | bsz 1 | num_updates 8128 | best_loss 9.173
2022-03-05 19:43:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8128 updates
2022-03-05 19:43:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:43:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:43:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 167 @ 8128 updates, score 13.433) (writing took 1.6371472561731935 seconds)
2022-03-05 19:43:32 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-05 19:43:32 | INFO | train | epoch 167 | loss 3.001 | nll_loss 0.792 | ppl 1.73 | wps 27693.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8128 | lr 0.000350758 | gnorm 0.772 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19251
2022-03-05 19:43:32 | INFO | fairseq.trainer | begin training epoch 168
2022-03-05 19:43:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:45:25 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 13.375 | nll_loss 12.523 | ppl 5885.12 | wps 46554.5 | wpb 510.9 | bsz 1 | num_updates 8177 | best_loss 9.173
2022-03-05 19:45:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8177 updates
2022-03-05 19:45:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:45:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 168 @ 8177 updates, score 13.375) (writing took 1.675323510542512 seconds)
2022-03-05 19:45:27 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-05 19:45:27 | INFO | train | epoch 168 | loss 2.994 | nll_loss 0.785 | ppl 1.72 | wps 27705.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8177 | lr 0.000349706 | gnorm 0.765 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19365
2022-03-05 19:45:27 | INFO | fairseq.trainer | begin training epoch 169
2022-03-05 19:45:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:46:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:46:20 | INFO | train_inner | epoch 169:     24 / 49 loss=2.995, nll_loss=0.786, ppl=1.72, wps=27480.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.761, loss_scale=16, train_wall=200, gb_free=21.6, wall=19419
2022-03-05 19:47:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:47:20 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 13.435 | nll_loss 12.597 | ppl 6195.63 | wps 46493.4 | wpb 510.9 | bsz 1 | num_updates 8225 | best_loss 9.173
2022-03-05 19:47:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8225 updates
2022-03-05 19:47:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:47:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:47:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 169 @ 8225 updates, score 13.435) (writing took 1.6687644375488162 seconds)
2022-03-05 19:47:22 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-05 19:47:22 | INFO | train | epoch 169 | loss 2.986 | nll_loss 0.777 | ppl 1.71 | wps 27127.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8225 | lr 0.000348684 | gnorm 0.742 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19480
2022-03-05 19:47:22 | INFO | fairseq.trainer | begin training epoch 170
2022-03-05 19:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:49:15 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 13.473 | nll_loss 12.638 | ppl 6376.02 | wps 46694.2 | wpb 510.9 | bsz 1 | num_updates 8274 | best_loss 9.173
2022-03-05 19:49:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8274 updates
2022-03-05 19:49:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:49:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:49:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 170 @ 8274 updates, score 13.473) (writing took 1.6350986985489726 seconds)
2022-03-05 19:49:16 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-05 19:49:16 | INFO | train | epoch 170 | loss 2.984 | nll_loss 0.776 | ppl 1.71 | wps 27714.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8274 | lr 0.00034765 | gnorm 0.768 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19595
2022-03-05 19:49:16 | INFO | fairseq.trainer | begin training epoch 171
2022-03-05 19:49:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:50:14 | INFO | train_inner | epoch 171:     26 / 49 loss=2.984, nll_loss=0.775, ppl=1.71, wps=27724.3, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.761, loss_scale=16, train_wall=198, gb_free=21.6, wall=19653
2022-03-05 19:51:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:51:09 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 13.477 | nll_loss 12.644 | ppl 6399.69 | wps 46652.8 | wpb 510.9 | bsz 1 | num_updates 8323 | best_loss 9.173
2022-03-05 19:51:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8323 updates
2022-03-05 19:51:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:51:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:51:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 171 @ 8323 updates, score 13.477) (writing took 1.679356986656785 seconds)
2022-03-05 19:51:11 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-05 19:51:11 | INFO | train | epoch 171 | loss 2.978 | nll_loss 0.77 | ppl 1.71 | wps 27680.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8323 | lr 0.000346625 | gnorm 0.756 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19710
2022-03-05 19:51:11 | INFO | fairseq.trainer | begin training epoch 172
2022-03-05 19:51:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:52:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:53:04 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 13.403 | nll_loss 12.563 | ppl 6050.99 | wps 46577.4 | wpb 510.9 | bsz 1 | num_updates 8372 | best_loss 9.173
2022-03-05 19:53:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8372 updates
2022-03-05 19:53:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:53:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:53:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 172 @ 8372 updates, score 13.403) (writing took 1.6980650387704372 seconds)
2022-03-05 19:53:06 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-05 19:53:06 | INFO | train | epoch 172 | loss 2.972 | nll_loss 0.764 | ppl 1.7 | wps 27678.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8372 | lr 0.000345609 | gnorm 0.737 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 19825
2022-03-05 19:53:06 | INFO | fairseq.trainer | begin training epoch 173
2022-03-05 19:53:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:53:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:54:11 | INFO | train_inner | epoch 173:     29 / 49 loss=2.972, nll_loss=0.764, ppl=1.7, wps=27465.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.748, loss_scale=16, train_wall=200, gb_free=21.6, wall=19889
2022-03-05 19:54:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:54:59 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 13.563 | nll_loss 12.744 | ppl 6857.83 | wps 46513.7 | wpb 510.9 | bsz 1 | num_updates 8420 | best_loss 9.173
2022-03-05 19:54:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8420 updates
2022-03-05 19:54:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:55:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:55:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 173 @ 8420 updates, score 13.563) (writing took 1.653612768277526 seconds)
2022-03-05 19:55:00 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-05 19:55:00 | INFO | train | epoch 173 | loss 2.969 | nll_loss 0.761 | ppl 1.69 | wps 27145.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8420 | lr 0.000344623 | gnorm 0.769 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19939
2022-03-05 19:55:01 | INFO | fairseq.trainer | begin training epoch 174
2022-03-05 19:55:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:56:53 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 13.414 | nll_loss 12.572 | ppl 6088.96 | wps 46645.2 | wpb 510.9 | bsz 1 | num_updates 8469 | best_loss 9.173
2022-03-05 19:56:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8469 updates
2022-03-05 19:56:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:56:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:56:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 174 @ 8469 updates, score 13.414) (writing took 1.6553034177049994 seconds)
2022-03-05 19:56:55 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-05 19:56:55 | INFO | train | epoch 174 | loss 2.963 | nll_loss 0.755 | ppl 1.69 | wps 27725.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8469 | lr 0.000343624 | gnorm 0.734 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20054
2022-03-05 19:56:55 | INFO | fairseq.trainer | begin training epoch 175
2022-03-05 19:56:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:58:04 | INFO | train_inner | epoch 175:     31 / 49 loss=2.961, nll_loss=0.753, ppl=1.69, wps=27744.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.738, loss_scale=32, train_wall=198, gb_free=21.6, wall=20123
2022-03-05 19:58:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:58:48 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 13.462 | nll_loss 12.637 | ppl 6367.52 | wps 46694.9 | wpb 510.9 | bsz 1 | num_updates 8517 | best_loss 9.173
2022-03-05 19:58:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8517 updates
2022-03-05 19:58:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:58:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 19:58:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 175 @ 8517 updates, score 13.462) (writing took 1.703556327149272 seconds)
2022-03-05 19:58:50 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-05 19:58:50 | INFO | train | epoch 175 | loss 2.956 | nll_loss 0.747 | ppl 1.68 | wps 27130 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8517 | lr 0.000342655 | gnorm 0.735 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20169
2022-03-05 19:58:50 | INFO | fairseq.trainer | begin training epoch 176
2022-03-05 19:58:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:00:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:00:43 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 13.502 | nll_loss 12.678 | ppl 6553.64 | wps 46589.3 | wpb 510.9 | bsz 1 | num_updates 8566 | best_loss 9.173
2022-03-05 20:00:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8566 updates
2022-03-05 20:00:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:00:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:00:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 176 @ 8566 updates, score 13.502) (writing took 1.6839459436014295 seconds)
2022-03-05 20:00:45 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-05 20:00:45 | INFO | train | epoch 176 | loss 2.952 | nll_loss 0.745 | ppl 1.68 | wps 27672.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8566 | lr 0.000341673 | gnorm 0.724 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20283
2022-03-05 20:00:45 | INFO | fairseq.trainer | begin training epoch 177
2022-03-05 20:00:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:02:01 | INFO | train_inner | epoch 177:     34 / 49 loss=2.952, nll_loss=0.745, ppl=1.68, wps=27451.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.731, loss_scale=16, train_wall=200, gb_free=21.6, wall=20359
2022-03-05 20:02:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:02:38 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 13.468 | nll_loss 12.645 | ppl 6403.27 | wps 46460.6 | wpb 510.9 | bsz 1 | num_updates 8615 | best_loss 9.173
2022-03-05 20:02:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8615 updates
2022-03-05 20:02:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:02:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:02:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 177 @ 8615 updates, score 13.468) (writing took 1.6578431110829115 seconds)
2022-03-05 20:02:40 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-05 20:02:40 | INFO | train | epoch 177 | loss 2.949 | nll_loss 0.742 | ppl 1.67 | wps 27675.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8615 | lr 0.0003407 | gnorm 0.728 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20398
2022-03-05 20:02:40 | INFO | fairseq.trainer | begin training epoch 178
2022-03-05 20:02:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:03:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:04:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:04:33 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 13.494 | nll_loss 12.671 | ppl 6522.22 | wps 46667 | wpb 510.9 | bsz 1 | num_updates 8663 | best_loss 9.173
2022-03-05 20:04:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8663 updates
2022-03-05 20:04:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:04:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:04:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 178 @ 8663 updates, score 13.494) (writing took 1.6524005746468902 seconds)
2022-03-05 20:04:34 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-05 20:04:34 | INFO | train | epoch 178 | loss 2.941 | nll_loss 0.734 | ppl 1.66 | wps 27133 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8663 | lr 0.000339755 | gnorm 0.72 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20513
2022-03-05 20:04:34 | INFO | fairseq.trainer | begin training epoch 179
2022-03-05 20:04:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:05:57 | INFO | train_inner | epoch 179:     37 / 49 loss=2.942, nll_loss=0.735, ppl=1.66, wps=27467.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.722, loss_scale=16, train_wall=200, gb_free=21.6, wall=20596
2022-03-05 20:06:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:06:27 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 13.479 | nll_loss 12.653 | ppl 6442.64 | wps 46616.7 | wpb 510.9 | bsz 1 | num_updates 8712 | best_loss 9.173
2022-03-05 20:06:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8712 updates
2022-03-05 20:06:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:06:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:06:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 179 @ 8712 updates, score 13.479) (writing took 1.6507797185331583 seconds)
2022-03-05 20:06:29 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-05 20:06:29 | INFO | train | epoch 179 | loss 2.94 | nll_loss 0.733 | ppl 1.66 | wps 27703.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8712 | lr 0.000338798 | gnorm 0.724 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20628
2022-03-05 20:06:29 | INFO | fairseq.trainer | begin training epoch 180
2022-03-05 20:06:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:08:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:08:22 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 13.461 | nll_loss 12.63 | ppl 6339.11 | wps 46695.9 | wpb 510.9 | bsz 1 | num_updates 8761 | best_loss 9.173
2022-03-05 20:08:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8761 updates
2022-03-05 20:08:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:08:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:08:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 180 @ 8761 updates, score 13.461) (writing took 1.725784637965262 seconds)
2022-03-05 20:08:24 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-05 20:08:24 | INFO | train | epoch 180 | loss 2.935 | nll_loss 0.729 | ppl 1.66 | wps 27678.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8761 | lr 0.000337849 | gnorm 0.73 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20742
2022-03-05 20:08:24 | INFO | fairseq.trainer | begin training epoch 181
2022-03-05 20:08:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:09:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:09:53 | INFO | train_inner | epoch 181:     40 / 49 loss=2.933, nll_loss=0.727, ppl=1.66, wps=27472.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.723, loss_scale=16, train_wall=200, gb_free=21.6, wall=20832
2022-03-05 20:10:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:10:17 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 13.439 | nll_loss 12.611 | ppl 6255.81 | wps 46653 | wpb 510.9 | bsz 1 | num_updates 8809 | best_loss 9.173
2022-03-05 20:10:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8809 updates
2022-03-05 20:10:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:10:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:10:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 181 @ 8809 updates, score 13.439) (writing took 1.67849750071764 seconds)
2022-03-05 20:10:18 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-05 20:10:18 | INFO | train | epoch 181 | loss 2.928 | nll_loss 0.721 | ppl 1.65 | wps 27143.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8809 | lr 0.000336928 | gnorm 0.704 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20857
2022-03-05 20:10:18 | INFO | fairseq.trainer | begin training epoch 182
2022-03-05 20:10:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:12:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:12:12 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 13.418 | nll_loss 12.584 | ppl 6138.1 | wps 44357.6 | wpb 510.9 | bsz 1 | num_updates 8858 | best_loss 9.173
2022-03-05 20:12:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8858 updates
2022-03-05 20:12:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:12:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:12:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 182 @ 8858 updates, score 13.418) (writing took 1.6531384522095323 seconds)
2022-03-05 20:12:13 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-05 20:12:13 | INFO | train | epoch 182 | loss 2.926 | nll_loss 0.72 | ppl 1.65 | wps 27643.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8858 | lr 0.000335994 | gnorm 0.721 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20972
2022-03-05 20:12:13 | INFO | fairseq.trainer | begin training epoch 183
2022-03-05 20:12:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:13:47 | INFO | train_inner | epoch 183:     42 / 49 loss=2.924, nll_loss=0.718, ppl=1.64, wps=27695, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.716, loss_scale=16, train_wall=198, gb_free=21.6, wall=21066
2022-03-05 20:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:14:07 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 13.458 | nll_loss 12.629 | ppl 6332.53 | wps 46544.3 | wpb 510.9 | bsz 1 | num_updates 8907 | best_loss 9.173
2022-03-05 20:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8907 updates
2022-03-05 20:14:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:14:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:14:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 183 @ 8907 updates, score 13.458) (writing took 1.6735218279063702 seconds)
2022-03-05 20:14:08 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-05 20:14:08 | INFO | train | epoch 183 | loss 2.922 | nll_loss 0.716 | ppl 1.64 | wps 27684.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8907 | lr 0.000335069 | gnorm 0.715 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21087
2022-03-05 20:14:08 | INFO | fairseq.trainer | begin training epoch 184
2022-03-05 20:14:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:14:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:15:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:16:01 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 13.382 | nll_loss 12.55 | ppl 5996.25 | wps 46582.6 | wpb 510.9 | bsz 1 | num_updates 8955 | best_loss 9.173
2022-03-05 20:16:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8955 updates
2022-03-05 20:16:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:16:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:16:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 184 @ 8955 updates, score 13.382) (writing took 1.6593244904652238 seconds)
2022-03-05 20:16:03 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-05 20:16:03 | INFO | train | epoch 184 | loss 2.917 | nll_loss 0.711 | ppl 1.64 | wps 27157.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8955 | lr 0.00033417 | gnorm 0.713 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21201
2022-03-05 20:16:03 | INFO | fairseq.trainer | begin training epoch 185
2022-03-05 20:16:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:17:43 | INFO | train_inner | epoch 185:     45 / 49 loss=2.916, nll_loss=0.711, ppl=1.64, wps=27474.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.709, loss_scale=16, train_wall=200, gb_free=21.6, wall=21302
2022-03-05 20:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:17:56 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 13.453 | nll_loss 12.636 | ppl 6365.7 | wps 46813.7 | wpb 510.9 | bsz 1 | num_updates 9004 | best_loss 9.173
2022-03-05 20:17:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9004 updates
2022-03-05 20:17:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:17:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:17:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 185 @ 9004 updates, score 13.453) (writing took 1.641270018182695 seconds)
2022-03-05 20:17:58 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-05 20:17:58 | INFO | train | epoch 185 | loss 2.913 | nll_loss 0.707 | ppl 1.63 | wps 27697.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9004 | lr 0.000333259 | gnorm 0.702 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21316
2022-03-05 20:17:58 | INFO | fairseq.trainer | begin training epoch 186
2022-03-05 20:17:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:19:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:19:51 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 13.437 | nll_loss 12.618 | ppl 6285.5 | wps 46759 | wpb 510.9 | bsz 1 | num_updates 9053 | best_loss 9.173
2022-03-05 20:19:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9053 updates
2022-03-05 20:19:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 186 @ 9053 updates, score 13.437) (writing took 1.6752452133223414 seconds)
2022-03-05 20:19:52 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-05 20:19:52 | INFO | train | epoch 186 | loss 2.909 | nll_loss 0.704 | ppl 1.63 | wps 27722 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9053 | lr 0.000332356 | gnorm 0.687 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21431
2022-03-05 20:19:52 | INFO | fairseq.trainer | begin training epoch 187
2022-03-05 20:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:20:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:21:39 | INFO | train_inner | epoch 187:     48 / 49 loss=2.908, nll_loss=0.703, ppl=1.63, wps=27497, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9100, lr=0.000331497, gnorm=0.697, loss_scale=16, train_wall=200, gb_free=21.6, wall=21538
2022-03-05 20:21:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:21:45 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 13.411 | nll_loss 12.59 | ppl 6167.34 | wps 46589.9 | wpb 510.9 | bsz 1 | num_updates 9101 | best_loss 9.173
2022-03-05 20:21:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9101 updates
2022-03-05 20:21:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:21:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 187 @ 9101 updates, score 13.411) (writing took 1.6502710729837418 seconds)
2022-03-05 20:21:47 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-05 20:21:47 | INFO | train | epoch 187 | loss 2.905 | nll_loss 0.7 | ppl 1.62 | wps 27152.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9101 | lr 0.000331479 | gnorm 0.707 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21546
2022-03-05 20:21:47 | INFO | fairseq.trainer | begin training epoch 188
2022-03-05 20:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:23:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:23:40 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 13.45 | nll_loss 12.625 | ppl 6316.46 | wps 46388.8 | wpb 510.9 | bsz 1 | num_updates 9150 | best_loss 9.173
2022-03-05 20:23:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9150 updates
2022-03-05 20:23:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:23:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 188 @ 9150 updates, score 13.45) (writing took 1.68708033580333 seconds)
2022-03-05 20:23:42 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-05 20:23:42 | INFO | train | epoch 188 | loss 2.902 | nll_loss 0.697 | ppl 1.62 | wps 27681.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9150 | lr 0.00033059 | gnorm 0.695 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21660
2022-03-05 20:23:42 | INFO | fairseq.trainer | begin training epoch 189
2022-03-05 20:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:25:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:25:35 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 13.486 | nll_loss 12.676 | ppl 6546.18 | wps 46639.8 | wpb 510.9 | bsz 1 | num_updates 9199 | best_loss 9.173
2022-03-05 20:25:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9199 updates
2022-03-05 20:25:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:25:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:25:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 189 @ 9199 updates, score 13.486) (writing took 1.6564244711771607 seconds)
2022-03-05 20:25:36 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-05 20:25:36 | INFO | train | epoch 189 | loss 2.898 | nll_loss 0.694 | ppl 1.62 | wps 27685 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9199 | lr 0.000329708 | gnorm 0.702 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 21775
2022-03-05 20:25:36 | INFO | fairseq.trainer | begin training epoch 190
2022-03-05 20:25:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:25:39 | INFO | train_inner | epoch 190:      1 / 49 loss=2.9, nll_loss=0.695, ppl=1.62, wps=26956.6, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=9200, lr=0.00032969, gnorm=0.7, loss_scale=32, train_wall=197, gb_free=21.6, wall=21777
2022-03-05 20:27:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:27:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:27:29 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 13.43 | nll_loss 12.615 | ppl 6271.32 | wps 46582 | wpb 510.9 | bsz 1 | num_updates 9247 | best_loss 9.173
2022-03-05 20:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9247 updates
2022-03-05 20:27:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:27:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:27:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 190 @ 9247 updates, score 13.43) (writing took 1.6579695232212543 seconds)
2022-03-05 20:27:31 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-05 20:27:31 | INFO | train | epoch 190 | loss 2.894 | nll_loss 0.69 | ppl 1.61 | wps 27139.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9247 | lr 0.000328851 | gnorm 0.692 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21890
2022-03-05 20:27:31 | INFO | fairseq.trainer | begin training epoch 191
2022-03-05 20:27:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:29:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:29:24 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 13.405 | nll_loss 12.589 | ppl 6161.73 | wps 46619.8 | wpb 510.9 | bsz 1 | num_updates 9296 | best_loss 9.173
2022-03-05 20:29:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9296 updates
2022-03-05 20:29:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:29:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:29:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 191 @ 9296 updates, score 13.405) (writing took 1.6476958869025111 seconds)
2022-03-05 20:29:26 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-05 20:29:26 | INFO | train | epoch 191 | loss 2.889 | nll_loss 0.686 | ppl 1.61 | wps 27692.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9296 | lr 0.000327983 | gnorm 0.684 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22005
2022-03-05 20:29:26 | INFO | fairseq.trainer | begin training epoch 192
2022-03-05 20:29:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:29:35 | INFO | train_inner | epoch 192:      4 / 49 loss=2.891, nll_loss=0.687, ppl=1.61, wps=27469.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.688, loss_scale=16, train_wall=200, gb_free=21.6, wall=22014
2022-03-05 20:31:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:31:19 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 13.443 | nll_loss 12.633 | ppl 6353.31 | wps 46467.3 | wpb 510.9 | bsz 1 | num_updates 9345 | best_loss 9.173
2022-03-05 20:31:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9345 updates
2022-03-05 20:31:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:31:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:31:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 192 @ 9345 updates, score 13.443) (writing took 1.6394706424325705 seconds)
2022-03-05 20:31:21 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-05 20:31:21 | INFO | train | epoch 192 | loss 2.885 | nll_loss 0.681 | ppl 1.6 | wps 27688.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9345 | lr 0.000327122 | gnorm 0.683 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22119
2022-03-05 20:31:21 | INFO | fairseq.trainer | begin training epoch 193
2022-03-05 20:31:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:32:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:33:14 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 13.37 | nll_loss 12.552 | ppl 6004.48 | wps 46657.6 | wpb 510.9 | bsz 1 | num_updates 9393 | best_loss 9.173
2022-03-05 20:33:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9393 updates
2022-03-05 20:33:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:33:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:33:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 193 @ 9393 updates, score 13.37) (writing took 1.673041868954897 seconds)
2022-03-05 20:33:15 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-05 20:33:15 | INFO | train | epoch 193 | loss 2.884 | nll_loss 0.681 | ppl 1.6 | wps 27133.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9393 | lr 0.000326286 | gnorm 0.702 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22234
2022-03-05 20:33:15 | INFO | fairseq.trainer | begin training epoch 194
2022-03-05 20:33:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:33:31 | INFO | train_inner | epoch 194:      7 / 49 loss=2.884, nll_loss=0.68, ppl=1.6, wps=27467.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.692, loss_scale=16, train_wall=200, gb_free=21.6, wall=22250
2022-03-05 20:35:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:35:08 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 13.49 | nll_loss 12.678 | ppl 6555.19 | wps 46577.4 | wpb 510.9 | bsz 1 | num_updates 9442 | best_loss 9.173
2022-03-05 20:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9442 updates
2022-03-05 20:35:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:35:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 194 @ 9442 updates, score 13.49) (writing took 1.6887964056804776 seconds)
2022-03-05 20:35:10 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-05 20:35:10 | INFO | train | epoch 194 | loss 2.88 | nll_loss 0.677 | ppl 1.6 | wps 27698.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9442 | lr 0.000325438 | gnorm 0.692 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22349
2022-03-05 20:35:10 | INFO | fairseq.trainer | begin training epoch 195
2022-03-05 20:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:37:03 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 13.364 | nll_loss 12.55 | ppl 5998.74 | wps 46722.8 | wpb 510.9 | bsz 1 | num_updates 9491 | best_loss 9.173
2022-03-05 20:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9491 updates
2022-03-05 20:37:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:37:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:37:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 195 @ 9491 updates, score 13.364) (writing took 1.677218115888536 seconds)
2022-03-05 20:37:05 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-05 20:37:05 | INFO | train | epoch 195 | loss 2.876 | nll_loss 0.673 | ppl 1.59 | wps 27687.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9491 | lr 0.000324597 | gnorm 0.687 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22464
2022-03-05 20:37:05 | INFO | fairseq.trainer | begin training epoch 196
2022-03-05 20:37:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:37:25 | INFO | train_inner | epoch 196:      9 / 49 loss=2.876, nll_loss=0.673, ppl=1.59, wps=27724.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.687, loss_scale=16, train_wall=198, gb_free=21.6, wall=22484
2022-03-05 20:38:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:38:58 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 13.403 | nll_loss 12.582 | ppl 6130.48 | wps 46492.1 | wpb 510.9 | bsz 1 | num_updates 9539 | best_loss 9.173
2022-03-05 20:38:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9539 updates
2022-03-05 20:38:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:39:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:39:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 196 @ 9539 updates, score 13.403) (writing took 1.6301903771236539 seconds)
2022-03-05 20:39:00 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-05 20:39:00 | INFO | train | epoch 196 | loss 2.871 | nll_loss 0.669 | ppl 1.59 | wps 27128.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9539 | lr 0.000323779 | gnorm 0.678 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22578
2022-03-05 20:39:00 | INFO | fairseq.trainer | begin training epoch 197
2022-03-05 20:39:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:40:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:40:53 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 13.504 | nll_loss 12.716 | ppl 6729.87 | wps 46558.7 | wpb 510.9 | bsz 1 | num_updates 9588 | best_loss 9.173
2022-03-05 20:40:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9588 updates
2022-03-05 20:40:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:40:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:40:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 197 @ 9588 updates, score 13.504) (writing took 1.6630564769729972 seconds)
2022-03-05 20:40:54 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-05 20:40:54 | INFO | train | epoch 197 | loss 2.869 | nll_loss 0.666 | ppl 1.59 | wps 27702.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9588 | lr 0.000322951 | gnorm 0.678 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22693
2022-03-05 20:40:54 | INFO | fairseq.trainer | begin training epoch 198
2022-03-05 20:40:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:41:21 | INFO | train_inner | epoch 198:     12 / 49 loss=2.869, nll_loss=0.667, ppl=1.59, wps=27474.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.678, loss_scale=16, train_wall=200, gb_free=21.6, wall=22720
2022-03-05 20:42:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:42:48 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 13.505 | nll_loss 12.705 | ppl 6675.73 | wps 46610.4 | wpb 510.9 | bsz 1 | num_updates 9637 | best_loss 9.173
2022-03-05 20:42:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9637 updates
2022-03-05 20:42:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:42:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:42:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 198 @ 9637 updates, score 13.505) (writing took 1.63318105135113 seconds)
2022-03-05 20:42:49 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-05 20:42:49 | INFO | train | epoch 198 | loss 2.866 | nll_loss 0.664 | ppl 1.58 | wps 27677.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9637 | lr 0.000322128 | gnorm 0.68 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22808
2022-03-05 20:42:49 | INFO | fairseq.trainer | begin training epoch 199
2022-03-05 20:42:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:44:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:44:42 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 13.509 | nll_loss 12.716 | ppl 6730.17 | wps 46611 | wpb 510.9 | bsz 1 | num_updates 9685 | best_loss 9.173
2022-03-05 20:44:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9685 updates
2022-03-05 20:44:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:44:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:44:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 199 @ 9685 updates, score 13.509) (writing took 1.677649705670774 seconds)
2022-03-05 20:44:44 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-05 20:44:44 | INFO | train | epoch 199 | loss 2.861 | nll_loss 0.659 | ppl 1.58 | wps 27123 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9685 | lr 0.000321329 | gnorm 0.668 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22923
2022-03-05 20:44:44 | INFO | fairseq.trainer | begin training epoch 200
2022-03-05 20:44:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:45:17 | INFO | train_inner | epoch 200:     15 / 49 loss=2.862, nll_loss=0.66, ppl=1.58, wps=27453, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.674, loss_scale=16, train_wall=200, gb_free=21.6, wall=22956
2022-03-05 20:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:46:37 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 13.475 | nll_loss 12.669 | ppl 6514.49 | wps 46569.9 | wpb 510.9 | bsz 1 | num_updates 9734 | best_loss 9.173
2022-03-05 20:46:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9734 updates
2022-03-05 20:46:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:46:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:46:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 200 @ 9734 updates, score 13.475) (writing took 1.6647172523662448 seconds)
2022-03-05 20:46:39 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-05 20:46:39 | INFO | train | epoch 200 | loss 2.857 | nll_loss 0.656 | ppl 1.58 | wps 27685.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9734 | lr 0.000320519 | gnorm 0.673 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23037
2022-03-05 20:46:39 | INFO | fairseq.trainer | begin training epoch 201
2022-03-05 20:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:48:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:48:32 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 13.459 | nll_loss 12.653 | ppl 6441.03 | wps 46490.6 | wpb 510.9 | bsz 1 | num_updates 9783 | best_loss 9.173
2022-03-05 20:48:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9783 updates
2022-03-05 20:48:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:48:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:48:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 201 @ 9783 updates, score 13.459) (writing took 1.7249909304082394 seconds)
2022-03-05 20:48:34 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-05 20:48:34 | INFO | train | epoch 201 | loss 2.855 | nll_loss 0.654 | ppl 1.57 | wps 27675.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9783 | lr 0.000319716 | gnorm 0.673 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23152
2022-03-05 20:48:34 | INFO | fairseq.trainer | begin training epoch 202
2022-03-05 20:48:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:49:12 | INFO | train_inner | epoch 202:     17 / 49 loss=2.856, nll_loss=0.654, ppl=1.57, wps=27717.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.675, loss_scale=32, train_wall=198, gb_free=21.6, wall=23190
2022-03-05 20:50:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:50:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:50:27 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 13.494 | nll_loss 12.689 | ppl 6605.32 | wps 46671.6 | wpb 510.9 | bsz 1 | num_updates 9831 | best_loss 9.173
2022-03-05 20:50:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9831 updates
2022-03-05 20:50:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:50:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 202 @ 9831 updates, score 13.494) (writing took 1.6697460068389773 seconds)
2022-03-05 20:50:28 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-05 20:50:28 | INFO | train | epoch 202 | loss 2.852 | nll_loss 0.651 | ppl 1.57 | wps 27143.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9831 | lr 0.000318934 | gnorm 0.675 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23267
2022-03-05 20:50:28 | INFO | fairseq.trainer | begin training epoch 203
2022-03-05 20:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:52:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:52:21 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 13.404 | nll_loss 12.582 | ppl 6133.47 | wps 46677.7 | wpb 510.9 | bsz 1 | num_updates 9880 | best_loss 9.173
2022-03-05 20:52:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9880 updates
2022-03-05 20:52:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:52:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:52:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 203 @ 9880 updates, score 13.404) (writing took 1.6364621836692095 seconds)
2022-03-05 20:52:23 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-05 20:52:23 | INFO | train | epoch 203 | loss 2.848 | nll_loss 0.648 | ppl 1.57 | wps 27708.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9880 | lr 0.000318142 | gnorm 0.661 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23382
2022-03-05 20:52:23 | INFO | fairseq.trainer | begin training epoch 204
2022-03-05 20:52:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:53:08 | INFO | train_inner | epoch 204:     20 / 49 loss=2.848, nll_loss=0.648, ppl=1.57, wps=27478.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.663, loss_scale=16, train_wall=200, gb_free=21.6, wall=23426
2022-03-05 20:54:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:54:16 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 13.384 | nll_loss 12.569 | ppl 6076.38 | wps 46408.5 | wpb 510.9 | bsz 1 | num_updates 9929 | best_loss 9.173
2022-03-05 20:54:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9929 updates
2022-03-05 20:54:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:54:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:54:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 204 @ 9929 updates, score 13.384) (writing took 1.6607689736410975 seconds)
2022-03-05 20:54:18 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-05 20:54:18 | INFO | train | epoch 204 | loss 2.845 | nll_loss 0.645 | ppl 1.56 | wps 27672.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9929 | lr 0.000317356 | gnorm 0.663 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23496
2022-03-05 20:54:18 | INFO | fairseq.trainer | begin training epoch 205
2022-03-05 20:54:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:55:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:56:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:56:11 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 13.505 | nll_loss 12.708 | ppl 6690.51 | wps 46753 | wpb 510.9 | bsz 1 | num_updates 9977 | best_loss 9.173
2022-03-05 20:56:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9977 updates
2022-03-05 20:56:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:56:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:56:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 205 @ 9977 updates, score 13.505) (writing took 1.6402521934360266 seconds)
2022-03-05 20:56:12 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-05 20:56:12 | INFO | train | epoch 205 | loss 2.842 | nll_loss 0.642 | ppl 1.56 | wps 27145.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9977 | lr 0.000316592 | gnorm 0.661 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23611
2022-03-05 20:56:12 | INFO | fairseq.trainer | begin training epoch 206
2022-03-05 20:56:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:57:04 | INFO | train_inner | epoch 206:     23 / 49 loss=2.842, nll_loss=0.642, ppl=1.56, wps=27457.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.657, loss_scale=16, train_wall=200, gb_free=21.6, wall=23663
2022-03-05 20:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:58:05 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 13.342 | nll_loss 12.519 | ppl 5868 | wps 46645.2 | wpb 510.9 | bsz 1 | num_updates 10026 | best_loss 9.173
2022-03-05 20:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10026 updates
2022-03-05 20:58:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:58:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 20:58:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 206 @ 10026 updates, score 13.342) (writing took 1.6312694530934095 seconds)
2022-03-05 20:58:07 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-05 20:58:07 | INFO | train | epoch 206 | loss 2.839 | nll_loss 0.639 | ppl 1.56 | wps 27715.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10026 | lr 0.000315817 | gnorm 0.647 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23726
2022-03-05 20:58:07 | INFO | fairseq.trainer | begin training epoch 207
2022-03-05 20:58:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:59:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:00:00 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 13.308 | nll_loss 12.489 | ppl 5749.47 | wps 46569.1 | wpb 510.9 | bsz 1 | num_updates 10075 | best_loss 9.173
2022-03-05 21:00:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10075 updates
2022-03-05 21:00:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:00:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:00:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 207 @ 10075 updates, score 13.308) (writing took 1.637445643544197 seconds)
2022-03-05 21:00:02 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-05 21:00:02 | INFO | train | epoch 207 | loss 2.837 | nll_loss 0.637 | ppl 1.56 | wps 27709 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10075 | lr 0.000315049 | gnorm 0.666 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23840
2022-03-05 21:00:02 | INFO | fairseq.trainer | begin training epoch 208
2022-03-05 21:00:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:00:58 | INFO | train_inner | epoch 208:     25 / 49 loss=2.837, nll_loss=0.637, ppl=1.56, wps=27742.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.656, loss_scale=32, train_wall=198, gb_free=21.6, wall=23896
2022-03-05 21:01:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:01:55 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 13.412 | nll_loss 12.604 | ppl 6227.02 | wps 46597.3 | wpb 510.9 | bsz 1 | num_updates 10124 | best_loss 9.173
2022-03-05 21:01:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10124 updates
2022-03-05 21:01:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:01:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:01:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 208 @ 10124 updates, score 13.412) (writing took 1.6732731200754642 seconds)
2022-03-05 21:01:57 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-05 21:01:57 | INFO | train | epoch 208 | loss 2.833 | nll_loss 0.634 | ppl 1.55 | wps 27682.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10124 | lr 0.000314285 | gnorm 0.64 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23955
2022-03-05 21:01:57 | INFO | fairseq.trainer | begin training epoch 209
2022-03-05 21:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:03:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:03:50 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 13.415 | nll_loss 12.608 | ppl 6240.81 | wps 46545 | wpb 510.9 | bsz 1 | num_updates 10173 | best_loss 9.173
2022-03-05 21:03:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10173 updates
2022-03-05 21:03:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 209 @ 10173 updates, score 13.415) (writing took 1.6780577274039388 seconds)
2022-03-05 21:03:51 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-05 21:03:51 | INFO | train | epoch 209 | loss 2.831 | nll_loss 0.632 | ppl 1.55 | wps 27677.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10173 | lr 0.000313527 | gnorm 0.649 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 24070
2022-03-05 21:03:51 | INFO | fairseq.trainer | begin training epoch 210
2022-03-05 21:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:04:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:04:54 | INFO | train_inner | epoch 210:     28 / 49 loss=2.83, nll_loss=0.631, ppl=1.55, wps=27454.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.641, loss_scale=16, train_wall=200, gb_free=21.6, wall=24133
2022-03-05 21:05:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:05:44 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 13.457 | nll_loss 12.665 | ppl 6496.36 | wps 46478.3 | wpb 510.9 | bsz 1 | num_updates 10221 | best_loss 9.173
2022-03-05 21:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10221 updates
2022-03-05 21:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:05:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 210 @ 10221 updates, score 13.457) (writing took 1.606007962487638 seconds)
2022-03-05 21:05:46 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-05 21:05:46 | INFO | train | epoch 210 | loss 2.826 | nll_loss 0.627 | ppl 1.54 | wps 27144 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10221 | lr 0.00031279 | gnorm 0.636 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24185
2022-03-05 21:05:46 | INFO | fairseq.trainer | begin training epoch 211
2022-03-05 21:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:07:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:07:39 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 13.373 | nll_loss 12.561 | ppl 6043.21 | wps 46452.6 | wpb 510.9 | bsz 1 | num_updates 10270 | best_loss 9.173
2022-03-05 21:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10270 updates
2022-03-05 21:07:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:07:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:07:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 211 @ 10270 updates, score 13.373) (writing took 1.6753155272454023 seconds)
2022-03-05 21:07:41 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-05 21:07:41 | INFO | train | epoch 211 | loss 2.824 | nll_loss 0.627 | ppl 1.54 | wps 27701.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10270 | lr 0.000312043 | gnorm 0.64 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24299
2022-03-05 21:07:41 | INFO | fairseq.trainer | begin training epoch 212
2022-03-05 21:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:08:48 | INFO | train_inner | epoch 212:     30 / 49 loss=2.824, nll_loss=0.626, ppl=1.54, wps=27744.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.643, loss_scale=16, train_wall=198, gb_free=21.6, wall=24367
2022-03-05 21:09:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:09:34 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 13.38 | nll_loss 12.57 | ppl 6079.71 | wps 46644.6 | wpb 510.9 | bsz 1 | num_updates 10319 | best_loss 9.173
2022-03-05 21:09:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10319 updates
2022-03-05 21:09:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:09:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:09:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 212 @ 10319 updates, score 13.38) (writing took 1.6520234923809767 seconds)
2022-03-05 21:09:35 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-05 21:09:35 | INFO | train | epoch 212 | loss 2.823 | nll_loss 0.625 | ppl 1.54 | wps 27708.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10319 | lr 0.000311301 | gnorm 0.644 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24414
2022-03-05 21:09:36 | INFO | fairseq.trainer | begin training epoch 213
2022-03-05 21:09:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:10:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:11:29 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 13.493 | nll_loss 12.692 | ppl 6618.03 | wps 46558.2 | wpb 510.9 | bsz 1 | num_updates 10367 | best_loss 9.173
2022-03-05 21:11:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10367 updates
2022-03-05 21:11:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:11:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:11:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 213 @ 10367 updates, score 13.493) (writing took 1.6721224701032043 seconds)
2022-03-05 21:11:30 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-05 21:11:30 | INFO | train | epoch 213 | loss 2.819 | nll_loss 0.622 | ppl 1.54 | wps 27135.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10367 | lr 0.00031058 | gnorm 0.649 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24529
2022-03-05 21:11:30 | INFO | fairseq.trainer | begin training epoch 214
2022-03-05 21:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:12:44 | INFO | train_inner | epoch 214:     33 / 49 loss=2.82, nll_loss=0.622, ppl=1.54, wps=27465.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.646, loss_scale=16, train_wall=200, gb_free=21.6, wall=24603
2022-03-05 21:13:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:13:23 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 13.383 | nll_loss 12.575 | ppl 6103.59 | wps 46643 | wpb 510.9 | bsz 1 | num_updates 10416 | best_loss 9.173
2022-03-05 21:13:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10416 updates
2022-03-05 21:13:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:13:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:13:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 214 @ 10416 updates, score 13.383) (writing took 1.6712957043200731 seconds)
2022-03-05 21:13:25 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-05 21:13:25 | INFO | train | epoch 214 | loss 2.817 | nll_loss 0.619 | ppl 1.54 | wps 27692.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10416 | lr 0.000309849 | gnorm 0.648 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24644
2022-03-05 21:13:25 | INFO | fairseq.trainer | begin training epoch 215
2022-03-05 21:13:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:15:18 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 13.517 | nll_loss 12.723 | ppl 6762.71 | wps 46592.1 | wpb 510.9 | bsz 1 | num_updates 10465 | best_loss 9.173
2022-03-05 21:15:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10465 updates
2022-03-05 21:15:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:15:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:15:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 215 @ 10465 updates, score 13.517) (writing took 1.632757886312902 seconds)
2022-03-05 21:15:20 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-05 21:15:20 | INFO | train | epoch 215 | loss 2.815 | nll_loss 0.618 | ppl 1.53 | wps 27696.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10465 | lr 0.000309122 | gnorm 0.646 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24758
2022-03-05 21:15:20 | INFO | fairseq.trainer | begin training epoch 216
2022-03-05 21:15:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:16:38 | INFO | train_inner | epoch 216:     35 / 49 loss=2.814, nll_loss=0.617, ppl=1.53, wps=27730.6, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.65, loss_scale=32, train_wall=198, gb_free=21.6, wall=24837
2022-03-05 21:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:17:13 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 13.401 | nll_loss 12.593 | ppl 6180.25 | wps 46416.8 | wpb 510.9 | bsz 1 | num_updates 10514 | best_loss 9.173
2022-03-05 21:17:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10514 updates
2022-03-05 21:17:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:17:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:17:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 216 @ 10514 updates, score 13.401) (writing took 1.6184921618551016 seconds)
2022-03-05 21:17:14 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-05 21:17:14 | INFO | train | epoch 216 | loss 2.811 | nll_loss 0.614 | ppl 1.53 | wps 27702 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10514 | lr 0.000308401 | gnorm 0.646 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 24873
2022-03-05 21:17:14 | INFO | fairseq.trainer | begin training epoch 217
2022-03-05 21:17:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:19:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:19:07 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 13.476 | nll_loss 12.682 | ppl 6570.58 | wps 46689.8 | wpb 510.9 | bsz 1 | num_updates 10563 | best_loss 9.173
2022-03-05 21:19:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10563 updates
2022-03-05 21:19:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:19:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:19:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 217 @ 10563 updates, score 13.476) (writing took 1.6453961906954646 seconds)
2022-03-05 21:19:09 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-05 21:19:09 | INFO | train | epoch 217 | loss 2.807 | nll_loss 0.611 | ppl 1.53 | wps 27703.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10563 | lr 0.000307685 | gnorm 0.626 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 24988
2022-03-05 21:19:09 | INFO | fairseq.trainer | begin training epoch 218
2022-03-05 21:19:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:20:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:20:34 | INFO | train_inner | epoch 218:     38 / 49 loss=2.807, nll_loss=0.611, ppl=1.53, wps=27478, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.633, loss_scale=32, train_wall=200, gb_free=21.6, wall=25073
2022-03-05 21:20:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:21:02 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 13.512 | nll_loss 12.731 | ppl 6798.79 | wps 46662.5 | wpb 510.9 | bsz 1 | num_updates 10611 | best_loss 9.173
2022-03-05 21:21:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10611 updates
2022-03-05 21:21:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:21:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:21:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 218 @ 10611 updates, score 13.512) (writing took 1.6879221489652991 seconds)
2022-03-05 21:21:04 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-05 21:21:04 | INFO | train | epoch 218 | loss 2.805 | nll_loss 0.609 | ppl 1.53 | wps 27136.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10611 | lr 0.000306988 | gnorm 0.644 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25103
2022-03-05 21:21:04 | INFO | fairseq.trainer | begin training epoch 219
2022-03-05 21:21:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:22:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:22:57 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 13.37 | nll_loss 12.565 | ppl 6058.21 | wps 46614.8 | wpb 510.9 | bsz 1 | num_updates 10660 | best_loss 9.173
2022-03-05 21:22:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10660 updates
2022-03-05 21:22:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:22:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:22:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 219 @ 10660 updates, score 13.37) (writing took 1.6049427725374699 seconds)
2022-03-05 21:22:58 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-05 21:22:58 | INFO | train | epoch 219 | loss 2.802 | nll_loss 0.606 | ppl 1.52 | wps 27735.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10660 | lr 0.000306282 | gnorm 0.624 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25217
2022-03-05 21:22:58 | INFO | fairseq.trainer | begin training epoch 220
2022-03-05 21:22:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:24:28 | INFO | train_inner | epoch 220:     40 / 49 loss=2.802, nll_loss=0.606, ppl=1.52, wps=27752.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.631, loss_scale=32, train_wall=198, gb_free=21.6, wall=25306
2022-03-05 21:24:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:24:51 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 13.617 | nll_loss 12.846 | ppl 7362.45 | wps 46565.1 | wpb 510.9 | bsz 1 | num_updates 10709 | best_loss 9.173
2022-03-05 21:24:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10709 updates
2022-03-05 21:24:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:24:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:24:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 220 @ 10709 updates, score 13.617) (writing took 1.6576493941247463 seconds)
2022-03-05 21:24:53 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-05 21:24:53 | INFO | train | epoch 220 | loss 2.801 | nll_loss 0.605 | ppl 1.52 | wps 27706.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10709 | lr 0.00030558 | gnorm 0.628 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25332
2022-03-05 21:24:53 | INFO | fairseq.trainer | begin training epoch 221
2022-03-05 21:24:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:25:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:26:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:26:46 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 13.423 | nll_loss 12.633 | ppl 6352.75 | wps 46493.3 | wpb 510.9 | bsz 1 | num_updates 10757 | best_loss 9.173
2022-03-05 21:26:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10757 updates
2022-03-05 21:26:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:26:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:26:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 221 @ 10757 updates, score 13.423) (writing took 1.6880741771310568 seconds)
2022-03-05 21:26:48 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-05 21:26:48 | INFO | train | epoch 221 | loss 2.798 | nll_loss 0.603 | ppl 1.52 | wps 27114.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10757 | lr 0.000304898 | gnorm 0.631 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25447
2022-03-05 21:26:48 | INFO | fairseq.trainer | begin training epoch 222
2022-03-05 21:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:27:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:28:26 | INFO | train_inner | epoch 222:     44 / 49 loss=2.798, nll_loss=0.602, ppl=1.52, wps=27219.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.631, loss_scale=16, train_wall=202, gb_free=21.6, wall=25545
2022-03-05 21:28:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:28:41 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 13.446 | nll_loss 12.656 | ppl 6454.25 | wps 46638.4 | wpb 510.9 | bsz 1 | num_updates 10805 | best_loss 9.173
2022-03-05 21:28:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10805 updates
2022-03-05 21:28:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:28:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:28:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 222 @ 10805 updates, score 13.446) (writing took 1.6559214815497398 seconds)
2022-03-05 21:28:43 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-05 21:28:43 | INFO | train | epoch 222 | loss 2.796 | nll_loss 0.601 | ppl 1.52 | wps 27161.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10805 | lr 0.00030422 | gnorm 0.636 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25561
2022-03-05 21:28:43 | INFO | fairseq.trainer | begin training epoch 223
2022-03-05 21:28:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:30:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:30:36 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 13.448 | nll_loss 12.664 | ppl 6491.76 | wps 46645.8 | wpb 510.9 | bsz 1 | num_updates 10854 | best_loss 9.173
2022-03-05 21:30:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10854 updates
2022-03-05 21:30:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:30:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:30:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 223 @ 10854 updates, score 13.448) (writing took 1.6861764835193753 seconds)
2022-03-05 21:30:37 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-05 21:30:37 | INFO | train | epoch 223 | loss 2.793 | nll_loss 0.598 | ppl 1.51 | wps 27708.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10854 | lr 0.000303532 | gnorm 0.624 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25676
2022-03-05 21:30:37 | INFO | fairseq.trainer | begin training epoch 224
2022-03-05 21:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:32:20 | INFO | train_inner | epoch 224:     46 / 49 loss=2.792, nll_loss=0.598, ppl=1.51, wps=27735.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.628, loss_scale=32, train_wall=198, gb_free=21.6, wall=25779
2022-03-05 21:32:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:32:30 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.415 | nll_loss 12.612 | ppl 6259.26 | wps 46599.8 | wpb 510.9 | bsz 1 | num_updates 10903 | best_loss 9.173
2022-03-05 21:32:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10903 updates
2022-03-05 21:32:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:32:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:32:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 224 @ 10903 updates, score 13.415) (writing took 1.6288664527237415 seconds)
2022-03-05 21:32:32 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-05 21:32:32 | INFO | train | epoch 224 | loss 2.791 | nll_loss 0.597 | ppl 1.51 | wps 27702.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10903 | lr 0.00030285 | gnorm 0.631 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25791
2022-03-05 21:32:32 | INFO | fairseq.trainer | begin training epoch 225
2022-03-05 21:32:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:33:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:34:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:34:25 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 13.445 | nll_loss 12.651 | ppl 6430.77 | wps 46578.7 | wpb 510.9 | bsz 1 | num_updates 10951 | best_loss 9.173
2022-03-05 21:34:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10951 updates
2022-03-05 21:34:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:34:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:34:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 225 @ 10951 updates, score 13.445) (writing took 1.664602480828762 seconds)
2022-03-05 21:34:27 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-05 21:34:27 | INFO | train | epoch 225 | loss 2.786 | nll_loss 0.592 | ppl 1.51 | wps 27131.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10951 | lr 0.000302185 | gnorm 0.611 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25905
2022-03-05 21:34:27 | INFO | fairseq.trainer | begin training epoch 226
2022-03-05 21:34:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:36:15 | INFO | train_inner | epoch 226:     49 / 49 loss=2.787, nll_loss=0.593, ppl=1.51, wps=27473.8, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=11000, lr=0.000301511, gnorm=0.616, loss_scale=16, train_wall=199, gb_free=21.6, wall=26014
2022-03-05 21:36:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:36:20 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 13.485 | nll_loss 12.699 | ppl 6648.3 | wps 46687.5 | wpb 510.9 | bsz 1 | num_updates 11000 | best_loss 9.173
2022-03-05 21:36:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 11000 updates
2022-03-05 21:36:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:36:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:36:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 226 @ 11000 updates, score 13.485) (writing took 1.6908018887043 seconds)
2022-03-05 21:36:21 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-05 21:36:21 | INFO | train | epoch 226 | loss 2.786 | nll_loss 0.592 | ppl 1.51 | wps 27714.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11000 | lr 0.000301511 | gnorm 0.617 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26020
2022-03-05 21:36:21 | INFO | fairseq.trainer | begin training epoch 227
2022-03-05 21:36:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:38:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:38:15 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.371 | nll_loss 12.577 | ppl 6108.16 | wps 46515.6 | wpb 510.9 | bsz 1 | num_updates 11049 | best_loss 9.173
2022-03-05 21:38:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11049 updates
2022-03-05 21:38:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:38:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:38:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 227 @ 11049 updates, score 13.371) (writing took 1.6667482377961278 seconds)
2022-03-05 21:38:16 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-05 21:38:16 | INFO | train | epoch 227 | loss 2.784 | nll_loss 0.59 | ppl 1.51 | wps 27661.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11049 | lr 0.000300842 | gnorm 0.621 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26135
2022-03-05 21:38:16 | INFO | fairseq.trainer | begin training epoch 228
2022-03-05 21:38:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:40:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:40:09 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.455 | nll_loss 12.665 | ppl 6494.1 | wps 46620.1 | wpb 510.9 | bsz 1 | num_updates 11098 | best_loss 9.173
2022-03-05 21:40:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11098 updates
2022-03-05 21:40:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:40:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:40:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 228 @ 11098 updates, score 13.455) (writing took 1.6599785080179572 seconds)
2022-03-05 21:40:11 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-05 21:40:11 | INFO | train | epoch 228 | loss 2.78 | nll_loss 0.587 | ppl 1.5 | wps 27681.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11098 | lr 0.000300177 | gnorm 0.606 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26250
2022-03-05 21:40:11 | INFO | fairseq.trainer | begin training epoch 229
2022-03-05 21:40:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:40:16 | INFO | train_inner | epoch 229:      2 / 49 loss=2.782, nll_loss=0.588, ppl=1.5, wps=26953.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.613, loss_scale=32, train_wall=199, gb_free=21.6, wall=26254
2022-03-05 21:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:42:04 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.501 | nll_loss 12.712 | ppl 6711.85 | wps 46701.5 | wpb 510.9 | bsz 1 | num_updates 11147 | best_loss 9.173
2022-03-05 21:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11147 updates
2022-03-05 21:42:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:42:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 229 @ 11147 updates, score 13.501) (writing took 1.6424422580748796 seconds)
2022-03-05 21:42:06 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-05 21:42:06 | INFO | train | epoch 229 | loss 2.779 | nll_loss 0.587 | ppl 1.5 | wps 27717.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11147 | lr 0.000299517 | gnorm 0.613 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26364
2022-03-05 21:42:06 | INFO | fairseq.trainer | begin training epoch 230
2022-03-05 21:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:43:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:43:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:43:59 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 13.339 | nll_loss 12.535 | ppl 5933.57 | wps 46683.6 | wpb 510.9 | bsz 1 | num_updates 11195 | best_loss 9.173
2022-03-05 21:43:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11195 updates
2022-03-05 21:43:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:44:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:44:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 230 @ 11195 updates, score 13.339) (writing took 1.6463707704097033 seconds)
2022-03-05 21:44:00 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-05 21:44:00 | INFO | train | epoch 230 | loss 2.775 | nll_loss 0.583 | ppl 1.5 | wps 27133.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11195 | lr 0.000298874 | gnorm 0.616 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26479
2022-03-05 21:44:00 | INFO | fairseq.trainer | begin training epoch 231
2022-03-05 21:44:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:44:12 | INFO | train_inner | epoch 231:      5 / 49 loss=2.777, nll_loss=0.584, ppl=1.5, wps=27483, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.617, loss_scale=32, train_wall=200, gb_free=21.6, wall=26490
2022-03-05 21:45:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:45:54 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 13.417 | nll_loss 12.628 | ppl 6330.08 | wps 46444.3 | wpb 510.9 | bsz 1 | num_updates 11244 | best_loss 9.173
2022-03-05 21:45:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11244 updates
2022-03-05 21:45:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:45:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:45:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 231 @ 11244 updates, score 13.417) (writing took 1.6704017212614417 seconds)
2022-03-05 21:45:55 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-05 21:45:55 | INFO | train | epoch 231 | loss 2.775 | nll_loss 0.583 | ppl 1.5 | wps 27686.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11244 | lr 0.000298222 | gnorm 0.629 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26594
2022-03-05 21:45:55 | INFO | fairseq.trainer | begin training epoch 232
2022-03-05 21:45:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:47:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:47:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:47:48 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.417 | nll_loss 12.623 | ppl 6307.24 | wps 46411 | wpb 510.9 | bsz 1 | num_updates 11292 | best_loss 9.173
2022-03-05 21:47:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11292 updates
2022-03-05 21:47:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:47:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:47:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 232 @ 11292 updates, score 13.417) (writing took 1.6735904468223453 seconds)
2022-03-05 21:47:50 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-05 21:47:50 | INFO | train | epoch 232 | loss 2.772 | nll_loss 0.58 | ppl 1.49 | wps 27147.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11292 | lr 0.000297587 | gnorm 0.615 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26709
2022-03-05 21:47:50 | INFO | fairseq.trainer | begin training epoch 233
2022-03-05 21:47:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:48:08 | INFO | train_inner | epoch 233:      8 / 49 loss=2.773, nll_loss=0.581, ppl=1.5, wps=27466.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.621, loss_scale=16, train_wall=200, gb_free=21.6, wall=26727
2022-03-05 21:49:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:49:43 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 13.485 | nll_loss 12.703 | ppl 6669.67 | wps 46774.5 | wpb 510.9 | bsz 1 | num_updates 11341 | best_loss 9.173
2022-03-05 21:49:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11341 updates
2022-03-05 21:49:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:49:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:49:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 233 @ 11341 updates, score 13.485) (writing took 1.6086150612682104 seconds)
2022-03-05 21:49:44 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-05 21:49:44 | INFO | train | epoch 233 | loss 2.77 | nll_loss 0.579 | ppl 1.49 | wps 27727.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11341 | lr 0.000296944 | gnorm 0.613 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26823
2022-03-05 21:49:44 | INFO | fairseq.trainer | begin training epoch 234
2022-03-05 21:49:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:51:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:51:37 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 13.447 | nll_loss 12.666 | ppl 6497.65 | wps 46643.7 | wpb 510.9 | bsz 1 | num_updates 11390 | best_loss 9.173
2022-03-05 21:51:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11390 updates
2022-03-05 21:51:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:51:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:51:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 234 @ 11390 updates, score 13.447) (writing took 1.653288159519434 seconds)
2022-03-05 21:51:39 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-05 21:51:39 | INFO | train | epoch 234 | loss 2.768 | nll_loss 0.576 | ppl 1.49 | wps 27718.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11390 | lr 0.000296304 | gnorm 0.618 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26938
2022-03-05 21:51:39 | INFO | fairseq.trainer | begin training epoch 235
2022-03-05 21:51:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:52:02 | INFO | train_inner | epoch 235:     10 / 49 loss=2.768, nll_loss=0.576, ppl=1.49, wps=27761.5, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.614, loss_scale=16, train_wall=198, gb_free=21.6, wall=26960
2022-03-05 21:52:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:53:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:53:32 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 13.39 | nll_loss 12.596 | ppl 6192.95 | wps 46532.9 | wpb 510.9 | bsz 1 | num_updates 11438 | best_loss 9.173
2022-03-05 21:53:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11438 updates
2022-03-05 21:53:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:53:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:53:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 235 @ 11438 updates, score 13.39) (writing took 1.6480553392320871 seconds)
2022-03-05 21:53:34 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-05 21:53:34 | INFO | train | epoch 235 | loss 2.764 | nll_loss 0.573 | ppl 1.49 | wps 27138 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11438 | lr 0.000295682 | gnorm 0.607 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27052
2022-03-05 21:53:34 | INFO | fairseq.trainer | begin training epoch 236
2022-03-05 21:53:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:55:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:55:27 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.358 | nll_loss 12.559 | ppl 6032.8 | wps 46439.5 | wpb 510.9 | bsz 1 | num_updates 11487 | best_loss 9.173
2022-03-05 21:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11487 updates
2022-03-05 21:55:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:55:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:55:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 236 @ 11487 updates, score 13.358) (writing took 1.6626851428300142 seconds)
2022-03-05 21:55:29 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-05 21:55:29 | INFO | train | epoch 236 | loss 2.762 | nll_loss 0.571 | ppl 1.49 | wps 27693.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11487 | lr 0.000295051 | gnorm 0.606 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27167
2022-03-05 21:55:29 | INFO | fairseq.trainer | begin training epoch 237
2022-03-05 21:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:55:58 | INFO | train_inner | epoch 237:     13 / 49 loss=2.763, nll_loss=0.571, ppl=1.49, wps=27471.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.606, loss_scale=16, train_wall=200, gb_free=21.6, wall=27196
2022-03-05 21:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:57:22 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 13.54 | nll_loss 12.77 | ppl 6986.09 | wps 46403.7 | wpb 510.9 | bsz 1 | num_updates 11536 | best_loss 9.173
2022-03-05 21:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11536 updates
2022-03-05 21:57:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:57:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:57:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 237 @ 11536 updates, score 13.54) (writing took 1.6462716767564416 seconds)
2022-03-05 21:57:23 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-05 21:57:23 | INFO | train | epoch 237 | loss 2.761 | nll_loss 0.571 | ppl 1.49 | wps 27706.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11536 | lr 0.000294423 | gnorm 0.61 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27282
2022-03-05 21:57:23 | INFO | fairseq.trainer | begin training epoch 238
2022-03-05 21:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:59:16 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.52 | nll_loss 12.742 | ppl 6849.25 | wps 46260.3 | wpb 510.9 | bsz 1 | num_updates 11585 | best_loss 9.173
2022-03-05 21:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11585 updates
2022-03-05 21:59:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 21:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 238 @ 11585 updates, score 13.52) (writing took 1.6842625346034765 seconds)
2022-03-05 21:59:18 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-05 21:59:18 | INFO | train | epoch 238 | loss 2.759 | nll_loss 0.569 | ppl 1.48 | wps 27715.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11585 | lr 0.0002938 | gnorm 0.6 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27397
2022-03-05 21:59:18 | INFO | fairseq.trainer | begin training epoch 239
2022-03-05 21:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:59:51 | INFO | train_inner | epoch 239:     15 / 49 loss=2.759, nll_loss=0.569, ppl=1.48, wps=27744.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.6, loss_scale=32, train_wall=198, gb_free=21.6, wall=27430
2022-03-05 22:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:01:11 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.403 | nll_loss 12.617 | ppl 6280.99 | wps 46653.1 | wpb 510.9 | bsz 1 | num_updates 11634 | best_loss 9.173
2022-03-05 22:01:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11634 updates
2022-03-05 22:01:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:01:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:01:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 239 @ 11634 updates, score 13.403) (writing took 1.6264272686094046 seconds)
2022-03-05 22:01:13 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-05 22:01:13 | INFO | train | epoch 239 | loss 2.756 | nll_loss 0.566 | ppl 1.48 | wps 27724.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11634 | lr 0.000293181 | gnorm 0.59 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27511
2022-03-05 22:01:13 | INFO | fairseq.trainer | begin training epoch 240
2022-03-05 22:01:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:02:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:03:06 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.373 | nll_loss 12.585 | ppl 6143.04 | wps 46555.8 | wpb 510.9 | bsz 1 | num_updates 11682 | best_loss 9.173
2022-03-05 22:03:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11682 updates
2022-03-05 22:03:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:03:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:03:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 240 @ 11682 updates, score 13.373) (writing took 1.6397212892770767 seconds)
2022-03-05 22:03:07 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-05 22:03:07 | INFO | train | epoch 240 | loss 2.755 | nll_loss 0.566 | ppl 1.48 | wps 27134.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11682 | lr 0.000292578 | gnorm 0.604 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27626
2022-03-05 22:03:07 | INFO | fairseq.trainer | begin training epoch 241
2022-03-05 22:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:03:48 | INFO | train_inner | epoch 241:     18 / 49 loss=2.755, nll_loss=0.565, ppl=1.48, wps=27482.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.603, loss_scale=32, train_wall=200, gb_free=21.6, wall=27666
2022-03-05 22:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:05:00 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 13.58 | nll_loss 12.821 | ppl 7235.72 | wps 46667.9 | wpb 510.9 | bsz 1 | num_updates 11731 | best_loss 9.173
2022-03-05 22:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11731 updates
2022-03-05 22:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:05:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:05:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 241 @ 11731 updates, score 13.58) (writing took 1.6901960084214807 seconds)
2022-03-05 22:05:02 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-05 22:05:02 | INFO | train | epoch 241 | loss 2.753 | nll_loss 0.563 | ppl 1.48 | wps 27682.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11731 | lr 0.000291966 | gnorm 0.595 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27741
2022-03-05 22:05:02 | INFO | fairseq.trainer | begin training epoch 242
2022-03-05 22:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:06:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:06:55 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.337 | nll_loss 12.541 | ppl 5957.94 | wps 46647.5 | wpb 510.9 | bsz 1 | num_updates 11780 | best_loss 9.173
2022-03-05 22:06:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11780 updates
2022-03-05 22:06:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:06:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:06:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 242 @ 11780 updates, score 13.337) (writing took 1.6118962652981281 seconds)
2022-03-05 22:06:57 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-05 22:06:57 | INFO | train | epoch 242 | loss 2.751 | nll_loss 0.561 | ppl 1.48 | wps 27748.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11780 | lr 0.000291358 | gnorm 0.593 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27855
2022-03-05 22:06:57 | INFO | fairseq.trainer | begin training epoch 243
2022-03-05 22:06:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:07:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:07:44 | INFO | train_inner | epoch 243:     21 / 49 loss=2.751, nll_loss=0.562, ppl=1.48, wps=27487.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.59, loss_scale=16, train_wall=200, gb_free=21.6, wall=27902
2022-03-05 22:08:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:08:50 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.519 | nll_loss 12.743 | ppl 6855.86 | wps 46737.8 | wpb 510.9 | bsz 1 | num_updates 11828 | best_loss 9.173
2022-03-05 22:08:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11828 updates
2022-03-05 22:08:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:08:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:08:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 243 @ 11828 updates, score 13.519) (writing took 1.6927107088267803 seconds)
2022-03-05 22:08:51 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-05 22:08:51 | INFO | train | epoch 243 | loss 2.749 | nll_loss 0.56 | ppl 1.47 | wps 27135.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11828 | lr 0.000290766 | gnorm 0.591 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27970
2022-03-05 22:08:51 | INFO | fairseq.trainer | begin training epoch 244
2022-03-05 22:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:10:44 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.449 | nll_loss 12.68 | ppl 6562.28 | wps 46703 | wpb 510.9 | bsz 1 | num_updates 11877 | best_loss 9.173
2022-03-05 22:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11877 updates
2022-03-05 22:10:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 244 @ 11877 updates, score 13.449) (writing took 1.6036747125908732 seconds)
2022-03-05 22:10:46 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-05 22:10:46 | INFO | train | epoch 244 | loss 2.747 | nll_loss 0.558 | ppl 1.47 | wps 27725.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11877 | lr 0.000290166 | gnorm 0.591 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28085
2022-03-05 22:10:46 | INFO | fairseq.trainer | begin training epoch 245
2022-03-05 22:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:11:37 | INFO | train_inner | epoch 245:     23 / 49 loss=2.747, nll_loss=0.558, ppl=1.47, wps=27750.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.589, loss_scale=16, train_wall=198, gb_free=21.6, wall=28136
2022-03-05 22:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:12:39 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.476 | nll_loss 12.69 | ppl 6607.22 | wps 46636.1 | wpb 510.9 | bsz 1 | num_updates 11926 | best_loss 9.173
2022-03-05 22:12:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11926 updates
2022-03-05 22:12:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:12:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:12:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 245 @ 11926 updates, score 13.476) (writing took 1.627297275699675 seconds)
2022-03-05 22:12:40 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-05 22:12:40 | INFO | train | epoch 245 | loss 2.745 | nll_loss 0.557 | ppl 1.47 | wps 27740.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11926 | lr 0.000289569 | gnorm 0.599 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28199
2022-03-05 22:12:41 | INFO | fairseq.trainer | begin training epoch 246
2022-03-05 22:12:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:13:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:14:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:14:34 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.44 | nll_loss 12.654 | ppl 6444.22 | wps 46571 | wpb 510.9 | bsz 1 | num_updates 11974 | best_loss 9.173
2022-03-05 22:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11974 updates
2022-03-05 22:14:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:14:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:14:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 246 @ 11974 updates, score 13.44) (writing took 1.6282280515879393 seconds)
2022-03-05 22:14:35 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-05 22:14:35 | INFO | train | epoch 246 | loss 2.743 | nll_loss 0.555 | ppl 1.47 | wps 27132.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11974 | lr 0.000288988 | gnorm 0.595 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28314
2022-03-05 22:14:35 | INFO | fairseq.trainer | begin training epoch 247
2022-03-05 22:14:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:15:33 | INFO | train_inner | epoch 247:     26 / 49 loss=2.743, nll_loss=0.555, ppl=1.47, wps=27487.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.598, loss_scale=16, train_wall=200, gb_free=21.6, wall=28372
2022-03-05 22:16:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:16:28 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.436 | nll_loss 12.656 | ppl 6455.15 | wps 46289.2 | wpb 510.9 | bsz 1 | num_updates 12023 | best_loss 9.173
2022-03-05 22:16:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12023 updates
2022-03-05 22:16:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:16:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:16:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 247 @ 12023 updates, score 13.436) (writing took 1.6253679851070046 seconds)
2022-03-05 22:16:30 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-05 22:16:30 | INFO | train | epoch 247 | loss 2.741 | nll_loss 0.553 | ppl 1.47 | wps 27728.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12023 | lr 0.000288399 | gnorm 0.581 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28429
2022-03-05 22:16:30 | INFO | fairseq.trainer | begin training epoch 248
2022-03-05 22:16:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:18:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:18:23 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 13.413 | nll_loss 12.637 | ppl 6371.21 | wps 46643.9 | wpb 510.9 | bsz 1 | num_updates 12072 | best_loss 9.173
2022-03-05 22:18:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12072 updates
2022-03-05 22:18:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:18:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:18:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 248 @ 12072 updates, score 13.413) (writing took 1.659312142059207 seconds)
2022-03-05 22:18:25 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-05 22:18:25 | INFO | train | epoch 248 | loss 2.74 | nll_loss 0.552 | ppl 1.47 | wps 27692.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12072 | lr 0.000287813 | gnorm 0.583 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28543
2022-03-05 22:18:25 | INFO | fairseq.trainer | begin training epoch 249
2022-03-05 22:18:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:18:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:19:30 | INFO | train_inner | epoch 249:     29 / 49 loss=2.739, nll_loss=0.551, ppl=1.47, wps=27463.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.581, loss_scale=16, train_wall=200, gb_free=21.6, wall=28608
2022-03-05 22:20:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:20:18 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 13.502 | nll_loss 12.73 | ppl 6795.69 | wps 46431.5 | wpb 510.9 | bsz 1 | num_updates 12120 | best_loss 9.173
2022-03-05 22:20:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12120 updates
2022-03-05 22:20:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:20:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:20:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 249 @ 12120 updates, score 13.502) (writing took 1.6576835587620735 seconds)
2022-03-05 22:20:19 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-05 22:20:19 | INFO | train | epoch 249 | loss 2.738 | nll_loss 0.55 | ppl 1.46 | wps 27102 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12120 | lr 0.000287242 | gnorm 0.586 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28658
2022-03-05 22:20:19 | INFO | fairseq.trainer | begin training epoch 250
2022-03-05 22:20:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:22:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:22:13 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.502 | nll_loss 12.732 | ppl 6802.3 | wps 46449 | wpb 510.9 | bsz 1 | num_updates 12169 | best_loss 9.173
2022-03-05 22:22:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12169 updates
2022-03-05 22:22:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:22:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:22:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 250 @ 12169 updates, score 13.502) (writing took 1.6835525529459119 seconds)
2022-03-05 22:22:14 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-05 22:22:14 | INFO | train | epoch 250 | loss 2.735 | nll_loss 0.548 | ppl 1.46 | wps 27691.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12169 | lr 0.000286664 | gnorm 0.578 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28773
2022-03-05 22:22:14 | INFO | fairseq.trainer | begin training epoch 251
2022-03-05 22:22:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:23:23 | INFO | train_inner | epoch 251:     31 / 49 loss=2.736, nll_loss=0.549, ppl=1.46, wps=27728.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.579, loss_scale=16, train_wall=198, gb_free=21.6, wall=28842
2022-03-05 22:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:24:07 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.415 | nll_loss 12.624 | ppl 6310.36 | wps 46679.3 | wpb 510.9 | bsz 1 | num_updates 12218 | best_loss 9.173
2022-03-05 22:24:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12218 updates
2022-03-05 22:24:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:24:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:24:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 251 @ 12218 updates, score 13.415) (writing took 1.6891476474702358 seconds)
2022-03-05 22:24:09 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-05 22:24:09 | INFO | train | epoch 251 | loss 2.734 | nll_loss 0.547 | ppl 1.46 | wps 27708.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12218 | lr 0.000286088 | gnorm 0.581 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28888
2022-03-05 22:24:09 | INFO | fairseq.trainer | begin training epoch 252
2022-03-05 22:24:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:25:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:26:02 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.348 | nll_loss 12.55 | ppl 5998.92 | wps 46681.7 | wpb 510.9 | bsz 1 | num_updates 12267 | best_loss 9.173
2022-03-05 22:26:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12267 updates
2022-03-05 22:26:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:26:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:26:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 252 @ 12267 updates, score 13.348) (writing took 1.6749501721933484 seconds)
2022-03-05 22:26:04 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-05 22:26:04 | INFO | train | epoch 252 | loss 2.733 | nll_loss 0.547 | ppl 1.46 | wps 27678 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12267 | lr 0.000285516 | gnorm 0.589 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29002
2022-03-05 22:26:04 | INFO | fairseq.trainer | begin training epoch 253
2022-03-05 22:26:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:27:17 | INFO | train_inner | epoch 253:     33 / 49 loss=2.733, nll_loss=0.547, ppl=1.46, wps=27726.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.589, loss_scale=32, train_wall=198, gb_free=21.6, wall=29076
2022-03-05 22:27:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:27:57 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.54 | nll_loss 12.78 | ppl 7032.19 | wps 45867.1 | wpb 510.9 | bsz 1 | num_updates 12316 | best_loss 9.173
2022-03-05 22:27:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12316 updates
2022-03-05 22:27:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:27:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:27:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 253 @ 12316 updates, score 13.54) (writing took 1.671903864480555 seconds)
2022-03-05 22:27:58 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-05 22:27:58 | INFO | train | epoch 253 | loss 2.731 | nll_loss 0.545 | ppl 1.46 | wps 27687.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12316 | lr 0.000284948 | gnorm 0.593 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29117
2022-03-05 22:27:59 | INFO | fairseq.trainer | begin training epoch 254
2022-03-05 22:27:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:28:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:29:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:29:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:29:52 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.385 | nll_loss 12.604 | ppl 6224.82 | wps 46439.9 | wpb 510.9 | bsz 1 | num_updates 12363 | best_loss 9.173
2022-03-05 22:29:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12363 updates
2022-03-05 22:29:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:29:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:29:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 254 @ 12363 updates, score 13.385) (writing took 1.6495867995545268 seconds)
2022-03-05 22:29:53 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-05 22:29:53 | INFO | train | epoch 254 | loss 2.728 | nll_loss 0.541 | ppl 1.46 | wps 26569.2 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 12363 | lr 0.000284406 | gnorm 0.586 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29232
2022-03-05 22:29:53 | INFO | fairseq.trainer | begin training epoch 255
2022-03-05 22:29:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:31:16 | INFO | train_inner | epoch 255:     37 / 49 loss=2.727, nll_loss=0.541, ppl=1.46, wps=27210.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.582, loss_scale=16, train_wall=202, gb_free=21.6, wall=29315
2022-03-05 22:31:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:31:46 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.517 | nll_loss 12.753 | ppl 6902.5 | wps 46479.5 | wpb 510.9 | bsz 1 | num_updates 12412 | best_loss 9.173
2022-03-05 22:31:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12412 updates
2022-03-05 22:31:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:31:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 255 @ 12412 updates, score 13.517) (writing took 1.662032874301076 seconds)
2022-03-05 22:31:48 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-05 22:31:48 | INFO | train | epoch 255 | loss 2.726 | nll_loss 0.54 | ppl 1.45 | wps 27694.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12412 | lr 0.000283844 | gnorm 0.571 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29347
2022-03-05 22:31:48 | INFO | fairseq.trainer | begin training epoch 256
2022-03-05 22:31:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:33:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:33:41 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.432 | nll_loss 12.661 | ppl 6474.65 | wps 46393.6 | wpb 510.9 | bsz 1 | num_updates 12461 | best_loss 9.173
2022-03-05 22:33:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12461 updates
2022-03-05 22:33:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:33:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:33:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 256 @ 12461 updates, score 13.432) (writing took 1.6734110433608294 seconds)
2022-03-05 22:33:43 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-05 22:33:43 | INFO | train | epoch 256 | loss 2.726 | nll_loss 0.541 | ppl 1.45 | wps 27687.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12461 | lr 0.000283285 | gnorm 0.591 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29461
2022-03-05 22:33:43 | INFO | fairseq.trainer | begin training epoch 257
2022-03-05 22:33:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:35:10 | INFO | train_inner | epoch 257:     39 / 49 loss=2.726, nll_loss=0.541, ppl=1.45, wps=27719, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.59, loss_scale=32, train_wall=198, gb_free=21.6, wall=29549
2022-03-05 22:35:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:35:36 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.533 | nll_loss 12.78 | ppl 7035.43 | wps 46616.5 | wpb 510.9 | bsz 1 | num_updates 12510 | best_loss 9.173
2022-03-05 22:35:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12510 updates
2022-03-05 22:35:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:35:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:35:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 257 @ 12510 updates, score 13.533) (writing took 1.6618368374183774 seconds)
2022-03-05 22:35:37 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-05 22:35:37 | INFO | train | epoch 257 | loss 2.725 | nll_loss 0.539 | ppl 1.45 | wps 27691.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12510 | lr 0.00028273 | gnorm 0.591 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29576
2022-03-05 22:35:37 | INFO | fairseq.trainer | begin training epoch 258
2022-03-05 22:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:37:31 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.472 | nll_loss 12.699 | ppl 6651.63 | wps 46695.9 | wpb 510.9 | bsz 1 | num_updates 12559 | best_loss 9.173
2022-03-05 22:37:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12559 updates
2022-03-05 22:37:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:37:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:37:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 258 @ 12559 updates, score 13.472) (writing took 1.6944908583536744 seconds)
2022-03-05 22:37:32 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-05 22:37:32 | INFO | train | epoch 258 | loss 2.721 | nll_loss 0.536 | ppl 1.45 | wps 27661.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12559 | lr 0.000282178 | gnorm 0.582 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29691
2022-03-05 22:37:32 | INFO | fairseq.trainer | begin training epoch 259
2022-03-05 22:37:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:39:04 | INFO | train_inner | epoch 259:     41 / 49 loss=2.721, nll_loss=0.536, ppl=1.45, wps=27709.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.578, loss_scale=32, train_wall=198, gb_free=21.6, wall=29783
2022-03-05 22:39:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:39:25 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.355 | nll_loss 12.575 | ppl 6101.62 | wps 46477.8 | wpb 510.9 | bsz 1 | num_updates 12607 | best_loss 9.173
2022-03-05 22:39:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12607 updates
2022-03-05 22:39:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:39:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:39:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 259 @ 12607 updates, score 13.355) (writing took 1.6355638280510902 seconds)
2022-03-05 22:39:27 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-05 22:39:27 | INFO | train | epoch 259 | loss 2.719 | nll_loss 0.535 | ppl 1.45 | wps 27135 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12607 | lr 0.00028164 | gnorm 0.573 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29806
2022-03-05 22:39:27 | INFO | fairseq.trainer | begin training epoch 260
2022-03-05 22:39:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:41:20 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.428 | nll_loss 12.663 | ppl 6483.85 | wps 46519 | wpb 510.9 | bsz 1 | num_updates 12656 | best_loss 9.173
2022-03-05 22:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12656 updates
2022-03-05 22:41:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:41:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:41:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 260 @ 12656 updates, score 13.428) (writing took 1.6418684292584658 seconds)
2022-03-05 22:41:22 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-05 22:41:22 | INFO | train | epoch 260 | loss 2.718 | nll_loss 0.534 | ppl 1.45 | wps 27713 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12656 | lr 0.000281094 | gnorm 0.574 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29920
2022-03-05 22:41:22 | INFO | fairseq.trainer | begin training epoch 261
2022-03-05 22:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:43:00 | INFO | train_inner | epoch 261:     44 / 49 loss=2.718, nll_loss=0.534, ppl=1.45, wps=27482.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.572, loss_scale=16, train_wall=200, gb_free=21.6, wall=30019
2022-03-05 22:43:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:43:15 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.326 | nll_loss 12.542 | ppl 5964.81 | wps 46466.7 | wpb 510.9 | bsz 1 | num_updates 12705 | best_loss 9.173
2022-03-05 22:43:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12705 updates
2022-03-05 22:43:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:43:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:43:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 261 @ 12705 updates, score 13.326) (writing took 1.6307578412815928 seconds)
2022-03-05 22:43:16 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-05 22:43:16 | INFO | train | epoch 261 | loss 2.716 | nll_loss 0.532 | ppl 1.45 | wps 27707.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12705 | lr 0.000280552 | gnorm 0.565 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 30035
2022-03-05 22:43:16 | INFO | fairseq.trainer | begin training epoch 262
2022-03-05 22:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:45:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:45:09 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.438 | nll_loss 12.663 | ppl 6485.41 | wps 46707.3 | wpb 510.9 | bsz 1 | num_updates 12754 | best_loss 9.173
2022-03-05 22:45:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12754 updates
2022-03-05 22:45:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:45:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:45:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 262 @ 12754 updates, score 13.438) (writing took 1.6586720058694482 seconds)
2022-03-05 22:45:11 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-05 22:45:11 | INFO | train | epoch 262 | loss 2.715 | nll_loss 0.531 | ppl 1.45 | wps 27717.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12754 | lr 0.000280012 | gnorm 0.564 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30150
2022-03-05 22:45:11 | INFO | fairseq.trainer | begin training epoch 263
2022-03-05 22:45:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:46:54 | INFO | train_inner | epoch 263:     46 / 49 loss=2.715, nll_loss=0.531, ppl=1.44, wps=27747.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.568, loss_scale=32, train_wall=198, gb_free=21.6, wall=30253
2022-03-05 22:46:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:47:04 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.52 | nll_loss 12.758 | ppl 6925.27 | wps 46436.9 | wpb 510.9 | bsz 1 | num_updates 12803 | best_loss 9.173
2022-03-05 22:47:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12803 updates
2022-03-05 22:47:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:47:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:47:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 263 @ 12803 updates, score 13.52) (writing took 1.6962787006050348 seconds)
2022-03-05 22:47:06 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-05 22:47:06 | INFO | train | epoch 263 | loss 2.714 | nll_loss 0.531 | ppl 1.44 | wps 27693.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12803 | lr 0.000279476 | gnorm 0.574 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30265
2022-03-05 22:47:06 | INFO | fairseq.trainer | begin training epoch 264
2022-03-05 22:47:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:48:59 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.443 | nll_loss 12.673 | ppl 6532.2 | wps 46675.7 | wpb 510.9 | bsz 1 | num_updates 12852 | best_loss 9.173
2022-03-05 22:48:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12852 updates
2022-03-05 22:48:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:49:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:49:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 264 @ 12852 updates, score 13.443) (writing took 1.6302925860509276 seconds)
2022-03-05 22:49:01 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-05 22:49:01 | INFO | train | epoch 264 | loss 2.712 | nll_loss 0.528 | ppl 1.44 | wps 27697.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12852 | lr 0.000278942 | gnorm 0.572 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30379
2022-03-05 22:49:01 | INFO | fairseq.trainer | begin training epoch 265
2022-03-05 22:49:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:49:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:50:49 | INFO | train_inner | epoch 265:     49 / 49 loss=2.711, nll_loss=0.528, ppl=1.44, wps=27454, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=12900, lr=0.000278423, gnorm=0.573, loss_scale=32, train_wall=199, gb_free=21.6, wall=30488
2022-03-05 22:50:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:50:54 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.506 | nll_loss 12.746 | ppl 6867.37 | wps 46710.1 | wpb 510.9 | bsz 1 | num_updates 12900 | best_loss 9.173
2022-03-05 22:50:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12900 updates
2022-03-05 22:50:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:50:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:50:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 265 @ 12900 updates, score 13.506) (writing took 1.675162261351943 seconds)
2022-03-05 22:50:55 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-05 22:50:55 | INFO | train | epoch 265 | loss 2.71 | nll_loss 0.526 | ppl 1.44 | wps 27134.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12900 | lr 0.000278423 | gnorm 0.572 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30494
2022-03-05 22:50:55 | INFO | fairseq.trainer | begin training epoch 266
2022-03-05 22:50:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:52:48 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.427 | nll_loss 12.658 | ppl 6462.92 | wps 46270.6 | wpb 510.9 | bsz 1 | num_updates 12949 | best_loss 9.173
2022-03-05 22:52:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12949 updates
2022-03-05 22:52:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:52:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:52:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 266 @ 12949 updates, score 13.427) (writing took 1.6892815185710788 seconds)
2022-03-05 22:52:50 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-05 22:52:50 | INFO | train | epoch 266 | loss 2.708 | nll_loss 0.526 | ppl 1.44 | wps 27685.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12949 | lr 0.000277896 | gnorm 0.564 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30609
2022-03-05 22:52:50 | INFO | fairseq.trainer | begin training epoch 267
2022-03-05 22:52:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:54:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:54:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:54:43 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.45 | nll_loss 12.678 | ppl 6553.05 | wps 46575.3 | wpb 510.9 | bsz 1 | num_updates 12997 | best_loss 9.173
2022-03-05 22:54:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12997 updates
2022-03-05 22:54:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:54:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:54:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 267 @ 12997 updates, score 13.45) (writing took 1.6323146615177393 seconds)
2022-03-05 22:54:45 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-05 22:54:45 | INFO | train | epoch 267 | loss 2.707 | nll_loss 0.525 | ppl 1.44 | wps 27155.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12997 | lr 0.000277382 | gnorm 0.565 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30723
2022-03-05 22:54:45 | INFO | fairseq.trainer | begin training epoch 268
2022-03-05 22:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:54:52 | INFO | train_inner | epoch 268:      3 / 49 loss=2.708, nll_loss=0.525, ppl=1.44, wps=26739.6, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.565, loss_scale=32, train_wall=200, gb_free=21.6, wall=30730
2022-03-05 22:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:56:38 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.416 | nll_loss 12.647 | ppl 6415.89 | wps 46600.3 | wpb 510.9 | bsz 1 | num_updates 13046 | best_loss 9.173
2022-03-05 22:56:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13046 updates
2022-03-05 22:56:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:56:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:56:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 268 @ 13046 updates, score 13.416) (writing took 1.6534900553524494 seconds)
2022-03-05 22:56:39 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-05 22:56:39 | INFO | train | epoch 268 | loss 2.706 | nll_loss 0.523 | ppl 1.44 | wps 27705.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13046 | lr 0.000276861 | gnorm 0.559 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30838
2022-03-05 22:56:39 | INFO | fairseq.trainer | begin training epoch 269
2022-03-05 22:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:58:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:58:32 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.497 | nll_loss 12.733 | ppl 6809.26 | wps 46562.9 | wpb 510.9 | bsz 1 | num_updates 13095 | best_loss 9.173
2022-03-05 22:58:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13095 updates
2022-03-05 22:58:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:58:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 22:58:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 269 @ 13095 updates, score 13.497) (writing took 1.6795291490852833 seconds)
2022-03-05 22:58:34 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-05 22:58:34 | INFO | train | epoch 269 | loss 2.704 | nll_loss 0.522 | ppl 1.44 | wps 27722.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13095 | lr 0.000276342 | gnorm 0.567 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30953
2022-03-05 22:58:34 | INFO | fairseq.trainer | begin training epoch 270
2022-03-05 22:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:58:45 | INFO | train_inner | epoch 270:      5 / 49 loss=2.704, nll_loss=0.522, ppl=1.44, wps=27740.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.561, loss_scale=32, train_wall=198, gb_free=21.6, wall=30964
2022-03-05 22:59:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:00:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:00:27 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.441 | nll_loss 12.667 | ppl 6505.47 | wps 46517.8 | wpb 510.9 | bsz 1 | num_updates 13143 | best_loss 9.173
2022-03-05 23:00:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13143 updates
2022-03-05 23:00:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:00:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:00:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 270 @ 13143 updates, score 13.441) (writing took 1.6281576557084918 seconds)
2022-03-05 23:00:29 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-05 23:00:29 | INFO | train | epoch 270 | loss 2.702 | nll_loss 0.52 | ppl 1.43 | wps 27129.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13143 | lr 0.000275837 | gnorm 0.561 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31067
2022-03-05 23:00:29 | INFO | fairseq.trainer | begin training epoch 271
2022-03-05 23:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:02:22 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.44 | nll_loss 12.671 | ppl 6520.73 | wps 46510.7 | wpb 510.9 | bsz 1 | num_updates 13192 | best_loss 9.173
2022-03-05 23:02:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13192 updates
2022-03-05 23:02:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:02:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 271 @ 13192 updates, score 13.44) (writing took 1.6119103115051985 seconds)
2022-03-05 23:02:23 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-05 23:02:23 | INFO | train | epoch 271 | loss 2.701 | nll_loss 0.519 | ppl 1.43 | wps 27714.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13192 | lr 0.000275324 | gnorm 0.555 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31182
2022-03-05 23:02:23 | INFO | fairseq.trainer | begin training epoch 272
2022-03-05 23:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:02:41 | INFO | train_inner | epoch 272:      8 / 49 loss=2.701, nll_loss=0.519, ppl=1.43, wps=27483.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.559, loss_scale=32, train_wall=200, gb_free=21.6, wall=31200
2022-03-05 23:04:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:04:16 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.522 | nll_loss 12.764 | ppl 6958.06 | wps 46580 | wpb 510.9 | bsz 1 | num_updates 13241 | best_loss 9.173
2022-03-05 23:04:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13241 updates
2022-03-05 23:04:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:04:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:04:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 272 @ 13241 updates, score 13.522) (writing took 1.6297952104359865 seconds)
2022-03-05 23:04:18 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-05 23:04:18 | INFO | train | epoch 272 | loss 2.7 | nll_loss 0.519 | ppl 1.43 | wps 27718 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13241 | lr 0.000274814 | gnorm 0.566 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31297
2022-03-05 23:04:18 | INFO | fairseq.trainer | begin training epoch 273
2022-03-05 23:04:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:04:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:06:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:06:11 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.437 | nll_loss 12.672 | ppl 6527.23 | wps 46608.7 | wpb 510.9 | bsz 1 | num_updates 13289 | best_loss 9.173
2022-03-05 23:06:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13289 updates
2022-03-05 23:06:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:06:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:06:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 273 @ 13289 updates, score 13.437) (writing took 1.6535697039216757 seconds)
2022-03-05 23:06:13 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-05 23:06:13 | INFO | train | epoch 273 | loss 2.698 | nll_loss 0.517 | ppl 1.43 | wps 27137.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13289 | lr 0.000274318 | gnorm 0.551 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31412
2022-03-05 23:06:13 | INFO | fairseq.trainer | begin training epoch 274
2022-03-05 23:06:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:06:37 | INFO | train_inner | epoch 274:     11 / 49 loss=2.699, nll_loss=0.517, ppl=1.43, wps=27485.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.558, loss_scale=32, train_wall=200, gb_free=21.6, wall=31436
2022-03-05 23:08:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:08:06 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 13.288 | nll_loss 12.497 | ppl 5782.35 | wps 46477.4 | wpb 510.9 | bsz 1 | num_updates 13338 | best_loss 9.173
2022-03-05 23:08:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13338 updates
2022-03-05 23:08:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:08:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 274 @ 13338 updates, score 13.288) (writing took 1.694045189768076 seconds)
2022-03-05 23:08:08 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-05 23:08:08 | INFO | train | epoch 274 | loss 2.697 | nll_loss 0.516 | ppl 1.43 | wps 27680.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13338 | lr 0.000273813 | gnorm 0.556 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31526
2022-03-05 23:08:08 | INFO | fairseq.trainer | begin training epoch 275
2022-03-05 23:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:09:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:09:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:10:01 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.302 | nll_loss 12.521 | ppl 5876.8 | wps 46858.2 | wpb 510.9 | bsz 1 | num_updates 13386 | best_loss 9.173
2022-03-05 23:10:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13386 updates
2022-03-05 23:10:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:10:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:10:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 275 @ 13386 updates, score 13.302) (writing took 1.6449161693453789 seconds)
2022-03-05 23:10:02 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-05 23:10:02 | INFO | train | epoch 275 | loss 2.695 | nll_loss 0.514 | ppl 1.43 | wps 27124.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13386 | lr 0.000273322 | gnorm 0.566 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31641
2022-03-05 23:10:02 | INFO | fairseq.trainer | begin training epoch 276
2022-03-05 23:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:10:34 | INFO | train_inner | epoch 276:     14 / 49 loss=2.696, nll_loss=0.515, ppl=1.43, wps=27459.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.563, loss_scale=32, train_wall=200, gb_free=21.6, wall=31672
2022-03-05 23:11:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:11:55 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.398 | nll_loss 12.625 | ppl 6316.44 | wps 46550.5 | wpb 510.9 | bsz 1 | num_updates 13435 | best_loss 9.173
2022-03-05 23:11:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13435 updates
2022-03-05 23:11:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:11:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:11:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 276 @ 13435 updates, score 13.398) (writing took 1.6600134810432792 seconds)
2022-03-05 23:11:57 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-05 23:11:57 | INFO | train | epoch 276 | loss 2.693 | nll_loss 0.513 | ppl 1.43 | wps 27691.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13435 | lr 0.000272823 | gnorm 0.553 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31756
2022-03-05 23:11:57 | INFO | fairseq.trainer | begin training epoch 277
2022-03-05 23:11:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:13:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:13:50 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.402 | nll_loss 12.627 | ppl 6327.15 | wps 46445.8 | wpb 510.9 | bsz 1 | num_updates 13484 | best_loss 9.173
2022-03-05 23:13:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13484 updates
2022-03-05 23:13:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:13:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:13:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 277 @ 13484 updates, score 13.402) (writing took 1.6428904812783003 seconds)
2022-03-05 23:13:52 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-05 23:13:52 | INFO | train | epoch 277 | loss 2.692 | nll_loss 0.512 | ppl 1.43 | wps 27688.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13484 | lr 0.000272327 | gnorm 0.556 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31871
2022-03-05 23:13:52 | INFO | fairseq.trainer | begin training epoch 278
2022-03-05 23:13:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:14:28 | INFO | train_inner | epoch 278:     16 / 49 loss=2.692, nll_loss=0.512, ppl=1.43, wps=27723.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.554, loss_scale=32, train_wall=198, gb_free=21.6, wall=31906
2022-03-05 23:14:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:15:45 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.483 | nll_loss 12.725 | ppl 6768.78 | wps 46544.2 | wpb 510.9 | bsz 1 | num_updates 13532 | best_loss 9.173
2022-03-05 23:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13532 updates
2022-03-05 23:15:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:15:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 278 @ 13532 updates, score 13.483) (writing took 1.6576743964105844 seconds)
2022-03-05 23:15:47 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-05 23:15:47 | INFO | train | epoch 278 | loss 2.69 | nll_loss 0.51 | ppl 1.42 | wps 27138.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13532 | lr 0.000271844 | gnorm 0.557 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31985
2022-03-05 23:15:47 | INFO | fairseq.trainer | begin training epoch 279
2022-03-05 23:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:17:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:17:40 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.43 | nll_loss 12.663 | ppl 6484.83 | wps 46644.6 | wpb 510.9 | bsz 1 | num_updates 13581 | best_loss 9.173
2022-03-05 23:17:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13581 updates
2022-03-05 23:17:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:17:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:17:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 279 @ 13581 updates, score 13.43) (writing took 1.6635794211179018 seconds)
2022-03-05 23:17:41 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-05 23:17:41 | INFO | train | epoch 279 | loss 2.689 | nll_loss 0.509 | ppl 1.42 | wps 27730.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13581 | lr 0.000271353 | gnorm 0.55 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32100
2022-03-05 23:17:41 | INFO | fairseq.trainer | begin training epoch 280
2022-03-05 23:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:18:24 | INFO | train_inner | epoch 280:     19 / 49 loss=2.689, nll_loss=0.509, ppl=1.42, wps=27483.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.55, loss_scale=32, train_wall=200, gb_free=21.6, wall=32142
2022-03-05 23:19:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:19:34 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.528 | nll_loss 12.774 | ppl 7005.41 | wps 46644.1 | wpb 510.9 | bsz 1 | num_updates 13630 | best_loss 9.173
2022-03-05 23:19:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13630 updates
2022-03-05 23:19:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:19:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:19:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 280 @ 13630 updates, score 13.528) (writing took 1.6300175171345472 seconds)
2022-03-05 23:19:36 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-05 23:19:36 | INFO | train | epoch 280 | loss 2.688 | nll_loss 0.508 | ppl 1.42 | wps 27712.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13630 | lr 0.000270864 | gnorm 0.555 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32215
2022-03-05 23:19:36 | INFO | fairseq.trainer | begin training epoch 281
2022-03-05 23:19:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:20:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:21:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:21:29 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.353 | nll_loss 12.568 | ppl 6072.81 | wps 46687.1 | wpb 510.9 | bsz 1 | num_updates 13678 | best_loss 9.173
2022-03-05 23:21:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13678 updates
2022-03-05 23:21:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:21:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:21:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 281 @ 13678 updates, score 13.353) (writing took 1.6512042414397001 seconds)
2022-03-05 23:21:31 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-05 23:21:31 | INFO | train | epoch 281 | loss 2.686 | nll_loss 0.507 | ppl 1.42 | wps 27115.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13678 | lr 0.000270389 | gnorm 0.557 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32329
2022-03-05 23:21:31 | INFO | fairseq.trainer | begin training epoch 282
2022-03-05 23:21:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:22:20 | INFO | train_inner | epoch 282:     22 / 49 loss=2.686, nll_loss=0.507, ppl=1.42, wps=27473.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.558, loss_scale=32, train_wall=200, gb_free=21.6, wall=32379
2022-03-05 23:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:23:24 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.536 | nll_loss 12.778 | ppl 7021.27 | wps 46619.6 | wpb 510.9 | bsz 1 | num_updates 13727 | best_loss 9.173
2022-03-05 23:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13727 updates
2022-03-05 23:23:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:23:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:23:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 282 @ 13727 updates, score 13.536) (writing took 1.700876665301621 seconds)
2022-03-05 23:23:25 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-05 23:23:25 | INFO | train | epoch 282 | loss 2.685 | nll_loss 0.506 | ppl 1.42 | wps 27686.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13727 | lr 0.000269906 | gnorm 0.555 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32444
2022-03-05 23:23:25 | INFO | fairseq.trainer | begin training epoch 283
2022-03-05 23:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:25:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:25:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:25:19 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.464 | nll_loss 12.706 | ppl 6681.2 | wps 46657.7 | wpb 510.9 | bsz 1 | num_updates 13775 | best_loss 9.173
2022-03-05 23:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13775 updates
2022-03-05 23:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:25:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 283 @ 13775 updates, score 13.464) (writing took 1.678887840360403 seconds)
2022-03-05 23:25:20 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-05 23:25:20 | INFO | train | epoch 283 | loss 2.683 | nll_loss 0.504 | ppl 1.42 | wps 27117.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13775 | lr 0.000269435 | gnorm 0.543 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32559
2022-03-05 23:25:20 | INFO | fairseq.trainer | begin training epoch 284
2022-03-05 23:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:26:16 | INFO | train_inner | epoch 284:     25 / 49 loss=2.683, nll_loss=0.505, ppl=1.42, wps=27451.9, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.546, loss_scale=32, train_wall=200, gb_free=21.6, wall=32615
2022-03-05 23:27:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:27:13 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.528 | nll_loss 12.772 | ppl 6996.4 | wps 46658.4 | wpb 510.9 | bsz 1 | num_updates 13824 | best_loss 9.173
2022-03-05 23:27:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13824 updates
2022-03-05 23:27:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:27:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:27:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 284 @ 13824 updates, score 13.528) (writing took 1.6350648328661919 seconds)
2022-03-05 23:27:15 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-05 23:27:15 | INFO | train | epoch 284 | loss 2.682 | nll_loss 0.504 | ppl 1.42 | wps 27698 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13824 | lr 0.000268957 | gnorm 0.547 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32674
2022-03-05 23:27:15 | INFO | fairseq.trainer | begin training epoch 285
2022-03-05 23:27:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:29:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:29:08 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.388 | nll_loss 12.613 | ppl 6264.2 | wps 45925.1 | wpb 510.9 | bsz 1 | num_updates 13873 | best_loss 9.173
2022-03-05 23:29:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13873 updates
2022-03-05 23:29:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:29:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 285 @ 13873 updates, score 13.388) (writing took 1.6595923732966185 seconds)
2022-03-05 23:29:10 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-05 23:29:10 | INFO | train | epoch 285 | loss 2.68 | nll_loss 0.502 | ppl 1.42 | wps 27682.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13873 | lr 0.000268482 | gnorm 0.545 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32788
2022-03-05 23:29:10 | INFO | fairseq.trainer | begin training epoch 286
2022-03-05 23:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:30:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:30:12 | INFO | train_inner | epoch 286:     28 / 49 loss=2.681, nll_loss=0.502, ppl=1.42, wps=27463.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.546, loss_scale=32, train_wall=200, gb_free=21.6, wall=32851
2022-03-05 23:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:31:03 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.437 | nll_loss 12.676 | ppl 6544.65 | wps 46820.4 | wpb 510.9 | bsz 1 | num_updates 13921 | best_loss 9.173
2022-03-05 23:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13921 updates
2022-03-05 23:31:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:31:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:31:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 286 @ 13921 updates, score 13.437) (writing took 1.67381686065346 seconds)
2022-03-05 23:31:05 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-05 23:31:05 | INFO | train | epoch 286 | loss 2.678 | nll_loss 0.5 | ppl 1.41 | wps 27136.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13921 | lr 0.000268019 | gnorm 0.54 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32903
2022-03-05 23:31:05 | INFO | fairseq.trainer | begin training epoch 287
2022-03-05 23:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:32:58 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.508 | nll_loss 12.757 | ppl 6920.55 | wps 46509.4 | wpb 510.9 | bsz 1 | num_updates 13970 | best_loss 9.173
2022-03-05 23:32:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13970 updates
2022-03-05 23:32:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:32:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:32:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 287 @ 13970 updates, score 13.508) (writing took 1.6928258948028088 seconds)
2022-03-05 23:32:59 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-05 23:32:59 | INFO | train | epoch 287 | loss 2.679 | nll_loss 0.501 | ppl 1.42 | wps 27678.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13970 | lr 0.000267548 | gnorm 0.546 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33018
2022-03-05 23:32:59 | INFO | fairseq.trainer | begin training epoch 288
2022-03-05 23:32:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:34:06 | INFO | train_inner | epoch 288:     30 / 49 loss=2.678, nll_loss=0.5, ppl=1.41, wps=27722.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.544, loss_scale=32, train_wall=198, gb_free=21.6, wall=33085
2022-03-05 23:34:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:34:52 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.437 | nll_loss 12.67 | ppl 6517.79 | wps 46544 | wpb 510.9 | bsz 1 | num_updates 14019 | best_loss 9.173
2022-03-05 23:34:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14019 updates
2022-03-05 23:34:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:34:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:34:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 288 @ 14019 updates, score 13.437) (writing took 1.661807918921113 seconds)
2022-03-05 23:34:54 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-05 23:34:54 | INFO | train | epoch 288 | loss 2.677 | nll_loss 0.5 | ppl 1.41 | wps 27692.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14019 | lr 0.00026708 | gnorm 0.549 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33133
2022-03-05 23:34:54 | INFO | fairseq.trainer | begin training epoch 289
2022-03-05 23:34:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:35:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:36:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:36:47 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.359 | nll_loss 12.591 | ppl 6171.55 | wps 46578.5 | wpb 510.9 | bsz 1 | num_updates 14067 | best_loss 9.173
2022-03-05 23:36:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14067 updates
2022-03-05 23:36:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:36:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:36:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 289 @ 14067 updates, score 13.359) (writing took 1.6503679044544697 seconds)
2022-03-05 23:36:49 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-05 23:36:49 | INFO | train | epoch 289 | loss 2.675 | nll_loss 0.498 | ppl 1.41 | wps 27127.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14067 | lr 0.000266624 | gnorm 0.545 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33248
2022-03-05 23:36:49 | INFO | fairseq.trainer | begin training epoch 290
2022-03-05 23:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:38:03 | INFO | train_inner | epoch 290:     33 / 49 loss=2.676, nll_loss=0.498, ppl=1.41, wps=27465.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.542, loss_scale=32, train_wall=200, gb_free=21.6, wall=33321
2022-03-05 23:38:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:38:42 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.453 | nll_loss 12.692 | ppl 6618.04 | wps 46549.2 | wpb 510.9 | bsz 1 | num_updates 14116 | best_loss 9.173
2022-03-05 23:38:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14116 updates
2022-03-05 23:38:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:38:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:38:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 290 @ 14116 updates, score 13.453) (writing took 1.7181726954877377 seconds)
2022-03-05 23:38:44 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-05 23:38:44 | INFO | train | epoch 290 | loss 2.674 | nll_loss 0.497 | ppl 1.41 | wps 27696.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14116 | lr 0.000266161 | gnorm 0.541 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33362
2022-03-05 23:38:44 | INFO | fairseq.trainer | begin training epoch 291
2022-03-05 23:38:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:40:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:40:37 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.479 | nll_loss 12.717 | ppl 6733.16 | wps 46589.1 | wpb 510.9 | bsz 1 | num_updates 14164 | best_loss 9.173
2022-03-05 23:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14164 updates
2022-03-05 23:40:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 291 @ 14164 updates, score 13.479) (writing took 1.6592381382361054 seconds)
2022-03-05 23:40:38 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-05 23:40:38 | INFO | train | epoch 291 | loss 2.673 | nll_loss 0.497 | ppl 1.41 | wps 27121.6 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 14164 | lr 0.000265709 | gnorm 0.542 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33477
2022-03-05 23:40:38 | INFO | fairseq.trainer | begin training epoch 292
2022-03-05 23:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:41:59 | INFO | train_inner | epoch 292:     36 / 49 loss=2.673, nll_loss=0.496, ppl=1.41, wps=27471.9, ups=0.42, wpb=64880.6, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.545, loss_scale=32, train_wall=200, gb_free=21.6, wall=33557
2022-03-05 23:42:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:42:31 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.448 | nll_loss 12.689 | ppl 6602.79 | wps 46517 | wpb 510.9 | bsz 1 | num_updates 14213 | best_loss 9.173
2022-03-05 23:42:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14213 updates
2022-03-05 23:42:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:42:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:42:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 292 @ 14213 updates, score 13.448) (writing took 1.6094824383035302 seconds)
2022-03-05 23:42:33 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-05 23:42:33 | INFO | train | epoch 292 | loss 2.672 | nll_loss 0.495 | ppl 1.41 | wps 27718.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14213 | lr 0.000265251 | gnorm 0.548 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33592
2022-03-05 23:42:33 | INFO | fairseq.trainer | begin training epoch 293
2022-03-05 23:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:44:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:44:26 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 13.379 | nll_loss 12.61 | ppl 6252.78 | wps 46668.8 | wpb 510.9 | bsz 1 | num_updates 14262 | best_loss 9.173
2022-03-05 23:44:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14262 updates
2022-03-05 23:44:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:44:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:44:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 293 @ 14262 updates, score 13.379) (writing took 1.645891172811389 seconds)
2022-03-05 23:44:28 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-05 23:44:28 | INFO | train | epoch 293 | loss 2.671 | nll_loss 0.495 | ppl 1.41 | wps 27713.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14262 | lr 0.000264795 | gnorm 0.536 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33706
2022-03-05 23:44:28 | INFO | fairseq.trainer | begin training epoch 294
2022-03-05 23:44:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:45:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:45:55 | INFO | train_inner | epoch 294:     39 / 49 loss=2.67, nll_loss=0.494, ppl=1.41, wps=27468.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.541, loss_scale=32, train_wall=200, gb_free=21.6, wall=33794
2022-03-05 23:45:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 23:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:46:21 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.615 | nll_loss 12.874 | ppl 7507.57 | wps 46497.6 | wpb 510.9 | bsz 1 | num_updates 14309 | best_loss 9.173
2022-03-05 23:46:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14309 updates
2022-03-05 23:46:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:46:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 294 @ 14309 updates, score 13.615) (writing took 1.6912192571908236 seconds)
2022-03-05 23:46:23 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-05 23:46:23 | INFO | train | epoch 294 | loss 2.668 | nll_loss 0.491 | ppl 1.41 | wps 26533.2 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 14309 | lr 0.00026436 | gnorm 0.539 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 33821
2022-03-05 23:46:23 | INFO | fairseq.trainer | begin training epoch 295
2022-03-05 23:46:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:48:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:48:16 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.496 | nll_loss 12.744 | ppl 6861.18 | wps 46519.4 | wpb 510.9 | bsz 1 | num_updates 14358 | best_loss 9.173
2022-03-05 23:48:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14358 updates
2022-03-05 23:48:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:48:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:48:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 295 @ 14358 updates, score 13.496) (writing took 1.6910121897235513 seconds)
2022-03-05 23:48:17 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-05 23:48:17 | INFO | train | epoch 295 | loss 2.669 | nll_loss 0.493 | ppl 1.41 | wps 27706.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14358 | lr 0.000263908 | gnorm 0.532 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 33936
2022-03-05 23:48:17 | INFO | fairseq.trainer | begin training epoch 296
2022-03-05 23:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:49:51 | INFO | train_inner | epoch 296:     42 / 49 loss=2.668, nll_loss=0.492, ppl=1.41, wps=27472.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.537, loss_scale=16, train_wall=200, gb_free=21.6, wall=34030
2022-03-05 23:50:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:50:10 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 13.499 | nll_loss 12.751 | ppl 6893.76 | wps 46540.4 | wpb 510.9 | bsz 1 | num_updates 14407 | best_loss 9.173
2022-03-05 23:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14407 updates
2022-03-05 23:50:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:50:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 296 @ 14407 updates, score 13.499) (writing took 1.667373980395496 seconds)
2022-03-05 23:50:12 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-05 23:50:12 | INFO | train | epoch 296 | loss 2.667 | nll_loss 0.491 | ppl 1.41 | wps 27702.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14407 | lr 0.000263459 | gnorm 0.546 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 34051
2022-03-05 23:50:12 | INFO | fairseq.trainer | begin training epoch 297
2022-03-05 23:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:52:05 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 13.411 | nll_loss 12.646 | ppl 6408.05 | wps 46711.6 | wpb 510.9 | bsz 1 | num_updates 14456 | best_loss 9.173
2022-03-05 23:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14456 updates
2022-03-05 23:52:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:52:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:52:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 297 @ 14456 updates, score 13.411) (writing took 1.6328172096982598 seconds)
2022-03-05 23:52:07 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-05 23:52:07 | INFO | train | epoch 297 | loss 2.665 | nll_loss 0.49 | ppl 1.4 | wps 27705.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14456 | lr 0.000263012 | gnorm 0.522 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34165
2022-03-05 23:52:07 | INFO | fairseq.trainer | begin training epoch 298
2022-03-05 23:52:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:53:45 | INFO | train_inner | epoch 298:     44 / 49 loss=2.665, nll_loss=0.49, ppl=1.4, wps=27736.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.533, loss_scale=32, train_wall=198, gb_free=21.6, wall=34264
2022-03-05 23:53:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:54:00 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.487 | nll_loss 12.734 | ppl 6811.64 | wps 46517.5 | wpb 510.9 | bsz 1 | num_updates 14505 | best_loss 9.173
2022-03-05 23:54:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14505 updates
2022-03-05 23:54:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:54:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:54:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 298 @ 14505 updates, score 13.487) (writing took 1.6374303717166185 seconds)
2022-03-05 23:54:01 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-05 23:54:01 | INFO | train | epoch 298 | loss 2.665 | nll_loss 0.49 | ppl 1.4 | wps 27703.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14505 | lr 0.000262568 | gnorm 0.541 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34280
2022-03-05 23:54:01 | INFO | fairseq.trainer | begin training epoch 299
2022-03-05 23:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:55:54 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.529 | nll_loss 12.778 | ppl 7022.72 | wps 46500.8 | wpb 510.9 | bsz 1 | num_updates 14554 | best_loss 9.173
2022-03-05 23:55:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14554 updates
2022-03-05 23:55:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:55:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:55:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 299 @ 14554 updates, score 13.529) (writing took 1.6981727639213204 seconds)
2022-03-05 23:55:56 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-05 23:55:56 | INFO | train | epoch 299 | loss 2.663 | nll_loss 0.488 | ppl 1.4 | wps 27688.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14554 | lr 0.000262125 | gnorm 0.535 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34395
2022-03-05 23:55:56 | INFO | fairseq.trainer | begin training epoch 300
2022-03-05 23:55:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:56:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:57:41 | INFO | train_inner | epoch 300:     47 / 49 loss=2.663, nll_loss=0.488, ppl=1.4, wps=27456.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.533, loss_scale=32, train_wall=200, gb_free=21.6, wall=34500
2022-03-05 23:57:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:57:49 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 13.472 | nll_loss 12.713 | ppl 6712.68 | wps 46407.2 | wpb 510.9 | bsz 1 | num_updates 14602 | best_loss 9.173
2022-03-05 23:57:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14602 updates
2022-03-05 23:57:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:57:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:57:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 300 @ 14602 updates, score 13.472) (writing took 1.6800095038488507 seconds)
2022-03-05 23:57:51 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-05 23:57:51 | INFO | train | epoch 300 | loss 2.662 | nll_loss 0.487 | ppl 1.4 | wps 27102.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14602 | lr 0.000261694 | gnorm 0.529 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34510
2022-03-05 23:57:51 | INFO | fairseq.trainer | begin training epoch 301
2022-03-05 23:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:59:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:59:44 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.405 | nll_loss 12.643 | ppl 6398.21 | wps 46434.3 | wpb 510.9 | bsz 1 | num_updates 14651 | best_loss 9.173
2022-03-05 23:59:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14651 updates
2022-03-05 23:59:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:59:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-05 23:59:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 301 @ 14651 updates, score 13.405) (writing took 1.6552688712254167 seconds)
2022-03-05 23:59:46 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-05 23:59:46 | INFO | train | epoch 301 | loss 2.661 | nll_loss 0.486 | ppl 1.4 | wps 27689.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14651 | lr 0.000261256 | gnorm 0.534 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34624
2022-03-05 23:59:46 | INFO | fairseq.trainer | begin training epoch 302
2022-03-05 23:59:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:01:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:01:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:01:39 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.483 | nll_loss 12.728 | ppl 6786.5 | wps 46583.5 | wpb 510.9 | bsz 1 | num_updates 14699 | best_loss 9.173
2022-03-06 00:01:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14699 updates
2022-03-06 00:01:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:01:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:01:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 302 @ 14699 updates, score 13.483) (writing took 1.6614483846351504 seconds)
2022-03-06 00:01:41 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-06 00:01:41 | INFO | train | epoch 302 | loss 2.659 | nll_loss 0.484 | ppl 1.4 | wps 27100.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14699 | lr 0.000260829 | gnorm 0.523 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34739
2022-03-06 00:01:41 | INFO | fairseq.trainer | begin training epoch 303
2022-03-06 00:01:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:01:43 | INFO | train_inner | epoch 303:      1 / 49 loss=2.66, nll_loss=0.485, ppl=1.4, wps=26698.8, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=14700, lr=0.00026082, gnorm=0.529, loss_scale=32, train_wall=199, gb_free=21.6, wall=34742
2022-03-06 00:03:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:03:34 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.519 | nll_loss 12.775 | ppl 7010.15 | wps 46478.5 | wpb 510.9 | bsz 1 | num_updates 14748 | best_loss 9.173
2022-03-06 00:03:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14748 updates
2022-03-06 00:03:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:03:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:03:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 303 @ 14748 updates, score 13.519) (writing took 1.7214644895866513 seconds)
2022-03-06 00:03:35 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-06 00:03:35 | INFO | train | epoch 303 | loss 2.658 | nll_loss 0.484 | ppl 1.4 | wps 27670.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14748 | lr 0.000260395 | gnorm 0.524 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34854
2022-03-06 00:03:35 | INFO | fairseq.trainer | begin training epoch 304
2022-03-06 00:03:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:05:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:05:29 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 13.37 | nll_loss 12.599 | ppl 6204.63 | wps 46500.1 | wpb 510.9 | bsz 1 | num_updates 14797 | best_loss 9.173
2022-03-06 00:05:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14797 updates
2022-03-06 00:05:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:05:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:05:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 304 @ 14797 updates, score 13.37) (writing took 1.655083678662777 seconds)
2022-03-06 00:05:30 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-06 00:05:30 | INFO | train | epoch 304 | loss 2.658 | nll_loss 0.485 | ppl 1.4 | wps 27685.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14797 | lr 0.000259964 | gnorm 0.534 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34969
2022-03-06 00:05:30 | INFO | fairseq.trainer | begin training epoch 305
2022-03-06 00:05:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:05:37 | INFO | train_inner | epoch 305:      3 / 49 loss=2.658, nll_loss=0.484, ppl=1.4, wps=27707.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.529, loss_scale=32, train_wall=198, gb_free=21.6, wall=34976
2022-03-06 00:06:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:07:23 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.424 | nll_loss 12.665 | ppl 6496.59 | wps 46590.7 | wpb 510.9 | bsz 1 | num_updates 14845 | best_loss 9.173
2022-03-06 00:07:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14845 updates
2022-03-06 00:07:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:07:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:07:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 305 @ 14845 updates, score 13.424) (writing took 1.6848790543153882 seconds)
2022-03-06 00:07:25 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-06 00:07:25 | INFO | train | epoch 305 | loss 2.656 | nll_loss 0.482 | ppl 1.4 | wps 27129.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14845 | lr 0.000259543 | gnorm 0.532 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35084
2022-03-06 00:07:25 | INFO | fairseq.trainer | begin training epoch 306
2022-03-06 00:07:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:09:18 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 13.521 | nll_loss 12.769 | ppl 6977.79 | wps 46645.2 | wpb 510.9 | bsz 1 | num_updates 14894 | best_loss 9.173
2022-03-06 00:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14894 updates
2022-03-06 00:09:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:09:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:09:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 306 @ 14894 updates, score 13.521) (writing took 1.6796334190294147 seconds)
2022-03-06 00:09:20 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-06 00:09:20 | INFO | train | epoch 306 | loss 2.656 | nll_loss 0.482 | ppl 1.4 | wps 27711.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14894 | lr 0.000259116 | gnorm 0.533 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35198
2022-03-06 00:09:20 | INFO | fairseq.trainer | begin training epoch 307
2022-03-06 00:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:09:33 | INFO | train_inner | epoch 307:      6 / 49 loss=2.656, nll_loss=0.482, ppl=1.4, wps=27478.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.532, loss_scale=32, train_wall=200, gb_free=21.6, wall=35212
2022-03-06 00:11:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:11:13 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 13.521 | nll_loss 12.773 | ppl 7001.4 | wps 46686 | wpb 510.9 | bsz 1 | num_updates 14943 | best_loss 9.173
2022-03-06 00:11:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14943 updates
2022-03-06 00:11:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:11:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:11:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 307 @ 14943 updates, score 13.521) (writing took 1.686673098243773 seconds)
2022-03-06 00:11:14 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-06 00:11:14 | INFO | train | epoch 307 | loss 2.654 | nll_loss 0.481 | ppl 1.4 | wps 27720.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14943 | lr 0.000258691 | gnorm 0.527 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35313
2022-03-06 00:11:14 | INFO | fairseq.trainer | begin training epoch 308
2022-03-06 00:11:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:11:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:13:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:13:07 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 13.527 | nll_loss 12.779 | ppl 7028.38 | wps 46569.9 | wpb 510.9 | bsz 1 | num_updates 14991 | best_loss 9.173
2022-03-06 00:13:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14991 updates
2022-03-06 00:13:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:13:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:13:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 308 @ 14991 updates, score 13.527) (writing took 1.6769359773024917 seconds)
2022-03-06 00:13:09 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-06 00:13:09 | INFO | train | epoch 308 | loss 2.652 | nll_loss 0.479 | ppl 1.39 | wps 27124.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14991 | lr 0.000258276 | gnorm 0.53 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35428
2022-03-06 00:13:09 | INFO | fairseq.trainer | begin training epoch 309
2022-03-06 00:13:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:13:29 | INFO | train_inner | epoch 309:      9 / 49 loss=2.653, nll_loss=0.479, ppl=1.39, wps=27470.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.528, loss_scale=32, train_wall=200, gb_free=21.6, wall=35448
2022-03-06 00:14:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:15:02 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 13.43 | nll_loss 12.669 | ppl 6513.58 | wps 46639 | wpb 510.9 | bsz 1 | num_updates 15040 | best_loss 9.173
2022-03-06 00:15:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15040 updates
2022-03-06 00:15:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:15:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:15:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 309 @ 15040 updates, score 13.43) (writing took 1.648434715345502 seconds)
2022-03-06 00:15:04 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-06 00:15:04 | INFO | train | epoch 309 | loss 2.652 | nll_loss 0.479 | ppl 1.39 | wps 27708.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15040 | lr 0.000257855 | gnorm 0.532 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35542
2022-03-06 00:15:04 | INFO | fairseq.trainer | begin training epoch 310
2022-03-06 00:15:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:16:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:16:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:16:57 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.475 | nll_loss 12.728 | ppl 6784.07 | wps 46449.7 | wpb 510.9 | bsz 1 | num_updates 15088 | best_loss 9.173
2022-03-06 00:16:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15088 updates
2022-03-06 00:16:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:16:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:16:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 310 @ 15088 updates, score 13.475) (writing took 1.7005365462973714 seconds)
2022-03-06 00:16:59 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-06 00:16:59 | INFO | train | epoch 310 | loss 2.65 | nll_loss 0.477 | ppl 1.39 | wps 27109.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15088 | lr 0.000257445 | gnorm 0.526 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35657
2022-03-06 00:16:59 | INFO | fairseq.trainer | begin training epoch 311
2022-03-06 00:16:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:17:25 | INFO | train_inner | epoch 311:     12 / 49 loss=2.65, nll_loss=0.478, ppl=1.39, wps=27471.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.53, loss_scale=32, train_wall=200, gb_free=21.6, wall=35684
2022-03-06 00:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:18:52 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.502 | nll_loss 12.758 | ppl 6927.21 | wps 46641.6 | wpb 510.9 | bsz 1 | num_updates 15137 | best_loss 9.173
2022-03-06 00:18:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15137 updates
2022-03-06 00:18:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:18:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:18:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 311 @ 15137 updates, score 13.502) (writing took 1.6512752547860146 seconds)
2022-03-06 00:18:53 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-06 00:18:53 | INFO | train | epoch 311 | loss 2.649 | nll_loss 0.476 | ppl 1.39 | wps 27709 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15137 | lr 0.000257028 | gnorm 0.525 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35772
2022-03-06 00:18:53 | INFO | fairseq.trainer | begin training epoch 312
2022-03-06 00:18:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:20:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:20:47 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 13.468 | nll_loss 12.716 | ppl 6728.16 | wps 46475.3 | wpb 510.9 | bsz 1 | num_updates 15186 | best_loss 9.173
2022-03-06 00:20:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15186 updates
2022-03-06 00:20:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:20:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:20:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 312 @ 15186 updates, score 13.468) (writing took 1.7101420061662793 seconds)
2022-03-06 00:20:48 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-06 00:20:48 | INFO | train | epoch 312 | loss 2.648 | nll_loss 0.476 | ppl 1.39 | wps 27615.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15186 | lr 0.000256613 | gnorm 0.518 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35887
2022-03-06 00:20:48 | INFO | fairseq.trainer | begin training epoch 313
2022-03-06 00:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:21:20 | INFO | train_inner | epoch 313:     14 / 49 loss=2.648, nll_loss=0.476, ppl=1.39, wps=27696.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.52, loss_scale=32, train_wall=198, gb_free=21.6, wall=35918
2022-03-06 00:21:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:22:41 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 13.559 | nll_loss 12.821 | ppl 7237.61 | wps 46471 | wpb 510.9 | bsz 1 | num_updates 15234 | best_loss 9.173
2022-03-06 00:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15234 updates
2022-03-06 00:22:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:22:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:22:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 313 @ 15234 updates, score 13.559) (writing took 1.665693862363696 seconds)
2022-03-06 00:22:43 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-06 00:22:43 | INFO | train | epoch 313 | loss 2.647 | nll_loss 0.475 | ppl 1.39 | wps 27117.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15234 | lr 0.000256208 | gnorm 0.529 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36002
2022-03-06 00:22:43 | INFO | fairseq.trainer | begin training epoch 314
2022-03-06 00:22:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:24:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:24:36 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.491 | nll_loss 12.748 | ppl 6877.46 | wps 46558.6 | wpb 510.9 | bsz 1 | num_updates 15283 | best_loss 9.173
2022-03-06 00:24:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15283 updates
2022-03-06 00:24:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:24:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 314 @ 15283 updates, score 13.491) (writing took 1.6628524772822857 seconds)
2022-03-06 00:24:38 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-06 00:24:38 | INFO | train | epoch 314 | loss 2.646 | nll_loss 0.474 | ppl 1.39 | wps 27718.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15283 | lr 0.000255797 | gnorm 0.518 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36116
2022-03-06 00:24:38 | INFO | fairseq.trainer | begin training epoch 315
2022-03-06 00:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:25:16 | INFO | train_inner | epoch 315:     17 / 49 loss=2.646, nll_loss=0.474, ppl=1.39, wps=27472.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.521, loss_scale=32, train_wall=200, gb_free=21.6, wall=36154
2022-03-06 00:26:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:26:31 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 13.439 | nll_loss 12.683 | ppl 6575.18 | wps 46549.1 | wpb 510.9 | bsz 1 | num_updates 15332 | best_loss 9.173
2022-03-06 00:26:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15332 updates
2022-03-06 00:26:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:26:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:26:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 315 @ 15332 updates, score 13.439) (writing took 1.6749358717352152 seconds)
2022-03-06 00:26:33 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-06 00:26:33 | INFO | train | epoch 315 | loss 2.644 | nll_loss 0.472 | ppl 1.39 | wps 27703.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15332 | lr 0.000255388 | gnorm 0.511 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36231
2022-03-06 00:26:33 | INFO | fairseq.trainer | begin training epoch 316
2022-03-06 00:26:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:27:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:28:26 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 13.469 | nll_loss 12.717 | ppl 6730.59 | wps 46395.6 | wpb 510.9 | bsz 1 | num_updates 15380 | best_loss 9.173
2022-03-06 00:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15380 updates
2022-03-06 00:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:28:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:28:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 316 @ 15380 updates, score 13.469) (writing took 1.6397811258211732 seconds)
2022-03-06 00:28:27 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-06 00:28:27 | INFO | train | epoch 316 | loss 2.644 | nll_loss 0.472 | ppl 1.39 | wps 27133.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15380 | lr 0.000254989 | gnorm 0.521 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36346
2022-03-06 00:28:27 | INFO | fairseq.trainer | begin training epoch 317
2022-03-06 00:28:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:29:12 | INFO | train_inner | epoch 317:     20 / 49 loss=2.644, nll_loss=0.472, ppl=1.39, wps=27472.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.516, loss_scale=32, train_wall=200, gb_free=21.6, wall=36391
2022-03-06 00:30:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:30:20 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 13.459 | nll_loss 12.702 | ppl 6665.47 | wps 46768 | wpb 510.9 | bsz 1 | num_updates 15429 | best_loss 9.173
2022-03-06 00:30:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15429 updates
2022-03-06 00:30:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:30:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:30:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 317 @ 15429 updates, score 13.459) (writing took 1.7207375038415194 seconds)
2022-03-06 00:30:22 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-06 00:30:22 | INFO | train | epoch 317 | loss 2.643 | nll_loss 0.472 | ppl 1.39 | wps 27710.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15429 | lr 0.000254584 | gnorm 0.511 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36461
2022-03-06 00:30:22 | INFO | fairseq.trainer | begin training epoch 318
2022-03-06 00:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:32:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:32:15 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 13.484 | nll_loss 12.74 | ppl 6842.78 | wps 46673.1 | wpb 510.9 | bsz 1 | num_updates 15477 | best_loss 9.173
2022-03-06 00:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15477 updates
2022-03-06 00:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:32:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 318 @ 15477 updates, score 13.484) (writing took 1.6607286464422941 seconds)
2022-03-06 00:32:17 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-06 00:32:17 | INFO | train | epoch 318 | loss 2.642 | nll_loss 0.471 | ppl 1.39 | wps 27109.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15477 | lr 0.000254189 | gnorm 0.521 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36575
2022-03-06 00:32:17 | INFO | fairseq.trainer | begin training epoch 319
2022-03-06 00:32:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:33:08 | INFO | train_inner | epoch 319:     23 / 49 loss=2.642, nll_loss=0.471, ppl=1.39, wps=27457.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.514, loss_scale=32, train_wall=200, gb_free=21.6, wall=36627
2022-03-06 00:34:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:34:10 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 13.438 | nll_loss 12.683 | ppl 6575.14 | wps 46746.1 | wpb 510.9 | bsz 1 | num_updates 15526 | best_loss 9.173
2022-03-06 00:34:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15526 updates
2022-03-06 00:34:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:34:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:34:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 319 @ 15526 updates, score 13.438) (writing took 1.6440465142950416 seconds)
2022-03-06 00:34:11 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-06 00:34:11 | INFO | train | epoch 319 | loss 2.641 | nll_loss 0.47 | ppl 1.39 | wps 27719.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15526 | lr 0.000253787 | gnorm 0.518 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36690
2022-03-06 00:34:11 | INFO | fairseq.trainer | begin training epoch 320
2022-03-06 00:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:36:04 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 13.437 | nll_loss 12.685 | ppl 6586.33 | wps 46745.5 | wpb 510.9 | bsz 1 | num_updates 15575 | best_loss 9.173
2022-03-06 00:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15575 updates
2022-03-06 00:36:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:36:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:36:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 320 @ 15575 updates, score 13.437) (writing took 1.653427223674953 seconds)
2022-03-06 00:36:06 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-06 00:36:06 | INFO | train | epoch 320 | loss 2.64 | nll_loss 0.469 | ppl 1.38 | wps 27760.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15575 | lr 0.000253388 | gnorm 0.518 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36805
2022-03-06 00:36:06 | INFO | fairseq.trainer | begin training epoch 321
2022-03-06 00:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:37:02 | INFO | train_inner | epoch 321:     25 / 49 loss=2.64, nll_loss=0.469, ppl=1.38, wps=27787, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.518, loss_scale=32, train_wall=198, gb_free=21.6, wall=36860
2022-03-06 00:37:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:37:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:37:59 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 13.442 | nll_loss 12.694 | ppl 6626.13 | wps 46740.7 | wpb 510.9 | bsz 1 | num_updates 15623 | best_loss 9.173
2022-03-06 00:37:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15623 updates
2022-03-06 00:37:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:38:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:38:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 321 @ 15623 updates, score 13.442) (writing took 1.6762080499902368 seconds)
2022-03-06 00:38:00 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-06 00:38:00 | INFO | train | epoch 321 | loss 2.639 | nll_loss 0.468 | ppl 1.38 | wps 27156.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15623 | lr 0.000252998 | gnorm 0.52 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36919
2022-03-06 00:38:00 | INFO | fairseq.trainer | begin training epoch 322
2022-03-06 00:38:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:39:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:39:54 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 13.455 | nll_loss 12.702 | ppl 6661.21 | wps 46617.6 | wpb 510.9 | bsz 1 | num_updates 15672 | best_loss 9.173
2022-03-06 00:39:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15672 updates
2022-03-06 00:39:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:39:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:39:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 322 @ 15672 updates, score 13.455) (writing took 1.6695407005026937 seconds)
2022-03-06 00:39:55 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-06 00:39:55 | INFO | train | epoch 322 | loss 2.638 | nll_loss 0.468 | ppl 1.38 | wps 27700.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15672 | lr 0.000252603 | gnorm 0.52 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37034
2022-03-06 00:39:55 | INFO | fairseq.trainer | begin training epoch 323
2022-03-06 00:39:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:40:58 | INFO | train_inner | epoch 323:     28 / 49 loss=2.638, nll_loss=0.468, ppl=1.38, wps=27461.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.521, loss_scale=32, train_wall=200, gb_free=21.6, wall=37097
2022-03-06 00:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:41:48 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 13.354 | nll_loss 12.593 | ppl 6179.46 | wps 46406.4 | wpb 510.9 | bsz 1 | num_updates 15721 | best_loss 9.173
2022-03-06 00:41:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15721 updates
2022-03-06 00:41:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:41:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:41:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 323 @ 15721 updates, score 13.354) (writing took 1.6428023166954517 seconds)
2022-03-06 00:41:50 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-06 00:41:50 | INFO | train | epoch 323 | loss 2.636 | nll_loss 0.466 | ppl 1.38 | wps 27655 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15721 | lr 0.000252209 | gnorm 0.518 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37149
2022-03-06 00:41:50 | INFO | fairseq.trainer | begin training epoch 324
2022-03-06 00:41:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:42:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:43:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:43:43 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.502 | nll_loss 12.755 | ppl 6911.86 | wps 46604.3 | wpb 510.9 | bsz 1 | num_updates 15769 | best_loss 9.173
2022-03-06 00:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15769 updates
2022-03-06 00:43:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:43:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:43:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 324 @ 15769 updates, score 13.502) (writing took 1.6747739808633924 seconds)
2022-03-06 00:43:45 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-06 00:43:45 | INFO | train | epoch 324 | loss 2.635 | nll_loss 0.465 | ppl 1.38 | wps 27128.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15769 | lr 0.000251824 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37264
2022-03-06 00:43:45 | INFO | fairseq.trainer | begin training epoch 325
2022-03-06 00:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:44:54 | INFO | train_inner | epoch 325:     31 / 49 loss=2.635, nll_loss=0.465, ppl=1.38, wps=27452.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.512, loss_scale=32, train_wall=200, gb_free=21.6, wall=37333
2022-03-06 00:45:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:45:38 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.439 | nll_loss 12.685 | ppl 6586.76 | wps 46505.3 | wpb 510.9 | bsz 1 | num_updates 15818 | best_loss 9.173
2022-03-06 00:45:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15818 updates
2022-03-06 00:45:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:45:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:45:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 325 @ 15818 updates, score 13.439) (writing took 1.6805487060919404 seconds)
2022-03-06 00:45:40 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-06 00:45:40 | INFO | train | epoch 325 | loss 2.635 | nll_loss 0.465 | ppl 1.38 | wps 27679.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15818 | lr 0.000251434 | gnorm 0.516 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37378
2022-03-06 00:45:40 | INFO | fairseq.trainer | begin training epoch 326
2022-03-06 00:45:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:47:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:47:33 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.379 | nll_loss 12.621 | ppl 6300.91 | wps 46598.2 | wpb 510.9 | bsz 1 | num_updates 15867 | best_loss 9.173
2022-03-06 00:47:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15867 updates
2022-03-06 00:47:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:47:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:47:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 326 @ 15867 updates, score 13.379) (writing took 1.6910807089880109 seconds)
2022-03-06 00:47:34 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-06 00:47:34 | INFO | train | epoch 326 | loss 2.634 | nll_loss 0.465 | ppl 1.38 | wps 27681.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15867 | lr 0.000251046 | gnorm 0.511 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37493
2022-03-06 00:47:34 | INFO | fairseq.trainer | begin training epoch 327
2022-03-06 00:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:47:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:48:50 | INFO | train_inner | epoch 327:     34 / 49 loss=2.634, nll_loss=0.464, ppl=1.38, wps=27460.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.509, loss_scale=32, train_wall=200, gb_free=21.6, wall=37569
2022-03-06 00:49:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 00:49:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:49:27 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 13.445 | nll_loss 12.693 | ppl 6620.55 | wps 46670 | wpb 510.9 | bsz 1 | num_updates 15914 | best_loss 9.173
2022-03-06 00:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15914 updates
2022-03-06 00:49:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:49:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:49:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 327 @ 15914 updates, score 13.445) (writing took 1.7203787146136165 seconds)
2022-03-06 00:49:29 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-06 00:49:29 | INFO | train | epoch 327 | loss 2.632 | nll_loss 0.463 | ppl 1.38 | wps 26558.1 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 15914 | lr 0.000250675 | gnorm 0.505 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 37608
2022-03-06 00:49:29 | INFO | fairseq.trainer | begin training epoch 328
2022-03-06 00:49:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:51:22 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 13.522 | nll_loss 12.78 | ppl 7030.95 | wps 46577 | wpb 510.9 | bsz 1 | num_updates 15963 | best_loss 9.173
2022-03-06 00:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15963 updates
2022-03-06 00:51:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:51:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 328 @ 15963 updates, score 13.522) (writing took 1.7018770417198539 seconds)
2022-03-06 00:51:24 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-06 00:51:24 | INFO | train | epoch 328 | loss 2.633 | nll_loss 0.464 | ppl 1.38 | wps 27695.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15963 | lr 0.00025029 | gnorm 0.521 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 37723
2022-03-06 00:51:24 | INFO | fairseq.trainer | begin training epoch 329
2022-03-06 00:51:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:52:47 | INFO | train_inner | epoch 329:     37 / 49 loss=2.632, nll_loss=0.463, ppl=1.38, wps=27464, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.512, loss_scale=16, train_wall=200, gb_free=21.6, wall=37805
2022-03-06 00:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:53:17 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 13.476 | nll_loss 12.73 | ppl 6794.07 | wps 46517.2 | wpb 510.9 | bsz 1 | num_updates 16012 | best_loss 9.173
2022-03-06 00:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16012 updates
2022-03-06 00:53:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:53:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:53:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 329 @ 16012 updates, score 13.476) (writing took 1.7182043166831136 seconds)
2022-03-06 00:53:19 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-06 00:53:19 | INFO | train | epoch 329 | loss 2.63 | nll_loss 0.461 | ppl 1.38 | wps 27681.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16012 | lr 0.000249906 | gnorm 0.506 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 37837
2022-03-06 00:53:19 | INFO | fairseq.trainer | begin training epoch 330
2022-03-06 00:53:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:55:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:55:12 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.404 | nll_loss 12.646 | ppl 6410.69 | wps 46495 | wpb 510.9 | bsz 1 | num_updates 16061 | best_loss 9.173
2022-03-06 00:55:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16061 updates
2022-03-06 00:55:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:55:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:55:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 330 @ 16061 updates, score 13.404) (writing took 1.6789996279403567 seconds)
2022-03-06 00:55:14 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-06 00:55:14 | INFO | train | epoch 330 | loss 2.63 | nll_loss 0.461 | ppl 1.38 | wps 27697.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16061 | lr 0.000249525 | gnorm 0.508 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37952
2022-03-06 00:55:14 | INFO | fairseq.trainer | begin training epoch 331
2022-03-06 00:55:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:56:41 | INFO | train_inner | epoch 331:     39 / 49 loss=2.63, nll_loss=0.461, ppl=1.38, wps=27703.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.511, loss_scale=32, train_wall=198, gb_free=21.6, wall=38039
2022-03-06 00:57:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:57:07 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 13.514 | nll_loss 12.772 | ppl 6994.98 | wps 46650.7 | wpb 510.9 | bsz 1 | num_updates 16110 | best_loss 9.173
2022-03-06 00:57:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16110 updates
2022-03-06 00:57:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:57:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:57:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 331 @ 16110 updates, score 13.514) (writing took 1.664976853877306 seconds)
2022-03-06 00:57:08 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-06 00:57:08 | INFO | train | epoch 331 | loss 2.629 | nll_loss 0.46 | ppl 1.38 | wps 27655 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16110 | lr 0.000249145 | gnorm 0.51 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38067
2022-03-06 00:57:08 | INFO | fairseq.trainer | begin training epoch 332
2022-03-06 00:57:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:58:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:59:02 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 13.401 | nll_loss 12.639 | ppl 6376.43 | wps 46500.9 | wpb 510.9 | bsz 1 | num_updates 16159 | best_loss 9.173
2022-03-06 00:59:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16159 updates
2022-03-06 00:59:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:59:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 00:59:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 332 @ 16159 updates, score 13.401) (writing took 1.6814775578677654 seconds)
2022-03-06 00:59:03 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-06 00:59:03 | INFO | train | epoch 332 | loss 2.629 | nll_loss 0.46 | ppl 1.38 | wps 27676.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16159 | lr 0.000248767 | gnorm 0.514 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38182
2022-03-06 00:59:03 | INFO | fairseq.trainer | begin training epoch 333
2022-03-06 00:59:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:59:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:00:37 | INFO | train_inner | epoch 333:     42 / 49 loss=2.628, nll_loss=0.46, ppl=1.38, wps=27448.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.511, loss_scale=32, train_wall=200, gb_free=21.6, wall=38276
2022-03-06 01:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:00:56 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 13.475 | nll_loss 12.729 | ppl 6788.72 | wps 46550.7 | wpb 510.9 | bsz 1 | num_updates 16207 | best_loss 9.173
2022-03-06 01:00:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16207 updates
2022-03-06 01:00:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:00:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:00:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 333 @ 16207 updates, score 13.475) (writing took 1.6848776740953326 seconds)
2022-03-06 01:00:58 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-06 01:00:58 | INFO | train | epoch 333 | loss 2.627 | nll_loss 0.459 | ppl 1.37 | wps 27113 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16207 | lr 0.000248398 | gnorm 0.514 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38297
2022-03-06 01:00:58 | INFO | fairseq.trainer | begin training epoch 334
2022-03-06 01:00:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:02:51 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 13.549 | nll_loss 12.813 | ppl 7196.1 | wps 46378.2 | wpb 510.9 | bsz 1 | num_updates 16256 | best_loss 9.173
2022-03-06 01:02:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16256 updates
2022-03-06 01:02:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:02:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:02:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 334 @ 16256 updates, score 13.549) (writing took 1.728190217167139 seconds)
2022-03-06 01:02:53 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-06 01:02:53 | INFO | train | epoch 334 | loss 2.626 | nll_loss 0.458 | ppl 1.37 | wps 27682.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16256 | lr 0.000248024 | gnorm 0.506 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38412
2022-03-06 01:02:53 | INFO | fairseq.trainer | begin training epoch 335
2022-03-06 01:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:04:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:04:33 | INFO | train_inner | epoch 335:     45 / 49 loss=2.626, nll_loss=0.458, ppl=1.37, wps=27459.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.508, loss_scale=32, train_wall=200, gb_free=21.6, wall=38512
2022-03-06 01:04:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:04:46 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 13.462 | nll_loss 12.715 | ppl 6725.44 | wps 46536 | wpb 510.9 | bsz 1 | num_updates 16304 | best_loss 9.173
2022-03-06 01:04:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16304 updates
2022-03-06 01:04:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:04:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 335 @ 16304 updates, score 13.462) (writing took 1.6543099768459797 seconds)
2022-03-06 01:04:48 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-06 01:04:48 | INFO | train | epoch 335 | loss 2.625 | nll_loss 0.457 | ppl 1.37 | wps 27128 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16304 | lr 0.000247658 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38526
2022-03-06 01:04:48 | INFO | fairseq.trainer | begin training epoch 336
2022-03-06 01:04:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:06:41 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 13.406 | nll_loss 12.649 | ppl 6421.98 | wps 46399.3 | wpb 510.9 | bsz 1 | num_updates 16353 | best_loss 9.173
2022-03-06 01:06:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16353 updates
2022-03-06 01:06:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:06:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:06:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 336 @ 16353 updates, score 13.406) (writing took 1.7120764926075935 seconds)
2022-03-06 01:06:42 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-06 01:06:42 | INFO | train | epoch 336 | loss 2.624 | nll_loss 0.457 | ppl 1.37 | wps 27693.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16353 | lr 0.000247287 | gnorm 0.509 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38641
2022-03-06 01:06:42 | INFO | fairseq.trainer | begin training epoch 337
2022-03-06 01:06:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:08:27 | INFO | train_inner | epoch 337:     47 / 49 loss=2.624, nll_loss=0.456, ppl=1.37, wps=27736.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.507, loss_scale=32, train_wall=198, gb_free=21.6, wall=38746
2022-03-06 01:08:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:08:35 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 13.428 | nll_loss 12.678 | ppl 6552.6 | wps 46516.8 | wpb 510.9 | bsz 1 | num_updates 16402 | best_loss 9.173
2022-03-06 01:08:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16402 updates
2022-03-06 01:08:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:08:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:08:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 337 @ 16402 updates, score 13.428) (writing took 1.7203320218250155 seconds)
2022-03-06 01:08:37 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-06 01:08:37 | INFO | train | epoch 337 | loss 2.623 | nll_loss 0.456 | ppl 1.37 | wps 27698.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16402 | lr 0.000246917 | gnorm 0.505 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38756
2022-03-06 01:08:37 | INFO | fairseq.trainer | begin training epoch 338
2022-03-06 01:08:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:09:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:10:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:10:30 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 13.459 | nll_loss 12.707 | ppl 6687.17 | wps 46618.6 | wpb 510.9 | bsz 1 | num_updates 16450 | best_loss 9.173
2022-03-06 01:10:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16450 updates
2022-03-06 01:10:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:10:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:10:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 338 @ 16450 updates, score 13.459) (writing took 1.6398693155497313 seconds)
2022-03-06 01:10:32 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-06 01:10:32 | INFO | train | epoch 338 | loss 2.622 | nll_loss 0.455 | ppl 1.37 | wps 27127.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16450 | lr 0.000246557 | gnorm 0.508 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38871
2022-03-06 01:10:32 | INFO | fairseq.trainer | begin training epoch 339
2022-03-06 01:10:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:12:25 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 13.478 | nll_loss 12.733 | ppl 6810.03 | wps 46594 | wpb 510.9 | bsz 1 | num_updates 16499 | best_loss 9.173
2022-03-06 01:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16499 updates
2022-03-06 01:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:12:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 339 @ 16499 updates, score 13.478) (writing took 1.6704730251803994 seconds)
2022-03-06 01:12:27 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-06 01:12:27 | INFO | train | epoch 339 | loss 2.623 | nll_loss 0.455 | ppl 1.37 | wps 27706.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16499 | lr 0.00024619 | gnorm 0.509 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38985
2022-03-06 01:12:27 | INFO | fairseq.trainer | begin training epoch 340
2022-03-06 01:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:12:29 | INFO | train_inner | epoch 340:      1 / 49 loss=2.622, nll_loss=0.455, ppl=1.37, wps=26716, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=16500, lr=0.000246183, gnorm=0.509, loss_scale=32, train_wall=199, gb_free=21.6, wall=38988
2022-03-06 01:14:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:14:20 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 13.561 | nll_loss 12.827 | ppl 7263.97 | wps 46521.1 | wpb 510.9 | bsz 1 | num_updates 16548 | best_loss 9.173
2022-03-06 01:14:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16548 updates
2022-03-06 01:14:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:14:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:14:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 340 @ 16548 updates, score 13.561) (writing took 1.7245553163811564 seconds)
2022-03-06 01:14:21 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-06 01:14:21 | INFO | train | epoch 340 | loss 2.62 | nll_loss 0.453 | ppl 1.37 | wps 27683 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16548 | lr 0.000245826 | gnorm 0.499 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 39100
2022-03-06 01:14:21 | INFO | fairseq.trainer | begin training epoch 341
2022-03-06 01:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:14:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:16:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:16:14 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 13.512 | nll_loss 12.775 | ppl 7009.96 | wps 46667.8 | wpb 510.9 | bsz 1 | num_updates 16596 | best_loss 9.173
2022-03-06 01:16:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16596 updates
2022-03-06 01:16:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:16:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:16:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 341 @ 16596 updates, score 13.512) (writing took 1.7004545284435153 seconds)
2022-03-06 01:16:16 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-06 01:16:16 | INFO | train | epoch 341 | loss 2.619 | nll_loss 0.452 | ppl 1.37 | wps 27142.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16596 | lr 0.00024547 | gnorm 0.506 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39215
2022-03-06 01:16:16 | INFO | fairseq.trainer | begin training epoch 342
2022-03-06 01:16:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:16:25 | INFO | train_inner | epoch 342:      4 / 49 loss=2.619, nll_loss=0.452, ppl=1.37, wps=27467.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.503, loss_scale=32, train_wall=200, gb_free=21.6, wall=39224
2022-03-06 01:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:18:09 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 13.42 | nll_loss 12.671 | ppl 6520.15 | wps 46599.2 | wpb 510.9 | bsz 1 | num_updates 16645 | best_loss 9.173
2022-03-06 01:18:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16645 updates
2022-03-06 01:18:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:18:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:18:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 342 @ 16645 updates, score 13.42) (writing took 1.6931701637804508 seconds)
2022-03-06 01:18:11 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-06 01:18:11 | INFO | train | epoch 342 | loss 2.618 | nll_loss 0.452 | ppl 1.37 | wps 27684.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16645 | lr 0.000245108 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39329
2022-03-06 01:18:11 | INFO | fairseq.trainer | begin training epoch 343
2022-03-06 01:18:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:19:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:19:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:20:04 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 13.463 | nll_loss 12.72 | ppl 6745.95 | wps 46310.8 | wpb 510.9 | bsz 1 | num_updates 16693 | best_loss 9.173
2022-03-06 01:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16693 updates
2022-03-06 01:20:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:20:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 343 @ 16693 updates, score 13.463) (writing took 1.617430885322392 seconds)
2022-03-06 01:20:06 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-06 01:20:06 | INFO | train | epoch 343 | loss 2.618 | nll_loss 0.451 | ppl 1.37 | wps 27126.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16693 | lr 0.000244756 | gnorm 0.501 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39444
2022-03-06 01:20:06 | INFO | fairseq.trainer | begin training epoch 344
2022-03-06 01:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:20:21 | INFO | train_inner | epoch 344:      7 / 49 loss=2.618, nll_loss=0.451, ppl=1.37, wps=27461.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.502, loss_scale=32, train_wall=200, gb_free=21.6, wall=39460
2022-03-06 01:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:21:59 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.403 | nll_loss 12.643 | ppl 6395.6 | wps 46587 | wpb 510.9 | bsz 1 | num_updates 16742 | best_loss 9.173
2022-03-06 01:21:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16742 updates
2022-03-06 01:21:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:22:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:22:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 344 @ 16742 updates, score 13.403) (writing took 1.6412550462409854 seconds)
2022-03-06 01:22:00 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-06 01:22:00 | INFO | train | epoch 344 | loss 2.617 | nll_loss 0.451 | ppl 1.37 | wps 27688 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16742 | lr 0.000244397 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39559
2022-03-06 01:22:00 | INFO | fairseq.trainer | begin training epoch 345
2022-03-06 01:22:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:23:53 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 13.499 | nll_loss 12.761 | ppl 6942.06 | wps 46555.2 | wpb 510.9 | bsz 1 | num_updates 16791 | best_loss 9.173
2022-03-06 01:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16791 updates
2022-03-06 01:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:23:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:23:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 345 @ 16791 updates, score 13.499) (writing took 1.6463781725615263 seconds)
2022-03-06 01:23:55 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-06 01:23:55 | INFO | train | epoch 345 | loss 2.615 | nll_loss 0.449 | ppl 1.37 | wps 27706.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16791 | lr 0.00024404 | gnorm 0.498 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39674
2022-03-06 01:23:55 | INFO | fairseq.trainer | begin training epoch 346
2022-03-06 01:23:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:24:15 | INFO | train_inner | epoch 346:      9 / 49 loss=2.616, nll_loss=0.45, ppl=1.37, wps=27730.3, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.503, loss_scale=32, train_wall=198, gb_free=21.6, wall=39694
2022-03-06 01:24:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:25:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:25:48 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 13.472 | nll_loss 12.731 | ppl 6797.85 | wps 46518.2 | wpb 510.9 | bsz 1 | num_updates 16839 | best_loss 9.173
2022-03-06 01:25:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16839 updates
2022-03-06 01:25:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:25:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:25:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 346 @ 16839 updates, score 13.472) (writing took 1.6475488543510437 seconds)
2022-03-06 01:25:50 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-06 01:25:50 | INFO | train | epoch 346 | loss 2.615 | nll_loss 0.449 | ppl 1.37 | wps 27131.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16839 | lr 0.000243692 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39788
2022-03-06 01:25:50 | INFO | fairseq.trainer | begin training epoch 347
2022-03-06 01:25:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:27:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:27:43 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 13.463 | nll_loss 12.719 | ppl 6743.66 | wps 46660 | wpb 510.9 | bsz 1 | num_updates 16888 | best_loss 9.173
2022-03-06 01:27:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16888 updates
2022-03-06 01:27:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:27:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:27:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 347 @ 16888 updates, score 13.463) (writing took 1.6673178747296333 seconds)
2022-03-06 01:27:44 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-06 01:27:44 | INFO | train | epoch 347 | loss 2.615 | nll_loss 0.449 | ppl 1.37 | wps 27728.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16888 | lr 0.000243339 | gnorm 0.495 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39903
2022-03-06 01:27:44 | INFO | fairseq.trainer | begin training epoch 348
2022-03-06 01:27:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:28:11 | INFO | train_inner | epoch 348:     12 / 49 loss=2.615, nll_loss=0.449, ppl=1.36, wps=27480.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.498, loss_scale=32, train_wall=200, gb_free=21.6, wall=39930
2022-03-06 01:29:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:29:37 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 13.458 | nll_loss 12.715 | ppl 6723.6 | wps 46687.7 | wpb 510.9 | bsz 1 | num_updates 16937 | best_loss 9.173
2022-03-06 01:29:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16937 updates
2022-03-06 01:29:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:29:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:29:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 348 @ 16937 updates, score 13.458) (writing took 1.6642428981140256 seconds)
2022-03-06 01:29:39 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-06 01:29:39 | INFO | train | epoch 348 | loss 2.614 | nll_loss 0.448 | ppl 1.36 | wps 27697.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16937 | lr 0.000242986 | gnorm 0.498 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40018
2022-03-06 01:29:39 | INFO | fairseq.trainer | begin training epoch 349
2022-03-06 01:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:29:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:31:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:31:32 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 13.524 | nll_loss 12.781 | ppl 7036.26 | wps 46688.1 | wpb 510.9 | bsz 1 | num_updates 16985 | best_loss 9.173
2022-03-06 01:31:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16985 updates
2022-03-06 01:31:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:31:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:31:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 349 @ 16985 updates, score 13.524) (writing took 1.6440709307789803 seconds)
2022-03-06 01:31:34 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-06 01:31:34 | INFO | train | epoch 349 | loss 2.613 | nll_loss 0.448 | ppl 1.36 | wps 27120.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16985 | lr 0.000242643 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40133
2022-03-06 01:31:34 | INFO | fairseq.trainer | begin training epoch 350
2022-03-06 01:31:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:32:07 | INFO | train_inner | epoch 350:     15 / 49 loss=2.614, nll_loss=0.448, ppl=1.36, wps=27472.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.505, loss_scale=32, train_wall=200, gb_free=21.6, wall=40166
2022-03-06 01:33:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:33:27 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.539 | nll_loss 12.807 | ppl 7163.81 | wps 46432.6 | wpb 510.9 | bsz 1 | num_updates 17034 | best_loss 9.173
2022-03-06 01:33:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17034 updates
2022-03-06 01:33:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:33:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:33:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 350 @ 17034 updates, score 13.539) (writing took 1.714486108161509 seconds)
2022-03-06 01:33:29 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-06 01:33:29 | INFO | train | epoch 350 | loss 2.612 | nll_loss 0.447 | ppl 1.36 | wps 27694.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17034 | lr 0.000242293 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40247
2022-03-06 01:33:29 | INFO | fairseq.trainer | begin training epoch 351
2022-03-06 01:33:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:34:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:35:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:35:22 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 13.46 | nll_loss 12.715 | ppl 6724.81 | wps 46541.8 | wpb 510.9 | bsz 1 | num_updates 17082 | best_loss 9.173
2022-03-06 01:35:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17082 updates
2022-03-06 01:35:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:35:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:35:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 351 @ 17082 updates, score 13.46) (writing took 1.636776496656239 seconds)
2022-03-06 01:35:23 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-06 01:35:23 | INFO | train | epoch 351 | loss 2.611 | nll_loss 0.446 | ppl 1.36 | wps 27120.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17082 | lr 0.000241953 | gnorm 0.501 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40362
2022-03-06 01:35:23 | INFO | fairseq.trainer | begin training epoch 352
2022-03-06 01:35:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:36:04 | INFO | train_inner | epoch 352:     18 / 49 loss=2.611, nll_loss=0.446, ppl=1.36, wps=27463.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.498, loss_scale=32, train_wall=200, gb_free=21.6, wall=40402
2022-03-06 01:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:37:17 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 13.621 | nll_loss 12.888 | ppl 7581.23 | wps 46507.5 | wpb 510.9 | bsz 1 | num_updates 17131 | best_loss 9.173
2022-03-06 01:37:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17131 updates
2022-03-06 01:37:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:37:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:37:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 352 @ 17131 updates, score 13.621) (writing took 1.6389982169494033 seconds)
2022-03-06 01:37:18 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-06 01:37:18 | INFO | train | epoch 352 | loss 2.611 | nll_loss 0.446 | ppl 1.36 | wps 27669.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17131 | lr 0.000241607 | gnorm 0.496 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40477
2022-03-06 01:37:18 | INFO | fairseq.trainer | begin training epoch 353
2022-03-06 01:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:39:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:39:11 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 13.458 | nll_loss 12.719 | ppl 6740.35 | wps 46661.8 | wpb 510.9 | bsz 1 | num_updates 17180 | best_loss 9.173
2022-03-06 01:39:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17180 updates
2022-03-06 01:39:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:39:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:39:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 353 @ 17180 updates, score 13.458) (writing took 1.6290681129321456 seconds)
2022-03-06 01:39:13 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-06 01:39:13 | INFO | train | epoch 353 | loss 2.609 | nll_loss 0.444 | ppl 1.36 | wps 27726.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17180 | lr 0.000241262 | gnorm 0.494 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40592
2022-03-06 01:39:13 | INFO | fairseq.trainer | begin training epoch 354
2022-03-06 01:39:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:39:58 | INFO | train_inner | epoch 354:     20 / 49 loss=2.609, nll_loss=0.445, ppl=1.36, wps=27721.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.496, loss_scale=32, train_wall=198, gb_free=21.6, wall=40636
2022-03-06 01:40:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:41:06 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 13.401 | nll_loss 12.653 | ppl 6440.83 | wps 46529.8 | wpb 510.9 | bsz 1 | num_updates 17228 | best_loss 9.173
2022-03-06 01:41:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17228 updates
2022-03-06 01:41:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:41:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:41:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 354 @ 17228 updates, score 13.401) (writing took 1.705841550603509 seconds)
2022-03-06 01:41:08 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-06 01:41:08 | INFO | train | epoch 354 | loss 2.609 | nll_loss 0.445 | ppl 1.36 | wps 27113.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17228 | lr 0.000240925 | gnorm 0.503 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40706
2022-03-06 01:41:08 | INFO | fairseq.trainer | begin training epoch 355
2022-03-06 01:41:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:42:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:43:01 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 13.508 | nll_loss 12.771 | ppl 6991.79 | wps 46481.1 | wpb 510.9 | bsz 1 | num_updates 17277 | best_loss 9.173
2022-03-06 01:43:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17277 updates
2022-03-06 01:43:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:43:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:43:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 355 @ 17277 updates, score 13.508) (writing took 1.6248819548636675 seconds)
2022-03-06 01:43:02 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-06 01:43:02 | INFO | train | epoch 355 | loss 2.609 | nll_loss 0.445 | ppl 1.36 | wps 27695.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17277 | lr 0.000240583 | gnorm 0.497 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40821
2022-03-06 01:43:02 | INFO | fairseq.trainer | begin training epoch 356
2022-03-06 01:43:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:43:54 | INFO | train_inner | epoch 356:     23 / 49 loss=2.609, nll_loss=0.445, ppl=1.36, wps=27461.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.501, loss_scale=32, train_wall=200, gb_free=21.6, wall=40873
2022-03-06 01:44:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:44:55 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 13.452 | nll_loss 12.713 | ppl 6714.84 | wps 46619.6 | wpb 510.9 | bsz 1 | num_updates 17326 | best_loss 9.173
2022-03-06 01:44:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17326 updates
2022-03-06 01:44:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:44:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:44:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 356 @ 17326 updates, score 13.452) (writing took 1.6446257140487432 seconds)
2022-03-06 01:44:57 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-06 01:44:57 | INFO | train | epoch 356 | loss 2.607 | nll_loss 0.443 | ppl 1.36 | wps 27711 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17326 | lr 0.000240243 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40936
2022-03-06 01:44:57 | INFO | fairseq.trainer | begin training epoch 357
2022-03-06 01:44:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:45:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:46:50 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.557 | nll_loss 12.823 | ppl 7248.64 | wps 46569.9 | wpb 510.9 | bsz 1 | num_updates 17374 | best_loss 9.173
2022-03-06 01:46:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17374 updates
2022-03-06 01:46:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:46:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 357 @ 17374 updates, score 13.557) (writing took 1.7113718083128333 seconds)
2022-03-06 01:46:52 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-06 01:46:52 | INFO | train | epoch 357 | loss 2.606 | nll_loss 0.443 | ppl 1.36 | wps 27103.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17374 | lr 0.000239911 | gnorm 0.497 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41051
2022-03-06 01:46:52 | INFO | fairseq.trainer | begin training epoch 358
2022-03-06 01:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:47:50 | INFO | train_inner | epoch 358:     26 / 49 loss=2.607, nll_loss=0.443, ppl=1.36, wps=27476.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.499, loss_scale=32, train_wall=200, gb_free=21.6, wall=41109
2022-03-06 01:48:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:48:45 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.425 | nll_loss 12.676 | ppl 6546.3 | wps 46394 | wpb 510.9 | bsz 1 | num_updates 17423 | best_loss 9.173
2022-03-06 01:48:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17423 updates
2022-03-06 01:48:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:48:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:48:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 358 @ 17423 updates, score 13.425) (writing took 1.629552205093205 seconds)
2022-03-06 01:48:47 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-06 01:48:47 | INFO | train | epoch 358 | loss 2.606 | nll_loss 0.443 | ppl 1.36 | wps 27737.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17423 | lr 0.000239573 | gnorm 0.505 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41165
2022-03-06 01:48:47 | INFO | fairseq.trainer | begin training epoch 359
2022-03-06 01:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:50:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:50:40 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.458 | nll_loss 12.718 | ppl 6736.96 | wps 46541.4 | wpb 510.9 | bsz 1 | num_updates 17471 | best_loss 9.173
2022-03-06 01:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17471 updates
2022-03-06 01:50:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:50:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:50:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 359 @ 17471 updates, score 13.458) (writing took 1.6878258967772126 seconds)
2022-03-06 01:50:41 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-06 01:50:41 | INFO | train | epoch 359 | loss 2.603 | nll_loss 0.44 | ppl 1.36 | wps 27104.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17471 | lr 0.000239244 | gnorm 0.487 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41280
2022-03-06 01:50:41 | INFO | fairseq.trainer | begin training epoch 360
2022-03-06 01:50:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:51:46 | INFO | train_inner | epoch 360:     29 / 49 loss=2.604, nll_loss=0.441, ppl=1.36, wps=27472.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.494, loss_scale=32, train_wall=200, gb_free=21.6, wall=41345
2022-03-06 01:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:52:34 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.455 | nll_loss 12.709 | ppl 6697.59 | wps 46414.9 | wpb 510.9 | bsz 1 | num_updates 17520 | best_loss 9.173
2022-03-06 01:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17520 updates
2022-03-06 01:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:52:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 360 @ 17520 updates, score 13.455) (writing took 1.6686727963387966 seconds)
2022-03-06 01:52:36 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-06 01:52:36 | INFO | train | epoch 360 | loss 2.603 | nll_loss 0.44 | ppl 1.36 | wps 27694.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17520 | lr 0.000238909 | gnorm 0.493 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41395
2022-03-06 01:52:36 | INFO | fairseq.trainer | begin training epoch 361
2022-03-06 01:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:54:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:54:29 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.548 | nll_loss 12.82 | ppl 7230.37 | wps 46629.4 | wpb 510.9 | bsz 1 | num_updates 17569 | best_loss 9.173
2022-03-06 01:54:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17569 updates
2022-03-06 01:54:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:54:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 361 @ 17569 updates, score 13.548) (writing took 1.7090396704152226 seconds)
2022-03-06 01:54:31 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-06 01:54:31 | INFO | train | epoch 361 | loss 2.604 | nll_loss 0.44 | ppl 1.36 | wps 27699 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17569 | lr 0.000238576 | gnorm 0.494 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41510
2022-03-06 01:54:31 | INFO | fairseq.trainer | begin training epoch 362
2022-03-06 01:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:55:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:55:42 | INFO | train_inner | epoch 362:     32 / 49 loss=2.603, nll_loss=0.44, ppl=1.36, wps=27447.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.496, loss_scale=32, train_wall=200, gb_free=21.6, wall=41581
2022-03-06 01:56:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:56:24 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 13.357 | nll_loss 12.599 | ppl 6206.19 | wps 46649.8 | wpb 510.9 | bsz 1 | num_updates 17617 | best_loss 9.173
2022-03-06 01:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17617 updates
2022-03-06 01:56:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 362 @ 17617 updates, score 13.357) (writing took 1.6270118178799748 seconds)
2022-03-06 01:56:26 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-06 01:56:26 | INFO | train | epoch 362 | loss 2.603 | nll_loss 0.44 | ppl 1.36 | wps 27115.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17617 | lr 0.000238251 | gnorm 0.501 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41624
2022-03-06 01:56:26 | INFO | fairseq.trainer | begin training epoch 363
2022-03-06 01:56:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:58:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:58:19 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.481 | nll_loss 12.736 | ppl 6823.11 | wps 45465 | wpb 510.9 | bsz 1 | num_updates 17666 | best_loss 9.173
2022-03-06 01:58:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17666 updates
2022-03-06 01:58:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:58:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 01:58:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 363 @ 17666 updates, score 13.481) (writing took 1.6706897672265768 seconds)
2022-03-06 01:58:21 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-06 01:58:21 | INFO | train | epoch 363 | loss 2.601 | nll_loss 0.439 | ppl 1.36 | wps 27657.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17666 | lr 0.00023792 | gnorm 0.494 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41739
2022-03-06 01:58:21 | INFO | fairseq.trainer | begin training epoch 364
2022-03-06 01:58:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:58:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 01:59:39 | INFO | train_inner | epoch 364:     35 / 49 loss=2.601, nll_loss=0.438, ppl=1.36, wps=27459.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.496, loss_scale=16, train_wall=200, gb_free=21.6, wall=41817
2022-03-06 02:00:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:00:14 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 13.508 | nll_loss 12.775 | ppl 7009.19 | wps 46416.6 | wpb 510.9 | bsz 1 | num_updates 17714 | best_loss 9.173
2022-03-06 02:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17714 updates
2022-03-06 02:00:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 364 @ 17714 updates, score 13.508) (writing took 1.632626454345882 seconds)
2022-03-06 02:00:15 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-06 02:00:15 | INFO | train | epoch 364 | loss 2.6 | nll_loss 0.437 | ppl 1.35 | wps 27145.5 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 17714 | lr 0.000237597 | gnorm 0.501 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 41854
2022-03-06 02:00:15 | INFO | fairseq.trainer | begin training epoch 365
2022-03-06 02:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:02:08 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.454 | nll_loss 12.714 | ppl 6718.97 | wps 46529.6 | wpb 510.9 | bsz 1 | num_updates 17763 | best_loss 9.173
2022-03-06 02:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17763 updates
2022-03-06 02:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 365 @ 17763 updates, score 13.454) (writing took 1.6563366949558258 seconds)
2022-03-06 02:02:10 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-06 02:02:10 | INFO | train | epoch 365 | loss 2.6 | nll_loss 0.437 | ppl 1.35 | wps 27681 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17763 | lr 0.000237269 | gnorm 0.491 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 41969
2022-03-06 02:02:10 | INFO | fairseq.trainer | begin training epoch 366
2022-03-06 02:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:03:33 | INFO | train_inner | epoch 366:     37 / 49 loss=2.6, nll_loss=0.437, ppl=1.35, wps=27730.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.492, loss_scale=32, train_wall=198, gb_free=21.6, wall=42051
2022-03-06 02:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:04:03 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.514 | nll_loss 12.778 | ppl 7023.95 | wps 46597.1 | wpb 510.9 | bsz 1 | num_updates 17812 | best_loss 9.173
2022-03-06 02:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17812 updates
2022-03-06 02:04:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:04:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 366 @ 17812 updates, score 13.514) (writing took 1.6454638447612524 seconds)
2022-03-06 02:04:05 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-06 02:04:05 | INFO | train | epoch 366 | loss 2.599 | nll_loss 0.436 | ppl 1.35 | wps 27727.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17812 | lr 0.000236943 | gnorm 0.491 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42083
2022-03-06 02:04:05 | INFO | fairseq.trainer | begin training epoch 367
2022-03-06 02:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:05:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:05:58 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 13.401 | nll_loss 12.659 | ppl 6468.4 | wps 46650 | wpb 510.9 | bsz 1 | num_updates 17861 | best_loss 9.173
2022-03-06 02:05:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17861 updates
2022-03-06 02:05:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 367 @ 17861 updates, score 13.401) (writing took 1.6897972719743848 seconds)
2022-03-06 02:05:59 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-06 02:05:59 | INFO | train | epoch 367 | loss 2.599 | nll_loss 0.437 | ppl 1.35 | wps 27694.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17861 | lr 0.000236618 | gnorm 0.489 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42198
2022-03-06 02:05:59 | INFO | fairseq.trainer | begin training epoch 368
2022-03-06 02:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:07:26 | INFO | train_inner | epoch 368:     39 / 49 loss=2.598, nll_loss=0.436, ppl=1.35, wps=27740.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.488, loss_scale=32, train_wall=198, gb_free=21.6, wall=42285
2022-03-06 02:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:07:52 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.41 | nll_loss 12.662 | ppl 6481.45 | wps 46708 | wpb 510.9 | bsz 1 | num_updates 17910 | best_loss 9.173
2022-03-06 02:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17910 updates
2022-03-06 02:07:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:07:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:07:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 368 @ 17910 updates, score 13.41) (writing took 1.6926635084673762 seconds)
2022-03-06 02:07:54 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-06 02:07:54 | INFO | train | epoch 368 | loss 2.597 | nll_loss 0.435 | ppl 1.35 | wps 27701.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17910 | lr 0.000236294 | gnorm 0.484 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42313
2022-03-06 02:07:54 | INFO | fairseq.trainer | begin training epoch 369
2022-03-06 02:07:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:08:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:09:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:09:47 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 13.431 | nll_loss 12.694 | ppl 6628.28 | wps 46601.3 | wpb 510.9 | bsz 1 | num_updates 17958 | best_loss 9.173
2022-03-06 02:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17958 updates
2022-03-06 02:09:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:09:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:09:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 369 @ 17958 updates, score 13.431) (writing took 1.6597039410844445 seconds)
2022-03-06 02:09:49 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-06 02:09:49 | INFO | train | epoch 369 | loss 2.598 | nll_loss 0.436 | ppl 1.35 | wps 27169.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17958 | lr 0.000235978 | gnorm 0.492 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42427
2022-03-06 02:09:49 | INFO | fairseq.trainer | begin training epoch 370
2022-03-06 02:09:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:11:23 | INFO | train_inner | epoch 370:     42 / 49 loss=2.597, nll_loss=0.435, ppl=1.35, wps=27484, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.487, loss_scale=32, train_wall=200, gb_free=21.6, wall=42521
2022-03-06 02:11:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:11:42 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.476 | nll_loss 12.741 | ppl 6845.36 | wps 46498.7 | wpb 510.9 | bsz 1 | num_updates 18007 | best_loss 9.173
2022-03-06 02:11:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18007 updates
2022-03-06 02:11:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:11:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:11:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 370 @ 18007 updates, score 13.476) (writing took 1.6574253914877772 seconds)
2022-03-06 02:11:43 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-06 02:11:43 | INFO | train | epoch 370 | loss 2.596 | nll_loss 0.435 | ppl 1.35 | wps 27699 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18007 | lr 0.000235656 | gnorm 0.483 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42542
2022-03-06 02:11:43 | INFO | fairseq.trainer | begin training epoch 371
2022-03-06 02:11:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:13:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:13:37 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 13.456 | nll_loss 12.721 | ppl 6752.6 | wps 46321.6 | wpb 510.9 | bsz 1 | num_updates 18055 | best_loss 9.173
2022-03-06 02:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18055 updates
2022-03-06 02:13:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:13:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 371 @ 18055 updates, score 13.456) (writing took 1.6494603287428617 seconds)
2022-03-06 02:13:38 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-06 02:13:38 | INFO | train | epoch 371 | loss 2.595 | nll_loss 0.433 | ppl 1.35 | wps 27114.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18055 | lr 0.000235343 | gnorm 0.487 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42657
2022-03-06 02:13:38 | INFO | fairseq.trainer | begin training epoch 372
2022-03-06 02:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:15:19 | INFO | train_inner | epoch 372:     45 / 49 loss=2.595, nll_loss=0.433, ppl=1.35, wps=27455.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.487, loss_scale=32, train_wall=200, gb_free=21.6, wall=42757
2022-03-06 02:15:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:15:31 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.538 | nll_loss 12.805 | ppl 7157.86 | wps 46609.6 | wpb 510.9 | bsz 1 | num_updates 18104 | best_loss 9.173
2022-03-06 02:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18104 updates
2022-03-06 02:15:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:15:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 372 @ 18104 updates, score 13.538) (writing took 1.6947645097970963 seconds)
2022-03-06 02:15:33 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-06 02:15:33 | INFO | train | epoch 372 | loss 2.594 | nll_loss 0.433 | ppl 1.35 | wps 27679.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18104 | lr 0.000235024 | gnorm 0.485 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42772
2022-03-06 02:15:33 | INFO | fairseq.trainer | begin training epoch 373
2022-03-06 02:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:17:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:17:26 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 13.46 | nll_loss 12.721 | ppl 6752.12 | wps 46759.9 | wpb 510.9 | bsz 1 | num_updates 18153 | best_loss 9.173
2022-03-06 02:17:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18153 updates
2022-03-06 02:17:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:17:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:17:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 373 @ 18153 updates, score 13.46) (writing took 1.6755205690860748 seconds)
2022-03-06 02:17:28 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-06 02:17:28 | INFO | train | epoch 373 | loss 2.593 | nll_loss 0.432 | ppl 1.35 | wps 27681 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18153 | lr 0.000234707 | gnorm 0.485 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42887
2022-03-06 02:17:28 | INFO | fairseq.trainer | begin training epoch 374
2022-03-06 02:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:18:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:19:15 | INFO | train_inner | epoch 374:     48 / 49 loss=2.594, nll_loss=0.433, ppl=1.35, wps=27460.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.492, loss_scale=32, train_wall=200, gb_free=21.6, wall=42994
2022-03-06 02:19:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:19:21 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.501 | nll_loss 12.763 | ppl 6948.61 | wps 46553.5 | wpb 510.9 | bsz 1 | num_updates 18201 | best_loss 9.173
2022-03-06 02:19:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18201 updates
2022-03-06 02:19:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:19:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 374 @ 18201 updates, score 13.501) (writing took 1.7035539699718356 seconds)
2022-03-06 02:19:23 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-06 02:19:23 | INFO | train | epoch 374 | loss 2.594 | nll_loss 0.433 | ppl 1.35 | wps 27121.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18201 | lr 0.000234397 | gnorm 0.499 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43001
2022-03-06 02:19:23 | INFO | fairseq.trainer | begin training epoch 375
2022-03-06 02:19:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:21:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:21:16 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.49 | nll_loss 12.76 | ppl 6934.25 | wps 46512.1 | wpb 510.9 | bsz 1 | num_updates 18250 | best_loss 9.173
2022-03-06 02:21:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18250 updates
2022-03-06 02:21:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:21:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:21:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 375 @ 18250 updates, score 13.49) (writing took 1.6668741097673774 seconds)
2022-03-06 02:21:17 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-06 02:21:17 | INFO | train | epoch 375 | loss 2.592 | nll_loss 0.431 | ppl 1.35 | wps 27707.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18250 | lr 0.000234082 | gnorm 0.482 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43116
2022-03-06 02:21:17 | INFO | fairseq.trainer | begin training epoch 376
2022-03-06 02:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:23:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:23:10 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.579 | nll_loss 12.856 | ppl 7416.19 | wps 46643.9 | wpb 510.9 | bsz 1 | num_updates 18299 | best_loss 9.173
2022-03-06 02:23:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18299 updates
2022-03-06 02:23:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:23:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:23:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 376 @ 18299 updates, score 13.579) (writing took 1.6352481245994568 seconds)
2022-03-06 02:23:12 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-06 02:23:12 | INFO | train | epoch 376 | loss 2.592 | nll_loss 0.431 | ppl 1.35 | wps 27715.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18299 | lr 0.000233769 | gnorm 0.484 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43231
2022-03-06 02:23:12 | INFO | fairseq.trainer | begin training epoch 377
2022-03-06 02:23:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:23:14 | INFO | train_inner | epoch 377:      1 / 49 loss=2.592, nll_loss=0.431, ppl=1.35, wps=26976.2, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=18300, lr=0.000233762, gnorm=0.485, loss_scale=32, train_wall=197, gb_free=21.6, wall=43233
2022-03-06 02:23:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:25:05 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.487 | nll_loss 12.75 | ppl 6887.59 | wps 46708.6 | wpb 510.9 | bsz 1 | num_updates 18347 | best_loss 9.173
2022-03-06 02:25:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18347 updates
2022-03-06 02:25:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:25:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 377 @ 18347 updates, score 13.487) (writing took 1.6378830336034298 seconds)
2022-03-06 02:25:07 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-06 02:25:07 | INFO | train | epoch 377 | loss 2.592 | nll_loss 0.431 | ppl 1.35 | wps 27133.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18347 | lr 0.000233463 | gnorm 0.49 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43345
2022-03-06 02:25:07 | INFO | fairseq.trainer | begin training epoch 378
2022-03-06 02:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:27:00 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.495 | nll_loss 12.763 | ppl 6948.97 | wps 46591.1 | wpb 510.9 | bsz 1 | num_updates 18396 | best_loss 9.173
2022-03-06 02:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18396 updates
2022-03-06 02:27:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:27:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:27:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 378 @ 18396 updates, score 13.495) (writing took 1.6580071905627847 seconds)
2022-03-06 02:27:02 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-06 02:27:02 | INFO | train | epoch 378 | loss 2.59 | nll_loss 0.43 | ppl 1.35 | wps 27661.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18396 | lr 0.000233152 | gnorm 0.484 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43460
2022-03-06 02:27:02 | INFO | fairseq.trainer | begin training epoch 379
2022-03-06 02:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:27:11 | INFO | train_inner | epoch 379:      4 / 49 loss=2.59, nll_loss=0.43, ppl=1.35, wps=27450.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.487, loss_scale=32, train_wall=200, gb_free=21.6, wall=43469
2022-03-06 02:28:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:28:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:28:55 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 13.407 | nll_loss 12.663 | ppl 6485.61 | wps 46560.1 | wpb 510.9 | bsz 1 | num_updates 18444 | best_loss 9.173
2022-03-06 02:28:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18444 updates
2022-03-06 02:28:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:28:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:28:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 379 @ 18444 updates, score 13.407) (writing took 1.6759571582078934 seconds)
2022-03-06 02:28:56 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-06 02:28:56 | INFO | train | epoch 379 | loss 2.59 | nll_loss 0.429 | ppl 1.35 | wps 27108.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18444 | lr 0.000232848 | gnorm 0.482 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43575
2022-03-06 02:28:56 | INFO | fairseq.trainer | begin training epoch 380
2022-03-06 02:28:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:30:49 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 13.36 | nll_loss 12.617 | ppl 6283.95 | wps 46607.5 | wpb 510.9 | bsz 1 | num_updates 18493 | best_loss 9.173
2022-03-06 02:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18493 updates
2022-03-06 02:30:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:30:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:30:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 380 @ 18493 updates, score 13.36) (writing took 1.653274042531848 seconds)
2022-03-06 02:30:51 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-06 02:30:51 | INFO | train | epoch 380 | loss 2.589 | nll_loss 0.428 | ppl 1.35 | wps 27700.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18493 | lr 0.000232539 | gnorm 0.486 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43690
2022-03-06 02:30:51 | INFO | fairseq.trainer | begin training epoch 381
2022-03-06 02:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:31:07 | INFO | train_inner | epoch 381:      7 / 49 loss=2.589, nll_loss=0.429, ppl=1.35, wps=27460.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.482, loss_scale=32, train_wall=200, gb_free=21.6, wall=43706
2022-03-06 02:32:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:32:44 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.466 | nll_loss 12.724 | ppl 6763.52 | wps 46854.2 | wpb 510.9 | bsz 1 | num_updates 18542 | best_loss 9.173
2022-03-06 02:32:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18542 updates
2022-03-06 02:32:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:32:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:32:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 381 @ 18542 updates, score 13.466) (writing took 1.6350751863792539 seconds)
2022-03-06 02:32:46 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-06 02:32:46 | INFO | train | epoch 381 | loss 2.589 | nll_loss 0.429 | ppl 1.35 | wps 27667 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18542 | lr 0.000232232 | gnorm 0.483 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43805
2022-03-06 02:32:46 | INFO | fairseq.trainer | begin training epoch 382
2022-03-06 02:32:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:34:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:34:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:34:39 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.431 | nll_loss 12.693 | ppl 6620.52 | wps 46609.7 | wpb 510.9 | bsz 1 | num_updates 18590 | best_loss 9.173
2022-03-06 02:34:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18590 updates
2022-03-06 02:34:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:34:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 382 @ 18590 updates, score 13.431) (writing took 1.6797319510951638 seconds)
2022-03-06 02:34:41 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-06 02:34:41 | INFO | train | epoch 382 | loss 2.587 | nll_loss 0.427 | ppl 1.34 | wps 27147.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18590 | lr 0.000231932 | gnorm 0.474 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43919
2022-03-06 02:34:41 | INFO | fairseq.trainer | begin training epoch 383
2022-03-06 02:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:35:03 | INFO | train_inner | epoch 383:     10 / 49 loss=2.587, nll_loss=0.428, ppl=1.34, wps=27465.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.478, loss_scale=32, train_wall=200, gb_free=21.6, wall=43942
2022-03-06 02:36:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:36:34 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 13.484 | nll_loss 12.74 | ppl 6843.19 | wps 46557.4 | wpb 510.9 | bsz 1 | num_updates 18639 | best_loss 9.173
2022-03-06 02:36:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18639 updates
2022-03-06 02:36:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:36:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:36:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 383 @ 18639 updates, score 13.484) (writing took 1.6768065234646201 seconds)
2022-03-06 02:36:35 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-06 02:36:35 | INFO | train | epoch 383 | loss 2.587 | nll_loss 0.427 | ppl 1.34 | wps 27688.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18639 | lr 0.000231627 | gnorm 0.477 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44034
2022-03-06 02:36:35 | INFO | fairseq.trainer | begin training epoch 384
2022-03-06 02:36:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:38:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:38:29 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 13.47 | nll_loss 12.736 | ppl 6819.79 | wps 46841.3 | wpb 510.9 | bsz 1 | num_updates 18688 | best_loss 9.173
2022-03-06 02:38:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18688 updates
2022-03-06 02:38:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:38:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:38:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 384 @ 18688 updates, score 13.47) (writing took 1.6986859031021595 seconds)
2022-03-06 02:38:30 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-06 02:38:30 | INFO | train | epoch 384 | loss 2.587 | nll_loss 0.427 | ppl 1.34 | wps 27673.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18688 | lr 0.000231323 | gnorm 0.485 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44149
2022-03-06 02:38:30 | INFO | fairseq.trainer | begin training epoch 385
2022-03-06 02:38:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:38:57 | INFO | train_inner | epoch 385:     12 / 49 loss=2.587, nll_loss=0.427, ppl=1.34, wps=27713.4, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.482, loss_scale=32, train_wall=198, gb_free=21.6, wall=44176
2022-03-06 02:39:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:40:23 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.464 | nll_loss 12.725 | ppl 6770.02 | wps 46718.6 | wpb 510.9 | bsz 1 | num_updates 18736 | best_loss 9.173
2022-03-06 02:40:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18736 updates
2022-03-06 02:40:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:40:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:40:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 385 @ 18736 updates, score 13.464) (writing took 1.6839588098227978 seconds)
2022-03-06 02:40:25 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-06 02:40:25 | INFO | train | epoch 385 | loss 2.586 | nll_loss 0.427 | ppl 1.34 | wps 27132.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18736 | lr 0.000231026 | gnorm 0.484 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44264
2022-03-06 02:40:25 | INFO | fairseq.trainer | begin training epoch 386
2022-03-06 02:40:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:42:18 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.455 | nll_loss 12.717 | ppl 6732.64 | wps 46472.6 | wpb 510.9 | bsz 1 | num_updates 18785 | best_loss 9.173
2022-03-06 02:42:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18785 updates
2022-03-06 02:42:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:42:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:42:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 386 @ 18785 updates, score 13.455) (writing took 1.6204295009374619 seconds)
2022-03-06 02:42:20 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-06 02:42:20 | INFO | train | epoch 386 | loss 2.585 | nll_loss 0.426 | ppl 1.34 | wps 27735.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18785 | lr 0.000230725 | gnorm 0.487 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44378
2022-03-06 02:42:20 | INFO | fairseq.trainer | begin training epoch 387
2022-03-06 02:42:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:42:53 | INFO | train_inner | epoch 387:     15 / 49 loss=2.585, nll_loss=0.426, ppl=1.34, wps=27491.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.484, loss_scale=32, train_wall=200, gb_free=21.6, wall=44412
2022-03-06 02:44:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:44:13 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.42 | nll_loss 12.674 | ppl 6535.79 | wps 46639.1 | wpb 510.9 | bsz 1 | num_updates 18834 | best_loss 9.173
2022-03-06 02:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18834 updates
2022-03-06 02:44:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:44:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:44:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 387 @ 18834 updates, score 13.42) (writing took 1.653076270595193 seconds)
2022-03-06 02:44:14 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-06 02:44:14 | INFO | train | epoch 387 | loss 2.584 | nll_loss 0.425 | ppl 1.34 | wps 27728.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18834 | lr 0.000230425 | gnorm 0.478 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44493
2022-03-06 02:44:14 | INFO | fairseq.trainer | begin training epoch 388
2022-03-06 02:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:44:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:46:07 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.523 | nll_loss 12.792 | ppl 7094.05 | wps 46531.2 | wpb 510.9 | bsz 1 | num_updates 18882 | best_loss 9.173
2022-03-06 02:46:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18882 updates
2022-03-06 02:46:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:46:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:46:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 388 @ 18882 updates, score 13.523) (writing took 1.6259960448369384 seconds)
2022-03-06 02:46:09 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-06 02:46:09 | INFO | train | epoch 388 | loss 2.583 | nll_loss 0.424 | ppl 1.34 | wps 27134.9 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 18882 | lr 0.000230131 | gnorm 0.478 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44608
2022-03-06 02:46:09 | INFO | fairseq.trainer | begin training epoch 389
2022-03-06 02:46:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:46:49 | INFO | train_inner | epoch 389:     18 / 49 loss=2.583, nll_loss=0.424, ppl=1.34, wps=27478.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.481, loss_scale=32, train_wall=200, gb_free=21.6, wall=44648
2022-03-06 02:47:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:48:02 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 13.504 | nll_loss 12.775 | ppl 7008.16 | wps 46450.7 | wpb 510.9 | bsz 1 | num_updates 18931 | best_loss 9.173
2022-03-06 02:48:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18931 updates
2022-03-06 02:48:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:48:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:48:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 389 @ 18931 updates, score 13.504) (writing took 1.6671130871400237 seconds)
2022-03-06 02:48:04 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-06 02:48:04 | INFO | train | epoch 389 | loss 2.583 | nll_loss 0.424 | ppl 1.34 | wps 27682.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18931 | lr 0.000229833 | gnorm 0.482 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44722
2022-03-06 02:48:04 | INFO | fairseq.trainer | begin training epoch 390
2022-03-06 02:48:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:49:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:49:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:49:57 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 13.505 | nll_loss 12.778 | ppl 7021.49 | wps 46570.6 | wpb 510.9 | bsz 1 | num_updates 18979 | best_loss 9.173
2022-03-06 02:49:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18979 updates
2022-03-06 02:49:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:49:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:49:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 390 @ 18979 updates, score 13.505) (writing took 1.6685651997104287 seconds)
2022-03-06 02:49:58 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-06 02:49:58 | INFO | train | epoch 390 | loss 2.583 | nll_loss 0.424 | ppl 1.34 | wps 27128.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18979 | lr 0.000229543 | gnorm 0.484 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44837
2022-03-06 02:49:58 | INFO | fairseq.trainer | begin training epoch 391
2022-03-06 02:49:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:50:45 | INFO | train_inner | epoch 391:     21 / 49 loss=2.583, nll_loss=0.424, ppl=1.34, wps=27472.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.481, loss_scale=32, train_wall=200, gb_free=21.6, wall=44884
2022-03-06 02:51:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:51:51 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.442 | nll_loss 12.706 | ppl 6682.08 | wps 46669.8 | wpb 510.9 | bsz 1 | num_updates 19028 | best_loss 9.173
2022-03-06 02:51:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19028 updates
2022-03-06 02:51:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:51:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:51:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 391 @ 19028 updates, score 13.442) (writing took 1.7118004113435745 seconds)
2022-03-06 02:51:53 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-06 02:51:53 | INFO | train | epoch 391 | loss 2.582 | nll_loss 0.423 | ppl 1.34 | wps 27711.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19028 | lr 0.000229247 | gnorm 0.478 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44952
2022-03-06 02:51:53 | INFO | fairseq.trainer | begin training epoch 392
2022-03-06 02:51:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:53:46 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 13.535 | nll_loss 12.804 | ppl 7153.52 | wps 46510.4 | wpb 510.9 | bsz 1 | num_updates 19077 | best_loss 9.173
2022-03-06 02:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19077 updates
2022-03-06 02:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 392 @ 19077 updates, score 13.535) (writing took 1.6730411481112242 seconds)
2022-03-06 02:53:48 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-06 02:53:48 | INFO | train | epoch 392 | loss 2.581 | nll_loss 0.423 | ppl 1.34 | wps 27707.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19077 | lr 0.000228952 | gnorm 0.478 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45067
2022-03-06 02:53:48 | INFO | fairseq.trainer | begin training epoch 393
2022-03-06 02:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:54:39 | INFO | train_inner | epoch 393:     23 / 49 loss=2.582, nll_loss=0.423, ppl=1.34, wps=27739.5, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.477, loss_scale=64, train_wall=198, gb_free=21.6, wall=45118
2022-03-06 02:55:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:55:41 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.448 | nll_loss 12.707 | ppl 6686.01 | wps 46529.8 | wpb 510.9 | bsz 1 | num_updates 19125 | best_loss 9.173
2022-03-06 02:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19125 updates
2022-03-06 02:55:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:55:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:55:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 393 @ 19125 updates, score 13.448) (writing took 1.669639523141086 seconds)
2022-03-06 02:55:43 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-06 02:55:43 | INFO | train | epoch 393 | loss 2.58 | nll_loss 0.422 | ppl 1.34 | wps 27133.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19125 | lr 0.000228665 | gnorm 0.474 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45181
2022-03-06 02:55:43 | INFO | fairseq.trainer | begin training epoch 394
2022-03-06 02:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:57:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:57:35 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.496 | nll_loss 12.762 | ppl 6948.17 | wps 46655.2 | wpb 510.9 | bsz 1 | num_updates 19174 | best_loss 9.173
2022-03-06 02:57:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19174 updates
2022-03-06 02:57:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:57:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 394 @ 19174 updates, score 13.496) (writing took 1.619243503548205 seconds)
2022-03-06 02:57:37 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-06 02:57:37 | INFO | train | epoch 394 | loss 2.58 | nll_loss 0.422 | ppl 1.34 | wps 27739 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19174 | lr 0.000228372 | gnorm 0.475 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45296
2022-03-06 02:57:37 | INFO | fairseq.trainer | begin training epoch 395
2022-03-06 02:57:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:58:35 | INFO | train_inner | epoch 395:     26 / 49 loss=2.58, nll_loss=0.422, ppl=1.34, wps=27484.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.475, loss_scale=32, train_wall=200, gb_free=21.6, wall=45354
2022-03-06 02:59:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:59:30 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 13.516 | nll_loss 12.782 | ppl 7043.95 | wps 46614.3 | wpb 510.9 | bsz 1 | num_updates 19223 | best_loss 9.173
2022-03-06 02:59:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19223 updates
2022-03-06 02:59:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:59:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 02:59:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 395 @ 19223 updates, score 13.516) (writing took 1.6695912731811404 seconds)
2022-03-06 02:59:32 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-06 02:59:32 | INFO | train | epoch 395 | loss 2.58 | nll_loss 0.422 | ppl 1.34 | wps 27710.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19223 | lr 0.000228081 | gnorm 0.481 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45410
2022-03-06 02:59:32 | INFO | fairseq.trainer | begin training epoch 396
2022-03-06 02:59:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:00:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:01:25 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 13.443 | nll_loss 12.709 | ppl 6697.85 | wps 46591.8 | wpb 510.9 | bsz 1 | num_updates 19271 | best_loss 9.173
2022-03-06 03:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19271 updates
2022-03-06 03:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 396 @ 19271 updates, score 13.443) (writing took 1.6076347474008799 seconds)
2022-03-06 03:01:26 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-06 03:01:26 | INFO | train | epoch 396 | loss 2.579 | nll_loss 0.421 | ppl 1.34 | wps 27149.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19271 | lr 0.000227797 | gnorm 0.476 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45525
2022-03-06 03:01:26 | INFO | fairseq.trainer | begin training epoch 397
2022-03-06 03:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:02:31 | INFO | train_inner | epoch 397:     29 / 49 loss=2.579, nll_loss=0.421, ppl=1.34, wps=27495.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.48, loss_scale=32, train_wall=200, gb_free=21.6, wall=45590
2022-03-06 03:03:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:03:19 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.589 | nll_loss 12.864 | ppl 7455.37 | wps 46738.9 | wpb 510.9 | bsz 1 | num_updates 19320 | best_loss 9.173
2022-03-06 03:03:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19320 updates
2022-03-06 03:03:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:03:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:03:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 397 @ 19320 updates, score 13.589) (writing took 1.6516498541459441 seconds)
2022-03-06 03:03:21 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-06 03:03:21 | INFO | train | epoch 397 | loss 2.578 | nll_loss 0.421 | ppl 1.34 | wps 27726.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19320 | lr 0.000227508 | gnorm 0.479 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45640
2022-03-06 03:03:21 | INFO | fairseq.trainer | begin training epoch 398
2022-03-06 03:03:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:05:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:05:14 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.58 | nll_loss 12.859 | ppl 7427.96 | wps 46685 | wpb 510.9 | bsz 1 | num_updates 19369 | best_loss 9.173
2022-03-06 03:05:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19369 updates
2022-03-06 03:05:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:05:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:05:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 398 @ 19369 updates, score 13.58) (writing took 1.6804632414132357 seconds)
2022-03-06 03:05:16 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-06 03:05:16 | INFO | train | epoch 398 | loss 2.577 | nll_loss 0.419 | ppl 1.34 | wps 27720.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19369 | lr 0.00022722 | gnorm 0.476 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 45754
2022-03-06 03:05:16 | INFO | fairseq.trainer | begin training epoch 399
2022-03-06 03:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:05:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:06:27 | INFO | train_inner | epoch 399:     32 / 49 loss=2.577, nll_loss=0.419, ppl=1.34, wps=27473.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.475, loss_scale=32, train_wall=200, gb_free=21.6, wall=45826
2022-03-06 03:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:07:09 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 13.501 | nll_loss 12.779 | ppl 7029.29 | wps 46837 | wpb 510.9 | bsz 1 | num_updates 19417 | best_loss 9.173
2022-03-06 03:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19417 updates
2022-03-06 03:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:07:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:07:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 399 @ 19417 updates, score 13.501) (writing took 1.7020486230030656 seconds)
2022-03-06 03:07:11 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-06 03:07:11 | INFO | train | epoch 399 | loss 2.576 | nll_loss 0.419 | ppl 1.34 | wps 27111.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19417 | lr 0.000226939 | gnorm 0.477 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45869
2022-03-06 03:07:11 | INFO | fairseq.trainer | begin training epoch 400
2022-03-06 03:07:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:08:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:09:04 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.505 | nll_loss 12.774 | ppl 7005.78 | wps 46650.6 | wpb 510.9 | bsz 1 | num_updates 19466 | best_loss 9.173
2022-03-06 03:09:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19466 updates
2022-03-06 03:09:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:09:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:09:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 400 @ 19466 updates, score 13.505) (writing took 1.671922706067562 seconds)
2022-03-06 03:09:05 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-06 03:09:05 | INFO | train | epoch 400 | loss 2.576 | nll_loss 0.419 | ppl 1.34 | wps 27700.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19466 | lr 0.000226653 | gnorm 0.471 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45984
2022-03-06 03:09:05 | INFO | fairseq.trainer | begin training epoch 401
2022-03-06 03:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:10:21 | INFO | train_inner | epoch 401:     34 / 49 loss=2.575, nll_loss=0.418, ppl=1.34, wps=27732.5, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.473, loss_scale=32, train_wall=198, gb_free=21.6, wall=46060
2022-03-06 03:10:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:10:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:10:58 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 13.389 | nll_loss 12.649 | ppl 6425.08 | wps 46759.4 | wpb 510.9 | bsz 1 | num_updates 19514 | best_loss 9.173
2022-03-06 03:10:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19514 updates
2022-03-06 03:10:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:11:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:11:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 401 @ 19514 updates, score 13.389) (writing took 1.6365354480221868 seconds)
2022-03-06 03:11:00 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-06 03:11:00 | INFO | train | epoch 401 | loss 2.574 | nll_loss 0.417 | ppl 1.34 | wps 27144.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19514 | lr 0.000226374 | gnorm 0.472 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46099
2022-03-06 03:11:00 | INFO | fairseq.trainer | begin training epoch 402
2022-03-06 03:11:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:12:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:12:53 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.461 | nll_loss 12.725 | ppl 6769.79 | wps 46551.7 | wpb 510.9 | bsz 1 | num_updates 19563 | best_loss 9.173
2022-03-06 03:12:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19563 updates
2022-03-06 03:12:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:12:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:12:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 402 @ 19563 updates, score 13.461) (writing took 1.6660169418901205 seconds)
2022-03-06 03:12:55 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-06 03:12:55 | INFO | train | epoch 402 | loss 2.575 | nll_loss 0.418 | ppl 1.34 | wps 27702.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19563 | lr 0.00022609 | gnorm 0.471 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46213
2022-03-06 03:12:55 | INFO | fairseq.trainer | begin training epoch 403
2022-03-06 03:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:14:17 | INFO | train_inner | epoch 403:     37 / 49 loss=2.575, nll_loss=0.418, ppl=1.34, wps=27494, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.474, loss_scale=32, train_wall=200, gb_free=21.6, wall=46296
2022-03-06 03:14:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:14:48 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 13.628 | nll_loss 12.907 | ppl 7680.21 | wps 46601.3 | wpb 510.9 | bsz 1 | num_updates 19612 | best_loss 9.173
2022-03-06 03:14:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19612 updates
2022-03-06 03:14:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:14:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:14:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 403 @ 19612 updates, score 13.628) (writing took 1.6454794853925705 seconds)
2022-03-06 03:14:49 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-06 03:14:49 | INFO | train | epoch 403 | loss 2.575 | nll_loss 0.418 | ppl 1.34 | wps 27728.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19612 | lr 0.000225808 | gnorm 0.481 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46328
2022-03-06 03:14:49 | INFO | fairseq.trainer | begin training epoch 404
2022-03-06 03:14:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:15:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:16:42 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.556 | nll_loss 12.835 | ppl 7306.21 | wps 46637.4 | wpb 510.9 | bsz 1 | num_updates 19660 | best_loss 9.173
2022-03-06 03:16:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19660 updates
2022-03-06 03:16:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:16:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 404 @ 19660 updates, score 13.556) (writing took 1.6135612120851874 seconds)
2022-03-06 03:16:44 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-06 03:16:44 | INFO | train | epoch 404 | loss 2.573 | nll_loss 0.416 | ppl 1.33 | wps 27155.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19660 | lr 0.000225532 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46443
2022-03-06 03:16:44 | INFO | fairseq.trainer | begin training epoch 405
2022-03-06 03:16:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:18:13 | INFO | train_inner | epoch 405:     40 / 49 loss=2.574, nll_loss=0.417, ppl=1.33, wps=27478.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.473, loss_scale=32, train_wall=200, gb_free=21.6, wall=46532
2022-03-06 03:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:18:37 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 13.508 | nll_loss 12.784 | ppl 7053 | wps 46585.4 | wpb 510.9 | bsz 1 | num_updates 19709 | best_loss 9.173
2022-03-06 03:18:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19709 updates
2022-03-06 03:18:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:18:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:18:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 405 @ 19709 updates, score 13.508) (writing took 1.6863373080268502 seconds)
2022-03-06 03:18:39 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-06 03:18:39 | INFO | train | epoch 405 | loss 2.573 | nll_loss 0.417 | ppl 1.33 | wps 27694.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19709 | lr 0.000225252 | gnorm 0.474 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46557
2022-03-06 03:18:39 | INFO | fairseq.trainer | begin training epoch 406
2022-03-06 03:18:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:20:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:20:32 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.479 | nll_loss 12.749 | ppl 6884.81 | wps 46622.2 | wpb 510.9 | bsz 1 | num_updates 19758 | best_loss 9.173
2022-03-06 03:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19758 updates
2022-03-06 03:20:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:20:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:20:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 406 @ 19758 updates, score 13.479) (writing took 1.6276890570297837 seconds)
2022-03-06 03:20:33 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-06 03:20:33 | INFO | train | epoch 406 | loss 2.573 | nll_loss 0.416 | ppl 1.33 | wps 27722 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19758 | lr 0.000224972 | gnorm 0.473 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46672
2022-03-06 03:20:33 | INFO | fairseq.trainer | begin training epoch 407
2022-03-06 03:20:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:20:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:22:09 | INFO | train_inner | epoch 407:     43 / 49 loss=2.572, nll_loss=0.416, ppl=1.33, wps=27485.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.472, loss_scale=32, train_wall=200, gb_free=21.6, wall=46768
2022-03-06 03:22:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:22:26 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.474 | nll_loss 12.742 | ppl 6852.59 | wps 46646.4 | wpb 510.9 | bsz 1 | num_updates 19806 | best_loss 9.173
2022-03-06 03:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19806 updates
2022-03-06 03:22:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:22:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:22:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 407 @ 19806 updates, score 13.474) (writing took 1.6798973074182868 seconds)
2022-03-06 03:22:28 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-06 03:22:28 | INFO | train | epoch 407 | loss 2.571 | nll_loss 0.415 | ppl 1.33 | wps 27143.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19806 | lr 0.000224699 | gnorm 0.467 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46787
2022-03-06 03:22:28 | INFO | fairseq.trainer | begin training epoch 408
2022-03-06 03:22:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:24:21 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 13.55 | nll_loss 12.823 | ppl 7246.82 | wps 46324.2 | wpb 510.9 | bsz 1 | num_updates 19855 | best_loss 9.173
2022-03-06 03:24:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19855 updates
2022-03-06 03:24:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:24:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:24:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 408 @ 19855 updates, score 13.55) (writing took 1.6492196470499039 seconds)
2022-03-06 03:24:23 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-06 03:24:23 | INFO | train | epoch 408 | loss 2.571 | nll_loss 0.415 | ppl 1.33 | wps 27671.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19855 | lr 0.000224422 | gnorm 0.473 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46901
2022-03-06 03:24:23 | INFO | fairseq.trainer | begin training epoch 409
2022-03-06 03:24:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:25:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:26:05 | INFO | train_inner | epoch 409:     46 / 49 loss=2.571, nll_loss=0.415, ppl=1.33, wps=27458.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.47, loss_scale=32, train_wall=200, gb_free=21.6, wall=47004
2022-03-06 03:26:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:26:16 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.492 | nll_loss 12.764 | ppl 6955.98 | wps 46674 | wpb 510.9 | bsz 1 | num_updates 19903 | best_loss 9.173
2022-03-06 03:26:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19903 updates
2022-03-06 03:26:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:26:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 409 @ 19903 updates, score 13.492) (writing took 1.6248611798509955 seconds)
2022-03-06 03:26:17 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-06 03:26:17 | INFO | train | epoch 409 | loss 2.571 | nll_loss 0.415 | ppl 1.33 | wps 27145.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19903 | lr 0.000224151 | gnorm 0.469 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47016
2022-03-06 03:26:17 | INFO | fairseq.trainer | begin training epoch 410
2022-03-06 03:26:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:28:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:28:10 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 13.52 | nll_loss 12.792 | ppl 7091.92 | wps 46547.6 | wpb 510.9 | bsz 1 | num_updates 19952 | best_loss 9.173
2022-03-06 03:28:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19952 updates
2022-03-06 03:28:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:28:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:28:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 410 @ 19952 updates, score 13.52) (writing took 1.6623685974627733 seconds)
2022-03-06 03:28:12 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-06 03:28:12 | INFO | train | epoch 410 | loss 2.57 | nll_loss 0.414 | ppl 1.33 | wps 27699.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19952 | lr 0.000223876 | gnorm 0.468 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47131
2022-03-06 03:28:12 | INFO | fairseq.trainer | begin training epoch 411
2022-03-06 03:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:29:59 | INFO | train_inner | epoch 411:     48 / 49 loss=2.57, nll_loss=0.414, ppl=1.33, wps=27746.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20000, lr=0.000223607, gnorm=0.47, loss_scale=32, train_wall=198, gb_free=21.6, wall=47238
2022-03-06 03:30:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:30:05 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.55 | nll_loss 12.828 | ppl 7272.05 | wps 46772.5 | wpb 510.9 | bsz 1 | num_updates 20001 | best_loss 9.173
2022-03-06 03:30:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20001 updates
2022-03-06 03:30:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:30:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:30:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 411 @ 20001 updates, score 13.55) (writing took 1.6641902783885598 seconds)
2022-03-06 03:30:07 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-06 03:30:07 | INFO | train | epoch 411 | loss 2.57 | nll_loss 0.414 | ppl 1.33 | wps 27721.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20001 | lr 0.000223601 | gnorm 0.474 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47245
2022-03-06 03:30:07 | INFO | fairseq.trainer | begin training epoch 412
2022-03-06 03:30:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:30:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:31:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:32:00 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.525 | nll_loss 12.8 | ppl 7133.52 | wps 46832.8 | wpb 510.9 | bsz 1 | num_updates 20049 | best_loss 9.173
2022-03-06 03:32:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20049 updates
2022-03-06 03:32:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:32:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:32:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 412 @ 20049 updates, score 13.525) (writing took 1.6804986940696836 seconds)
2022-03-06 03:32:01 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-06 03:32:01 | INFO | train | epoch 412 | loss 2.568 | nll_loss 0.413 | ppl 1.33 | wps 27140.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20049 | lr 0.000223333 | gnorm 0.462 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47360
2022-03-06 03:32:01 | INFO | fairseq.trainer | begin training epoch 413
2022-03-06 03:32:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:33:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:33:55 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 13.512 | nll_loss 12.785 | ppl 7056.03 | wps 46544.4 | wpb 510.9 | bsz 1 | num_updates 20098 | best_loss 9.173
2022-03-06 03:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20098 updates
2022-03-06 03:33:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:33:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 413 @ 20098 updates, score 13.512) (writing took 1.6646679565310478 seconds)
2022-03-06 03:33:56 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-06 03:33:56 | INFO | train | epoch 413 | loss 2.568 | nll_loss 0.412 | ppl 1.33 | wps 27699.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20098 | lr 0.000223061 | gnorm 0.464 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47475
2022-03-06 03:33:56 | INFO | fairseq.trainer | begin training epoch 414
2022-03-06 03:33:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:34:01 | INFO | train_inner | epoch 414:      2 / 49 loss=2.568, nll_loss=0.412, ppl=1.33, wps=26727.9, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=20100, lr=0.00022305, gnorm=0.465, loss_scale=32, train_wall=199, gb_free=21.6, wall=47479
2022-03-06 03:35:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:35:49 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.502 | nll_loss 12.774 | ppl 7004.91 | wps 46463.2 | wpb 510.9 | bsz 1 | num_updates 20147 | best_loss 9.173
2022-03-06 03:35:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20147 updates
2022-03-06 03:35:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:35:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:35:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 414 @ 20147 updates, score 13.502) (writing took 1.6812103800475597 seconds)
2022-03-06 03:35:51 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-06 03:35:51 | INFO | train | epoch 414 | loss 2.568 | nll_loss 0.412 | ppl 1.33 | wps 27684.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20147 | lr 0.00022279 | gnorm 0.471 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47590
2022-03-06 03:35:51 | INFO | fairseq.trainer | begin training epoch 415
2022-03-06 03:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:35:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:37:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:37:44 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.562 | nll_loss 12.842 | ppl 7339.67 | wps 46742.9 | wpb 510.9 | bsz 1 | num_updates 20195 | best_loss 9.173
2022-03-06 03:37:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20195 updates
2022-03-06 03:37:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:37:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:37:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 415 @ 20195 updates, score 13.562) (writing took 1.6478382321074605 seconds)
2022-03-06 03:37:46 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-06 03:37:46 | INFO | train | epoch 415 | loss 2.567 | nll_loss 0.412 | ppl 1.33 | wps 27142.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20195 | lr 0.000222525 | gnorm 0.471 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47704
2022-03-06 03:37:46 | INFO | fairseq.trainer | begin training epoch 416
2022-03-06 03:37:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:37:57 | INFO | train_inner | epoch 416:      5 / 49 loss=2.567, nll_loss=0.412, ppl=1.33, wps=27468.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.471, loss_scale=32, train_wall=200, gb_free=21.6, wall=47716
2022-03-06 03:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:39:39 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.433 | nll_loss 12.704 | ppl 6673.78 | wps 46687.1 | wpb 510.9 | bsz 1 | num_updates 20244 | best_loss 9.173
2022-03-06 03:39:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20244 updates
2022-03-06 03:39:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:39:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:39:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 416 @ 20244 updates, score 13.433) (writing took 1.7754566771909595 seconds)
2022-03-06 03:39:40 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-06 03:39:40 | INFO | train | epoch 416 | loss 2.566 | nll_loss 0.411 | ppl 1.33 | wps 27683.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20244 | lr 0.000222255 | gnorm 0.466 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47819
2022-03-06 03:39:41 | INFO | fairseq.trainer | begin training epoch 417
2022-03-06 03:39:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:40:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:41:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:41:33 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.404 | nll_loss 12.667 | ppl 6504.43 | wps 46585.7 | wpb 510.9 | bsz 1 | num_updates 20292 | best_loss 9.173
2022-03-06 03:41:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20292 updates
2022-03-06 03:41:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:41:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:41:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 417 @ 20292 updates, score 13.404) (writing took 1.6227839970961213 seconds)
2022-03-06 03:41:35 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-06 03:41:35 | INFO | train | epoch 417 | loss 2.566 | nll_loss 0.411 | ppl 1.33 | wps 27165.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20292 | lr 0.000221992 | gnorm 0.468 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47934
2022-03-06 03:41:35 | INFO | fairseq.trainer | begin training epoch 418
2022-03-06 03:41:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:41:53 | INFO | train_inner | epoch 418:      8 / 49 loss=2.566, nll_loss=0.411, ppl=1.33, wps=27483.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.468, loss_scale=32, train_wall=200, gb_free=21.6, wall=47952
2022-03-06 03:43:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:43:28 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.568 | nll_loss 12.845 | ppl 7357.41 | wps 46702.4 | wpb 510.9 | bsz 1 | num_updates 20341 | best_loss 9.173
2022-03-06 03:43:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20341 updates
2022-03-06 03:43:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:43:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:43:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 418 @ 20341 updates, score 13.568) (writing took 1.6517885737121105 seconds)
2022-03-06 03:43:30 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-06 03:43:30 | INFO | train | epoch 418 | loss 2.566 | nll_loss 0.411 | ppl 1.33 | wps 27707.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20341 | lr 0.000221725 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48048
2022-03-06 03:43:30 | INFO | fairseq.trainer | begin training epoch 419
2022-03-06 03:43:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:45:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:45:23 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.408 | nll_loss 12.673 | ppl 6530.55 | wps 46648.5 | wpb 510.9 | bsz 1 | num_updates 20390 | best_loss 9.173
2022-03-06 03:45:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20390 updates
2022-03-06 03:45:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:45:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:45:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 419 @ 20390 updates, score 13.408) (writing took 1.681077416986227 seconds)
2022-03-06 03:45:24 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-06 03:45:24 | INFO | train | epoch 419 | loss 2.565 | nll_loss 0.41 | ppl 1.33 | wps 27721.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20390 | lr 0.000221458 | gnorm 0.467 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48163
2022-03-06 03:45:24 | INFO | fairseq.trainer | begin training epoch 420
2022-03-06 03:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:45:47 | INFO | train_inner | epoch 420:     10 / 49 loss=2.565, nll_loss=0.41, ppl=1.33, wps=27743.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.469, loss_scale=32, train_wall=198, gb_free=21.6, wall=48185
2022-03-06 03:46:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:47:17 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.497 | nll_loss 12.766 | ppl 6967.72 | wps 46516.2 | wpb 510.9 | bsz 1 | num_updates 20438 | best_loss 9.173
2022-03-06 03:47:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20438 updates
2022-03-06 03:47:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:47:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:47:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 420 @ 20438 updates, score 13.497) (writing took 1.6831931667402387 seconds)
2022-03-06 03:47:19 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-06 03:47:19 | INFO | train | epoch 420 | loss 2.563 | nll_loss 0.409 | ppl 1.33 | wps 27137.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20438 | lr 0.000221198 | gnorm 0.463 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48278
2022-03-06 03:47:19 | INFO | fairseq.trainer | begin training epoch 421
2022-03-06 03:47:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:49:12 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.484 | nll_loss 12.753 | ppl 6904.59 | wps 46647.9 | wpb 510.9 | bsz 1 | num_updates 20487 | best_loss 9.173
2022-03-06 03:49:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20487 updates
2022-03-06 03:49:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:49:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:49:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 421 @ 20487 updates, score 13.484) (writing took 1.6902819145470858 seconds)
2022-03-06 03:49:14 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-06 03:49:14 | INFO | train | epoch 421 | loss 2.563 | nll_loss 0.409 | ppl 1.33 | wps 27684.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20487 | lr 0.000220933 | gnorm 0.467 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48393
2022-03-06 03:49:14 | INFO | fairseq.trainer | begin training epoch 422
2022-03-06 03:49:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:49:43 | INFO | train_inner | epoch 422:     13 / 49 loss=2.563, nll_loss=0.409, ppl=1.33, wps=27468.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.467, loss_scale=32, train_wall=200, gb_free=21.6, wall=48422
2022-03-06 03:51:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:51:07 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.558 | nll_loss 12.836 | ppl 7313.09 | wps 46732.6 | wpb 510.9 | bsz 1 | num_updates 20536 | best_loss 9.173
2022-03-06 03:51:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20536 updates
2022-03-06 03:51:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:51:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:51:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 422 @ 20536 updates, score 13.558) (writing took 1.6218718588352203 seconds)
2022-03-06 03:51:08 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-06 03:51:08 | INFO | train | epoch 422 | loss 2.564 | nll_loss 0.409 | ppl 1.33 | wps 27736.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20536 | lr 0.000220669 | gnorm 0.468 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48507
2022-03-06 03:51:08 | INFO | fairseq.trainer | begin training epoch 423
2022-03-06 03:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:51:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:53:01 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.574 | nll_loss 12.856 | ppl 7412.9 | wps 46590.5 | wpb 510.9 | bsz 1 | num_updates 20584 | best_loss 9.173
2022-03-06 03:53:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20584 updates
2022-03-06 03:53:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:53:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:53:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 423 @ 20584 updates, score 13.574) (writing took 1.6552962446585298 seconds)
2022-03-06 03:53:03 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-06 03:53:03 | INFO | train | epoch 423 | loss 2.563 | nll_loss 0.409 | ppl 1.33 | wps 27142.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20584 | lr 0.000220412 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48622
2022-03-06 03:53:03 | INFO | fairseq.trainer | begin training epoch 424
2022-03-06 03:53:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:53:39 | INFO | train_inner | epoch 424:     16 / 49 loss=2.563, nll_loss=0.408, ppl=1.33, wps=27492.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.465, loss_scale=32, train_wall=200, gb_free=21.6, wall=48658
2022-03-06 03:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:54:56 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.517 | nll_loss 12.793 | ppl 7094.65 | wps 46602.3 | wpb 510.9 | bsz 1 | num_updates 20633 | best_loss 9.173
2022-03-06 03:54:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20633 updates
2022-03-06 03:54:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:54:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:54:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 424 @ 20633 updates, score 13.517) (writing took 1.6538771521300077 seconds)
2022-03-06 03:54:58 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-06 03:54:58 | INFO | train | epoch 424 | loss 2.561 | nll_loss 0.407 | ppl 1.33 | wps 27701.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20633 | lr 0.00022015 | gnorm 0.462 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48737
2022-03-06 03:54:58 | INFO | fairseq.trainer | begin training epoch 425
2022-03-06 03:54:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:56:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:56:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:56:51 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.53 | nll_loss 12.806 | ppl 7160.65 | wps 46929.7 | wpb 510.9 | bsz 1 | num_updates 20681 | best_loss 9.173
2022-03-06 03:56:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20681 updates
2022-03-06 03:56:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:56:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:56:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 425 @ 20681 updates, score 13.53) (writing took 1.6278177807107568 seconds)
2022-03-06 03:56:53 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-06 03:56:53 | INFO | train | epoch 425 | loss 2.561 | nll_loss 0.407 | ppl 1.33 | wps 27150.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20681 | lr 0.000219894 | gnorm 0.467 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48851
2022-03-06 03:56:53 | INFO | fairseq.trainer | begin training epoch 426
2022-03-06 03:56:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:57:35 | INFO | train_inner | epoch 426:     19 / 49 loss=2.561, nll_loss=0.407, ppl=1.33, wps=27484.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.466, loss_scale=32, train_wall=200, gb_free=21.6, wall=48894
2022-03-06 03:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:58:46 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.459 | nll_loss 12.726 | ppl 6774.24 | wps 46519 | wpb 510.9 | bsz 1 | num_updates 20730 | best_loss 9.173
2022-03-06 03:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20730 updates
2022-03-06 03:58:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:58:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 03:58:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 426 @ 20730 updates, score 13.459) (writing took 1.6224802266806364 seconds)
2022-03-06 03:58:47 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-06 03:58:47 | INFO | train | epoch 426 | loss 2.56 | nll_loss 0.407 | ppl 1.33 | wps 27721.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20730 | lr 0.000219634 | gnorm 0.463 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48966
2022-03-06 03:58:47 | INFO | fairseq.trainer | begin training epoch 427
2022-03-06 03:58:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:00:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:00:40 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.666 | nll_loss 12.959 | ppl 7960.32 | wps 46639.2 | wpb 510.9 | bsz 1 | num_updates 20779 | best_loss 9.173
2022-03-06 04:00:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20779 updates
2022-03-06 04:00:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:00:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:00:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 427 @ 20779 updates, score 13.666) (writing took 1.6686487132683396 seconds)
2022-03-06 04:00:42 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-06 04:00:42 | INFO | train | epoch 427 | loss 2.56 | nll_loss 0.407 | ppl 1.33 | wps 27723.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20779 | lr 0.000219375 | gnorm 0.467 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49080
2022-03-06 04:00:42 | INFO | fairseq.trainer | begin training epoch 428
2022-03-06 04:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:01:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:01:31 | INFO | train_inner | epoch 428:     22 / 49 loss=2.56, nll_loss=0.407, ppl=1.33, wps=27489, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.466, loss_scale=32, train_wall=200, gb_free=21.6, wall=49130
2022-03-06 04:02:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:02:35 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.469 | nll_loss 12.744 | ppl 6861.31 | wps 46546 | wpb 510.9 | bsz 1 | num_updates 20827 | best_loss 9.173
2022-03-06 04:02:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20827 updates
2022-03-06 04:02:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:02:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:02:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 428 @ 20827 updates, score 13.469) (writing took 1.6339600766077638 seconds)
2022-03-06 04:02:36 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-06 04:02:36 | INFO | train | epoch 428 | loss 2.559 | nll_loss 0.406 | ppl 1.32 | wps 27140 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20827 | lr 0.000219122 | gnorm 0.465 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49195
2022-03-06 04:02:36 | INFO | fairseq.trainer | begin training epoch 429
2022-03-06 04:02:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:04:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:04:29 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 13.541 | nll_loss 12.824 | ppl 7252.99 | wps 46610.5 | wpb 510.9 | bsz 1 | num_updates 20876 | best_loss 9.173
2022-03-06 04:04:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20876 updates
2022-03-06 04:04:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:04:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:04:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 429 @ 20876 updates, score 13.541) (writing took 1.71661267708987 seconds)
2022-03-06 04:04:31 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-06 04:04:31 | INFO | train | epoch 429 | loss 2.559 | nll_loss 0.405 | ppl 1.32 | wps 27735.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20876 | lr 0.000218865 | gnorm 0.465 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49310
2022-03-06 04:04:31 | INFO | fairseq.trainer | begin training epoch 430
2022-03-06 04:04:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:05:25 | INFO | train_inner | epoch 430:     24 / 49 loss=2.559, nll_loss=0.406, ppl=1.32, wps=27752.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.463, loss_scale=32, train_wall=198, gb_free=21.6, wall=49363
2022-03-06 04:06:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:06:24 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.578 | nll_loss 12.864 | ppl 7453.18 | wps 46762.2 | wpb 510.9 | bsz 1 | num_updates 20925 | best_loss 9.173
2022-03-06 04:06:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20925 updates
2022-03-06 04:06:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:06:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:06:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 430 @ 20925 updates, score 13.578) (writing took 1.615835308097303 seconds)
2022-03-06 04:06:26 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-06 04:06:26 | INFO | train | epoch 430 | loss 2.558 | nll_loss 0.405 | ppl 1.32 | wps 27722 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20925 | lr 0.000218609 | gnorm 0.458 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49424
2022-03-06 04:06:26 | INFO | fairseq.trainer | begin training epoch 431
2022-03-06 04:06:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:07:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 04:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:08:19 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.508 | nll_loss 12.785 | ppl 7056.19 | wps 46666.1 | wpb 510.9 | bsz 1 | num_updates 20972 | best_loss 9.173
2022-03-06 04:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20972 updates
2022-03-06 04:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:08:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:08:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 431 @ 20972 updates, score 13.508) (writing took 1.6480270493775606 seconds)
2022-03-06 04:08:20 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-06 04:08:20 | INFO | train | epoch 431 | loss 2.558 | nll_loss 0.405 | ppl 1.32 | wps 26582.6 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 20972 | lr 0.000218364 | gnorm 0.467 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 49539
2022-03-06 04:08:20 | INFO | fairseq.trainer | begin training epoch 432
2022-03-06 04:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:09:23 | INFO | train_inner | epoch 432:     28 / 49 loss=2.558, nll_loss=0.405, ppl=1.32, wps=27249, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.463, loss_scale=16, train_wall=202, gb_free=21.6, wall=49601
2022-03-06 04:10:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:10:13 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.627 | nll_loss 12.908 | ppl 7686.43 | wps 46586.3 | wpb 510.9 | bsz 1 | num_updates 21021 | best_loss 9.173
2022-03-06 04:10:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21021 updates
2022-03-06 04:10:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:10:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:10:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 432 @ 21021 updates, score 13.627) (writing took 1.6574000380933285 seconds)
2022-03-06 04:10:15 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-06 04:10:15 | INFO | train | epoch 432 | loss 2.558 | nll_loss 0.405 | ppl 1.32 | wps 27731.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21021 | lr 0.000218109 | gnorm 0.458 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 49654
2022-03-06 04:10:15 | INFO | fairseq.trainer | begin training epoch 433
2022-03-06 04:10:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:12:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:12:08 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.58 | nll_loss 12.861 | ppl 7439.69 | wps 46656.5 | wpb 510.9 | bsz 1 | num_updates 21070 | best_loss 9.173
2022-03-06 04:12:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21070 updates
2022-03-06 04:12:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:12:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:12:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 433 @ 21070 updates, score 13.58) (writing took 1.5953054409474134 seconds)
2022-03-06 04:12:10 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-06 04:12:10 | INFO | train | epoch 433 | loss 2.557 | nll_loss 0.404 | ppl 1.32 | wps 27725.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21070 | lr 0.000217855 | gnorm 0.466 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 49768
2022-03-06 04:12:10 | INFO | fairseq.trainer | begin training epoch 434
2022-03-06 04:12:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:13:17 | INFO | train_inner | epoch 434:     30 / 49 loss=2.557, nll_loss=0.404, ppl=1.32, wps=27754.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.464, loss_scale=32, train_wall=198, gb_free=21.6, wall=49835
2022-03-06 04:13:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:14:03 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.532 | nll_loss 12.804 | ppl 7150.13 | wps 46706.4 | wpb 510.9 | bsz 1 | num_updates 21119 | best_loss 9.173
2022-03-06 04:14:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21119 updates
2022-03-06 04:14:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:14:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:14:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 434 @ 21119 updates, score 13.532) (writing took 1.6316030845046043 seconds)
2022-03-06 04:14:04 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-06 04:14:04 | INFO | train | epoch 434 | loss 2.556 | nll_loss 0.403 | ppl 1.32 | wps 27721.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21119 | lr 0.000217602 | gnorm 0.468 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49883
2022-03-06 04:14:04 | INFO | fairseq.trainer | begin training epoch 435
2022-03-06 04:14:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:15:57 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.478 | nll_loss 12.748 | ppl 6878.75 | wps 46751.6 | wpb 510.9 | bsz 1 | num_updates 21168 | best_loss 9.173
2022-03-06 04:15:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21168 updates
2022-03-06 04:15:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:15:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:15:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 435 @ 21168 updates, score 13.478) (writing took 1.6852890085428953 seconds)
2022-03-06 04:15:59 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-06 04:15:59 | INFO | train | epoch 435 | loss 2.556 | nll_loss 0.404 | ppl 1.32 | wps 27712.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21168 | lr 0.00021735 | gnorm 0.469 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49998
2022-03-06 04:15:59 | INFO | fairseq.trainer | begin training epoch 436
2022-03-06 04:15:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:17:10 | INFO | train_inner | epoch 436:     32 / 49 loss=2.556, nll_loss=0.404, ppl=1.32, wps=27752.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.466, loss_scale=32, train_wall=198, gb_free=21.6, wall=50069
2022-03-06 04:17:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:17:52 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.444 | nll_loss 12.714 | ppl 6718.91 | wps 46656.4 | wpb 510.9 | bsz 1 | num_updates 21216 | best_loss 9.173
2022-03-06 04:17:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21216 updates
2022-03-06 04:17:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:17:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 436 @ 21216 updates, score 13.444) (writing took 1.6180102471262217 seconds)
2022-03-06 04:17:53 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-06 04:17:53 | INFO | train | epoch 436 | loss 2.555 | nll_loss 0.402 | ppl 1.32 | wps 27172.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21216 | lr 0.000217104 | gnorm 0.459 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50112
2022-03-06 04:17:53 | INFO | fairseq.trainer | begin training epoch 437
2022-03-06 04:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:19:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:19:46 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.558 | nll_loss 12.841 | ppl 7336.54 | wps 46604.7 | wpb 510.9 | bsz 1 | num_updates 21265 | best_loss 9.173
2022-03-06 04:19:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21265 updates
2022-03-06 04:19:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:19:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:19:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 437 @ 21265 updates, score 13.558) (writing took 1.7188359946012497 seconds)
2022-03-06 04:19:48 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-06 04:19:48 | INFO | train | epoch 437 | loss 2.555 | nll_loss 0.403 | ppl 1.32 | wps 27711.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21265 | lr 0.000216854 | gnorm 0.463 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50227
2022-03-06 04:19:48 | INFO | fairseq.trainer | begin training epoch 438
2022-03-06 04:19:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:21:06 | INFO | train_inner | epoch 438:     35 / 49 loss=2.554, nll_loss=0.402, ppl=1.32, wps=27490.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.46, loss_scale=32, train_wall=200, gb_free=21.6, wall=50305
2022-03-06 04:21:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:21:41 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.574 | nll_loss 12.859 | ppl 7431.37 | wps 46726.4 | wpb 510.9 | bsz 1 | num_updates 21314 | best_loss 9.173
2022-03-06 04:21:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21314 updates
2022-03-06 04:21:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:21:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:21:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 438 @ 21314 updates, score 13.574) (writing took 1.6147801699116826 seconds)
2022-03-06 04:21:43 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-06 04:21:43 | INFO | train | epoch 438 | loss 2.554 | nll_loss 0.402 | ppl 1.32 | wps 27727.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21314 | lr 0.000216605 | gnorm 0.461 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50341
2022-03-06 04:21:43 | INFO | fairseq.trainer | begin training epoch 439
2022-03-06 04:21:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:22:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:23:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:23:36 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.628 | nll_loss 12.915 | ppl 7725.31 | wps 46546 | wpb 510.9 | bsz 1 | num_updates 21362 | best_loss 9.173
2022-03-06 04:23:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21362 updates
2022-03-06 04:23:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:23:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:23:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 439 @ 21362 updates, score 13.628) (writing took 1.6369550293311477 seconds)
2022-03-06 04:23:37 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-06 04:23:37 | INFO | train | epoch 439 | loss 2.554 | nll_loss 0.401 | ppl 1.32 | wps 27147.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21362 | lr 0.000216361 | gnorm 0.456 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50456
2022-03-06 04:23:37 | INFO | fairseq.trainer | begin training epoch 440
2022-03-06 04:23:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:25:02 | INFO | train_inner | epoch 440:     38 / 49 loss=2.554, nll_loss=0.402, ppl=1.32, wps=27502.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.462, loss_scale=32, train_wall=200, gb_free=21.6, wall=50541
2022-03-06 04:25:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:25:30 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 13.586 | nll_loss 12.875 | ppl 7509.74 | wps 46583.9 | wpb 510.9 | bsz 1 | num_updates 21411 | best_loss 9.173
2022-03-06 04:25:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21411 updates
2022-03-06 04:25:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:25:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:25:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 440 @ 21411 updates, score 13.586) (writing took 1.6591164572164416 seconds)
2022-03-06 04:25:32 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-06 04:25:32 | INFO | train | epoch 440 | loss 2.553 | nll_loss 0.401 | ppl 1.32 | wps 27738 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21411 | lr 0.000216113 | gnorm 0.464 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50571
2022-03-06 04:25:32 | INFO | fairseq.trainer | begin training epoch 441
2022-03-06 04:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:27:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:27:25 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.564 | nll_loss 12.843 | ppl 7349.12 | wps 46685.2 | wpb 510.9 | bsz 1 | num_updates 21460 | best_loss 9.173
2022-03-06 04:27:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21460 updates
2022-03-06 04:27:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:27:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:27:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 441 @ 21460 updates, score 13.564) (writing took 1.677123594097793 seconds)
2022-03-06 04:27:27 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-06 04:27:27 | INFO | train | epoch 441 | loss 2.553 | nll_loss 0.401 | ppl 1.32 | wps 27714.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21460 | lr 0.000215866 | gnorm 0.451 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 50685
2022-03-06 04:27:27 | INFO | fairseq.trainer | begin training epoch 442
2022-03-06 04:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:27:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:28:58 | INFO | train_inner | epoch 442:     41 / 49 loss=2.552, nll_loss=0.4, ppl=1.32, wps=27482.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.452, loss_scale=32, train_wall=200, gb_free=21.6, wall=50777
2022-03-06 04:29:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:29:20 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.439 | nll_loss 12.705 | ppl 6677.39 | wps 46389.2 | wpb 510.9 | bsz 1 | num_updates 21508 | best_loss 9.173
2022-03-06 04:29:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21508 updates
2022-03-06 04:29:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:29:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:29:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 442 @ 21508 updates, score 13.439) (writing took 1.7023283392190933 seconds)
2022-03-06 04:29:21 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-06 04:29:21 | INFO | train | epoch 442 | loss 2.552 | nll_loss 0.4 | ppl 1.32 | wps 27128.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21508 | lr 0.000215625 | gnorm 0.456 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50800
2022-03-06 04:29:21 | INFO | fairseq.trainer | begin training epoch 443
2022-03-06 04:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:31:14 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.52 | nll_loss 12.8 | ppl 7132.32 | wps 46720.4 | wpb 510.9 | bsz 1 | num_updates 21557 | best_loss 9.173
2022-03-06 04:31:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21557 updates
2022-03-06 04:31:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:31:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:31:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 443 @ 21557 updates, score 13.52) (writing took 1.6797734815627337 seconds)
2022-03-06 04:31:16 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-06 04:31:16 | INFO | train | epoch 443 | loss 2.552 | nll_loss 0.4 | ppl 1.32 | wps 27729.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21557 | lr 0.00021538 | gnorm 0.463 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50915
2022-03-06 04:31:16 | INFO | fairseq.trainer | begin training epoch 444
2022-03-06 04:31:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:32:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:32:54 | INFO | train_inner | epoch 444:     44 / 49 loss=2.552, nll_loss=0.4, ppl=1.32, wps=27490.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.457, loss_scale=32, train_wall=200, gb_free=21.6, wall=51013
2022-03-06 04:33:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:33:09 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.54 | nll_loss 12.816 | ppl 7209.02 | wps 46628.6 | wpb 510.9 | bsz 1 | num_updates 21605 | best_loss 9.173
2022-03-06 04:33:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21605 updates
2022-03-06 04:33:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:33:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:33:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 444 @ 21605 updates, score 13.54) (writing took 1.6507604252547026 seconds)
2022-03-06 04:33:11 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-06 04:33:11 | INFO | train | epoch 444 | loss 2.551 | nll_loss 0.4 | ppl 1.32 | wps 27156 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21605 | lr 0.000215141 | gnorm 0.451 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51029
2022-03-06 04:33:11 | INFO | fairseq.trainer | begin training epoch 445
2022-03-06 04:33:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:35:03 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.534 | nll_loss 12.816 | ppl 7210.58 | wps 46160.7 | wpb 510.9 | bsz 1 | num_updates 21654 | best_loss 9.173
2022-03-06 04:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21654 updates
2022-03-06 04:35:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:35:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:35:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 445 @ 21654 updates, score 13.534) (writing took 1.65165460947901 seconds)
2022-03-06 04:35:05 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-06 04:35:05 | INFO | train | epoch 445 | loss 2.551 | nll_loss 0.399 | ppl 1.32 | wps 27740.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21654 | lr 0.000214897 | gnorm 0.457 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51144
2022-03-06 04:35:05 | INFO | fairseq.trainer | begin training epoch 446
2022-03-06 04:35:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:36:48 | INFO | train_inner | epoch 446:     46 / 49 loss=2.551, nll_loss=0.399, ppl=1.32, wps=27767.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.458, loss_scale=32, train_wall=198, gb_free=21.6, wall=51246
2022-03-06 04:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:36:58 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.558 | nll_loss 12.843 | ppl 7346.17 | wps 46607.3 | wpb 510.9 | bsz 1 | num_updates 21703 | best_loss 9.173
2022-03-06 04:36:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21703 updates
2022-03-06 04:36:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:37:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:37:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 446 @ 21703 updates, score 13.558) (writing took 1.6556686107069254 seconds)
2022-03-06 04:37:00 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-06 04:37:00 | INFO | train | epoch 446 | loss 2.551 | nll_loss 0.399 | ppl 1.32 | wps 27727.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21703 | lr 0.000214655 | gnorm 0.457 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51258
2022-03-06 04:37:00 | INFO | fairseq.trainer | begin training epoch 447
2022-03-06 04:37:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:38:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:38:53 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.548 | nll_loss 12.83 | ppl 7281.28 | wps 46580 | wpb 510.9 | bsz 1 | num_updates 21751 | best_loss 9.173
2022-03-06 04:38:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21751 updates
2022-03-06 04:38:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:38:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:38:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 447 @ 21751 updates, score 13.548) (writing took 1.7126092230901122 seconds)
2022-03-06 04:38:55 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-06 04:38:55 | INFO | train | epoch 447 | loss 2.55 | nll_loss 0.399 | ppl 1.32 | wps 27117.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21751 | lr 0.000214418 | gnorm 0.457 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51373
2022-03-06 04:38:55 | INFO | fairseq.trainer | begin training epoch 448
2022-03-06 04:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:40:43 | INFO | train_inner | epoch 448:     49 / 49 loss=2.55, nll_loss=0.398, ppl=1.32, wps=27463.4, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=21800, lr=0.000214176, gnorm=0.457, loss_scale=32, train_wall=199, gb_free=21.6, wall=51481
2022-03-06 04:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:40:48 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.531 | nll_loss 12.814 | ppl 7201.29 | wps 46615 | wpb 510.9 | bsz 1 | num_updates 21800 | best_loss 9.173
2022-03-06 04:40:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21800 updates
2022-03-06 04:40:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:40:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:40:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 448 @ 21800 updates, score 13.531) (writing took 1.7116739535704255 seconds)
2022-03-06 04:40:49 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-06 04:40:49 | INFO | train | epoch 448 | loss 2.549 | nll_loss 0.398 | ppl 1.32 | wps 27707.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21800 | lr 0.000214176 | gnorm 0.454 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51488
2022-03-06 04:40:49 | INFO | fairseq.trainer | begin training epoch 449
2022-03-06 04:40:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:42:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:42:42 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.526 | nll_loss 12.803 | ppl 7145.4 | wps 46539.7 | wpb 510.9 | bsz 1 | num_updates 21849 | best_loss 9.173
2022-03-06 04:42:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21849 updates
2022-03-06 04:42:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:42:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:42:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 449 @ 21849 updates, score 13.526) (writing took 1.6815560599789023 seconds)
2022-03-06 04:42:44 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-06 04:42:44 | INFO | train | epoch 449 | loss 2.548 | nll_loss 0.397 | ppl 1.32 | wps 27734.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21849 | lr 0.000213936 | gnorm 0.453 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51603
2022-03-06 04:42:44 | INFO | fairseq.trainer | begin training epoch 450
2022-03-06 04:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:43:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:44:37 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.535 | nll_loss 12.815 | ppl 7207.9 | wps 46587 | wpb 510.9 | bsz 1 | num_updates 21897 | best_loss 9.173
2022-03-06 04:44:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21897 updates
2022-03-06 04:44:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:44:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:44:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 450 @ 21897 updates, score 13.535) (writing took 1.7126562278717756 seconds)
2022-03-06 04:44:39 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-06 04:44:39 | INFO | train | epoch 450 | loss 2.548 | nll_loss 0.397 | ppl 1.32 | wps 27135.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21897 | lr 0.000213702 | gnorm 0.454 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51717
2022-03-06 04:44:39 | INFO | fairseq.trainer | begin training epoch 451
2022-03-06 04:44:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:44:45 | INFO | train_inner | epoch 451:      3 / 49 loss=2.548, nll_loss=0.397, ppl=1.32, wps=26747.1, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.454, loss_scale=32, train_wall=200, gb_free=21.6, wall=51724
2022-03-06 04:46:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:46:31 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.426 | nll_loss 12.69 | ppl 6606.02 | wps 46689.1 | wpb 510.9 | bsz 1 | num_updates 21946 | best_loss 9.173
2022-03-06 04:46:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21946 updates
2022-03-06 04:46:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:46:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:46:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 451 @ 21946 updates, score 13.426) (writing took 1.6992423962801695 seconds)
2022-03-06 04:46:33 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-06 04:46:33 | INFO | train | epoch 451 | loss 2.547 | nll_loss 0.397 | ppl 1.32 | wps 27716.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21946 | lr 0.000213463 | gnorm 0.453 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51832
2022-03-06 04:46:33 | INFO | fairseq.trainer | begin training epoch 452
2022-03-06 04:46:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:48:26 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.424 | nll_loss 12.695 | ppl 6631.51 | wps 46616.5 | wpb 510.9 | bsz 1 | num_updates 21995 | best_loss 9.173
2022-03-06 04:48:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21995 updates
2022-03-06 04:48:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:48:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:48:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 452 @ 21995 updates, score 13.424) (writing took 1.6838710932061076 seconds)
2022-03-06 04:48:28 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-06 04:48:28 | INFO | train | epoch 452 | loss 2.548 | nll_loss 0.397 | ppl 1.32 | wps 27711.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21995 | lr 0.000213225 | gnorm 0.457 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51947
2022-03-06 04:48:28 | INFO | fairseq.trainer | begin training epoch 453
2022-03-06 04:48:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:48:39 | INFO | train_inner | epoch 453:      5 / 49 loss=2.547, nll_loss=0.397, ppl=1.32, wps=27749.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.454, loss_scale=64, train_wall=198, gb_free=21.6, wall=51958
2022-03-06 04:48:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:50:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:50:21 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.563 | nll_loss 12.847 | ppl 7368.95 | wps 46587.2 | wpb 510.9 | bsz 1 | num_updates 22043 | best_loss 9.173
2022-03-06 04:50:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22043 updates
2022-03-06 04:50:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:50:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 453 @ 22043 updates, score 13.563) (writing took 1.681260828860104 seconds)
2022-03-06 04:50:23 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-06 04:50:23 | INFO | train | epoch 453 | loss 2.547 | nll_loss 0.397 | ppl 1.32 | wps 27150.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22043 | lr 0.000212993 | gnorm 0.452 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52061
2022-03-06 04:50:23 | INFO | fairseq.trainer | begin training epoch 454
2022-03-06 04:50:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:52:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:52:16 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.54 | nll_loss 12.83 | ppl 7281.38 | wps 46743.2 | wpb 510.9 | bsz 1 | num_updates 22092 | best_loss 9.173
2022-03-06 04:52:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22092 updates
2022-03-06 04:52:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:52:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:52:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 454 @ 22092 updates, score 13.54) (writing took 1.7095745196565986 seconds)
2022-03-06 04:52:17 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-06 04:52:17 | INFO | train | epoch 454 | loss 2.546 | nll_loss 0.396 | ppl 1.32 | wps 27702 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22092 | lr 0.000212756 | gnorm 0.461 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52176
2022-03-06 04:52:17 | INFO | fairseq.trainer | begin training epoch 455
2022-03-06 04:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:52:35 | INFO | train_inner | epoch 455:      8 / 49 loss=2.547, nll_loss=0.396, ppl=1.32, wps=27483.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.456, loss_scale=32, train_wall=200, gb_free=21.6, wall=52194
2022-03-06 04:53:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:54:10 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.4 | nll_loss 12.669 | ppl 6510.35 | wps 46749.7 | wpb 510.9 | bsz 1 | num_updates 22140 | best_loss 9.173
2022-03-06 04:54:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22140 updates
2022-03-06 04:54:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:54:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:54:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 455 @ 22140 updates, score 13.4) (writing took 1.689926266670227 seconds)
2022-03-06 04:54:12 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-06 04:54:12 | INFO | train | epoch 455 | loss 2.545 | nll_loss 0.395 | ppl 1.31 | wps 27133 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22140 | lr 0.000212526 | gnorm 0.451 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52291
2022-03-06 04:54:12 | INFO | fairseq.trainer | begin training epoch 456
2022-03-06 04:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:56:05 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.42 | nll_loss 12.69 | ppl 6610.01 | wps 46472.3 | wpb 510.9 | bsz 1 | num_updates 22189 | best_loss 9.173
2022-03-06 04:56:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22189 updates
2022-03-06 04:56:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:56:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:56:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 456 @ 22189 updates, score 13.42) (writing took 1.645286701619625 seconds)
2022-03-06 04:56:07 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-06 04:56:07 | INFO | train | epoch 456 | loss 2.545 | nll_loss 0.395 | ppl 1.31 | wps 27732.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22189 | lr 0.000212291 | gnorm 0.453 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52405
2022-03-06 04:56:07 | INFO | fairseq.trainer | begin training epoch 457
2022-03-06 04:56:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:31 | INFO | train_inner | epoch 457:     11 / 49 loss=2.545, nll_loss=0.395, ppl=1.31, wps=27485.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.454, loss_scale=32, train_wall=200, gb_free=21.6, wall=52430
2022-03-06 04:57:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:58:00 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.408 | nll_loss 12.679 | ppl 6558.19 | wps 46693.5 | wpb 510.9 | bsz 1 | num_updates 22238 | best_loss 9.173
2022-03-06 04:58:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22238 updates
2022-03-06 04:58:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:58:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:58:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 457 @ 22238 updates, score 13.408) (writing took 1.6739133186638355 seconds)
2022-03-06 04:58:01 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-06 04:58:01 | INFO | train | epoch 457 | loss 2.545 | nll_loss 0.395 | ppl 1.31 | wps 27685.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22238 | lr 0.000212057 | gnorm 0.458 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52520
2022-03-06 04:58:01 | INFO | fairseq.trainer | begin training epoch 458
2022-03-06 04:58:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:58:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:59:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:59:54 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.594 | nll_loss 12.887 | ppl 7576.25 | wps 46396.5 | wpb 510.9 | bsz 1 | num_updates 22286 | best_loss 9.173
2022-03-06 04:59:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22286 updates
2022-03-06 04:59:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:59:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 04:59:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 458 @ 22286 updates, score 13.594) (writing took 1.677224108017981 seconds)
2022-03-06 04:59:56 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-06 04:59:56 | INFO | train | epoch 458 | loss 2.544 | nll_loss 0.394 | ppl 1.31 | wps 27146.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22286 | lr 0.000211828 | gnorm 0.452 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52635
2022-03-06 04:59:56 | INFO | fairseq.trainer | begin training epoch 459
2022-03-06 04:59:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:00:27 | INFO | train_inner | epoch 459:     14 / 49 loss=2.544, nll_loss=0.394, ppl=1.31, wps=27470.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.452, loss_scale=32, train_wall=200, gb_free=21.6, wall=52666
2022-03-06 05:01:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:01:49 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.489 | nll_loss 12.77 | ppl 6984.09 | wps 46570.7 | wpb 510.9 | bsz 1 | num_updates 22335 | best_loss 9.173
2022-03-06 05:01:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22335 updates
2022-03-06 05:01:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:01:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:01:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 459 @ 22335 updates, score 13.489) (writing took 1.7166367257013917 seconds)
2022-03-06 05:01:51 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-06 05:01:51 | INFO | train | epoch 459 | loss 2.544 | nll_loss 0.394 | ppl 1.31 | wps 27702.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22335 | lr 0.000211596 | gnorm 0.445 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52749
2022-03-06 05:01:51 | INFO | fairseq.trainer | begin training epoch 460
2022-03-06 05:01:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:03:44 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.465 | nll_loss 12.739 | ppl 6835.51 | wps 46602.3 | wpb 510.9 | bsz 1 | num_updates 22384 | best_loss 9.173
2022-03-06 05:03:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22384 updates
2022-03-06 05:03:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:03:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:03:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 460 @ 22384 updates, score 13.465) (writing took 1.6496833954006433 seconds)
2022-03-06 05:03:45 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-06 05:03:45 | INFO | train | epoch 460 | loss 2.544 | nll_loss 0.395 | ppl 1.31 | wps 27720.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22384 | lr 0.000211364 | gnorm 0.453 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52864
2022-03-06 05:03:45 | INFO | fairseq.trainer | begin training epoch 461
2022-03-06 05:03:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:04:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:04:23 | INFO | train_inner | epoch 461:     17 / 49 loss=2.544, nll_loss=0.394, ppl=1.31, wps=27484.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.452, loss_scale=32, train_wall=200, gb_free=21.6, wall=52902
2022-03-06 05:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:05:38 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.532 | nll_loss 12.817 | ppl 7216.15 | wps 46185.8 | wpb 510.9 | bsz 1 | num_updates 22432 | best_loss 9.173
2022-03-06 05:05:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22432 updates
2022-03-06 05:05:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:05:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 461 @ 22432 updates, score 13.532) (writing took 1.7004803288727999 seconds)
2022-03-06 05:05:40 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-06 05:05:40 | INFO | train | epoch 461 | loss 2.544 | nll_loss 0.394 | ppl 1.31 | wps 27142.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22432 | lr 0.000211138 | gnorm 0.456 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52979
2022-03-06 05:05:40 | INFO | fairseq.trainer | begin training epoch 462
2022-03-06 05:05:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:06:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 05:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:07:33 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.506 | nll_loss 12.782 | ppl 7040.76 | wps 46702.6 | wpb 510.9 | bsz 1 | num_updates 22480 | best_loss 9.173
2022-03-06 05:07:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22480 updates
2022-03-06 05:07:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:07:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:07:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 462 @ 22480 updates, score 13.506) (writing took 1.6893938649445772 seconds)
2022-03-06 05:07:35 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-06 05:07:35 | INFO | train | epoch 462 | loss 2.542 | nll_loss 0.393 | ppl 1.31 | wps 27154.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22480 | lr 0.000210912 | gnorm 0.447 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 53093
2022-03-06 05:07:35 | INFO | fairseq.trainer | begin training epoch 463
2022-03-06 05:07:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:08:19 | INFO | train_inner | epoch 463:     20 / 49 loss=2.543, nll_loss=0.393, ppl=1.31, wps=27488.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.45, loss_scale=16, train_wall=200, gb_free=21.6, wall=53138
2022-03-06 05:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:09:28 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.563 | nll_loss 12.848 | ppl 7371.2 | wps 46570.8 | wpb 510.9 | bsz 1 | num_updates 22529 | best_loss 9.173
2022-03-06 05:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22529 updates
2022-03-06 05:09:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:09:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:09:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 463 @ 22529 updates, score 13.563) (writing took 1.6649252427741885 seconds)
2022-03-06 05:09:29 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-06 05:09:29 | INFO | train | epoch 463 | loss 2.543 | nll_loss 0.393 | ppl 1.31 | wps 27705.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22529 | lr 0.000210683 | gnorm 0.454 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 53208
2022-03-06 05:09:29 | INFO | fairseq.trainer | begin training epoch 464
2022-03-06 05:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:11:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:11:22 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.484 | nll_loss 12.757 | ppl 6920.05 | wps 46566.5 | wpb 510.9 | bsz 1 | num_updates 22578 | best_loss 9.173
2022-03-06 05:11:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22578 updates
2022-03-06 05:11:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:11:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:11:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 464 @ 22578 updates, score 13.484) (writing took 1.6658053621649742 seconds)
2022-03-06 05:11:24 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-06 05:11:24 | INFO | train | epoch 464 | loss 2.541 | nll_loss 0.392 | ppl 1.31 | wps 27715.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22578 | lr 0.000210454 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53323
2022-03-06 05:11:24 | INFO | fairseq.trainer | begin training epoch 465
2022-03-06 05:11:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:12:13 | INFO | train_inner | epoch 465:     22 / 49 loss=2.542, nll_loss=0.393, ppl=1.31, wps=27742, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.454, loss_scale=32, train_wall=198, gb_free=21.6, wall=53372
2022-03-06 05:13:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:13:17 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.462 | nll_loss 12.737 | ppl 6827.27 | wps 46509.5 | wpb 510.9 | bsz 1 | num_updates 22627 | best_loss 9.173
2022-03-06 05:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22627 updates
2022-03-06 05:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:13:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:13:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 465 @ 22627 updates, score 13.462) (writing took 1.6679698722437024 seconds)
2022-03-06 05:13:19 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-06 05:13:19 | INFO | train | epoch 465 | loss 2.542 | nll_loss 0.393 | ppl 1.31 | wps 27705.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22627 | lr 0.000210226 | gnorm 0.458 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53437
2022-03-06 05:13:19 | INFO | fairseq.trainer | begin training epoch 466
2022-03-06 05:13:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:15:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:15:12 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.526 | nll_loss 12.806 | ppl 7158.97 | wps 46532.1 | wpb 510.9 | bsz 1 | num_updates 22676 | best_loss 9.173
2022-03-06 05:15:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22676 updates
2022-03-06 05:15:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:15:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 466 @ 22676 updates, score 13.526) (writing took 1.6849203361198306 seconds)
2022-03-06 05:15:14 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-06 05:15:14 | INFO | train | epoch 466 | loss 2.54 | nll_loss 0.391 | ppl 1.31 | wps 27672.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22676 | lr 0.000209999 | gnorm 0.452 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53552
2022-03-06 05:15:14 | INFO | fairseq.trainer | begin training epoch 467
2022-03-06 05:15:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:16:07 | INFO | train_inner | epoch 467:     24 / 49 loss=2.541, nll_loss=0.392, ppl=1.31, wps=27720, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.454, loss_scale=32, train_wall=198, gb_free=21.6, wall=53606
2022-03-06 05:16:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:17:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:17:07 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.456 | nll_loss 12.728 | ppl 6782.24 | wps 46494.9 | wpb 510.9 | bsz 1 | num_updates 22724 | best_loss 9.173
2022-03-06 05:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22724 updates
2022-03-06 05:17:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 467 @ 22724 updates, score 13.456) (writing took 1.6509915348142385 seconds)
2022-03-06 05:17:08 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-06 05:17:08 | INFO | train | epoch 467 | loss 2.541 | nll_loss 0.391 | ppl 1.31 | wps 27123.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22724 | lr 0.000209777 | gnorm 0.453 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53667
2022-03-06 05:17:08 | INFO | fairseq.trainer | begin training epoch 468
2022-03-06 05:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:18:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:19:01 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.482 | nll_loss 12.764 | ppl 6956.41 | wps 46442.6 | wpb 510.9 | bsz 1 | num_updates 22773 | best_loss 9.173
2022-03-06 05:19:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22773 updates
2022-03-06 05:19:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:19:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:19:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 468 @ 22773 updates, score 13.482) (writing took 1.680393080227077 seconds)
2022-03-06 05:19:03 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-06 05:19:03 | INFO | train | epoch 468 | loss 2.54 | nll_loss 0.391 | ppl 1.31 | wps 27744.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22773 | lr 0.000209551 | gnorm 0.445 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53782
2022-03-06 05:19:03 | INFO | fairseq.trainer | begin training epoch 469
2022-03-06 05:19:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:20:03 | INFO | train_inner | epoch 469:     27 / 49 loss=2.539, nll_loss=0.391, ppl=1.31, wps=27480.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.443, loss_scale=32, train_wall=200, gb_free=21.6, wall=53842
2022-03-06 05:20:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:20:56 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.486 | nll_loss 12.763 | ppl 6951.33 | wps 46753.3 | wpb 510.9 | bsz 1 | num_updates 22822 | best_loss 9.173
2022-03-06 05:20:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22822 updates
2022-03-06 05:20:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:20:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:20:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 469 @ 22822 updates, score 13.486) (writing took 1.6647660015150905 seconds)
2022-03-06 05:20:58 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-06 05:20:58 | INFO | train | epoch 469 | loss 2.538 | nll_loss 0.39 | ppl 1.31 | wps 27697 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22822 | lr 0.000209326 | gnorm 0.436 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53896
2022-03-06 05:20:58 | INFO | fairseq.trainer | begin training epoch 470
2022-03-06 05:20:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:21:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:22:51 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.484 | nll_loss 12.765 | ppl 6961.8 | wps 46505.8 | wpb 510.9 | bsz 1 | num_updates 22870 | best_loss 9.173
2022-03-06 05:22:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22870 updates
2022-03-06 05:22:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:22:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:22:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 470 @ 22870 updates, score 13.484) (writing took 1.679794754832983 seconds)
2022-03-06 05:22:52 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-06 05:22:52 | INFO | train | epoch 470 | loss 2.539 | nll_loss 0.391 | ppl 1.31 | wps 27123.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22870 | lr 0.000209106 | gnorm 0.443 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54011
2022-03-06 05:22:52 | INFO | fairseq.trainer | begin training epoch 471
2022-03-06 05:22:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:23:59 | INFO | train_inner | epoch 471:     30 / 49 loss=2.539, nll_loss=0.39, ppl=1.31, wps=27478.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.443, loss_scale=32, train_wall=200, gb_free=21.6, wall=54078
2022-03-06 05:24:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:24:45 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.512 | nll_loss 12.794 | ppl 7104.22 | wps 46668.2 | wpb 510.9 | bsz 1 | num_updates 22919 | best_loss 9.173
2022-03-06 05:24:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22919 updates
2022-03-06 05:24:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:24:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:24:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 471 @ 22919 updates, score 13.512) (writing took 1.6906787967309356 seconds)
2022-03-06 05:24:47 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-06 05:24:47 | INFO | train | epoch 471 | loss 2.538 | nll_loss 0.39 | ppl 1.31 | wps 27699 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22919 | lr 0.000208883 | gnorm 0.444 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54126
2022-03-06 05:24:47 | INFO | fairseq.trainer | begin training epoch 472
2022-03-06 05:24:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:26:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:26:40 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.517 | nll_loss 12.796 | ppl 7111.97 | wps 46669.2 | wpb 510.9 | bsz 1 | num_updates 22968 | best_loss 9.173
2022-03-06 05:26:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22968 updates
2022-03-06 05:26:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:26:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:26:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 472 @ 22968 updates, score 13.517) (writing took 1.6828974904492497 seconds)
2022-03-06 05:26:42 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-06 05:26:42 | INFO | train | epoch 472 | loss 2.539 | nll_loss 0.39 | ppl 1.31 | wps 27708.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22968 | lr 0.00020866 | gnorm 0.448 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 54240
2022-03-06 05:26:42 | INFO | fairseq.trainer | begin training epoch 473
2022-03-06 05:26:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:26:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:27:55 | INFO | train_inner | epoch 473:     33 / 49 loss=2.538, nll_loss=0.39, ppl=1.31, wps=27472.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.447, loss_scale=32, train_wall=200, gb_free=21.6, wall=54314
2022-03-06 05:28:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:28:35 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.481 | nll_loss 12.76 | ppl 6934.45 | wps 46507.2 | wpb 510.9 | bsz 1 | num_updates 23016 | best_loss 9.173
2022-03-06 05:28:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23016 updates
2022-03-06 05:28:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:28:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:28:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 473 @ 23016 updates, score 13.481) (writing took 1.6785056861117482 seconds)
2022-03-06 05:28:36 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-06 05:28:36 | INFO | train | epoch 473 | loss 2.538 | nll_loss 0.39 | ppl 1.31 | wps 27144.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23016 | lr 0.000208442 | gnorm 0.447 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54355
2022-03-06 05:28:36 | INFO | fairseq.trainer | begin training epoch 474
2022-03-06 05:28:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:30:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:30:29 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.595 | nll_loss 12.885 | ppl 7562.51 | wps 46509.5 | wpb 510.9 | bsz 1 | num_updates 23065 | best_loss 9.173
2022-03-06 05:30:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23065 updates
2022-03-06 05:30:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:30:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:30:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 474 @ 23065 updates, score 13.595) (writing took 1.6384551040828228 seconds)
2022-03-06 05:30:31 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-06 05:30:31 | INFO | train | epoch 474 | loss 2.537 | nll_loss 0.389 | ppl 1.31 | wps 27731.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23065 | lr 0.00020822 | gnorm 0.443 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54470
2022-03-06 05:30:31 | INFO | fairseq.trainer | begin training epoch 475
2022-03-06 05:30:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:31:49 | INFO | train_inner | epoch 475:     35 / 49 loss=2.538, nll_loss=0.389, ppl=1.31, wps=27770.4, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.446, loss_scale=64, train_wall=198, gb_free=21.6, wall=54548
2022-03-06 05:31:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:32:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:32:24 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.566 | nll_loss 12.854 | ppl 7405.45 | wps 46693.3 | wpb 510.9 | bsz 1 | num_updates 23113 | best_loss 9.173
2022-03-06 05:32:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23113 updates
2022-03-06 05:32:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:32:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:32:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 475 @ 23113 updates, score 13.566) (writing took 1.7129995096474886 seconds)
2022-03-06 05:32:26 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-06 05:32:26 | INFO | train | epoch 475 | loss 2.537 | nll_loss 0.389 | ppl 1.31 | wps 27169.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23113 | lr 0.000208004 | gnorm 0.446 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54584
2022-03-06 05:32:26 | INFO | fairseq.trainer | begin training epoch 476
2022-03-06 05:32:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:34:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:34:19 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.547 | nll_loss 12.834 | ppl 7299.97 | wps 46498.1 | wpb 510.9 | bsz 1 | num_updates 23162 | best_loss 9.173
2022-03-06 05:34:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23162 updates
2022-03-06 05:34:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:34:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:34:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 476 @ 23162 updates, score 13.547) (writing took 1.7084349067881703 seconds)
2022-03-06 05:34:20 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-06 05:34:20 | INFO | train | epoch 476 | loss 2.537 | nll_loss 0.388 | ppl 1.31 | wps 27708.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23162 | lr 0.000207784 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54699
2022-03-06 05:34:20 | INFO | fairseq.trainer | begin training epoch 477
2022-03-06 05:34:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:35:45 | INFO | train_inner | epoch 477:     38 / 49 loss=2.536, nll_loss=0.388, ppl=1.31, wps=27481, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.447, loss_scale=32, train_wall=200, gb_free=21.6, wall=54784
2022-03-06 05:36:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:36:13 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.561 | nll_loss 12.849 | ppl 7380.05 | wps 46769.2 | wpb 510.9 | bsz 1 | num_updates 23211 | best_loss 9.173
2022-03-06 05:36:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23211 updates
2022-03-06 05:36:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:36:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:36:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 477 @ 23211 updates, score 13.561) (writing took 1.6619065552949905 seconds)
2022-03-06 05:36:15 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-06 05:36:15 | INFO | train | epoch 477 | loss 2.536 | nll_loss 0.388 | ppl 1.31 | wps 27711.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23211 | lr 0.000207564 | gnorm 0.446 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54814
2022-03-06 05:36:15 | INFO | fairseq.trainer | begin training epoch 478
2022-03-06 05:36:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:37:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:38:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:38:08 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.558 | nll_loss 12.843 | ppl 7344.99 | wps 46636.9 | wpb 510.9 | bsz 1 | num_updates 23259 | best_loss 9.173
2022-03-06 05:38:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23259 updates
2022-03-06 05:38:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:38:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:38:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 478 @ 23259 updates, score 13.558) (writing took 1.7108138436451554 seconds)
2022-03-06 05:38:10 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-06 05:38:10 | INFO | train | epoch 478 | loss 2.536 | nll_loss 0.388 | ppl 1.31 | wps 27160.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23259 | lr 0.00020735 | gnorm 0.45 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54928
2022-03-06 05:38:10 | INFO | fairseq.trainer | begin training epoch 479
2022-03-06 05:38:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:39:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 05:39:43 | INFO | train_inner | epoch 479:     42 / 49 loss=2.536, nll_loss=0.388, ppl=1.31, wps=27231.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.448, loss_scale=16, train_wall=202, gb_free=21.6, wall=55022
2022-03-06 05:39:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:40:03 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.492 | nll_loss 12.774 | ppl 7002.07 | wps 46579.3 | wpb 510.9 | bsz 1 | num_updates 23307 | best_loss 9.173
2022-03-06 05:40:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23307 updates
2022-03-06 05:40:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:40:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:40:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 479 @ 23307 updates, score 13.492) (writing took 1.7114032851532102 seconds)
2022-03-06 05:40:04 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-06 05:40:04 | INFO | train | epoch 479 | loss 2.534 | nll_loss 0.387 | ppl 1.31 | wps 27132.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23307 | lr 0.000207137 | gnorm 0.449 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 55043
2022-03-06 05:40:04 | INFO | fairseq.trainer | begin training epoch 480
2022-03-06 05:40:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:41:57 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.581 | nll_loss 12.869 | ppl 7482.04 | wps 46717 | wpb 510.9 | bsz 1 | num_updates 23356 | best_loss 9.173
2022-03-06 05:41:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23356 updates
2022-03-06 05:41:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:41:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:41:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 480 @ 23356 updates, score 13.581) (writing took 1.6658533988520503 seconds)
2022-03-06 05:41:59 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-06 05:41:59 | INFO | train | epoch 480 | loss 2.535 | nll_loss 0.388 | ppl 1.31 | wps 27710.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23356 | lr 0.000206919 | gnorm 0.455 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 55158
2022-03-06 05:41:59 | INFO | fairseq.trainer | begin training epoch 481
2022-03-06 05:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:43:37 | INFO | train_inner | epoch 481:     44 / 49 loss=2.535, nll_loss=0.387, ppl=1.31, wps=27734.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.452, loss_scale=16, train_wall=198, gb_free=21.6, wall=55256
2022-03-06 05:43:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:43:52 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.474 | nll_loss 12.755 | ppl 6911.56 | wps 46657 | wpb 510.9 | bsz 1 | num_updates 23405 | best_loss 9.173
2022-03-06 05:43:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23405 updates
2022-03-06 05:43:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:43:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:43:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 481 @ 23405 updates, score 13.474) (writing took 1.6914066802710295 seconds)
2022-03-06 05:43:54 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-06 05:43:54 | INFO | train | epoch 481 | loss 2.535 | nll_loss 0.387 | ppl 1.31 | wps 27702.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23405 | lr 0.000206702 | gnorm 0.449 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 55272
2022-03-06 05:43:54 | INFO | fairseq.trainer | begin training epoch 482
2022-03-06 05:43:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:45:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:45:47 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 13.406 | nll_loss 12.677 | ppl 6548.86 | wps 46497.6 | wpb 510.9 | bsz 1 | num_updates 23454 | best_loss 9.173
2022-03-06 05:45:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23454 updates
2022-03-06 05:45:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:45:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:45:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 482 @ 23454 updates, score 13.406) (writing took 1.7322071995586157 seconds)
2022-03-06 05:45:49 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-06 05:45:49 | INFO | train | epoch 482 | loss 2.533 | nll_loss 0.386 | ppl 1.31 | wps 27682.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23454 | lr 0.000206486 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55387
2022-03-06 05:45:49 | INFO | fairseq.trainer | begin training epoch 483
2022-03-06 05:45:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:47:31 | INFO | train_inner | epoch 483:     46 / 49 loss=2.534, nll_loss=0.386, ppl=1.31, wps=27731.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.441, loss_scale=32, train_wall=198, gb_free=21.6, wall=55490
2022-03-06 05:47:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:47:42 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.576 | nll_loss 12.865 | ppl 7458.83 | wps 46610.1 | wpb 510.9 | bsz 1 | num_updates 23503 | best_loss 9.173
2022-03-06 05:47:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23503 updates
2022-03-06 05:47:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:47:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:47:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 483 @ 23503 updates, score 13.576) (writing took 1.6964560197666287 seconds)
2022-03-06 05:47:43 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-06 05:47:43 | INFO | train | epoch 483 | loss 2.533 | nll_loss 0.386 | ppl 1.31 | wps 27714.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23503 | lr 0.000206271 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55502
2022-03-06 05:47:43 | INFO | fairseq.trainer | begin training epoch 484
2022-03-06 05:47:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:49:36 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.504 | nll_loss 12.787 | ppl 7065.2 | wps 46600.6 | wpb 510.9 | bsz 1 | num_updates 23552 | best_loss 9.173
2022-03-06 05:49:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23552 updates
2022-03-06 05:49:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:49:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:49:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 484 @ 23552 updates, score 13.504) (writing took 1.693791026249528 seconds)
2022-03-06 05:49:38 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-06 05:49:38 | INFO | train | epoch 484 | loss 2.533 | nll_loss 0.386 | ppl 1.31 | wps 27716.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23552 | lr 0.000206056 | gnorm 0.446 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 55617
2022-03-06 05:49:38 | INFO | fairseq.trainer | begin training epoch 485
2022-03-06 05:49:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:49:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:51:26 | INFO | train_inner | epoch 485:     49 / 49 loss=2.533, nll_loss=0.386, ppl=1.31, wps=27460.9, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=23600, lr=0.000205847, gnorm=0.449, loss_scale=32, train_wall=199, gb_free=21.6, wall=55725
2022-03-06 05:51:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:51:31 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.513 | nll_loss 12.798 | ppl 7122.62 | wps 46782.4 | wpb 510.9 | bsz 1 | num_updates 23600 | best_loss 9.173
2022-03-06 05:51:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23600 updates
2022-03-06 05:51:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:51:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:51:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 485 @ 23600 updates, score 13.513) (writing took 1.6768297143280506 seconds)
2022-03-06 05:51:33 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-06 05:51:33 | INFO | train | epoch 485 | loss 2.533 | nll_loss 0.386 | ppl 1.31 | wps 27122.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23600 | lr 0.000205847 | gnorm 0.45 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55731
2022-03-06 05:51:33 | INFO | fairseq.trainer | begin training epoch 486
2022-03-06 05:51:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:53:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:53:26 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 13.494 | nll_loss 12.776 | ppl 7012.23 | wps 46445.3 | wpb 510.9 | bsz 1 | num_updates 23649 | best_loss 9.173
2022-03-06 05:53:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23649 updates
2022-03-06 05:53:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:53:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 486 @ 23649 updates, score 13.494) (writing took 1.6997481482103467 seconds)
2022-03-06 05:53:27 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-06 05:53:27 | INFO | train | epoch 486 | loss 2.532 | nll_loss 0.385 | ppl 1.31 | wps 27700 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23649 | lr 0.000205633 | gnorm 0.444 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55846
2022-03-06 05:53:27 | INFO | fairseq.trainer | begin training epoch 487
2022-03-06 05:53:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:54:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:55:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:55:20 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.47 | nll_loss 12.75 | ppl 6890.34 | wps 46656.8 | wpb 510.9 | bsz 1 | num_updates 23697 | best_loss 9.173
2022-03-06 05:55:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23697 updates
2022-03-06 05:55:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:55:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:55:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 487 @ 23697 updates, score 13.47) (writing took 1.6620492171496153 seconds)
2022-03-06 05:55:22 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-06 05:55:22 | INFO | train | epoch 487 | loss 2.531 | nll_loss 0.384 | ppl 1.3 | wps 27147.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23697 | lr 0.000205425 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55961
2022-03-06 05:55:22 | INFO | fairseq.trainer | begin training epoch 488
2022-03-06 05:55:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:55:29 | INFO | train_inner | epoch 488:      3 / 49 loss=2.531, nll_loss=0.384, ppl=1.31, wps=26744.3, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.44, loss_scale=32, train_wall=200, gb_free=21.6, wall=55967
2022-03-06 05:57:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:57:15 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.504 | nll_loss 12.788 | ppl 7073.65 | wps 46510.8 | wpb 510.9 | bsz 1 | num_updates 23746 | best_loss 9.173
2022-03-06 05:57:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23746 updates
2022-03-06 05:57:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:57:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:57:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 488 @ 23746 updates, score 13.504) (writing took 1.6975237084552646 seconds)
2022-03-06 05:57:17 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-06 05:57:17 | INFO | train | epoch 488 | loss 2.531 | nll_loss 0.385 | ppl 1.31 | wps 27707.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23746 | lr 0.000205213 | gnorm 0.444 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56075
2022-03-06 05:57:17 | INFO | fairseq.trainer | begin training epoch 489
2022-03-06 05:57:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:59:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:59:10 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.495 | nll_loss 12.77 | ppl 6984.45 | wps 46660.7 | wpb 510.9 | bsz 1 | num_updates 23795 | best_loss 9.173
2022-03-06 05:59:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23795 updates
2022-03-06 05:59:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:59:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 05:59:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 489 @ 23795 updates, score 13.495) (writing took 1.7039977926760912 seconds)
2022-03-06 05:59:11 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-06 05:59:11 | INFO | train | epoch 489 | loss 2.531 | nll_loss 0.385 | ppl 1.31 | wps 27701 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23795 | lr 0.000205002 | gnorm 0.445 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56190
2022-03-06 05:59:11 | INFO | fairseq.trainer | begin training epoch 490
2022-03-06 05:59:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:59:23 | INFO | train_inner | epoch 490:      5 / 49 loss=2.531, nll_loss=0.384, ppl=1.31, wps=27737.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.445, loss_scale=32, train_wall=198, gb_free=21.6, wall=56201
2022-03-06 05:59:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:01:04 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.522 | nll_loss 12.809 | ppl 7174.28 | wps 46413.6 | wpb 510.9 | bsz 1 | num_updates 23843 | best_loss 9.173
2022-03-06 06:01:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23843 updates
2022-03-06 06:01:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:01:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:01:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 490 @ 23843 updates, score 13.522) (writing took 1.6413865918293595 seconds)
2022-03-06 06:01:06 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-06 06:01:06 | INFO | train | epoch 490 | loss 2.531 | nll_loss 0.384 | ppl 1.31 | wps 27153.9 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 23843 | lr 0.000204795 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56305
2022-03-06 06:01:06 | INFO | fairseq.trainer | begin training epoch 491
2022-03-06 06:01:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:02:59 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.701 | nll_loss 13.004 | ppl 8215.55 | wps 46639.4 | wpb 510.9 | bsz 1 | num_updates 23892 | best_loss 9.173
2022-03-06 06:02:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23892 updates
2022-03-06 06:02:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:03:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:03:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 491 @ 23892 updates, score 13.701) (writing took 1.6777657801285386 seconds)
2022-03-06 06:03:01 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-06 06:03:01 | INFO | train | epoch 491 | loss 2.53 | nll_loss 0.383 | ppl 1.3 | wps 27712 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23892 | lr 0.000204585 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56419
2022-03-06 06:03:01 | INFO | fairseq.trainer | begin training epoch 492
2022-03-06 06:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:03:19 | INFO | train_inner | epoch 492:      8 / 49 loss=2.53, nll_loss=0.384, ppl=1.3, wps=27488.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.446, loss_scale=32, train_wall=200, gb_free=21.6, wall=56437
2022-03-06 06:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:04:54 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.623 | nll_loss 12.919 | ppl 7747.06 | wps 46608.3 | wpb 510.9 | bsz 1 | num_updates 23941 | best_loss 9.173
2022-03-06 06:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23941 updates
2022-03-06 06:04:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:04:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:04:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 492 @ 23941 updates, score 13.623) (writing took 1.681968574412167 seconds)
2022-03-06 06:04:55 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-06 06:04:55 | INFO | train | epoch 492 | loss 2.53 | nll_loss 0.384 | ppl 1.3 | wps 27713.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23941 | lr 0.000204376 | gnorm 0.451 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 56534
2022-03-06 06:04:55 | INFO | fairseq.trainer | begin training epoch 493
2022-03-06 06:04:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:05:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:06:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:06:48 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.562 | nll_loss 12.849 | ppl 7375.92 | wps 46695 | wpb 510.9 | bsz 1 | num_updates 23989 | best_loss 9.173
2022-03-06 06:06:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23989 updates
2022-03-06 06:06:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:06:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:06:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 493 @ 23989 updates, score 13.562) (writing took 1.7232000110670924 seconds)
2022-03-06 06:06:50 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-06 06:06:50 | INFO | train | epoch 493 | loss 2.529 | nll_loss 0.383 | ppl 1.3 | wps 27119.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23989 | lr 0.000204171 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56649
2022-03-06 06:06:50 | INFO | fairseq.trainer | begin training epoch 494
2022-03-06 06:06:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:07:15 | INFO | train_inner | epoch 494:     11 / 49 loss=2.529, nll_loss=0.383, ppl=1.3, wps=27464.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.444, loss_scale=32, train_wall=200, gb_free=21.6, wall=56674
2022-03-06 06:08:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:08:43 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.561 | nll_loss 12.848 | ppl 7371.32 | wps 46642.4 | wpb 510.9 | bsz 1 | num_updates 24038 | best_loss 9.173
2022-03-06 06:08:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24038 updates
2022-03-06 06:08:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:08:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:08:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 494 @ 24038 updates, score 13.561) (writing took 1.635057303123176 seconds)
2022-03-06 06:08:45 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-06 06:08:45 | INFO | train | epoch 494 | loss 2.528 | nll_loss 0.382 | ppl 1.3 | wps 27709.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24038 | lr 0.000203963 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56764
2022-03-06 06:08:45 | INFO | fairseq.trainer | begin training epoch 495
2022-03-06 06:08:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:10:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:10:38 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 13.52 | nll_loss 12.801 | ppl 7135.33 | wps 46745.2 | wpb 510.9 | bsz 1 | num_updates 24086 | best_loss 9.173
2022-03-06 06:10:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24086 updates
2022-03-06 06:10:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:10:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:10:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 495 @ 24086 updates, score 13.52) (writing took 1.6804721467196941 seconds)
2022-03-06 06:10:40 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-06 06:10:40 | INFO | train | epoch 495 | loss 2.528 | nll_loss 0.382 | ppl 1.3 | wps 27146.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24086 | lr 0.000203759 | gnorm 0.436 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56878
2022-03-06 06:10:40 | INFO | fairseq.trainer | begin training epoch 496
2022-03-06 06:10:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:11:11 | INFO | train_inner | epoch 496:     14 / 49 loss=2.528, nll_loss=0.382, ppl=1.3, wps=27494.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.438, loss_scale=32, train_wall=200, gb_free=21.6, wall=56910
2022-03-06 06:12:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:12:33 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.557 | nll_loss 12.841 | ppl 7337.4 | wps 46556.8 | wpb 510.9 | bsz 1 | num_updates 24135 | best_loss 9.173
2022-03-06 06:12:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24135 updates
2022-03-06 06:12:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:12:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:12:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 496 @ 24135 updates, score 13.557) (writing took 1.6938252756372094 seconds)
2022-03-06 06:12:34 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-06 06:12:34 | INFO | train | epoch 496 | loss 2.527 | nll_loss 0.381 | ppl 1.3 | wps 27712.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24135 | lr 0.000203552 | gnorm 0.436 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56993
2022-03-06 06:12:34 | INFO | fairseq.trainer | begin training epoch 497
2022-03-06 06:12:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:14:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:14:27 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.572 | nll_loss 12.857 | ppl 7420.6 | wps 46629.3 | wpb 510.9 | bsz 1 | num_updates 24184 | best_loss 9.173
2022-03-06 06:14:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24184 updates
2022-03-06 06:14:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:14:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:14:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 497 @ 24184 updates, score 13.572) (writing took 1.670028724707663 seconds)
2022-03-06 06:14:29 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-06 06:14:29 | INFO | train | epoch 497 | loss 2.528 | nll_loss 0.382 | ppl 1.3 | wps 27686.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24184 | lr 0.000203346 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57108
2022-03-06 06:14:29 | INFO | fairseq.trainer | begin training epoch 498
2022-03-06 06:14:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:15:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 06:15:07 | INFO | train_inner | epoch 498:     17 / 49 loss=2.528, nll_loss=0.382, ppl=1.3, wps=27462.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.435, loss_scale=16, train_wall=200, gb_free=21.6, wall=57146
2022-03-06 06:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:16:22 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.471 | nll_loss 12.749 | ppl 6882.36 | wps 46500.1 | wpb 510.9 | bsz 1 | num_updates 24232 | best_loss 9.173
2022-03-06 06:16:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24232 updates
2022-03-06 06:16:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:16:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:16:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 498 @ 24232 updates, score 13.471) (writing took 1.6682809041813016 seconds)
2022-03-06 06:16:24 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-06 06:16:24 | INFO | train | epoch 498 | loss 2.527 | nll_loss 0.382 | ppl 1.3 | wps 27147.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24232 | lr 0.000203145 | gnorm 0.439 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 57222
2022-03-06 06:16:24 | INFO | fairseq.trainer | begin training epoch 499
2022-03-06 06:16:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:18:17 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.533 | nll_loss 12.819 | ppl 7227.8 | wps 46556.1 | wpb 510.9 | bsz 1 | num_updates 24281 | best_loss 9.173
2022-03-06 06:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24281 updates
2022-03-06 06:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:18:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 499 @ 24281 updates, score 13.533) (writing took 1.671896249987185 seconds)
2022-03-06 06:18:18 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-06 06:18:18 | INFO | train | epoch 499 | loss 2.527 | nll_loss 0.382 | ppl 1.3 | wps 27731.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24281 | lr 0.00020294 | gnorm 0.445 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 57337
2022-03-06 06:18:18 | INFO | fairseq.trainer | begin training epoch 500
2022-03-06 06:18:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:19:01 | INFO | train_inner | epoch 500:     19 / 49 loss=2.527, nll_loss=0.382, ppl=1.3, wps=27760.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.443, loss_scale=16, train_wall=198, gb_free=21.6, wall=57379
2022-03-06 06:20:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:20:11 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.558 | nll_loss 12.842 | ppl 7340.57 | wps 46528.5 | wpb 510.9 | bsz 1 | num_updates 24330 | best_loss 9.173
2022-03-06 06:20:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24330 updates
2022-03-06 06:20:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:20:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:20:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 500 @ 24330 updates, score 13.558) (writing took 1.6515059722587466 seconds)
2022-03-06 06:20:13 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-06 06:20:13 | INFO | train | epoch 500 | loss 2.526 | nll_loss 0.381 | ppl 1.3 | wps 27728.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24330 | lr 0.000202735 | gnorm 0.441 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57452
2022-03-06 06:20:13 | INFO | fairseq.trainer | begin training epoch 501
2022-03-06 06:20:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:22:06 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.562 | nll_loss 12.851 | ppl 7388.99 | wps 46525 | wpb 510.9 | bsz 1 | num_updates 24379 | best_loss 9.173
2022-03-06 06:22:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24379 updates
2022-03-06 06:22:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:22:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:22:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 501 @ 24379 updates, score 13.562) (writing took 1.6938743190839887 seconds)
2022-03-06 06:22:08 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-06 06:22:08 | INFO | train | epoch 501 | loss 2.525 | nll_loss 0.38 | ppl 1.3 | wps 27705.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24379 | lr 0.000202531 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57566
2022-03-06 06:22:08 | INFO | fairseq.trainer | begin training epoch 502
2022-03-06 06:22:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:22:55 | INFO | train_inner | epoch 502:     21 / 49 loss=2.526, nll_loss=0.38, ppl=1.3, wps=27752.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.44, loss_scale=32, train_wall=198, gb_free=21.6, wall=57613
2022-03-06 06:23:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:24:01 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.605 | nll_loss 12.902 | ppl 7652.3 | wps 46417.7 | wpb 510.9 | bsz 1 | num_updates 24428 | best_loss 9.173
2022-03-06 06:24:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24428 updates
2022-03-06 06:24:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:24:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:24:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 502 @ 24428 updates, score 13.605) (writing took 1.64753014780581 seconds)
2022-03-06 06:24:02 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-06 06:24:02 | INFO | train | epoch 502 | loss 2.526 | nll_loss 0.381 | ppl 1.3 | wps 27714 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24428 | lr 0.000202328 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57681
2022-03-06 06:24:02 | INFO | fairseq.trainer | begin training epoch 503
2022-03-06 06:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:25:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:25:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:25:55 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.492 | nll_loss 12.774 | ppl 7001.79 | wps 46431.8 | wpb 510.9 | bsz 1 | num_updates 24476 | best_loss 9.173
2022-03-06 06:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24476 updates
2022-03-06 06:25:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:25:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:25:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 503 @ 24476 updates, score 13.492) (writing took 1.632022243924439 seconds)
2022-03-06 06:25:57 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-06 06:25:57 | INFO | train | epoch 503 | loss 2.525 | nll_loss 0.38 | ppl 1.3 | wps 27153.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24476 | lr 0.00020213 | gnorm 0.446 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57796
2022-03-06 06:25:57 | INFO | fairseq.trainer | begin training epoch 504
2022-03-06 06:25:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:26:51 | INFO | train_inner | epoch 504:     24 / 49 loss=2.526, nll_loss=0.38, ppl=1.3, wps=27484.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.446, loss_scale=32, train_wall=200, gb_free=21.6, wall=57849
2022-03-06 06:27:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:27:50 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.639 | nll_loss 12.937 | ppl 7841.97 | wps 46486.9 | wpb 510.9 | bsz 1 | num_updates 24525 | best_loss 9.173
2022-03-06 06:27:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24525 updates
2022-03-06 06:27:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:27:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:27:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 504 @ 24525 updates, score 13.639) (writing took 1.7188504580408335 seconds)
2022-03-06 06:27:52 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-06 06:27:52 | INFO | train | epoch 504 | loss 2.525 | nll_loss 0.38 | ppl 1.3 | wps 27683.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24525 | lr 0.000201928 | gnorm 0.445 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57910
2022-03-06 06:27:52 | INFO | fairseq.trainer | begin training epoch 505
2022-03-06 06:27:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:29:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:29:45 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.549 | nll_loss 12.838 | ppl 7321.36 | wps 46783.3 | wpb 510.9 | bsz 1 | num_updates 24574 | best_loss 9.173
2022-03-06 06:29:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24574 updates
2022-03-06 06:29:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:29:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:29:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 505 @ 24574 updates, score 13.549) (writing took 1.6439132923260331 seconds)
2022-03-06 06:29:46 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-06 06:29:46 | INFO | train | epoch 505 | loss 2.524 | nll_loss 0.38 | ppl 1.3 | wps 27738.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24574 | lr 0.000201726 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58025
2022-03-06 06:29:46 | INFO | fairseq.trainer | begin training epoch 506
2022-03-06 06:29:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:30:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:30:47 | INFO | train_inner | epoch 506:     27 / 49 loss=2.524, nll_loss=0.379, ppl=1.3, wps=27485.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.436, loss_scale=32, train_wall=200, gb_free=21.6, wall=58085
2022-03-06 06:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:31:39 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.6 | nll_loss 12.891 | ppl 7596.45 | wps 46555 | wpb 510.9 | bsz 1 | num_updates 24622 | best_loss 9.173
2022-03-06 06:31:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24622 updates
2022-03-06 06:31:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:31:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:31:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 506 @ 24622 updates, score 13.6) (writing took 1.7027004715055227 seconds)
2022-03-06 06:31:41 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-06 06:31:41 | INFO | train | epoch 506 | loss 2.524 | nll_loss 0.379 | ppl 1.3 | wps 27129.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24622 | lr 0.000201529 | gnorm 0.441 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58140
2022-03-06 06:31:41 | INFO | fairseq.trainer | begin training epoch 507
2022-03-06 06:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:33:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:33:34 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.58 | nll_loss 12.874 | ppl 7507.86 | wps 46655.4 | wpb 510.9 | bsz 1 | num_updates 24671 | best_loss 9.173
2022-03-06 06:33:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24671 updates
2022-03-06 06:33:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:33:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 507 @ 24671 updates, score 13.58) (writing took 1.6600753590464592 seconds)
2022-03-06 06:33:36 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-06 06:33:36 | INFO | train | epoch 507 | loss 2.524 | nll_loss 0.379 | ppl 1.3 | wps 27717.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24671 | lr 0.000201329 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58254
2022-03-06 06:33:36 | INFO | fairseq.trainer | begin training epoch 508
2022-03-06 06:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:34:40 | INFO | train_inner | epoch 508:     29 / 49 loss=2.523, nll_loss=0.379, ppl=1.3, wps=27732.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.44, loss_scale=32, train_wall=198, gb_free=21.6, wall=58319
2022-03-06 06:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:35:29 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.618 | nll_loss 12.914 | ppl 7718.35 | wps 46650.6 | wpb 510.9 | bsz 1 | num_updates 24720 | best_loss 9.173
2022-03-06 06:35:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24720 updates
2022-03-06 06:35:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:35:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:35:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 508 @ 24720 updates, score 13.618) (writing took 1.6855627791956067 seconds)
2022-03-06 06:35:30 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-06 06:35:30 | INFO | train | epoch 508 | loss 2.523 | nll_loss 0.378 | ppl 1.3 | wps 27697.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24720 | lr 0.000201129 | gnorm 0.438 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58369
2022-03-06 06:35:30 | INFO | fairseq.trainer | begin training epoch 509
2022-03-06 06:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:36:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:37:24 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.434 | nll_loss 12.71 | ppl 6702.24 | wps 46602.8 | wpb 510.9 | bsz 1 | num_updates 24768 | best_loss 9.173
2022-03-06 06:37:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24768 updates
2022-03-06 06:37:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:37:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:37:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 509 @ 24768 updates, score 13.434) (writing took 1.6913400925695896 seconds)
2022-03-06 06:37:25 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-06 06:37:25 | INFO | train | epoch 509 | loss 2.522 | nll_loss 0.378 | ppl 1.3 | wps 27106.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24768 | lr 0.000200935 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58484
2022-03-06 06:37:25 | INFO | fairseq.trainer | begin training epoch 510
2022-03-06 06:37:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:38:37 | INFO | train_inner | epoch 510:     32 / 49 loss=2.523, nll_loss=0.378, ppl=1.3, wps=27470.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.438, loss_scale=32, train_wall=200, gb_free=21.6, wall=58555
2022-03-06 06:39:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:39:18 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.489 | nll_loss 12.773 | ppl 6999.85 | wps 46739.8 | wpb 510.9 | bsz 1 | num_updates 24817 | best_loss 9.173
2022-03-06 06:39:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24817 updates
2022-03-06 06:39:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 510 @ 24817 updates, score 13.489) (writing took 1.673444981686771 seconds)
2022-03-06 06:39:20 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-06 06:39:20 | INFO | train | epoch 510 | loss 2.522 | nll_loss 0.378 | ppl 1.3 | wps 27738.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24817 | lr 0.000200736 | gnorm 0.443 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58598
2022-03-06 06:39:20 | INFO | fairseq.trainer | begin training epoch 511
2022-03-06 06:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:41:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:41:13 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.602 | nll_loss 12.896 | ppl 7622.67 | wps 46442.5 | wpb 510.9 | bsz 1 | num_updates 24865 | best_loss 9.173
2022-03-06 06:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24865 updates
2022-03-06 06:41:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:41:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 511 @ 24865 updates, score 13.602) (writing took 1.6791975256055593 seconds)
2022-03-06 06:41:15 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-06 06:41:15 | INFO | train | epoch 511 | loss 2.522 | nll_loss 0.378 | ppl 1.3 | wps 27126.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24865 | lr 0.000200542 | gnorm 0.437 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58713
2022-03-06 06:41:15 | INFO | fairseq.trainer | begin training epoch 512
2022-03-06 06:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:42:33 | INFO | train_inner | epoch 512:     35 / 49 loss=2.522, nll_loss=0.378, ppl=1.3, wps=27485.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.437, loss_scale=32, train_wall=200, gb_free=21.6, wall=58791
2022-03-06 06:43:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:43:08 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.597 | nll_loss 12.887 | ppl 7577.2 | wps 46140.6 | wpb 510.9 | bsz 1 | num_updates 24914 | best_loss 9.173
2022-03-06 06:43:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24914 updates
2022-03-06 06:43:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:43:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:43:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 512 @ 24914 updates, score 13.597) (writing took 1.6815887475386262 seconds)
2022-03-06 06:43:09 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-06 06:43:09 | INFO | train | epoch 512 | loss 2.521 | nll_loss 0.377 | ppl 1.3 | wps 27709.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24914 | lr 0.000200345 | gnorm 0.441 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58828
2022-03-06 06:43:09 | INFO | fairseq.trainer | begin training epoch 513
2022-03-06 06:43:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:44:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:45:02 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.536 | nll_loss 12.824 | ppl 7248.74 | wps 46550.4 | wpb 510.9 | bsz 1 | num_updates 24963 | best_loss 9.173
2022-03-06 06:45:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24963 updates
2022-03-06 06:45:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:45:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:45:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 513 @ 24963 updates, score 13.536) (writing took 1.7237209361046553 seconds)
2022-03-06 06:45:04 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-06 06:45:04 | INFO | train | epoch 513 | loss 2.521 | nll_loss 0.377 | ppl 1.3 | wps 27719.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24963 | lr 0.000200148 | gnorm 0.438 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58943
2022-03-06 06:45:04 | INFO | fairseq.trainer | begin training epoch 514
2022-03-06 06:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:46:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:46:29 | INFO | train_inner | epoch 514:     38 / 49 loss=2.521, nll_loss=0.377, ppl=1.3, wps=27491.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.438, loss_scale=32, train_wall=200, gb_free=21.6, wall=59027
2022-03-06 06:46:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:46:57 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.605 | nll_loss 12.902 | ppl 7652.06 | wps 46532.2 | wpb 510.9 | bsz 1 | num_updates 25011 | best_loss 9.173
2022-03-06 06:46:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25011 updates
2022-03-06 06:46:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:46:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:46:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 514 @ 25011 updates, score 13.605) (writing took 1.6623832359910011 seconds)
2022-03-06 06:46:58 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-06 06:46:58 | INFO | train | epoch 514 | loss 2.521 | nll_loss 0.377 | ppl 1.3 | wps 27173.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25011 | lr 0.000199956 | gnorm 0.436 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59057
2022-03-06 06:46:58 | INFO | fairseq.trainer | begin training epoch 515
2022-03-06 06:46:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:48:51 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.729 | nll_loss 13.037 | ppl 8403.82 | wps 46588.9 | wpb 510.9 | bsz 1 | num_updates 25060 | best_loss 9.173
2022-03-06 06:48:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25060 updates
2022-03-06 06:48:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:48:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:48:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 515 @ 25060 updates, score 13.729) (writing took 1.6738633522763848 seconds)
2022-03-06 06:48:53 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-06 06:48:53 | INFO | train | epoch 515 | loss 2.521 | nll_loss 0.377 | ppl 1.3 | wps 27730.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25060 | lr 0.00019976 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59172
2022-03-06 06:48:53 | INFO | fairseq.trainer | begin training epoch 516
2022-03-06 06:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:50:22 | INFO | train_inner | epoch 516:     40 / 49 loss=2.521, nll_loss=0.377, ppl=1.3, wps=27753.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.437, loss_scale=32, train_wall=198, gb_free=21.6, wall=59261
2022-03-06 06:50:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:50:46 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.52 | nll_loss 12.81 | ppl 7179.07 | wps 46535.5 | wpb 510.9 | bsz 1 | num_updates 25109 | best_loss 9.173
2022-03-06 06:50:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25109 updates
2022-03-06 06:50:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:50:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:50:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 516 @ 25109 updates, score 13.52) (writing took 1.6679404824972153 seconds)
2022-03-06 06:50:48 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-06 06:50:48 | INFO | train | epoch 516 | loss 2.52 | nll_loss 0.376 | ppl 1.3 | wps 27707.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25109 | lr 0.000199565 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59286
2022-03-06 06:50:48 | INFO | fairseq.trainer | begin training epoch 517
2022-03-06 06:50:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:51:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:52:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:52:41 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.554 | nll_loss 12.842 | ppl 7341.19 | wps 46584.2 | wpb 510.9 | bsz 1 | num_updates 25157 | best_loss 9.173
2022-03-06 06:52:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25157 updates
2022-03-06 06:52:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:52:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:52:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 517 @ 25157 updates, score 13.554) (writing took 1.6800805758684874 seconds)
2022-03-06 06:52:42 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-06 06:52:42 | INFO | train | epoch 517 | loss 2.519 | nll_loss 0.376 | ppl 1.3 | wps 27146.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25157 | lr 0.000199375 | gnorm 0.437 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59401
2022-03-06 06:52:42 | INFO | fairseq.trainer | begin training epoch 518
2022-03-06 06:52:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:54:18 | INFO | train_inner | epoch 518:     43 / 49 loss=2.52, nll_loss=0.376, ppl=1.3, wps=27480.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.438, loss_scale=32, train_wall=200, gb_free=21.6, wall=59497
2022-03-06 06:54:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:54:36 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.656 | nll_loss 12.957 | ppl 7952.59 | wps 46416.1 | wpb 510.9 | bsz 1 | num_updates 25206 | best_loss 9.173
2022-03-06 06:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25206 updates
2022-03-06 06:54:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:54:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:54:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 518 @ 25206 updates, score 13.656) (writing took 1.6878713807091117 seconds)
2022-03-06 06:54:37 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-06 06:54:37 | INFO | train | epoch 518 | loss 2.52 | nll_loss 0.376 | ppl 1.3 | wps 27677.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25206 | lr 0.000199181 | gnorm 0.439 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59516
2022-03-06 06:54:37 | INFO | fairseq.trainer | begin training epoch 519
2022-03-06 06:54:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:56:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:56:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:56:30 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.6 | nll_loss 12.89 | ppl 7588.31 | wps 46633.9 | wpb 510.9 | bsz 1 | num_updates 25254 | best_loss 9.173
2022-03-06 06:56:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25254 updates
2022-03-06 06:56:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:56:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:56:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 519 @ 25254 updates, score 13.6) (writing took 1.6911187963560224 seconds)
2022-03-06 06:56:32 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-06 06:56:32 | INFO | train | epoch 519 | loss 2.518 | nll_loss 0.375 | ppl 1.3 | wps 27135.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25254 | lr 0.000198992 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59631
2022-03-06 06:56:32 | INFO | fairseq.trainer | begin training epoch 520
2022-03-06 06:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:58:15 | INFO | train_inner | epoch 520:     46 / 49 loss=2.519, nll_loss=0.375, ppl=1.3, wps=27459.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.43, loss_scale=32, train_wall=200, gb_free=21.6, wall=59733
2022-03-06 06:58:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:58:25 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 13.646 | nll_loss 12.95 | ppl 7910.27 | wps 46539.9 | wpb 510.9 | bsz 1 | num_updates 25303 | best_loss 9.173
2022-03-06 06:58:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25303 updates
2022-03-06 06:58:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 06:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 520 @ 25303 updates, score 13.646) (writing took 1.7422096692025661 seconds)
2022-03-06 06:58:27 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-06 06:58:27 | INFO | train | epoch 520 | loss 2.518 | nll_loss 0.375 | ppl 1.3 | wps 27682.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25303 | lr 0.000198799 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59745
2022-03-06 06:58:27 | INFO | fairseq.trainer | begin training epoch 521
2022-03-06 06:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:00:20 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 13.532 | nll_loss 12.818 | ppl 7223.07 | wps 46589.4 | wpb 510.9 | bsz 1 | num_updates 25352 | best_loss 9.173
2022-03-06 07:00:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25352 updates
2022-03-06 07:00:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:00:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:00:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 521 @ 25352 updates, score 13.532) (writing took 1.6840365724638104 seconds)
2022-03-06 07:00:22 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-06 07:00:22 | INFO | train | epoch 521 | loss 2.519 | nll_loss 0.375 | ppl 1.3 | wps 27666.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25352 | lr 0.000198607 | gnorm 0.432 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59860
2022-03-06 07:00:22 | INFO | fairseq.trainer | begin training epoch 522
2022-03-06 07:00:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:01:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:02:10 | INFO | train_inner | epoch 522:     49 / 49 loss=2.519, nll_loss=0.375, ppl=1.3, wps=27438.7, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=25400, lr=0.000198419, gnorm=0.437, loss_scale=32, train_wall=199, gb_free=21.6, wall=59969
2022-03-06 07:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:02:15 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 13.42 | nll_loss 12.695 | ppl 6629.97 | wps 46427.5 | wpb 510.9 | bsz 1 | num_updates 25400 | best_loss 9.173
2022-03-06 07:02:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25400 updates
2022-03-06 07:02:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:02:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:02:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 522 @ 25400 updates, score 13.42) (writing took 1.6390677224844694 seconds)
2022-03-06 07:02:16 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-06 07:02:16 | INFO | train | epoch 522 | loss 2.519 | nll_loss 0.375 | ppl 1.3 | wps 27143.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25400 | lr 0.000198419 | gnorm 0.439 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59975
2022-03-06 07:02:16 | INFO | fairseq.trainer | begin training epoch 523
2022-03-06 07:02:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:04:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:04:09 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 13.546 | nll_loss 12.838 | ppl 7319.54 | wps 46675.9 | wpb 510.9 | bsz 1 | num_updates 25449 | best_loss 9.173
2022-03-06 07:04:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25449 updates
2022-03-06 07:04:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:04:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 523 @ 25449 updates, score 13.546) (writing took 1.7030882155522704 seconds)
2022-03-06 07:04:11 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-06 07:04:11 | INFO | train | epoch 523 | loss 2.518 | nll_loss 0.374 | ppl 1.3 | wps 27707 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25449 | lr 0.000198228 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60090
2022-03-06 07:04:11 | INFO | fairseq.trainer | begin training epoch 524
2022-03-06 07:04:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:05:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:06:04 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 13.567 | nll_loss 12.857 | ppl 7417.18 | wps 46376.9 | wpb 510.9 | bsz 1 | num_updates 25498 | best_loss 9.173
2022-03-06 07:06:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25498 updates
2022-03-06 07:06:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:06:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:06:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 524 @ 25498 updates, score 13.567) (writing took 1.6767874229699373 seconds)
2022-03-06 07:06:06 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-06 07:06:06 | INFO | train | epoch 524 | loss 2.517 | nll_loss 0.374 | ppl 1.3 | wps 27672.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25498 | lr 0.000198037 | gnorm 0.432 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60204
2022-03-06 07:06:06 | INFO | fairseq.trainer | begin training epoch 525
2022-03-06 07:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:06:10 | INFO | train_inner | epoch 525:      2 / 49 loss=2.517, nll_loss=0.374, ppl=1.3, wps=26972.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.432, loss_scale=32, train_wall=198, gb_free=21.6, wall=60209
2022-03-06 07:06:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:06:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 07:07:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:07:59 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 13.526 | nll_loss 12.811 | ppl 7186.44 | wps 46449.9 | wpb 510.9 | bsz 1 | num_updates 25545 | best_loss 9.173
2022-03-06 07:07:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25545 updates
2022-03-06 07:07:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:08:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:08:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 525 @ 25545 updates, score 13.526) (writing took 1.6913246754556894 seconds)
2022-03-06 07:08:01 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-06 07:08:01 | INFO | train | epoch 525 | loss 2.517 | nll_loss 0.374 | ppl 1.3 | wps 26556.5 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 25545 | lr 0.000197855 | gnorm 0.443 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 60319
2022-03-06 07:08:01 | INFO | fairseq.trainer | begin training epoch 526
2022-03-06 07:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:09:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:09:54 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 13.626 | nll_loss 12.926 | ppl 7781.31 | wps 46486.3 | wpb 510.9 | bsz 1 | num_updates 25594 | best_loss 9.173
2022-03-06 07:09:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25594 updates
2022-03-06 07:09:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 526 @ 25594 updates, score 13.626) (writing took 1.6705890158191323 seconds)
2022-03-06 07:09:55 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-06 07:09:55 | INFO | train | epoch 526 | loss 2.516 | nll_loss 0.373 | ppl 1.29 | wps 27722.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25594 | lr 0.000197666 | gnorm 0.426 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 60434
2022-03-06 07:09:55 | INFO | fairseq.trainer | begin training epoch 527
2022-03-06 07:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:10:09 | INFO | train_inner | epoch 527:      6 / 49 loss=2.516, nll_loss=0.374, ppl=1.3, wps=27225.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.433, loss_scale=16, train_wall=202, gb_free=21.6, wall=60447
2022-03-06 07:11:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:11:48 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 13.544 | nll_loss 12.839 | ppl 7328.94 | wps 46385.2 | wpb 510.9 | bsz 1 | num_updates 25643 | best_loss 9.173
2022-03-06 07:11:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25643 updates
2022-03-06 07:11:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:11:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:11:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 527 @ 25643 updates, score 13.544) (writing took 1.6839497229084373 seconds)
2022-03-06 07:11:50 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-06 07:11:50 | INFO | train | epoch 527 | loss 2.516 | nll_loss 0.373 | ppl 1.3 | wps 27703.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25643 | lr 0.000197477 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60549
2022-03-06 07:11:50 | INFO | fairseq.trainer | begin training epoch 528
2022-03-06 07:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:13:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:13:43 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 13.639 | nll_loss 12.938 | ppl 7847.11 | wps 46527.4 | wpb 510.9 | bsz 1 | num_updates 25692 | best_loss 9.173
2022-03-06 07:13:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25692 updates
2022-03-06 07:13:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 528 @ 25692 updates, score 13.639) (writing took 1.7102245884016156 seconds)
2022-03-06 07:13:45 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-06 07:13:45 | INFO | train | epoch 528 | loss 2.516 | nll_loss 0.373 | ppl 1.3 | wps 27679.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25692 | lr 0.000197288 | gnorm 0.43 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60663
2022-03-06 07:13:45 | INFO | fairseq.trainer | begin training epoch 529
2022-03-06 07:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:14:03 | INFO | train_inner | epoch 529:      8 / 49 loss=2.516, nll_loss=0.373, ppl=1.3, wps=27725.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.431, loss_scale=32, train_wall=198, gb_free=21.6, wall=60681
2022-03-06 07:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:15:38 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 13.649 | nll_loss 12.951 | ppl 7919.89 | wps 46502.2 | wpb 510.9 | bsz 1 | num_updates 25741 | best_loss 9.173
2022-03-06 07:15:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25741 updates
2022-03-06 07:15:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:15:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:15:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 529 @ 25741 updates, score 13.649) (writing took 1.6706420499831438 seconds)
2022-03-06 07:15:39 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-06 07:15:39 | INFO | train | epoch 529 | loss 2.516 | nll_loss 0.373 | ppl 1.3 | wps 27712.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25741 | lr 0.0001971 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60778
2022-03-06 07:15:39 | INFO | fairseq.trainer | begin training epoch 530
2022-03-06 07:15:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:17:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:17:32 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 13.533 | nll_loss 12.82 | ppl 7232.1 | wps 46296.7 | wpb 510.9 | bsz 1 | num_updates 25789 | best_loss 9.173
2022-03-06 07:17:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25789 updates
2022-03-06 07:17:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:17:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:17:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 530 @ 25789 updates, score 13.533) (writing took 1.6760575957596302 seconds)
2022-03-06 07:17:34 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-06 07:17:34 | INFO | train | epoch 530 | loss 2.515 | nll_loss 0.373 | ppl 1.29 | wps 27126.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25789 | lr 0.000196917 | gnorm 0.436 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60893
2022-03-06 07:17:34 | INFO | fairseq.trainer | begin training epoch 531
2022-03-06 07:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:17:59 | INFO | train_inner | epoch 531:     11 / 49 loss=2.515, nll_loss=0.372, ppl=1.29, wps=27474.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.433, loss_scale=32, train_wall=200, gb_free=21.6, wall=60917
2022-03-06 07:19:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:19:27 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 13.527 | nll_loss 12.816 | ppl 7209.7 | wps 46492 | wpb 510.9 | bsz 1 | num_updates 25838 | best_loss 9.173
2022-03-06 07:19:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25838 updates
2022-03-06 07:19:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:19:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:19:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 531 @ 25838 updates, score 13.527) (writing took 1.7080912115052342 seconds)
2022-03-06 07:19:29 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-06 07:19:29 | INFO | train | epoch 531 | loss 2.515 | nll_loss 0.372 | ppl 1.29 | wps 27698.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25838 | lr 0.00019673 | gnorm 0.432 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61008
2022-03-06 07:19:29 | INFO | fairseq.trainer | begin training epoch 532
2022-03-06 07:19:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:21:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:21:22 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 13.588 | nll_loss 12.891 | ppl 7595.11 | wps 46486.5 | wpb 510.9 | bsz 1 | num_updates 25887 | best_loss 9.173
2022-03-06 07:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25887 updates
2022-03-06 07:21:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:21:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 532 @ 25887 updates, score 13.588) (writing took 1.6534481775015593 seconds)
2022-03-06 07:21:24 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-06 07:21:24 | INFO | train | epoch 532 | loss 2.515 | nll_loss 0.372 | ppl 1.29 | wps 27710.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25887 | lr 0.000196544 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61122
2022-03-06 07:21:24 | INFO | fairseq.trainer | begin training epoch 533
2022-03-06 07:21:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:21:53 | INFO | train_inner | epoch 533:     13 / 49 loss=2.515, nll_loss=0.372, ppl=1.29, wps=27731.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.434, loss_scale=32, train_wall=198, gb_free=21.6, wall=61151
2022-03-06 07:22:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:23:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:23:17 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 13.438 | nll_loss 12.72 | ppl 6746.92 | wps 46457.7 | wpb 510.9 | bsz 1 | num_updates 25935 | best_loss 9.173
2022-03-06 07:23:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25935 updates
2022-03-06 07:23:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:23:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:23:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 533 @ 25935 updates, score 13.438) (writing took 1.6692010816186666 seconds)
2022-03-06 07:23:18 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-06 07:23:18 | INFO | train | epoch 533 | loss 2.515 | nll_loss 0.372 | ppl 1.29 | wps 27121.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25935 | lr 0.000196362 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61237
2022-03-06 07:23:18 | INFO | fairseq.trainer | begin training epoch 534
2022-03-06 07:23:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:25:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:25:11 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 13.58 | nll_loss 12.879 | ppl 7531.03 | wps 46463.5 | wpb 510.9 | bsz 1 | num_updates 25984 | best_loss 9.173
2022-03-06 07:25:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25984 updates
2022-03-06 07:25:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:25:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:25:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 534 @ 25984 updates, score 13.58) (writing took 1.7167223831638694 seconds)
2022-03-06 07:25:13 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-06 07:25:13 | INFO | train | epoch 534 | loss 2.514 | nll_loss 0.372 | ppl 1.29 | wps 27709.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25984 | lr 0.000196177 | gnorm 0.428 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61352
2022-03-06 07:25:13 | INFO | fairseq.trainer | begin training epoch 535
2022-03-06 07:25:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:25:49 | INFO | train_inner | epoch 535:     16 / 49 loss=2.514, nll_loss=0.372, ppl=1.29, wps=27469.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.434, loss_scale=32, train_wall=200, gb_free=21.6, wall=61388
2022-03-06 07:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:27:06 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 13.659 | nll_loss 12.955 | ppl 7942.01 | wps 46616.4 | wpb 510.9 | bsz 1 | num_updates 26033 | best_loss 9.173
2022-03-06 07:27:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26033 updates
2022-03-06 07:27:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:27:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:27:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 535 @ 26033 updates, score 13.659) (writing took 1.76763263810426 seconds)
2022-03-06 07:27:08 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-06 07:27:08 | INFO | train | epoch 535 | loss 2.513 | nll_loss 0.371 | ppl 1.29 | wps 27676.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26033 | lr 0.000195992 | gnorm 0.429 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 61467
2022-03-06 07:27:08 | INFO | fairseq.trainer | begin training epoch 536
2022-03-06 07:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:27:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:28:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:29:01 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 13.607 | nll_loss 12.907 | ppl 7682.45 | wps 46601.7 | wpb 510.9 | bsz 1 | num_updates 26081 | best_loss 9.173
2022-03-06 07:29:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26081 updates
2022-03-06 07:29:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:29:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 536 @ 26081 updates, score 13.607) (writing took 1.6457249876111746 seconds)
2022-03-06 07:29:03 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-06 07:29:03 | INFO | train | epoch 536 | loss 2.513 | nll_loss 0.371 | ppl 1.29 | wps 27135.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26081 | lr 0.000195811 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61581
2022-03-06 07:29:03 | INFO | fairseq.trainer | begin training epoch 537
2022-03-06 07:29:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:29:45 | INFO | train_inner | epoch 537:     19 / 49 loss=2.513, nll_loss=0.371, ppl=1.29, wps=27470.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.429, loss_scale=32, train_wall=200, gb_free=21.6, wall=61624
2022-03-06 07:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:30:56 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 13.581 | nll_loss 12.876 | ppl 7516.59 | wps 46326.3 | wpb 510.9 | bsz 1 | num_updates 26130 | best_loss 9.173
2022-03-06 07:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26130 updates
2022-03-06 07:30:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:30:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:30:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 537 @ 26130 updates, score 13.581) (writing took 1.6739413738250732 seconds)
2022-03-06 07:30:57 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-06 07:30:57 | INFO | train | epoch 537 | loss 2.513 | nll_loss 0.371 | ppl 1.29 | wps 27700.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26130 | lr 0.000195628 | gnorm 0.429 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61696
2022-03-06 07:30:57 | INFO | fairseq.trainer | begin training epoch 538
2022-03-06 07:30:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:32:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:32:50 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 13.529 | nll_loss 12.816 | ppl 7208.9 | wps 46570.1 | wpb 510.9 | bsz 1 | num_updates 26178 | best_loss 9.173
2022-03-06 07:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26178 updates
2022-03-06 07:32:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 538 @ 26178 updates, score 13.529) (writing took 1.7665368663147092 seconds)
2022-03-06 07:32:52 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-06 07:32:52 | INFO | train | epoch 538 | loss 2.512 | nll_loss 0.37 | ppl 1.29 | wps 27120.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26178 | lr 0.000195448 | gnorm 0.429 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61811
2022-03-06 07:32:52 | INFO | fairseq.trainer | begin training epoch 539
2022-03-06 07:32:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:33:41 | INFO | train_inner | epoch 539:     22 / 49 loss=2.512, nll_loss=0.37, ppl=1.29, wps=27464.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.428, loss_scale=32, train_wall=200, gb_free=21.6, wall=61860
2022-03-06 07:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:34:45 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 13.56 | nll_loss 12.849 | ppl 7377.84 | wps 46481.8 | wpb 510.9 | bsz 1 | num_updates 26227 | best_loss 9.173
2022-03-06 07:34:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26227 updates
2022-03-06 07:34:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:34:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:34:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 539 @ 26227 updates, score 13.56) (writing took 1.7070731446146965 seconds)
2022-03-06 07:34:47 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-06 07:34:47 | INFO | train | epoch 539 | loss 2.512 | nll_loss 0.37 | ppl 1.29 | wps 27706.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26227 | lr 0.000195266 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61925
2022-03-06 07:34:47 | INFO | fairseq.trainer | begin training epoch 540
2022-03-06 07:34:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:36:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:36:40 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 13.585 | nll_loss 12.88 | ppl 7540.07 | wps 46523.7 | wpb 510.9 | bsz 1 | num_updates 26276 | best_loss 9.173
2022-03-06 07:36:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26276 updates
2022-03-06 07:36:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:36:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:36:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 540 @ 26276 updates, score 13.585) (writing took 1.7201581737026572 seconds)
2022-03-06 07:36:41 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-06 07:36:41 | INFO | train | epoch 540 | loss 2.511 | nll_loss 0.369 | ppl 1.29 | wps 27699.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26276 | lr 0.000195083 | gnorm 0.428 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62040
2022-03-06 07:36:41 | INFO | fairseq.trainer | begin training epoch 541
2022-03-06 07:36:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:37:35 | INFO | train_inner | epoch 541:     24 / 49 loss=2.512, nll_loss=0.37, ppl=1.29, wps=27744, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.429, loss_scale=64, train_wall=198, gb_free=21.6, wall=62094
2022-03-06 07:37:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:38:34 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 13.555 | nll_loss 12.846 | ppl 7362.15 | wps 46505.9 | wpb 510.9 | bsz 1 | num_updates 26324 | best_loss 9.173
2022-03-06 07:38:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26324 updates
2022-03-06 07:38:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 541 @ 26324 updates, score 13.555) (writing took 1.7481973683461547 seconds)
2022-03-06 07:38:36 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-06 07:38:36 | INFO | train | epoch 541 | loss 2.512 | nll_loss 0.37 | ppl 1.29 | wps 27125.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26324 | lr 0.000194905 | gnorm 0.43 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62155
2022-03-06 07:38:36 | INFO | fairseq.trainer | begin training epoch 542
2022-03-06 07:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:40:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:40:29 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 13.608 | nll_loss 12.904 | ppl 7665.49 | wps 46552.9 | wpb 510.9 | bsz 1 | num_updates 26373 | best_loss 9.173
2022-03-06 07:40:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26373 updates
2022-03-06 07:40:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 542 @ 26373 updates, score 13.608) (writing took 1.7163696512579918 seconds)
2022-03-06 07:40:31 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-06 07:40:31 | INFO | train | epoch 542 | loss 2.511 | nll_loss 0.369 | ppl 1.29 | wps 27696 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26373 | lr 0.000194724 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62270
2022-03-06 07:40:31 | INFO | fairseq.trainer | begin training epoch 543
2022-03-06 07:40:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:41:31 | INFO | train_inner | epoch 543:     27 / 49 loss=2.511, nll_loss=0.369, ppl=1.29, wps=27449.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.429, loss_scale=32, train_wall=200, gb_free=21.6, wall=62330
2022-03-06 07:42:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:42:24 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 13.589 | nll_loss 12.88 | ppl 7536.28 | wps 46485.3 | wpb 510.9 | bsz 1 | num_updates 26422 | best_loss 9.173
2022-03-06 07:42:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26422 updates
2022-03-06 07:42:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:42:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 543 @ 26422 updates, score 13.589) (writing took 1.7808984210714698 seconds)
2022-03-06 07:42:26 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-06 07:42:26 | INFO | train | epoch 543 | loss 2.511 | nll_loss 0.369 | ppl 1.29 | wps 27672.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26422 | lr 0.000194544 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62385
2022-03-06 07:42:26 | INFO | fairseq.trainer | begin training epoch 544
2022-03-06 07:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:42:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:44:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:44:19 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 13.55 | nll_loss 12.84 | ppl 7333.93 | wps 46513.5 | wpb 510.9 | bsz 1 | num_updates 26470 | best_loss 9.173
2022-03-06 07:44:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26470 updates
2022-03-06 07:44:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:44:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:44:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 544 @ 26470 updates, score 13.55) (writing took 1.7652761861681938 seconds)
2022-03-06 07:44:21 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-06 07:44:21 | INFO | train | epoch 544 | loss 2.51 | nll_loss 0.368 | ppl 1.29 | wps 27131 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26470 | lr 0.000194367 | gnorm 0.43 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62499
2022-03-06 07:44:21 | INFO | fairseq.trainer | begin training epoch 545
2022-03-06 07:44:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:45:28 | INFO | train_inner | epoch 545:     30 / 49 loss=2.51, nll_loss=0.369, ppl=1.29, wps=27460.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.427, loss_scale=32, train_wall=200, gb_free=21.6, wall=62566
2022-03-06 07:46:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:46:14 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 13.63 | nll_loss 12.933 | ppl 7820.9 | wps 46617.1 | wpb 510.9 | bsz 1 | num_updates 26519 | best_loss 9.173
2022-03-06 07:46:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26519 updates
2022-03-06 07:46:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:46:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:46:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 545 @ 26519 updates, score 13.63) (writing took 1.7925172252580523 seconds)
2022-03-06 07:46:15 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-06 07:46:15 | INFO | train | epoch 545 | loss 2.51 | nll_loss 0.369 | ppl 1.29 | wps 27660.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26519 | lr 0.000194188 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62614
2022-03-06 07:46:15 | INFO | fairseq.trainer | begin training epoch 546
2022-03-06 07:46:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:48:09 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 13.566 | nll_loss 12.859 | ppl 7429.81 | wps 46455.4 | wpb 510.9 | bsz 1 | num_updates 26568 | best_loss 9.173
2022-03-06 07:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26568 updates
2022-03-06 07:48:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:48:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 546 @ 26568 updates, score 13.566) (writing took 1.7671026065945625 seconds)
2022-03-06 07:48:10 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-06 07:48:10 | INFO | train | epoch 546 | loss 2.509 | nll_loss 0.368 | ppl 1.29 | wps 27637.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26568 | lr 0.000194008 | gnorm 0.431 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 62729
2022-03-06 07:48:10 | INFO | fairseq.trainer | begin training epoch 547
2022-03-06 07:48:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:48:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:49:24 | INFO | train_inner | epoch 547:     33 / 49 loss=2.51, nll_loss=0.369, ppl=1.29, wps=27433.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.431, loss_scale=32, train_wall=200, gb_free=21.6, wall=62803
2022-03-06 07:49:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:50:03 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 13.582 | nll_loss 12.874 | ppl 7505.56 | wps 46487.6 | wpb 510.9 | bsz 1 | num_updates 26616 | best_loss 9.173
2022-03-06 07:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26616 updates
2022-03-06 07:50:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:50:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:50:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 547 @ 26616 updates, score 13.582) (writing took 1.7865131050348282 seconds)
2022-03-06 07:50:05 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-06 07:50:05 | INFO | train | epoch 547 | loss 2.509 | nll_loss 0.368 | ppl 1.29 | wps 27122.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26616 | lr 0.000193833 | gnorm 0.43 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62844
2022-03-06 07:50:05 | INFO | fairseq.trainer | begin training epoch 548
2022-03-06 07:50:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:51:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:51:58 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 13.611 | nll_loss 12.912 | ppl 7705.5 | wps 46542 | wpb 510.9 | bsz 1 | num_updates 26665 | best_loss 9.173
2022-03-06 07:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26665 updates
2022-03-06 07:51:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:52:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:52:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 548 @ 26665 updates, score 13.611) (writing took 1.7864084541797638 seconds)
2022-03-06 07:52:00 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-06 07:52:00 | INFO | train | epoch 548 | loss 2.509 | nll_loss 0.368 | ppl 1.29 | wps 27671.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26665 | lr 0.000193655 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62959
2022-03-06 07:52:00 | INFO | fairseq.trainer | begin training epoch 549
2022-03-06 07:52:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:53:18 | INFO | train_inner | epoch 549:     35 / 49 loss=2.509, nll_loss=0.368, ppl=1.29, wps=27709.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.432, loss_scale=64, train_wall=198, gb_free=21.6, wall=63037
2022-03-06 07:53:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:53:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:53:53 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 13.662 | nll_loss 12.97 | ppl 8023.09 | wps 46486.4 | wpb 510.9 | bsz 1 | num_updates 26713 | best_loss 9.173
2022-03-06 07:53:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26713 updates
2022-03-06 07:53:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:53:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:53:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 549 @ 26713 updates, score 13.662) (writing took 1.7641986943781376 seconds)
2022-03-06 07:53:55 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-06 07:53:55 | INFO | train | epoch 549 | loss 2.509 | nll_loss 0.368 | ppl 1.29 | wps 27108.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26713 | lr 0.000193481 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63074
2022-03-06 07:53:55 | INFO | fairseq.trainer | begin training epoch 550
2022-03-06 07:53:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:55:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:55:48 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 13.48 | nll_loss 12.765 | ppl 6960.93 | wps 46553.8 | wpb 510.9 | bsz 1 | num_updates 26762 | best_loss 9.173
2022-03-06 07:55:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26762 updates
2022-03-06 07:55:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:55:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:55:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 550 @ 26762 updates, score 13.48) (writing took 1.7499087313190103 seconds)
2022-03-06 07:55:50 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-06 07:55:50 | INFO | train | epoch 550 | loss 2.509 | nll_loss 0.368 | ppl 1.29 | wps 27685.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26762 | lr 0.000193304 | gnorm 0.436 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63188
2022-03-06 07:55:50 | INFO | fairseq.trainer | begin training epoch 551
2022-03-06 07:55:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:57:15 | INFO | train_inner | epoch 551:     38 / 49 loss=2.508, nll_loss=0.368, ppl=1.29, wps=27444.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.433, loss_scale=32, train_wall=200, gb_free=21.6, wall=63273
2022-03-06 07:57:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 07:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:57:43 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 13.508 | nll_loss 12.795 | ppl 7106.13 | wps 46588.1 | wpb 510.9 | bsz 1 | num_updates 26810 | best_loss 9.173
2022-03-06 07:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26810 updates
2022-03-06 07:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:57:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 551 @ 26810 updates, score 13.508) (writing took 1.7828621827065945 seconds)
2022-03-06 07:57:45 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-06 07:57:45 | INFO | train | epoch 551 | loss 2.509 | nll_loss 0.368 | ppl 1.29 | wps 27090.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26810 | lr 0.000193131 | gnorm 0.429 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 63303
2022-03-06 07:57:45 | INFO | fairseq.trainer | begin training epoch 552
2022-03-06 07:57:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:59:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:59:37 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 13.577 | nll_loss 12.873 | ppl 7503.99 | wps 46381.1 | wpb 510.9 | bsz 1 | num_updates 26859 | best_loss 9.173
2022-03-06 07:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26859 updates
2022-03-06 07:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:59:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 07:59:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 552 @ 26859 updates, score 13.577) (writing took 1.788014518097043 seconds)
2022-03-06 07:59:39 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-06 07:59:39 | INFO | train | epoch 552 | loss 2.508 | nll_loss 0.367 | ppl 1.29 | wps 27697 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26859 | lr 0.000192955 | gnorm 0.428 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 63418
2022-03-06 07:59:39 | INFO | fairseq.trainer | begin training epoch 553
2022-03-06 07:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:01:11 | INFO | train_inner | epoch 553:     41 / 49 loss=2.508, nll_loss=0.367, ppl=1.29, wps=27463.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.428, loss_scale=16, train_wall=200, gb_free=21.6, wall=63509
2022-03-06 08:01:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:01:32 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 13.594 | nll_loss 12.89 | ppl 7590.44 | wps 46806.2 | wpb 510.9 | bsz 1 | num_updates 26908 | best_loss 9.173
2022-03-06 08:01:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26908 updates
2022-03-06 08:01:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:01:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:01:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 553 @ 26908 updates, score 13.594) (writing took 1.7519020913168788 seconds)
2022-03-06 08:01:34 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-06 08:01:34 | INFO | train | epoch 553 | loss 2.507 | nll_loss 0.367 | ppl 1.29 | wps 27705.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26908 | lr 0.000192779 | gnorm 0.428 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 63533
2022-03-06 08:01:34 | INFO | fairseq.trainer | begin training epoch 554
2022-03-06 08:01:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:03:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:03:27 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 13.508 | nll_loss 12.8 | ppl 7130.1 | wps 46444.8 | wpb 510.9 | bsz 1 | num_updates 26957 | best_loss 9.173
2022-03-06 08:03:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26957 updates
2022-03-06 08:03:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:03:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:03:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 554 @ 26957 updates, score 13.508) (writing took 1.804499908350408 seconds)
2022-03-06 08:03:29 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-06 08:03:29 | INFO | train | epoch 554 | loss 2.507 | nll_loss 0.366 | ppl 1.29 | wps 27666.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26957 | lr 0.000192604 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63648
2022-03-06 08:03:29 | INFO | fairseq.trainer | begin training epoch 555
2022-03-06 08:03:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:05:05 | INFO | train_inner | epoch 555:     43 / 49 loss=2.507, nll_loss=0.366, ppl=1.29, wps=27722.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.423, loss_scale=32, train_wall=198, gb_free=21.6, wall=63743
2022-03-06 08:05:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:05:22 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 13.519 | nll_loss 12.808 | ppl 7170.73 | wps 46410 | wpb 510.9 | bsz 1 | num_updates 27006 | best_loss 9.173
2022-03-06 08:05:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27006 updates
2022-03-06 08:05:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:05:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:05:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 555 @ 27006 updates, score 13.519) (writing took 1.7919845068827271 seconds)
2022-03-06 08:05:24 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-06 08:05:24 | INFO | train | epoch 555 | loss 2.507 | nll_loss 0.366 | ppl 1.29 | wps 27692.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27006 | lr 0.000192429 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63762
2022-03-06 08:05:24 | INFO | fairseq.trainer | begin training epoch 556
2022-03-06 08:05:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:07:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:07:17 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 13.499 | nll_loss 12.785 | ppl 7055.41 | wps 46252.9 | wpb 510.9 | bsz 1 | num_updates 27055 | best_loss 9.173
2022-03-06 08:07:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27055 updates
2022-03-06 08:07:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:07:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:07:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 556 @ 27055 updates, score 13.499) (writing took 1.8180437805131078 seconds)
2022-03-06 08:07:19 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-06 08:07:19 | INFO | train | epoch 556 | loss 2.506 | nll_loss 0.366 | ppl 1.29 | wps 27660.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27055 | lr 0.000192254 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63877
2022-03-06 08:07:19 | INFO | fairseq.trainer | begin training epoch 557
2022-03-06 08:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:07:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:09:01 | INFO | train_inner | epoch 557:     46 / 49 loss=2.506, nll_loss=0.366, ppl=1.29, wps=27445.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.43, loss_scale=32, train_wall=200, gb_free=21.6, wall=63980
2022-03-06 08:09:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:09:12 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 13.587 | nll_loss 12.889 | ppl 7584.06 | wps 46283.3 | wpb 510.9 | bsz 1 | num_updates 27103 | best_loss 9.173
2022-03-06 08:09:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27103 updates
2022-03-06 08:09:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:09:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:09:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 557 @ 27103 updates, score 13.587) (writing took 1.7628301363438368 seconds)
2022-03-06 08:09:13 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-06 08:09:13 | INFO | train | epoch 557 | loss 2.506 | nll_loss 0.366 | ppl 1.29 | wps 27121.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27103 | lr 0.000192084 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63992
2022-03-06 08:09:13 | INFO | fairseq.trainer | begin training epoch 558
2022-03-06 08:09:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:11:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:11:06 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 13.559 | nll_loss 12.858 | ppl 7423.74 | wps 46406 | wpb 510.9 | bsz 1 | num_updates 27152 | best_loss 9.173
2022-03-06 08:11:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27152 updates
2022-03-06 08:11:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:11:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:11:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 558 @ 27152 updates, score 13.559) (writing took 1.7377767404541373 seconds)
2022-03-06 08:11:08 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-06 08:11:08 | INFO | train | epoch 558 | loss 2.505 | nll_loss 0.365 | ppl 1.29 | wps 27696.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27152 | lr 0.000191911 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64107
2022-03-06 08:11:08 | INFO | fairseq.trainer | begin training epoch 559
2022-03-06 08:11:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:12:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:12:56 | INFO | train_inner | epoch 559:     49 / 49 loss=2.505, nll_loss=0.366, ppl=1.29, wps=27452.4, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=27200, lr=0.000191741, gnorm=0.427, loss_scale=32, train_wall=199, gb_free=21.6, wall=64215
2022-03-06 08:12:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:13:01 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 13.65 | nll_loss 12.95 | ppl 7915.12 | wps 46358.4 | wpb 510.9 | bsz 1 | num_updates 27200 | best_loss 9.173
2022-03-06 08:13:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27200 updates
2022-03-06 08:13:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:13:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 559 @ 27200 updates, score 13.65) (writing took 1.732592892833054 seconds)
2022-03-06 08:13:03 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-06 08:13:03 | INFO | train | epoch 559 | loss 2.505 | nll_loss 0.366 | ppl 1.29 | wps 27133.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27200 | lr 0.000191741 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64221
2022-03-06 08:13:03 | INFO | fairseq.trainer | begin training epoch 560
2022-03-06 08:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:14:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:14:56 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 13.585 | nll_loss 12.883 | ppl 7554.53 | wps 46226.2 | wpb 510.9 | bsz 1 | num_updates 27249 | best_loss 9.173
2022-03-06 08:14:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27249 updates
2022-03-06 08:14:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:14:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:14:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 560 @ 27249 updates, score 13.585) (writing took 1.8098313426598907 seconds)
2022-03-06 08:14:58 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-06 08:14:58 | INFO | train | epoch 560 | loss 2.506 | nll_loss 0.366 | ppl 1.29 | wps 27670.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27249 | lr 0.000191569 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64336
2022-03-06 08:14:58 | INFO | fairseq.trainer | begin training epoch 561
2022-03-06 08:14:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:16:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:16:51 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 13.684 | nll_loss 12.992 | ppl 8145.68 | wps 46237.1 | wpb 510.9 | bsz 1 | num_updates 27298 | best_loss 9.173
2022-03-06 08:16:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27298 updates
2022-03-06 08:16:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:16:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:16:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 561 @ 27298 updates, score 13.684) (writing took 1.736956070177257 seconds)
2022-03-06 08:16:52 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-06 08:16:52 | INFO | train | epoch 561 | loss 2.505 | nll_loss 0.365 | ppl 1.29 | wps 27684.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27298 | lr 0.000191397 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64451
2022-03-06 08:16:52 | INFO | fairseq.trainer | begin training epoch 562
2022-03-06 08:16:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:16:57 | INFO | train_inner | epoch 562:      2 / 49 loss=2.505, nll_loss=0.365, ppl=1.29, wps=26952.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.429, loss_scale=32, train_wall=198, gb_free=21.6, wall=64456
2022-03-06 08:17:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:18:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:18:45 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 13.59 | nll_loss 12.886 | ppl 7571.52 | wps 46050.8 | wpb 510.9 | bsz 1 | num_updates 27346 | best_loss 9.173
2022-03-06 08:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27346 updates
2022-03-06 08:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:18:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:18:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 562 @ 27346 updates, score 13.59) (writing took 1.7411234993487597 seconds)
2022-03-06 08:18:47 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-06 08:18:47 | INFO | train | epoch 562 | loss 2.504 | nll_loss 0.364 | ppl 1.29 | wps 27120.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27346 | lr 0.000191229 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64566
2022-03-06 08:18:47 | INFO | fairseq.trainer | begin training epoch 563
2022-03-06 08:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:20:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:20:40 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 13.571 | nll_loss 12.87 | ppl 7485.61 | wps 46114 | wpb 510.9 | bsz 1 | num_updates 27395 | best_loss 9.173
2022-03-06 08:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27395 updates
2022-03-06 08:20:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:20:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 563 @ 27395 updates, score 13.571) (writing took 1.7302307402715087 seconds)
2022-03-06 08:20:42 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-06 08:20:42 | INFO | train | epoch 563 | loss 2.504 | nll_loss 0.364 | ppl 1.29 | wps 27673.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27395 | lr 0.000191058 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64681
2022-03-06 08:20:42 | INFO | fairseq.trainer | begin training epoch 564
2022-03-06 08:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:20:53 | INFO | train_inner | epoch 564:      5 / 49 loss=2.504, nll_loss=0.364, ppl=1.29, wps=27453.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.423, loss_scale=32, train_wall=200, gb_free=21.6, wall=64692
2022-03-06 08:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:22:35 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 13.615 | nll_loss 12.917 | ppl 7736.66 | wps 45956 | wpb 510.9 | bsz 1 | num_updates 27444 | best_loss 9.173
2022-03-06 08:22:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27444 updates
2022-03-06 08:22:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:22:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:22:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 564 @ 27444 updates, score 13.615) (writing took 1.7262385580688715 seconds)
2022-03-06 08:22:37 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-06 08:22:37 | INFO | train | epoch 564 | loss 2.504 | nll_loss 0.364 | ppl 1.29 | wps 27686.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27444 | lr 0.000190887 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64795
2022-03-06 08:22:37 | INFO | fairseq.trainer | begin training epoch 565
2022-03-06 08:22:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:23:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:24:30 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 13.604 | nll_loss 12.901 | ppl 7647.43 | wps 46320.2 | wpb 510.9 | bsz 1 | num_updates 27492 | best_loss 9.173
2022-03-06 08:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27492 updates
2022-03-06 08:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:24:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:24:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 565 @ 27492 updates, score 13.604) (writing took 1.7778045106679201 seconds)
2022-03-06 08:24:31 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-06 08:24:31 | INFO | train | epoch 565 | loss 2.503 | nll_loss 0.363 | ppl 1.29 | wps 27151 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27492 | lr 0.00019072 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64910
2022-03-06 08:24:31 | INFO | fairseq.trainer | begin training epoch 566
2022-03-06 08:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:24:49 | INFO | train_inner | epoch 566:      8 / 49 loss=2.503, nll_loss=0.364, ppl=1.29, wps=27477.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.427, loss_scale=32, train_wall=200, gb_free=21.6, wall=64928
2022-03-06 08:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:26:24 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 13.582 | nll_loss 12.88 | ppl 7535.61 | wps 45849 | wpb 510.9 | bsz 1 | num_updates 27541 | best_loss 9.173
2022-03-06 08:26:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27541 updates
2022-03-06 08:26:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:26:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:26:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 566 @ 27541 updates, score 13.582) (writing took 1.6992167448624969 seconds)
2022-03-06 08:26:26 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-06 08:26:26 | INFO | train | epoch 566 | loss 2.503 | nll_loss 0.364 | ppl 1.29 | wps 27700.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27541 | lr 0.000190551 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65025
2022-03-06 08:26:26 | INFO | fairseq.trainer | begin training epoch 567
2022-03-06 08:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:28:19 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 13.519 | nll_loss 12.809 | ppl 7177.15 | wps 45938.4 | wpb 510.9 | bsz 1 | num_updates 27590 | best_loss 9.173
2022-03-06 08:28:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27590 updates
2022-03-06 08:28:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:28:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:28:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 567 @ 27590 updates, score 13.519) (writing took 1.7050623558461666 seconds)
2022-03-06 08:28:21 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-06 08:28:21 | INFO | train | epoch 567 | loss 2.503 | nll_loss 0.363 | ppl 1.29 | wps 27728.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27590 | lr 0.000190381 | gnorm 0.423 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 65139
2022-03-06 08:28:21 | INFO | fairseq.trainer | begin training epoch 568
2022-03-06 08:28:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:28:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:28:45 | INFO | train_inner | epoch 568:     11 / 49 loss=2.503, nll_loss=0.364, ppl=1.29, wps=27480.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.424, loss_scale=32, train_wall=200, gb_free=21.6, wall=65164
2022-03-06 08:28:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 08:30:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:30:14 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 13.597 | nll_loss 12.899 | ppl 7637.6 | wps 46073.5 | wpb 510.9 | bsz 1 | num_updates 27637 | best_loss 9.173
2022-03-06 08:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27637 updates
2022-03-06 08:30:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:30:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:30:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 568 @ 27637 updates, score 13.597) (writing took 1.761750454083085 seconds)
2022-03-06 08:30:16 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-06 08:30:16 | INFO | train | epoch 568 | loss 2.502 | nll_loss 0.363 | ppl 1.29 | wps 26545.9 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 27637 | lr 0.000190219 | gnorm 0.42 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 65254
2022-03-06 08:30:16 | INFO | fairseq.trainer | begin training epoch 569
2022-03-06 08:30:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:32:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:32:09 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 13.625 | nll_loss 12.928 | ppl 7795.54 | wps 45812 | wpb 510.9 | bsz 1 | num_updates 27686 | best_loss 9.173
2022-03-06 08:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27686 updates
2022-03-06 08:32:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:32:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 569 @ 27686 updates, score 13.625) (writing took 1.845920018851757 seconds)
2022-03-06 08:32:10 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-06 08:32:10 | INFO | train | epoch 569 | loss 2.503 | nll_loss 0.364 | ppl 1.29 | wps 27668.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27686 | lr 0.000190051 | gnorm 0.425 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 65369
2022-03-06 08:32:10 | INFO | fairseq.trainer | begin training epoch 570
2022-03-06 08:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:32:42 | INFO | train_inner | epoch 570:     14 / 49 loss=2.503, nll_loss=0.363, ppl=1.29, wps=27456.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.425, loss_scale=16, train_wall=200, gb_free=21.6, wall=65400
2022-03-06 08:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:34:03 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 13.56 | nll_loss 12.863 | ppl 7450.32 | wps 45938.6 | wpb 510.9 | bsz 1 | num_updates 27735 | best_loss 9.173
2022-03-06 08:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27735 updates
2022-03-06 08:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 570 @ 27735 updates, score 13.56) (writing took 1.7505662944167852 seconds)
2022-03-06 08:34:05 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-06 08:34:05 | INFO | train | epoch 570 | loss 2.502 | nll_loss 0.363 | ppl 1.29 | wps 27680.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27735 | lr 0.000189883 | gnorm 0.422 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65484
2022-03-06 08:34:05 | INFO | fairseq.trainer | begin training epoch 571
2022-03-06 08:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:35:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:35:58 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 13.565 | nll_loss 12.857 | ppl 7420.75 | wps 45958.8 | wpb 510.9 | bsz 1 | num_updates 27784 | best_loss 9.173
2022-03-06 08:35:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27784 updates
2022-03-06 08:35:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:36:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:36:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 571 @ 27784 updates, score 13.565) (writing took 1.7580366777256131 seconds)
2022-03-06 08:36:00 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-06 08:36:00 | INFO | train | epoch 571 | loss 2.502 | nll_loss 0.363 | ppl 1.29 | wps 27671.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27784 | lr 0.000189715 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65599
2022-03-06 08:36:00 | INFO | fairseq.trainer | begin training epoch 572
2022-03-06 08:36:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:36:36 | INFO | train_inner | epoch 572:     16 / 49 loss=2.501, nll_loss=0.362, ppl=1.29, wps=27710.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.423, loss_scale=32, train_wall=198, gb_free=21.6, wall=65634
2022-03-06 08:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:37:53 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 13.56 | nll_loss 12.853 | ppl 7400.59 | wps 45920.9 | wpb 510.9 | bsz 1 | num_updates 27833 | best_loss 9.173
2022-03-06 08:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27833 updates
2022-03-06 08:37:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 572 @ 27833 updates, score 13.56) (writing took 1.7833727160468698 seconds)
2022-03-06 08:37:55 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-06 08:37:55 | INFO | train | epoch 572 | loss 2.501 | nll_loss 0.362 | ppl 1.29 | wps 27670.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27833 | lr 0.000189548 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65714
2022-03-06 08:37:55 | INFO | fairseq.trainer | begin training epoch 573
2022-03-06 08:37:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:39:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:39:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:39:48 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 13.565 | nll_loss 12.863 | ppl 7450.89 | wps 45855.6 | wpb 510.9 | bsz 1 | num_updates 27881 | best_loss 9.173
2022-03-06 08:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27881 updates
2022-03-06 08:39:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:39:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:39:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 573 @ 27881 updates, score 13.565) (writing took 1.711579179391265 seconds)
2022-03-06 08:39:50 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-06 08:39:50 | INFO | train | epoch 573 | loss 2.501 | nll_loss 0.362 | ppl 1.29 | wps 27122.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27881 | lr 0.000189385 | gnorm 0.428 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65828
2022-03-06 08:39:50 | INFO | fairseq.trainer | begin training epoch 574
2022-03-06 08:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:40:32 | INFO | train_inner | epoch 574:     19 / 49 loss=2.501, nll_loss=0.362, ppl=1.29, wps=27442.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.424, loss_scale=32, train_wall=200, gb_free=21.6, wall=65871
2022-03-06 08:41:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:41:43 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 13.595 | nll_loss 12.893 | ppl 7607.85 | wps 45950.8 | wpb 510.9 | bsz 1 | num_updates 27930 | best_loss 9.173
2022-03-06 08:41:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27930 updates
2022-03-06 08:41:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:41:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:41:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 574 @ 27930 updates, score 13.595) (writing took 1.7759996205568314 seconds)
2022-03-06 08:41:45 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-06 08:41:45 | INFO | train | epoch 574 | loss 2.501 | nll_loss 0.362 | ppl 1.29 | wps 27670.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27930 | lr 0.000189219 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65943
2022-03-06 08:41:45 | INFO | fairseq.trainer | begin training epoch 575
2022-03-06 08:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:43:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:43:38 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 13.718 | nll_loss 13.03 | ppl 8365.96 | wps 46116.2 | wpb 510.9 | bsz 1 | num_updates 27979 | best_loss 9.173
2022-03-06 08:43:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27979 updates
2022-03-06 08:43:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 575 @ 27979 updates, score 13.718) (writing took 1.7606399431824684 seconds)
2022-03-06 08:43:39 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-06 08:43:39 | INFO | train | epoch 575 | loss 2.501 | nll_loss 0.362 | ppl 1.29 | wps 27686.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27979 | lr 0.000189053 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66058
2022-03-06 08:43:39 | INFO | fairseq.trainer | begin training epoch 576
2022-03-06 08:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:44:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:44:28 | INFO | train_inner | epoch 576:     22 / 49 loss=2.501, nll_loss=0.362, ppl=1.29, wps=27459.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.421, loss_scale=32, train_wall=200, gb_free=21.6, wall=66107
2022-03-06 08:45:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:45:32 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 13.628 | nll_loss 12.931 | ppl 7811.99 | wps 45914.6 | wpb 510.9 | bsz 1 | num_updates 28027 | best_loss 9.173
2022-03-06 08:45:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28027 updates
2022-03-06 08:45:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:45:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:45:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 576 @ 28027 updates, score 13.628) (writing took 1.7008371856063604 seconds)
2022-03-06 08:45:34 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-06 08:45:34 | INFO | train | epoch 576 | loss 2.5 | nll_loss 0.361 | ppl 1.28 | wps 27107.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28027 | lr 0.000188891 | gnorm 0.419 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66173
2022-03-06 08:45:34 | INFO | fairseq.trainer | begin training epoch 577
2022-03-06 08:45:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:47:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:47:27 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 13.634 | nll_loss 12.937 | ppl 7840.14 | wps 45849.3 | wpb 510.9 | bsz 1 | num_updates 28076 | best_loss 9.173
2022-03-06 08:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28076 updates
2022-03-06 08:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:47:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 577 @ 28076 updates, score 13.634) (writing took 1.7011872604489326 seconds)
2022-03-06 08:47:29 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-06 08:47:29 | INFO | train | epoch 577 | loss 2.501 | nll_loss 0.362 | ppl 1.29 | wps 27665.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28076 | lr 0.000188726 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66288
2022-03-06 08:47:29 | INFO | fairseq.trainer | begin training epoch 578
2022-03-06 08:47:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:48:23 | INFO | train_inner | epoch 578:     24 / 49 loss=2.5, nll_loss=0.362, ppl=1.29, wps=27694.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.426, loss_scale=32, train_wall=198, gb_free=21.6, wall=66341
2022-03-06 08:49:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:49:22 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 13.576 | nll_loss 12.873 | ppl 7500.24 | wps 45902.3 | wpb 510.9 | bsz 1 | num_updates 28124 | best_loss 9.173
2022-03-06 08:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28124 updates
2022-03-06 08:49:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:49:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:49:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 578 @ 28124 updates, score 13.576) (writing took 1.7763770325109363 seconds)
2022-03-06 08:49:24 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-06 08:49:24 | INFO | train | epoch 578 | loss 2.499 | nll_loss 0.361 | ppl 1.28 | wps 27099 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 28124 | lr 0.000188565 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66403
2022-03-06 08:49:24 | INFO | fairseq.trainer | begin training epoch 579
2022-03-06 08:49:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:51:17 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 13.591 | nll_loss 12.893 | ppl 7606.23 | wps 45794.7 | wpb 510.9 | bsz 1 | num_updates 28173 | best_loss 9.173
2022-03-06 08:51:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28173 updates
2022-03-06 08:51:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:51:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:51:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 579 @ 28173 updates, score 13.591) (writing took 1.7172268088907003 seconds)
2022-03-06 08:51:19 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-06 08:51:19 | INFO | train | epoch 579 | loss 2.499 | nll_loss 0.361 | ppl 1.28 | wps 27685.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28173 | lr 0.000188401 | gnorm 0.412 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66517
2022-03-06 08:51:19 | INFO | fairseq.trainer | begin training epoch 580
2022-03-06 08:51:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:52:19 | INFO | train_inner | epoch 580:     27 / 49 loss=2.499, nll_loss=0.361, ppl=1.28, wps=27447.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.417, loss_scale=32, train_wall=200, gb_free=21.6, wall=66578
2022-03-06 08:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:53:12 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 13.553 | nll_loss 12.854 | ppl 7401.24 | wps 45924.7 | wpb 510.9 | bsz 1 | num_updates 28222 | best_loss 9.173
2022-03-06 08:53:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28222 updates
2022-03-06 08:53:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:53:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:53:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 580 @ 28222 updates, score 13.553) (writing took 1.7271830700337887 seconds)
2022-03-06 08:53:13 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-06 08:53:13 | INFO | train | epoch 580 | loss 2.499 | nll_loss 0.361 | ppl 1.28 | wps 27678.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28222 | lr 0.000188237 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66632
2022-03-06 08:53:14 | INFO | fairseq.trainer | begin training epoch 581
2022-03-06 08:53:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:54:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:55:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:55:06 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 13.556 | nll_loss 12.851 | ppl 7389.65 | wps 45934.4 | wpb 510.9 | bsz 1 | num_updates 28270 | best_loss 9.173
2022-03-06 08:55:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28270 updates
2022-03-06 08:55:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:55:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-06 08:55:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.1_#1/checkpoint_last.pt (epoch 581 @ 28270 updates, score 13.556) (writing took 1.7013386087492108 seconds)
2022-03-06 08:55:08 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-06 08:55:08 | INFO | train | epoch 581 | loss 2.499 | nll_loss 0.361 | ppl 1.28 | wps 27136.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28270 | lr 0.000188078 | gnorm 0.417 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66747
2022-03-06 08:55:08 | INFO | fairseq.trainer | begin training epoch 582
2022-03-06 08:55:08 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/label_smoothed_cross_entropy.py", line 79, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 340, in extract_features_scriptable
    x, layer_attn, _ = layer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/transformer_layer.py", line 423, in forward
    x = self.activation_fn(self.fc1(x))
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 734, in _call_impl
    if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
KeyboardInterrupt
