Sender: LSF System <lsfadmin@eu-g3-028>
Subject: Job 207345550: <w103_size_0.0625_fp16_label_smoothing_0.04_#2> in cluster <euler> Done

Job <w103_size_0.0625_fp16_label_smoothing_0.04_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 12:50:48 2022
Job was executed on host(s) <eu-g3-028>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 12:51:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 12:51:15 2022
Terminated at Tue Mar  8 05:55:16 2022
Results reported at Tue Mar  8 05:55:16 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.04 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575612 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   147723.23 sec.
    Max Memory :                                 8059 MB
    Average Memory :                             3796.04 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               11941.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   147840 sec.
    Turnaround time :                            147868 sec.

The output (if any) follows:

2022-03-06 12:51:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575612, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.04, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 12:51:23 | INFO | fairseq.tasks.language_modeling | dictionary: 138136 types
2022-03-06 12:51:25 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(138136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=138136, bias=False)
  )
)
2022-03-06 12:51:25 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 12:51:25 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 12:51:25 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 12:51:25 | INFO | fairseq_cli.train | num. shared model params: 89,639,936 (num. trained: 89,639,936)
2022-03-06 12:51:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 12:51:25 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.0625/valid
2022-03-06 12:51:28 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 12:51:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:28 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-06 12:51:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:28 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 12:51:28 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 12:51:28 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 12:51:28 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 12:51:28 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 12:51:28 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-raw-size-0.0625/train
2022-03-06 12:51:28 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 12:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:51:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 12:51:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 12:51:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 12:51:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 12:52:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 12:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 12:56:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.675 | nll_loss 14.543 | ppl 23874 | wps 41813 | wpb 510.9 | bsz 1 | num_updates 92
2022-03-06 12:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 92 updates
2022-03-06 12:56:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 12:56:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 12:56:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 1 @ 92 updates, score 14.675) (writing took 5.140944211278111 seconds)
2022-03-06 12:56:39 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 12:56:39 | INFO | train | epoch 001 | loss 16.299 | nll_loss 16.235 | ppl 77127.9 | wps 21827.5 | ups 0.33 | wpb 65489.2 | bsz 127.9 | num_updates 92 | lr 1.15977e-05 | gnorm 3.435 | loss_scale 4 | train_wall 278 | gb_free 8.1 | wall 311
2022-03-06 12:56:39 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 12:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:57:02 | INFO | train_inner | epoch 002:      8 / 97 loss=16.174, nll_loss=16.104, ppl=70459, wps=21902.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=100, lr=1.25975e-05, gnorm=3.3, loss_scale=4, train_wall=299, gb_free=8.1, wall=334
2022-03-06 13:01:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:01:22 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 12.967 | nll_loss 12.762 | ppl 6947.4 | wps 41465.6 | wpb 510.9 | bsz 1 | num_updates 189 | best_loss 12.967
2022-03-06 13:01:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 189 updates
2022-03-06 13:01:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:01:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:01:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 2 @ 189 updates, score 12.967) (writing took 4.957743849605322 seconds)
2022-03-06 13:01:27 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:01:27 | INFO | train | epoch 002 | loss 14.02 | nll_loss 13.863 | ppl 14896.3 | wps 22101.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 189 | lr 2.37203e-05 | gnorm 1.572 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 598
2022-03-06 13:01:27 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:01:58 | INFO | train_inner | epoch 003:     11 / 97 loss=13.849, nll_loss=13.684, ppl=13164.1, wps=22134, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=200, lr=2.5095e-05, gnorm=1.528, loss_scale=8, train_wall=263, gb_free=8.1, wall=630
2022-03-06 13:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:06:09 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.366 | nll_loss 11.073 | ppl 2154.3 | wps 41392.3 | wpb 510.9 | bsz 1 | num_updates 286 | best_loss 11.366
2022-03-06 13:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 286 updates
2022-03-06 13:06:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:06:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 3 @ 286 updates, score 11.366) (writing took 4.878602326847613 seconds)
2022-03-06 13:06:14 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:06:14 | INFO | train | epoch 003 | loss 12.218 | nll_loss 11.976 | ppl 4028.85 | wps 22135.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 286 | lr 3.58429e-05 | gnorm 1.037 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 885
2022-03-06 13:06:14 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:06:54 | INFO | train_inner | epoch 004:     14 / 97 loss=12.012, nll_loss=11.759, ppl=3464.79, wps=22157.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=300, lr=3.75925e-05, gnorm=0.973, loss_scale=16, train_wall=262, gb_free=8.1, wall=925
2022-03-06 13:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:10:56 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.607 | nll_loss 10.246 | ppl 1214.43 | wps 40573.3 | wpb 510.9 | bsz 1 | num_updates 383 | best_loss 10.607
2022-03-06 13:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 383 updates
2022-03-06 13:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:10:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:11:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 4 @ 383 updates, score 10.607) (writing took 5.031435315031558 seconds)
2022-03-06 13:11:01 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:11:01 | INFO | train | epoch 004 | loss 10.967 | nll_loss 10.643 | ppl 1599.01 | wps 22101.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 383 | lr 4.79654e-05 | gnorm 0.598 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 1173
2022-03-06 13:11:01 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:11:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:11:50 | INFO | train_inner | epoch 005:     17 / 97 loss=10.852, nll_loss=10.517, ppl=1465.16, wps=22121.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=400, lr=5.009e-05, gnorm=0.547, loss_scale=32, train_wall=263, gb_free=8.1, wall=1222
2022-03-06 13:15:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:15:43 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.266 | nll_loss 9.866 | ppl 932.99 | wps 41069.2 | wpb 510.9 | bsz 1 | num_updates 480 | best_loss 10.266
2022-03-06 13:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 480 updates
2022-03-06 13:15:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:15:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 5 @ 480 updates, score 10.266) (writing took 4.770135056227446 seconds)
2022-03-06 13:15:48 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:15:48 | INFO | train | epoch 005 | loss 10.438 | nll_loss 10.059 | ppl 1066.92 | wps 22111.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 480 | lr 6.0088e-05 | gnorm 0.486 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 1460
2022-03-06 13:15:48 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:15:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:16:46 | INFO | train_inner | epoch 006:     20 / 97 loss=10.366, nll_loss=9.98, ppl=1009.96, wps=22135.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=500, lr=6.25875e-05, gnorm=0.5, loss_scale=32, train_wall=263, gb_free=8.1, wall=1517
2022-03-06 13:17:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:20:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:20:31 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.998 | nll_loss 9.575 | ppl 762.83 | wps 41711.5 | wpb 510.9 | bsz 1 | num_updates 576 | best_loss 9.998
2022-03-06 13:20:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 576 updates
2022-03-06 13:20:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:20:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:20:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 6 @ 576 updates, score 9.998) (writing took 5.061942441854626 seconds)
2022-03-06 13:20:36 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:20:36 | INFO | train | epoch 006 | loss 10.117 | nll_loss 9.709 | ppl 836.97 | wps 21854.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 576 | lr 7.20856e-05 | gnorm 0.534 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 1748
2022-03-06 13:20:36 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:20:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:21:45 | INFO | train_inner | epoch 007:     24 / 97 loss=10.051, nll_loss=9.638, ppl=796.91, wps=21892.8, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=600, lr=7.5085e-05, gnorm=0.546, loss_scale=32, train_wall=266, gb_free=8.1, wall=1817
2022-03-06 13:23:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:25:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:25:19 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.752 | nll_loss 9.316 | ppl 637.47 | wps 42256.7 | wpb 510.9 | bsz 1 | num_updates 672 | best_loss 9.752
2022-03-06 13:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 672 updates
2022-03-06 13:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:25:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:25:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 7 @ 672 updates, score 9.752) (writing took 4.9962994661182165 seconds)
2022-03-06 13:25:24 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:25:24 | INFO | train | epoch 007 | loss 9.841 | nll_loss 9.414 | ppl 682.07 | wps 21857.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 672 | lr 8.40832e-05 | gnorm 0.589 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 2035
2022-03-06 13:25:24 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:25:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:26:44 | INFO | train_inner | epoch 008:     28 / 97 loss=9.771, nll_loss=9.339, ppl=647.46, wps=21905, ups=0.33, wpb=65495, bsz=127.9, num_updates=700, lr=8.75825e-05, gnorm=0.624, loss_scale=32, train_wall=266, gb_free=8.1, wall=2116
2022-03-06 13:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:30:06 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.532 | nll_loss 9.079 | ppl 540.88 | wps 42215.1 | wpb 510.9 | bsz 1 | num_updates 769 | best_loss 9.532
2022-03-06 13:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 769 updates
2022-03-06 13:30:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:30:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 8 @ 769 updates, score 9.532) (writing took 4.719687739852816 seconds)
2022-03-06 13:30:11 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 13:30:11 | INFO | train | epoch 008 | loss 9.586 | nll_loss 9.142 | ppl 565.08 | wps 22132.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 769 | lr 9.62058e-05 | gnorm 0.691 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 2323
2022-03-06 13:30:11 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 13:30:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:30:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:31:42 | INFO | train_inner | epoch 009:     32 / 97 loss=9.512, nll_loss=9.063, ppl=534.91, wps=21944.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=800, lr=0.00010008, gnorm=0.729, loss_scale=32, train_wall=265, gb_free=8.1, wall=2414
2022-03-06 13:34:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:34:53 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.338 | nll_loss 8.873 | ppl 468.91 | wps 42477.4 | wpb 510.9 | bsz 1 | num_updates 865 | best_loss 9.338
2022-03-06 13:34:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 865 updates
2022-03-06 13:34:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:34:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 9 @ 865 updates, score 9.338) (writing took 4.662026193924248 seconds)
2022-03-06 13:34:57 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 13:34:57 | INFO | train | epoch 009 | loss 9.353 | nll_loss 8.893 | ppl 475.49 | wps 21915.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 865 | lr 0.000108203 | gnorm 0.784 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 2609
2022-03-06 13:34:58 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 13:34:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:36:38 | INFO | train_inner | epoch 010:     35 / 97 loss=9.276, nll_loss=8.811, ppl=449.1, wps=22164, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=900, lr=0.000112578, gnorm=0.784, loss_scale=32, train_wall=263, gb_free=8.1, wall=2709
2022-03-06 13:37:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:39:40 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.151 | nll_loss 8.669 | ppl 407.02 | wps 42639.5 | wpb 510.9 | bsz 1 | num_updates 961 | best_loss 9.151
2022-03-06 13:39:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 961 updates
2022-03-06 13:39:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:39:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 10 @ 961 updates, score 9.151) (writing took 4.643876789137721 seconds)
2022-03-06 13:39:44 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 13:39:44 | INFO | train | epoch 010 | loss 9.137 | nll_loss 8.664 | ppl 405.53 | wps 21915.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 961 | lr 0.000120201 | gnorm 0.82 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 2896
2022-03-06 13:39:44 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 13:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:41:36 | INFO | train_inner | epoch 011:     39 / 97 loss=9.06, nll_loss=8.581, ppl=382.96, wps=21955.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=1000, lr=0.000125075, gnorm=0.84, loss_scale=32, train_wall=265, gb_free=8.1, wall=3008
2022-03-06 13:43:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:44:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:44:27 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.997 | nll_loss 8.507 | ppl 363.78 | wps 42534.5 | wpb 510.9 | bsz 1 | num_updates 1057 | best_loss 8.997
2022-03-06 13:44:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1057 updates
2022-03-06 13:44:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:44:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:44:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 11 @ 1057 updates, score 8.997) (writing took 4.980241532903165 seconds)
2022-03-06 13:44:32 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 13:44:32 | INFO | train | epoch 011 | loss 8.941 | nll_loss 8.454 | ppl 350.74 | wps 21887.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1057 | lr 0.000132199 | gnorm 0.89 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 3184
2022-03-06 13:44:32 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 13:44:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:45:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 13:46:38 | INFO | train_inner | epoch 012:     44 / 97 loss=8.859, nll_loss=8.367, ppl=330.19, wps=21713.6, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=1100, lr=0.000137573, gnorm=0.896, loss_scale=16, train_wall=268, gb_free=8.1, wall=3309
2022-03-06 13:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:49:14 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.863 | nll_loss 8.357 | ppl 327.99 | wps 42580 | wpb 510.9 | bsz 1 | num_updates 1153 | best_loss 8.863
2022-03-06 13:49:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1153 updates
2022-03-06 13:49:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:49:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:49:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 12 @ 1153 updates, score 8.863) (writing took 4.899388227146119 seconds)
2022-03-06 13:49:19 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 13:49:19 | INFO | train | epoch 012 | loss 8.761 | nll_loss 8.262 | ppl 307.02 | wps 21880.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1153 | lr 0.000144196 | gnorm 0.87 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 3471
2022-03-06 13:49:19 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 13:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:51:33 | INFO | train_inner | epoch 013:     47 / 97 loss=8.684, nll_loss=8.18, ppl=290.02, wps=22129, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1200, lr=0.00015007, gnorm=0.849, loss_scale=16, train_wall=263, gb_free=8.1, wall=3605
2022-03-06 13:53:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:54:01 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.733 | nll_loss 8.223 | ppl 298.75 | wps 42886.5 | wpb 510.9 | bsz 1 | num_updates 1250 | best_loss 8.733
2022-03-06 13:54:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1250 updates
2022-03-06 13:54:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:54:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:54:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 13 @ 1250 updates, score 8.733) (writing took 4.600916291121393 seconds)
2022-03-06 13:54:06 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 13:54:06 | INFO | train | epoch 013 | loss 8.592 | nll_loss 8.082 | ppl 271.01 | wps 22138.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1250 | lr 0.000156319 | gnorm 0.881 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 3758
2022-03-06 13:54:06 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 13:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:56:29 | INFO | train_inner | epoch 014:     50 / 97 loss=8.503, nll_loss=7.988, ppl=253.83, wps=22162.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1300, lr=0.000162568, gnorm=0.911, loss_scale=32, train_wall=263, gb_free=8.1, wall=3901
2022-03-06 13:58:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:58:48 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.631 | nll_loss 8.108 | ppl 275.92 | wps 42688.4 | wpb 510.9 | bsz 1 | num_updates 1346 | best_loss 8.631
2022-03-06 13:58:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1346 updates
2022-03-06 13:58:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:58:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:58:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 14 @ 1346 updates, score 8.631) (writing took 4.615739703178406 seconds)
2022-03-06 13:58:53 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 13:58:53 | INFO | train | epoch 014 | loss 8.432 | nll_loss 7.912 | ppl 240.82 | wps 21902.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1346 | lr 0.000168316 | gnorm 0.919 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 4045
2022-03-06 13:58:53 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 13:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:01:27 | INFO | train_inner | epoch 015:     54 / 97 loss=8.354, nll_loss=7.828, ppl=227.25, wps=21953.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1400, lr=0.000175065, gnorm=0.935, loss_scale=32, train_wall=265, gb_free=8.1, wall=4199
2022-03-06 14:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:03:35 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.52 | nll_loss 7.994 | ppl 254.94 | wps 42552.8 | wpb 510.9 | bsz 1 | num_updates 1443 | best_loss 8.52
2022-03-06 14:03:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1443 updates
2022-03-06 14:03:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:03:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:03:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 15 @ 1443 updates, score 8.52) (writing took 4.648751968983561 seconds)
2022-03-06 14:03:40 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 14:03:40 | INFO | train | epoch 015 | loss 8.277 | nll_loss 7.746 | ppl 214.68 | wps 22140.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1443 | lr 0.000180439 | gnorm 0.916 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 4332
2022-03-06 14:03:40 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 14:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:05:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:06:26 | INFO | train_inner | epoch 016:     58 / 97 loss=8.185, nll_loss=7.648, ppl=200.57, wps=21962.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1500, lr=0.000187563, gnorm=0.906, loss_scale=32, train_wall=265, gb_free=8.1, wall=4497
2022-03-06 14:08:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:08:22 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.424 | nll_loss 7.886 | ppl 236.61 | wps 42555.9 | wpb 510.9 | bsz 1 | num_updates 1539 | best_loss 8.424
2022-03-06 14:08:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1539 updates
2022-03-06 14:08:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:08:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 16 @ 1539 updates, score 8.424) (writing took 4.645122290123254 seconds)
2022-03-06 14:08:27 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 14:08:27 | INFO | train | epoch 016 | loss 8.123 | nll_loss 7.582 | ppl 191.61 | wps 21925.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1539 | lr 0.000192437 | gnorm 0.918 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 4619
2022-03-06 14:08:27 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 14:08:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:11:21 | INFO | train_inner | epoch 017:     61 / 97 loss=8.027, nll_loss=7.48, ppl=178.48, wps=22144, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1600, lr=0.00020006, gnorm=0.94, loss_scale=32, train_wall=263, gb_free=8.1, wall=4793
2022-03-06 14:12:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:13:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:13:09 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.343 | nll_loss 7.801 | ppl 223.07 | wps 42664 | wpb 510.9 | bsz 1 | num_updates 1635 | best_loss 8.343
2022-03-06 14:13:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1635 updates
2022-03-06 14:13:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:13:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:13:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 17 @ 1635 updates, score 8.343) (writing took 4.825283667072654 seconds)
2022-03-06 14:13:14 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 14:13:14 | INFO | train | epoch 017 | loss 7.974 | nll_loss 7.423 | ppl 171.58 | wps 21871.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1635 | lr 0.000204434 | gnorm 0.944 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 4906
2022-03-06 14:13:14 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 14:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:16:20 | INFO | train_inner | epoch 018:     65 / 97 loss=7.876, nll_loss=7.319, ppl=159.68, wps=21919.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=1700, lr=0.000212558, gnorm=0.924, loss_scale=32, train_wall=266, gb_free=8.1, wall=5092
2022-03-06 14:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:17:57 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.263 | nll_loss 7.705 | ppl 208.66 | wps 42549 | wpb 510.9 | bsz 1 | num_updates 1732 | best_loss 8.263
2022-03-06 14:17:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1732 updates
2022-03-06 14:17:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:17:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:18:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 18 @ 1732 updates, score 8.263) (writing took 4.58827504189685 seconds)
2022-03-06 14:18:01 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 14:18:01 | INFO | train | epoch 018 | loss 7.826 | nll_loss 7.265 | ppl 153.85 | wps 22125.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1732 | lr 0.000216557 | gnorm 0.914 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 5193
2022-03-06 14:18:01 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 14:18:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:19:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:21:19 | INFO | train_inner | epoch 019:     69 / 97 loss=7.729, nll_loss=7.161, ppl=143.16, wps=21936.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=1800, lr=0.000225055, gnorm=0.909, loss_scale=32, train_wall=266, gb_free=8.1, wall=5391
2022-03-06 14:22:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:22:44 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.203 | nll_loss 7.644 | ppl 199.99 | wps 42709.8 | wpb 510.9 | bsz 1 | num_updates 1828 | best_loss 8.203
2022-03-06 14:22:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1828 updates
2022-03-06 14:22:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:22:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:22:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 19 @ 1828 updates, score 8.203) (writing took 4.622646077070385 seconds)
2022-03-06 14:22:48 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 14:22:48 | INFO | train | epoch 019 | loss 7.683 | nll_loss 7.112 | ppl 138.34 | wps 21901 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1828 | lr 0.000228554 | gnorm 0.936 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 5480
2022-03-06 14:22:48 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 14:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:25:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:26:17 | INFO | train_inner | epoch 020:     73 / 97 loss=7.581, nll_loss=7.004, ppl=128.34, wps=21943.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=1900, lr=0.000237553, gnorm=0.944, loss_scale=32, train_wall=266, gb_free=8.1, wall=5689
2022-03-06 14:27:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:27:31 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.141 | nll_loss 7.57 | ppl 190.02 | wps 42781.5 | wpb 510.9 | bsz 1 | num_updates 1924 | best_loss 8.141
2022-03-06 14:27:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 1924 updates
2022-03-06 14:27:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:27:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:27:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 20 @ 1924 updates, score 8.141) (writing took 4.618982286192477 seconds)
2022-03-06 14:27:35 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 14:27:35 | INFO | train | epoch 020 | loss 7.542 | nll_loss 6.962 | ppl 124.65 | wps 21903.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1924 | lr 0.000240552 | gnorm 0.924 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 5767
2022-03-06 14:27:35 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 14:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:31:13 | INFO | train_inner | epoch 021:     76 / 97 loss=7.435, nll_loss=6.848, ppl=115.2, wps=22165.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=2000, lr=0.00025005, gnorm=0.906, loss_scale=32, train_wall=263, gb_free=8.1, wall=5984
2022-03-06 14:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:32:18 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.097 | nll_loss 7.53 | ppl 184.82 | wps 42591.3 | wpb 510.9 | bsz 1 | num_updates 2021 | best_loss 8.097
2022-03-06 14:32:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2021 updates
2022-03-06 14:32:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:32:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:32:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 21 @ 2021 updates, score 8.097) (writing took 4.600951688364148 seconds)
2022-03-06 14:32:22 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 14:32:22 | INFO | train | epoch 021 | loss 7.404 | nll_loss 6.815 | ppl 112.56 | wps 22144.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2021 | lr 0.000252674 | gnorm 0.912 | loss_scale 64 | train_wall 255 | gb_free 8.1 | wall 6054
2022-03-06 14:32:22 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 14:32:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:32:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:36:11 | INFO | train_inner | epoch 022:     80 / 97 loss=7.302, nll_loss=6.706, ppl=104.38, wps=21955.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2100, lr=0.000262548, gnorm=0.945, loss_scale=32, train_wall=265, gb_free=8.1, wall=6283
2022-03-06 14:36:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:37:05 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.024 | nll_loss 7.445 | ppl 174.29 | wps 42607.2 | wpb 510.9 | bsz 1 | num_updates 2117 | best_loss 8.024
2022-03-06 14:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2117 updates
2022-03-06 14:37:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:37:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:37:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 22 @ 2117 updates, score 8.024) (writing took 4.5808892310597 seconds)
2022-03-06 14:37:09 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 14:37:09 | INFO | train | epoch 022 | loss 7.272 | nll_loss 6.673 | ppl 102.07 | wps 21911.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 2117 | lr 0.000264672 | gnorm 0.946 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 6341
2022-03-06 14:37:09 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 14:37:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:39:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:41:09 | INFO | train_inner | epoch 023:     84 / 97 loss=7.163, nll_loss=6.556, ppl=94.11, wps=21940.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2200, lr=0.000275045, gnorm=0.925, loss_scale=32, train_wall=266, gb_free=8.1, wall=6581
2022-03-06 14:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:41:52 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.013 | nll_loss 7.436 | ppl 173.14 | wps 42637.5 | wpb 510.9 | bsz 1 | num_updates 2213 | best_loss 8.013
2022-03-06 14:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2213 updates
2022-03-06 14:41:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:41:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:41:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 23 @ 2213 updates, score 8.013) (writing took 4.781329253222793 seconds)
2022-03-06 14:41:56 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 14:41:56 | INFO | train | epoch 023 | loss 7.142 | nll_loss 6.534 | ppl 92.68 | wps 21887.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 2213 | lr 0.00027667 | gnorm 0.908 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 6628
2022-03-06 14:41:56 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 14:41:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:46:05 | INFO | train_inner | epoch 024:     87 / 97 loss=7.036, nll_loss=6.421, ppl=85.67, wps=22121.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2300, lr=0.000287543, gnorm=0.91, loss_scale=64, train_wall=263, gb_free=8.1, wall=6877
2022-03-06 14:46:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:46:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:46:39 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.003 | nll_loss 7.406 | ppl 169.57 | wps 42484 | wpb 510.9 | bsz 1 | num_updates 2309 | best_loss 8.003
2022-03-06 14:46:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2309 updates
2022-03-06 14:46:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:46:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:46:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 24 @ 2309 updates, score 8.003) (writing took 4.5855756108649075 seconds)
2022-03-06 14:46:44 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 14:46:44 | INFO | train | epoch 024 | loss 7.018 | nll_loss 6.402 | ppl 84.54 | wps 21900 | ups 0.33 | wpb 65533.8 | bsz 128 | num_updates 2309 | lr 0.000288667 | gnorm 0.93 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 6916
2022-03-06 14:46:44 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 14:46:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:51:04 | INFO | train_inner | epoch 025:     91 / 97 loss=6.903, nll_loss=6.277, ppl=77.57, wps=21928.5, ups=0.33, wpb=65533.9, bsz=128, num_updates=2400, lr=0.00030004, gnorm=0.944, loss_scale=32, train_wall=266, gb_free=8.1, wall=7176
2022-03-06 14:51:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:51:26 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.003 | nll_loss 7.417 | ppl 170.85 | wps 42723 | wpb 510.9 | bsz 1 | num_updates 2406 | best_loss 8.003
2022-03-06 14:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2406 updates
2022-03-06 14:51:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:51:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 25 @ 2406 updates, score 8.003) (writing took 4.664243021979928 seconds)
2022-03-06 14:51:31 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 14:51:31 | INFO | train | epoch 025 | loss 6.897 | nll_loss 6.271 | ppl 77.23 | wps 22101.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2406 | lr 0.00030079 | gnorm 0.94 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 7203
2022-03-06 14:51:31 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 14:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:53:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:56:03 | INFO | train_inner | epoch 026:     95 / 97 loss=6.785, nll_loss=6.151, ppl=71.07, wps=21955.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2500, lr=0.000312538, gnorm=0.93, loss_scale=32, train_wall=265, gb_free=8.1, wall=7475
2022-03-06 14:56:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:56:13 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.984 | nll_loss 7.4 | ppl 168.85 | wps 42544.9 | wpb 510.9 | bsz 1 | num_updates 2502 | best_loss 7.984
2022-03-06 14:56:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2502 updates
2022-03-06 14:56:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:56:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:56:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 26 @ 2502 updates, score 7.984) (writing took 4.584292551036924 seconds)
2022-03-06 14:56:18 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 14:56:18 | INFO | train | epoch 026 | loss 6.777 | nll_loss 6.142 | ppl 70.64 | wps 21923 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 2502 | lr 0.000312787 | gnorm 0.928 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 7490
2022-03-06 14:56:18 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 14:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:59:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:01:00 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.003 | nll_loss 7.418 | ppl 171.01 | wps 42771.8 | wpb 510.9 | bsz 1 | num_updates 2598 | best_loss 7.984
2022-03-06 15:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2598 updates
2022-03-06 15:01:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 27 @ 2598 updates, score 8.003) (writing took 2.130349474027753 seconds)
2022-03-06 15:01:02 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 15:01:02 | INFO | train | epoch 027 | loss 6.663 | nll_loss 6.02 | ppl 64.9 | wps 22112.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2598 | lr 0.000324785 | gnorm 0.951 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 7774
2022-03-06 15:01:02 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 15:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:01:08 | INFO | train_inner | epoch 028:      2 / 97 loss=6.664, nll_loss=6.021, ppl=64.94, wps=21428.1, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=2600, lr=0.000325035, gnorm=0.947, loss_scale=32, train_wall=265, gb_free=8.1, wall=7780
2022-03-06 15:04:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:05:44 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.981 | nll_loss 7.394 | ppl 168.2 | wps 42574.2 | wpb 510.9 | bsz 1 | num_updates 2694 | best_loss 7.981
2022-03-06 15:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2694 updates
2022-03-06 15:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:05:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 28 @ 2694 updates, score 7.981) (writing took 4.74141481006518 seconds)
2022-03-06 15:05:49 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 15:05:49 | INFO | train | epoch 028 | loss 6.551 | nll_loss 5.9 | ppl 59.73 | wps 21904.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 2694 | lr 0.000336783 | gnorm 0.964 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 8061
2022-03-06 15:05:49 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 15:05:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:06:07 | INFO | train_inner | epoch 029:      6 / 97 loss=6.543, nll_loss=5.891, ppl=59.36, wps=21943, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2700, lr=0.000337533, gnorm=0.961, loss_scale=16, train_wall=265, gb_free=8.1, wall=8078
2022-03-06 15:10:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:10:32 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.03 | nll_loss 7.439 | ppl 173.54 | wps 42519.5 | wpb 510.9 | bsz 1 | num_updates 2791 | best_loss 7.981
2022-03-06 15:10:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2791 updates
2022-03-06 15:10:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:10:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:10:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 29 @ 2791 updates, score 8.03) (writing took 2.242053432855755 seconds)
2022-03-06 15:10:34 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 15:10:34 | INFO | train | epoch 029 | loss 6.44 | nll_loss 5.78 | ppl 54.96 | wps 22299.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2791 | lr 0.000348905 | gnorm 0.942 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 8346
2022-03-06 15:10:34 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 15:10:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:11:00 | INFO | train_inner | epoch 030:      9 / 97 loss=6.429, nll_loss=5.769, ppl=54.52, wps=22319.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2800, lr=0.00035003, gnorm=0.952, loss_scale=32, train_wall=263, gb_free=8.1, wall=8372
2022-03-06 15:15:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:15:17 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.073 | nll_loss 7.483 | ppl 178.86 | wps 42533.5 | wpb 510.9 | bsz 1 | num_updates 2888 | best_loss 7.981
2022-03-06 15:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 2888 updates
2022-03-06 15:15:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:15:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:15:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 30 @ 2888 updates, score 8.073) (writing took 2.262410794850439 seconds)
2022-03-06 15:15:19 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 15:15:19 | INFO | train | epoch 030 | loss 6.334 | nll_loss 5.666 | ppl 50.76 | wps 22308.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2888 | lr 0.000361028 | gnorm 0.986 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 8631
2022-03-06 15:15:19 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 15:15:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:15:53 | INFO | train_inner | epoch 031:     12 / 97 loss=6.317, nll_loss=5.648, ppl=50.15, wps=22324.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2900, lr=0.000362528, gnorm=0.976, loss_scale=32, train_wall=263, gb_free=8.1, wall=8665
2022-03-06 15:17:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:20:01 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.104 | nll_loss 7.517 | ppl 183.14 | wps 42637.4 | wpb 510.9 | bsz 1 | num_updates 2984 | best_loss 7.981
2022-03-06 15:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 2984 updates
2022-03-06 15:20:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 31 @ 2984 updates, score 8.104) (writing took 2.2666518767364323 seconds)
2022-03-06 15:20:04 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 15:20:04 | INFO | train | epoch 031 | loss 6.226 | nll_loss 5.55 | ppl 46.85 | wps 22079.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2984 | lr 0.000373025 | gnorm 0.973 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 8916
2022-03-06 15:20:04 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 15:20:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:20:49 | INFO | train_inner | epoch 032:     16 / 97 loss=6.211, nll_loss=5.534, ppl=46.32, wps=22113.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3000, lr=0.000375025, gnorm=0.988, loss_scale=32, train_wall=266, gb_free=8.1, wall=8961
2022-03-06 15:21:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:24:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:24:46 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.139 | nll_loss 7.547 | ppl 186.95 | wps 42267.6 | wpb 510.9 | bsz 1 | num_updates 3080 | best_loss 7.981
2022-03-06 15:24:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3080 updates
2022-03-06 15:24:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:24:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:24:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 32 @ 3080 updates, score 8.139) (writing took 2.189682825934142 seconds)
2022-03-06 15:24:48 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 15:24:48 | INFO | train | epoch 032 | loss 6.119 | nll_loss 5.435 | ppl 43.26 | wps 22088.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3080 | lr 0.000385023 | gnorm 0.988 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 9200
2022-03-06 15:24:48 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 15:24:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:25:46 | INFO | train_inner | epoch 033:     20 / 97 loss=6.097, nll_loss=5.411, ppl=42.55, wps=22115.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3100, lr=0.000387523, gnorm=0.979, loss_scale=16, train_wall=266, gb_free=8.1, wall=9258
2022-03-06 15:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:29:31 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.193 | nll_loss 7.603 | ppl 194.41 | wps 42683.6 | wpb 510.9 | bsz 1 | num_updates 3177 | best_loss 7.981
2022-03-06 15:29:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3177 updates
2022-03-06 15:29:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:29:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:29:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 33 @ 3177 updates, score 8.193) (writing took 2.1606822898611426 seconds)
2022-03-06 15:29:33 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 15:29:33 | INFO | train | epoch 033 | loss 6.023 | nll_loss 5.331 | ppl 40.26 | wps 22319.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3177 | lr 0.000397146 | gnorm 1.02 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 9485
2022-03-06 15:29:33 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 15:29:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:30:39 | INFO | train_inner | epoch 034:     23 / 97 loss=5.996, nll_loss=5.302, ppl=39.44, wps=22344.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3200, lr=0.00040002, gnorm=1.011, loss_scale=32, train_wall=263, gb_free=8.1, wall=9551
2022-03-06 15:34:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:34:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:34:15 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.212 | nll_loss 7.616 | ppl 196.16 | wps 42641.5 | wpb 510.9 | bsz 1 | num_updates 3273 | best_loss 7.981
2022-03-06 15:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3273 updates
2022-03-06 15:34:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:34:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:34:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 34 @ 3273 updates, score 8.212) (writing took 2.150724089704454 seconds)
2022-03-06 15:34:17 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 15:34:17 | INFO | train | epoch 034 | loss 5.918 | nll_loss 5.217 | ppl 37.2 | wps 22108.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3273 | lr 0.000409143 | gnorm 1.032 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 9769
2022-03-06 15:34:17 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 15:34:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:35:35 | INFO | train_inner | epoch 035:     27 / 97 loss=5.885, nll_loss=5.182, ppl=36.31, wps=22136, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3300, lr=0.000412518, gnorm=1.019, loss_scale=16, train_wall=265, gb_free=8.1, wall=9847
2022-03-06 15:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:39:00 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.237 | nll_loss 7.635 | ppl 198.79 | wps 42417.2 | wpb 510.9 | bsz 1 | num_updates 3370 | best_loss 7.981
2022-03-06 15:39:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3370 updates
2022-03-06 15:39:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:39:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:39:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 35 @ 3370 updates, score 8.237) (writing took 2.1689134277403355 seconds)
2022-03-06 15:39:02 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 15:39:02 | INFO | train | epoch 035 | loss 5.818 | nll_loss 5.11 | ppl 34.53 | wps 22308.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3370 | lr 0.000421266 | gnorm 0.992 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 10054
2022-03-06 15:39:02 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 15:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:40:28 | INFO | train_inner | epoch 036:     30 / 97 loss=5.793, nll_loss=5.083, ppl=33.89, wps=22326.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3400, lr=0.000425015, gnorm=1.037, loss_scale=32, train_wall=263, gb_free=8.1, wall=10140
2022-03-06 15:43:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:43:45 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.286 | nll_loss 7.691 | ppl 206.61 | wps 42396.6 | wpb 510.9 | bsz 1 | num_updates 3467 | best_loss 7.981
2022-03-06 15:43:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3467 updates
2022-03-06 15:43:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:43:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:43:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 36 @ 3467 updates, score 8.286) (writing took 2.1439219978637993 seconds)
2022-03-06 15:43:47 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 15:43:47 | INFO | train | epoch 036 | loss 5.72 | nll_loss 5.003 | ppl 32.07 | wps 22310.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3467 | lr 0.000433388 | gnorm 1.032 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 10339
2022-03-06 15:43:47 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 15:43:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:45:21 | INFO | train_inner | epoch 037:     33 / 97 loss=5.687, nll_loss=4.968, ppl=31.29, wps=22322.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3500, lr=0.000437513, gnorm=1.041, loss_scale=32, train_wall=263, gb_free=8.1, wall=10433
2022-03-06 15:45:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:48:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:48:29 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.337 | nll_loss 7.728 | ppl 211.95 | wps 42767.5 | wpb 510.9 | bsz 1 | num_updates 3563 | best_loss 7.981
2022-03-06 15:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3563 updates
2022-03-06 15:48:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:48:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:48:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 37 @ 3563 updates, score 8.337) (writing took 2.1425161226652563 seconds)
2022-03-06 15:48:32 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 15:48:32 | INFO | train | epoch 037 | loss 5.621 | nll_loss 4.897 | ppl 29.79 | wps 22079.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3563 | lr 0.000445386 | gnorm 1.043 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 10623
2022-03-06 15:48:32 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 15:48:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:50:17 | INFO | train_inner | epoch 038:     37 / 97 loss=5.585, nll_loss=4.858, ppl=29, wps=22120.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3600, lr=0.00045001, gnorm=1.062, loss_scale=16, train_wall=266, gb_free=8.1, wall=10729
2022-03-06 15:53:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:53:14 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.374 | nll_loss 7.754 | ppl 215.87 | wps 42747.3 | wpb 510.9 | bsz 1 | num_updates 3660 | best_loss 7.981
2022-03-06 15:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3660 updates
2022-03-06 15:53:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:53:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:53:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 38 @ 3660 updates, score 8.374) (writing took 2.1429145741276443 seconds)
2022-03-06 15:53:16 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 15:53:16 | INFO | train | epoch 038 | loss 5.529 | nll_loss 4.796 | ppl 27.78 | wps 22326.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3660 | lr 0.000457509 | gnorm 1.069 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 10908
2022-03-06 15:53:16 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 15:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:53:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:55:13 | INFO | train_inner | epoch 039:     41 / 97 loss=5.49, nll_loss=4.754, ppl=26.99, wps=22134.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=3700, lr=0.000462508, gnorm=1.061, loss_scale=16, train_wall=265, gb_free=8.1, wall=11025
2022-03-06 15:57:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:57:58 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.384 | nll_loss 7.765 | ppl 217.46 | wps 42484.4 | wpb 510.9 | bsz 1 | num_updates 3756 | best_loss 7.981
2022-03-06 15:57:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 3756 updates
2022-03-06 15:57:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:58:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:58:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 39 @ 3756 updates, score 8.384) (writing took 2.2010111599229276 seconds)
2022-03-06 15:58:01 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 15:58:01 | INFO | train | epoch 039 | loss 5.433 | nll_loss 4.692 | ppl 25.86 | wps 22088.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3756 | lr 0.000469506 | gnorm 1.098 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 11193
2022-03-06 15:58:01 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 15:58:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:00:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:00:09 | INFO | train_inner | epoch 040:     45 / 97 loss=5.385, nll_loss=4.64, ppl=24.94, wps=22123.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3800, lr=0.000475005, gnorm=1.077, loss_scale=16, train_wall=265, gb_free=8.1, wall=11321
2022-03-06 16:02:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:02:43 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.457 | nll_loss 7.848 | ppl 230.41 | wps 42735.2 | wpb 510.9 | bsz 1 | num_updates 3852 | best_loss 7.981
2022-03-06 16:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 3852 updates
2022-03-06 16:02:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:02:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 40 @ 3852 updates, score 8.457) (writing took 2.220289102755487 seconds)
2022-03-06 16:02:45 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 16:02:45 | INFO | train | epoch 040 | loss 5.339 | nll_loss 4.59 | ppl 24.09 | wps 22091.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3852 | lr 0.000481504 | gnorm 1.041 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 11477
2022-03-06 16:02:45 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 16:02:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:05:03 | INFO | train_inner | epoch 041:     48 / 97 loss=5.299, nll_loss=4.546, ppl=23.37, wps=22322.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3900, lr=0.000487503, gnorm=1.067, loss_scale=16, train_wall=263, gb_free=8.1, wall=11615
2022-03-06 16:06:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:07:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:07:28 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.505 | nll_loss 7.892 | ppl 237.49 | wps 42319.6 | wpb 510.9 | bsz 1 | num_updates 3948 | best_loss 7.981
2022-03-06 16:07:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 3948 updates
2022-03-06 16:07:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:07:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:07:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 41 @ 3948 updates, score 8.505) (writing took 2.1188664259389043 seconds)
2022-03-06 16:07:30 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 16:07:30 | INFO | train | epoch 041 | loss 5.252 | nll_loss 4.495 | ppl 22.55 | wps 22076.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3948 | lr 0.000493501 | gnorm 1.125 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 11762
2022-03-06 16:07:30 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 16:07:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:09:59 | INFO | train_inner | epoch 042:     52 / 97 loss=5.202, nll_loss=4.441, ppl=21.72, wps=22105.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=4000, lr=0.0005, gnorm=1.107, loss_scale=16, train_wall=266, gb_free=8.1, wall=11911
2022-03-06 16:12:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:12:13 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.603 | nll_loss 7.975 | ppl 251.67 | wps 42752.3 | wpb 510.9 | bsz 1 | num_updates 4045 | best_loss 7.981
2022-03-06 16:12:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4045 updates
2022-03-06 16:12:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:12:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:12:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 42 @ 4045 updates, score 8.603) (writing took 2.1766962315887213 seconds)
2022-03-06 16:12:15 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 16:12:15 | INFO | train | epoch 042 | loss 5.159 | nll_loss 4.394 | ppl 21.03 | wps 22304.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4045 | lr 0.000497211 | gnorm 1.1 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 12047
2022-03-06 16:12:15 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 16:12:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:13:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:14:55 | INFO | train_inner | epoch 043:     56 / 97 loss=5.103, nll_loss=4.334, ppl=20.16, wps=22109.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4100, lr=0.000493865, gnorm=1.086, loss_scale=16, train_wall=266, gb_free=8.1, wall=12207
2022-03-06 16:16:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:16:58 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.616 | nll_loss 8 | ppl 256.08 | wps 42501.2 | wpb 510.9 | bsz 1 | num_updates 4141 | best_loss 7.981
2022-03-06 16:16:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4141 updates
2022-03-06 16:16:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:17:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:17:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 43 @ 4141 updates, score 8.616) (writing took 2.1112635107710958 seconds)
2022-03-06 16:17:00 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 16:17:00 | INFO | train | epoch 043 | loss 5.063 | nll_loss 4.29 | ppl 19.56 | wps 22071.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4141 | lr 0.000491414 | gnorm 1.079 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 12332
2022-03-06 16:17:00 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 16:17:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:19:48 | INFO | train_inner | epoch 044:     59 / 97 loss=5.008, nll_loss=4.23, ppl=18.77, wps=22337.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=4200, lr=0.00048795, gnorm=1.094, loss_scale=32, train_wall=263, gb_free=8.1, wall=12500
2022-03-06 16:20:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:21:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:21:42 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.693 | nll_loss 8.065 | ppl 267.73 | wps 42583 | wpb 510.9 | bsz 1 | num_updates 4237 | best_loss 7.981
2022-03-06 16:21:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4237 updates
2022-03-06 16:21:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:21:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 44 @ 4237 updates, score 8.693) (writing took 2.1404533060267568 seconds)
2022-03-06 16:21:44 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 16:21:44 | INFO | train | epoch 044 | loss 4.966 | nll_loss 4.184 | ppl 18.18 | wps 22105 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4237 | lr 0.000485815 | gnorm 1.072 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 12616
2022-03-06 16:21:44 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 16:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:24:44 | INFO | train_inner | epoch 045:     63 / 97 loss=4.91, nll_loss=4.123, ppl=17.43, wps=22130.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=4300, lr=0.000482243, gnorm=1.044, loss_scale=16, train_wall=265, gb_free=8.1, wall=12796
2022-03-06 16:26:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:26:27 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.787 | nll_loss 8.168 | ppl 287.65 | wps 42798.6 | wpb 510.9 | bsz 1 | num_updates 4334 | best_loss 7.981
2022-03-06 16:26:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4334 updates
2022-03-06 16:26:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:26:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:26:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 45 @ 4334 updates, score 8.787) (writing took 2.1259530521929264 seconds)
2022-03-06 16:26:29 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 16:26:29 | INFO | train | epoch 045 | loss 4.876 | nll_loss 4.086 | ppl 16.98 | wps 22328.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4334 | lr 0.000480348 | gnorm 1.064 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 12901
2022-03-06 16:26:29 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 16:26:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:27:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:29:40 | INFO | train_inner | epoch 046:     67 / 97 loss=4.817, nll_loss=4.022, ppl=16.25, wps=22126.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=4400, lr=0.000476731, gnorm=1.077, loss_scale=16, train_wall=266, gb_free=8.1, wall=13092
2022-03-06 16:31:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:31:11 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.889 | nll_loss 8.266 | ppl 307.81 | wps 42728 | wpb 510.9 | bsz 1 | num_updates 4430 | best_loss 7.981
2022-03-06 16:31:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4430 updates
2022-03-06 16:31:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:31:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 46 @ 4430 updates, score 8.889) (writing took 2.1646009320393205 seconds)
2022-03-06 16:31:13 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 16:31:13 | INFO | train | epoch 046 | loss 4.786 | nll_loss 3.988 | ppl 15.87 | wps 22086.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4430 | lr 0.000475114 | gnorm 1.072 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 13185
2022-03-06 16:31:13 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 16:31:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:34:34 | INFO | train_inner | epoch 047:     70 / 97 loss=4.726, nll_loss=3.923, ppl=15.16, wps=22341.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4500, lr=0.000471405, gnorm=1.051, loss_scale=32, train_wall=263, gb_free=8.1, wall=13385
2022-03-06 16:34:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:35:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:35:56 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.968 | nll_loss 8.357 | ppl 327.77 | wps 42586.3 | wpb 510.9 | bsz 1 | num_updates 4526 | best_loss 7.981
2022-03-06 16:35:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4526 updates
2022-03-06 16:35:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:35:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:35:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 47 @ 4526 updates, score 8.968) (writing took 2.173339560162276 seconds)
2022-03-06 16:35:58 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 16:35:58 | INFO | train | epoch 047 | loss 4.697 | nll_loss 3.892 | ppl 14.84 | wps 22091 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4526 | lr 0.000470049 | gnorm 1.05 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 13470
2022-03-06 16:35:58 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 16:35:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:39:30 | INFO | train_inner | epoch 048:     74 / 97 loss=4.64, nll_loss=3.829, ppl=14.21, wps=22115.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4600, lr=0.000466252, gnorm=1.064, loss_scale=16, train_wall=266, gb_free=8.1, wall=13682
2022-03-06 16:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:40:40 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.045 | nll_loss 8.421 | ppl 342.74 | wps 42388.3 | wpb 510.9 | bsz 1 | num_updates 4623 | best_loss 7.981
2022-03-06 16:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4623 updates
2022-03-06 16:40:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:40:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:40:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 48 @ 4623 updates, score 9.045) (writing took 2.1857345402240753 seconds)
2022-03-06 16:40:43 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 16:40:43 | INFO | train | epoch 048 | loss 4.615 | nll_loss 3.802 | ppl 13.95 | wps 22312.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4623 | lr 0.000465091 | gnorm 1.039 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 13755
2022-03-06 16:40:43 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 16:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:41:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:44:26 | INFO | train_inner | epoch 049:     78 / 97 loss=4.552, nll_loss=3.734, ppl=13.3, wps=22094.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4700, lr=0.000461266, gnorm=1.06, loss_scale=16, train_wall=266, gb_free=8.1, wall=13978
2022-03-06 16:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:45:25 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.111 | nll_loss 8.482 | ppl 357.64 | wps 42335.1 | wpb 510.9 | bsz 1 | num_updates 4719 | best_loss 7.981
2022-03-06 16:45:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 4719 updates
2022-03-06 16:45:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:45:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:45:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 49 @ 4719 updates, score 9.111) (writing took 2.140747453086078 seconds)
2022-03-06 16:45:28 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 16:45:28 | INFO | train | epoch 049 | loss 4.533 | nll_loss 3.713 | ppl 13.11 | wps 22061 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4719 | lr 0.000460336 | gnorm 1.075 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 14040
2022-03-06 16:45:28 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 16:45:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:49:19 | INFO | train_inner | epoch 050:     81 / 97 loss=4.47, nll_loss=3.644, ppl=12.5, wps=22323.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=4800, lr=0.000456435, gnorm=1.051, loss_scale=32, train_wall=263, gb_free=8.1, wall=14271
2022-03-06 16:50:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:50:10 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.163 | nll_loss 8.539 | ppl 371.96 | wps 42513.7 | wpb 510.9 | bsz 1 | num_updates 4816 | best_loss 7.981
2022-03-06 16:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 4816 updates
2022-03-06 16:50:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:50:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 50 @ 4816 updates, score 9.163) (writing took 2.186153559014201 seconds)
2022-03-06 16:50:12 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 16:50:12 | INFO | train | epoch 050 | loss 4.458 | nll_loss 3.63 | ppl 12.38 | wps 22311.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4816 | lr 0.000455677 | gnorm 1.046 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 14324
2022-03-06 16:50:12 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 16:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:50:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:54:16 | INFO | train_inner | epoch 051:     85 / 97 loss=4.4, nll_loss=3.567, ppl=11.85, wps=22120.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=4900, lr=0.000451754, gnorm=1.043, loss_scale=16, train_wall=266, gb_free=8.1, wall=14567
2022-03-06 16:54:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:54:55 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.276 | nll_loss 8.658 | ppl 403.95 | wps 42759.2 | wpb 510.9 | bsz 1 | num_updates 4912 | best_loss 7.981
2022-03-06 16:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 4912 updates
2022-03-06 16:54:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:54:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:54:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 51 @ 4912 updates, score 9.276) (writing took 2.232653066981584 seconds)
2022-03-06 16:54:57 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 16:54:57 | INFO | train | epoch 051 | loss 4.38 | nll_loss 3.546 | ppl 11.68 | wps 22087.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4912 | lr 0.000451202 | gnorm 1.037 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 14609
2022-03-06 16:54:57 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 16:54:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:58:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:59:12 | INFO | train_inner | epoch 052:     89 / 97 loss=4.321, nll_loss=3.48, ppl=11.16, wps=22120.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5000, lr=0.000447214, gnorm=1.063, loss_scale=16, train_wall=266, gb_free=8.1, wall=14864
2022-03-06 16:59:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:59:39 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.338 | nll_loss 8.716 | ppl 420.58 | wps 42773.1 | wpb 510.9 | bsz 1 | num_updates 5008 | best_loss 7.981
2022-03-06 16:59:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5008 updates
2022-03-06 16:59:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:59:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:59:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 52 @ 5008 updates, score 9.338) (writing took 2.371479450725019 seconds)
2022-03-06 16:59:42 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 16:59:42 | INFO | train | epoch 052 | loss 4.311 | nll_loss 3.469 | ppl 11.08 | wps 22074.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5008 | lr 0.000446856 | gnorm 1.073 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 14894
2022-03-06 16:59:42 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 16:59:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:04:05 | INFO | train_inner | epoch 053:     92 / 97 loss=4.249, nll_loss=3.402, ppl=10.57, wps=22318.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5100, lr=0.000442807, gnorm=1.044, loss_scale=16, train_wall=263, gb_free=8.1, wall=15157
2022-03-06 17:04:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:04:24 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.405 | nll_loss 8.783 | ppl 440.62 | wps 42657.5 | wpb 510.9 | bsz 1 | num_updates 5105 | best_loss 7.981
2022-03-06 17:04:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5105 updates
2022-03-06 17:04:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:04:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:04:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 53 @ 5105 updates, score 9.405) (writing took 2.3387974719516933 seconds)
2022-03-06 17:04:27 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 17:04:27 | INFO | train | epoch 053 | loss 4.242 | nll_loss 3.394 | ppl 10.51 | wps 22302.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5105 | lr 0.000442591 | gnorm 1.038 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 15179
2022-03-06 17:04:27 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 17:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:05:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:09:02 | INFO | train_inner | epoch 054:     96 / 97 loss=4.18, nll_loss=3.326, ppl=10.03, wps=22092.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5200, lr=0.000438529, gnorm=1.061, loss_scale=16, train_wall=266, gb_free=8.1, wall=15453
2022-03-06 17:09:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:09:09 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.537 | nll_loss 8.91 | ppl 480.94 | wps 42229.3 | wpb 510.9 | bsz 1 | num_updates 5201 | best_loss 7.981
2022-03-06 17:09:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5201 updates
2022-03-06 17:09:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:09:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:09:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 54 @ 5201 updates, score 9.537) (writing took 2.321652851998806 seconds)
2022-03-06 17:09:12 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 17:09:12 | INFO | train | epoch 054 | loss 4.173 | nll_loss 3.319 | ppl 9.98 | wps 22056 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5201 | lr 0.000438487 | gnorm 1.064 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 15464
2022-03-06 17:09:12 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 17:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:12:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:13:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:13:54 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.561 | nll_loss 8.931 | ppl 487.97 | wps 42564.7 | wpb 510.9 | bsz 1 | num_updates 5297 | best_loss 7.981
2022-03-06 17:13:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5297 updates
2022-03-06 17:13:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:13:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:13:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 55 @ 5297 updates, score 9.561) (writing took 2.331197409890592 seconds)
2022-03-06 17:13:57 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 17:13:57 | INFO | train | epoch 055 | loss 4.11 | nll_loss 3.249 | ppl 9.51 | wps 22064.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5297 | lr 0.000434495 | gnorm 1.048 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 15749
2022-03-06 17:13:57 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 17:13:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:14:05 | INFO | train_inner | epoch 056:      3 / 97 loss=4.106, nll_loss=3.245, ppl=9.48, wps=21541.4, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=5300, lr=0.000434372, gnorm=1.049, loss_scale=16, train_wall=265, gb_free=8.1, wall=15757
2022-03-06 17:18:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:18:39 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.678 | nll_loss 9.062 | ppl 534.51 | wps 42494.6 | wpb 510.9 | bsz 1 | num_updates 5394 | best_loss 7.981
2022-03-06 17:18:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5394 updates
2022-03-06 17:18:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:18:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 56 @ 5394 updates, score 9.678) (writing took 2.3258556267246604 seconds)
2022-03-06 17:18:42 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 17:18:42 | INFO | train | epoch 056 | loss 4.049 | nll_loss 3.182 | ppl 9.08 | wps 22283.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5394 | lr 0.000430571 | gnorm 1.057 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 16034
2022-03-06 17:18:42 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 17:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:18:59 | INFO | train_inner | epoch 057:      6 / 97 loss=4.044, nll_loss=3.177, ppl=9.04, wps=22300.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5400, lr=0.000430331, gnorm=1.053, loss_scale=32, train_wall=263, gb_free=8.1, wall=16051
2022-03-06 17:19:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:23:24 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.763 | nll_loss 9.142 | ppl 564.89 | wps 42777.7 | wpb 510.9 | bsz 1 | num_updates 5490 | best_loss 7.981
2022-03-06 17:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5490 updates
2022-03-06 17:23:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:23:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 57 @ 5490 updates, score 9.763) (writing took 2.3095679888501763 seconds)
2022-03-06 17:23:26 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 17:23:26 | INFO | train | epoch 057 | loss 3.988 | nll_loss 3.116 | ppl 8.67 | wps 22082.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5490 | lr 0.00042679 | gnorm 1.054 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 16318
2022-03-06 17:23:26 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 17:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:23:55 | INFO | train_inner | epoch 058:     10 / 97 loss=3.979, nll_loss=3.106, ppl=8.61, wps=22116.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5500, lr=0.000426401, gnorm=1.056, loss_scale=16, train_wall=265, gb_free=8.1, wall=16347
2022-03-06 17:26:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:28:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:28:09 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.806 | nll_loss 9.188 | ppl 583.42 | wps 42619.3 | wpb 510.9 | bsz 1 | num_updates 5586 | best_loss 7.981
2022-03-06 17:28:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5586 updates
2022-03-06 17:28:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:28:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:28:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 58 @ 5586 updates, score 9.806) (writing took 2.3703223378397524 seconds)
2022-03-06 17:28:11 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 17:28:11 | INFO | train | epoch 058 | loss 3.929 | nll_loss 3.051 | ppl 8.29 | wps 22070.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5586 | lr 0.000423106 | gnorm 1.066 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 16603
2022-03-06 17:28:11 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 17:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:28:52 | INFO | train_inner | epoch 059:     14 / 97 loss=3.921, nll_loss=3.042, ppl=8.24, wps=22099.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=5600, lr=0.000422577, gnorm=1.07, loss_scale=16, train_wall=266, gb_free=8.1, wall=16643
2022-03-06 17:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:32:54 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.892 | nll_loss 9.277 | ppl 620.53 | wps 42463.2 | wpb 510.9 | bsz 1 | num_updates 5683 | best_loss 7.981
2022-03-06 17:32:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 5683 updates
2022-03-06 17:32:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:32:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:32:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 59 @ 5683 updates, score 9.892) (writing took 2.4061957970261574 seconds)
2022-03-06 17:32:56 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 17:32:56 | INFO | train | epoch 059 | loss 3.875 | nll_loss 2.991 | ppl 7.95 | wps 22292.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5683 | lr 0.00041948 | gnorm 1.064 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 16888
2022-03-06 17:32:56 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 17:32:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:33:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:33:48 | INFO | train_inner | epoch 060:     18 / 97 loss=3.859, nll_loss=2.974, ppl=7.86, wps=22099.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=5700, lr=0.000418854, gnorm=1.061, loss_scale=16, train_wall=266, gb_free=8.1, wall=16940
2022-03-06 17:37:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:37:39 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.95 | nll_loss 9.328 | ppl 642.52 | wps 42816 | wpb 510.9 | bsz 1 | num_updates 5779 | best_loss 7.981
2022-03-06 17:37:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 5779 updates
2022-03-06 17:37:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:37:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 60 @ 5779 updates, score 9.95) (writing took 2.3020572112873197 seconds)
2022-03-06 17:37:41 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 17:37:41 | INFO | train | epoch 060 | loss 3.818 | nll_loss 2.929 | ppl 7.62 | wps 22069.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5779 | lr 0.000415981 | gnorm 1.056 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 17173
2022-03-06 17:37:41 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 17:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:38:41 | INFO | train_inner | epoch 061:     21 / 97 loss=3.81, nll_loss=2.92, ppl=7.57, wps=22312.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5800, lr=0.000415227, gnorm=1.052, loss_scale=16, train_wall=263, gb_free=8.1, wall=17233
2022-03-06 17:39:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:39:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:42:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:42:24 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 10.015 | nll_loss 9.396 | ppl 673.59 | wps 42165.7 | wpb 510.9 | bsz 1 | num_updates 5874 | best_loss 7.981
2022-03-06 17:42:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 5874 updates
2022-03-06 17:42:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:42:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 61 @ 5874 updates, score 10.015) (writing took 2.313216662965715 seconds)
2022-03-06 17:42:26 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 17:42:26 | INFO | train | epoch 061 | loss 3.766 | nll_loss 2.872 | ppl 7.32 | wps 21827.1 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 5874 | lr 0.000412604 | gnorm 1.053 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 17458
2022-03-06 17:42:26 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 17:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:43:41 | INFO | train_inner | epoch 062:     26 / 97 loss=3.745, nll_loss=2.849, ppl=7.21, wps=21875.1, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=5900, lr=0.000411693, gnorm=1.055, loss_scale=8, train_wall=268, gb_free=8.1, wall=17533
2022-03-06 17:47:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:47:09 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 10.21 | nll_loss 9.595 | ppl 773.55 | wps 42592.8 | wpb 510.9 | bsz 1 | num_updates 5971 | best_loss 7.981
2022-03-06 17:47:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 5971 updates
2022-03-06 17:47:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:47:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:47:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 62 @ 5971 updates, score 10.21) (writing took 2.3465448319911957 seconds)
2022-03-06 17:47:11 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 17:47:11 | INFO | train | epoch 062 | loss 3.719 | nll_loss 2.82 | ppl 7.06 | wps 22290.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5971 | lr 0.000409238 | gnorm 1.066 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 17743
2022-03-06 17:47:11 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 17:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:48:34 | INFO | train_inner | epoch 063:     29 / 97 loss=3.703, nll_loss=2.803, ppl=6.98, wps=22318.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=6000, lr=0.000408248, gnorm=1.059, loss_scale=16, train_wall=263, gb_free=8.1, wall=17826
2022-03-06 17:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:51:54 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 10.249 | nll_loss 9.637 | ppl 796.37 | wps 42809.5 | wpb 510.9 | bsz 1 | num_updates 6068 | best_loss 7.981
2022-03-06 17:51:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6068 updates
2022-03-06 17:51:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:51:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:51:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 63 @ 6068 updates, score 10.249) (writing took 2.3639050289057195 seconds)
2022-03-06 17:51:56 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 17:51:56 | INFO | train | epoch 063 | loss 3.67 | nll_loss 2.767 | ppl 6.81 | wps 22302.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6068 | lr 0.000405954 | gnorm 1.06 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 18028
2022-03-06 17:51:56 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 17:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:52:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:53:31 | INFO | train_inner | epoch 064:     33 / 97 loss=3.657, nll_loss=2.752, ppl=6.73, wps=22110.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6100, lr=0.000404888, gnorm=1.059, loss_scale=16, train_wall=266, gb_free=8.1, wall=18122
2022-03-06 17:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:56:39 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 10.27 | nll_loss 9.657 | ppl 807.26 | wps 42454.1 | wpb 510.9 | bsz 1 | num_updates 6164 | best_loss 7.981
2022-03-06 17:56:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6164 updates
2022-03-06 17:56:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:56:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:56:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 64 @ 6164 updates, score 10.27) (writing took 2.39741722214967 seconds)
2022-03-06 17:56:41 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 17:56:41 | INFO | train | epoch 064 | loss 3.623 | nll_loss 2.715 | ppl 6.57 | wps 22071 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6164 | lr 0.000402781 | gnorm 1.076 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 18313
2022-03-06 17:56:41 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 17:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:58:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:58:27 | INFO | train_inner | epoch 065:     37 / 97 loss=3.601, nll_loss=2.691, ppl=6.46, wps=22093.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6200, lr=0.00040161, gnorm=1.078, loss_scale=8, train_wall=266, gb_free=8.1, wall=18419
2022-03-06 18:01:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:01:24 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.406 | nll_loss 9.8 | ppl 891.46 | wps 42560.9 | wpb 510.9 | bsz 1 | num_updates 6260 | best_loss 7.981
2022-03-06 18:01:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6260 updates
2022-03-06 18:01:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 65 @ 6260 updates, score 10.406) (writing took 2.339622301980853 seconds)
2022-03-06 18:01:26 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 18:01:26 | INFO | train | epoch 065 | loss 3.576 | nll_loss 2.664 | ppl 6.34 | wps 22062.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6260 | lr 0.00039968 | gnorm 1.051 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 18598
2022-03-06 18:01:26 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 18:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:03:21 | INFO | train_inner | epoch 066:     40 / 97 loss=3.561, nll_loss=2.647, ppl=6.27, wps=22306.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=6300, lr=0.00039841, gnorm=1.047, loss_scale=8, train_wall=263, gb_free=8.1, wall=18712
2022-03-06 18:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:06:09 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.426 | nll_loss 9.819 | ppl 902.96 | wps 42578.5 | wpb 510.9 | bsz 1 | num_updates 6357 | best_loss 7.981
2022-03-06 18:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6357 updates
2022-03-06 18:06:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:06:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:06:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 66 @ 6357 updates, score 10.426) (writing took 2.356742338743061 seconds)
2022-03-06 18:06:11 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 18:06:11 | INFO | train | epoch 066 | loss 3.534 | nll_loss 2.617 | ppl 6.14 | wps 22281.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6357 | lr 0.000396619 | gnorm 1.043 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 18883
2022-03-06 18:06:11 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 18:06:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:08:14 | INFO | train_inner | epoch 067:     43 / 97 loss=3.516, nll_loss=2.597, ppl=6.05, wps=22306.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6400, lr=0.000395285, gnorm=1.052, loss_scale=16, train_wall=263, gb_free=8.1, wall=19006
2022-03-06 18:09:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:10:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:10:54 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.494 | nll_loss 9.889 | ppl 948.33 | wps 42555 | wpb 510.9 | bsz 1 | num_updates 6453 | best_loss 7.981
2022-03-06 18:10:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6453 updates
2022-03-06 18:10:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:10:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:10:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 67 @ 6453 updates, score 10.494) (writing took 2.338888127822429 seconds)
2022-03-06 18:10:56 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 18:10:56 | INFO | train | epoch 067 | loss 3.492 | nll_loss 2.571 | ppl 5.94 | wps 22048.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6453 | lr 0.000393658 | gnorm 1.073 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 19168
2022-03-06 18:10:56 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 18:10:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:13:11 | INFO | train_inner | epoch 068:     47 / 97 loss=3.474, nll_loss=2.551, ppl=5.86, wps=22072.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6500, lr=0.000392232, gnorm=1.07, loss_scale=8, train_wall=266, gb_free=8.1, wall=19303
2022-03-06 18:15:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:15:39 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.526 | nll_loss 9.924 | ppl 971.4 | wps 42682.3 | wpb 510.9 | bsz 1 | num_updates 6550 | best_loss 7.981
2022-03-06 18:15:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6550 updates
2022-03-06 18:15:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:15:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 68 @ 6550 updates, score 10.526) (writing took 2.3540142672136426 seconds)
2022-03-06 18:15:41 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 18:15:41 | INFO | train | epoch 068 | loss 3.45 | nll_loss 2.526 | ppl 5.76 | wps 22278.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6550 | lr 0.000390732 | gnorm 1.056 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 19453
2022-03-06 18:15:41 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 18:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:18:04 | INFO | train_inner | epoch 069:     50 / 97 loss=3.43, nll_loss=2.504, ppl=5.67, wps=22309.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=6600, lr=0.000389249, gnorm=1.066, loss_scale=16, train_wall=263, gb_free=8.1, wall=19596
2022-03-06 18:20:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:20:24 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.587 | nll_loss 9.972 | ppl 1004.07 | wps 42621.6 | wpb 510.9 | bsz 1 | num_updates 6647 | best_loss 7.981
2022-03-06 18:20:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 6647 updates
2022-03-06 18:20:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:20:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:20:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 69 @ 6647 updates, score 10.587) (writing took 2.363395302556455 seconds)
2022-03-06 18:20:26 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 18:20:26 | INFO | train | epoch 069 | loss 3.409 | nll_loss 2.48 | ppl 5.58 | wps 22297.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6647 | lr 0.000387871 | gnorm 1.059 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 19738
2022-03-06 18:20:26 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 18:20:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:21:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:23:01 | INFO | train_inner | epoch 070:     54 / 97 loss=3.389, nll_loss=2.459, ppl=5.5, wps=22100, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=6700, lr=0.000386334, gnorm=1.044, loss_scale=16, train_wall=266, gb_free=8.1, wall=19893
2022-03-06 18:23:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:25:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:25:09 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.677 | nll_loss 10.08 | ppl 1082.65 | wps 42725.3 | wpb 510.9 | bsz 1 | num_updates 6742 | best_loss 7.981
2022-03-06 18:25:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 6742 updates
2022-03-06 18:25:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:25:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:25:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 70 @ 6742 updates, score 10.677) (writing took 2.341379303019494 seconds)
2022-03-06 18:25:11 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 18:25:11 | INFO | train | epoch 070 | loss 3.369 | nll_loss 2.436 | ppl 5.41 | wps 21839.4 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 6742 | lr 0.000385128 | gnorm 1.05 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 20023
2022-03-06 18:25:11 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 18:25:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:27:57 | INFO | train_inner | epoch 071:     58 / 97 loss=3.35, nll_loss=2.416, ppl=5.34, wps=22099, ups=0.34, wpb=65495, bsz=127.9, num_updates=6800, lr=0.000383482, gnorm=1.055, loss_scale=8, train_wall=266, gb_free=8.1, wall=20189
2022-03-06 18:29:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:29:54 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.748 | nll_loss 10.146 | ppl 1132.79 | wps 42730.1 | wpb 510.9 | bsz 1 | num_updates 6839 | best_loss 7.981
2022-03-06 18:29:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 6839 updates
2022-03-06 18:29:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:29:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:29:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 71 @ 6839 updates, score 10.748) (writing took 2.362540820147842 seconds)
2022-03-06 18:29:56 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 18:29:56 | INFO | train | epoch 071 | loss 3.335 | nll_loss 2.399 | ppl 5.27 | wps 22291.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6839 | lr 0.000382388 | gnorm 1.051 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 20308
2022-03-06 18:29:56 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 18:29:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:32:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:32:54 | INFO | train_inner | epoch 072:     62 / 97 loss=3.311, nll_loss=2.373, ppl=5.18, wps=22080.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6900, lr=0.000380693, gnorm=1.055, loss_scale=8, train_wall=266, gb_free=8.1, wall=20486
2022-03-06 18:34:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:34:39 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.822 | nll_loss 10.222 | ppl 1194 | wps 42370.4 | wpb 510.9 | bsz 1 | num_updates 6935 | best_loss 7.981
2022-03-06 18:34:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 6935 updates
2022-03-06 18:34:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:34:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 72 @ 6935 updates, score 10.822) (writing took 2.3556507267057896 seconds)
2022-03-06 18:34:41 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 18:34:41 | INFO | train | epoch 072 | loss 3.298 | nll_loss 2.358 | ppl 5.13 | wps 22031.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6935 | lr 0.000379732 | gnorm 1.053 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 20593
2022-03-06 18:34:41 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 18:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:37:48 | INFO | train_inner | epoch 073:     65 / 97 loss=3.277, nll_loss=2.336, ppl=5.05, wps=22280.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7000, lr=0.000377964, gnorm=1.06, loss_scale=8, train_wall=263, gb_free=8.1, wall=20780
2022-03-06 18:38:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:39:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:39:24 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.818 | nll_loss 10.209 | ppl 1183.59 | wps 42566.2 | wpb 510.9 | bsz 1 | num_updates 7031 | best_loss 7.981
2022-03-06 18:39:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7031 updates
2022-03-06 18:39:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:39:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:39:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 73 @ 7031 updates, score 10.818) (writing took 2.3465843251906335 seconds)
2022-03-06 18:39:27 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 18:39:27 | INFO | train | epoch 073 | loss 3.264 | nll_loss 2.322 | ppl 5 | wps 22040.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7031 | lr 0.00037713 | gnorm 1.065 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 20879
2022-03-06 18:39:27 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 18:39:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:42:44 | INFO | train_inner | epoch 074:     69 / 97 loss=3.241, nll_loss=2.297, ppl=4.91, wps=22073.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7100, lr=0.000375293, gnorm=1.069, loss_scale=8, train_wall=266, gb_free=8.1, wall=21076
2022-03-06 18:44:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:44:10 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.888 | nll_loss 10.293 | ppl 1254.35 | wps 42523.9 | wpb 510.9 | bsz 1 | num_updates 7128 | best_loss 7.981
2022-03-06 18:44:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7128 updates
2022-03-06 18:44:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:44:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:44:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 74 @ 7128 updates, score 10.888) (writing took 2.388044979888946 seconds)
2022-03-06 18:44:12 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 18:44:12 | INFO | train | epoch 074 | loss 3.229 | nll_loss 2.284 | ppl 4.87 | wps 22267.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7128 | lr 0.000374555 | gnorm 1.058 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 21164
2022-03-06 18:44:12 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 18:44:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:45:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:47:41 | INFO | train_inner | epoch 075:     73 / 97 loss=3.206, nll_loss=2.258, ppl=4.78, wps=22067.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7200, lr=0.000372678, gnorm=1.049, loss_scale=8, train_wall=266, gb_free=8.1, wall=21373
2022-03-06 18:48:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:48:56 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 11.002 | nll_loss 10.413 | ppl 1363.15 | wps 39650.3 | wpb 510.9 | bsz 1 | num_updates 7224 | best_loss 7.981
2022-03-06 18:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7224 updates
2022-03-06 18:48:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:48:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:48:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 75 @ 7224 updates, score 11.002) (writing took 2.3709407201968133 seconds)
2022-03-06 18:48:58 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 18:48:58 | INFO | train | epoch 075 | loss 3.196 | nll_loss 2.247 | ppl 4.75 | wps 21966.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7224 | lr 0.000372058 | gnorm 1.054 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 21450
2022-03-06 18:48:58 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 18:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:52:40 | INFO | train_inner | epoch 076:     76 / 97 loss=3.176, nll_loss=2.225, ppl=4.67, wps=21953.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=7300, lr=0.000370117, gnorm=1.056, loss_scale=16, train_wall=266, gb_free=8.1, wall=21671
2022-03-06 18:53:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:53:45 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.997 | nll_loss 10.399 | ppl 1350.37 | wps 42531.2 | wpb 510.9 | bsz 1 | num_updates 7321 | best_loss 7.981
2022-03-06 18:53:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7321 updates
2022-03-06 18:53:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:53:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:53:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 76 @ 7321 updates, score 10.997) (writing took 2.4888713201507926 seconds)
2022-03-06 18:53:47 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 18:53:47 | INFO | train | epoch 076 | loss 3.167 | nll_loss 2.215 | ppl 4.64 | wps 21968.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7321 | lr 0.000369585 | gnorm 1.068 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 21739
2022-03-06 18:53:47 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 18:53:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:55:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:57:37 | INFO | train_inner | epoch 077:     80 / 97 loss=3.141, nll_loss=2.187, ppl=4.55, wps=22022.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7400, lr=0.000367607, gnorm=1.055, loss_scale=8, train_wall=266, gb_free=8.1, wall=21969
2022-03-06 18:58:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:58:31 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 11.099 | nll_loss 10.512 | ppl 1460.18 | wps 41924.6 | wpb 510.9 | bsz 1 | num_updates 7417 | best_loss 7.981
2022-03-06 18:58:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7417 updates
2022-03-06 18:58:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:58:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:58:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 77 @ 7417 updates, score 11.099) (writing took 2.5314877359196544 seconds)
2022-03-06 18:58:33 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 18:58:33 | INFO | train | epoch 077 | loss 3.135 | nll_loss 2.18 | ppl 4.53 | wps 21991.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7417 | lr 0.000367186 | gnorm 1.05 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 22025
2022-03-06 18:58:33 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 18:58:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:02:32 | INFO | train_inner | epoch 078:     83 / 97 loss=3.115, nll_loss=2.158, ppl=4.46, wps=22228.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7500, lr=0.000365148, gnorm=1.052, loss_scale=16, train_wall=264, gb_free=8.1, wall=22263
2022-03-06 19:02:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:03:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:03:17 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.125 | nll_loss 10.53 | ppl 1478.45 | wps 42248.7 | wpb 510.9 | bsz 1 | num_updates 7513 | best_loss 7.981
2022-03-06 19:03:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 7513 updates
2022-03-06 19:03:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:03:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:03:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 78 @ 7513 updates, score 11.125) (writing took 2.5765283280052245 seconds)
2022-03-06 19:03:19 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 19:03:19 | INFO | train | epoch 078 | loss 3.105 | nll_loss 2.148 | ppl 4.43 | wps 21979.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7513 | lr 0.000364832 | gnorm 1.048 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 22311
2022-03-06 19:03:19 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 19:03:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:07:29 | INFO | train_inner | epoch 079:     87 / 97 loss=3.082, nll_loss=2.123, ppl=4.35, wps=22025.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=7600, lr=0.000362738, gnorm=1.045, loss_scale=8, train_wall=266, gb_free=8.1, wall=22561
2022-03-06 19:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:08:03 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.13 | nll_loss 10.532 | ppl 1480.36 | wps 42262.5 | wpb 510.9 | bsz 1 | num_updates 7610 | best_loss 7.981
2022-03-06 19:08:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 7610 updates
2022-03-06 19:08:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:08:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:08:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 79 @ 7610 updates, score 11.13) (writing took 2.4572562952525914 seconds)
2022-03-06 19:08:05 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 19:08:05 | INFO | train | epoch 079 | loss 3.077 | nll_loss 2.117 | ppl 4.34 | wps 22237.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7610 | lr 0.0003625 | gnorm 1.042 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 22597
2022-03-06 19:08:05 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 19:08:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:10:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:12:26 | INFO | train_inner | epoch 080:     91 / 97 loss=3.056, nll_loss=2.094, ppl=4.27, wps=22077.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7700, lr=0.000360375, gnorm=1.063, loss_scale=8, train_wall=266, gb_free=8.1, wall=22857
2022-03-06 19:12:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:12:48 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.205 | nll_loss 10.613 | ppl 1565.74 | wps 42455.9 | wpb 510.9 | bsz 1 | num_updates 7706 | best_loss 7.981
2022-03-06 19:12:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 7706 updates
2022-03-06 19:12:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:12:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:12:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 80 @ 7706 updates, score 11.205) (writing took 2.4016119688749313 seconds)
2022-03-06 19:12:50 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 19:12:50 | INFO | train | epoch 080 | loss 3.049 | nll_loss 2.086 | ppl 4.25 | wps 22049.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7706 | lr 0.000360235 | gnorm 1.067 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 22882
2022-03-06 19:12:50 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 19:12:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:17:20 | INFO | train_inner | epoch 081:     94 / 97 loss=3.023, nll_loss=2.058, ppl=4.17, wps=22276.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7800, lr=0.000358057, gnorm=1.052, loss_scale=16, train_wall=263, gb_free=8.1, wall=23151
2022-03-06 19:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:17:33 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.29 | nll_loss 10.699 | ppl 1662.3 | wps 42364.1 | wpb 510.9 | bsz 1 | num_updates 7803 | best_loss 7.981
2022-03-06 19:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 7803 updates
2022-03-06 19:17:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:17:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:17:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 81 @ 7803 updates, score 11.29) (writing took 2.3961054543033242 seconds)
2022-03-06 19:17:36 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 19:17:36 | INFO | train | epoch 081 | loss 3.021 | nll_loss 2.056 | ppl 4.16 | wps 22257.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7803 | lr 0.000357989 | gnorm 1.052 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 23167
2022-03-06 19:17:36 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 19:17:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:19:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:22:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:22:19 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.337 | nll_loss 10.751 | ppl 1723.93 | wps 42287.3 | wpb 510.9 | bsz 1 | num_updates 7899 | best_loss 7.981
2022-03-06 19:22:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 7899 updates
2022-03-06 19:22:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:22:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:22:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 82 @ 7899 updates, score 11.337) (writing took 2.591365333646536 seconds)
2022-03-06 19:22:22 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 19:22:22 | INFO | train | epoch 082 | loss 2.994 | nll_loss 2.027 | ppl 4.08 | wps 21949.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7899 | lr 0.000355807 | gnorm 1.041 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 23454
2022-03-06 19:22:22 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 19:22:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:22:25 | INFO | train_inner | epoch 083:      1 / 97 loss=2.997, nll_loss=2.03, ppl=4.08, wps=21432.1, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=7900, lr=0.000355784, gnorm=1.042, loss_scale=8, train_wall=266, gb_free=8.1, wall=23457
2022-03-06 19:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:27:05 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.352 | nll_loss 10.767 | ppl 1742.4 | wps 42250.2 | wpb 510.9 | bsz 1 | num_updates 7996 | best_loss 7.981
2022-03-06 19:27:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 7996 updates
2022-03-06 19:27:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:27:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:27:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 83 @ 7996 updates, score 11.352) (writing took 2.5525139132514596 seconds)
2022-03-06 19:27:08 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 19:27:08 | INFO | train | epoch 083 | loss 2.969 | nll_loss 1.999 | ppl 4 | wps 22234.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7996 | lr 0.000353642 | gnorm 1.038 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 23740
2022-03-06 19:27:08 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 19:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:27:19 | INFO | train_inner | epoch 084:      4 / 97 loss=2.965, nll_loss=1.995, ppl=3.99, wps=22252.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8000, lr=0.000353553, gnorm=1.036, loss_scale=16, train_wall=263, gb_free=8.1, wall=23751
2022-03-06 19:27:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:31:51 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.449 | nll_loss 10.865 | ppl 1864.64 | wps 42279 | wpb 510.9 | bsz 1 | num_updates 8092 | best_loss 7.981
2022-03-06 19:31:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8092 updates
2022-03-06 19:31:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:31:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:31:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 84 @ 8092 updates, score 11.449) (writing took 2.648341610096395 seconds)
2022-03-06 19:31:53 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 19:31:53 | INFO | train | epoch 084 | loss 2.943 | nll_loss 1.971 | ppl 3.92 | wps 21999.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8092 | lr 0.000351538 | gnorm 1.046 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 24025
2022-03-06 19:31:53 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 19:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:32:17 | INFO | train_inner | epoch 085:      8 / 97 loss=2.939, nll_loss=1.966, ppl=3.91, wps=22028, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8100, lr=0.000351364, gnorm=1.047, loss_scale=8, train_wall=266, gb_free=8.1, wall=24048
2022-03-06 19:36:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:36:37 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.34 | nll_loss 10.749 | ppl 1721.05 | wps 42228.2 | wpb 510.9 | bsz 1 | num_updates 8189 | best_loss 7.981
2022-03-06 19:36:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8189 updates
2022-03-06 19:36:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:36:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:36:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 85 @ 8189 updates, score 11.34) (writing took 2.281873774714768 seconds)
2022-03-06 19:36:39 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 19:36:39 | INFO | train | epoch 085 | loss 2.918 | nll_loss 1.943 | ppl 3.85 | wps 22221 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8189 | lr 0.00034945 | gnorm 1.042 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 24311
2022-03-06 19:36:39 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 19:36:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:36:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:37:14 | INFO | train_inner | epoch 086:     12 / 97 loss=2.911, nll_loss=1.936, ppl=3.83, wps=22032.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8200, lr=0.000349215, gnorm=1.047, loss_scale=8, train_wall=266, gb_free=8.1, wall=24346
2022-03-06 19:41:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:41:22 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.49 | nll_loss 10.91 | ppl 1924.33 | wps 42572.6 | wpb 510.9 | bsz 1 | num_updates 8285 | best_loss 7.981
2022-03-06 19:41:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8285 updates
2022-03-06 19:41:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:41:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:41:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 86 @ 8285 updates, score 11.49) (writing took 2.4268546090461314 seconds)
2022-03-06 19:41:25 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 19:41:25 | INFO | train | epoch 086 | loss 2.897 | nll_loss 1.92 | ppl 3.78 | wps 22043.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8285 | lr 0.000347419 | gnorm 1.058 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 24596
2022-03-06 19:41:25 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 19:41:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:42:08 | INFO | train_inner | epoch 087:     15 / 97 loss=2.892, nll_loss=1.915, ppl=3.77, wps=22288.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8300, lr=0.000347105, gnorm=1.048, loss_scale=8, train_wall=263, gb_free=8.1, wall=24640
2022-03-06 19:44:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:46:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:46:07 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.515 | nll_loss 10.93 | ppl 1950.51 | wps 42525.4 | wpb 510.9 | bsz 1 | num_updates 8381 | best_loss 7.981
2022-03-06 19:46:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8381 updates
2022-03-06 19:46:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:46:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 87 @ 8381 updates, score 11.515) (writing took 2.498621277976781 seconds)
2022-03-06 19:46:10 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 19:46:10 | INFO | train | epoch 087 | loss 2.871 | nll_loss 1.893 | ppl 3.71 | wps 22045.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8381 | lr 0.000345424 | gnorm 1.055 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 24882
2022-03-06 19:46:10 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 19:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:47:04 | INFO | train_inner | epoch 088:     19 / 97 loss=2.863, nll_loss=1.883, ppl=3.69, wps=22076.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8400, lr=0.000345033, gnorm=1.05, loss_scale=8, train_wall=266, gb_free=8.1, wall=24936
2022-03-06 19:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:50:53 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.566 | nll_loss 10.986 | ppl 2028.48 | wps 42312 | wpb 510.9 | bsz 1 | num_updates 8478 | best_loss 7.981
2022-03-06 19:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 8478 updates
2022-03-06 19:50:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:50:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:50:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 88 @ 8478 updates, score 11.566) (writing took 2.3767475923523307 seconds)
2022-03-06 19:50:55 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 19:50:55 | INFO | train | epoch 088 | loss 2.85 | nll_loss 1.87 | ppl 3.65 | wps 22244.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8478 | lr 0.000343442 | gnorm 1.034 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 25167
2022-03-06 19:50:55 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 19:50:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:51:59 | INFO | train_inner | epoch 089:     22 / 97 loss=2.845, nll_loss=1.864, ppl=3.64, wps=22254.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8500, lr=0.000342997, gnorm=1.034, loss_scale=16, train_wall=264, gb_free=8.1, wall=25231
2022-03-06 19:55:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:55:39 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.569 | nll_loss 10.983 | ppl 2024.33 | wps 42053.7 | wpb 510.9 | bsz 1 | num_updates 8575 | best_loss 7.981
2022-03-06 19:55:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 8575 updates
2022-03-06 19:55:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:55:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:55:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 89 @ 8575 updates, score 11.569) (writing took 2.5910417321138084 seconds)
2022-03-06 19:55:41 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 19:55:41 | INFO | train | epoch 089 | loss 2.828 | nll_loss 1.846 | ppl 3.59 | wps 22202.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8575 | lr 0.000341494 | gnorm 1.028 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 25453
2022-03-06 19:55:41 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 19:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:56:53 | INFO | train_inner | epoch 090:     25 / 97 loss=2.823, nll_loss=1.84, ppl=3.58, wps=22224.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8600, lr=0.000340997, gnorm=1.026, loss_scale=16, train_wall=264, gb_free=8.1, wall=25525
2022-03-06 19:57:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:00:25 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.651 | nll_loss 11.072 | ppl 2153.13 | wps 42159.4 | wpb 510.9 | bsz 1 | num_updates 8671 | best_loss 7.981
2022-03-06 20:00:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 8671 updates
2022-03-06 20:00:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:00:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:00:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 90 @ 8671 updates, score 11.651) (writing took 2.6084914109669626 seconds)
2022-03-06 20:00:28 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 20:00:28 | INFO | train | epoch 090 | loss 2.807 | nll_loss 1.823 | ppl 3.54 | wps 21961.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8671 | lr 0.000339598 | gnorm 1.033 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 25740
2022-03-06 20:00:28 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 20:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:01:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:01:54 | INFO | train_inner | epoch 091:     30 / 97 loss=2.8, nll_loss=1.815, ppl=3.52, wps=21778.9, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=8700, lr=0.000339032, gnorm=1.038, loss_scale=8, train_wall=269, gb_free=8.1, wall=25826
2022-03-06 20:05:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:05:12 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.667 | nll_loss 11.088 | ppl 2177.37 | wps 41997.4 | wpb 510.9 | bsz 1 | num_updates 8767 | best_loss 7.981
2022-03-06 20:05:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 8767 updates
2022-03-06 20:05:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:05:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:05:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 91 @ 8767 updates, score 11.667) (writing took 2.615790724288672 seconds)
2022-03-06 20:05:14 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 20:05:14 | INFO | train | epoch 091 | loss 2.787 | nll_loss 1.801 | ppl 3.48 | wps 21954.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8767 | lr 0.000337734 | gnorm 1.034 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 26026
2022-03-06 20:05:14 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 20:05:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:06:49 | INFO | train_inner | epoch 092:     33 / 97 loss=2.782, nll_loss=1.795, ppl=3.47, wps=22205.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=8800, lr=0.0003371, gnorm=1.052, loss_scale=8, train_wall=264, gb_free=8.1, wall=26121
2022-03-06 20:09:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:09:58 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.719 | nll_loss 11.14 | ppl 2256.06 | wps 42311 | wpb 510.9 | bsz 1 | num_updates 8864 | best_loss 7.981
2022-03-06 20:09:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 8864 updates
2022-03-06 20:09:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:10:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:10:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 92 @ 8864 updates, score 11.719) (writing took 2.547483755275607 seconds)
2022-03-06 20:10:00 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 20:10:00 | INFO | train | epoch 092 | loss 2.768 | nll_loss 1.78 | ppl 3.43 | wps 22215.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8864 | lr 0.000335881 | gnorm 1.059 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 26312
2022-03-06 20:10:00 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 20:10:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:11:43 | INFO | train_inner | epoch 093:     36 / 97 loss=2.758, nll_loss=1.769, ppl=3.41, wps=22238.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=8900, lr=0.000335201, gnorm=1.036, loss_scale=16, train_wall=264, gb_free=8.1, wall=26415
2022-03-06 20:14:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:14:43 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.737 | nll_loss 11.161 | ppl 2290.13 | wps 42518.9 | wpb 510.9 | bsz 1 | num_updates 8960 | best_loss 7.981
2022-03-06 20:14:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 8960 updates
2022-03-06 20:14:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 93 @ 8960 updates, score 11.737) (writing took 2.527069142088294 seconds)
2022-03-06 20:14:46 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 20:14:46 | INFO | train | epoch 093 | loss 2.746 | nll_loss 1.757 | ppl 3.38 | wps 22008.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8960 | lr 0.000334077 | gnorm 1.03 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 26598
2022-03-06 20:14:46 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 20:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:15:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:16:43 | INFO | train_inner | epoch 094:     41 / 97 loss=2.736, nll_loss=1.746, ppl=3.35, wps=21846.5, ups=0.33, wpb=65495, bsz=127.9, num_updates=9000, lr=0.000333333, gnorm=1.036, loss_scale=8, train_wall=269, gb_free=8.1, wall=26715
2022-03-06 20:19:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:19:29 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.748 | nll_loss 11.169 | ppl 2302.64 | wps 42546.3 | wpb 510.9 | bsz 1 | num_updates 9056 | best_loss 7.981
2022-03-06 20:19:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9056 updates
2022-03-06 20:19:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:19:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:19:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 94 @ 9056 updates, score 11.748) (writing took 2.503518566954881 seconds)
2022-03-06 20:19:31 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 20:19:31 | INFO | train | epoch 094 | loss 2.729 | nll_loss 1.737 | ppl 3.33 | wps 22030.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9056 | lr 0.000332301 | gnorm 1.041 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 26883
2022-03-06 20:19:31 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 20:19:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:21:37 | INFO | train_inner | epoch 095:     44 / 97 loss=2.722, nll_loss=1.73, ppl=3.32, wps=22281.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=9100, lr=0.000331497, gnorm=1.038, loss_scale=16, train_wall=263, gb_free=8.1, wall=27009
2022-03-06 20:24:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:24:14 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.782 | nll_loss 11.212 | ppl 2372.31 | wps 42251.3 | wpb 510.9 | bsz 1 | num_updates 9153 | best_loss 7.981
2022-03-06 20:24:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9153 updates
2022-03-06 20:24:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:24:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 95 @ 9153 updates, score 11.782) (writing took 2.618440011050552 seconds)
2022-03-06 20:24:17 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 20:24:17 | INFO | train | epoch 095 | loss 2.709 | nll_loss 1.717 | ppl 3.29 | wps 22215.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9153 | lr 0.000330536 | gnorm 1.023 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 27169
2022-03-06 20:24:17 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 20:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:26:32 | INFO | train_inner | epoch 096:     47 / 97 loss=2.703, nll_loss=1.71, ppl=3.27, wps=22208.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=9200, lr=0.00032969, gnorm=1.033, loss_scale=16, train_wall=264, gb_free=8.1, wall=27304
2022-03-06 20:28:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:28:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:29:01 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.842 | nll_loss 11.273 | ppl 2474.54 | wps 42207.9 | wpb 510.9 | bsz 1 | num_updates 9249 | best_loss 7.981
2022-03-06 20:29:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9249 updates
2022-03-06 20:29:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:29:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:29:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 96 @ 9249 updates, score 11.842) (writing took 2.6956229847855866 seconds)
2022-03-06 20:29:03 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 20:29:03 | INFO | train | epoch 096 | loss 2.691 | nll_loss 1.697 | ppl 3.24 | wps 21965.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9249 | lr 0.000328816 | gnorm 1.038 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 27455
2022-03-06 20:29:03 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 20:29:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:29:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:31:33 | INFO | train_inner | epoch 097:     52 / 97 loss=2.682, nll_loss=1.687, ppl=3.22, wps=21790.5, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=9300, lr=0.000327913, gnorm=1.032, loss_scale=8, train_wall=269, gb_free=8.1, wall=27605
2022-03-06 20:33:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:33:47 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 11.925 | nll_loss 11.365 | ppl 2637.45 | wps 42190.4 | wpb 510.9 | bsz 1 | num_updates 9345 | best_loss 7.981
2022-03-06 20:33:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9345 updates
2022-03-06 20:33:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:33:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:33:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 97 @ 9345 updates, score 11.925) (writing took 2.606313400901854 seconds)
2022-03-06 20:33:50 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 20:33:50 | INFO | train | epoch 097 | loss 2.674 | nll_loss 1.678 | ppl 3.2 | wps 21963.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9345 | lr 0.000327122 | gnorm 1.027 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 27741
2022-03-06 20:33:50 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 20:33:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:36:28 | INFO | train_inner | epoch 098:     55 / 97 loss=2.667, nll_loss=1.671, ppl=3.18, wps=22203.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9400, lr=0.000326164, gnorm=1.03, loss_scale=16, train_wall=264, gb_free=8.1, wall=27900
2022-03-06 20:38:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:38:33 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 11.898 | nll_loss 11.333 | ppl 2579.04 | wps 42206.8 | wpb 510.9 | bsz 1 | num_updates 9442 | best_loss 7.981
2022-03-06 20:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 9442 updates
2022-03-06 20:38:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 98 @ 9442 updates, score 11.898) (writing took 2.4493433400057256 seconds)
2022-03-06 20:38:36 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 20:38:36 | INFO | train | epoch 098 | loss 2.659 | nll_loss 1.662 | ppl 3.16 | wps 22199.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9442 | lr 0.000325438 | gnorm 1.025 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 28028
2022-03-06 20:38:36 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 20:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:40:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:41:25 | INFO | train_inner | epoch 099:     59 / 97 loss=2.645, nll_loss=1.647, ppl=3.13, wps=22041.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=9500, lr=0.000324443, gnorm=1.021, loss_scale=8, train_wall=266, gb_free=8.1, wall=28197
2022-03-06 20:43:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:43:19 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 11.938 | nll_loss 11.367 | ppl 2641.1 | wps 42421.8 | wpb 510.9 | bsz 1 | num_updates 9538 | best_loss 7.981
2022-03-06 20:43:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 9538 updates
2022-03-06 20:43:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:43:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:43:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 99 @ 9538 updates, score 11.938) (writing took 2.5646648830734193 seconds)
2022-03-06 20:43:21 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 20:43:21 | INFO | train | epoch 099 | loss 2.64 | nll_loss 1.642 | ppl 3.12 | wps 22024.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9538 | lr 0.000323796 | gnorm 1.036 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 28313
2022-03-06 20:43:21 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 20:43:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:46:19 | INFO | train_inner | epoch 100:     62 / 97 loss=2.635, nll_loss=1.636, ppl=3.11, wps=22259.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9600, lr=0.000322749, gnorm=1.033, loss_scale=16, train_wall=263, gb_free=8.1, wall=28491
2022-03-06 20:47:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:48:04 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 11.956 | nll_loss 11.388 | ppl 2680.36 | wps 42504.3 | wpb 510.9 | bsz 1 | num_updates 9635 | best_loss 7.981
2022-03-06 20:48:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 9635 updates
2022-03-06 20:48:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:48:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:48:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 100 @ 9635 updates, score 11.956) (writing took 2.464624833781272 seconds)
2022-03-06 20:48:07 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 20:48:07 | INFO | train | epoch 100 | loss 2.625 | nll_loss 1.625 | ppl 3.08 | wps 22249.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9635 | lr 0.000322162 | gnorm 1.024 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 28599
2022-03-06 20:48:07 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 20:48:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:51:13 | INFO | train_inner | epoch 101:     65 / 97 loss=2.612, nll_loss=1.611, ppl=3.06, wps=22267.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9700, lr=0.000321081, gnorm=1.016, loss_scale=16, train_wall=263, gb_free=8.1, wall=28785
2022-03-06 20:52:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:52:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:52:50 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 11.97 | nll_loss 11.406 | ppl 2712.91 | wps 42483.6 | wpb 510.9 | bsz 1 | num_updates 9731 | best_loss 7.981
2022-03-06 20:52:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 9731 updates
2022-03-06 20:52:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:52:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:52:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 101 @ 9731 updates, score 11.97) (writing took 2.5794942090287805 seconds)
2022-03-06 20:52:52 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 20:52:52 | INFO | train | epoch 101 | loss 2.608 | nll_loss 1.607 | ppl 3.05 | wps 22014.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9731 | lr 0.000320569 | gnorm 1.022 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 28884
2022-03-06 20:52:52 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 20:52:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:56:10 | INFO | train_inner | epoch 102:     69 / 97 loss=2.601, nll_loss=1.599, ppl=3.03, wps=22029.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=9800, lr=0.000319438, gnorm=1.032, loss_scale=16, train_wall=266, gb_free=8.1, wall=29082
2022-03-06 20:57:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:57:36 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 11.997 | nll_loss 11.432 | ppl 2763.65 | wps 42065.1 | wpb 510.9 | bsz 1 | num_updates 9828 | best_loss 7.981
2022-03-06 20:57:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 9828 updates
2022-03-06 20:57:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:57:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:57:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 102 @ 9828 updates, score 11.997) (writing took 2.717121005989611 seconds)
2022-03-06 20:57:39 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 20:57:39 | INFO | train | epoch 102 | loss 2.593 | nll_loss 1.59 | ppl 3.01 | wps 22195.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9828 | lr 0.000318983 | gnorm 1.026 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 29170
2022-03-06 20:57:39 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 20:57:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:59:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:01:08 | INFO | train_inner | epoch 103:     73 / 97 loss=2.582, nll_loss=1.579, ppl=2.99, wps=21986.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9900, lr=0.000317821, gnorm=1.024, loss_scale=16, train_wall=266, gb_free=8.1, wall=29380
2022-03-06 21:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:02:22 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.068 | nll_loss 11.506 | ppl 2908.75 | wps 42211.9 | wpb 510.9 | bsz 1 | num_updates 9924 | best_loss 7.981
2022-03-06 21:02:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 9924 updates
2022-03-06 21:02:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:02:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:02:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 103 @ 9924 updates, score 12.068) (writing took 2.5994667652994394 seconds)
2022-03-06 21:02:25 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 21:02:25 | INFO | train | epoch 103 | loss 2.578 | nll_loss 1.574 | ppl 2.98 | wps 21965.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9924 | lr 0.000317436 | gnorm 1.028 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 29457
2022-03-06 21:02:25 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 21:02:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:03:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:06:06 | INFO | train_inner | epoch 104:     77 / 97 loss=2.57, nll_loss=1.565, ppl=2.96, wps=22002.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10000, lr=0.000316228, gnorm=1.023, loss_scale=8, train_wall=266, gb_free=8.1, wall=29678
2022-03-06 21:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:07:08 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.067 | nll_loss 11.502 | ppl 2900.7 | wps 42424.7 | wpb 510.9 | bsz 1 | num_updates 10020 | best_loss 7.981
2022-03-06 21:07:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10020 updates
2022-03-06 21:07:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:07:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:07:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 104 @ 10020 updates, score 12.067) (writing took 2.678880339022726 seconds)
2022-03-06 21:07:11 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 21:07:11 | INFO | train | epoch 104 | loss 2.563 | nll_loss 1.558 | ppl 2.94 | wps 21964.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10020 | lr 0.000315912 | gnorm 1.024 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 29743
2022-03-06 21:07:11 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 21:07:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:11:01 | INFO | train_inner | epoch 105:     80 / 97 loss=2.55, nll_loss=1.544, ppl=2.92, wps=22231.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=10100, lr=0.000314658, gnorm=1.019, loss_scale=16, train_wall=264, gb_free=8.1, wall=29972
2022-03-06 21:11:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:11:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:11:54 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.081 | nll_loss 11.521 | ppl 2939.4 | wps 42491.1 | wpb 510.9 | bsz 1 | num_updates 10116 | best_loss 7.981
2022-03-06 21:11:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10116 updates
2022-03-06 21:11:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:11:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:11:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 105 @ 10116 updates, score 12.081) (writing took 2.595361215993762 seconds)
2022-03-06 21:11:57 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 21:11:57 | INFO | train | epoch 105 | loss 2.547 | nll_loss 1.541 | ppl 2.91 | wps 22000.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10116 | lr 0.000314409 | gnorm 1.018 | loss_scale 8 | train_wall 256 | gb_free 8.1 | wall 30029
2022-03-06 21:11:57 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 21:11:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:15:57 | INFO | train_inner | epoch 106:     84 / 97 loss=2.541, nll_loss=1.534, ppl=2.9, wps=22064.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=10200, lr=0.000313112, gnorm=1.021, loss_scale=8, train_wall=266, gb_free=8.1, wall=30269
2022-03-06 21:16:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:16:40 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.108 | nll_loss 11.548 | ppl 2994.77 | wps 42534.8 | wpb 510.9 | bsz 1 | num_updates 10213 | best_loss 7.981
2022-03-06 21:16:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10213 updates
2022-03-06 21:16:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:16:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:16:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 106 @ 10213 updates, score 12.108) (writing took 2.438862564973533 seconds)
2022-03-06 21:16:42 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 21:16:42 | INFO | train | epoch 106 | loss 2.535 | nll_loss 1.528 | ppl 2.88 | wps 22268.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10213 | lr 0.000312913 | gnorm 1.016 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 30314
2022-03-06 21:16:42 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 21:16:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:20:51 | INFO | train_inner | epoch 107:     87 / 97 loss=2.525, nll_loss=1.517, ppl=2.86, wps=22280.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10300, lr=0.000311588, gnorm=1.018, loss_scale=16, train_wall=263, gb_free=8.1, wall=30563
2022-03-06 21:21:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:21:25 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.142 | nll_loss 11.584 | ppl 3070.99 | wps 42519.9 | wpb 510.9 | bsz 1 | num_updates 10310 | best_loss 7.981
2022-03-06 21:21:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 10310 updates
2022-03-06 21:21:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:21:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:21:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 107 @ 10310 updates, score 12.142) (writing took 2.4530624132603407 seconds)
2022-03-06 21:21:27 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 21:21:27 | INFO | train | epoch 107 | loss 2.522 | nll_loss 1.514 | ppl 2.86 | wps 22263.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10310 | lr 0.000311437 | gnorm 1.019 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 30599
2022-03-06 21:21:27 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 21:21:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:24:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:25:49 | INFO | train_inner | epoch 108:     91 / 97 loss=2.509, nll_loss=1.5, ppl=2.83, wps=22024.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10400, lr=0.000310087, gnorm=1.017, loss_scale=16, train_wall=266, gb_free=8.1, wall=30861
2022-03-06 21:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:26:11 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.188 | nll_loss 11.628 | ppl 3165.6 | wps 42102.1 | wpb 510.9 | bsz 1 | num_updates 10406 | best_loss 7.981
2022-03-06 21:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 10406 updates
2022-03-06 21:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:26:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 108 @ 10406 updates, score 12.188) (writing took 2.6444480451755226 seconds)
2022-03-06 21:26:14 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 21:26:14 | INFO | train | epoch 108 | loss 2.507 | nll_loss 1.497 | ppl 2.82 | wps 21968.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10406 | lr 0.000309997 | gnorm 1.019 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 30885
2022-03-06 21:26:14 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 21:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:30:43 | INFO | train_inner | epoch 109:     94 / 97 loss=2.498, nll_loss=1.488, ppl=2.8, wps=22217, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10500, lr=0.000308607, gnorm=1.018, loss_scale=32, train_wall=264, gb_free=8.1, wall=31155
2022-03-06 21:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:30:57 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.197 | nll_loss 11.641 | ppl 3192.87 | wps 42077.2 | wpb 510.9 | bsz 1 | num_updates 10503 | best_loss 7.981
2022-03-06 21:30:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 10503 updates
2022-03-06 21:30:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:31:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:31:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 109 @ 10503 updates, score 12.197) (writing took 2.6902175820432603 seconds)
2022-03-06 21:31:00 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 21:31:00 | INFO | train | epoch 109 | loss 2.493 | nll_loss 1.482 | ppl 2.79 | wps 22195.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10503 | lr 0.000308563 | gnorm 1.014 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 31172
2022-03-06 21:31:00 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 21:31:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:31:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:35:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:35:43 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.227 | nll_loss 11.676 | ppl 3271.81 | wps 42163.4 | wpb 510.9 | bsz 1 | num_updates 10599 | best_loss 7.981
2022-03-06 21:35:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 10599 updates
2022-03-06 21:35:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:35:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:35:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 110 @ 10599 updates, score 12.227) (writing took 2.605539945885539 seconds)
2022-03-06 21:35:46 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 21:35:46 | INFO | train | epoch 110 | loss 2.482 | nll_loss 1.471 | ppl 2.77 | wps 21967.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10599 | lr 0.000307162 | gnorm 1.008 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 31458
2022-03-06 21:35:46 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 21:35:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:35:49 | INFO | train_inner | epoch 111:      1 / 97 loss=2.483, nll_loss=1.471, ppl=2.77, wps=21424.6, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=10600, lr=0.000307148, gnorm=1.009, loss_scale=16, train_wall=266, gb_free=8.1, wall=31461
2022-03-06 21:38:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:40:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:40:29 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.241 | nll_loss 11.692 | ppl 3309.42 | wps 42135.6 | wpb 510.9 | bsz 1 | num_updates 10695 | best_loss 7.981
2022-03-06 21:40:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 10695 updates
2022-03-06 21:40:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:40:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:40:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 111 @ 10695 updates, score 12.241) (writing took 2.675124065950513 seconds)
2022-03-06 21:40:32 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 21:40:32 | INFO | train | epoch 111 | loss 2.467 | nll_loss 1.455 | ppl 2.74 | wps 21980.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10695 | lr 0.00030578 | gnorm 0.997 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 31744
2022-03-06 21:40:32 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 21:40:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:40:46 | INFO | train_inner | epoch 112:      5 / 97 loss=2.464, nll_loss=1.451, ppl=2.73, wps=22015.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10700, lr=0.000305709, gnorm=0.994, loss_scale=16, train_wall=266, gb_free=8.1, wall=31758
2022-03-06 21:44:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:45:15 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.327 | nll_loss 11.778 | ppl 3511.8 | wps 42611.6 | wpb 510.9 | bsz 1 | num_updates 10791 | best_loss 7.981
2022-03-06 21:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 10791 updates
2022-03-06 21:45:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:45:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:45:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 112 @ 10791 updates, score 12.327) (writing took 2.581496869213879 seconds)
2022-03-06 21:45:18 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 21:45:18 | INFO | train | epoch 112 | loss 2.457 | nll_loss 1.444 | ppl 2.72 | wps 21999.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10791 | lr 0.000304417 | gnorm 1.009 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 32030
2022-03-06 21:45:18 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 21:45:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:45:44 | INFO | train_inner | epoch 113:      9 / 97 loss=2.453, nll_loss=1.44, ppl=2.71, wps=22030.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10800, lr=0.00030429, gnorm=1.011, loss_scale=16, train_wall=266, gb_free=8.1, wall=32056
2022-03-06 21:49:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:50:01 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 12.333 | nll_loss 11.785 | ppl 3528.92 | wps 42513 | wpb 510.9 | bsz 1 | num_updates 10888 | best_loss 7.981
2022-03-06 21:50:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 10888 updates
2022-03-06 21:50:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:50:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:50:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 113 @ 10888 updates, score 12.333) (writing took 2.5316157923080027 seconds)
2022-03-06 21:50:04 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 21:50:04 | INFO | train | epoch 113 | loss 2.444 | nll_loss 1.43 | ppl 2.69 | wps 22238.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10888 | lr 0.000303058 | gnorm 1.015 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 32315
2022-03-06 21:50:04 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 21:50:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:50:38 | INFO | train_inner | epoch 114:     12 / 97 loss=2.441, nll_loss=1.426, ppl=2.69, wps=22257.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=10900, lr=0.000302891, gnorm=1.015, loss_scale=16, train_wall=263, gb_free=8.1, wall=32350
2022-03-06 21:51:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:54:46 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 12.267 | nll_loss 11.713 | ppl 3357.49 | wps 42291.7 | wpb 510.9 | bsz 1 | num_updates 10984 | best_loss 7.981
2022-03-06 21:54:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 10984 updates
2022-03-06 21:54:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:54:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:54:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 114 @ 10984 updates, score 12.267) (writing took 2.5559632699005306 seconds)
2022-03-06 21:54:49 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 21:54:49 | INFO | train | epoch 114 | loss 2.431 | nll_loss 1.416 | ppl 2.67 | wps 22025.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10984 | lr 0.000301731 | gnorm 1.004 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 32601
2022-03-06 21:54:49 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 21:54:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:55:35 | INFO | train_inner | epoch 115:     16 / 97 loss=2.427, nll_loss=1.412, ppl=2.66, wps=22055.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11000, lr=0.000301511, gnorm=1.005, loss_scale=16, train_wall=266, gb_free=8.1, wall=32647
2022-03-06 21:57:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:59:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:59:32 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 12.349 | nll_loss 11.799 | ppl 3563.17 | wps 42111.8 | wpb 510.9 | bsz 1 | num_updates 11080 | best_loss 7.981
2022-03-06 21:59:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11080 updates
2022-03-06 21:59:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:59:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:59:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 115 @ 11080 updates, score 12.349) (writing took 2.7072075600735843 seconds)
2022-03-06 21:59:35 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 21:59:35 | INFO | train | epoch 115 | loss 2.421 | nll_loss 1.405 | ppl 2.65 | wps 21982.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11080 | lr 0.000300421 | gnorm 1.013 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 32887
2022-03-06 21:59:35 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 21:59:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:00:32 | INFO | train_inner | epoch 116:     20 / 97 loss=2.417, nll_loss=1.4, ppl=2.64, wps=22016.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=11100, lr=0.00030015, gnorm=1.014, loss_scale=16, train_wall=266, gb_free=8.1, wall=32944
2022-03-06 22:03:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:04:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:04:18 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 12.32 | nll_loss 11.768 | ppl 3486.93 | wps 42118.1 | wpb 510.9 | bsz 1 | num_updates 11176 | best_loss 7.981
2022-03-06 22:04:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11176 updates
2022-03-06 22:04:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:04:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:04:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 116 @ 11176 updates, score 12.32) (writing took 2.707561029586941 seconds)
2022-03-06 22:04:21 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 22:04:21 | INFO | train | epoch 116 | loss 2.409 | nll_loss 1.392 | ppl 2.62 | wps 21976.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11176 | lr 0.000299128 | gnorm 1.003 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 33173
2022-03-06 22:04:21 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 22:04:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:05:30 | INFO | train_inner | epoch 117:     24 / 97 loss=2.407, nll_loss=1.391, ppl=2.62, wps=22001.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11200, lr=0.000298807, gnorm=1.004, loss_scale=16, train_wall=266, gb_free=8.1, wall=33242
2022-03-06 22:08:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:09:05 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 12.328 | nll_loss 11.777 | ppl 3510.26 | wps 42250.5 | wpb 510.9 | bsz 1 | num_updates 11273 | best_loss 7.981
2022-03-06 22:09:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 11273 updates
2022-03-06 22:09:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 117 @ 11273 updates, score 12.328) (writing took 2.641136765945703 seconds)
2022-03-06 22:09:07 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 22:09:07 | INFO | train | epoch 117 | loss 2.399 | nll_loss 1.381 | ppl 2.6 | wps 22203.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11273 | lr 0.000297838 | gnorm 1 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 33459
2022-03-06 22:09:07 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 22:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:10:25 | INFO | train_inner | epoch 118:     27 / 97 loss=2.392, nll_loss=1.374, ppl=2.59, wps=22228.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11300, lr=0.000297482, gnorm=0.991, loss_scale=32, train_wall=264, gb_free=8.1, wall=33537
2022-03-06 22:10:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:13:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:13:51 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 12.363 | nll_loss 11.818 | ppl 3611.49 | wps 42183.9 | wpb 510.9 | bsz 1 | num_updates 11369 | best_loss 7.981
2022-03-06 22:13:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 11369 updates
2022-03-06 22:13:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:13:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:13:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 118 @ 11369 updates, score 12.363) (writing took 2.6390158720314503 seconds)
2022-03-06 22:13:53 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 22:13:53 | INFO | train | epoch 118 | loss 2.387 | nll_loss 1.368 | ppl 2.58 | wps 21977.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11369 | lr 0.000296578 | gnorm 0.995 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 33745
2022-03-06 22:13:53 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 22:13:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:15:22 | INFO | train_inner | epoch 119:     31 / 97 loss=2.385, nll_loss=1.366, ppl=2.58, wps=22014, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11400, lr=0.000296174, gnorm=0.994, loss_scale=16, train_wall=266, gb_free=8.1, wall=33834
2022-03-06 22:17:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:18:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:18:36 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 12.4 | nll_loss 11.85 | ppl 3692.15 | wps 42795.8 | wpb 510.9 | bsz 1 | num_updates 11465 | best_loss 7.981
2022-03-06 22:18:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 11465 updates
2022-03-06 22:18:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:18:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:18:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 119 @ 11465 updates, score 12.4) (writing took 2.546707716304809 seconds)
2022-03-06 22:18:39 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 22:18:39 | INFO | train | epoch 119 | loss 2.378 | nll_loss 1.359 | ppl 2.57 | wps 22028.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11465 | lr 0.000295334 | gnorm 0.995 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 34031
2022-03-06 22:18:39 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 22:18:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:20:19 | INFO | train_inner | epoch 120:     35 / 97 loss=2.375, nll_loss=1.356, ppl=2.56, wps=22078.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=11500, lr=0.000294884, gnorm=1, loss_scale=16, train_wall=266, gb_free=8.1, wall=34131
2022-03-06 22:23:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:23:22 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 12.389 | nll_loss 11.841 | ppl 3667.65 | wps 42302.5 | wpb 510.9 | bsz 1 | num_updates 11562 | best_loss 7.981
2022-03-06 22:23:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 11562 updates
2022-03-06 22:23:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:23:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:23:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 120 @ 11562 updates, score 12.389) (writing took 2.350507487077266 seconds)
2022-03-06 22:23:24 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 22:23:24 | INFO | train | epoch 120 | loss 2.367 | nll_loss 1.347 | ppl 2.54 | wps 22255 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11562 | lr 0.000294092 | gnorm 0.991 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 34316
2022-03-06 22:23:24 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 22:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:24:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:25:16 | INFO | train_inner | epoch 121:     39 / 97 loss=2.36, nll_loss=1.34, ppl=2.53, wps=22041.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=11600, lr=0.00029361, gnorm=0.985, loss_scale=16, train_wall=266, gb_free=8.1, wall=34428
2022-03-06 22:28:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:28:07 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 12.437 | nll_loss 11.891 | ppl 3799.02 | wps 42468.4 | wpb 510.9 | bsz 1 | num_updates 11658 | best_loss 7.981
2022-03-06 22:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 11658 updates
2022-03-06 22:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:28:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:28:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 121 @ 11658 updates, score 12.437) (writing took 2.285277344752103 seconds)
2022-03-06 22:28:09 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 22:28:09 | INFO | train | epoch 121 | loss 2.356 | nll_loss 1.336 | ppl 2.52 | wps 22034.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11658 | lr 0.000292879 | gnorm 0.983 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 34601
2022-03-06 22:28:09 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 22:28:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:30:10 | INFO | train_inner | epoch 122:     42 / 97 loss=2.354, nll_loss=1.334, ppl=2.52, wps=22287.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11700, lr=0.000292353, gnorm=0.984, loss_scale=16, train_wall=263, gb_free=8.1, wall=34722
2022-03-06 22:30:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:32:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:32:53 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 12.488 | nll_loss 11.946 | ppl 3946.43 | wps 42230.9 | wpb 510.9 | bsz 1 | num_updates 11754 | best_loss 7.981
2022-03-06 22:32:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 11754 updates
2022-03-06 22:32:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:32:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:32:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 122 @ 11754 updates, score 12.488) (writing took 2.296415463555604 seconds)
2022-03-06 22:32:55 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 22:32:55 | INFO | train | epoch 122 | loss 2.347 | nll_loss 1.326 | ppl 2.51 | wps 22028.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11754 | lr 0.00029168 | gnorm 0.992 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 34887
2022-03-06 22:32:55 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 22:32:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:35:07 | INFO | train_inner | epoch 123:     46 / 97 loss=2.341, nll_loss=1.32, ppl=2.5, wps=22064.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=11800, lr=0.000291111, gnorm=0.986, loss_scale=16, train_wall=266, gb_free=8.1, wall=35019
2022-03-06 22:37:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:37:38 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 12.456 | nll_loss 11.913 | ppl 3856.02 | wps 42214.2 | wpb 510.9 | bsz 1 | num_updates 11851 | best_loss 7.981
2022-03-06 22:37:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 11851 updates
2022-03-06 22:37:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:37:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:37:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 123 @ 11851 updates, score 12.456) (writing took 2.4268511151894927 seconds)
2022-03-06 22:37:40 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 22:37:40 | INFO | train | epoch 123 | loss 2.338 | nll_loss 1.317 | ppl 2.49 | wps 22258 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11851 | lr 0.000290484 | gnorm 0.988 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 35172
2022-03-06 22:37:40 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 22:37:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:38:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:40:04 | INFO | train_inner | epoch 124:     50 / 97 loss=2.335, nll_loss=1.313, ppl=2.48, wps=22064.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=11900, lr=0.000289886, gnorm=0.987, loss_scale=16, train_wall=266, gb_free=8.1, wall=35315
2022-03-06 22:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:42:23 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 12.487 | nll_loss 11.946 | ppl 3944.5 | wps 42578.1 | wpb 510.9 | bsz 1 | num_updates 11947 | best_loss 7.981
2022-03-06 22:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 11947 updates
2022-03-06 22:42:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:42:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 124 @ 11947 updates, score 12.487) (writing took 2.218613150063902 seconds)
2022-03-06 22:42:25 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 22:42:25 | INFO | train | epoch 124 | loss 2.327 | nll_loss 1.305 | ppl 2.47 | wps 22054.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11947 | lr 0.000289315 | gnorm 0.983 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 35457
2022-03-06 22:42:25 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 22:42:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:44:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:45:00 | INFO | train_inner | epoch 125:     54 / 97 loss=2.323, nll_loss=1.3, ppl=2.46, wps=22079, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=12000, lr=0.000288675, gnorm=0.992, loss_scale=16, train_wall=266, gb_free=8.1, wall=35612
2022-03-06 22:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:47:08 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 12.516 | nll_loss 11.971 | ppl 4013.74 | wps 42483.6 | wpb 510.9 | bsz 1 | num_updates 12043 | best_loss 7.981
2022-03-06 22:47:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12043 updates
2022-03-06 22:47:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:47:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:47:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 125 @ 12043 updates, score 12.516) (writing took 2.235068950802088 seconds)
2022-03-06 22:47:11 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 22:47:11 | INFO | train | epoch 125 | loss 2.317 | nll_loss 1.294 | ppl 2.45 | wps 22039.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12043 | lr 0.000288159 | gnorm 0.99 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 35742
2022-03-06 22:47:11 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 22:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:49:54 | INFO | train_inner | epoch 126:     57 / 97 loss=2.311, nll_loss=1.288, ppl=2.44, wps=22292.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12100, lr=0.00028748, gnorm=0.987, loss_scale=16, train_wall=263, gb_free=8.1, wall=35906
2022-03-06 22:51:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:51:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:51:54 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 12.518 | nll_loss 11.978 | ppl 4034.08 | wps 42436.3 | wpb 510.9 | bsz 1 | num_updates 12139 | best_loss 7.981
2022-03-06 22:51:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12139 updates
2022-03-06 22:51:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:51:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:51:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 126 @ 12139 updates, score 12.518) (writing took 2.467718344181776 seconds)
2022-03-06 22:51:56 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 22:51:56 | INFO | train | epoch 126 | loss 2.309 | nll_loss 1.285 | ppl 2.44 | wps 22018.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12139 | lr 0.000287018 | gnorm 0.985 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 36028
2022-03-06 22:51:56 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 22:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:54:51 | INFO | train_inner | epoch 127:     61 / 97 loss=2.303, nll_loss=1.279, ppl=2.43, wps=22028.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12200, lr=0.000286299, gnorm=0.98, loss_scale=16, train_wall=266, gb_free=8.1, wall=36203
2022-03-06 22:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:56:39 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 12.56 | nll_loss 12.021 | ppl 4155.79 | wps 42579.9 | wpb 510.9 | bsz 1 | num_updates 12236 | best_loss 7.981
2022-03-06 22:56:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 12236 updates
2022-03-06 22:56:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:56:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 127 @ 12236 updates, score 12.56) (writing took 2.3305557910352945 seconds)
2022-03-06 22:56:42 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 22:56:42 | INFO | train | epoch 127 | loss 2.301 | nll_loss 1.277 | ppl 2.42 | wps 22237.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12236 | lr 0.000285878 | gnorm 0.984 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 36314
2022-03-06 22:56:42 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 22:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:59:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:59:48 | INFO | train_inner | epoch 128:     65 / 97 loss=2.298, nll_loss=1.273, ppl=2.42, wps=22055.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12300, lr=0.000285133, gnorm=0.988, loss_scale=16, train_wall=266, gb_free=8.1, wall=36500
2022-03-06 23:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:01:25 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 12.521 | nll_loss 11.983 | ppl 4047.32 | wps 42292.8 | wpb 510.9 | bsz 1 | num_updates 12332 | best_loss 7.981
2022-03-06 23:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 12332 updates
2022-03-06 23:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:01:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:01:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 128 @ 12332 updates, score 12.521) (writing took 2.3092758948914707 seconds)
2022-03-06 23:01:27 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 23:01:27 | INFO | train | epoch 128 | loss 2.291 | nll_loss 1.266 | ppl 2.41 | wps 22021.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12332 | lr 0.000284763 | gnorm 0.988 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 36599
2022-03-06 23:01:27 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 23:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:04:42 | INFO | train_inner | epoch 129:     68 / 97 loss=2.285, nll_loss=1.26, ppl=2.39, wps=22271, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12400, lr=0.000283981, gnorm=0.982, loss_scale=16, train_wall=263, gb_free=8.1, wall=36794
2022-03-06 23:06:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:06:10 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 12.526 | nll_loss 11.992 | ppl 4072.52 | wps 42606.9 | wpb 510.9 | bsz 1 | num_updates 12429 | best_loss 7.981
2022-03-06 23:06:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 12429 updates
2022-03-06 23:06:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:06:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:06:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 129 @ 12429 updates, score 12.526) (writing took 2.327099619898945 seconds)
2022-03-06 23:06:13 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 23:06:13 | INFO | train | epoch 129 | loss 2.282 | nll_loss 1.257 | ppl 2.39 | wps 22260.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12429 | lr 0.000283649 | gnorm 0.97 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 36885
2022-03-06 23:06:13 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 23:06:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:06:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:09:39 | INFO | train_inner | epoch 130:     72 / 97 loss=2.278, nll_loss=1.253, ppl=2.38, wps=22068.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=12500, lr=0.000282843, gnorm=0.98, loss_scale=16, train_wall=266, gb_free=8.1, wall=37091
2022-03-06 23:10:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:10:56 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 12.571 | nll_loss 12.037 | ppl 4201.4 | wps 42838.3 | wpb 510.9 | bsz 1 | num_updates 12525 | best_loss 7.981
2022-03-06 23:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 12525 updates
2022-03-06 23:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:10:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:10:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 130 @ 12525 updates, score 12.571) (writing took 2.2949576801620424 seconds)
2022-03-06 23:10:58 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 23:10:58 | INFO | train | epoch 130 | loss 2.274 | nll_loss 1.248 | ppl 2.37 | wps 22048.6 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 12525 | lr 0.00028256 | gnorm 0.987 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 37170
2022-03-06 23:10:58 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 23:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:12:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:14:36 | INFO | train_inner | epoch 131:     76 / 97 loss=2.265, nll_loss=1.239, ppl=2.36, wps=22073.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12600, lr=0.000281718, gnorm=0.97, loss_scale=16, train_wall=266, gb_free=8.1, wall=37388
2022-03-06 23:15:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:15:41 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 12.575 | nll_loss 12.037 | ppl 4201.35 | wps 42412.9 | wpb 510.9 | bsz 1 | num_updates 12621 | best_loss 7.981
2022-03-06 23:15:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 12621 updates
2022-03-06 23:15:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:15:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:15:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 131 @ 12621 updates, score 12.575) (writing took 2.2025676798075438 seconds)
2022-03-06 23:15:43 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 23:15:43 | INFO | train | epoch 131 | loss 2.264 | nll_loss 1.237 | ppl 2.36 | wps 22037.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12621 | lr 0.000281484 | gnorm 0.968 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 37455
2022-03-06 23:15:43 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 23:15:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:19:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:19:33 | INFO | train_inner | epoch 132:     80 / 97 loss=2.26, nll_loss=1.234, ppl=2.35, wps=22065.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12700, lr=0.000280607, gnorm=0.984, loss_scale=16, train_wall=266, gb_free=8.1, wall=37684
2022-03-06 23:20:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:20:26 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 12.618 | nll_loss 12.081 | ppl 4333.6 | wps 42559.6 | wpb 510.9 | bsz 1 | num_updates 12717 | best_loss 7.981
2022-03-06 23:20:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 12717 updates
2022-03-06 23:20:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:20:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:20:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 132 @ 12717 updates, score 12.618) (writing took 2.355423355009407 seconds)
2022-03-06 23:20:29 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 23:20:29 | INFO | train | epoch 132 | loss 2.258 | nll_loss 1.231 | ppl 2.35 | wps 22019.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12717 | lr 0.000280419 | gnorm 0.982 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 37741
2022-03-06 23:20:29 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 23:20:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:24:27 | INFO | train_inner | epoch 133:     83 / 97 loss=2.253, nll_loss=1.227, ppl=2.34, wps=22261.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12800, lr=0.000279508, gnorm=0.978, loss_scale=16, train_wall=264, gb_free=8.1, wall=37979
2022-03-06 23:25:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:25:12 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 12.611 | nll_loss 12.078 | ppl 4323.32 | wps 42107.7 | wpb 510.9 | bsz 1 | num_updates 12814 | best_loss 7.981
2022-03-06 23:25:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 12814 updates
2022-03-06 23:25:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:25:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:25:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 133 @ 12814 updates, score 12.611) (writing took 2.3187161032110453 seconds)
2022-03-06 23:25:14 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 23:25:14 | INFO | train | epoch 133 | loss 2.249 | nll_loss 1.222 | ppl 2.33 | wps 22240.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12814 | lr 0.000279356 | gnorm 0.982 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 38026
2022-03-06 23:25:14 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 23:25:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:26:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:29:24 | INFO | train_inner | epoch 134:     87 / 97 loss=2.242, nll_loss=1.215, ppl=2.32, wps=22053.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12900, lr=0.000278423, gnorm=0.965, loss_scale=16, train_wall=266, gb_free=8.1, wall=38276
2022-03-06 23:29:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:29:57 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 12.629 | nll_loss 12.096 | ppl 4377.45 | wps 42538.7 | wpb 510.9 | bsz 1 | num_updates 12910 | best_loss 7.981
2022-03-06 23:29:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 12910 updates
2022-03-06 23:29:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:30:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:30:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 134 @ 12910 updates, score 12.629) (writing took 2.2945588366128504 seconds)
2022-03-06 23:30:00 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 23:30:00 | INFO | train | epoch 134 | loss 2.24 | nll_loss 1.213 | ppl 2.32 | wps 22030.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12910 | lr 0.000278315 | gnorm 0.96 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 38312
2022-03-06 23:30:00 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 23:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:32:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:34:20 | INFO | train_inner | epoch 135:     91 / 97 loss=2.236, nll_loss=1.208, ppl=2.31, wps=22073.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13000, lr=0.00027735, gnorm=0.969, loss_scale=16, train_wall=266, gb_free=8.1, wall=38572
2022-03-06 23:34:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:34:43 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 12.65 | nll_loss 12.119 | ppl 4448.32 | wps 42501.5 | wpb 510.9 | bsz 1 | num_updates 13006 | best_loss 7.981
2022-03-06 23:34:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13006 updates
2022-03-06 23:34:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:34:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:34:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 135 @ 13006 updates, score 12.65) (writing took 2.303505656775087 seconds)
2022-03-06 23:34:45 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 23:34:45 | INFO | train | epoch 135 | loss 2.233 | nll_loss 1.205 | ppl 2.31 | wps 22040.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13006 | lr 0.000277286 | gnorm 0.969 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 38597
2022-03-06 23:34:45 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 23:34:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:38:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:39:17 | INFO | train_inner | epoch 136:     95 / 97 loss=2.228, nll_loss=1.199, ppl=2.3, wps=22069.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13100, lr=0.000276289, gnorm=0.978, loss_scale=16, train_wall=266, gb_free=8.1, wall=38869
2022-03-06 23:39:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:39:28 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 12.693 | nll_loss 12.166 | ppl 4596.01 | wps 42412.3 | wpb 510.9 | bsz 1 | num_updates 13102 | best_loss 7.981
2022-03-06 23:39:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13102 updates
2022-03-06 23:39:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:39:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:39:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 136 @ 13102 updates, score 12.693) (writing took 2.2411971669644117 seconds)
2022-03-06 23:39:30 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 23:39:30 | INFO | train | epoch 136 | loss 2.226 | nll_loss 1.197 | ppl 2.29 | wps 22040.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13102 | lr 0.000276268 | gnorm 0.977 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 38882
2022-03-06 23:39:30 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 23:39:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:44:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:44:13 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 12.646 | nll_loss 12.113 | ppl 4428.73 | wps 42294.9 | wpb 510.9 | bsz 1 | num_updates 13199 | best_loss 7.981
2022-03-06 23:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 13199 updates
2022-03-06 23:44:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:44:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 137 @ 13199 updates, score 12.646) (writing took 2.253233664203435 seconds)
2022-03-06 23:44:15 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 23:44:15 | INFO | train | epoch 137 | loss 2.218 | nll_loss 1.189 | ppl 2.28 | wps 22266.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13199 | lr 0.000275251 | gnorm 0.965 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 39167
2022-03-06 23:44:15 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 23:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:44:18 | INFO | train_inner | epoch 138:      1 / 97 loss=2.218, nll_loss=1.189, ppl=2.28, wps=21727.8, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=13200, lr=0.000275241, gnorm=0.966, loss_scale=16, train_wall=263, gb_free=8.1, wall=39170
2022-03-06 23:46:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:48:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:48:58 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 12.699 | nll_loss 12.175 | ppl 4625.48 | wps 42436.6 | wpb 510.9 | bsz 1 | num_updates 13295 | best_loss 7.981
2022-03-06 23:48:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 13295 updates
2022-03-06 23:48:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:49:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:49:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 138 @ 13295 updates, score 12.699) (writing took 2.3032369851134717 seconds)
2022-03-06 23:49:01 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 23:49:01 | INFO | train | epoch 138 | loss 2.21 | nll_loss 1.181 | ppl 2.27 | wps 22046.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13295 | lr 0.000274256 | gnorm 0.962 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 39453
2022-03-06 23:49:01 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 23:49:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:49:15 | INFO | train_inner | epoch 139:      5 / 97 loss=2.208, nll_loss=1.178, ppl=2.26, wps=22079.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13300, lr=0.000274204, gnorm=0.961, loss_scale=16, train_wall=266, gb_free=8.1, wall=39467
2022-03-06 23:52:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:53:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:53:44 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 12.689 | nll_loss 12.154 | ppl 4558.94 | wps 42514.8 | wpb 510.9 | bsz 1 | num_updates 13391 | best_loss 7.981
2022-03-06 23:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 13391 updates
2022-03-06 23:53:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:53:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:53:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 139 @ 13391 updates, score 12.689) (writing took 2.286423758137971 seconds)
2022-03-06 23:53:46 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 23:53:46 | INFO | train | epoch 139 | loss 2.205 | nll_loss 1.175 | ppl 2.26 | wps 22013 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13391 | lr 0.000273271 | gnorm 0.966 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 39738
2022-03-06 23:53:46 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 23:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:54:12 | INFO | train_inner | epoch 140:      9 / 97 loss=2.202, nll_loss=1.172, ppl=2.25, wps=22041.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13400, lr=0.000273179, gnorm=0.966, loss_scale=16, train_wall=266, gb_free=8.1, wall=39764
2022-03-06 23:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:58:29 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 12.731 | nll_loss 12.207 | ppl 4727.34 | wps 42754.4 | wpb 510.9 | bsz 1 | num_updates 13488 | best_loss 7.981
2022-03-06 23:58:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 13488 updates
2022-03-06 23:58:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:58:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:58:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 140 @ 13488 updates, score 12.731) (writing took 2.34752213768661 seconds)
2022-03-06 23:58:32 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 23:58:32 | INFO | train | epoch 140 | loss 2.195 | nll_loss 1.164 | ppl 2.24 | wps 22266.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13488 | lr 0.000272287 | gnorm 0.977 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 40023
2022-03-06 23:58:32 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 23:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:59:06 | INFO | train_inner | epoch 141:     12 / 97 loss=2.194, nll_loss=1.164, ppl=2.24, wps=22286.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13500, lr=0.000272166, gnorm=0.974, loss_scale=32, train_wall=263, gb_free=8.1, wall=40058
2022-03-06 23:59:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:03:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:03:15 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 12.717 | nll_loss 12.187 | ppl 4663.04 | wps 42409.5 | wpb 510.9 | bsz 1 | num_updates 13584 | best_loss 7.981
2022-03-07 00:03:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 13584 updates
2022-03-07 00:03:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:03:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:03:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 141 @ 13584 updates, score 12.717) (writing took 2.3297085375525057 seconds)
2022-03-07 00:03:17 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-07 00:03:17 | INFO | train | epoch 141 | loss 2.188 | nll_loss 1.158 | ppl 2.23 | wps 22028.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13584 | lr 0.000271323 | gnorm 0.959 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 40309
2022-03-07 00:03:17 | INFO | fairseq.trainer | begin training epoch 142
2022-03-07 00:03:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:04:03 | INFO | train_inner | epoch 142:     16 / 97 loss=2.186, nll_loss=1.155, ppl=2.23, wps=22060.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13600, lr=0.000271163, gnorm=0.96, loss_scale=16, train_wall=266, gb_free=8.1, wall=40355
2022-03-07 00:06:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:07:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:08:00 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 12.787 | nll_loss 12.268 | ppl 4931.87 | wps 42446.3 | wpb 510.9 | bsz 1 | num_updates 13680 | best_loss 7.981
2022-03-07 00:08:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 13680 updates
2022-03-07 00:08:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:08:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 142 @ 13680 updates, score 12.787) (writing took 2.2804313455708325 seconds)
2022-03-07 00:08:02 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-07 00:08:02 | INFO | train | epoch 142 | loss 2.183 | nll_loss 1.152 | ppl 2.22 | wps 22047.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13680 | lr 0.000270369 | gnorm 0.959 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 40594
2022-03-07 00:08:02 | INFO | fairseq.trainer | begin training epoch 143
2022-03-07 00:08:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:09:00 | INFO | train_inner | epoch 143:     20 / 97 loss=2.18, nll_loss=1.149, ppl=2.22, wps=22075.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13700, lr=0.000270172, gnorm=0.961, loss_scale=16, train_wall=266, gb_free=8.1, wall=40652
2022-03-07 00:12:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:12:45 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 12.713 | nll_loss 12.187 | ppl 4662.77 | wps 42815 | wpb 510.9 | bsz 1 | num_updates 13777 | best_loss 7.981
2022-03-07 00:12:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 13777 updates
2022-03-07 00:12:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:12:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:12:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 143 @ 13777 updates, score 12.713) (writing took 2.225038147997111 seconds)
2022-03-07 00:12:48 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-07 00:12:48 | INFO | train | epoch 143 | loss 2.176 | nll_loss 1.144 | ppl 2.21 | wps 22258 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13777 | lr 0.000269416 | gnorm 0.958 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 40879
2022-03-07 00:12:48 | INFO | fairseq.trainer | begin training epoch 144
2022-03-07 00:12:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:13:54 | INFO | train_inner | epoch 144:     23 / 97 loss=2.172, nll_loss=1.141, ppl=2.2, wps=22283.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13800, lr=0.000269191, gnorm=0.955, loss_scale=32, train_wall=263, gb_free=8.1, wall=40945
2022-03-07 00:14:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:17:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:17:31 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 12.796 | nll_loss 12.27 | ppl 4938.79 | wps 42291.2 | wpb 510.9 | bsz 1 | num_updates 13873 | best_loss 7.981
2022-03-07 00:17:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 13873 updates
2022-03-07 00:17:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:17:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 144 @ 13873 updates, score 12.796) (writing took 2.281714770011604 seconds)
2022-03-07 00:17:33 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-07 00:17:33 | INFO | train | epoch 144 | loss 2.17 | nll_loss 1.138 | ppl 2.2 | wps 22033.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13873 | lr 0.000268482 | gnorm 0.972 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 41165
2022-03-07 00:17:33 | INFO | fairseq.trainer | begin training epoch 145
2022-03-07 00:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:18:50 | INFO | train_inner | epoch 145:     27 / 97 loss=2.167, nll_loss=1.135, ppl=2.2, wps=22057.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13900, lr=0.000268221, gnorm=0.972, loss_scale=16, train_wall=266, gb_free=8.1, wall=41242
2022-03-07 00:20:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:22:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:22:16 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 12.771 | nll_loss 12.247 | ppl 4859.48 | wps 42242.1 | wpb 510.9 | bsz 1 | num_updates 13969 | best_loss 7.981
2022-03-07 00:22:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 13969 updates
2022-03-07 00:22:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:22:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 145 @ 13969 updates, score 12.771) (writing took 2.3761805072426796 seconds)
2022-03-07 00:22:19 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-07 00:22:19 | INFO | train | epoch 145 | loss 2.161 | nll_loss 1.129 | ppl 2.19 | wps 22007.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13969 | lr 0.000267558 | gnorm 0.962 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 41450
2022-03-07 00:22:19 | INFO | fairseq.trainer | begin training epoch 146
2022-03-07 00:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:23:48 | INFO | train_inner | epoch 146:     31 / 97 loss=2.159, nll_loss=1.127, ppl=2.18, wps=22041.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14000, lr=0.000267261, gnorm=0.951, loss_scale=16, train_wall=266, gb_free=8.1, wall=41539
2022-03-07 00:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:27:02 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 12.782 | nll_loss 12.26 | ppl 4903.37 | wps 42192.6 | wpb 510.9 | bsz 1 | num_updates 14066 | best_loss 7.981
2022-03-07 00:27:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 14066 updates
2022-03-07 00:27:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:27:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:27:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 146 @ 14066 updates, score 12.782) (writing took 2.293236882891506 seconds)
2022-03-07 00:27:04 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-07 00:27:04 | INFO | train | epoch 146 | loss 2.155 | nll_loss 1.123 | ppl 2.18 | wps 22248.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14066 | lr 0.000266633 | gnorm 0.955 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 41736
2022-03-07 00:27:04 | INFO | fairseq.trainer | begin training epoch 147
2022-03-07 00:27:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:27:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:28:45 | INFO | train_inner | epoch 147:     35 / 97 loss=2.153, nll_loss=1.121, ppl=2.17, wps=22052.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14100, lr=0.000266312, gnorm=0.965, loss_scale=16, train_wall=266, gb_free=8.1, wall=41836
2022-03-07 00:31:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:31:47 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 12.742 | nll_loss 12.216 | ppl 4758.96 | wps 42266.3 | wpb 510.9 | bsz 1 | num_updates 14162 | best_loss 7.981
2022-03-07 00:31:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 14162 updates
2022-03-07 00:31:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:31:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:31:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 147 @ 14162 updates, score 12.742) (writing took 2.2119279569014907 seconds)
2022-03-07 00:31:50 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-07 00:31:50 | INFO | train | epoch 147 | loss 2.148 | nll_loss 1.115 | ppl 2.17 | wps 22024.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14162 | lr 0.000265728 | gnorm 0.951 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 42021
2022-03-07 00:31:50 | INFO | fairseq.trainer | begin training epoch 148
2022-03-07 00:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:33:39 | INFO | train_inner | epoch 148:     38 / 97 loss=2.145, nll_loss=1.112, ppl=2.16, wps=22274.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14200, lr=0.000265372, gnorm=0.953, loss_scale=32, train_wall=264, gb_free=8.1, wall=42130
2022-03-07 00:33:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:36:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:36:33 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 12.766 | nll_loss 12.237 | ppl 4828.83 | wps 42609.6 | wpb 510.9 | bsz 1 | num_updates 14258 | best_loss 7.981
2022-03-07 00:36:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 14258 updates
2022-03-07 00:36:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:36:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:36:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 148 @ 14258 updates, score 12.766) (writing took 2.2312381812371314 seconds)
2022-03-07 00:36:35 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-07 00:36:35 | INFO | train | epoch 148 | loss 2.142 | nll_loss 1.109 | ppl 2.16 | wps 22040.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14258 | lr 0.000264832 | gnorm 0.959 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 42307
2022-03-07 00:36:35 | INFO | fairseq.trainer | begin training epoch 149
2022-03-07 00:36:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:38:35 | INFO | train_inner | epoch 149:     42 / 97 loss=2.139, nll_loss=1.106, ppl=2.15, wps=22069.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14300, lr=0.000264443, gnorm=0.953, loss_scale=16, train_wall=266, gb_free=8.1, wall=42427
2022-03-07 00:40:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:41:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:41:18 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 12.785 | nll_loss 12.264 | ppl 4918.2 | wps 42797.3 | wpb 510.9 | bsz 1 | num_updates 14354 | best_loss 7.981
2022-03-07 00:41:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 14354 updates
2022-03-07 00:41:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:41:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:41:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 149 @ 14354 updates, score 12.785) (writing took 2.2939301249571145 seconds)
2022-03-07 00:41:20 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-07 00:41:20 | INFO | train | epoch 149 | loss 2.136 | nll_loss 1.103 | ppl 2.15 | wps 22033.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14354 | lr 0.000263945 | gnorm 0.948 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 42592
2022-03-07 00:41:20 | INFO | fairseq.trainer | begin training epoch 150
2022-03-07 00:41:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:43:32 | INFO | train_inner | epoch 150:     46 / 97 loss=2.134, nll_loss=1.101, ppl=2.14, wps=22078.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=14400, lr=0.000263523, gnorm=0.945, loss_scale=16, train_wall=266, gb_free=8.1, wall=42724
2022-03-07 00:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:46:03 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 12.789 | nll_loss 12.264 | ppl 4917.52 | wps 42274.7 | wpb 510.9 | bsz 1 | num_updates 14451 | best_loss 7.981
2022-03-07 00:46:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 14451 updates
2022-03-07 00:46:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:46:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:46:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 150 @ 14451 updates, score 12.789) (writing took 2.244490215089172 seconds)
2022-03-07 00:46:05 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-07 00:46:05 | INFO | train | epoch 150 | loss 2.131 | nll_loss 1.098 | ppl 2.14 | wps 22270.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14451 | lr 0.000263058 | gnorm 0.95 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 42877
2022-03-07 00:46:05 | INFO | fairseq.trainer | begin training epoch 151
2022-03-07 00:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:47:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:48:29 | INFO | train_inner | epoch 151:     50 / 97 loss=2.128, nll_loss=1.094, ppl=2.14, wps=22060.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14500, lr=0.000262613, gnorm=0.955, loss_scale=16, train_wall=266, gb_free=8.1, wall=43021
2022-03-07 00:50:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:50:49 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 12.798 | nll_loss 12.278 | ppl 4965.79 | wps 42243.8 | wpb 510.9 | bsz 1 | num_updates 14547 | best_loss 7.981
2022-03-07 00:50:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 14547 updates
2022-03-07 00:50:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:50:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:50:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 151 @ 14547 updates, score 12.798) (writing took 2.332249823026359 seconds)
2022-03-07 00:50:51 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-07 00:50:51 | INFO | train | epoch 151 | loss 2.124 | nll_loss 1.09 | ppl 2.13 | wps 22017.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14547 | lr 0.000262188 | gnorm 0.951 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 43163
2022-03-07 00:50:51 | INFO | fairseq.trainer | begin training epoch 152
2022-03-07 00:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:53:23 | INFO | train_inner | epoch 152:     53 / 97 loss=2.121, nll_loss=1.087, ppl=2.12, wps=22261.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=14600, lr=0.000261712, gnorm=0.938, loss_scale=16, train_wall=264, gb_free=8.1, wall=43315
2022-03-07 00:53:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:55:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:55:34 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 12.782 | nll_loss 12.265 | ppl 4921.68 | wps 42352 | wpb 510.9 | bsz 1 | num_updates 14643 | best_loss 7.981
2022-03-07 00:55:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 14643 updates
2022-03-07 00:55:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:55:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:55:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 152 @ 14643 updates, score 12.782) (writing took 2.23721923539415 seconds)
2022-03-07 00:55:36 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-07 00:55:36 | INFO | train | epoch 152 | loss 2.118 | nll_loss 1.084 | ppl 2.12 | wps 22025.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14643 | lr 0.000261327 | gnorm 0.947 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 43448
2022-03-07 00:55:36 | INFO | fairseq.trainer | begin training epoch 153
2022-03-07 00:55:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:58:20 | INFO | train_inner | epoch 153:     57 / 97 loss=2.115, nll_loss=1.081, ppl=2.12, wps=22060.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14700, lr=0.00026082, gnorm=0.953, loss_scale=16, train_wall=266, gb_free=8.1, wall=43612
2022-03-07 01:00:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:00:19 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 12.788 | nll_loss 12.267 | ppl 4927.12 | wps 42364.7 | wpb 510.9 | bsz 1 | num_updates 14740 | best_loss 7.981
2022-03-07 01:00:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 14740 updates
2022-03-07 01:00:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:00:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:00:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 153 @ 14740 updates, score 12.788) (writing took 2.3295059856027365 seconds)
2022-03-07 01:00:22 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-07 01:00:22 | INFO | train | epoch 153 | loss 2.113 | nll_loss 1.078 | ppl 2.11 | wps 22260.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14740 | lr 0.000260466 | gnorm 0.941 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 43734
2022-03-07 01:00:22 | INFO | fairseq.trainer | begin training epoch 154
2022-03-07 01:00:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:01:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:03:17 | INFO | train_inner | epoch 154:     61 / 97 loss=2.109, nll_loss=1.074, ppl=2.11, wps=22066.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14800, lr=0.000259938, gnorm=0.94, loss_scale=16, train_wall=266, gb_free=8.1, wall=43909
2022-03-07 01:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:05:05 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 12.766 | nll_loss 12.242 | ppl 4844.52 | wps 42287.6 | wpb 510.9 | bsz 1 | num_updates 14836 | best_loss 7.981
2022-03-07 01:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 14836 updates
2022-03-07 01:05:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:05:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 154 @ 14836 updates, score 12.766) (writing took 2.347127172164619 seconds)
2022-03-07 01:05:07 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-07 01:05:07 | INFO | train | epoch 154 | loss 2.107 | nll_loss 1.072 | ppl 2.1 | wps 22030 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14836 | lr 0.000259622 | gnorm 0.94 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 44019
2022-03-07 01:05:07 | INFO | fairseq.trainer | begin training epoch 155
2022-03-07 01:05:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:07:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:08:14 | INFO | train_inner | epoch 155:     65 / 97 loss=2.105, nll_loss=1.07, ppl=2.1, wps=22063.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14900, lr=0.000259064, gnorm=0.945, loss_scale=16, train_wall=266, gb_free=8.1, wall=44205
2022-03-07 01:09:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:09:50 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 12.854 | nll_loss 12.335 | ppl 5167.79 | wps 42463.4 | wpb 510.9 | bsz 1 | num_updates 14932 | best_loss 7.981
2022-03-07 01:09:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 14932 updates
2022-03-07 01:09:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:09:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:09:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 155 @ 14932 updates, score 12.854) (writing took 2.219618492759764 seconds)
2022-03-07 01:09:52 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-07 01:09:52 | INFO | train | epoch 155 | loss 2.102 | nll_loss 1.067 | ppl 2.1 | wps 22043.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14932 | lr 0.000258786 | gnorm 0.945 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 44304
2022-03-07 01:09:52 | INFO | fairseq.trainer | begin training epoch 156
2022-03-07 01:09:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:13:07 | INFO | train_inner | epoch 156:     68 / 97 loss=2.097, nll_loss=1.062, ppl=2.09, wps=22285.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15000, lr=0.000258199, gnorm=0.943, loss_scale=16, train_wall=263, gb_free=8.1, wall=44499
2022-03-07 01:13:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:14:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:14:36 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 12.842 | nll_loss 12.32 | ppl 5111.7 | wps 42355.9 | wpb 510.9 | bsz 1 | num_updates 15028 | best_loss 7.981
2022-03-07 01:14:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 15028 updates
2022-03-07 01:14:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:14:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:14:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 156 @ 15028 updates, score 12.842) (writing took 2.2758813556283712 seconds)
2022-03-07 01:14:38 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-07 01:14:38 | INFO | train | epoch 156 | loss 2.096 | nll_loss 1.061 | ppl 2.09 | wps 22030.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15028 | lr 0.000257958 | gnorm 0.943 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 44590
2022-03-07 01:14:38 | INFO | fairseq.trainer | begin training epoch 157
2022-03-07 01:14:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:18:04 | INFO | train_inner | epoch 157:     72 / 97 loss=2.094, nll_loss=1.059, ppl=2.08, wps=22053.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=15100, lr=0.000257343, gnorm=0.934, loss_scale=16, train_wall=266, gb_free=8.1, wall=44796
2022-03-07 01:19:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:19:21 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 12.867 | nll_loss 12.349 | ppl 5217.64 | wps 42441.3 | wpb 510.9 | bsz 1 | num_updates 15125 | best_loss 7.981
2022-03-07 01:19:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 15125 updates
2022-03-07 01:19:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:19:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 157 @ 15125 updates, score 12.867) (writing took 2.3484415831044316 seconds)
2022-03-07 01:19:23 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-07 01:19:23 | INFO | train | epoch 157 | loss 2.091 | nll_loss 1.056 | ppl 2.08 | wps 22241.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15125 | lr 0.00025713 | gnorm 0.938 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 44875
2022-03-07 01:19:23 | INFO | fairseq.trainer | begin training epoch 158
2022-03-07 01:19:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:20:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:23:01 | INFO | train_inner | epoch 158:     76 / 97 loss=2.087, nll_loss=1.052, ppl=2.07, wps=22062.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=15200, lr=0.000256495, gnorm=0.944, loss_scale=16, train_wall=266, gb_free=8.1, wall=45093
2022-03-07 01:24:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:24:06 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 12.892 | nll_loss 12.376 | ppl 5316.36 | wps 42712.7 | wpb 510.9 | bsz 1 | num_updates 15221 | best_loss 7.981
2022-03-07 01:24:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 15221 updates
2022-03-07 01:24:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:24:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:24:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 158 @ 15221 updates, score 12.892) (writing took 2.2636707220226526 seconds)
2022-03-07 01:24:09 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-07 01:24:09 | INFO | train | epoch 158 | loss 2.083 | nll_loss 1.047 | ppl 2.07 | wps 22042.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15221 | lr 0.000256318 | gnorm 0.94 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 45161
2022-03-07 01:24:09 | INFO | fairseq.trainer | begin training epoch 159
2022-03-07 01:24:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:27:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:27:58 | INFO | train_inner | epoch 159:     80 / 97 loss=2.081, nll_loss=1.045, ppl=2.06, wps=22079.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=15300, lr=0.000255655, gnorm=0.935, loss_scale=16, train_wall=266, gb_free=8.1, wall=45390
2022-03-07 01:28:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:28:52 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 12.855 | nll_loss 12.337 | ppl 5172.52 | wps 42477.8 | wpb 510.9 | bsz 1 | num_updates 15317 | best_loss 7.981
2022-03-07 01:28:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 15317 updates
2022-03-07 01:28:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:28:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:28:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 159 @ 15317 updates, score 12.855) (writing took 2.3102109590545297 seconds)
2022-03-07 01:28:54 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-07 01:28:54 | INFO | train | epoch 159 | loss 2.08 | nll_loss 1.044 | ppl 2.06 | wps 22040.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15317 | lr 0.000255513 | gnorm 0.94 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 45446
2022-03-07 01:28:54 | INFO | fairseq.trainer | begin training epoch 160
2022-03-07 01:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:32:52 | INFO | train_inner | epoch 160:     83 / 97 loss=2.075, nll_loss=1.039, ppl=2.05, wps=22294.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=15400, lr=0.000254824, gnorm=0.945, loss_scale=16, train_wall=263, gb_free=8.1, wall=45684
2022-03-07 01:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:33:37 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 12.915 | nll_loss 12.4 | ppl 5404.11 | wps 42626.7 | wpb 510.9 | bsz 1 | num_updates 15414 | best_loss 7.981
2022-03-07 01:33:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 15414 updates
2022-03-07 01:33:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:33:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 160 @ 15414 updates, score 12.915) (writing took 2.256838051136583 seconds)
2022-03-07 01:33:39 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-07 01:33:39 | INFO | train | epoch 160 | loss 2.075 | nll_loss 1.039 | ppl 2.05 | wps 22283.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15414 | lr 0.000254708 | gnorm 0.939 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 45731
2022-03-07 01:33:39 | INFO | fairseq.trainer | begin training epoch 161
2022-03-07 01:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:36:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:37:48 | INFO | train_inner | epoch 161:     87 / 97 loss=2.073, nll_loss=1.037, ppl=2.05, wps=22088.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15500, lr=0.000254, gnorm=0.936, loss_scale=16, train_wall=266, gb_free=8.1, wall=45980
2022-03-07 01:38:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:38:22 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 12.869 | nll_loss 12.351 | ppl 5224.01 | wps 42676.5 | wpb 510.9 | bsz 1 | num_updates 15510 | best_loss 7.981
2022-03-07 01:38:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 15510 updates
2022-03-07 01:38:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:38:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:38:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 161 @ 15510 updates, score 12.869) (writing took 2.2562424722127616 seconds)
2022-03-07 01:38:24 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-07 01:38:24 | INFO | train | epoch 161 | loss 2.069 | nll_loss 1.033 | ppl 2.05 | wps 22057 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15510 | lr 0.000253918 | gnorm 0.932 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 46016
2022-03-07 01:38:24 | INFO | fairseq.trainer | begin training epoch 162
2022-03-07 01:38:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:42:42 | INFO | train_inner | epoch 162:     90 / 97 loss=2.067, nll_loss=1.03, ppl=2.04, wps=22282.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15600, lr=0.000253185, gnorm=0.949, loss_scale=32, train_wall=263, gb_free=8.1, wall=46274
2022-03-07 01:43:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:43:07 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 12.894 | nll_loss 12.384 | ppl 5344.83 | wps 42247.6 | wpb 510.9 | bsz 1 | num_updates 15607 | best_loss 7.981
2022-03-07 01:43:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 15607 updates
2022-03-07 01:43:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:43:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:43:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 162 @ 15607 updates, score 12.894) (writing took 2.3096034987829626 seconds)
2022-03-07 01:43:10 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-07 01:43:10 | INFO | train | epoch 162 | loss 2.064 | nll_loss 1.028 | ppl 2.04 | wps 22252.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15607 | lr 0.000253128 | gnorm 0.949 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 46301
2022-03-07 01:43:10 | INFO | fairseq.trainer | begin training epoch 163
2022-03-07 01:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:44:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:47:39 | INFO | train_inner | epoch 163:     94 / 97 loss=2.059, nll_loss=1.023, ppl=2.03, wps=22045.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15700, lr=0.000252377, gnorm=0.935, loss_scale=16, train_wall=266, gb_free=8.1, wall=46571
2022-03-07 01:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:47:53 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 12.944 | nll_loss 12.437 | ppl 5544.19 | wps 42583.7 | wpb 510.9 | bsz 1 | num_updates 15703 | best_loss 7.981
2022-03-07 01:47:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 15703 updates
2022-03-07 01:47:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:47:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:47:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 163 @ 15703 updates, score 12.944) (writing took 2.233240180183202 seconds)
2022-03-07 01:47:55 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-07 01:47:55 | INFO | train | epoch 163 | loss 2.057 | nll_loss 1.02 | ppl 2.03 | wps 22021.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15703 | lr 0.000252353 | gnorm 0.935 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 46587
2022-03-07 01:47:55 | INFO | fairseq.trainer | begin training epoch 164
2022-03-07 01:47:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:51:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:52:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:52:38 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 12.865 | nll_loss 12.352 | ppl 5228.5 | wps 42327.5 | wpb 510.9 | bsz 1 | num_updates 15799 | best_loss 7.981
2022-03-07 01:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 15799 updates
2022-03-07 01:52:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 164 @ 15799 updates, score 12.865) (writing took 2.3001781180500984 seconds)
2022-03-07 01:52:40 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-07 01:52:40 | INFO | train | epoch 164 | loss 2.055 | nll_loss 1.018 | ppl 2.03 | wps 22043.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15799 | lr 0.000251585 | gnorm 0.945 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 46872
2022-03-07 01:52:40 | INFO | fairseq.trainer | begin training epoch 165
2022-03-07 01:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:52:43 | INFO | train_inner | epoch 165:      1 / 97 loss=2.055, nll_loss=1.018, ppl=2.03, wps=21530.1, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=15800, lr=0.000251577, gnorm=0.945, loss_scale=16, train_wall=266, gb_free=8.1, wall=46875
2022-03-07 01:57:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:57:23 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 12.957 | nll_loss 12.446 | ppl 5581.57 | wps 42332.9 | wpb 510.9 | bsz 1 | num_updates 15896 | best_loss 7.981
2022-03-07 01:57:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 15896 updates
2022-03-07 01:57:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:57:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:57:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 165 @ 15896 updates, score 12.957) (writing took 2.3668518690392375 seconds)
2022-03-07 01:57:26 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-07 01:57:26 | INFO | train | epoch 165 | loss 2.049 | nll_loss 1.012 | ppl 2.02 | wps 22253.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15896 | lr 0.000250816 | gnorm 0.928 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 47158
2022-03-07 01:57:26 | INFO | fairseq.trainer | begin training epoch 166
2022-03-07 01:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:57:37 | INFO | train_inner | epoch 166:      4 / 97 loss=2.047, nll_loss=1.01, ppl=2.01, wps=22272.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15900, lr=0.000250785, gnorm=0.927, loss_scale=16, train_wall=263, gb_free=8.1, wall=47169
2022-03-07 01:58:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:02:09 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 12.905 | nll_loss 12.396 | ppl 5389.61 | wps 42707.5 | wpb 510.9 | bsz 1 | num_updates 15992 | best_loss 7.981
2022-03-07 02:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 15992 updates
2022-03-07 02:02:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:02:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 166 @ 15992 updates, score 12.905) (writing took 2.2422592560760677 seconds)
2022-03-07 02:02:11 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-07 02:02:11 | INFO | train | epoch 166 | loss 2.044 | nll_loss 1.006 | ppl 2.01 | wps 22027.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15992 | lr 0.000250063 | gnorm 0.93 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 47443
2022-03-07 02:02:11 | INFO | fairseq.trainer | begin training epoch 167
2022-03-07 02:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:02:34 | INFO | train_inner | epoch 167:      8 / 97 loss=2.043, nll_loss=1.006, ppl=2.01, wps=22062.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16000, lr=0.00025, gnorm=0.934, loss_scale=16, train_wall=266, gb_free=8.1, wall=47466
2022-03-07 02:05:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:06:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:06:54 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 12.947 | nll_loss 12.434 | ppl 5534.71 | wps 42496 | wpb 510.9 | bsz 1 | num_updates 16088 | best_loss 7.981
2022-03-07 02:06:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 16088 updates
2022-03-07 02:06:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:06:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:06:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 167 @ 16088 updates, score 12.947) (writing took 2.311083526816219 seconds)
2022-03-07 02:06:56 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-07 02:06:56 | INFO | train | epoch 167 | loss 2.04 | nll_loss 1.002 | ppl 2 | wps 22044 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16088 | lr 0.000249315 | gnorm 0.926 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 47728
2022-03-07 02:06:56 | INFO | fairseq.trainer | begin training epoch 168
2022-03-07 02:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:07:31 | INFO | train_inner | epoch 168:     12 / 97 loss=2.037, nll_loss=0.999, ppl=2, wps=22073, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16100, lr=0.000249222, gnorm=0.92, loss_scale=16, train_wall=266, gb_free=8.1, wall=47763
2022-03-07 02:11:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:11:40 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 12.989 | nll_loss 12.482 | ppl 5721.55 | wps 42094.2 | wpb 510.9 | bsz 1 | num_updates 16185 | best_loss 7.981
2022-03-07 02:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 16185 updates
2022-03-07 02:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 168 @ 16185 updates, score 12.989) (writing took 2.2157622510567307 seconds)
2022-03-07 02:11:42 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-07 02:11:42 | INFO | train | epoch 168 | loss 2.036 | nll_loss 0.998 | ppl 2 | wps 22256.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16185 | lr 0.000248567 | gnorm 0.924 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 48014
2022-03-07 02:11:42 | INFO | fairseq.trainer | begin training epoch 169
2022-03-07 02:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:12:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:12:28 | INFO | train_inner | epoch 169:     16 / 97 loss=2.034, nll_loss=0.996, ppl=2, wps=22062.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16200, lr=0.000248452, gnorm=0.923, loss_scale=16, train_wall=266, gb_free=8.1, wall=48060
2022-03-07 02:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:16:25 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 12.954 | nll_loss 12.445 | ppl 5576.97 | wps 42475.7 | wpb 510.9 | bsz 1 | num_updates 16281 | best_loss 7.981
2022-03-07 02:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 16281 updates
2022-03-07 02:16:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 169 @ 16281 updates, score 12.954) (writing took 2.2306717541068792 seconds)
2022-03-07 02:16:27 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-07 02:16:27 | INFO | train | epoch 169 | loss 2.031 | nll_loss 0.993 | ppl 1.99 | wps 22034.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16281 | lr 0.000247833 | gnorm 0.927 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 48299
2022-03-07 02:16:27 | INFO | fairseq.trainer | begin training epoch 170
2022-03-07 02:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:17:22 | INFO | train_inner | epoch 170:     19 / 97 loss=2.027, nll_loss=0.989, ppl=1.99, wps=22274.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=16300, lr=0.000247689, gnorm=0.922, loss_scale=16, train_wall=263, gb_free=8.1, wall=48354
2022-03-07 02:19:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:21:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:21:10 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 12.942 | nll_loss 12.43 | ppl 5517.83 | wps 42109.1 | wpb 510.9 | bsz 1 | num_updates 16377 | best_loss 7.981
2022-03-07 02:21:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 16377 updates
2022-03-07 02:21:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:21:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:21:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 170 @ 16377 updates, score 12.942) (writing took 2.2482485990040004 seconds)
2022-03-07 02:21:13 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-07 02:21:13 | INFO | train | epoch 170 | loss 2.026 | nll_loss 0.988 | ppl 1.98 | wps 22011.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16377 | lr 0.000247106 | gnorm 0.921 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 48585
2022-03-07 02:21:13 | INFO | fairseq.trainer | begin training epoch 171
2022-03-07 02:21:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:22:19 | INFO | train_inner | epoch 171:     23 / 97 loss=2.026, nll_loss=0.989, ppl=1.98, wps=22048.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=16400, lr=0.000246932, gnorm=0.926, loss_scale=16, train_wall=266, gb_free=8.1, wall=48651
2022-03-07 02:25:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:25:56 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 12.965 | nll_loss 12.458 | ppl 5626.87 | wps 42449.2 | wpb 510.9 | bsz 1 | num_updates 16474 | best_loss 7.981
2022-03-07 02:25:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 16474 updates
2022-03-07 02:25:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:25:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:25:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 171 @ 16474 updates, score 12.965) (writing took 2.270840667653829 seconds)
2022-03-07 02:25:58 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-07 02:25:58 | INFO | train | epoch 171 | loss 2.022 | nll_loss 0.984 | ppl 1.98 | wps 22265 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16474 | lr 0.000246377 | gnorm 0.935 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 48870
2022-03-07 02:25:58 | INFO | fairseq.trainer | begin training epoch 172
2022-03-07 02:25:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:27:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:27:15 | INFO | train_inner | epoch 172:     27 / 97 loss=2.017, nll_loss=0.979, ppl=1.97, wps=22074.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16500, lr=0.000246183, gnorm=0.928, loss_scale=16, train_wall=266, gb_free=8.1, wall=48947
2022-03-07 02:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:30:41 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 12.952 | nll_loss 12.438 | ppl 5549.4 | wps 42696.9 | wpb 510.9 | bsz 1 | num_updates 16570 | best_loss 7.981
2022-03-07 02:30:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 16570 updates
2022-03-07 02:30:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:30:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:30:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 172 @ 16570 updates, score 12.952) (writing took 2.246139156166464 seconds)
2022-03-07 02:30:43 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-07 02:30:43 | INFO | train | epoch 172 | loss 2.017 | nll_loss 0.979 | ppl 1.97 | wps 22058.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16570 | lr 0.000245662 | gnorm 0.93 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 49155
2022-03-07 02:30:43 | INFO | fairseq.trainer | begin training epoch 173
2022-03-07 02:30:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:32:09 | INFO | train_inner | epoch 173:     30 / 97 loss=2.016, nll_loss=0.979, ppl=1.97, wps=22296.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16600, lr=0.00024544, gnorm=0.935, loss_scale=16, train_wall=263, gb_free=8.1, wall=49241
2022-03-07 02:34:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:35:26 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 12.976 | nll_loss 12.469 | ppl 5667.96 | wps 42565 | wpb 510.9 | bsz 1 | num_updates 16666 | best_loss 7.981
2022-03-07 02:35:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 16666 updates
2022-03-07 02:35:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:35:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:35:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 173 @ 16666 updates, score 12.976) (writing took 2.2758038621395826 seconds)
2022-03-07 02:35:28 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-07 02:35:28 | INFO | train | epoch 173 | loss 2.013 | nll_loss 0.975 | ppl 1.97 | wps 22042.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16666 | lr 0.000244954 | gnorm 0.927 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 49440
2022-03-07 02:35:28 | INFO | fairseq.trainer | begin training epoch 174
2022-03-07 02:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:37:06 | INFO | train_inner | epoch 174:     34 / 97 loss=2.01, nll_loss=0.972, ppl=1.96, wps=22081.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16700, lr=0.000244704, gnorm=0.92, loss_scale=16, train_wall=266, gb_free=8.1, wall=49538
2022-03-07 02:40:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:40:11 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 12.982 | nll_loss 12.474 | ppl 5689.83 | wps 42648.9 | wpb 510.9 | bsz 1 | num_updates 16763 | best_loss 7.981
2022-03-07 02:40:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 16763 updates
2022-03-07 02:40:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:40:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:40:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 174 @ 16763 updates, score 12.982) (writing took 2.271217746194452 seconds)
2022-03-07 02:40:14 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-07 02:40:14 | INFO | train | epoch 174 | loss 2.007 | nll_loss 0.969 | ppl 1.96 | wps 22271.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16763 | lr 0.000244244 | gnorm 0.915 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 49725
2022-03-07 02:40:14 | INFO | fairseq.trainer | begin training epoch 175
2022-03-07 02:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:41:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:42:03 | INFO | train_inner | epoch 175:     38 / 97 loss=2.004, nll_loss=0.966, ppl=1.95, wps=22065.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=16800, lr=0.000243975, gnorm=0.918, loss_scale=16, train_wall=266, gb_free=8.1, wall=49834
2022-03-07 02:44:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:44:57 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 12.919 | nll_loss 12.409 | ppl 5436.98 | wps 42341.4 | wpb 510.9 | bsz 1 | num_updates 16859 | best_loss 7.981
2022-03-07 02:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 16859 updates
2022-03-07 02:44:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:44:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:44:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 175 @ 16859 updates, score 12.919) (writing took 2.2701995549723506 seconds)
2022-03-07 02:44:59 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-07 02:44:59 | INFO | train | epoch 175 | loss 2.005 | nll_loss 0.966 | ppl 1.95 | wps 22033.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16859 | lr 0.000243548 | gnorm 0.916 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 50011
2022-03-07 02:44:59 | INFO | fairseq.trainer | begin training epoch 176
2022-03-07 02:44:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:46:57 | INFO | train_inner | epoch 176:     41 / 97 loss=2.004, nll_loss=0.966, ppl=1.95, wps=22276.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=16900, lr=0.000243252, gnorm=0.915, loss_scale=16, train_wall=263, gb_free=8.1, wall=50128
2022-03-07 02:49:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:49:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:49:42 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 12.914 | nll_loss 12.405 | ppl 5423.89 | wps 42160.2 | wpb 510.9 | bsz 1 | num_updates 16955 | best_loss 7.981
2022-03-07 02:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 16955 updates
2022-03-07 02:49:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:49:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:49:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 176 @ 16955 updates, score 12.914) (writing took 2.255538903642446 seconds)
2022-03-07 02:49:44 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-07 02:49:44 | INFO | train | epoch 176 | loss 2 | nll_loss 0.962 | ppl 1.95 | wps 22018.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16955 | lr 0.000242857 | gnorm 0.915 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 50296
2022-03-07 02:49:44 | INFO | fairseq.trainer | begin training epoch 177
2022-03-07 02:49:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:51:54 | INFO | train_inner | epoch 177:     45 / 97 loss=1.999, nll_loss=0.961, ppl=1.95, wps=22038.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=17000, lr=0.000242536, gnorm=0.921, loss_scale=16, train_wall=266, gb_free=8.1, wall=50426
2022-03-07 02:54:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:54:28 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 12.997 | nll_loss 12.492 | ppl 5760.96 | wps 42718.4 | wpb 510.9 | bsz 1 | num_updates 17052 | best_loss 7.981
2022-03-07 02:54:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 17052 updates
2022-03-07 02:54:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:54:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:54:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 177 @ 17052 updates, score 12.997) (writing took 2.359910183120519 seconds)
2022-03-07 02:54:30 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-07 02:54:30 | INFO | train | epoch 177 | loss 1.995 | nll_loss 0.956 | ppl 1.94 | wps 22226.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17052 | lr 0.000242166 | gnorm 0.919 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 50582
2022-03-07 02:54:30 | INFO | fairseq.trainer | begin training epoch 178
2022-03-07 02:54:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:56:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:56:51 | INFO | train_inner | epoch 178:     49 / 97 loss=1.992, nll_loss=0.953, ppl=1.94, wps=22045.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17100, lr=0.000241825, gnorm=0.912, loss_scale=16, train_wall=266, gb_free=8.1, wall=50723
2022-03-07 02:59:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:59:13 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 13.02 | nll_loss 12.519 | ppl 5870.52 | wps 42421.7 | wpb 510.9 | bsz 1 | num_updates 17148 | best_loss 7.981
2022-03-07 02:59:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 17148 updates
2022-03-07 02:59:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:59:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:59:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 178 @ 17148 updates, score 13.02) (writing took 2.3137145903892815 seconds)
2022-03-07 02:59:16 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-07 02:59:16 | INFO | train | epoch 178 | loss 1.992 | nll_loss 0.953 | ppl 1.94 | wps 22038.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17148 | lr 0.000241487 | gnorm 0.923 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 50867
2022-03-07 02:59:16 | INFO | fairseq.trainer | begin training epoch 179
2022-03-07 02:59:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:01:45 | INFO | train_inner | epoch 179:     52 / 97 loss=1.991, nll_loss=0.953, ppl=1.94, wps=22289.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17200, lr=0.000241121, gnorm=0.926, loss_scale=16, train_wall=263, gb_free=8.1, wall=51017
2022-03-07 03:03:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:03:59 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 12.965 | nll_loss 12.459 | ppl 5629.67 | wps 42520.2 | wpb 510.9 | bsz 1 | num_updates 17245 | best_loss 7.981
2022-03-07 03:03:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 17245 updates
2022-03-07 03:03:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:04:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:04:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 179 @ 17245 updates, score 12.965) (writing took 2.2835634909570217 seconds)
2022-03-07 03:04:01 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-07 03:04:01 | INFO | train | epoch 179 | loss 1.987 | nll_loss 0.949 | ppl 1.93 | wps 22260.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17245 | lr 0.000240807 | gnorm 0.913 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 51153
2022-03-07 03:04:01 | INFO | fairseq.trainer | begin training epoch 180
2022-03-07 03:04:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:06:39 | INFO | train_inner | epoch 180:     55 / 97 loss=1.984, nll_loss=0.945, ppl=1.93, wps=22278.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=17300, lr=0.000240424, gnorm=0.909, loss_scale=32, train_wall=263, gb_free=8.1, wall=51311
2022-03-07 03:07:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:08:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:08:44 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 12.96 | nll_loss 12.454 | ppl 5610.21 | wps 42440.5 | wpb 510.9 | bsz 1 | num_updates 17341 | best_loss 7.981
2022-03-07 03:08:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 17341 updates
2022-03-07 03:08:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:08:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:08:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 180 @ 17341 updates, score 12.96) (writing took 2.2907490618526936 seconds)
2022-03-07 03:08:46 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-07 03:08:46 | INFO | train | epoch 180 | loss 1.983 | nll_loss 0.944 | ppl 1.92 | wps 22032.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17341 | lr 0.000240139 | gnorm 0.914 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 51438
2022-03-07 03:08:46 | INFO | fairseq.trainer | begin training epoch 181
2022-03-07 03:08:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:11:35 | INFO | train_inner | epoch 181:     59 / 97 loss=1.981, nll_loss=0.941, ppl=1.92, wps=22064.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=17400, lr=0.000239732, gnorm=0.91, loss_scale=16, train_wall=266, gb_free=8.1, wall=51607
2022-03-07 03:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:13:29 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 12.964 | nll_loss 12.462 | ppl 5642.07 | wps 42279 | wpb 510.9 | bsz 1 | num_updates 17438 | best_loss 7.981
2022-03-07 03:13:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 17438 updates
2022-03-07 03:13:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:13:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:13:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 181 @ 17438 updates, score 12.964) (writing took 2.263617830350995 seconds)
2022-03-07 03:13:32 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-07 03:13:32 | INFO | train | epoch 181 | loss 1.98 | nll_loss 0.941 | ppl 1.92 | wps 22264 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17438 | lr 0.00023947 | gnorm 0.903 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 51723
2022-03-07 03:13:32 | INFO | fairseq.trainer | begin training epoch 182
2022-03-07 03:13:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:14:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:16:32 | INFO | train_inner | epoch 182:     63 / 97 loss=1.981, nll_loss=0.942, ppl=1.92, wps=22060.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17500, lr=0.000239046, gnorm=0.909, loss_scale=16, train_wall=266, gb_free=8.1, wall=51904
2022-03-07 03:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:18:15 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 13 | nll_loss 12.497 | ppl 5781.96 | wps 42351.9 | wpb 510.9 | bsz 1 | num_updates 17534 | best_loss 7.981
2022-03-07 03:18:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 17534 updates
2022-03-07 03:18:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:18:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:18:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 182 @ 17534 updates, score 13.0) (writing took 2.284518581815064 seconds)
2022-03-07 03:18:17 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-07 03:18:17 | INFO | train | epoch 182 | loss 1.975 | nll_loss 0.936 | ppl 1.91 | wps 22028.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17534 | lr 0.000238814 | gnorm 0.909 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 52009
2022-03-07 03:18:17 | INFO | fairseq.trainer | begin training epoch 183
2022-03-07 03:18:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:21:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:21:29 | INFO | train_inner | epoch 183:     67 / 97 loss=1.973, nll_loss=0.934, ppl=1.91, wps=22056.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17600, lr=0.000238366, gnorm=0.91, loss_scale=16, train_wall=266, gb_free=8.1, wall=52201
2022-03-07 03:22:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:23:00 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 13.055 | nll_loss 12.556 | ppl 6022.05 | wps 42656.6 | wpb 510.9 | bsz 1 | num_updates 17630 | best_loss 7.981
2022-03-07 03:23:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 17630 updates
2022-03-07 03:23:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:23:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:23:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 183 @ 17630 updates, score 13.055) (writing took 2.2648835950531065 seconds)
2022-03-07 03:23:02 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-07 03:23:02 | INFO | train | epoch 183 | loss 1.971 | nll_loss 0.932 | ppl 1.91 | wps 22023.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17630 | lr 0.000238163 | gnorm 0.908 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 52294
2022-03-07 03:23:02 | INFO | fairseq.trainer | begin training epoch 184
2022-03-07 03:23:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:26:23 | INFO | train_inner | epoch 184:     70 / 97 loss=1.97, nll_loss=0.93, ppl=1.91, wps=22284.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17700, lr=0.000237691, gnorm=0.904, loss_scale=16, train_wall=263, gb_free=8.1, wall=52495
2022-03-07 03:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:27:46 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 13.02 | nll_loss 12.52 | ppl 5875.16 | wps 42490.9 | wpb 510.9 | bsz 1 | num_updates 17727 | best_loss 7.981
2022-03-07 03:27:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 17727 updates
2022-03-07 03:27:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:27:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:27:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 184 @ 17727 updates, score 13.02) (writing took 2.2627448020502925 seconds)
2022-03-07 03:27:48 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-07 03:27:48 | INFO | train | epoch 184 | loss 1.969 | nll_loss 0.93 | ppl 1.91 | wps 22257.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17727 | lr 0.00023751 | gnorm 0.914 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 52580
2022-03-07 03:27:48 | INFO | fairseq.trainer | begin training epoch 185
2022-03-07 03:27:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:30:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:31:20 | INFO | train_inner | epoch 185:     74 / 97 loss=1.966, nll_loss=0.927, ppl=1.9, wps=22076.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17800, lr=0.000237023, gnorm=0.922, loss_scale=16, train_wall=266, gb_free=8.1, wall=52792
2022-03-07 03:32:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:32:31 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 13.042 | nll_loss 12.543 | ppl 5969.05 | wps 42460.8 | wpb 510.9 | bsz 1 | num_updates 17823 | best_loss 7.981
2022-03-07 03:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 17823 updates
2022-03-07 03:32:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:32:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:32:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 185 @ 17823 updates, score 13.042) (writing took 2.2553483871743083 seconds)
2022-03-07 03:32:33 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-07 03:32:33 | INFO | train | epoch 185 | loss 1.964 | nll_loss 0.924 | ppl 1.9 | wps 22060.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17823 | lr 0.00023687 | gnorm 0.918 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 52865
2022-03-07 03:32:33 | INFO | fairseq.trainer | begin training epoch 186
2022-03-07 03:32:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:36:14 | INFO | train_inner | epoch 186:     77 / 97 loss=1.962, nll_loss=0.922, ppl=1.89, wps=22293.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=17900, lr=0.00023636, gnorm=0.906, loss_scale=16, train_wall=263, gb_free=8.1, wall=53086
2022-03-07 03:36:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:37:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:37:16 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 13.059 | nll_loss 12.563 | ppl 6052.44 | wps 42346.8 | wpb 510.9 | bsz 1 | num_updates 17919 | best_loss 7.981
2022-03-07 03:37:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 17919 updates
2022-03-07 03:37:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:37:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:37:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 186 @ 17919 updates, score 13.059) (writing took 2.2498994772322476 seconds)
2022-03-07 03:37:18 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-07 03:37:18 | INFO | train | epoch 186 | loss 1.96 | nll_loss 0.92 | ppl 1.89 | wps 22038.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17919 | lr 0.000236234 | gnorm 0.903 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 53150
2022-03-07 03:37:18 | INFO | fairseq.trainer | begin training epoch 187
2022-03-07 03:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:41:10 | INFO | train_inner | epoch 187:     81 / 97 loss=1.957, nll_loss=0.917, ppl=1.89, wps=22068.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18000, lr=0.000235702, gnorm=0.895, loss_scale=16, train_wall=266, gb_free=8.1, wall=53382
2022-03-07 03:41:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:42:01 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 13.027 | nll_loss 12.528 | ppl 5904.84 | wps 42203.7 | wpb 510.9 | bsz 1 | num_updates 18016 | best_loss 7.981
2022-03-07 03:42:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 18016 updates
2022-03-07 03:42:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:42:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:42:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 187 @ 18016 updates, score 13.027) (writing took 2.2824456989765167 seconds)
2022-03-07 03:42:04 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-07 03:42:04 | INFO | train | epoch 187 | loss 1.956 | nll_loss 0.916 | ppl 1.89 | wps 22255.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18016 | lr 0.000235598 | gnorm 0.89 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 53435
2022-03-07 03:42:04 | INFO | fairseq.trainer | begin training epoch 188
2022-03-07 03:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:44:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:46:07 | INFO | train_inner | epoch 188:     85 / 97 loss=1.955, nll_loss=0.915, ppl=1.89, wps=22055, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18100, lr=0.00023505, gnorm=0.89, loss_scale=16, train_wall=266, gb_free=8.1, wall=53679
2022-03-07 03:46:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:46:47 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 13.019 | nll_loss 12.518 | ppl 5865.75 | wps 42251.7 | wpb 510.9 | bsz 1 | num_updates 18112 | best_loss 7.981
2022-03-07 03:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 18112 updates
2022-03-07 03:46:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:46:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:46:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 188 @ 18112 updates, score 13.019) (writing took 2.2689448199234903 seconds)
2022-03-07 03:46:49 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-07 03:46:49 | INFO | train | epoch 188 | loss 1.952 | nll_loss 0.912 | ppl 1.88 | wps 22030.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18112 | lr 0.000234972 | gnorm 0.888 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 53721
2022-03-07 03:46:49 | INFO | fairseq.trainer | begin training epoch 189
2022-03-07 03:46:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:51:01 | INFO | train_inner | epoch 189:     88 / 97 loss=1.949, nll_loss=0.91, ppl=1.88, wps=22282, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=18200, lr=0.000234404, gnorm=0.899, loss_scale=16, train_wall=263, gb_free=8.1, wall=53973
2022-03-07 03:51:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:51:32 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 12.987 | nll_loss 12.485 | ppl 5732.46 | wps 42546.9 | wpb 510.9 | bsz 1 | num_updates 18209 | best_loss 7.981
2022-03-07 03:51:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 18209 updates
2022-03-07 03:51:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:51:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 189 @ 18209 updates, score 12.987) (writing took 2.213019389193505 seconds)
2022-03-07 03:51:34 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-07 03:51:34 | INFO | train | epoch 189 | loss 1.95 | nll_loss 0.91 | ppl 1.88 | wps 22269.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18209 | lr 0.000234346 | gnorm 0.901 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 54006
2022-03-07 03:51:34 | INFO | fairseq.trainer | begin training epoch 190
2022-03-07 03:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:52:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:55:58 | INFO | train_inner | epoch 190:     92 / 97 loss=1.949, nll_loss=0.909, ppl=1.88, wps=22076.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18300, lr=0.000233762, gnorm=0.898, loss_scale=16, train_wall=266, gb_free=8.1, wall=54270
2022-03-07 03:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:56:17 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 13.065 | nll_loss 12.568 | ppl 6072.31 | wps 42294.7 | wpb 510.9 | bsz 1 | num_updates 18305 | best_loss 7.981
2022-03-07 03:56:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 18305 updates
2022-03-07 03:56:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:56:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 190 @ 18305 updates, score 13.065) (writing took 2.292164674960077 seconds)
2022-03-07 03:56:20 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-07 03:56:20 | INFO | train | epoch 190 | loss 1.946 | nll_loss 0.906 | ppl 1.87 | wps 22037.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18305 | lr 0.00023373 | gnorm 0.898 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 54291
2022-03-07 03:56:20 | INFO | fairseq.trainer | begin training epoch 191
2022-03-07 03:56:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:58:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:00:55 | INFO | train_inner | epoch 191:     96 / 97 loss=1.942, nll_loss=0.902, ppl=1.87, wps=22068.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18400, lr=0.000233126, gnorm=0.906, loss_scale=16, train_wall=266, gb_free=8.1, wall=54567
2022-03-07 04:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:01:03 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 13.086 | nll_loss 12.587 | ppl 6153.86 | wps 42486 | wpb 510.9 | bsz 1 | num_updates 18401 | best_loss 7.981
2022-03-07 04:01:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 18401 updates
2022-03-07 04:01:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:01:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 191 @ 18401 updates, score 13.086) (writing took 2.386523251887411 seconds)
2022-03-07 04:01:05 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-07 04:01:05 | INFO | train | epoch 191 | loss 1.941 | nll_loss 0.901 | ppl 1.87 | wps 22028.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18401 | lr 0.00023312 | gnorm 0.903 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 54577
2022-03-07 04:01:05 | INFO | fairseq.trainer | begin training epoch 192
2022-03-07 04:01:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:05:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:05:48 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 13.089 | nll_loss 12.594 | ppl 6182.82 | wps 42430.3 | wpb 510.9 | bsz 1 | num_updates 18498 | best_loss 7.981
2022-03-07 04:05:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 18498 updates
2022-03-07 04:05:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:05:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:05:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 192 @ 18498 updates, score 13.089) (writing took 2.2719936626963317 seconds)
2022-03-07 04:05:50 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-07 04:05:50 | INFO | train | epoch 192 | loss 1.938 | nll_loss 0.898 | ppl 1.86 | wps 22258.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18498 | lr 0.000232508 | gnorm 0.9 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 54862
2022-03-07 04:05:50 | INFO | fairseq.trainer | begin training epoch 193
2022-03-07 04:05:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:05:56 | INFO | train_inner | epoch 193:      2 / 97 loss=1.938, nll_loss=0.898, ppl=1.86, wps=21711.3, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=18500, lr=0.000232495, gnorm=0.9, loss_scale=32, train_wall=263, gb_free=8.1, wall=54868
2022-03-07 04:08:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:10:33 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 13.077 | nll_loss 12.578 | ppl 6115.18 | wps 42359.9 | wpb 510.9 | bsz 1 | num_updates 18594 | best_loss 7.981
2022-03-07 04:10:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 18594 updates
2022-03-07 04:10:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:10:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:10:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 193 @ 18594 updates, score 13.077) (writing took 2.324053172953427 seconds)
2022-03-07 04:10:36 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-07 04:10:36 | INFO | train | epoch 193 | loss 1.935 | nll_loss 0.895 | ppl 1.86 | wps 22034.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18594 | lr 0.000231907 | gnorm 0.895 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 55148
2022-03-07 04:10:36 | INFO | fairseq.trainer | begin training epoch 194
2022-03-07 04:10:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:10:53 | INFO | train_inner | epoch 194:      6 / 97 loss=1.933, nll_loss=0.893, ppl=1.86, wps=22066, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18600, lr=0.000231869, gnorm=0.893, loss_scale=16, train_wall=266, gb_free=8.1, wall=55165
2022-03-07 04:15:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:15:19 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 13.12 | nll_loss 12.627 | ppl 6327.84 | wps 42454.9 | wpb 510.9 | bsz 1 | num_updates 18691 | best_loss 7.981
2022-03-07 04:15:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 18691 updates
2022-03-07 04:15:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:15:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:15:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 194 @ 18691 updates, score 13.12) (writing took 2.281826133839786 seconds)
2022-03-07 04:15:21 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-07 04:15:21 | INFO | train | epoch 194 | loss 1.933 | nll_loss 0.893 | ppl 1.86 | wps 22235.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18691 | lr 0.000231304 | gnorm 0.904 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 55433
2022-03-07 04:15:21 | INFO | fairseq.trainer | begin training epoch 195
2022-03-07 04:15:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:15:47 | INFO | train_inner | epoch 195:      9 / 97 loss=1.932, nll_loss=0.892, ppl=1.86, wps=22251.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18700, lr=0.000231249, gnorm=0.903, loss_scale=32, train_wall=264, gb_free=8.1, wall=55459
2022-03-07 04:16:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:20:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:20:05 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 13.068 | nll_loss 12.572 | ppl 6089.53 | wps 42265.3 | wpb 510.9 | bsz 1 | num_updates 18787 | best_loss 7.981
2022-03-07 04:20:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 18787 updates
2022-03-07 04:20:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:20:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:20:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 195 @ 18787 updates, score 13.068) (writing took 2.325681945774704 seconds)
2022-03-07 04:20:07 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-07 04:20:07 | INFO | train | epoch 195 | loss 1.928 | nll_loss 0.887 | ppl 1.85 | wps 22006.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18787 | lr 0.000230713 | gnorm 0.89 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 55719
2022-03-07 04:20:07 | INFO | fairseq.trainer | begin training epoch 196
2022-03-07 04:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:20:44 | INFO | train_inner | epoch 196:     13 / 97 loss=1.926, nll_loss=0.885, ppl=1.85, wps=22045.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18800, lr=0.000230633, gnorm=0.892, loss_scale=16, train_wall=266, gb_free=8.1, wall=55756
2022-03-07 04:23:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:24:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:24:50 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 13.072 | nll_loss 12.579 | ppl 6118.51 | wps 42180.4 | wpb 510.9 | bsz 1 | num_updates 18883 | best_loss 7.981
2022-03-07 04:24:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 18883 updates
2022-03-07 04:24:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:24:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:24:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 196 @ 18883 updates, score 13.072) (writing took 2.2815561508759856 seconds)
2022-03-07 04:24:52 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-07 04:24:52 | INFO | train | epoch 196 | loss 1.925 | nll_loss 0.884 | ppl 1.85 | wps 22045.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18883 | lr 0.000230125 | gnorm 0.904 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 56004
2022-03-07 04:24:52 | INFO | fairseq.trainer | begin training epoch 197
2022-03-07 04:24:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:25:41 | INFO | train_inner | epoch 197:     17 / 97 loss=1.922, nll_loss=0.882, ppl=1.84, wps=22076.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18900, lr=0.000230022, gnorm=0.899, loss_scale=16, train_wall=266, gb_free=8.1, wall=56053
2022-03-07 04:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:29:35 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 13.093 | nll_loss 12.6 | ppl 6208.02 | wps 42287 | wpb 510.9 | bsz 1 | num_updates 18980 | best_loss 7.981
2022-03-07 04:29:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 18980 updates
2022-03-07 04:29:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:29:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:29:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 197 @ 18980 updates, score 13.093) (writing took 2.2404369050636888 seconds)
2022-03-07 04:29:38 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-07 04:29:38 | INFO | train | epoch 197 | loss 1.921 | nll_loss 0.881 | ppl 1.84 | wps 22256.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18980 | lr 0.000229537 | gnorm 0.898 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 56290
2022-03-07 04:29:38 | INFO | fairseq.trainer | begin training epoch 198
2022-03-07 04:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:30:35 | INFO | train_inner | epoch 198:     20 / 97 loss=1.92, nll_loss=0.879, ppl=1.84, wps=22279.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19000, lr=0.000229416, gnorm=0.893, loss_scale=32, train_wall=263, gb_free=8.1, wall=56347
2022-03-07 04:30:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:34:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:34:20 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 13.147 | nll_loss 12.655 | ppl 6450.92 | wps 42479.5 | wpb 510.9 | bsz 1 | num_updates 19076 | best_loss 7.981
2022-03-07 04:34:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 19076 updates
2022-03-07 04:34:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:34:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:34:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 198 @ 19076 updates, score 13.147) (writing took 2.354618031065911 seconds)
2022-03-07 04:34:23 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-07 04:34:23 | INFO | train | epoch 198 | loss 1.918 | nll_loss 0.878 | ppl 1.84 | wps 22050 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19076 | lr 0.000228958 | gnorm 0.888 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 56575
2022-03-07 04:34:23 | INFO | fairseq.trainer | begin training epoch 199
2022-03-07 04:34:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:35:32 | INFO | train_inner | epoch 199:     24 / 97 loss=1.918, nll_loss=0.878, ppl=1.84, wps=22072.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=19100, lr=0.000228814, gnorm=0.89, loss_scale=16, train_wall=266, gb_free=8.1, wall=56644
2022-03-07 04:37:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:39:06 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 13.111 | nll_loss 12.619 | ppl 6291.25 | wps 42527.1 | wpb 510.9 | bsz 1 | num_updates 19172 | best_loss 7.981
2022-03-07 04:39:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 19172 updates
2022-03-07 04:39:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:39:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:39:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 199 @ 19172 updates, score 13.111) (writing took 2.264327948912978 seconds)
2022-03-07 04:39:08 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-07 04:39:08 | INFO | train | epoch 199 | loss 1.916 | nll_loss 0.876 | ppl 1.84 | wps 22031.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19172 | lr 0.000228384 | gnorm 0.896 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 56860
2022-03-07 04:39:08 | INFO | fairseq.trainer | begin training epoch 200
2022-03-07 04:39:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:40:29 | INFO | train_inner | epoch 200:     28 / 97 loss=1.913, nll_loss=0.873, ppl=1.83, wps=22062.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19200, lr=0.000228218, gnorm=0.896, loss_scale=16, train_wall=266, gb_free=8.1, wall=56940
2022-03-07 04:43:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:43:51 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 13.092 | nll_loss 12.601 | ppl 6210.65 | wps 42329.9 | wpb 510.9 | bsz 1 | num_updates 19269 | best_loss 7.981
2022-03-07 04:43:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 19269 updates
2022-03-07 04:43:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:43:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:43:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 200 @ 19269 updates, score 13.092) (writing took 2.2838274762034416 seconds)
2022-03-07 04:43:54 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-07 04:43:54 | INFO | train | epoch 200 | loss 1.91 | nll_loss 0.87 | ppl 1.83 | wps 22257.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19269 | lr 0.000227809 | gnorm 0.881 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 57146
2022-03-07 04:43:54 | INFO | fairseq.trainer | begin training epoch 201
2022-03-07 04:43:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:44:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:45:25 | INFO | train_inner | epoch 201:     32 / 97 loss=1.909, nll_loss=0.868, ppl=1.83, wps=22060.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=19300, lr=0.000227626, gnorm=0.883, loss_scale=16, train_wall=266, gb_free=8.1, wall=57237
2022-03-07 04:48:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:48:37 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 13.185 | nll_loss 12.697 | ppl 6639.77 | wps 42429.5 | wpb 510.9 | bsz 1 | num_updates 19365 | best_loss 7.981
2022-03-07 04:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 19365 updates
2022-03-07 04:48:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:48:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:48:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 201 @ 19365 updates, score 13.185) (writing took 2.1923389988951385 seconds)
2022-03-07 04:48:39 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-07 04:48:39 | INFO | train | epoch 201 | loss 1.907 | nll_loss 0.867 | ppl 1.82 | wps 22041.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19365 | lr 0.000227243 | gnorm 0.886 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 57431
2022-03-07 04:48:39 | INFO | fairseq.trainer | begin training epoch 202
2022-03-07 04:48:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:50:19 | INFO | train_inner | epoch 202:     35 / 97 loss=1.906, nll_loss=0.866, ppl=1.82, wps=22289.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19400, lr=0.000227038, gnorm=0.884, loss_scale=16, train_wall=263, gb_free=8.1, wall=57531
2022-03-07 04:51:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:53:22 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 13.11 | nll_loss 12.615 | ppl 6274.8 | wps 42245 | wpb 510.9 | bsz 1 | num_updates 19461 | best_loss 7.981
2022-03-07 04:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 19461 updates
2022-03-07 04:53:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:53:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:53:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 202 @ 19461 updates, score 13.11) (writing took 2.34185712877661 seconds)
2022-03-07 04:53:24 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-07 04:53:24 | INFO | train | epoch 202 | loss 1.904 | nll_loss 0.864 | ppl 1.82 | wps 22026.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19461 | lr 0.000226682 | gnorm 0.883 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 57716
2022-03-07 04:53:24 | INFO | fairseq.trainer | begin training epoch 203
2022-03-07 04:53:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:55:16 | INFO | train_inner | epoch 203:     39 / 97 loss=1.902, nll_loss=0.861, ppl=1.82, wps=22063, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19500, lr=0.000226455, gnorm=0.883, loss_scale=16, train_wall=266, gb_free=8.1, wall=57828
2022-03-07 04:58:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:58:07 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 13.096 | nll_loss 12.605 | ppl 6231.32 | wps 42238.5 | wpb 510.9 | bsz 1 | num_updates 19558 | best_loss 7.981
2022-03-07 04:58:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 19558 updates
2022-03-07 04:58:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:58:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:58:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 203 @ 19558 updates, score 13.096) (writing took 2.248137603048235 seconds)
2022-03-07 04:58:10 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-07 04:58:10 | INFO | train | epoch 203 | loss 1.903 | nll_loss 0.863 | ppl 1.82 | wps 22270.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19558 | lr 0.000226119 | gnorm 0.884 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 58001
2022-03-07 04:58:10 | INFO | fairseq.trainer | begin training epoch 204
2022-03-07 04:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:58:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:00:13 | INFO | train_inner | epoch 204:     43 / 97 loss=1.903, nll_loss=0.863, ppl=1.82, wps=22067.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19600, lr=0.000225877, gnorm=0.885, loss_scale=16, train_wall=266, gb_free=8.1, wall=58125
2022-03-07 05:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:02:53 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 13.099 | nll_loss 12.609 | ppl 6245.3 | wps 42241.8 | wpb 510.9 | bsz 1 | num_updates 19654 | best_loss 7.981
2022-03-07 05:02:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 19654 updates
2022-03-07 05:02:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 204 @ 19654 updates, score 13.099) (writing took 2.2418488790281117 seconds)
2022-03-07 05:02:55 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-07 05:02:55 | INFO | train | epoch 204 | loss 1.9 | nll_loss 0.859 | ppl 1.81 | wps 22039.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19654 | lr 0.000225566 | gnorm 0.892 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 58287
2022-03-07 05:02:55 | INFO | fairseq.trainer | begin training epoch 205
2022-03-07 05:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:04:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:05:10 | INFO | train_inner | epoch 205:     47 / 97 loss=1.896, nll_loss=0.855, ppl=1.81, wps=22078.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19700, lr=0.000225303, gnorm=0.887, loss_scale=16, train_wall=266, gb_free=8.1, wall=58421
2022-03-07 05:07:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:07:38 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 13.09 | nll_loss 12.598 | ppl 6200.38 | wps 42522.7 | wpb 510.9 | bsz 1 | num_updates 19750 | best_loss 7.981
2022-03-07 05:07:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 19750 updates
2022-03-07 05:07:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:07:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:07:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 205 @ 19750 updates, score 13.09) (writing took 2.2846717592328787 seconds)
2022-03-07 05:07:40 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-07 05:07:40 | INFO | train | epoch 205 | loss 1.895 | nll_loss 0.854 | ppl 1.81 | wps 22038.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19750 | lr 0.000225018 | gnorm 0.874 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 58572
2022-03-07 05:07:40 | INFO | fairseq.trainer | begin training epoch 206
2022-03-07 05:07:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:10:04 | INFO | train_inner | epoch 206:     50 / 97 loss=1.895, nll_loss=0.854, ppl=1.81, wps=22280.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=19800, lr=0.000224733, gnorm=0.875, loss_scale=16, train_wall=263, gb_free=8.1, wall=58715
2022-03-07 05:11:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:12:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:12:23 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 13.135 | nll_loss 12.644 | ppl 6401.3 | wps 42310 | wpb 510.9 | bsz 1 | num_updates 19846 | best_loss 7.981
2022-03-07 05:12:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 19846 updates
2022-03-07 05:12:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:12:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:12:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 206 @ 19846 updates, score 13.135) (writing took 2.274275743868202 seconds)
2022-03-07 05:12:25 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-07 05:12:25 | INFO | train | epoch 206 | loss 1.893 | nll_loss 0.853 | ppl 1.81 | wps 22035.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19846 | lr 0.000224473 | gnorm 0.881 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 58857
2022-03-07 05:12:25 | INFO | fairseq.trainer | begin training epoch 207
2022-03-07 05:12:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:15:00 | INFO | train_inner | epoch 207:     54 / 97 loss=1.892, nll_loss=0.852, ppl=1.8, wps=22057, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19900, lr=0.000224168, gnorm=0.879, loss_scale=16, train_wall=266, gb_free=8.1, wall=59012
2022-03-07 05:17:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:17:09 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 13.132 | nll_loss 12.643 | ppl 6396.82 | wps 42388.1 | wpb 510.9 | bsz 1 | num_updates 19943 | best_loss 7.981
2022-03-07 05:17:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 19943 updates
2022-03-07 05:17:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:17:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:17:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 207 @ 19943 updates, score 13.132) (writing took 2.278403302654624 seconds)
2022-03-07 05:17:11 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-07 05:17:11 | INFO | train | epoch 207 | loss 1.89 | nll_loss 0.85 | ppl 1.8 | wps 22234.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19943 | lr 0.000223926 | gnorm 0.879 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 59143
2022-03-07 05:17:11 | INFO | fairseq.trainer | begin training epoch 208
2022-03-07 05:17:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:19:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:19:58 | INFO | train_inner | epoch 208:     58 / 97 loss=1.889, nll_loss=0.848, ppl=1.8, wps=22046.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20000, lr=0.000223607, gnorm=0.878, loss_scale=16, train_wall=266, gb_free=8.1, wall=59309
2022-03-07 05:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:21:54 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 13.18 | nll_loss 12.693 | ppl 6620.34 | wps 42251.7 | wpb 510.9 | bsz 1 | num_updates 20039 | best_loss 7.981
2022-03-07 05:21:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 20039 updates
2022-03-07 05:21:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:21:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:21:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 208 @ 20039 updates, score 13.18) (writing took 2.287874572444707 seconds)
2022-03-07 05:21:57 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-07 05:21:57 | INFO | train | epoch 208 | loss 1.887 | nll_loss 0.847 | ppl 1.8 | wps 22025.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20039 | lr 0.000223389 | gnorm 0.876 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 59428
2022-03-07 05:21:57 | INFO | fairseq.trainer | begin training epoch 209
2022-03-07 05:21:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:24:51 | INFO | train_inner | epoch 209:     61 / 97 loss=1.887, nll_loss=0.846, ppl=1.8, wps=22280.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=20100, lr=0.00022305, gnorm=0.877, loss_scale=16, train_wall=263, gb_free=8.1, wall=59603
2022-03-07 05:26:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:26:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:26:39 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 13.132 | nll_loss 12.643 | ppl 6396.43 | wps 42380.2 | wpb 510.9 | bsz 1 | num_updates 20135 | best_loss 7.981
2022-03-07 05:26:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 20135 updates
2022-03-07 05:26:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:26:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:26:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 209 @ 20135 updates, score 13.132) (writing took 2.4284152388572693 seconds)
2022-03-07 05:26:42 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-07 05:26:42 | INFO | train | epoch 209 | loss 1.884 | nll_loss 0.843 | ppl 1.79 | wps 22035.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20135 | lr 0.000222856 | gnorm 0.871 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 59714
2022-03-07 05:26:42 | INFO | fairseq.trainer | begin training epoch 210
2022-03-07 05:26:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:29:48 | INFO | train_inner | epoch 210:     65 / 97 loss=1.882, nll_loss=0.841, ppl=1.79, wps=22060.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=20200, lr=0.000222497, gnorm=0.871, loss_scale=16, train_wall=266, gb_free=8.1, wall=59900
2022-03-07 05:31:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:31:25 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 13.154 | nll_loss 12.668 | ppl 6506.92 | wps 42642.4 | wpb 510.9 | bsz 1 | num_updates 20232 | best_loss 7.981
2022-03-07 05:31:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 20232 updates
2022-03-07 05:31:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:31:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:31:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 210 @ 20232 updates, score 13.154) (writing took 2.289977096952498 seconds)
2022-03-07 05:31:27 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-07 05:31:27 | INFO | train | epoch 210 | loss 1.882 | nll_loss 0.842 | ppl 1.79 | wps 22256.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20232 | lr 0.000222321 | gnorm 0.88 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 59999
2022-03-07 05:31:27 | INFO | fairseq.trainer | begin training epoch 211
2022-03-07 05:31:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:33:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:34:45 | INFO | train_inner | epoch 211:     69 / 97 loss=1.882, nll_loss=0.841, ppl=1.79, wps=22066, ups=0.34, wpb=65495, bsz=127.9, num_updates=20300, lr=0.000221948, gnorm=0.882, loss_scale=16, train_wall=266, gb_free=8.1, wall=60197
2022-03-07 05:36:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:36:10 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 13.185 | nll_loss 12.698 | ppl 6646.13 | wps 42258.6 | wpb 510.9 | bsz 1 | num_updates 20328 | best_loss 7.981
2022-03-07 05:36:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 20328 updates
2022-03-07 05:36:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:36:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 211 @ 20328 updates, score 13.185) (writing took 2.270689185708761 seconds)
2022-03-07 05:36:13 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-07 05:36:13 | INFO | train | epoch 211 | loss 1.88 | nll_loss 0.839 | ppl 1.79 | wps 22041.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20328 | lr 0.000221795 | gnorm 0.876 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 60284
2022-03-07 05:36:13 | INFO | fairseq.trainer | begin training epoch 212
2022-03-07 05:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:39:39 | INFO | train_inner | epoch 212:     72 / 97 loss=1.877, nll_loss=0.836, ppl=1.79, wps=22289.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20400, lr=0.000221404, gnorm=0.87, loss_scale=16, train_wall=263, gb_free=8.1, wall=60491
2022-03-07 05:40:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:40:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:40:56 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 13.166 | nll_loss 12.681 | ppl 6565.4 | wps 42429.2 | wpb 510.9 | bsz 1 | num_updates 20424 | best_loss 7.981
2022-03-07 05:40:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 20424 updates
2022-03-07 05:40:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:40:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:40:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 212 @ 20424 updates, score 13.166) (writing took 2.4174474170431495 seconds)
2022-03-07 05:40:58 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-07 05:40:58 | INFO | train | epoch 212 | loss 1.875 | nll_loss 0.834 | ppl 1.78 | wps 22028.7 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 20424 | lr 0.000221274 | gnorm 0.871 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 60570
2022-03-07 05:40:58 | INFO | fairseq.trainer | begin training epoch 213
2022-03-07 05:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:44:36 | INFO | train_inner | epoch 213:     76 / 97 loss=1.874, nll_loss=0.833, ppl=1.78, wps=22056, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20500, lr=0.000220863, gnorm=0.878, loss_scale=16, train_wall=266, gb_free=8.1, wall=60788
2022-03-07 05:45:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:45:41 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 13.144 | nll_loss 12.653 | ppl 6439.67 | wps 42465.3 | wpb 510.9 | bsz 1 | num_updates 20521 | best_loss 7.981
2022-03-07 05:45:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 20521 updates
2022-03-07 05:45:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:45:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:45:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 213 @ 20521 updates, score 13.144) (writing took 2.209270447026938 seconds)
2022-03-07 05:45:43 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-07 05:45:43 | INFO | train | epoch 213 | loss 1.873 | nll_loss 0.833 | ppl 1.78 | wps 22266.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20521 | lr 0.00022075 | gnorm 0.877 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 60855
2022-03-07 05:45:43 | INFO | fairseq.trainer | begin training epoch 214
2022-03-07 05:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:47:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:49:33 | INFO | train_inner | epoch 214:     80 / 97 loss=1.872, nll_loss=0.832, ppl=1.78, wps=22068.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20600, lr=0.000220326, gnorm=0.879, loss_scale=16, train_wall=266, gb_free=8.1, wall=61085
2022-03-07 05:50:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:50:26 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 13.13 | nll_loss 12.637 | ppl 6371.23 | wps 42386.6 | wpb 510.9 | bsz 1 | num_updates 20617 | best_loss 7.981
2022-03-07 05:50:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 20617 updates
2022-03-07 05:50:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:50:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:50:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 214 @ 20617 updates, score 13.13) (writing took 2.4102665269747376 seconds)
2022-03-07 05:50:29 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-07 05:50:29 | INFO | train | epoch 214 | loss 1.87 | nll_loss 0.829 | ppl 1.78 | wps 22020.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20617 | lr 0.000220235 | gnorm 0.877 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 61141
2022-03-07 05:50:29 | INFO | fairseq.trainer | begin training epoch 215
2022-03-07 05:50:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:54:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:54:30 | INFO | train_inner | epoch 215:     84 / 97 loss=1.869, nll_loss=0.828, ppl=1.78, wps=22063.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20700, lr=0.000219793, gnorm=0.872, loss_scale=16, train_wall=266, gb_free=8.1, wall=61381
2022-03-07 05:55:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:55:12 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 13.131 | nll_loss 12.642 | ppl 6392.46 | wps 42623.5 | wpb 510.9 | bsz 1 | num_updates 20713 | best_loss 7.981
2022-03-07 05:55:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 20713 updates
2022-03-07 05:55:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:55:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:55:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 215 @ 20713 updates, score 13.131) (writing took 2.283670360222459 seconds)
2022-03-07 05:55:14 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-07 05:55:14 | INFO | train | epoch 215 | loss 1.867 | nll_loss 0.826 | ppl 1.77 | wps 22041.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20713 | lr 0.000219725 | gnorm 0.875 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 61426
2022-03-07 05:55:14 | INFO | fairseq.trainer | begin training epoch 216
2022-03-07 05:55:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:59:23 | INFO | train_inner | epoch 216:     87 / 97 loss=1.865, nll_loss=0.825, ppl=1.77, wps=22281.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20800, lr=0.000219265, gnorm=0.872, loss_scale=16, train_wall=263, gb_free=8.1, wall=61675
2022-03-07 05:59:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:59:57 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 13.138 | nll_loss 12.65 | ppl 6426.98 | wps 42223.7 | wpb 510.9 | bsz 1 | num_updates 20810 | best_loss 7.981
2022-03-07 05:59:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 20810 updates
2022-03-07 05:59:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:59:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:59:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 216 @ 20810 updates, score 13.138) (writing took 2.2417057040147483 seconds)
2022-03-07 05:59:59 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-07 05:59:59 | INFO | train | epoch 216 | loss 1.865 | nll_loss 0.825 | ppl 1.77 | wps 22262.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20810 | lr 0.000219212 | gnorm 0.87 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 61711
2022-03-07 05:59:59 | INFO | fairseq.trainer | begin training epoch 217
2022-03-07 05:59:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:04:17 | INFO | train_inner | epoch 217:     90 / 97 loss=1.863, nll_loss=0.823, ppl=1.77, wps=22288.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20900, lr=0.000218739, gnorm=0.87, loss_scale=32, train_wall=263, gb_free=8.1, wall=61969
2022-03-07 06:04:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:04:42 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 13.187 | nll_loss 12.702 | ppl 6662.55 | wps 42537.4 | wpb 510.9 | bsz 1 | num_updates 20907 | best_loss 7.981
2022-03-07 06:04:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 20907 updates
2022-03-07 06:04:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:04:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:04:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 217 @ 20907 updates, score 13.187) (writing took 2.2675088779069483 seconds)
2022-03-07 06:04:45 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-07 06:04:45 | INFO | train | epoch 217 | loss 1.862 | nll_loss 0.822 | ppl 1.77 | wps 22271.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20907 | lr 0.000218703 | gnorm 0.869 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 61997
2022-03-07 06:04:45 | INFO | fairseq.trainer | begin training epoch 218
2022-03-07 06:04:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:04:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:09:14 | INFO | train_inner | epoch 218:     94 / 97 loss=1.861, nll_loss=0.821, ppl=1.77, wps=22050.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21000, lr=0.000218218, gnorm=0.875, loss_scale=16, train_wall=266, gb_free=8.1, wall=62266
2022-03-07 06:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:09:28 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 13.176 | nll_loss 12.69 | ppl 6610.13 | wps 42092 | wpb 510.9 | bsz 1 | num_updates 21003 | best_loss 7.981
2022-03-07 06:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 21003 updates
2022-03-07 06:09:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:09:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:09:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 218 @ 21003 updates, score 13.176) (writing took 2.2139815748669207 seconds)
2022-03-07 06:09:30 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-07 06:09:30 | INFO | train | epoch 218 | loss 1.859 | nll_loss 0.818 | ppl 1.76 | wps 22017.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21003 | lr 0.000218202 | gnorm 0.874 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 62282
2022-03-07 06:09:30 | INFO | fairseq.trainer | begin training epoch 219
2022-03-07 06:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:11:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:14:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:14:13 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 13.209 | nll_loss 12.726 | ppl 6777.04 | wps 42482.3 | wpb 510.9 | bsz 1 | num_updates 21099 | best_loss 7.981
2022-03-07 06:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 21099 updates
2022-03-07 06:14:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:14:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:14:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 219 @ 21099 updates, score 13.209) (writing took 2.3144095027819276 seconds)
2022-03-07 06:14:15 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-07 06:14:15 | INFO | train | epoch 219 | loss 1.856 | nll_loss 0.815 | ppl 1.76 | wps 22036.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21099 | lr 0.000217705 | gnorm 0.871 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 62567
2022-03-07 06:14:16 | INFO | fairseq.trainer | begin training epoch 220
2022-03-07 06:14:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:14:18 | INFO | train_inner | epoch 220:      1 / 97 loss=1.856, nll_loss=0.816, ppl=1.76, wps=21522.7, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=21100, lr=0.0002177, gnorm=0.872, loss_scale=16, train_wall=266, gb_free=8.1, wall=62570
2022-03-07 06:18:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:18:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:18:59 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 13.21 | nll_loss 12.727 | ppl 6781.23 | wps 42376.5 | wpb 510.9 | bsz 1 | num_updates 21195 | best_loss 7.981
2022-03-07 06:18:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 21195 updates
2022-03-07 06:18:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:19:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:19:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 220 @ 21195 updates, score 13.21) (writing took 2.325384374242276 seconds)
2022-03-07 06:19:01 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-07 06:19:01 | INFO | train | epoch 220 | loss 1.854 | nll_loss 0.814 | ppl 1.76 | wps 22027.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21195 | lr 0.000217212 | gnorm 0.875 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 62853
2022-03-07 06:19:01 | INFO | fairseq.trainer | begin training epoch 221
2022-03-07 06:19:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:19:15 | INFO | train_inner | epoch 221:      5 / 97 loss=1.853, nll_loss=0.812, ppl=1.76, wps=22059.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21200, lr=0.000217186, gnorm=0.874, loss_scale=16, train_wall=266, gb_free=8.1, wall=62867
2022-03-07 06:23:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:23:44 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 13.222 | nll_loss 12.739 | ppl 6837.86 | wps 42360.4 | wpb 510.9 | bsz 1 | num_updates 21292 | best_loss 7.981
2022-03-07 06:23:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 21292 updates
2022-03-07 06:23:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:23:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:23:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 221 @ 21292 updates, score 13.222) (writing took 2.184503911063075 seconds)
2022-03-07 06:23:46 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-07 06:23:46 | INFO | train | epoch 221 | loss 1.851 | nll_loss 0.811 | ppl 1.75 | wps 22266.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21292 | lr 0.000216716 | gnorm 0.864 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 63138
2022-03-07 06:23:46 | INFO | fairseq.trainer | begin training epoch 222
2022-03-07 06:23:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:24:09 | INFO | train_inner | epoch 222:      8 / 97 loss=1.851, nll_loss=0.81, ppl=1.75, wps=22287.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21300, lr=0.000216676, gnorm=0.865, loss_scale=16, train_wall=263, gb_free=8.1, wall=63161
2022-03-07 06:24:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:28:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:28:29 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 13.156 | nll_loss 12.671 | ppl 6519.85 | wps 42245.1 | wpb 510.9 | bsz 1 | num_updates 21388 | best_loss 7.981
2022-03-07 06:28:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 21388 updates
2022-03-07 06:28:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:28:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:28:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 222 @ 21388 updates, score 13.156) (writing took 2.2506484426558018 seconds)
2022-03-07 06:28:31 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-07 06:28:31 | INFO | train | epoch 222 | loss 1.849 | nll_loss 0.808 | ppl 1.75 | wps 22038.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21388 | lr 0.000216229 | gnorm 0.87 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 63423
2022-03-07 06:28:32 | INFO | fairseq.trainer | begin training epoch 223
2022-03-07 06:28:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:29:06 | INFO | train_inner | epoch 223:     12 / 97 loss=1.847, nll_loss=0.806, ppl=1.75, wps=22070.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21400, lr=0.000216169, gnorm=0.866, loss_scale=16, train_wall=266, gb_free=8.1, wall=63458
2022-03-07 06:31:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:33:15 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 13.22 | nll_loss 12.735 | ppl 6817.3 | wps 42361.1 | wpb 510.9 | bsz 1 | num_updates 21484 | best_loss 7.981
2022-03-07 06:33:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 21484 updates
2022-03-07 06:33:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:33:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:33:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 223 @ 21484 updates, score 13.22) (writing took 2.3731269259005785 seconds)
2022-03-07 06:33:17 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-07 06:33:17 | INFO | train | epoch 223 | loss 1.846 | nll_loss 0.805 | ppl 1.75 | wps 22028 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21484 | lr 0.000215746 | gnorm 0.862 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 63709
2022-03-07 06:33:17 | INFO | fairseq.trainer | begin training epoch 224
2022-03-07 06:33:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:34:03 | INFO | train_inner | epoch 224:     16 / 97 loss=1.844, nll_loss=0.804, ppl=1.75, wps=22056.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21500, lr=0.000215666, gnorm=0.859, loss_scale=16, train_wall=266, gb_free=8.1, wall=63755
2022-03-07 06:37:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:38:00 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.221 | nll_loss 12.743 | ppl 6856.8 | wps 42515.2 | wpb 510.9 | bsz 1 | num_updates 21581 | best_loss 7.981
2022-03-07 06:38:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 21581 updates
2022-03-07 06:38:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:38:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:38:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 224 @ 21581 updates, score 13.221) (writing took 2.219993408303708 seconds)
2022-03-07 06:38:02 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-07 06:38:02 | INFO | train | epoch 224 | loss 1.844 | nll_loss 0.804 | ppl 1.75 | wps 22254.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21581 | lr 0.00021526 | gnorm 0.864 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 63994
2022-03-07 06:38:02 | INFO | fairseq.trainer | begin training epoch 225
2022-03-07 06:38:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:38:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:39:00 | INFO | train_inner | epoch 225:     20 / 97 loss=1.842, nll_loss=0.802, ppl=1.74, wps=22062.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21600, lr=0.000215166, gnorm=0.864, loss_scale=16, train_wall=266, gb_free=8.1, wall=64052
2022-03-07 06:42:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:42:46 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 13.163 | nll_loss 12.681 | ppl 6565.55 | wps 42472.8 | wpb 510.9 | bsz 1 | num_updates 21677 | best_loss 7.981
2022-03-07 06:42:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 21677 updates
2022-03-07 06:42:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:42:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:42:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 225 @ 21677 updates, score 13.163) (writing took 2.3140201191417873 seconds)
2022-03-07 06:42:48 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-07 06:42:48 | INFO | train | epoch 225 | loss 1.842 | nll_loss 0.802 | ppl 1.74 | wps 22023.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21677 | lr 0.000214783 | gnorm 0.869 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 64280
2022-03-07 06:42:48 | INFO | fairseq.trainer | begin training epoch 226
2022-03-07 06:42:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:43:54 | INFO | train_inner | epoch 226:     23 / 97 loss=1.842, nll_loss=0.802, ppl=1.74, wps=22265.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21700, lr=0.000214669, gnorm=0.871, loss_scale=16, train_wall=264, gb_free=8.1, wall=64346
2022-03-07 06:45:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:47:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:47:31 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 13.18 | nll_loss 12.7 | ppl 6654.78 | wps 42031.4 | wpb 510.9 | bsz 1 | num_updates 21773 | best_loss 7.981
2022-03-07 06:47:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 21773 updates
2022-03-07 06:47:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:47:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 226 @ 21773 updates, score 13.18) (writing took 2.2469578706659377 seconds)
2022-03-07 06:47:33 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-07 06:47:33 | INFO | train | epoch 226 | loss 1.838 | nll_loss 0.798 | ppl 1.74 | wps 22033.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21773 | lr 0.000214309 | gnorm 0.86 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 64565
2022-03-07 06:47:33 | INFO | fairseq.trainer | begin training epoch 227
2022-03-07 06:47:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:48:51 | INFO | train_inner | epoch 227:     27 / 97 loss=1.836, nll_loss=0.796, ppl=1.74, wps=22065.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21800, lr=0.000214176, gnorm=0.857, loss_scale=16, train_wall=266, gb_free=8.1, wall=64643
2022-03-07 06:52:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:52:16 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.197 | nll_loss 12.717 | ppl 6733.08 | wps 42203.1 | wpb 510.9 | bsz 1 | num_updates 21870 | best_loss 7.981
2022-03-07 06:52:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 21870 updates
2022-03-07 06:52:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:52:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:52:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 227 @ 21870 updates, score 13.197) (writing took 2.168488315772265 seconds)
2022-03-07 06:52:19 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-07 06:52:19 | INFO | train | epoch 227 | loss 1.835 | nll_loss 0.795 | ppl 1.73 | wps 22260.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21870 | lr 0.000213833 | gnorm 0.861 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 64850
2022-03-07 06:52:19 | INFO | fairseq.trainer | begin training epoch 228
2022-03-07 06:52:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:52:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:53:47 | INFO | train_inner | epoch 228:     31 / 97 loss=1.832, nll_loss=0.792, ppl=1.73, wps=22067.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21900, lr=0.000213687, gnorm=0.86, loss_scale=16, train_wall=266, gb_free=8.1, wall=64939
2022-03-07 06:56:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:57:01 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.248 | nll_loss 12.774 | ppl 7006.24 | wps 42205.3 | wpb 510.9 | bsz 1 | num_updates 21966 | best_loss 7.981
2022-03-07 06:57:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 21966 updates
2022-03-07 06:57:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:57:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:57:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 228 @ 21966 updates, score 13.248) (writing took 2.2224945658817887 seconds)
2022-03-07 06:57:04 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-07 06:57:04 | INFO | train | epoch 228 | loss 1.832 | nll_loss 0.792 | ppl 1.73 | wps 22057.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21966 | lr 0.000213366 | gnorm 0.864 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 65136
2022-03-07 06:57:04 | INFO | fairseq.trainer | begin training epoch 229
2022-03-07 06:57:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:58:41 | INFO | train_inner | epoch 229:     34 / 97 loss=1.833, nll_loss=0.792, ppl=1.73, wps=22295.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22000, lr=0.000213201, gnorm=0.865, loss_scale=16, train_wall=263, gb_free=8.1, wall=65233
2022-03-07 06:59:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:01:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:01:46 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.244 | nll_loss 12.763 | ppl 6950.97 | wps 42624.9 | wpb 510.9 | bsz 1 | num_updates 22062 | best_loss 7.981
2022-03-07 07:01:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 22062 updates
2022-03-07 07:01:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:01:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:01:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 229 @ 22062 updates, score 13.244) (writing took 2.312307986896485 seconds)
2022-03-07 07:01:49 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-07 07:01:49 | INFO | train | epoch 229 | loss 1.83 | nll_loss 0.789 | ppl 1.73 | wps 22044.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22062 | lr 0.000212901 | gnorm 0.855 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 65421
2022-03-07 07:01:49 | INFO | fairseq.trainer | begin training epoch 230
2022-03-07 07:01:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:03:38 | INFO | train_inner | epoch 230:     38 / 97 loss=1.829, nll_loss=0.788, ppl=1.73, wps=22094, ups=0.34, wpb=65495, bsz=127.9, num_updates=22100, lr=0.000212718, gnorm=0.855, loss_scale=16, train_wall=266, gb_free=8.1, wall=65530
2022-03-07 07:05:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:06:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:06:32 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 13.169 | nll_loss 12.689 | ppl 6601.79 | wps 42507.3 | wpb 510.9 | bsz 1 | num_updates 22158 | best_loss 7.981
2022-03-07 07:06:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 22158 updates
2022-03-07 07:06:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 230 @ 22158 updates, score 13.169) (writing took 2.2616768279112875 seconds)
2022-03-07 07:06:34 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-07 07:06:34 | INFO | train | epoch 230 | loss 1.83 | nll_loss 0.789 | ppl 1.73 | wps 22052.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22158 | lr 0.000212439 | gnorm 0.872 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 65706
2022-03-07 07:06:34 | INFO | fairseq.trainer | begin training epoch 231
2022-03-07 07:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:08:34 | INFO | train_inner | epoch 231:     42 / 97 loss=1.83, nll_loss=0.79, ppl=1.73, wps=22064.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22200, lr=0.000212238, gnorm=0.874, loss_scale=16, train_wall=266, gb_free=8.1, wall=65826
2022-03-07 07:11:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:11:17 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 13.222 | nll_loss 12.742 | ppl 6851.69 | wps 42610.7 | wpb 510.9 | bsz 1 | num_updates 22255 | best_loss 7.981
2022-03-07 07:11:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 22255 updates
2022-03-07 07:11:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:11:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:11:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 231 @ 22255 updates, score 13.222) (writing took 2.2831791741773486 seconds)
2022-03-07 07:11:19 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-07 07:11:19 | INFO | train | epoch 231 | loss 1.827 | nll_loss 0.787 | ppl 1.73 | wps 22260.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22255 | lr 0.000211976 | gnorm 0.858 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 65991
2022-03-07 07:11:19 | INFO | fairseq.trainer | begin training epoch 232
2022-03-07 07:11:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:12:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:13:31 | INFO | train_inner | epoch 232:     46 / 97 loss=1.824, nll_loss=0.783, ppl=1.72, wps=22068, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22300, lr=0.000211762, gnorm=0.85, loss_scale=16, train_wall=266, gb_free=8.1, wall=66123
2022-03-07 07:15:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:16:02 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.208 | nll_loss 12.729 | ppl 6789.03 | wps 42391.2 | wpb 510.9 | bsz 1 | num_updates 22351 | best_loss 7.981
2022-03-07 07:16:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 22351 updates
2022-03-07 07:16:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:16:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:16:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 232 @ 22351 updates, score 13.208) (writing took 2.2249169261194766 seconds)
2022-03-07 07:16:05 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-07 07:16:05 | INFO | train | epoch 232 | loss 1.823 | nll_loss 0.783 | ppl 1.72 | wps 22035.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22351 | lr 0.00021152 | gnorm 0.851 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 66277
2022-03-07 07:16:05 | INFO | fairseq.trainer | begin training epoch 233
2022-03-07 07:16:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:18:25 | INFO | train_inner | epoch 233:     49 / 97 loss=1.824, nll_loss=0.784, ppl=1.72, wps=22284, ups=0.34, wpb=65495, bsz=127.9, num_updates=22400, lr=0.000211289, gnorm=0.854, loss_scale=16, train_wall=263, gb_free=8.1, wall=66417
2022-03-07 07:19:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:20:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:20:48 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 13.208 | nll_loss 12.728 | ppl 6784.06 | wps 42432.7 | wpb 510.9 | bsz 1 | num_updates 22447 | best_loss 7.981
2022-03-07 07:20:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 22447 updates
2022-03-07 07:20:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:20:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:20:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 233 @ 22447 updates, score 13.208) (writing took 2.29254780896008 seconds)
2022-03-07 07:20:50 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-07 07:20:50 | INFO | train | epoch 233 | loss 1.823 | nll_loss 0.782 | ppl 1.72 | wps 22042.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22447 | lr 0.000211067 | gnorm 0.863 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 66562
2022-03-07 07:20:50 | INFO | fairseq.trainer | begin training epoch 234
2022-03-07 07:20:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:23:22 | INFO | train_inner | epoch 234:     53 / 97 loss=1.821, nll_loss=0.781, ppl=1.72, wps=22068.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22500, lr=0.000210819, gnorm=0.863, loss_scale=16, train_wall=266, gb_free=8.1, wall=66714
2022-03-07 07:25:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:25:33 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 13.212 | nll_loss 12.733 | ppl 6806.54 | wps 42466 | wpb 510.9 | bsz 1 | num_updates 22544 | best_loss 7.981
2022-03-07 07:25:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 22544 updates
2022-03-07 07:25:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:25:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:25:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 234 @ 22544 updates, score 13.212) (writing took 2.2265883972868323 seconds)
2022-03-07 07:25:35 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-07 07:25:35 | INFO | train | epoch 234 | loss 1.82 | nll_loss 0.779 | ppl 1.72 | wps 22265.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22544 | lr 0.000210613 | gnorm 0.857 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 66847
2022-03-07 07:25:35 | INFO | fairseq.trainer | begin training epoch 235
2022-03-07 07:25:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:26:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:28:18 | INFO | train_inner | epoch 235:     57 / 97 loss=1.819, nll_loss=0.778, ppl=1.72, wps=22084.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=22600, lr=0.000210352, gnorm=0.854, loss_scale=16, train_wall=266, gb_free=8.1, wall=67010
2022-03-07 07:30:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:30:18 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 13.228 | nll_loss 12.749 | ppl 6883.84 | wps 42318.1 | wpb 510.9 | bsz 1 | num_updates 22640 | best_loss 7.981
2022-03-07 07:30:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 22640 updates
2022-03-07 07:30:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:30:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:30:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 235 @ 22640 updates, score 13.228) (writing took 2.2530283252708614 seconds)
2022-03-07 07:30:20 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-07 07:30:20 | INFO | train | epoch 235 | loss 1.817 | nll_loss 0.776 | ppl 1.71 | wps 22046.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22640 | lr 0.000210166 | gnorm 0.859 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 67132
2022-03-07 07:30:20 | INFO | fairseq.trainer | begin training epoch 236
2022-03-07 07:30:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:33:12 | INFO | train_inner | epoch 236:     60 / 97 loss=1.815, nll_loss=0.775, ppl=1.71, wps=22284.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22700, lr=0.000209888, gnorm=0.863, loss_scale=32, train_wall=263, gb_free=8.1, wall=67304
2022-03-07 07:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:35:03 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.22 | nll_loss 12.737 | ppl 6827.45 | wps 42433.1 | wpb 510.9 | bsz 1 | num_updates 22737 | best_loss 7.981
2022-03-07 07:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 22737 updates
2022-03-07 07:35:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:35:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 236 @ 22737 updates, score 13.22) (writing took 2.216371768154204 seconds)
2022-03-07 07:35:06 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-07 07:35:06 | INFO | train | epoch 236 | loss 1.815 | nll_loss 0.774 | ppl 1.71 | wps 22276.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22737 | lr 0.000209717 | gnorm 0.854 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 67417
2022-03-07 07:35:06 | INFO | fairseq.trainer | begin training epoch 237
2022-03-07 07:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:35:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:38:09 | INFO | train_inner | epoch 237:     64 / 97 loss=1.814, nll_loss=0.774, ppl=1.71, wps=22085.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=22800, lr=0.000209427, gnorm=0.846, loss_scale=16, train_wall=266, gb_free=8.1, wall=67601
2022-03-07 07:39:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:39:48 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 13.261 | nll_loss 12.784 | ppl 7054.21 | wps 42334.7 | wpb 510.9 | bsz 1 | num_updates 22833 | best_loss 7.981
2022-03-07 07:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 22833 updates
2022-03-07 07:39:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:39:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:39:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 237 @ 22833 updates, score 13.261) (writing took 2.352165416814387 seconds)
2022-03-07 07:39:51 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-07 07:39:51 | INFO | train | epoch 237 | loss 1.812 | nll_loss 0.772 | ppl 1.71 | wps 22043.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22833 | lr 0.000209276 | gnorm 0.846 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 67703
2022-03-07 07:39:51 | INFO | fairseq.trainer | begin training epoch 238
2022-03-07 07:39:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:42:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:43:06 | INFO | train_inner | epoch 238:     68 / 97 loss=1.811, nll_loss=0.771, ppl=1.71, wps=22061.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22900, lr=0.000208969, gnorm=0.85, loss_scale=16, train_wall=266, gb_free=8.1, wall=67898
2022-03-07 07:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:44:34 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.219 | nll_loss 12.74 | ppl 6840.89 | wps 42306.1 | wpb 510.9 | bsz 1 | num_updates 22929 | best_loss 7.981
2022-03-07 07:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 22929 updates
2022-03-07 07:44:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:44:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:44:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 238 @ 22929 updates, score 13.219) (writing took 2.2150355051271617 seconds)
2022-03-07 07:44:36 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-07 07:44:36 | INFO | train | epoch 238 | loss 1.811 | nll_loss 0.771 | ppl 1.71 | wps 22035.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22929 | lr 0.000208837 | gnorm 0.851 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 67988
2022-03-07 07:44:36 | INFO | fairseq.trainer | begin training epoch 239
2022-03-07 07:44:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:48:00 | INFO | train_inner | epoch 239:     71 / 97 loss=1.81, nll_loss=0.77, ppl=1.7, wps=22285.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23000, lr=0.000208514, gnorm=0.854, loss_scale=16, train_wall=263, gb_free=8.1, wall=68192
2022-03-07 07:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:49:19 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.221 | nll_loss 12.747 | ppl 6874.16 | wps 42154.2 | wpb 510.9 | bsz 1 | num_updates 23026 | best_loss 7.981
2022-03-07 07:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 23026 updates
2022-03-07 07:49:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:49:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 239 @ 23026 updates, score 13.221) (writing took 2.380997756961733 seconds)
2022-03-07 07:49:22 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 07:49:22 | INFO | train | epoch 239 | loss 1.809 | nll_loss 0.769 | ppl 1.7 | wps 22252 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23026 | lr 0.000208397 | gnorm 0.855 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 68273
2022-03-07 07:49:22 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 07:49:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:51:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:52:57 | INFO | train_inner | epoch 240:     75 / 97 loss=1.807, nll_loss=0.767, ppl=1.7, wps=22060, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23100, lr=0.000208063, gnorm=0.855, loss_scale=16, train_wall=266, gb_free=8.1, wall=68488
2022-03-07 07:53:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:54:05 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.253 | nll_loss 12.778 | ppl 7024.65 | wps 42569.8 | wpb 510.9 | bsz 1 | num_updates 23122 | best_loss 7.981
2022-03-07 07:54:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 23122 updates
2022-03-07 07:54:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:54:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:54:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 240 @ 23122 updates, score 13.253) (writing took 2.2869469239376485 seconds)
2022-03-07 07:54:07 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 07:54:07 | INFO | train | epoch 240 | loss 1.806 | nll_loss 0.766 | ppl 1.7 | wps 22036.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23122 | lr 0.000207964 | gnorm 0.851 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 68559
2022-03-07 07:54:07 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 07:54:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:57:50 | INFO | train_inner | epoch 241:     78 / 97 loss=1.806, nll_loss=0.766, ppl=1.7, wps=22302.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23200, lr=0.000207614, gnorm=0.85, loss_scale=32, train_wall=263, gb_free=8.1, wall=68782
2022-03-07 07:58:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:58:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:58:50 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 13.246 | nll_loss 12.773 | ppl 6998.93 | wps 42303.4 | wpb 510.9 | bsz 1 | num_updates 23218 | best_loss 7.981
2022-03-07 07:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 23218 updates
2022-03-07 07:58:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:58:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:58:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 241 @ 23218 updates, score 13.246) (writing took 2.2860122858546674 seconds)
2022-03-07 07:58:52 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 07:58:52 | INFO | train | epoch 241 | loss 1.804 | nll_loss 0.764 | ppl 1.7 | wps 22057 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23218 | lr 0.000207533 | gnorm 0.848 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 68844
2022-03-07 07:58:52 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 07:58:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:02:47 | INFO | train_inner | epoch 242:     82 / 97 loss=1.804, nll_loss=0.764, ppl=1.7, wps=22071.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23300, lr=0.000207168, gnorm=0.841, loss_scale=16, train_wall=266, gb_free=8.1, wall=69079
2022-03-07 08:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:03:35 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.33 | nll_loss 12.863 | ppl 7450.71 | wps 42282.6 | wpb 510.9 | bsz 1 | num_updates 23315 | best_loss 7.981
2022-03-07 08:03:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 23315 updates
2022-03-07 08:03:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:03:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:03:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 242 @ 23315 updates, score 13.33) (writing took 2.2745197135955095 seconds)
2022-03-07 08:03:37 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 08:03:37 | INFO | train | epoch 242 | loss 1.803 | nll_loss 0.763 | ppl 1.7 | wps 22264.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23315 | lr 0.000207101 | gnorm 0.848 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 69129
2022-03-07 08:03:37 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 08:03:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:05:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:07:44 | INFO | train_inner | epoch 243:     86 / 97 loss=1.801, nll_loss=0.761, ppl=1.69, wps=22058.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23400, lr=0.000206725, gnorm=0.857, loss_scale=16, train_wall=266, gb_free=8.1, wall=69376
2022-03-07 08:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:08:20 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.234 | nll_loss 12.757 | ppl 6922.78 | wps 42478.5 | wpb 510.9 | bsz 1 | num_updates 23411 | best_loss 7.981
2022-03-07 08:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 23411 updates
2022-03-07 08:08:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:08:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:08:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 243 @ 23411 updates, score 13.234) (writing took 2.253647461067885 seconds)
2022-03-07 08:08:23 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 08:08:23 | INFO | train | epoch 243 | loss 1.8 | nll_loss 0.76 | ppl 1.69 | wps 22030.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23411 | lr 0.000206676 | gnorm 0.854 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 69415
2022-03-07 08:08:23 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 08:08:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:12:38 | INFO | train_inner | epoch 244:     89 / 97 loss=1.799, nll_loss=0.759, ppl=1.69, wps=22284.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23500, lr=0.000206284, gnorm=0.859, loss_scale=32, train_wall=263, gb_free=8.1, wall=69670
2022-03-07 08:13:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:13:06 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.253 | nll_loss 12.775 | ppl 7010.79 | wps 42526 | wpb 510.9 | bsz 1 | num_updates 23508 | best_loss 7.981
2022-03-07 08:13:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 23508 updates
2022-03-07 08:13:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:13:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 244 @ 23508 updates, score 13.253) (writing took 2.3285778290592134 seconds)
2022-03-07 08:13:08 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 08:13:08 | INFO | train | epoch 244 | loss 1.798 | nll_loss 0.759 | ppl 1.69 | wps 22264.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23508 | lr 0.000206249 | gnorm 0.856 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 69700
2022-03-07 08:13:08 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 08:13:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:13:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:17:34 | INFO | train_inner | epoch 245:     93 / 97 loss=1.795, nll_loss=0.755, ppl=1.69, wps=22073, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23600, lr=0.000205847, gnorm=0.844, loss_scale=16, train_wall=266, gb_free=8.1, wall=69966
2022-03-07 08:17:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:17:51 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.254 | nll_loss 12.778 | ppl 7022.85 | wps 42542 | wpb 510.9 | bsz 1 | num_updates 23604 | best_loss 7.981
2022-03-07 08:17:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 23604 updates
2022-03-07 08:17:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:17:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 245 @ 23604 updates, score 13.254) (writing took 2.249698592349887 seconds)
2022-03-07 08:17:53 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 08:17:53 | INFO | train | epoch 245 | loss 1.794 | nll_loss 0.754 | ppl 1.69 | wps 22046.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23604 | lr 0.000205829 | gnorm 0.844 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 69985
2022-03-07 08:17:53 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 08:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:19:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:22:31 | INFO | train_inner | epoch 246:     97 / 97 loss=1.794, nll_loss=0.754, ppl=1.69, wps=22079.2, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=23700, lr=0.000205412, gnorm=0.854, loss_scale=16, train_wall=266, gb_free=8.1, wall=70263
2022-03-07 08:22:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:22:36 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.262 | nll_loss 12.788 | ppl 7070.77 | wps 42367.6 | wpb 510.9 | bsz 1 | num_updates 23700 | best_loss 7.981
2022-03-07 08:22:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 23700 updates
2022-03-07 08:22:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:22:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:22:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 246 @ 23700 updates, score 13.262) (writing took 2.191189595963806 seconds)
2022-03-07 08:22:38 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 08:22:38 | INFO | train | epoch 246 | loss 1.792 | nll_loss 0.752 | ppl 1.68 | wps 22049.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23700 | lr 0.000205412 | gnorm 0.852 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 70270
2022-03-07 08:22:38 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 08:22:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:26:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:27:21 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.255 | nll_loss 12.78 | ppl 7033.17 | wps 42654.2 | wpb 510.9 | bsz 1 | num_updates 23796 | best_loss 7.981
2022-03-07 08:27:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 23796 updates
2022-03-07 08:27:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:27:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:27:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 247 @ 23796 updates, score 13.255) (writing took 2.2265896280296147 seconds)
2022-03-07 08:27:23 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 08:27:23 | INFO | train | epoch 247 | loss 1.791 | nll_loss 0.751 | ppl 1.68 | wps 22043.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23796 | lr 0.000204997 | gnorm 0.84 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 70555
2022-03-07 08:27:23 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 08:27:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:27:35 | INFO | train_inner | epoch 248:      4 / 97 loss=1.789, nll_loss=0.749, ppl=1.68, wps=21532.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23800, lr=0.00020498, gnorm=0.839, loss_scale=16, train_wall=266, gb_free=8.1, wall=70567
2022-03-07 08:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:32:07 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 13.297 | nll_loss 12.819 | ppl 7227.49 | wps 42438.2 | wpb 510.9 | bsz 1 | num_updates 23893 | best_loss 7.981
2022-03-07 08:32:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 23893 updates
2022-03-07 08:32:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:32:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 248 @ 23893 updates, score 13.297) (writing took 2.25771320797503 seconds)
2022-03-07 08:32:09 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 08:32:09 | INFO | train | epoch 248 | loss 1.79 | nll_loss 0.75 | ppl 1.68 | wps 22241.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23893 | lr 0.000204581 | gnorm 0.841 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 70841
2022-03-07 08:32:09 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 08:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:32:29 | INFO | train_inner | epoch 249:      7 / 97 loss=1.789, nll_loss=0.749, ppl=1.68, wps=22261.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23900, lr=0.000204551, gnorm=0.841, loss_scale=16, train_wall=264, gb_free=8.1, wall=70861
2022-03-07 08:33:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:36:52 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 13.284 | nll_loss 12.811 | ppl 7186.53 | wps 42314.1 | wpb 510.9 | bsz 1 | num_updates 23989 | best_loss 7.981
2022-03-07 08:36:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 23989 updates
2022-03-07 08:36:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:36:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 249 @ 23989 updates, score 13.284) (writing took 2.381675634998828 seconds)
2022-03-07 08:36:55 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 08:36:55 | INFO | train | epoch 249 | loss 1.787 | nll_loss 0.747 | ppl 1.68 | wps 22018.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23989 | lr 0.000204171 | gnorm 0.842 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 71127
2022-03-07 08:36:55 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 08:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:37:26 | INFO | train_inner | epoch 250:     11 / 97 loss=1.786, nll_loss=0.746, ppl=1.68, wps=22052.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24000, lr=0.000204124, gnorm=0.84, loss_scale=16, train_wall=266, gb_free=8.1, wall=71158
2022-03-07 08:40:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:41:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:41:38 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.266 | nll_loss 12.789 | ppl 7078.05 | wps 42270.8 | wpb 510.9 | bsz 1 | num_updates 24085 | best_loss 7.981
2022-03-07 08:41:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 24085 updates
2022-03-07 08:41:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:41:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:41:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 250 @ 24085 updates, score 13.266) (writing took 2.2129014348611236 seconds)
2022-03-07 08:41:40 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 08:41:40 | INFO | train | epoch 250 | loss 1.786 | nll_loss 0.746 | ppl 1.68 | wps 22049.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24085 | lr 0.000203764 | gnorm 0.835 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 71412
2022-03-07 08:41:40 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 08:41:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:42:23 | INFO | train_inner | epoch 251:     15 / 97 loss=1.784, nll_loss=0.744, ppl=1.68, wps=22085, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24100, lr=0.0002037, gnorm=0.836, loss_scale=16, train_wall=266, gb_free=8.1, wall=71455
2022-03-07 08:46:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:46:23 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.269 | nll_loss 12.795 | ppl 7108.54 | wps 42528.5 | wpb 510.9 | bsz 1 | num_updates 24182 | best_loss 7.981
2022-03-07 08:46:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 24182 updates
2022-03-07 08:46:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:46:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:46:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 251 @ 24182 updates, score 13.269) (writing took 2.2804060857743025 seconds)
2022-03-07 08:46:25 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 08:46:25 | INFO | train | epoch 251 | loss 1.784 | nll_loss 0.744 | ppl 1.67 | wps 22269.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24182 | lr 0.000203355 | gnorm 0.844 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 71697
2022-03-07 08:46:25 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 08:46:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:47:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:47:20 | INFO | train_inner | epoch 252:     19 / 97 loss=1.782, nll_loss=0.742, ppl=1.67, wps=22070.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24200, lr=0.000203279, gnorm=0.843, loss_scale=16, train_wall=266, gb_free=8.1, wall=71751
2022-03-07 08:51:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:51:08 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.256 | nll_loss 12.784 | ppl 7051.91 | wps 42175.5 | wpb 510.9 | bsz 1 | num_updates 24278 | best_loss 7.981
2022-03-07 08:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 24278 updates
2022-03-07 08:51:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:51:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:51:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 252 @ 24278 updates, score 13.256) (writing took 2.286861422006041 seconds)
2022-03-07 08:51:11 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 08:51:11 | INFO | train | epoch 252 | loss 1.78 | nll_loss 0.74 | ppl 1.67 | wps 22023.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24278 | lr 0.000202952 | gnorm 0.84 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 71982
2022-03-07 08:51:11 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 08:51:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:52:14 | INFO | train_inner | epoch 253:     22 / 97 loss=1.78, nll_loss=0.74, ppl=1.67, wps=22264.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=24300, lr=0.00020286, gnorm=0.844, loss_scale=16, train_wall=264, gb_free=8.1, wall=72046
2022-03-07 08:54:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:55:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:55:53 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.251 | nll_loss 12.78 | ppl 7031.44 | wps 42519.5 | wpb 510.9 | bsz 1 | num_updates 24374 | best_loss 7.981
2022-03-07 08:55:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 24374 updates
2022-03-07 08:55:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:55:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:55:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 253 @ 24374 updates, score 13.251) (writing took 2.3536983062513173 seconds)
2022-03-07 08:55:56 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 08:55:56 | INFO | train | epoch 253 | loss 1.779 | nll_loss 0.739 | ppl 1.67 | wps 22048 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24374 | lr 0.000202552 | gnorm 0.845 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 72268
2022-03-07 08:55:56 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 08:55:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:57:10 | INFO | train_inner | epoch 254:     26 / 97 loss=1.777, nll_loss=0.737, ppl=1.67, wps=22075.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24400, lr=0.000202444, gnorm=0.839, loss_scale=16, train_wall=266, gb_free=8.1, wall=72342
2022-03-07 09:00:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:00:39 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.275 | nll_loss 12.805 | ppl 7154.64 | wps 42268 | wpb 510.9 | bsz 1 | num_updates 24471 | best_loss 7.981
2022-03-07 09:00:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 24471 updates
2022-03-07 09:00:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:00:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:00:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 254 @ 24471 updates, score 13.275) (writing took 2.1924275369383395 seconds)
2022-03-07 09:00:41 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 09:00:41 | INFO | train | epoch 254 | loss 1.777 | nll_loss 0.737 | ppl 1.67 | wps 22271.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24471 | lr 0.00020215 | gnorm 0.837 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 72553
2022-03-07 09:00:41 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 09:00:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:01:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:02:07 | INFO | train_inner | epoch 255:     30 / 97 loss=1.777, nll_loss=0.737, ppl=1.67, wps=22074.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24500, lr=0.000202031, gnorm=0.837, loss_scale=16, train_wall=266, gb_free=8.1, wall=72639
2022-03-07 09:05:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:05:24 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.282 | nll_loss 12.812 | ppl 7189.12 | wps 42367.8 | wpb 510.9 | bsz 1 | num_updates 24567 | best_loss 7.981
2022-03-07 09:05:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 24567 updates
2022-03-07 09:05:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:05:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:05:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 255 @ 24567 updates, score 13.282) (writing took 2.224684961140156 seconds)
2022-03-07 09:05:26 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 09:05:26 | INFO | train | epoch 255 | loss 1.775 | nll_loss 0.735 | ppl 1.66 | wps 22024.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24567 | lr 0.000201755 | gnorm 0.845 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 72838
2022-03-07 09:05:26 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 09:05:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:07:01 | INFO | train_inner | epoch 256:     33 / 97 loss=1.774, nll_loss=0.734, ppl=1.66, wps=22272.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=24600, lr=0.000201619, gnorm=0.842, loss_scale=16, train_wall=264, gb_free=8.1, wall=72933
2022-03-07 09:08:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:10:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:10:10 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.297 | nll_loss 12.826 | ppl 7260.09 | wps 42762.7 | wpb 510.9 | bsz 1 | num_updates 24663 | best_loss 7.981
2022-03-07 09:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 24663 updates
2022-03-07 09:10:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:10:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:10:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 256 @ 24663 updates, score 13.297) (writing took 2.2787128021009266 seconds)
2022-03-07 09:10:12 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 09:10:12 | INFO | train | epoch 256 | loss 1.773 | nll_loss 0.734 | ppl 1.66 | wps 22021.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24663 | lr 0.000201362 | gnorm 0.833 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 73124
2022-03-07 09:10:12 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 09:10:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:11:58 | INFO | train_inner | epoch 257:     37 / 97 loss=1.774, nll_loss=0.734, ppl=1.66, wps=22067.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24700, lr=0.000201211, gnorm=0.834, loss_scale=16, train_wall=266, gb_free=8.1, wall=73230
2022-03-07 09:14:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:14:55 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.282 | nll_loss 12.808 | ppl 7170.04 | wps 42655.2 | wpb 510.9 | bsz 1 | num_updates 24760 | best_loss 7.981
2022-03-07 09:14:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 24760 updates
2022-03-07 09:14:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:14:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:14:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 257 @ 24760 updates, score 13.282) (writing took 2.3349577230401337 seconds)
2022-03-07 09:14:57 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 09:14:57 | INFO | train | epoch 257 | loss 1.772 | nll_loss 0.732 | ppl 1.66 | wps 22285.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24760 | lr 0.000200967 | gnorm 0.835 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 73409
2022-03-07 09:14:57 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 09:14:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:16:52 | INFO | train_inner | epoch 258:     40 / 97 loss=1.77, nll_loss=0.73, ppl=1.66, wps=22301.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=24800, lr=0.000200805, gnorm=0.829, loss_scale=32, train_wall=263, gb_free=8.1, wall=73523
2022-03-07 09:18:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:19:40 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.32 | nll_loss 12.854 | ppl 7404.79 | wps 42365.8 | wpb 510.9 | bsz 1 | num_updates 24856 | best_loss 7.981
2022-03-07 09:19:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 24856 updates
2022-03-07 09:19:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:19:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:19:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 258 @ 24856 updates, score 13.32) (writing took 2.2478584833443165 seconds)
2022-03-07 09:19:42 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 09:19:42 | INFO | train | epoch 258 | loss 1.769 | nll_loss 0.729 | ppl 1.66 | wps 22052.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24856 | lr 0.000200579 | gnorm 0.828 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 73694
2022-03-07 09:19:42 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 09:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:21:48 | INFO | train_inner | epoch 259:     44 / 97 loss=1.768, nll_loss=0.728, ppl=1.66, wps=22072.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24900, lr=0.000200401, gnorm=0.836, loss_scale=16, train_wall=266, gb_free=8.1, wall=73820
2022-03-07 09:24:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:24:25 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.324 | nll_loss 12.851 | ppl 7389.13 | wps 42518.6 | wpb 510.9 | bsz 1 | num_updates 24953 | best_loss 7.981
2022-03-07 09:24:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 24953 updates
2022-03-07 09:24:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:24:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:24:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 259 @ 24953 updates, score 13.324) (writing took 2.278805846348405 seconds)
2022-03-07 09:24:27 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 09:24:27 | INFO | train | epoch 259 | loss 1.767 | nll_loss 0.728 | ppl 1.66 | wps 22271.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24953 | lr 0.000200188 | gnorm 0.835 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 73979
2022-03-07 09:24:27 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 09:24:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:25:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:26:45 | INFO | train_inner | epoch 260:     48 / 97 loss=1.765, nll_loss=0.726, ppl=1.65, wps=22073.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25000, lr=0.0002, gnorm=0.825, loss_scale=16, train_wall=266, gb_free=8.1, wall=74117
2022-03-07 09:29:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:29:10 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.296 | nll_loss 12.829 | ppl 7274.76 | wps 42549.6 | wpb 510.9 | bsz 1 | num_updates 25049 | best_loss 7.981
2022-03-07 09:29:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 25049 updates
2022-03-07 09:29:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:29:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:29:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 260 @ 25049 updates, score 13.296) (writing took 2.314290275797248 seconds)
2022-03-07 09:29:13 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 09:29:13 | INFO | train | epoch 260 | loss 1.766 | nll_loss 0.726 | ppl 1.65 | wps 22025.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25049 | lr 0.000199804 | gnorm 0.829 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 74265
2022-03-07 09:29:13 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 09:29:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:31:39 | INFO | train_inner | epoch 261:     51 / 97 loss=1.766, nll_loss=0.727, ppl=1.66, wps=22281.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25100, lr=0.000199601, gnorm=0.838, loss_scale=32, train_wall=263, gb_free=8.1, wall=74411
2022-03-07 09:32:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:33:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:33:56 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.295 | nll_loss 12.827 | ppl 7263.81 | wps 42672.1 | wpb 510.9 | bsz 1 | num_updates 25145 | best_loss 7.981
2022-03-07 09:33:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 25145 updates
2022-03-07 09:33:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:33:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:33:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 261 @ 25145 updates, score 13.295) (writing took 2.3954807589761913 seconds)
2022-03-07 09:33:58 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 09:33:58 | INFO | train | epoch 261 | loss 1.764 | nll_loss 0.725 | ppl 1.65 | wps 22041 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25145 | lr 0.000199423 | gnorm 0.833 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 74550
2022-03-07 09:33:58 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 09:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:36:36 | INFO | train_inner | epoch 262:     55 / 97 loss=1.763, nll_loss=0.724, ppl=1.65, wps=22064.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25200, lr=0.000199205, gnorm=0.833, loss_scale=16, train_wall=266, gb_free=8.1, wall=74708
2022-03-07 09:38:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:38:41 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.294 | nll_loss 12.825 | ppl 7254.44 | wps 42450.8 | wpb 510.9 | bsz 1 | num_updates 25242 | best_loss 7.981
2022-03-07 09:38:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 25242 updates
2022-03-07 09:38:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:38:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:38:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 262 @ 25242 updates, score 13.294) (writing took 2.2191985910758376 seconds)
2022-03-07 09:38:43 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 09:38:43 | INFO | train | epoch 262 | loss 1.762 | nll_loss 0.723 | ppl 1.65 | wps 22265.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25242 | lr 0.000199039 | gnorm 0.834 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 74835
2022-03-07 09:38:43 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 09:38:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:39:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:41:32 | INFO | train_inner | epoch 263:     59 / 97 loss=1.762, nll_loss=0.722, ppl=1.65, wps=22088.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=25300, lr=0.000198811, gnorm=0.833, loss_scale=16, train_wall=266, gb_free=8.1, wall=75004
2022-03-07 09:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:43:26 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.322 | nll_loss 12.851 | ppl 7387.08 | wps 42440.7 | wpb 510.9 | bsz 1 | num_updates 25338 | best_loss 7.981
2022-03-07 09:43:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 25338 updates
2022-03-07 09:43:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:43:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:43:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 263 @ 25338 updates, score 13.322) (writing took 2.2712109279818833 seconds)
2022-03-07 09:43:28 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 09:43:28 | INFO | train | epoch 263 | loss 1.761 | nll_loss 0.721 | ppl 1.65 | wps 22062.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25338 | lr 0.000198662 | gnorm 0.837 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 75120
2022-03-07 09:43:28 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 09:43:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:46:26 | INFO | train_inner | epoch 264:     62 / 97 loss=1.759, nll_loss=0.719, ppl=1.65, wps=22306.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25400, lr=0.000198419, gnorm=0.836, loss_scale=32, train_wall=263, gb_free=8.1, wall=75298
2022-03-07 09:47:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:48:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:48:11 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.285 | nll_loss 12.817 | ppl 7213.77 | wps 42306.3 | wpb 510.9 | bsz 1 | num_updates 25434 | best_loss 7.981
2022-03-07 09:48:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 25434 updates
2022-03-07 09:48:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:48:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:48:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 264 @ 25434 updates, score 13.285) (writing took 2.3815364437177777 seconds)
2022-03-07 09:48:13 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 09:48:13 | INFO | train | epoch 264 | loss 1.759 | nll_loss 0.72 | ppl 1.65 | wps 22038.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25434 | lr 0.000198286 | gnorm 0.827 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 75405
2022-03-07 09:48:14 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 09:48:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:51:23 | INFO | train_inner | epoch 265:     66 / 97 loss=1.757, nll_loss=0.718, ppl=1.64, wps=22055, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=25500, lr=0.00019803, gnorm=0.818, loss_scale=16, train_wall=266, gb_free=8.1, wall=75595
2022-03-07 09:52:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:52:57 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.274 | nll_loss 12.804 | ppl 7152.63 | wps 42607.1 | wpb 510.9 | bsz 1 | num_updates 25531 | best_loss 7.981
2022-03-07 09:52:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 25531 updates
2022-03-07 09:52:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:52:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:52:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 265 @ 25531 updates, score 13.274) (writing took 2.315682840999216 seconds)
2022-03-07 09:52:59 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 09:52:59 | INFO | train | epoch 265 | loss 1.757 | nll_loss 0.718 | ppl 1.64 | wps 22262.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25531 | lr 0.000197909 | gnorm 0.825 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 75691
2022-03-07 09:52:59 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 09:52:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:53:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:56:19 | INFO | train_inner | epoch 266:     70 / 97 loss=1.758, nll_loss=0.719, ppl=1.65, wps=22078.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=25600, lr=0.000197642, gnorm=0.838, loss_scale=16, train_wall=266, gb_free=8.1, wall=75891
2022-03-07 09:57:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:57:42 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.287 | nll_loss 12.817 | ppl 7218.29 | wps 42354.7 | wpb 510.9 | bsz 1 | num_updates 25627 | best_loss 7.981
2022-03-07 09:57:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 25627 updates
2022-03-07 09:57:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:57:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:57:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 266 @ 25627 updates, score 13.287) (writing took 2.1846383060328662 seconds)
2022-03-07 09:57:44 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 09:57:44 | INFO | train | epoch 266 | loss 1.756 | nll_loss 0.716 | ppl 1.64 | wps 22050.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25627 | lr 0.000197538 | gnorm 0.837 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 75976
2022-03-07 09:57:44 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 09:57:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:01:13 | INFO | train_inner | epoch 267:     73 / 97 loss=1.754, nll_loss=0.715, ppl=1.64, wps=22303.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=25700, lr=0.000197257, gnorm=0.829, loss_scale=32, train_wall=263, gb_free=8.1, wall=76185
2022-03-07 10:01:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:02:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:02:27 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.264 | nll_loss 12.796 | ppl 7110.72 | wps 42257.6 | wpb 510.9 | bsz 1 | num_updates 25723 | best_loss 7.981
2022-03-07 10:02:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 25723 updates
2022-03-07 10:02:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:02:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:02:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 267 @ 25723 updates, score 13.264) (writing took 2.2903757500462234 seconds)
2022-03-07 10:02:29 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 10:02:29 | INFO | train | epoch 267 | loss 1.754 | nll_loss 0.715 | ppl 1.64 | wps 22054.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25723 | lr 0.000197169 | gnorm 0.829 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 76261
2022-03-07 10:02:29 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 10:02:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:06:10 | INFO | train_inner | epoch 268:     77 / 97 loss=1.753, nll_loss=0.714, ppl=1.64, wps=22069.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25800, lr=0.000196875, gnorm=0.839, loss_scale=16, train_wall=266, gb_free=8.1, wall=76482
2022-03-07 10:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:07:12 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.304 | nll_loss 12.839 | ppl 7327.66 | wps 42139.9 | wpb 510.9 | bsz 1 | num_updates 25820 | best_loss 7.981
2022-03-07 10:07:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 25820 updates
2022-03-07 10:07:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:07:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:07:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 268 @ 25820 updates, score 13.304) (writing took 2.2238519843667746 seconds)
2022-03-07 10:07:14 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 10:07:14 | INFO | train | epoch 268 | loss 1.752 | nll_loss 0.713 | ppl 1.64 | wps 22260.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25820 | lr 0.000196799 | gnorm 0.84 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 76546
2022-03-07 10:07:14 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 10:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:08:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:11:06 | INFO | train_inner | epoch 269:     81 / 97 loss=1.752, nll_loss=0.713, ppl=1.64, wps=22080.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25900, lr=0.000196494, gnorm=0.827, loss_scale=16, train_wall=266, gb_free=8.1, wall=76778
2022-03-07 10:11:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:11:57 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.299 | nll_loss 12.833 | ppl 7297.9 | wps 42456.2 | wpb 510.9 | bsz 1 | num_updates 25916 | best_loss 7.981
2022-03-07 10:11:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 25916 updates
2022-03-07 10:11:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:11:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:11:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 269 @ 25916 updates, score 13.299) (writing took 2.271525093819946 seconds)
2022-03-07 10:11:59 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 10:11:59 | INFO | train | epoch 269 | loss 1.75 | nll_loss 0.711 | ppl 1.64 | wps 22055.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25916 | lr 0.000196434 | gnorm 0.822 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 76831
2022-03-07 10:12:00 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 10:12:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:15:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:16:03 | INFO | train_inner | epoch 270:     85 / 97 loss=1.75, nll_loss=0.711, ppl=1.64, wps=22090.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26000, lr=0.000196116, gnorm=0.829, loss_scale=16, train_wall=266, gb_free=8.1, wall=77075
2022-03-07 10:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:16:42 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.337 | nll_loss 12.874 | ppl 7509.1 | wps 42412.3 | wpb 510.9 | bsz 1 | num_updates 26012 | best_loss 7.981
2022-03-07 10:16:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 26012 updates
2022-03-07 10:16:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 270 @ 26012 updates, score 13.337) (writing took 2.2546250498853624 seconds)
2022-03-07 10:16:45 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 10:16:45 | INFO | train | epoch 270 | loss 1.748 | nll_loss 0.709 | ppl 1.63 | wps 22058.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26012 | lr 0.000196071 | gnorm 0.829 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 77116
2022-03-07 10:16:45 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 10:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:20:57 | INFO | train_inner | epoch 271:     88 / 97 loss=1.747, nll_loss=0.707, ppl=1.63, wps=22294.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26100, lr=0.00019574, gnorm=0.82, loss_scale=16, train_wall=263, gb_free=8.1, wall=77369
2022-03-07 10:21:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:21:27 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.304 | nll_loss 12.833 | ppl 7294.12 | wps 42297.6 | wpb 510.9 | bsz 1 | num_updates 26109 | best_loss 7.981
2022-03-07 10:21:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 26109 updates
2022-03-07 10:21:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:21:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:21:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 271 @ 26109 updates, score 13.304) (writing took 2.2921592802740633 seconds)
2022-03-07 10:21:30 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 10:21:30 | INFO | train | epoch 271 | loss 1.747 | nll_loss 0.707 | ppl 1.63 | wps 22271.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26109 | lr 0.000195706 | gnorm 0.821 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 77402
2022-03-07 10:21:30 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 10:21:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:21:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:25:53 | INFO | train_inner | epoch 272:     92 / 97 loss=1.746, nll_loss=0.707, ppl=1.63, wps=22081.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26200, lr=0.000195366, gnorm=0.831, loss_scale=16, train_wall=266, gb_free=8.1, wall=77665
2022-03-07 10:26:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:26:13 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.301 | nll_loss 12.835 | ppl 7304.99 | wps 42410.3 | wpb 510.9 | bsz 1 | num_updates 26205 | best_loss 7.981
2022-03-07 10:26:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 26205 updates
2022-03-07 10:26:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:26:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:26:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 272 @ 26205 updates, score 13.301) (writing took 2.2356311129406095 seconds)
2022-03-07 10:26:15 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 10:26:15 | INFO | train | epoch 272 | loss 1.745 | nll_loss 0.706 | ppl 1.63 | wps 22049 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26205 | lr 0.000195348 | gnorm 0.83 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 77687
2022-03-07 10:26:15 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 10:26:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:30:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:30:50 | INFO | train_inner | epoch 273:     96 / 97 loss=1.744, nll_loss=0.705, ppl=1.63, wps=22071.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26300, lr=0.000194994, gnorm=0.826, loss_scale=16, train_wall=266, gb_free=8.1, wall=77962
2022-03-07 10:30:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:30:58 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.353 | nll_loss 12.888 | ppl 7578.54 | wps 42231.1 | wpb 510.9 | bsz 1 | num_updates 26301 | best_loss 7.981
2022-03-07 10:30:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 26301 updates
2022-03-07 10:30:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:31:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:31:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 273 @ 26301 updates, score 13.353) (writing took 2.264884158037603 seconds)
2022-03-07 10:31:00 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 10:31:00 | INFO | train | epoch 273 | loss 1.743 | nll_loss 0.703 | ppl 1.63 | wps 22038.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26301 | lr 0.000194991 | gnorm 0.825 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 77972
2022-03-07 10:31:00 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 10:31:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:35:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:35:43 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 13.352 | nll_loss 12.888 | ppl 7582.09 | wps 42161.8 | wpb 510.9 | bsz 1 | num_updates 26398 | best_loss 7.981
2022-03-07 10:35:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 26398 updates
2022-03-07 10:35:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:35:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:35:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 274 @ 26398 updates, score 13.352) (writing took 2.2683232980780303 seconds)
2022-03-07 10:35:45 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 10:35:45 | INFO | train | epoch 274 | loss 1.742 | nll_loss 0.703 | ppl 1.63 | wps 22282.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26398 | lr 0.000194632 | gnorm 0.832 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 78257
2022-03-07 10:35:45 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 10:35:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:35:51 | INFO | train_inner | epoch 275:      2 / 97 loss=1.742, nll_loss=0.703, ppl=1.63, wps=21735.1, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=26400, lr=0.000194625, gnorm=0.832, loss_scale=16, train_wall=263, gb_free=8.1, wall=78263
2022-03-07 10:37:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:40:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:40:28 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.294 | nll_loss 12.827 | ppl 7268.42 | wps 42574.9 | wpb 510.9 | bsz 1 | num_updates 26494 | best_loss 7.981
2022-03-07 10:40:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 26494 updates
2022-03-07 10:40:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:40:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 275 @ 26494 updates, score 13.294) (writing took 2.257285561878234 seconds)
2022-03-07 10:40:31 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 10:40:31 | INFO | train | epoch 275 | loss 1.74 | nll_loss 0.701 | ppl 1.63 | wps 22037.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26494 | lr 0.000194279 | gnorm 0.827 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 78542
2022-03-07 10:40:31 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 10:40:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:40:48 | INFO | train_inner | epoch 276:      6 / 97 loss=1.738, nll_loss=0.699, ppl=1.62, wps=22074.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26500, lr=0.000194257, gnorm=0.826, loss_scale=16, train_wall=266, gb_free=8.1, wall=78560
2022-03-07 10:44:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:45:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:45:13 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.28 | nll_loss 12.812 | ppl 7191.06 | wps 42626.5 | wpb 510.9 | bsz 1 | num_updates 26590 | best_loss 7.981
2022-03-07 10:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 26590 updates
2022-03-07 10:45:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 276 @ 26590 updates, score 13.28) (writing took 2.3753902330063283 seconds)
2022-03-07 10:45:16 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 10:45:16 | INFO | train | epoch 276 | loss 1.738 | nll_loss 0.699 | ppl 1.62 | wps 22052.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26590 | lr 0.000193928 | gnorm 0.822 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 78828
2022-03-07 10:45:16 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 10:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:45:44 | INFO | train_inner | epoch 277:     10 / 97 loss=1.737, nll_loss=0.698, ppl=1.62, wps=22086, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26600, lr=0.000193892, gnorm=0.821, loss_scale=16, train_wall=266, gb_free=8.1, wall=78856
2022-03-07 10:49:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:49:58 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.345 | nll_loss 12.882 | ppl 7548.44 | wps 42750.3 | wpb 510.9 | bsz 1 | num_updates 26687 | best_loss 7.981
2022-03-07 10:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 26687 updates
2022-03-07 10:49:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:50:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:50:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 277 @ 26687 updates, score 13.345) (writing took 2.3379621380008757 seconds)
2022-03-07 10:50:00 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 10:50:00 | INFO | train | epoch 277 | loss 1.735 | nll_loss 0.696 | ppl 1.62 | wps 22309.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26687 | lr 0.000193575 | gnorm 0.812 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 79112
2022-03-07 10:50:00 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 10:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:50:38 | INFO | train_inner | epoch 278:     13 / 97 loss=1.735, nll_loss=0.696, ppl=1.62, wps=22331.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26700, lr=0.000193528, gnorm=0.811, loss_scale=16, train_wall=263, gb_free=8.1, wall=79150
2022-03-07 10:52:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:54:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:54:43 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.325 | nll_loss 12.861 | ppl 7440.52 | wps 42663.4 | wpb 510.9 | bsz 1 | num_updates 26783 | best_loss 7.981
2022-03-07 10:54:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 26783 updates
2022-03-07 10:54:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:54:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:54:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 278 @ 26783 updates, score 13.325) (writing took 2.202285904902965 seconds)
2022-03-07 10:54:45 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 10:54:45 | INFO | train | epoch 278 | loss 1.735 | nll_loss 0.696 | ppl 1.62 | wps 22082.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26783 | lr 0.000193228 | gnorm 0.818 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 79397
2022-03-07 10:54:45 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 10:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:55:34 | INFO | train_inner | epoch 279:     17 / 97 loss=1.734, nll_loss=0.695, ppl=1.62, wps=22106.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26800, lr=0.000193167, gnorm=0.818, loss_scale=16, train_wall=266, gb_free=8.1, wall=79446
2022-03-07 10:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:59:28 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.372 | nll_loss 12.91 | ppl 7697.95 | wps 42841.5 | wpb 510.9 | bsz 1 | num_updates 26880 | best_loss 7.981
2022-03-07 10:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 26880 updates
2022-03-07 10:59:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:59:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 279 @ 26880 updates, score 13.372) (writing took 2.208653974812478 seconds)
2022-03-07 10:59:30 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 10:59:30 | INFO | train | epoch 279 | loss 1.734 | nll_loss 0.695 | ppl 1.62 | wps 22301.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26880 | lr 0.000192879 | gnorm 0.821 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 79682
2022-03-07 10:59:30 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 10:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:00:27 | INFO | train_inner | epoch 280:     20 / 97 loss=1.732, nll_loss=0.694, ppl=1.62, wps=22325.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26900, lr=0.000192807, gnorm=0.82, loss_scale=32, train_wall=263, gb_free=8.1, wall=79739
2022-03-07 11:00:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:04:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:04:13 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.338 | nll_loss 12.874 | ppl 7509.31 | wps 42587.8 | wpb 510.9 | bsz 1 | num_updates 26976 | best_loss 7.981
2022-03-07 11:04:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 26976 updates
2022-03-07 11:04:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:04:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 280 @ 26976 updates, score 13.338) (writing took 2.2799999928101897 seconds)
2022-03-07 11:04:15 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 11:04:15 | INFO | train | epoch 280 | loss 1.732 | nll_loss 0.693 | ppl 1.62 | wps 22072.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26976 | lr 0.000192536 | gnorm 0.817 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 79967
2022-03-07 11:04:15 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 11:04:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:05:24 | INFO | train_inner | epoch 281:     24 / 97 loss=1.73, nll_loss=0.692, ppl=1.62, wps=22106.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27000, lr=0.00019245, gnorm=0.822, loss_scale=16, train_wall=266, gb_free=8.1, wall=80035
2022-03-07 11:07:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:08:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:08:57 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.344 | nll_loss 12.876 | ppl 7517.47 | wps 42327.8 | wpb 510.9 | bsz 1 | num_updates 27072 | best_loss 7.981
2022-03-07 11:08:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 27072 updates
2022-03-07 11:08:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:08:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:09:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 281 @ 27072 updates, score 13.344) (writing took 2.3287306358106434 seconds)
2022-03-07 11:09:00 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 11:09:00 | INFO | train | epoch 281 | loss 1.73 | nll_loss 0.691 | ppl 1.61 | wps 22079.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27072 | lr 0.000192194 | gnorm 0.821 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 80251
2022-03-07 11:09:00 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 11:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:10:20 | INFO | train_inner | epoch 282:     28 / 97 loss=1.728, nll_loss=0.689, ppl=1.61, wps=22110.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=27100, lr=0.000192095, gnorm=0.815, loss_scale=16, train_wall=265, gb_free=8.1, wall=80332
2022-03-07 11:13:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:13:42 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.32 | nll_loss 12.857 | ppl 7417.31 | wps 42818.7 | wpb 510.9 | bsz 1 | num_updates 27169 | best_loss 7.981
2022-03-07 11:13:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 27169 updates
2022-03-07 11:13:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:13:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:13:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 282 @ 27169 updates, score 13.32) (writing took 2.255568286869675 seconds)
2022-03-07 11:13:44 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 11:13:44 | INFO | train | epoch 282 | loss 1.729 | nll_loss 0.69 | ppl 1.61 | wps 22330.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27169 | lr 0.000191851 | gnorm 0.822 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 80536
2022-03-07 11:13:44 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 11:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:15:12 | INFO | train_inner | epoch 283:     31 / 97 loss=1.729, nll_loss=0.691, ppl=1.61, wps=22373, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27200, lr=0.000191741, gnorm=0.817, loss_scale=32, train_wall=263, gb_free=8.1, wall=80624
2022-03-07 11:17:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:18:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:18:25 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.345 | nll_loss 12.883 | ppl 7555.45 | wps 43112.9 | wpb 510.9 | bsz 1 | num_updates 27265 | best_loss 7.981
2022-03-07 11:18:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 27265 updates
2022-03-07 11:18:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:18:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:18:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 283 @ 27265 updates, score 13.345) (writing took 2.3274588650092483 seconds)
2022-03-07 11:18:28 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 11:18:28 | INFO | train | epoch 283 | loss 1.726 | nll_loss 0.687 | ppl 1.61 | wps 22163 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27265 | lr 0.000191513 | gnorm 0.8 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 80820
2022-03-07 11:18:28 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 11:18:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:20:08 | INFO | train_inner | epoch 284:     35 / 97 loss=1.725, nll_loss=0.686, ppl=1.61, wps=22192.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27300, lr=0.00019139, gnorm=0.801, loss_scale=16, train_wall=265, gb_free=8.1, wall=80919
2022-03-07 11:23:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:23:09 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.375 | nll_loss 12.911 | ppl 7704.01 | wps 42980 | wpb 510.9 | bsz 1 | num_updates 27362 | best_loss 7.981
2022-03-07 11:23:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 27362 updates
2022-03-07 11:23:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:23:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:23:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 284 @ 27362 updates, score 13.375) (writing took 2.2418388831429183 seconds)
2022-03-07 11:23:11 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 11:23:11 | INFO | train | epoch 284 | loss 1.726 | nll_loss 0.687 | ppl 1.61 | wps 22394.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27362 | lr 0.000191173 | gnorm 0.808 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 81103
2022-03-07 11:23:11 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 11:23:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:24:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:25:03 | INFO | train_inner | epoch 285:     39 / 97 loss=1.725, nll_loss=0.686, ppl=1.61, wps=22199.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27400, lr=0.00019104, gnorm=0.809, loss_scale=16, train_wall=265, gb_free=8.1, wall=81215
2022-03-07 11:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:27:53 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.305 | nll_loss 12.838 | ppl 7323.52 | wps 43100.2 | wpb 510.9 | bsz 1 | num_updates 27458 | best_loss 7.981
2022-03-07 11:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 27458 updates
2022-03-07 11:27:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:27:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:27:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 285 @ 27458 updates, score 13.305) (writing took 2.245569767896086 seconds)
2022-03-07 11:27:55 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 11:27:55 | INFO | train | epoch 285 | loss 1.725 | nll_loss 0.686 | ppl 1.61 | wps 22183.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27458 | lr 0.000190838 | gnorm 0.819 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 81387
2022-03-07 11:27:55 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 11:27:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:29:55 | INFO | train_inner | epoch 286:     42 / 97 loss=1.724, nll_loss=0.686, ppl=1.61, wps=22433.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27500, lr=0.000190693, gnorm=0.816, loss_scale=16, train_wall=262, gb_free=8.1, wall=81506
2022-03-07 11:30:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:32:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:32:36 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.337 | nll_loss 12.874 | ppl 7506.08 | wps 42744.1 | wpb 510.9 | bsz 1 | num_updates 27554 | best_loss 7.981
2022-03-07 11:32:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 27554 updates
2022-03-07 11:32:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:32:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:32:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 286 @ 27554 updates, score 13.337) (writing took 2.21259393915534 seconds)
2022-03-07 11:32:38 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 11:32:38 | INFO | train | epoch 286 | loss 1.722 | nll_loss 0.683 | ppl 1.61 | wps 22183.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27554 | lr 0.000190506 | gnorm 0.81 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 81670
2022-03-07 11:32:38 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 11:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:34:49 | INFO | train_inner | epoch 287:     46 / 97 loss=1.721, nll_loss=0.682, ppl=1.6, wps=22221.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27600, lr=0.000190347, gnorm=0.822, loss_scale=16, train_wall=265, gb_free=8.1, wall=81801
2022-03-07 11:37:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:37:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:37:19 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.381 | nll_loss 12.916 | ppl 7726.93 | wps 42881.8 | wpb 510.9 | bsz 1 | num_updates 27650 | best_loss 7.981
2022-03-07 11:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 27650 updates
2022-03-07 11:37:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:37:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:37:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 287 @ 27650 updates, score 13.381) (writing took 2.202339373063296 seconds)
2022-03-07 11:37:21 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 11:37:21 | INFO | train | epoch 287 | loss 1.721 | nll_loss 0.682 | ppl 1.6 | wps 22195.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27650 | lr 0.000190175 | gnorm 0.815 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 81953
2022-03-07 11:37:22 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 11:37:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:39:44 | INFO | train_inner | epoch 288:     50 / 97 loss=1.72, nll_loss=0.681, ppl=1.6, wps=22224.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=27700, lr=0.000190003, gnorm=0.81, loss_scale=16, train_wall=265, gb_free=8.1, wall=82096
2022-03-07 11:41:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:42:03 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.324 | nll_loss 12.861 | ppl 7441.25 | wps 43269.9 | wpb 510.9 | bsz 1 | num_updates 27747 | best_loss 7.981
2022-03-07 11:42:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 27747 updates
2022-03-07 11:42:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:42:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:42:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 288 @ 27747 updates, score 13.324) (writing took 2.2340286220423877 seconds)
2022-03-07 11:42:05 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 11:42:05 | INFO | train | epoch 288 | loss 1.72 | nll_loss 0.681 | ppl 1.6 | wps 22423.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27747 | lr 0.000189842 | gnorm 0.821 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 82237
2022-03-07 11:42:05 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 11:42:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:44:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:44:39 | INFO | train_inner | epoch 289:     54 / 97 loss=1.719, nll_loss=0.681, ppl=1.6, wps=22227.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27800, lr=0.000189661, gnorm=0.809, loss_scale=16, train_wall=265, gb_free=8.1, wall=82391
2022-03-07 11:46:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:46:46 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.368 | nll_loss 12.904 | ppl 7666.02 | wps 42824.2 | wpb 510.9 | bsz 1 | num_updates 27843 | best_loss 7.981
2022-03-07 11:46:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 27843 updates
2022-03-07 11:46:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:46:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:46:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 289 @ 27843 updates, score 13.368) (writing took 2.2316539930179715 seconds)
2022-03-07 11:46:48 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 11:46:48 | INFO | train | epoch 289 | loss 1.717 | nll_loss 0.678 | ppl 1.6 | wps 22198.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27843 | lr 0.000189514 | gnorm 0.798 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 82520
2022-03-07 11:46:48 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 11:46:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:49:30 | INFO | train_inner | epoch 290:     57 / 97 loss=1.717, nll_loss=0.679, ppl=1.6, wps=22440.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27900, lr=0.000189321, gnorm=0.81, loss_scale=16, train_wall=262, gb_free=8.1, wall=82682
2022-03-07 11:51:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:51:29 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.337 | nll_loss 12.879 | ppl 7532.46 | wps 43046.1 | wpb 510.9 | bsz 1 | num_updates 27940 | best_loss 7.981
2022-03-07 11:51:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 27940 updates
2022-03-07 11:51:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 290 @ 27940 updates, score 13.337) (writing took 2.1803492377512157 seconds)
2022-03-07 11:51:31 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 11:51:31 | INFO | train | epoch 290 | loss 1.716 | nll_loss 0.678 | ppl 1.6 | wps 22416.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27940 | lr 0.000189185 | gnorm 0.813 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 82803
2022-03-07 11:51:31 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 11:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:53:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:54:25 | INFO | train_inner | epoch 291:     61 / 97 loss=1.714, nll_loss=0.676, ppl=1.6, wps=22212.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=28000, lr=0.000188982, gnorm=0.808, loss_scale=16, train_wall=265, gb_free=8.1, wall=82977
2022-03-07 11:56:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:56:13 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.319 | nll_loss 12.854 | ppl 7405.34 | wps 43051.2 | wpb 510.9 | bsz 1 | num_updates 28036 | best_loss 7.981
2022-03-07 11:56:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 28036 updates
2022-03-07 11:56:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:56:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:56:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 291 @ 28036 updates, score 13.319) (writing took 2.18759718677029 seconds)
2022-03-07 11:56:15 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 11:56:15 | INFO | train | epoch 291 | loss 1.715 | nll_loss 0.676 | ppl 1.6 | wps 22179.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28036 | lr 0.000188861 | gnorm 0.808 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 83087
2022-03-07 11:56:15 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 11:56:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:59:17 | INFO | train_inner | epoch 292:     64 / 97 loss=1.714, nll_loss=0.676, ppl=1.6, wps=22431.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=28100, lr=0.000188646, gnorm=0.813, loss_scale=16, train_wall=262, gb_free=8.1, wall=83269
2022-03-07 12:00:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:00:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:00:56 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.363 | nll_loss 12.903 | ppl 7659.94 | wps 43023.9 | wpb 510.9 | bsz 1 | num_updates 28132 | best_loss 7.981
2022-03-07 12:00:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 28132 updates
2022-03-07 12:00:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:00:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:00:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 292 @ 28132 updates, score 13.363) (writing took 2.1858337316662073 seconds)
2022-03-07 12:00:58 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 12:00:58 | INFO | train | epoch 292 | loss 1.713 | nll_loss 0.674 | ppl 1.6 | wps 22182.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28132 | lr 0.000188538 | gnorm 0.817 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 83370
2022-03-07 12:00:58 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 12:00:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:04:12 | INFO | train_inner | epoch 293:     68 / 97 loss=1.713, nll_loss=0.674, ppl=1.6, wps=22229.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28200, lr=0.000188311, gnorm=0.817, loss_scale=16, train_wall=265, gb_free=8.1, wall=83564
2022-03-07 12:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:05:39 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 13.393 | nll_loss 12.935 | ppl 7832.35 | wps 42845.8 | wpb 510.9 | bsz 1 | num_updates 28229 | best_loss 7.981
2022-03-07 12:05:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 28229 updates
2022-03-07 12:05:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:05:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:05:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 293 @ 28229 updates, score 13.393) (writing took 2.2189925890415907 seconds)
2022-03-07 12:05:42 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 12:05:42 | INFO | train | epoch 293 | loss 1.712 | nll_loss 0.674 | ppl 1.6 | wps 22425.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28229 | lr 0.000188214 | gnorm 0.816 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 83653
2022-03-07 12:05:42 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 12:05:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:07:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:09:07 | INFO | train_inner | epoch 294:     72 / 97 loss=1.712, nll_loss=0.674, ppl=1.59, wps=22217.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28300, lr=0.000187978, gnorm=0.825, loss_scale=16, train_wall=265, gb_free=8.1, wall=83859
2022-03-07 12:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:10:23 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.341 | nll_loss 12.883 | ppl 7554.38 | wps 42988.6 | wpb 510.9 | bsz 1 | num_updates 28325 | best_loss 7.981
2022-03-07 12:10:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 28325 updates
2022-03-07 12:10:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:10:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:10:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 294 @ 28325 updates, score 13.341) (writing took 2.2207980039529502 seconds)
2022-03-07 12:10:25 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 12:10:25 | INFO | train | epoch 294 | loss 1.711 | nll_loss 0.673 | ppl 1.59 | wps 22187.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28325 | lr 0.000187895 | gnorm 0.824 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 83937
2022-03-07 12:10:25 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 12:10:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:13:58 | INFO | train_inner | epoch 295:     75 / 97 loss=1.71, nll_loss=0.672, ppl=1.59, wps=22444.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28400, lr=0.000187647, gnorm=0.814, loss_scale=32, train_wall=262, gb_free=8.1, wall=84150
2022-03-07 12:15:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:15:06 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.364 | nll_loss 12.906 | ppl 7676.99 | wps 43142.5 | wpb 510.9 | bsz 1 | num_updates 28422 | best_loss 7.981
2022-03-07 12:15:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 28422 updates
2022-03-07 12:15:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:15:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:15:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 295 @ 28422 updates, score 13.364) (writing took 2.193515947088599 seconds)
2022-03-07 12:15:08 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 12:15:08 | INFO | train | epoch 295 | loss 1.71 | nll_loss 0.672 | ppl 1.59 | wps 22433.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28422 | lr 0.000187574 | gnorm 0.813 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 84220
2022-03-07 12:15:08 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 12:15:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:16:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:18:53 | INFO | train_inner | epoch 296:     79 / 97 loss=1.71, nll_loss=0.671, ppl=1.59, wps=22223.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28500, lr=0.000187317, gnorm=0.812, loss_scale=16, train_wall=265, gb_free=8.1, wall=84445
2022-03-07 12:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:19:49 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 13.327 | nll_loss 12.865 | ppl 7460.92 | wps 42622.4 | wpb 510.9 | bsz 1 | num_updates 28518 | best_loss 7.981
2022-03-07 12:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 28518 updates
2022-03-07 12:19:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:19:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 296 @ 28518 updates, score 13.327) (writing took 2.1798736229538918 seconds)
2022-03-07 12:19:52 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 12:19:52 | INFO | train | epoch 296 | loss 1.707 | nll_loss 0.669 | ppl 1.59 | wps 22184.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28518 | lr 0.000187258 | gnorm 0.811 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 84503
2022-03-07 12:19:52 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 12:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:23:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:23:48 | INFO | train_inner | epoch 297:     83 / 97 loss=1.706, nll_loss=0.668, ppl=1.59, wps=22227.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28600, lr=0.000186989, gnorm=0.803, loss_scale=16, train_wall=264, gb_free=8.1, wall=84740
2022-03-07 12:24:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:24:33 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 13.376 | nll_loss 12.915 | ppl 7720.85 | wps 43178.9 | wpb 510.9 | bsz 1 | num_updates 28614 | best_loss 7.981
2022-03-07 12:24:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 28614 updates
2022-03-07 12:24:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:24:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:24:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 297 @ 28614 updates, score 13.376) (writing took 2.2002268405631185 seconds)
2022-03-07 12:24:35 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 12:24:35 | INFO | train | epoch 297 | loss 1.706 | nll_loss 0.668 | ppl 1.59 | wps 22198.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28614 | lr 0.000186944 | gnorm 0.802 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 84787
2022-03-07 12:24:35 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 12:24:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:28:40 | INFO | train_inner | epoch 298:     86 / 97 loss=1.705, nll_loss=0.667, ppl=1.59, wps=22428.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28700, lr=0.000186663, gnorm=0.803, loss_scale=16, train_wall=262, gb_free=8.1, wall=85032
2022-03-07 12:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:29:16 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.329 | nll_loss 12.867 | ppl 7469.71 | wps 43065.6 | wpb 510.9 | bsz 1 | num_updates 28711 | best_loss 7.981
2022-03-07 12:29:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 28711 updates
2022-03-07 12:29:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:29:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:29:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 298 @ 28711 updates, score 13.329) (writing took 2.2451148610562086 seconds)
2022-03-07 12:29:18 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 12:29:18 | INFO | train | epoch 298 | loss 1.705 | nll_loss 0.666 | ppl 1.59 | wps 22404.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28711 | lr 0.000186628 | gnorm 0.802 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 85070
2022-03-07 12:29:18 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 12:29:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:30:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:33:35 | INFO | train_inner | epoch 299:     90 / 97 loss=1.705, nll_loss=0.667, ppl=1.59, wps=22218.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28800, lr=0.000186339, gnorm=0.807, loss_scale=16, train_wall=265, gb_free=8.1, wall=85327
2022-03-07 12:33:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:33:59 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.329 | nll_loss 12.866 | ppl 7464.28 | wps 42902.4 | wpb 510.9 | bsz 1 | num_updates 28807 | best_loss 7.981
2022-03-07 12:33:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 28807 updates
2022-03-07 12:33:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:34:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 299 @ 28807 updates, score 13.329) (writing took 2.265502456109971 seconds)
2022-03-07 12:34:02 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 12:34:02 | INFO | train | epoch 299 | loss 1.704 | nll_loss 0.666 | ppl 1.59 | wps 22184.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28807 | lr 0.000186316 | gnorm 0.808 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 85354
2022-03-07 12:34:02 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 12:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:36:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:38:29 | INFO | train_inner | epoch 300:     94 / 97 loss=1.703, nll_loss=0.665, ppl=1.59, wps=22218.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28900, lr=0.000186016, gnorm=0.814, loss_scale=16, train_wall=265, gb_free=8.1, wall=85621
2022-03-07 12:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:38:43 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 13.364 | nll_loss 12.905 | ppl 7669.84 | wps 42805.5 | wpb 510.9 | bsz 1 | num_updates 28903 | best_loss 7.981
2022-03-07 12:38:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 28903 updates
2022-03-07 12:38:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:38:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:38:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 300 @ 28903 updates, score 13.364) (writing took 2.2780915671028197 seconds)
2022-03-07 12:38:45 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 12:38:45 | INFO | train | epoch 300 | loss 1.702 | nll_loss 0.664 | ppl 1.58 | wps 22183.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28903 | lr 0.000186007 | gnorm 0.813 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 85637
2022-03-07 12:38:45 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 12:38:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:43:21 | INFO | train_inner | epoch 301:     97 / 97 loss=1.702, nll_loss=0.664, ppl=1.58, wps=22411.5, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=29000, lr=0.000185695, gnorm=0.807, loss_scale=32, train_wall=262, gb_free=8.1, wall=85913
2022-03-07 12:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:43:27 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.383 | nll_loss 12.923 | ppl 7766.74 | wps 43142.5 | wpb 510.9 | bsz 1 | num_updates 29000 | best_loss 7.981
2022-03-07 12:43:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 29000 updates
2022-03-07 12:43:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:43:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:43:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 301 @ 29000 updates, score 13.383) (writing took 2.301830875687301 seconds)
2022-03-07 12:43:29 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 12:43:29 | INFO | train | epoch 301 | loss 1.702 | nll_loss 0.664 | ppl 1.58 | wps 22394.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29000 | lr 0.000185695 | gnorm 0.806 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 85921
2022-03-07 12:43:29 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 12:43:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:43:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:48:10 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.402 | nll_loss 12.941 | ppl 7866.2 | wps 43113.6 | wpb 510.9 | bsz 1 | num_updates 29096 | best_loss 7.981
2022-03-07 12:48:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 29096 updates
2022-03-07 12:48:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 302 @ 29096 updates, score 13.402) (writing took 2.2248325049877167 seconds)
2022-03-07 12:48:12 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 12:48:12 | INFO | train | epoch 302 | loss 1.699 | nll_loss 0.661 | ppl 1.58 | wps 22186.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29096 | lr 0.000185389 | gnorm 0.805 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 86204
2022-03-07 12:48:12 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 12:48:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:48:24 | INFO | train_inner | epoch 303:      4 / 97 loss=1.698, nll_loss=0.66, ppl=1.58, wps=21667.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=29100, lr=0.000185376, gnorm=0.805, loss_scale=16, train_wall=265, gb_free=8.1, wall=86216
2022-03-07 12:49:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:52:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:52:53 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.398 | nll_loss 12.94 | ppl 7855.87 | wps 43016.1 | wpb 510.9 | bsz 1 | num_updates 29192 | best_loss 7.981
2022-03-07 12:52:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 29192 updates
2022-03-07 12:52:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:52:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:52:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 303 @ 29192 updates, score 13.398) (writing took 2.231607120949775 seconds)
2022-03-07 12:52:56 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 12:52:56 | INFO | train | epoch 303 | loss 1.698 | nll_loss 0.66 | ppl 1.58 | wps 22176.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29192 | lr 0.000185084 | gnorm 0.806 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 86488
2022-03-07 12:52:56 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 12:52:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:53:19 | INFO | train_inner | epoch 304:      8 / 97 loss=1.697, nll_loss=0.659, ppl=1.58, wps=22206.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29200, lr=0.000185058, gnorm=0.807, loss_scale=16, train_wall=265, gb_free=8.1, wall=86511
2022-03-07 12:57:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:57:37 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 13.39 | nll_loss 12.935 | ppl 7831.35 | wps 42854.4 | wpb 510.9 | bsz 1 | num_updates 29289 | best_loss 7.981
2022-03-07 12:57:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 29289 updates
2022-03-07 12:57:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:57:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:57:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 304 @ 29289 updates, score 13.39) (writing took 2.2524953819811344 seconds)
2022-03-07 12:57:39 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 12:57:39 | INFO | train | epoch 304 | loss 1.697 | nll_loss 0.659 | ppl 1.58 | wps 22415.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29289 | lr 0.000184777 | gnorm 0.801 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 86771
2022-03-07 12:57:39 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 12:57:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:58:11 | INFO | train_inner | epoch 305:     11 / 97 loss=1.696, nll_loss=0.659, ppl=1.58, wps=22434.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29300, lr=0.000184742, gnorm=0.8, loss_scale=32, train_wall=262, gb_free=8.1, wall=86802
2022-03-07 12:58:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:02:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:02:20 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.377 | nll_loss 12.918 | ppl 7739.81 | wps 43094 | wpb 510.9 | bsz 1 | num_updates 29385 | best_loss 7.981
2022-03-07 13:02:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 29385 updates
2022-03-07 13:02:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:02:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 305 @ 29385 updates, score 13.377) (writing took 2.286507527343929 seconds)
2022-03-07 13:02:22 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 13:02:22 | INFO | train | epoch 305 | loss 1.695 | nll_loss 0.657 | ppl 1.58 | wps 22194.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29385 | lr 0.000184475 | gnorm 0.8 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 87054
2022-03-07 13:02:22 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 13:02:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:03:05 | INFO | train_inner | epoch 306:     15 / 97 loss=1.693, nll_loss=0.655, ppl=1.57, wps=22225.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29400, lr=0.000184428, gnorm=0.796, loss_scale=16, train_wall=264, gb_free=8.1, wall=87097
2022-03-07 13:05:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:06:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:07:03 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 13.347 | nll_loss 12.889 | ppl 7587.32 | wps 43105 | wpb 510.9 | bsz 1 | num_updates 29481 | best_loss 7.981
2022-03-07 13:07:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 29481 updates
2022-03-07 13:07:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:07:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:07:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 306 @ 29481 updates, score 13.347) (writing took 2.252204158809036 seconds)
2022-03-07 13:07:06 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 13:07:06 | INFO | train | epoch 306 | loss 1.694 | nll_loss 0.656 | ppl 1.58 | wps 22190.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29481 | lr 0.000184174 | gnorm 0.811 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 87338
2022-03-07 13:07:06 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 13:07:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:08:00 | INFO | train_inner | epoch 307:     19 / 97 loss=1.694, nll_loss=0.656, ppl=1.58, wps=22221.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29500, lr=0.000184115, gnorm=0.811, loss_scale=16, train_wall=265, gb_free=8.1, wall=87392
2022-03-07 13:11:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:11:47 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 13.339 | nll_loss 12.879 | ppl 7534.16 | wps 42710.1 | wpb 510.9 | bsz 1 | num_updates 29578 | best_loss 7.981
2022-03-07 13:11:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 29578 updates
2022-03-07 13:11:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:11:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:11:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 307 @ 29578 updates, score 13.339) (writing took 2.203033053316176 seconds)
2022-03-07 13:11:49 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 13:11:49 | INFO | train | epoch 307 | loss 1.693 | nll_loss 0.655 | ppl 1.57 | wps 22413.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29578 | lr 0.000183872 | gnorm 0.802 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 87621
2022-03-07 13:11:49 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 13:11:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:12:55 | INFO | train_inner | epoch 308:     23 / 97 loss=1.692, nll_loss=0.654, ppl=1.57, wps=22218.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=29600, lr=0.000183804, gnorm=0.802, loss_scale=16, train_wall=265, gb_free=8.1, wall=87687
2022-03-07 13:16:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:16:30 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 13.388 | nll_loss 12.932 | ppl 7816.51 | wps 43273.9 | wpb 510.9 | bsz 1 | num_updates 29674 | best_loss 7.981
2022-03-07 13:16:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 29674 updates
2022-03-07 13:16:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:16:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:16:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 308 @ 29674 updates, score 13.388) (writing took 2.209833061788231 seconds)
2022-03-07 13:16:33 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 13:16:33 | INFO | train | epoch 308 | loss 1.691 | nll_loss 0.654 | ppl 1.57 | wps 22186.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29674 | lr 0.000183574 | gnorm 0.795 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 87904
2022-03-07 13:16:33 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 13:16:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:17:47 | INFO | train_inner | epoch 309:     26 / 97 loss=1.691, nll_loss=0.653, ppl=1.57, wps=22431.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29700, lr=0.000183494, gnorm=0.796, loss_scale=16, train_wall=262, gb_free=8.1, wall=87979
2022-03-07 13:18:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:21:14 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 13.394 | nll_loss 12.934 | ppl 7827.38 | wps 42987.4 | wpb 510.9 | bsz 1 | num_updates 29770 | best_loss 7.981
2022-03-07 13:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 29770 updates
2022-03-07 13:21:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:21:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:21:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 309 @ 29770 updates, score 13.394) (writing took 2.243430321570486 seconds)
2022-03-07 13:21:16 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 13:21:16 | INFO | train | epoch 309 | loss 1.69 | nll_loss 0.652 | ppl 1.57 | wps 22185.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29770 | lr 0.000183278 | gnorm 0.802 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 88188
2022-03-07 13:21:16 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 13:21:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:22:41 | INFO | train_inner | epoch 310:     30 / 97 loss=1.69, nll_loss=0.652, ppl=1.57, wps=22222.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=29800, lr=0.000183186, gnorm=0.802, loss_scale=16, train_wall=265, gb_free=8.1, wall=88273
2022-03-07 13:25:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:25:57 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.408 | nll_loss 12.952 | ppl 7926.56 | wps 43075.5 | wpb 510.9 | bsz 1 | num_updates 29866 | best_loss 7.981
2022-03-07 13:25:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 29866 updates
2022-03-07 13:25:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:25:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:25:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 310 @ 29866 updates, score 13.408) (writing took 2.2385220769792795 seconds)
2022-03-07 13:25:59 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 13:25:59 | INFO | train | epoch 310 | loss 1.688 | nll_loss 0.65 | ppl 1.57 | wps 22189.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29866 | lr 0.000182983 | gnorm 0.798 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 88471
2022-03-07 13:25:59 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 13:25:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:27:36 | INFO | train_inner | epoch 311:     34 / 97 loss=1.687, nll_loss=0.649, ppl=1.57, wps=22220, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29900, lr=0.000182879, gnorm=0.799, loss_scale=16, train_wall=265, gb_free=8.1, wall=88568
2022-03-07 13:30:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:30:40 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.368 | nll_loss 12.911 | ppl 7701.3 | wps 43051.1 | wpb 510.9 | bsz 1 | num_updates 29963 | best_loss 7.981
2022-03-07 13:30:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 29963 updates
2022-03-07 13:30:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:30:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:30:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 311 @ 29963 updates, score 13.368) (writing took 2.2109220940619707 seconds)
2022-03-07 13:30:43 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 13:30:43 | INFO | train | epoch 311 | loss 1.688 | nll_loss 0.651 | ppl 1.57 | wps 22422 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29963 | lr 0.000182687 | gnorm 0.802 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 88754
2022-03-07 13:30:43 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 13:30:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:32:28 | INFO | train_inner | epoch 312:     37 / 97 loss=1.687, nll_loss=0.65, ppl=1.57, wps=22434.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30000, lr=0.000182574, gnorm=0.801, loss_scale=32, train_wall=262, gb_free=8.1, wall=88860
2022-03-07 13:33:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:35:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:35:24 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 13.454 | nll_loss 13.001 | ppl 8194.93 | wps 43142.4 | wpb 510.9 | bsz 1 | num_updates 30059 | best_loss 7.981
2022-03-07 13:35:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 30059 updates
2022-03-07 13:35:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:35:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:35:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 312 @ 30059 updates, score 13.454) (writing took 2.2019604318775237 seconds)
2022-03-07 13:35:26 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 13:35:26 | INFO | train | epoch 312 | loss 1.686 | nll_loss 0.648 | ppl 1.57 | wps 22189.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30059 | lr 0.000182395 | gnorm 0.804 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 89038
2022-03-07 13:35:26 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 13:35:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:37:23 | INFO | train_inner | epoch 313:     41 / 97 loss=1.685, nll_loss=0.647, ppl=1.57, wps=22221.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30100, lr=0.000182271, gnorm=0.8, loss_scale=16, train_wall=265, gb_free=8.1, wall=89155
2022-03-07 13:40:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:40:07 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 13.393 | nll_loss 12.939 | ppl 7854.31 | wps 43211.1 | wpb 510.9 | bsz 1 | num_updates 30156 | best_loss 7.981
2022-03-07 13:40:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 30156 updates
2022-03-07 13:40:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:40:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:40:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 313 @ 30156 updates, score 13.393) (writing took 2.2272124611772597 seconds)
2022-03-07 13:40:09 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 13:40:09 | INFO | train | epoch 313 | loss 1.685 | nll_loss 0.647 | ppl 1.57 | wps 22421.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30156 | lr 0.000182101 | gnorm 0.789 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 89321
2022-03-07 13:40:09 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 13:40:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:42:15 | INFO | train_inner | epoch 314:     44 / 97 loss=1.684, nll_loss=0.646, ppl=1.57, wps=22442.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=30200, lr=0.000181969, gnorm=0.791, loss_scale=32, train_wall=262, gb_free=8.1, wall=89447
2022-03-07 13:42:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:44:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:44:50 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.438 | nll_loss 12.979 | ppl 8076.21 | wps 42996 | wpb 510.9 | bsz 1 | num_updates 30252 | best_loss 7.981
2022-03-07 13:44:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 30252 updates
2022-03-07 13:44:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:44:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:44:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 314 @ 30252 updates, score 13.438) (writing took 2.2816230137832463 seconds)
2022-03-07 13:44:53 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 13:44:53 | INFO | train | epoch 314 | loss 1.684 | nll_loss 0.647 | ppl 1.57 | wps 22183.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30252 | lr 0.000181812 | gnorm 0.798 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 89605
2022-03-07 13:44:53 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 13:44:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:47:09 | INFO | train_inner | epoch 315:     48 / 97 loss=1.684, nll_loss=0.647, ppl=1.57, wps=22216.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30300, lr=0.000181668, gnorm=0.8, loss_scale=16, train_wall=265, gb_free=8.1, wall=89741
2022-03-07 13:49:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:49:34 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 13.397 | nll_loss 12.944 | ppl 7880.87 | wps 43457.3 | wpb 510.9 | bsz 1 | num_updates 30348 | best_loss 7.981
2022-03-07 13:49:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 30348 updates
2022-03-07 13:49:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:49:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:49:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 315 @ 30348 updates, score 13.397) (writing took 2.2067941171117127 seconds)
2022-03-07 13:49:36 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 13:49:36 | INFO | train | epoch 315 | loss 1.683 | nll_loss 0.645 | ppl 1.56 | wps 22199.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30348 | lr 0.000181524 | gnorm 0.802 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 89888
2022-03-07 13:49:36 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 13:49:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:52:04 | INFO | train_inner | epoch 316:     52 / 97 loss=1.682, nll_loss=0.645, ppl=1.56, wps=22232.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30400, lr=0.000181369, gnorm=0.806, loss_scale=16, train_wall=265, gb_free=8.1, wall=90036
2022-03-07 13:54:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:54:17 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 13.36 | nll_loss 12.905 | ppl 7670.63 | wps 42919.2 | wpb 510.9 | bsz 1 | num_updates 30445 | best_loss 7.981
2022-03-07 13:54:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 30445 updates
2022-03-07 13:54:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:54:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:54:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 316 @ 30445 updates, score 13.36) (writing took 2.214642016682774 seconds)
2022-03-07 13:54:19 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 13:54:19 | INFO | train | epoch 316 | loss 1.682 | nll_loss 0.645 | ppl 1.56 | wps 22423 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30445 | lr 0.000181235 | gnorm 0.804 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 90171
2022-03-07 13:54:19 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 13:54:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:55:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:56:59 | INFO | train_inner | epoch 317:     56 / 97 loss=1.681, nll_loss=0.644, ppl=1.56, wps=22223.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=30500, lr=0.000181071, gnorm=0.799, loss_scale=16, train_wall=265, gb_free=8.1, wall=90331
2022-03-07 13:58:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:59:00 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 13.421 | nll_loss 12.966 | ppl 8003.36 | wps 42765.1 | wpb 510.9 | bsz 1 | num_updates 30541 | best_loss 7.981
2022-03-07 13:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 30541 updates
2022-03-07 13:59:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:59:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:59:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 317 @ 30541 updates, score 13.421) (writing took 2.2420275253243744 seconds)
2022-03-07 13:59:03 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 13:59:03 | INFO | train | epoch 317 | loss 1.68 | nll_loss 0.643 | ppl 1.56 | wps 22189.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30541 | lr 0.00018095 | gnorm 0.802 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 90454
2022-03-07 13:59:03 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 13:59:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:01:51 | INFO | train_inner | epoch 318:     59 / 97 loss=1.679, nll_loss=0.642, ppl=1.56, wps=22435.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30600, lr=0.000180775, gnorm=0.802, loss_scale=16, train_wall=262, gb_free=8.1, wall=90623
2022-03-07 14:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:03:44 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 13.378 | nll_loss 12.922 | ppl 7761.26 | wps 42958 | wpb 510.9 | bsz 1 | num_updates 30638 | best_loss 7.981
2022-03-07 14:03:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 30638 updates
2022-03-07 14:03:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:03:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:03:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 318 @ 30638 updates, score 13.378) (writing took 2.2410946302115917 seconds)
2022-03-07 14:03:46 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 14:03:46 | INFO | train | epoch 318 | loss 1.679 | nll_loss 0.642 | ppl 1.56 | wps 22417.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30638 | lr 0.000180663 | gnorm 0.794 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 90738
2022-03-07 14:03:46 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 14:03:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:06:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:06:45 | INFO | train_inner | epoch 319:     63 / 97 loss=1.678, nll_loss=0.641, ppl=1.56, wps=22219.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30700, lr=0.000180481, gnorm=0.785, loss_scale=16, train_wall=265, gb_free=8.1, wall=90917
2022-03-07 14:08:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:08:27 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 13.416 | nll_loss 12.963 | ppl 7984.4 | wps 42964 | wpb 510.9 | bsz 1 | num_updates 30734 | best_loss 7.981
2022-03-07 14:08:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 30734 updates
2022-03-07 14:08:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:08:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:08:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 319 @ 30734 updates, score 13.416) (writing took 2.2511850870214403 seconds)
2022-03-07 14:08:29 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 14:08:29 | INFO | train | epoch 319 | loss 1.677 | nll_loss 0.64 | ppl 1.56 | wps 22181.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30734 | lr 0.000180381 | gnorm 0.789 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 91021
2022-03-07 14:08:29 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 14:08:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:11:37 | INFO | train_inner | epoch 320:     66 / 97 loss=1.677, nll_loss=0.64, ppl=1.56, wps=22430.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30800, lr=0.000180187, gnorm=0.797, loss_scale=16, train_wall=262, gb_free=8.1, wall=91209
2022-03-07 14:12:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:13:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:13:11 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 13.417 | nll_loss 12.964 | ppl 7989.61 | wps 43067.7 | wpb 510.9 | bsz 1 | num_updates 30830 | best_loss 7.981
2022-03-07 14:13:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 30830 updates
2022-03-07 14:13:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:13:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:13:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 320 @ 30830 updates, score 13.417) (writing took 2.251594648230821 seconds)
2022-03-07 14:13:13 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 14:13:13 | INFO | train | epoch 320 | loss 1.677 | nll_loss 0.64 | ppl 1.56 | wps 22183.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30830 | lr 0.0001801 | gnorm 0.803 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 91305
2022-03-07 14:13:13 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 14:13:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:16:32 | INFO | train_inner | epoch 321:     70 / 97 loss=1.676, nll_loss=0.639, ppl=1.56, wps=22219.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30900, lr=0.000179896, gnorm=0.792, loss_scale=16, train_wall=265, gb_free=8.1, wall=91504
2022-03-07 14:17:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:17:54 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 13.42 | nll_loss 12.971 | ppl 8026.55 | wps 43020.1 | wpb 510.9 | bsz 1 | num_updates 30927 | best_loss 7.981
2022-03-07 14:17:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 30927 updates
2022-03-07 14:17:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:17:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:17:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 321 @ 30927 updates, score 13.42) (writing took 2.2149442941881716 seconds)
2022-03-07 14:17:56 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 14:17:56 | INFO | train | epoch 321 | loss 1.674 | nll_loss 0.637 | ppl 1.55 | wps 22426.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30927 | lr 0.000179817 | gnorm 0.782 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 91588
2022-03-07 14:17:56 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 14:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:20:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:21:27 | INFO | train_inner | epoch 322:     74 / 97 loss=1.674, nll_loss=0.637, ppl=1.56, wps=22227.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31000, lr=0.000179605, gnorm=0.796, loss_scale=16, train_wall=265, gb_free=8.1, wall=91799
2022-03-07 14:22:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:22:37 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 13.411 | nll_loss 12.955 | ppl 7940.94 | wps 42938.4 | wpb 510.9 | bsz 1 | num_updates 31023 | best_loss 7.981
2022-03-07 14:22:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 31023 updates
2022-03-07 14:22:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:22:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:22:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 322 @ 31023 updates, score 13.411) (writing took 2.2194509422406554 seconds)
2022-03-07 14:22:39 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 14:22:39 | INFO | train | epoch 322 | loss 1.674 | nll_loss 0.637 | ppl 1.55 | wps 22188.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31023 | lr 0.000179539 | gnorm 0.795 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 91871
2022-03-07 14:22:39 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 14:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:26:19 | INFO | train_inner | epoch 323:     77 / 97 loss=1.673, nll_loss=0.636, ppl=1.55, wps=22423.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31100, lr=0.000179316, gnorm=0.781, loss_scale=16, train_wall=262, gb_free=8.1, wall=92091
2022-03-07 14:27:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:27:21 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 13.405 | nll_loss 12.95 | ppl 7914.88 | wps 43010.5 | wpb 510.9 | bsz 1 | num_updates 31119 | best_loss 7.981
2022-03-07 14:27:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 31119 updates
2022-03-07 14:27:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:27:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:27:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 323 @ 31119 updates, score 13.405) (writing took 2.270900816190988 seconds)
2022-03-07 14:27:23 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 14:27:23 | INFO | train | epoch 323 | loss 1.672 | nll_loss 0.635 | ppl 1.55 | wps 22176.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31119 | lr 0.000179262 | gnorm 0.783 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 92155
2022-03-07 14:27:23 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 14:27:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:31:14 | INFO | train_inner | epoch 324:     81 / 97 loss=1.672, nll_loss=0.635, ppl=1.55, wps=22210.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31200, lr=0.000179029, gnorm=0.793, loss_scale=16, train_wall=265, gb_free=8.1, wall=92386
2022-03-07 14:31:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:32:04 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.43 | nll_loss 12.979 | ppl 8073.5 | wps 42913 | wpb 510.9 | bsz 1 | num_updates 31216 | best_loss 7.981
2022-03-07 14:32:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 31216 updates
2022-03-07 14:32:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:32:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:32:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 324 @ 31216 updates, score 13.43) (writing took 2.236967397853732 seconds)
2022-03-07 14:32:06 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 14:32:06 | INFO | train | epoch 324 | loss 1.672 | nll_loss 0.635 | ppl 1.55 | wps 22407.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31216 | lr 0.000178983 | gnorm 0.794 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 92438
2022-03-07 14:32:06 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 14:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:34:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:36:08 | INFO | train_inner | epoch 325:     85 / 97 loss=1.671, nll_loss=0.634, ppl=1.55, wps=22220.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31300, lr=0.000178743, gnorm=0.788, loss_scale=16, train_wall=265, gb_free=8.1, wall=92680
2022-03-07 14:36:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:36:48 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.416 | nll_loss 12.963 | ppl 7982.19 | wps 42548.9 | wpb 510.9 | bsz 1 | num_updates 31312 | best_loss 7.981
2022-03-07 14:36:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 31312 updates
2022-03-07 14:36:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:36:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:36:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 325 @ 31312 updates, score 13.416) (writing took 2.3298385217785835 seconds)
2022-03-07 14:36:50 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 14:36:50 | INFO | train | epoch 325 | loss 1.669 | nll_loss 0.632 | ppl 1.55 | wps 22176.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31312 | lr 0.000178708 | gnorm 0.785 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 92722
2022-03-07 14:36:50 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 14:36:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:41:01 | INFO | train_inner | epoch 326:     88 / 97 loss=1.669, nll_loss=0.632, ppl=1.55, wps=22420.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31400, lr=0.000178458, gnorm=0.786, loss_scale=16, train_wall=262, gb_free=8.1, wall=92972
2022-03-07 14:41:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:41:31 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.4 | nll_loss 12.944 | ppl 7882.42 | wps 42387.4 | wpb 510.9 | bsz 1 | num_updates 31409 | best_loss 7.981
2022-03-07 14:41:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 31409 updates
2022-03-07 14:41:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:41:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:41:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 326 @ 31409 updates, score 13.4) (writing took 2.2671034149825573 seconds)
2022-03-07 14:41:33 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 14:41:33 | INFO | train | epoch 326 | loss 1.67 | nll_loss 0.633 | ppl 1.55 | wps 22404.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31409 | lr 0.000178432 | gnorm 0.787 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 93005
2022-03-07 14:41:33 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 14:41:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:41:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:45:55 | INFO | train_inner | epoch 327:     92 / 97 loss=1.669, nll_loss=0.632, ppl=1.55, wps=22211.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31500, lr=0.000178174, gnorm=0.788, loss_scale=16, train_wall=265, gb_free=8.1, wall=93267
2022-03-07 14:46:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:46:15 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 13.399 | nll_loss 12.943 | ppl 7876 | wps 42952.4 | wpb 510.9 | bsz 1 | num_updates 31505 | best_loss 7.981
2022-03-07 14:46:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 31505 updates
2022-03-07 14:46:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:46:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:46:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 327 @ 31505 updates, score 13.399) (writing took 2.3092723372392356 seconds)
2022-03-07 14:46:17 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 14:46:17 | INFO | train | epoch 327 | loss 1.667 | nll_loss 0.63 | ppl 1.55 | wps 22181.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31505 | lr 0.00017816 | gnorm 0.789 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 93289
2022-03-07 14:46:17 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 14:46:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:48:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:50:50 | INFO | train_inner | epoch 328:     96 / 97 loss=1.668, nll_loss=0.631, ppl=1.55, wps=22210.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31600, lr=0.000177892, gnorm=0.799, loss_scale=16, train_wall=265, gb_free=8.1, wall=93562
2022-03-07 14:50:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:50:58 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 13.403 | nll_loss 12.954 | ppl 7935.08 | wps 42468.1 | wpb 510.9 | bsz 1 | num_updates 31601 | best_loss 7.981
2022-03-07 14:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 31601 updates
2022-03-07 14:50:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:51:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:51:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 328 @ 31601 updates, score 13.403) (writing took 2.2591338423080742 seconds)
2022-03-07 14:51:00 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 14:51:00 | INFO | train | epoch 328 | loss 1.667 | nll_loss 0.63 | ppl 1.55 | wps 22176.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31601 | lr 0.000177889 | gnorm 0.797 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 93572
2022-03-07 14:51:00 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 14:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:55:42 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 13.45 | nll_loss 13 | ppl 8193.35 | wps 42436.4 | wpb 510.9 | bsz 1 | num_updates 31698 | best_loss 7.981
2022-03-07 14:55:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 31698 updates
2022-03-07 14:55:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:55:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:55:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 329 @ 31698 updates, score 13.45) (writing took 2.3980497480370104 seconds)
2022-03-07 14:55:44 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 14:55:44 | INFO | train | epoch 329 | loss 1.666 | nll_loss 0.629 | ppl 1.55 | wps 22400.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31698 | lr 0.000177617 | gnorm 0.791 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 93856
2022-03-07 14:55:44 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 14:55:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:55:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:55:53 | INFO | train_inner | epoch 330:      3 / 97 loss=1.666, nll_loss=0.629, ppl=1.55, wps=21649.1, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=31700, lr=0.000177611, gnorm=0.792, loss_scale=16, train_wall=264, gb_free=8.1, wall=93865
2022-03-07 15:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:00:25 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.451 | nll_loss 13.001 | ppl 8197.78 | wps 41916.5 | wpb 510.9 | bsz 1 | num_updates 31794 | best_loss 7.981
2022-03-07 15:00:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 31794 updates
2022-03-07 15:00:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:00:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:00:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 330 @ 31794 updates, score 13.451) (writing took 2.50479394197464 seconds)
2022-03-07 15:00:28 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 15:00:28 | INFO | train | epoch 330 | loss 1.664 | nll_loss 0.627 | ppl 1.54 | wps 22149.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31794 | lr 0.000177348 | gnorm 0.787 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 94140
2022-03-07 15:00:28 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 15:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:00:45 | INFO | train_inner | epoch 331:      6 / 97 loss=1.663, nll_loss=0.627, ppl=1.54, wps=22398.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31800, lr=0.000177332, gnorm=0.786, loss_scale=16, train_wall=262, gb_free=8.1, wall=94157
2022-03-07 15:03:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:05:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:05:09 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 13.447 | nll_loss 13 | ppl 8192.84 | wps 42098.4 | wpb 510.9 | bsz 1 | num_updates 31890 | best_loss 7.981
2022-03-07 15:05:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 31890 updates
2022-03-07 15:05:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:05:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:05:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 331 @ 31890 updates, score 13.447) (writing took 2.418130261823535 seconds)
2022-03-07 15:05:11 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 15:05:11 | INFO | train | epoch 331 | loss 1.663 | nll_loss 0.626 | ppl 1.54 | wps 22173.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31890 | lr 0.000177081 | gnorm 0.788 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 94423
2022-03-07 15:05:11 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 15:05:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:05:40 | INFO | train_inner | epoch 332:     10 / 97 loss=1.662, nll_loss=0.625, ppl=1.54, wps=22208.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31900, lr=0.000177054, gnorm=0.784, loss_scale=16, train_wall=265, gb_free=8.1, wall=94452
2022-03-07 15:09:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:09:53 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 13.416 | nll_loss 12.964 | ppl 7992.43 | wps 42044.8 | wpb 510.9 | bsz 1 | num_updates 31987 | best_loss 7.981
2022-03-07 15:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 31987 updates
2022-03-07 15:09:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 332 @ 31987 updates, score 13.416) (writing took 2.2849945230409503 seconds)
2022-03-07 15:09:55 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 15:09:55 | INFO | train | epoch 332 | loss 1.662 | nll_loss 0.626 | ppl 1.54 | wps 22411.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31987 | lr 0.000176813 | gnorm 0.787 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 94707
2022-03-07 15:09:55 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 15:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:10:32 | INFO | train_inner | epoch 333:     13 / 97 loss=1.661, nll_loss=0.625, ppl=1.54, wps=22428.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32000, lr=0.000176777, gnorm=0.79, loss_scale=32, train_wall=262, gb_free=8.1, wall=94744
2022-03-07 15:10:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:14:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:14:36 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 13.427 | nll_loss 12.977 | ppl 8063.33 | wps 42025 | wpb 510.9 | bsz 1 | num_updates 32083 | best_loss 7.981
2022-03-07 15:14:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 32083 updates
2022-03-07 15:14:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:14:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:14:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 333 @ 32083 updates, score 13.427) (writing took 2.2860568212345243 seconds)
2022-03-07 15:14:38 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 15:14:38 | INFO | train | epoch 333 | loss 1.661 | nll_loss 0.624 | ppl 1.54 | wps 22187.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32083 | lr 0.000176548 | gnorm 0.785 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 94990
2022-03-07 15:14:38 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 15:14:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:15:27 | INFO | train_inner | epoch 334:     17 / 97 loss=1.66, nll_loss=0.623, ppl=1.54, wps=22214.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32100, lr=0.000176501, gnorm=0.78, loss_scale=16, train_wall=265, gb_free=8.1, wall=95039
2022-03-07 15:17:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:19:20 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 13.463 | nll_loss 13.014 | ppl 8271.07 | wps 42555.9 | wpb 510.9 | bsz 1 | num_updates 32179 | best_loss 7.981
2022-03-07 15:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 32179 updates
2022-03-07 15:19:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:19:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:19:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 334 @ 32179 updates, score 13.463) (writing took 2.2780211898498237 seconds)
2022-03-07 15:19:22 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 15:19:22 | INFO | train | epoch 334 | loss 1.66 | nll_loss 0.623 | ppl 1.54 | wps 22162.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32179 | lr 0.000176284 | gnorm 0.788 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 95274
2022-03-07 15:19:22 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 15:19:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:20:22 | INFO | train_inner | epoch 335:     21 / 97 loss=1.659, nll_loss=0.622, ppl=1.54, wps=22199.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32200, lr=0.000176227, gnorm=0.789, loss_scale=16, train_wall=265, gb_free=8.1, wall=95334
2022-03-07 15:23:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:24:03 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 13.44 | nll_loss 12.989 | ppl 8130.52 | wps 42890.4 | wpb 510.9 | bsz 1 | num_updates 32276 | best_loss 7.981
2022-03-07 15:24:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 32276 updates
2022-03-07 15:24:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:24:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:24:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 335 @ 32276 updates, score 13.44) (writing took 2.251225857064128 seconds)
2022-03-07 15:24:05 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 15:24:05 | INFO | train | epoch 335 | loss 1.659 | nll_loss 0.622 | ppl 1.54 | wps 22407.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32276 | lr 0.000176019 | gnorm 0.782 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 95557
2022-03-07 15:24:05 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 15:24:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:24:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:25:17 | INFO | train_inner | epoch 336:     25 / 97 loss=1.658, nll_loss=0.622, ppl=1.54, wps=22213.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32300, lr=0.000175954, gnorm=0.785, loss_scale=16, train_wall=265, gb_free=8.1, wall=95629
2022-03-07 15:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:28:47 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 13.43 | nll_loss 12.979 | ppl 8074.61 | wps 42939.3 | wpb 510.9 | bsz 1 | num_updates 32372 | best_loss 7.981
2022-03-07 15:28:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 32372 updates
2022-03-07 15:28:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:28:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:28:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 336 @ 32372 updates, score 13.43) (writing took 2.2831075680442154 seconds)
2022-03-07 15:28:49 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 15:28:49 | INFO | train | epoch 336 | loss 1.658 | nll_loss 0.621 | ppl 1.54 | wps 22184.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32372 | lr 0.000175758 | gnorm 0.794 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 95841
2022-03-07 15:28:49 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 15:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:30:09 | INFO | train_inner | epoch 337:     28 / 97 loss=1.657, nll_loss=0.62, ppl=1.54, wps=22427.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32400, lr=0.000175682, gnorm=0.795, loss_scale=16, train_wall=262, gb_free=8.1, wall=95921
2022-03-07 15:30:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:33:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:33:30 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 13.39 | nll_loss 12.936 | ppl 7835.65 | wps 43047.7 | wpb 510.9 | bsz 1 | num_updates 32468 | best_loss 7.981
2022-03-07 15:33:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 32468 updates
2022-03-07 15:33:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:33:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:33:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 337 @ 32468 updates, score 13.39) (writing took 2.2545813797041774 seconds)
2022-03-07 15:33:32 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 15:33:32 | INFO | train | epoch 337 | loss 1.656 | nll_loss 0.62 | ppl 1.54 | wps 22195.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32468 | lr 0.000175498 | gnorm 0.79 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 96124
2022-03-07 15:33:32 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 15:33:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:35:03 | INFO | train_inner | epoch 338:     32 / 97 loss=1.656, nll_loss=0.62, ppl=1.54, wps=22229.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32500, lr=0.000175412, gnorm=0.788, loss_scale=16, train_wall=264, gb_free=8.1, wall=96215
2022-03-07 15:38:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:38:13 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 13.441 | nll_loss 12.994 | ppl 8159.44 | wps 43058.3 | wpb 510.9 | bsz 1 | num_updates 32565 | best_loss 7.981
2022-03-07 15:38:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 32565 updates
2022-03-07 15:38:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:38:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:38:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 338 @ 32565 updates, score 13.441) (writing took 2.264423245098442 seconds)
2022-03-07 15:38:15 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 15:38:15 | INFO | train | epoch 338 | loss 1.655 | nll_loss 0.619 | ppl 1.54 | wps 22414.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32565 | lr 0.000175236 | gnorm 0.782 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 96407
2022-03-07 15:38:16 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 15:38:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:38:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:39:58 | INFO | train_inner | epoch 339:     36 / 97 loss=1.655, nll_loss=0.618, ppl=1.54, wps=22224.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=32600, lr=0.000175142, gnorm=0.779, loss_scale=16, train_wall=265, gb_free=8.1, wall=96510
2022-03-07 15:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:42:57 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 13.426 | nll_loss 12.974 | ppl 8046.52 | wps 42962.1 | wpb 510.9 | bsz 1 | num_updates 32661 | best_loss 7.981
2022-03-07 15:42:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 32661 updates
2022-03-07 15:42:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:42:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:42:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 339 @ 32661 updates, score 13.426) (writing took 2.256839593872428 seconds)
2022-03-07 15:42:59 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 15:42:59 | INFO | train | epoch 339 | loss 1.655 | nll_loss 0.618 | ppl 1.54 | wps 22189.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32661 | lr 0.000174979 | gnorm 0.787 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 96691
2022-03-07 15:42:59 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 15:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:44:50 | INFO | train_inner | epoch 340:     39 / 97 loss=1.653, nll_loss=0.617, ppl=1.53, wps=22431.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=32700, lr=0.000174874, gnorm=0.786, loss_scale=32, train_wall=262, gb_free=8.1, wall=96802
2022-03-07 15:47:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:47:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:47:40 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 13.411 | nll_loss 12.961 | ppl 7971.2 | wps 43130.7 | wpb 510.9 | bsz 1 | num_updates 32757 | best_loss 7.981
2022-03-07 15:47:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 32757 updates
2022-03-07 15:47:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:47:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:47:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 340 @ 32757 updates, score 13.411) (writing took 2.2513363077305257 seconds)
2022-03-07 15:47:42 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 15:47:42 | INFO | train | epoch 340 | loss 1.654 | nll_loss 0.617 | ppl 1.53 | wps 22187 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32757 | lr 0.000174722 | gnorm 0.786 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 96974
2022-03-07 15:47:42 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 15:47:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:49:45 | INFO | train_inner | epoch 341:     43 / 97 loss=1.654, nll_loss=0.618, ppl=1.53, wps=22212.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=32800, lr=0.000174608, gnorm=0.79, loss_scale=16, train_wall=265, gb_free=8.1, wall=97097
2022-03-07 15:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:52:23 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 13.459 | nll_loss 13.011 | ppl 8254.71 | wps 43059.9 | wpb 510.9 | bsz 1 | num_updates 32854 | best_loss 7.981
2022-03-07 15:52:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 32854 updates
2022-03-07 15:52:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:52:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:52:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 341 @ 32854 updates, score 13.459) (writing took 2.2845103568397462 seconds)
2022-03-07 15:52:26 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 15:52:26 | INFO | train | epoch 341 | loss 1.652 | nll_loss 0.615 | ppl 1.53 | wps 22403.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32854 | lr 0.000174464 | gnorm 0.784 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 97258
2022-03-07 15:52:26 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 15:52:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:54:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:54:40 | INFO | train_inner | epoch 342:     47 / 97 loss=1.65, nll_loss=0.614, ppl=1.53, wps=22203.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32900, lr=0.000174342, gnorm=0.782, loss_scale=16, train_wall=265, gb_free=8.1, wall=97392
2022-03-07 15:57:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:57:07 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 13.439 | nll_loss 12.986 | ppl 8111.84 | wps 43061.4 | wpb 510.9 | bsz 1 | num_updates 32950 | best_loss 7.981
2022-03-07 15:57:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 32950 updates
2022-03-07 15:57:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:57:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:57:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 342 @ 32950 updates, score 13.439) (writing took 2.2365424153394997 seconds)
2022-03-07 15:57:09 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 15:57:09 | INFO | train | epoch 342 | loss 1.651 | nll_loss 0.614 | ppl 1.53 | wps 22181.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32950 | lr 0.00017421 | gnorm 0.786 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 97541
2022-03-07 15:57:09 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 15:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:59:32 | INFO | train_inner | epoch 343:     50 / 97 loss=1.651, nll_loss=0.615, ppl=1.53, wps=22431.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33000, lr=0.000174078, gnorm=0.784, loss_scale=16, train_wall=262, gb_free=8.1, wall=97684
2022-03-07 16:01:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:01:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:01:50 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 13.493 | nll_loss 13.044 | ppl 8445.09 | wps 42685.8 | wpb 510.9 | bsz 1 | num_updates 33046 | best_loss 7.981
2022-03-07 16:01:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 33046 updates
2022-03-07 16:01:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:01:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 343 @ 33046 updates, score 13.493) (writing took 2.3196015269495547 seconds)
2022-03-07 16:01:53 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 16:01:53 | INFO | train | epoch 343 | loss 1.65 | nll_loss 0.614 | ppl 1.53 | wps 22170.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33046 | lr 0.000173956 | gnorm 0.782 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 97825
2022-03-07 16:01:53 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 16:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:04:27 | INFO | train_inner | epoch 344:     54 / 97 loss=1.65, nll_loss=0.614, ppl=1.53, wps=22206.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33100, lr=0.000173814, gnorm=0.78, loss_scale=16, train_wall=265, gb_free=8.1, wall=97979
2022-03-07 16:06:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:06:34 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.475 | nll_loss 13.03 | ppl 8365.43 | wps 43030.4 | wpb 510.9 | bsz 1 | num_updates 33143 | best_loss 7.981
2022-03-07 16:06:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 33143 updates
2022-03-07 16:06:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:06:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:06:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 344 @ 33143 updates, score 13.475) (writing took 2.2153480648994446 seconds)
2022-03-07 16:06:36 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 16:06:36 | INFO | train | epoch 344 | loss 1.65 | nll_loss 0.614 | ppl 1.53 | wps 22417.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33143 | lr 0.000173702 | gnorm 0.778 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 98108
2022-03-07 16:06:36 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 16:06:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:07:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:09:21 | INFO | train_inner | epoch 345:     58 / 97 loss=1.649, nll_loss=0.613, ppl=1.53, wps=22220, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33200, lr=0.000173553, gnorm=0.775, loss_scale=16, train_wall=265, gb_free=8.1, wall=98273
2022-03-07 16:11:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:11:17 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 13.382 | nll_loss 12.932 | ppl 7816.77 | wps 43102.3 | wpb 510.9 | bsz 1 | num_updates 33239 | best_loss 7.981
2022-03-07 16:11:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 33239 updates
2022-03-07 16:11:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:11:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:11:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 345 @ 33239 updates, score 13.382) (writing took 2.242502241861075 seconds)
2022-03-07 16:11:19 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 16:11:19 | INFO | train | epoch 345 | loss 1.647 | nll_loss 0.611 | ppl 1.53 | wps 22190.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33239 | lr 0.000173451 | gnorm 0.776 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 98391
2022-03-07 16:11:20 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 16:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:14:13 | INFO | train_inner | epoch 346:     61 / 97 loss=1.646, nll_loss=0.61, ppl=1.53, wps=22434.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=33300, lr=0.000173292, gnorm=0.779, loss_scale=32, train_wall=262, gb_free=8.1, wall=98565
2022-03-07 16:15:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:15:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:16:01 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 13.405 | nll_loss 12.955 | ppl 7942.58 | wps 43128.7 | wpb 510.9 | bsz 1 | num_updates 33335 | best_loss 7.981
2022-03-07 16:16:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 33335 updates
2022-03-07 16:16:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:16:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:16:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 346 @ 33335 updates, score 13.405) (writing took 2.236611353699118 seconds)
2022-03-07 16:16:03 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 16:16:03 | INFO | train | epoch 346 | loss 1.646 | nll_loss 0.61 | ppl 1.53 | wps 22179.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33335 | lr 0.000173201 | gnorm 0.777 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 98675
2022-03-07 16:16:03 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 16:16:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:19:08 | INFO | train_inner | epoch 347:     65 / 97 loss=1.645, nll_loss=0.609, ppl=1.53, wps=22213.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33400, lr=0.000173032, gnorm=0.774, loss_scale=16, train_wall=265, gb_free=8.1, wall=98860
2022-03-07 16:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:20:44 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 13.399 | nll_loss 12.949 | ppl 7907.67 | wps 43233.2 | wpb 510.9 | bsz 1 | num_updates 33432 | best_loss 7.981
2022-03-07 16:20:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 33432 updates
2022-03-07 16:20:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:20:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:20:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 347 @ 33432 updates, score 13.399) (writing took 2.2481702170334756 seconds)
2022-03-07 16:20:46 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 16:20:46 | INFO | train | epoch 347 | loss 1.646 | nll_loss 0.61 | ppl 1.53 | wps 22412.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33432 | lr 0.000172949 | gnorm 0.776 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 98958
2022-03-07 16:20:46 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 16:20:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:24:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:24:03 | INFO | train_inner | epoch 348:     69 / 97 loss=1.646, nll_loss=0.61, ppl=1.53, wps=22218.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=33500, lr=0.000172774, gnorm=0.782, loss_scale=16, train_wall=265, gb_free=8.1, wall=99155
2022-03-07 16:25:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:25:28 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 13.428 | nll_loss 12.979 | ppl 8074.3 | wps 43037 | wpb 510.9 | bsz 1 | num_updates 33528 | best_loss 7.981
2022-03-07 16:25:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 33528 updates
2022-03-07 16:25:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:25:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:25:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 348 @ 33528 updates, score 13.428) (writing took 2.331906766165048 seconds)
2022-03-07 16:25:30 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 16:25:30 | INFO | train | epoch 348 | loss 1.644 | nll_loss 0.608 | ppl 1.52 | wps 22176.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33528 | lr 0.000172702 | gnorm 0.784 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 99242
2022-03-07 16:25:30 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 16:25:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:28:55 | INFO | train_inner | epoch 349:     72 / 97 loss=1.643, nll_loss=0.607, ppl=1.52, wps=22423.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33600, lr=0.000172516, gnorm=0.771, loss_scale=16, train_wall=262, gb_free=8.1, wall=99447
2022-03-07 16:30:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:30:11 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 13.412 | nll_loss 12.961 | ppl 7973.47 | wps 43040.6 | wpb 510.9 | bsz 1 | num_updates 33625 | best_loss 7.981
2022-03-07 16:30:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 33625 updates
2022-03-07 16:30:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:30:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:30:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 349 @ 33625 updates, score 13.412) (writing took 2.2579410769976676 seconds)
2022-03-07 16:30:13 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 16:30:13 | INFO | train | epoch 349 | loss 1.643 | nll_loss 0.607 | ppl 1.52 | wps 22412.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33625 | lr 0.000172452 | gnorm 0.768 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 99525
2022-03-07 16:30:13 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 16:30:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:31:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:33:50 | INFO | train_inner | epoch 350:     76 / 97 loss=1.645, nll_loss=0.609, ppl=1.53, wps=22216.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33700, lr=0.00017226, gnorm=0.783, loss_scale=16, train_wall=265, gb_free=8.1, wall=99742
2022-03-07 16:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:34:55 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.424 | nll_loss 12.974 | ppl 8045.11 | wps 42959.7 | wpb 510.9 | bsz 1 | num_updates 33721 | best_loss 7.981
2022-03-07 16:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 33721 updates
2022-03-07 16:34:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:34:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:34:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 350 @ 33721 updates, score 13.424) (writing took 2.228509903419763 seconds)
2022-03-07 16:34:57 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 16:34:57 | INFO | train | epoch 350 | loss 1.643 | nll_loss 0.608 | ppl 1.52 | wps 22184.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33721 | lr 0.000172207 | gnorm 0.783 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 99809
2022-03-07 16:34:57 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 16:34:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:38:45 | INFO | train_inner | epoch 351:     80 / 97 loss=1.642, nll_loss=0.607, ppl=1.52, wps=22207.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=33800, lr=0.000172005, gnorm=0.783, loss_scale=16, train_wall=265, gb_free=8.1, wall=100037
2022-03-07 16:39:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:39:38 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 13.433 | nll_loss 12.985 | ppl 8108.16 | wps 43023.1 | wpb 510.9 | bsz 1 | num_updates 33817 | best_loss 7.981
2022-03-07 16:39:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 33817 updates
2022-03-07 16:39:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:39:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:39:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 351 @ 33817 updates, score 13.433) (writing took 2.232879643328488 seconds)
2022-03-07 16:39:40 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 16:39:40 | INFO | train | epoch 351 | loss 1.642 | nll_loss 0.606 | ppl 1.52 | wps 22173.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33817 | lr 0.000171962 | gnorm 0.783 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 100092
2022-03-07 16:39:40 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 16:39:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:43:37 | INFO | train_inner | epoch 352:     83 / 97 loss=1.641, nll_loss=0.605, ppl=1.52, wps=22426.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33900, lr=0.000171751, gnorm=0.777, loss_scale=16, train_wall=262, gb_free=8.1, wall=100329
2022-03-07 16:44:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:44:22 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 13.469 | nll_loss 13.024 | ppl 8327.65 | wps 42944.3 | wpb 510.9 | bsz 1 | num_updates 33914 | best_loss 7.981
2022-03-07 16:44:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 33914 updates
2022-03-07 16:44:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:44:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:44:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 352 @ 33914 updates, score 13.469) (writing took 2.2871659747324884 seconds)
2022-03-07 16:44:24 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 16:44:24 | INFO | train | epoch 352 | loss 1.64 | nll_loss 0.604 | ppl 1.52 | wps 22404.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33914 | lr 0.000171716 | gnorm 0.773 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 100376
2022-03-07 16:44:24 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 16:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:46:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:48:32 | INFO | train_inner | epoch 353:     87 / 97 loss=1.641, nll_loss=0.605, ppl=1.52, wps=22215.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34000, lr=0.000171499, gnorm=0.78, loss_scale=16, train_wall=265, gb_free=8.1, wall=100623
2022-03-07 16:49:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:49:05 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 13.382 | nll_loss 12.932 | ppl 7815.16 | wps 42917.4 | wpb 510.9 | bsz 1 | num_updates 34010 | best_loss 7.981
2022-03-07 16:49:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 34010 updates
2022-03-07 16:49:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:49:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:49:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 353 @ 34010 updates, score 13.382) (writing took 2.256299324799329 seconds)
2022-03-07 16:49:07 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 16:49:07 | INFO | train | epoch 353 | loss 1.64 | nll_loss 0.604 | ppl 1.52 | wps 22185.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34010 | lr 0.000171473 | gnorm 0.782 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 100659
2022-03-07 16:49:07 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 16:49:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:53:23 | INFO | train_inner | epoch 354:     90 / 97 loss=1.639, nll_loss=0.603, ppl=1.52, wps=22433.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34100, lr=0.000171247, gnorm=0.774, loss_scale=32, train_wall=262, gb_free=8.1, wall=100915
2022-03-07 16:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:53:48 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 13.409 | nll_loss 12.956 | ppl 7947.69 | wps 42877.8 | wpb 510.9 | bsz 1 | num_updates 34107 | best_loss 7.981
2022-03-07 16:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 34107 updates
2022-03-07 16:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:53:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 354 @ 34107 updates, score 13.409) (writing took 2.30713558383286 seconds)
2022-03-07 16:53:51 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 16:53:51 | INFO | train | epoch 354 | loss 1.639 | nll_loss 0.603 | ppl 1.52 | wps 22411.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34107 | lr 0.000171229 | gnorm 0.775 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 100943
2022-03-07 16:53:51 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 16:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:54:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:58:18 | INFO | train_inner | epoch 355:     94 / 97 loss=1.639, nll_loss=0.603, ppl=1.52, wps=22204.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34200, lr=0.000170996, gnorm=0.783, loss_scale=16, train_wall=265, gb_free=8.1, wall=101210
2022-03-07 16:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:58:32 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 13.425 | nll_loss 12.973 | ppl 8039.25 | wps 43123.4 | wpb 510.9 | bsz 1 | num_updates 34203 | best_loss 7.981
2022-03-07 16:58:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 34203 updates
2022-03-07 16:58:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:58:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:58:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 355 @ 34203 updates, score 13.425) (writing took 2.210926823783666 seconds)
2022-03-07 16:58:34 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 16:58:34 | INFO | train | epoch 355 | loss 1.638 | nll_loss 0.602 | ppl 1.52 | wps 22184.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34203 | lr 0.000170989 | gnorm 0.782 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 101226
2022-03-07 16:58:34 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 16:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:01:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:03:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:03:15 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 13.453 | nll_loss 13.008 | ppl 8235.93 | wps 43059.1 | wpb 510.9 | bsz 1 | num_updates 34299 | best_loss 7.981
2022-03-07 17:03:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 34299 updates
2022-03-07 17:03:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:03:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:03:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 356 @ 34299 updates, score 13.453) (writing took 2.195626333821565 seconds)
2022-03-07 17:03:17 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 17:03:17 | INFO | train | epoch 356 | loss 1.636 | nll_loss 0.6 | ppl 1.52 | wps 22188.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34299 | lr 0.000170749 | gnorm 0.778 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 101509
2022-03-07 17:03:17 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 17:03:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:03:20 | INFO | train_inner | epoch 357:      1 / 97 loss=1.637, nll_loss=0.601, ppl=1.52, wps=21675.5, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=34300, lr=0.000170747, gnorm=0.78, loss_scale=16, train_wall=264, gb_free=8.1, wall=101512
2022-03-07 17:07:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:07:59 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.462 | nll_loss 13.017 | ppl 8286.69 | wps 43123 | wpb 510.9 | bsz 1 | num_updates 34396 | best_loss 7.981
2022-03-07 17:07:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 34396 updates
2022-03-07 17:07:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:08:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:08:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 357 @ 34396 updates, score 13.462) (writing took 2.182085098233074 seconds)
2022-03-07 17:08:01 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 17:08:01 | INFO | train | epoch 357 | loss 1.636 | nll_loss 0.6 | ppl 1.52 | wps 22418.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34396 | lr 0.000170508 | gnorm 0.774 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 101793
2022-03-07 17:08:01 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 17:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:08:12 | INFO | train_inner | epoch 358:      4 / 97 loss=1.635, nll_loss=0.6, ppl=1.52, wps=22434.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34400, lr=0.000170499, gnorm=0.774, loss_scale=32, train_wall=262, gb_free=8.1, wall=101804
2022-03-07 17:12:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:12:42 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.405 | nll_loss 12.956 | ppl 7945.18 | wps 42948.8 | wpb 510.9 | bsz 1 | num_updates 34493 | best_loss 7.981
2022-03-07 17:12:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 34493 updates
2022-03-07 17:12:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:12:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:12:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 358 @ 34493 updates, score 13.405) (writing took 2.335138785187155 seconds)
2022-03-07 17:12:44 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 17:12:44 | INFO | train | epoch 358 | loss 1.635 | nll_loss 0.6 | ppl 1.52 | wps 22413.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34493 | lr 0.000170269 | gnorm 0.773 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 102076
2022-03-07 17:12:44 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 17:12:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:13:04 | INFO | train_inner | epoch 359:      7 / 97 loss=1.635, nll_loss=0.599, ppl=1.51, wps=22432.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34500, lr=0.000170251, gnorm=0.772, loss_scale=32, train_wall=262, gb_free=8.1, wall=102096
2022-03-07 17:13:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:17:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:17:25 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.44 | nll_loss 12.994 | ppl 8156.83 | wps 42926.7 | wpb 510.9 | bsz 1 | num_updates 34588 | best_loss 7.981
2022-03-07 17:17:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 34588 updates
2022-03-07 17:17:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:17:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:17:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 359 @ 34588 updates, score 13.44) (writing took 2.327954255975783 seconds)
2022-03-07 17:17:28 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 17:17:28 | INFO | train | epoch 359 | loss 1.634 | nll_loss 0.598 | ppl 1.51 | wps 21942.2 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 34588 | lr 0.000170035 | gnorm 0.768 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 102360
2022-03-07 17:17:28 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 17:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:18:02 | INFO | train_inner | epoch 360:     12 / 97 loss=1.632, nll_loss=0.596, ppl=1.51, wps=21994.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34600, lr=0.000170005, gnorm=0.766, loss_scale=16, train_wall=267, gb_free=8.1, wall=102394
2022-03-07 17:22:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:22:09 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.445 | nll_loss 12.999 | ppl 8187.2 | wps 43052.1 | wpb 510.9 | bsz 1 | num_updates 34685 | best_loss 7.981
2022-03-07 17:22:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 34685 updates
2022-03-07 17:22:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:22:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:22:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 360 @ 34685 updates, score 13.445) (writing took 2.2861712481826544 seconds)
2022-03-07 17:22:11 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 17:22:11 | INFO | train | epoch 360 | loss 1.633 | nll_loss 0.598 | ppl 1.51 | wps 22417.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34685 | lr 0.000169797 | gnorm 0.773 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 102643
2022-03-07 17:22:11 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 17:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:22:54 | INFO | train_inner | epoch 361:     15 / 97 loss=1.632, nll_loss=0.596, ppl=1.51, wps=22434.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34700, lr=0.00016976, gnorm=0.771, loss_scale=16, train_wall=262, gb_free=8.1, wall=102686
2022-03-07 17:24:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:26:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:26:52 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.416 | nll_loss 12.966 | ppl 8000.03 | wps 43101.1 | wpb 510.9 | bsz 1 | num_updates 34781 | best_loss 7.981
2022-03-07 17:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 34781 updates
2022-03-07 17:26:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:26:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:26:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 361 @ 34781 updates, score 13.416) (writing took 2.2986186291091144 seconds)
2022-03-07 17:26:55 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 17:26:55 | INFO | train | epoch 361 | loss 1.632 | nll_loss 0.597 | ppl 1.51 | wps 22179.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34781 | lr 0.000169562 | gnorm 0.764 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 102927
2022-03-07 17:26:55 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 17:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:27:49 | INFO | train_inner | epoch 362:     19 / 97 loss=1.632, nll_loss=0.597, ppl=1.51, wps=22212.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34800, lr=0.000169516, gnorm=0.764, loss_scale=16, train_wall=265, gb_free=8.1, wall=102981
2022-03-07 17:30:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:31:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:31:36 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 13.479 | nll_loss 13.036 | ppl 8398.71 | wps 43065 | wpb 510.9 | bsz 1 | num_updates 34877 | best_loss 7.981
2022-03-07 17:31:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 34877 updates
2022-03-07 17:31:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:31:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:31:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 362 @ 34877 updates, score 13.479) (writing took 2.2278312211856246 seconds)
2022-03-07 17:31:38 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 17:31:38 | INFO | train | epoch 362 | loss 1.631 | nll_loss 0.596 | ppl 1.51 | wps 22183.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34877 | lr 0.000169329 | gnorm 0.77 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 103210
2022-03-07 17:31:38 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 17:31:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:32:44 | INFO | train_inner | epoch 363:     23 / 97 loss=1.631, nll_loss=0.595, ppl=1.51, wps=22218.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34900, lr=0.000169273, gnorm=0.77, loss_scale=16, train_wall=265, gb_free=8.1, wall=103275
2022-03-07 17:36:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:36:19 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.529 | nll_loss 13.085 | ppl 8686.55 | wps 43052.9 | wpb 510.9 | bsz 1 | num_updates 34974 | best_loss 7.981
2022-03-07 17:36:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 34974 updates
2022-03-07 17:36:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:36:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:36:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 363 @ 34974 updates, score 13.529) (writing took 2.391080440953374 seconds)
2022-03-07 17:36:22 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 17:36:22 | INFO | train | epoch 363 | loss 1.631 | nll_loss 0.595 | ppl 1.51 | wps 22407.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34974 | lr 0.000169094 | gnorm 0.769 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 103493
2022-03-07 17:36:22 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 17:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:37:36 | INFO | train_inner | epoch 364:     26 / 97 loss=1.63, nll_loss=0.595, ppl=1.51, wps=22425.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35000, lr=0.000169031, gnorm=0.767, loss_scale=32, train_wall=262, gb_free=8.1, wall=103568
2022-03-07 17:40:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:41:03 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 13.413 | nll_loss 12.963 | ppl 7985.58 | wps 43144 | wpb 510.9 | bsz 1 | num_updates 35071 | best_loss 7.981
2022-03-07 17:41:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 35071 updates
2022-03-07 17:41:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:41:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:41:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 364 @ 35071 updates, score 13.413) (writing took 2.2222459162585437 seconds)
2022-03-07 17:41:05 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 17:41:05 | INFO | train | epoch 364 | loss 1.63 | nll_loss 0.594 | ppl 1.51 | wps 22424.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35071 | lr 0.00016886 | gnorm 0.765 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 103777
2022-03-07 17:41:05 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 17:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:42:27 | INFO | train_inner | epoch 365:     29 / 97 loss=1.629, nll_loss=0.594, ppl=1.51, wps=22444.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35100, lr=0.00016879, gnorm=0.763, loss_scale=32, train_wall=262, gb_free=8.1, wall=103859
2022-03-07 17:42:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:45:46 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.465 | nll_loss 13.019 | ppl 8303.28 | wps 42996.9 | wpb 510.9 | bsz 1 | num_updates 35167 | best_loss 7.981
2022-03-07 17:45:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 35167 updates
2022-03-07 17:45:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:45:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:45:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 365 @ 35167 updates, score 13.465) (writing took 2.2287504938431084 seconds)
2022-03-07 17:45:48 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 17:45:48 | INFO | train | epoch 365 | loss 1.628 | nll_loss 0.593 | ppl 1.51 | wps 22183.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35167 | lr 0.000168629 | gnorm 0.768 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 104060
2022-03-07 17:45:48 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 17:45:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:47:22 | INFO | train_inner | epoch 366:     33 / 97 loss=1.628, nll_loss=0.592, ppl=1.51, wps=22215.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35200, lr=0.00016855, gnorm=0.772, loss_scale=16, train_wall=265, gb_free=8.1, wall=104154
2022-03-07 17:48:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:50:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:50:29 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.451 | nll_loss 13.004 | ppl 8212.23 | wps 43096.4 | wpb 510.9 | bsz 1 | num_updates 35263 | best_loss 7.981
2022-03-07 17:50:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 35263 updates
2022-03-07 17:50:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:50:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:50:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 366 @ 35263 updates, score 13.451) (writing took 2.219066903926432 seconds)
2022-03-07 17:50:31 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 17:50:31 | INFO | train | epoch 366 | loss 1.627 | nll_loss 0.592 | ppl 1.51 | wps 22195.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35263 | lr 0.000168399 | gnorm 0.772 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 104343
2022-03-07 17:50:32 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 17:50:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:52:17 | INFO | train_inner | epoch 367:     37 / 97 loss=1.626, nll_loss=0.591, ppl=1.51, wps=22225.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35300, lr=0.000168311, gnorm=0.769, loss_scale=16, train_wall=265, gb_free=8.1, wall=104449
2022-03-07 17:55:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:55:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:55:13 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 13.421 | nll_loss 12.974 | ppl 8048.29 | wps 43054.9 | wpb 510.9 | bsz 1 | num_updates 35359 | best_loss 7.981
2022-03-07 17:55:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 35359 updates
2022-03-07 17:55:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:55:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:55:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 367 @ 35359 updates, score 13.421) (writing took 2.1216579182073474 seconds)
2022-03-07 17:55:15 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 17:55:15 | INFO | train | epoch 367 | loss 1.626 | nll_loss 0.59 | ppl 1.51 | wps 22198.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35359 | lr 0.000168171 | gnorm 0.764 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 104627
2022-03-07 17:55:15 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 17:55:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:57:11 | INFO | train_inner | epoch 368:     41 / 97 loss=1.626, nll_loss=0.59, ppl=1.51, wps=22234.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35400, lr=0.000168073, gnorm=0.766, loss_scale=16, train_wall=265, gb_free=8.1, wall=104743
2022-03-07 17:59:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:59:56 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.467 | nll_loss 13.023 | ppl 8323.74 | wps 43364.5 | wpb 510.9 | bsz 1 | num_updates 35456 | best_loss 7.981
2022-03-07 17:59:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 35456 updates
2022-03-07 17:59:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:59:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:59:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 368 @ 35456 updates, score 13.467) (writing took 2.20263908803463 seconds)
2022-03-07 17:59:59 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 17:59:59 | INFO | train | epoch 368 | loss 1.625 | nll_loss 0.59 | ppl 1.51 | wps 22372 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35456 | lr 0.00016794 | gnorm 0.771 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 104911
2022-03-07 17:59:59 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 17:59:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:01:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:02:07 | INFO | train_inner | epoch 369:     45 / 97 loss=1.625, nll_loss=0.59, ppl=1.51, wps=22160, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35500, lr=0.000167836, gnorm=0.77, loss_scale=16, train_wall=266, gb_free=8.1, wall=105039
2022-03-07 18:04:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:04:40 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 13.488 | nll_loss 13.044 | ppl 8448.2 | wps 42934 | wpb 510.9 | bsz 1 | num_updates 35552 | best_loss 7.981
2022-03-07 18:04:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 35552 updates
2022-03-07 18:04:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:04:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:04:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 369 @ 35552 updates, score 13.488) (writing took 2.230349355842918 seconds)
2022-03-07 18:04:42 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 18:04:42 | INFO | train | epoch 369 | loss 1.624 | nll_loss 0.589 | ppl 1.5 | wps 22158.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35552 | lr 0.000167713 | gnorm 0.768 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 105194
2022-03-07 18:04:42 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 18:04:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:06:59 | INFO | train_inner | epoch 370:     48 / 97 loss=1.624, nll_loss=0.589, ppl=1.5, wps=22414.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35600, lr=0.0001676, gnorm=0.774, loss_scale=16, train_wall=262, gb_free=8.1, wall=105331
2022-03-07 18:08:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:09:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:09:24 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.416 | nll_loss 12.972 | ppl 8034.1 | wps 42947.5 | wpb 510.9 | bsz 1 | num_updates 35648 | best_loss 7.981
2022-03-07 18:09:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 35648 updates
2022-03-07 18:09:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:09:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:09:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 370 @ 35648 updates, score 13.416) (writing took 2.2048355569131672 seconds)
2022-03-07 18:09:26 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 18:09:26 | INFO | train | epoch 370 | loss 1.624 | nll_loss 0.589 | ppl 1.5 | wps 22182.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35648 | lr 0.000167488 | gnorm 0.779 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 105478
2022-03-07 18:09:26 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 18:09:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:11:54 | INFO | train_inner | epoch 371:     52 / 97 loss=1.623, nll_loss=0.588, ppl=1.5, wps=22202.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=35700, lr=0.000167365, gnorm=0.767, loss_scale=16, train_wall=265, gb_free=8.1, wall=105626
2022-03-07 18:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:14:07 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 13.471 | nll_loss 13.025 | ppl 8334.66 | wps 43186.4 | wpb 510.9 | bsz 1 | num_updates 35745 | best_loss 7.981
2022-03-07 18:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 35745 updates
2022-03-07 18:14:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:14:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 371 @ 35745 updates, score 13.471) (writing took 2.216432978399098 seconds)
2022-03-07 18:14:10 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 18:14:10 | INFO | train | epoch 371 | loss 1.622 | nll_loss 0.587 | ppl 1.5 | wps 22393.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35745 | lr 0.00016726 | gnorm 0.761 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 105761
2022-03-07 18:14:10 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 18:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:16:46 | INFO | train_inner | epoch 372:     55 / 97 loss=1.621, nll_loss=0.586, ppl=1.5, wps=22424.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=35800, lr=0.000167132, gnorm=0.766, loss_scale=32, train_wall=262, gb_free=8.1, wall=105918
2022-03-07 18:17:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:18:51 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.439 | nll_loss 12.991 | ppl 8140.68 | wps 42867.9 | wpb 510.9 | bsz 1 | num_updates 35841 | best_loss 7.981
2022-03-07 18:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 35841 updates
2022-03-07 18:18:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:18:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:18:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 372 @ 35841 updates, score 13.439) (writing took 2.0918139801360667 seconds)
2022-03-07 18:18:53 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 18:18:53 | INFO | train | epoch 372 | loss 1.621 | nll_loss 0.586 | ppl 1.5 | wps 22185.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35841 | lr 0.000167036 | gnorm 0.773 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 106045
2022-03-07 18:18:53 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 18:18:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:21:41 | INFO | train_inner | epoch 373:     59 / 97 loss=1.621, nll_loss=0.586, ppl=1.5, wps=22182.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=35900, lr=0.000166899, gnorm=0.77, loss_scale=16, train_wall=265, gb_free=8.1, wall=106213
2022-03-07 18:23:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:23:35 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 13.417 | nll_loss 12.972 | ppl 8031.85 | wps 43317.9 | wpb 510.9 | bsz 1 | num_updates 35938 | best_loss 7.981
2022-03-07 18:23:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 35938 updates
2022-03-07 18:23:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:23:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:23:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 373 @ 35938 updates, score 13.417) (writing took 2.3703822479583323 seconds)
2022-03-07 18:23:37 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 18:23:37 | INFO | train | epoch 373 | loss 1.621 | nll_loss 0.586 | ppl 1.5 | wps 22367.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35938 | lr 0.00016681 | gnorm 0.764 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 106329
2022-03-07 18:23:37 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 18:23:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:26:34 | INFO | train_inner | epoch 374:     62 / 97 loss=1.621, nll_loss=0.586, ppl=1.5, wps=22417.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=36000, lr=0.000166667, gnorm=0.763, loss_scale=32, train_wall=262, gb_free=8.1, wall=106506
2022-03-07 18:26:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:28:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:28:18 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.455 | nll_loss 13.008 | ppl 8235.96 | wps 42825.9 | wpb 510.9 | bsz 1 | num_updates 36034 | best_loss 7.981
2022-03-07 18:28:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 36034 updates
2022-03-07 18:28:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:28:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:28:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 374 @ 36034 updates, score 13.455) (writing took 2.319101694971323 seconds)
2022-03-07 18:28:21 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 18:28:21 | INFO | train | epoch 374 | loss 1.619 | nll_loss 0.585 | ppl 1.5 | wps 22164 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36034 | lr 0.000166588 | gnorm 0.763 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 106612
2022-03-07 18:28:21 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 18:28:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:31:29 | INFO | train_inner | epoch 375:     66 / 97 loss=1.619, nll_loss=0.584, ppl=1.5, wps=22198, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36100, lr=0.000166436, gnorm=0.767, loss_scale=16, train_wall=265, gb_free=8.1, wall=106801
2022-03-07 18:32:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:33:02 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.447 | nll_loss 13.002 | ppl 8204.17 | wps 43052.8 | wpb 510.9 | bsz 1 | num_updates 36131 | best_loss 7.981
2022-03-07 18:33:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 36131 updates
2022-03-07 18:33:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:33:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:33:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 375 @ 36131 updates, score 13.447) (writing took 2.2641789601184428 seconds)
2022-03-07 18:33:04 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 18:33:04 | INFO | train | epoch 375 | loss 1.619 | nll_loss 0.585 | ppl 1.5 | wps 22405.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36131 | lr 0.000166364 | gnorm 0.764 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 106896
2022-03-07 18:33:04 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 18:33:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:36:21 | INFO | train_inner | epoch 376:     69 / 97 loss=1.62, nll_loss=0.586, ppl=1.5, wps=22427.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36200, lr=0.000166206, gnorm=0.762, loss_scale=32, train_wall=262, gb_free=8.1, wall=107093
2022-03-07 18:37:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:37:46 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.417 | nll_loss 12.97 | ppl 8025.58 | wps 42615.7 | wpb 510.9 | bsz 1 | num_updates 36228 | best_loss 7.981
2022-03-07 18:37:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 36228 updates
2022-03-07 18:37:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:37:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:37:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 376 @ 36228 updates, score 13.417) (writing took 2.1928689158521593 seconds)
2022-03-07 18:37:48 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 18:37:48 | INFO | train | epoch 376 | loss 1.619 | nll_loss 0.584 | ppl 1.5 | wps 22398.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36228 | lr 0.000166141 | gnorm 0.762 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 107180
2022-03-07 18:37:48 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 18:37:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:38:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:41:16 | INFO | train_inner | epoch 377:     73 / 97 loss=1.618, nll_loss=0.584, ppl=1.5, wps=22151.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=36300, lr=0.000165977, gnorm=0.766, loss_scale=16, train_wall=265, gb_free=8.1, wall=107388
2022-03-07 18:42:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:42:30 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.449 | nll_loss 13.005 | ppl 8222.13 | wps 42779.4 | wpb 510.9 | bsz 1 | num_updates 36324 | best_loss 7.981
2022-03-07 18:42:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 36324 updates
2022-03-07 18:42:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:42:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:42:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 377 @ 36324 updates, score 13.449) (writing took 2.281089197844267 seconds)
2022-03-07 18:42:32 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 18:42:32 | INFO | train | epoch 377 | loss 1.618 | nll_loss 0.583 | ppl 1.5 | wps 22121 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36324 | lr 0.000165922 | gnorm 0.767 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 107464
2022-03-07 18:42:32 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 18:42:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:44:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:46:11 | INFO | train_inner | epoch 378:     77 / 97 loss=1.617, nll_loss=0.582, ppl=1.5, wps=22205.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36400, lr=0.000165748, gnorm=0.763, loss_scale=16, train_wall=265, gb_free=8.1, wall=107683
2022-03-07 18:47:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:47:13 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.476 | nll_loss 13.032 | ppl 8374.39 | wps 42893.2 | wpb 510.9 | bsz 1 | num_updates 36420 | best_loss 7.981
2022-03-07 18:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 36420 updates
2022-03-07 18:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 378 @ 36420 updates, score 13.476) (writing took 2.240447945892811 seconds)
2022-03-07 18:47:15 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 18:47:15 | INFO | train | epoch 378 | loss 1.616 | nll_loss 0.582 | ppl 1.5 | wps 22180.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36420 | lr 0.000165703 | gnorm 0.764 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 107747
2022-03-07 18:47:15 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 18:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:51:03 | INFO | train_inner | epoch 379:     80 / 97 loss=1.617, nll_loss=0.582, ppl=1.5, wps=22419.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36500, lr=0.000165521, gnorm=0.767, loss_scale=16, train_wall=262, gb_free=8.1, wall=107975
2022-03-07 18:51:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:51:57 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 13.49 | nll_loss 13.048 | ppl 8468.37 | wps 43063.2 | wpb 510.9 | bsz 1 | num_updates 36517 | best_loss 7.981
2022-03-07 18:51:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 36517 updates
2022-03-07 18:51:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:51:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:51:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 379 @ 36517 updates, score 13.49) (writing took 2.3027377449907362 seconds)
2022-03-07 18:51:59 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 18:51:59 | INFO | train | epoch 379 | loss 1.616 | nll_loss 0.581 | ppl 1.5 | wps 22396 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36517 | lr 0.000165483 | gnorm 0.763 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 108031
2022-03-07 18:51:59 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 18:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:53:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:55:58 | INFO | train_inner | epoch 380:     84 / 97 loss=1.614, nll_loss=0.58, ppl=1.49, wps=22208.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36600, lr=0.000165295, gnorm=0.756, loss_scale=16, train_wall=265, gb_free=8.1, wall=108270
2022-03-07 18:56:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:56:40 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 13.431 | nll_loss 12.985 | ppl 8105.18 | wps 42969.3 | wpb 510.9 | bsz 1 | num_updates 36613 | best_loss 7.981
2022-03-07 18:56:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 36613 updates
2022-03-07 18:56:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:56:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 380 @ 36613 updates, score 13.431) (writing took 2.2094422630034387 seconds)
2022-03-07 18:56:43 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 18:56:43 | INFO | train | epoch 380 | loss 1.614 | nll_loss 0.58 | ppl 1.49 | wps 22181.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36613 | lr 0.000165266 | gnorm 0.756 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 108314
2022-03-07 18:56:43 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 18:56:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:00:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:00:54 | INFO | train_inner | epoch 381:     88 / 97 loss=1.614, nll_loss=0.58, ppl=1.49, wps=22179.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36700, lr=0.00016507, gnorm=0.756, loss_scale=16, train_wall=265, gb_free=8.1, wall=108565
2022-03-07 19:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:01:24 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.49 | nll_loss 13.047 | ppl 8461.3 | wps 42649.6 | wpb 510.9 | bsz 1 | num_updates 36709 | best_loss 7.981
2022-03-07 19:01:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 36709 updates
2022-03-07 19:01:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:01:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:01:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 381 @ 36709 updates, score 13.49) (writing took 2.2574373688548803 seconds)
2022-03-07 19:01:27 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 19:01:27 | INFO | train | epoch 381 | loss 1.613 | nll_loss 0.578 | ppl 1.49 | wps 22129.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36709 | lr 0.000165049 | gnorm 0.755 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 108599
2022-03-07 19:01:27 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 19:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:05:47 | INFO | train_inner | epoch 382:     91 / 97 loss=1.614, nll_loss=0.579, ppl=1.49, wps=22325.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36800, lr=0.000164845, gnorm=0.766, loss_scale=16, train_wall=263, gb_free=8.1, wall=108859
2022-03-07 19:06:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:06:09 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.412 | nll_loss 12.969 | ppl 8018.16 | wps 42588.2 | wpb 510.9 | bsz 1 | num_updates 36806 | best_loss 7.981
2022-03-07 19:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 36806 updates
2022-03-07 19:06:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:06:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:06:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 382 @ 36806 updates, score 13.412) (writing took 2.2113796188496053 seconds)
2022-03-07 19:06:11 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 19:06:11 | INFO | train | epoch 382 | loss 1.613 | nll_loss 0.579 | ppl 1.49 | wps 22318.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36806 | lr 0.000164832 | gnorm 0.765 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 108883
2022-03-07 19:06:11 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 19:06:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:07:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:10:43 | INFO | train_inner | epoch 383:     95 / 97 loss=1.613, nll_loss=0.579, ppl=1.49, wps=22109, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36900, lr=0.000164622, gnorm=0.763, loss_scale=16, train_wall=266, gb_free=8.1, wall=109155
2022-03-07 19:10:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:10:54 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 13.403 | nll_loss 12.956 | ppl 7948.46 | wps 42430.1 | wpb 510.9 | bsz 1 | num_updates 36902 | best_loss 7.981
2022-03-07 19:10:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 36902 updates
2022-03-07 19:10:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:10:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:10:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 383 @ 36902 updates, score 13.403) (writing took 2.234016704838723 seconds)
2022-03-07 19:10:56 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 19:10:56 | INFO | train | epoch 383 | loss 1.612 | nll_loss 0.578 | ppl 1.49 | wps 22069.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36902 | lr 0.000164617 | gnorm 0.763 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 109168
2022-03-07 19:10:56 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 19:10:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:14:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:15:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:15:39 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 13.501 | nll_loss 13.059 | ppl 8533.73 | wps 42512.9 | wpb 510.9 | bsz 1 | num_updates 36998 | best_loss 7.981
2022-03-07 19:15:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 36998 updates
2022-03-07 19:15:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:15:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 384 @ 36998 updates, score 13.501) (writing took 2.277211726643145 seconds)
2022-03-07 19:15:41 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 19:15:41 | INFO | train | epoch 384 | loss 1.611 | nll_loss 0.577 | ppl 1.49 | wps 22069.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36998 | lr 0.000164403 | gnorm 0.769 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 109453
2022-03-07 19:15:41 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 19:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:15:47 | INFO | train_inner | epoch 385:      2 / 97 loss=1.611, nll_loss=0.577, ppl=1.49, wps=21554.3, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=37000, lr=0.000164399, gnorm=0.769, loss_scale=16, train_wall=266, gb_free=8.1, wall=109459
2022-03-07 19:20:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:20:24 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.521 | nll_loss 13.079 | ppl 8654.55 | wps 42609.2 | wpb 510.9 | bsz 1 | num_updates 37095 | best_loss 7.981
2022-03-07 19:20:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 37095 updates
2022-03-07 19:20:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:20:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:20:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 385 @ 37095 updates, score 13.521) (writing took 2.1783935739658773 seconds)
2022-03-07 19:20:26 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 19:20:26 | INFO | train | epoch 385 | loss 1.611 | nll_loss 0.576 | ppl 1.49 | wps 22311.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37095 | lr 0.000164188 | gnorm 0.764 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 109738
2022-03-07 19:20:26 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 19:20:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:20:40 | INFO | train_inner | epoch 386:      5 / 97 loss=1.611, nll_loss=0.576, ppl=1.49, wps=22326.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37100, lr=0.000164177, gnorm=0.763, loss_scale=16, train_wall=263, gb_free=8.1, wall=109752
2022-03-07 19:20:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:25:08 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.466 | nll_loss 13.025 | ppl 8332.55 | wps 42794.9 | wpb 510.9 | bsz 1 | num_updates 37191 | best_loss 7.981
2022-03-07 19:25:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 37191 updates
2022-03-07 19:25:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:25:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:25:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 386 @ 37191 updates, score 13.466) (writing took 2.187798570841551 seconds)
2022-03-07 19:25:10 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 19:25:10 | INFO | train | epoch 386 | loss 1.609 | nll_loss 0.575 | ppl 1.49 | wps 22093.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37191 | lr 0.000163976 | gnorm 0.764 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 110022
2022-03-07 19:25:10 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 19:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:25:36 | INFO | train_inner | epoch 387:      9 / 97 loss=1.608, nll_loss=0.574, ppl=1.49, wps=22126.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=37200, lr=0.000163956, gnorm=0.762, loss_scale=16, train_wall=266, gb_free=8.1, wall=110048
2022-03-07 19:28:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:29:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:29:53 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.425 | nll_loss 12.98 | ppl 8077.65 | wps 42190.8 | wpb 510.9 | bsz 1 | num_updates 37287 | best_loss 7.981
2022-03-07 19:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 37287 updates
2022-03-07 19:29:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:29:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:29:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 387 @ 37287 updates, score 13.425) (writing took 2.2541772481054068 seconds)
2022-03-07 19:29:55 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 19:29:55 | INFO | train | epoch 387 | loss 1.608 | nll_loss 0.574 | ppl 1.49 | wps 22072.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37287 | lr 0.000163765 | gnorm 0.75 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 110307
2022-03-07 19:29:55 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 19:29:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:30:32 | INFO | train_inner | epoch 388:     13 / 97 loss=1.607, nll_loss=0.573, ppl=1.49, wps=22111.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=37300, lr=0.000163737, gnorm=0.752, loss_scale=16, train_wall=266, gb_free=8.1, wall=110344
2022-03-07 19:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:34:37 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.441 | nll_loss 12.995 | ppl 8166.44 | wps 42589.6 | wpb 510.9 | bsz 1 | num_updates 37384 | best_loss 7.981
2022-03-07 19:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 37384 updates
2022-03-07 19:34:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:34:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:34:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 388 @ 37384 updates, score 13.441) (writing took 2.254290055949241 seconds)
2022-03-07 19:34:40 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 19:34:40 | INFO | train | epoch 388 | loss 1.608 | nll_loss 0.574 | ppl 1.49 | wps 22326.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37384 | lr 0.000163552 | gnorm 0.765 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 110592
2022-03-07 19:34:40 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 19:34:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:35:26 | INFO | train_inner | epoch 389:     16 / 97 loss=1.608, nll_loss=0.574, ppl=1.49, wps=22340, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37400, lr=0.000163517, gnorm=0.765, loss_scale=32, train_wall=263, gb_free=8.1, wall=110637
2022-03-07 19:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:39:22 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 13.444 | nll_loss 13.002 | ppl 8205.07 | wps 42629.4 | wpb 510.9 | bsz 1 | num_updates 37481 | best_loss 7.981
2022-03-07 19:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 37481 updates
2022-03-07 19:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:39:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:39:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 389 @ 37481 updates, score 13.444) (writing took 2.193726234138012 seconds)
2022-03-07 19:39:24 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 19:39:24 | INFO | train | epoch 389 | loss 1.606 | nll_loss 0.572 | ppl 1.49 | wps 22316.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37481 | lr 0.000163341 | gnorm 0.756 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 110876
2022-03-07 19:39:24 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 19:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:40:19 | INFO | train_inner | epoch 390:     19 / 97 loss=1.606, nll_loss=0.572, ppl=1.49, wps=22343.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37500, lr=0.000163299, gnorm=0.751, loss_scale=32, train_wall=263, gb_free=8.1, wall=110931
2022-03-07 19:41:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:42:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:44:06 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 13.431 | nll_loss 12.988 | ppl 8124.16 | wps 43403.5 | wpb 510.9 | bsz 1 | num_updates 37576 | best_loss 7.981
2022-03-07 19:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 37576 updates
2022-03-07 19:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:44:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:44:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 390 @ 37576 updates, score 13.431) (writing took 2.2752482150681317 seconds)
2022-03-07 19:44:08 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 19:44:08 | INFO | train | epoch 390 | loss 1.607 | nll_loss 0.573 | ppl 1.49 | wps 21921.1 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 37576 | lr 0.000163134 | gnorm 0.766 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 111160
2022-03-07 19:44:08 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 19:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:45:17 | INFO | train_inner | epoch 391:     24 / 97 loss=1.605, nll_loss=0.571, ppl=1.49, wps=21977.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=37600, lr=0.000163082, gnorm=0.767, loss_scale=16, train_wall=267, gb_free=8.1, wall=111229
2022-03-07 19:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:48:50 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.494 | nll_loss 13.052 | ppl 8490.87 | wps 42887.6 | wpb 510.9 | bsz 1 | num_updates 37673 | best_loss 7.981
2022-03-07 19:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 37673 updates
2022-03-07 19:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:48:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:48:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 391 @ 37673 updates, score 13.494) (writing took 2.264821578282863 seconds)
2022-03-07 19:48:52 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 19:48:52 | INFO | train | epoch 391 | loss 1.605 | nll_loss 0.571 | ppl 1.49 | wps 22384.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37673 | lr 0.000162924 | gnorm 0.76 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 111444
2022-03-07 19:48:52 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 19:48:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:49:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:50:12 | INFO | train_inner | epoch 392:     28 / 97 loss=1.604, nll_loss=0.57, ppl=1.48, wps=22193.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=37700, lr=0.000162866, gnorm=0.759, loss_scale=16, train_wall=265, gb_free=8.1, wall=111524
2022-03-07 19:53:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:53:33 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 13.422 | nll_loss 12.979 | ppl 8075.82 | wps 43189.5 | wpb 510.9 | bsz 1 | num_updates 37769 | best_loss 7.981
2022-03-07 19:53:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 37769 updates
2022-03-07 19:53:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:53:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:53:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 392 @ 37769 updates, score 13.422) (writing took 2.3349253833293915 seconds)
2022-03-07 19:53:36 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 19:53:36 | INFO | train | epoch 392 | loss 1.604 | nll_loss 0.57 | ppl 1.48 | wps 22171.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37769 | lr 0.000162717 | gnorm 0.751 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 111727
2022-03-07 19:53:36 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 19:53:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:55:04 | INFO | train_inner | epoch 393:     31 / 97 loss=1.604, nll_loss=0.57, ppl=1.48, wps=22413.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37800, lr=0.00016265, gnorm=0.75, loss_scale=16, train_wall=262, gb_free=8.1, wall=111816
2022-03-07 19:57:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:58:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:58:17 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.483 | nll_loss 13.045 | ppl 8449.46 | wps 43055.2 | wpb 510.9 | bsz 1 | num_updates 37865 | best_loss 7.981
2022-03-07 19:58:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 37865 updates
2022-03-07 19:58:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:58:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:58:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 393 @ 37865 updates, score 13.483) (writing took 2.2738260473124683 seconds)
2022-03-07 19:58:19 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 19:58:19 | INFO | train | epoch 393 | loss 1.604 | nll_loss 0.57 | ppl 1.48 | wps 22174.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37865 | lr 0.00016251 | gnorm 0.759 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 112011
2022-03-07 19:58:19 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 19:58:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:59 | INFO | train_inner | epoch 394:     35 / 97 loss=1.603, nll_loss=0.57, ppl=1.48, wps=22207.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=37900, lr=0.000162435, gnorm=0.764, loss_scale=16, train_wall=265, gb_free=8.1, wall=112111
2022-03-07 20:02:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:03:00 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.452 | nll_loss 13.01 | ppl 8249.77 | wps 42992.3 | wpb 510.9 | bsz 1 | num_updates 37962 | best_loss 7.981
2022-03-07 20:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 37962 updates
2022-03-07 20:03:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:03:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:03:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 394 @ 37962 updates, score 13.452) (writing took 2.2585243908688426 seconds)
2022-03-07 20:03:03 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 20:03:03 | INFO | train | epoch 394 | loss 1.603 | nll_loss 0.57 | ppl 1.48 | wps 22399 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37962 | lr 0.000162303 | gnorm 0.762 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 112295
2022-03-07 20:03:03 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 20:03:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:03:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:04:54 | INFO | train_inner | epoch 395:     39 / 97 loss=1.603, nll_loss=0.569, ppl=1.48, wps=22193.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38000, lr=0.000162221, gnorm=0.758, loss_scale=16, train_wall=265, gb_free=8.1, wall=112406
2022-03-07 20:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:07:44 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 13.44 | nll_loss 12.999 | ppl 8183.72 | wps 42656.6 | wpb 510.9 | bsz 1 | num_updates 38058 | best_loss 7.981
2022-03-07 20:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 38058 updates
2022-03-07 20:07:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:07:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:07:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 395 @ 38058 updates, score 13.44) (writing took 2.135587580036372 seconds)
2022-03-07 20:07:47 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 20:07:47 | INFO | train | epoch 395 | loss 1.602 | nll_loss 0.568 | ppl 1.48 | wps 22145.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38058 | lr 0.000162098 | gnorm 0.764 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 112578
2022-03-07 20:07:47 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 20:07:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:09:46 | INFO | train_inner | epoch 396:     42 / 97 loss=1.601, nll_loss=0.567, ppl=1.48, wps=22387.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38100, lr=0.000162008, gnorm=0.763, loss_scale=16, train_wall=262, gb_free=8.1, wall=112698
2022-03-07 20:12:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:12:29 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 13.448 | nll_loss 13.006 | ppl 8225.71 | wps 42697.3 | wpb 510.9 | bsz 1 | num_updates 38154 | best_loss 7.981
2022-03-07 20:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 38154 updates
2022-03-07 20:12:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:12:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:12:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 396 @ 38154 updates, score 13.448) (writing took 2.225743376649916 seconds)
2022-03-07 20:12:31 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 20:12:31 | INFO | train | epoch 396 | loss 1.601 | nll_loss 0.567 | ppl 1.48 | wps 22122.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38154 | lr 0.000161894 | gnorm 0.755 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 112863
2022-03-07 20:12:31 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 20:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:14:42 | INFO | train_inner | epoch 397:     46 / 97 loss=1.603, nll_loss=0.57, ppl=1.48, wps=22153.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=38200, lr=0.000161796, gnorm=0.761, loss_scale=16, train_wall=265, gb_free=8.1, wall=112994
2022-03-07 20:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:17:13 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.43 | nll_loss 12.988 | ppl 8122.21 | wps 42885.7 | wpb 510.9 | bsz 1 | num_updates 38251 | best_loss 7.981
2022-03-07 20:17:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 38251 updates
2022-03-07 20:17:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:17:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:17:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 397 @ 38251 updates, score 13.43) (writing took 2.2791373590007424 seconds)
2022-03-07 20:17:15 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 20:17:15 | INFO | train | epoch 397 | loss 1.601 | nll_loss 0.568 | ppl 1.48 | wps 22357.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38251 | lr 0.000161688 | gnorm 0.759 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 113147
2022-03-07 20:17:15 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 20:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:18:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:19:38 | INFO | train_inner | epoch 398:     50 / 97 loss=1.599, nll_loss=0.565, ppl=1.48, wps=22150.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38300, lr=0.000161585, gnorm=0.75, loss_scale=16, train_wall=265, gb_free=8.1, wall=113290
2022-03-07 20:21:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:21:57 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.492 | nll_loss 13.052 | ppl 8494.65 | wps 43062.6 | wpb 510.9 | bsz 1 | num_updates 38347 | best_loss 7.981
2022-03-07 20:21:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 38347 updates
2022-03-07 20:21:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:21:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 398 @ 38347 updates, score 13.492) (writing took 2.2728430703282356 seconds)
2022-03-07 20:21:59 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 20:21:59 | INFO | train | epoch 398 | loss 1.6 | nll_loss 0.566 | ppl 1.48 | wps 22095 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38347 | lr 0.000161486 | gnorm 0.746 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 113431
2022-03-07 20:22:00 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 20:22:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:24:31 | INFO | train_inner | epoch 399:     53 / 97 loss=1.6, nll_loss=0.566, ppl=1.48, wps=22326.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=38400, lr=0.000161374, gnorm=0.751, loss_scale=16, train_wall=263, gb_free=8.1, wall=113583
2022-03-07 20:25:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:26:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:26:42 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 13.443 | nll_loss 12.997 | ppl 8176.38 | wps 42845.1 | wpb 510.9 | bsz 1 | num_updates 38443 | best_loss 7.981
2022-03-07 20:26:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 38443 updates
2022-03-07 20:26:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:26:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:26:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 399 @ 38443 updates, score 13.443) (writing took 2.325239719823003 seconds)
2022-03-07 20:26:44 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 20:26:44 | INFO | train | epoch 399 | loss 1.598 | nll_loss 0.565 | ppl 1.48 | wps 22076.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38443 | lr 0.000161284 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 113716
2022-03-07 20:26:44 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 20:26:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:27 | INFO | train_inner | epoch 400:     57 / 97 loss=1.598, nll_loss=0.565, ppl=1.48, wps=22114.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38500, lr=0.000161165, gnorm=0.752, loss_scale=16, train_wall=266, gb_free=8.1, wall=113879
2022-03-07 20:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:31:26 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.464 | nll_loss 13.023 | ppl 8320.9 | wps 43340.8 | wpb 510.9 | bsz 1 | num_updates 38540 | best_loss 7.981
2022-03-07 20:31:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 38540 updates
2022-03-07 20:31:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:31:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 400 @ 38540 updates, score 13.464) (writing took 2.2928375876508653 seconds)
2022-03-07 20:31:29 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 20:31:29 | INFO | train | epoch 400 | loss 1.598 | nll_loss 0.565 | ppl 1.48 | wps 22326.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38540 | lr 0.000161081 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 114001
2022-03-07 20:31:29 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 20:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:34:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:34:23 | INFO | train_inner | epoch 401:     61 / 97 loss=1.598, nll_loss=0.565, ppl=1.48, wps=22129, ups=0.34, wpb=65495, bsz=127.9, num_updates=38600, lr=0.000160956, gnorm=0.755, loss_scale=16, train_wall=265, gb_free=8.1, wall=114175
2022-03-07 20:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:36:11 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 13.432 | nll_loss 12.987 | ppl 8118.01 | wps 42765.3 | wpb 510.9 | bsz 1 | num_updates 38636 | best_loss 7.981
2022-03-07 20:36:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 38636 updates
2022-03-07 20:36:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:36:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 401 @ 38636 updates, score 13.432) (writing took 2.2864987878128886 seconds)
2022-03-07 20:36:13 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 20:36:13 | INFO | train | epoch 401 | loss 1.598 | nll_loss 0.564 | ppl 1.48 | wps 22090.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38636 | lr 0.000160881 | gnorm 0.755 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 114285
2022-03-07 20:36:13 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 20:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:39:17 | INFO | train_inner | epoch 402:     64 / 97 loss=1.596, nll_loss=0.563, ppl=1.48, wps=22325.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38700, lr=0.000160748, gnorm=0.758, loss_scale=16, train_wall=263, gb_free=8.1, wall=114469
2022-03-07 20:40:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:40:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:40:56 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.405 | nll_loss 12.964 | ppl 7988.94 | wps 42738 | wpb 510.9 | bsz 1 | num_updates 38732 | best_loss 7.981
2022-03-07 20:40:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 38732 updates
2022-03-07 20:40:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:40:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:40:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 402 @ 38732 updates, score 13.405) (writing took 2.2875004578381777 seconds)
2022-03-07 20:40:58 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 20:40:58 | INFO | train | epoch 402 | loss 1.596 | nll_loss 0.563 | ppl 1.48 | wps 22076.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38732 | lr 0.000160681 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 114570
2022-03-07 20:40:58 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 20:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:44:13 | INFO | train_inner | epoch 403:     68 / 97 loss=1.596, nll_loss=0.563, ppl=1.48, wps=22121.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38800, lr=0.00016054, gnorm=0.757, loss_scale=16, train_wall=266, gb_free=8.1, wall=114765
2022-03-07 20:45:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:45:41 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 13.462 | nll_loss 13.024 | ppl 8331.1 | wps 42710.1 | wpb 510.9 | bsz 1 | num_updates 38829 | best_loss 7.981
2022-03-07 20:45:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 38829 updates
2022-03-07 20:45:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:45:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:45:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 403 @ 38829 updates, score 13.462) (writing took 2.316395156085491 seconds)
2022-03-07 20:45:43 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 20:45:43 | INFO | train | epoch 403 | loss 1.597 | nll_loss 0.563 | ppl 1.48 | wps 22317.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38829 | lr 0.00016048 | gnorm 0.756 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 114855
2022-03-07 20:45:43 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 20:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:47:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:49:09 | INFO | train_inner | epoch 404:     72 / 97 loss=1.596, nll_loss=0.562, ppl=1.48, wps=22116.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38900, lr=0.000160334, gnorm=0.75, loss_scale=16, train_wall=266, gb_free=8.1, wall=115061
2022-03-07 20:50:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:50:25 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.449 | nll_loss 13.006 | ppl 8228.98 | wps 43075 | wpb 510.9 | bsz 1 | num_updates 38925 | best_loss 7.981
2022-03-07 20:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 38925 updates
2022-03-07 20:50:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:50:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 404 @ 38925 updates, score 13.449) (writing took 2.377812454942614 seconds)
2022-03-07 20:50:28 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 20:50:28 | INFO | train | epoch 404 | loss 1.595 | nll_loss 0.561 | ppl 1.48 | wps 22078.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38925 | lr 0.000160282 | gnorm 0.752 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 115140
2022-03-07 20:50:28 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 20:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:54:02 | INFO | train_inner | epoch 405:     75 / 97 loss=1.596, nll_loss=0.562, ppl=1.48, wps=22329.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39000, lr=0.000160128, gnorm=0.762, loss_scale=32, train_wall=263, gb_free=8.1, wall=115354
2022-03-07 20:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:55:10 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 13.477 | nll_loss 13.039 | ppl 8416.1 | wps 42752.4 | wpb 510.9 | bsz 1 | num_updates 39022 | best_loss 7.981
2022-03-07 20:55:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 39022 updates
2022-03-07 20:55:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:55:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:55:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 405 @ 39022 updates, score 13.477) (writing took 2.25005142390728 seconds)
2022-03-07 20:55:12 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 20:55:12 | INFO | train | epoch 405 | loss 1.595 | nll_loss 0.561 | ppl 1.48 | wps 22320.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39022 | lr 0.000160083 | gnorm 0.758 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 115424
2022-03-07 20:55:12 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 20:55:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:57:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:58:58 | INFO | train_inner | epoch 406:     79 / 97 loss=1.593, nll_loss=0.56, ppl=1.47, wps=22120.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39100, lr=0.000159923, gnorm=0.745, loss_scale=16, train_wall=266, gb_free=8.1, wall=115650
2022-03-07 20:59:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:59:55 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.544 | nll_loss 13.108 | ppl 8829.72 | wps 42775.6 | wpb 510.9 | bsz 1 | num_updates 39118 | best_loss 7.981
2022-03-07 20:59:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 39118 updates
2022-03-07 20:59:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:59:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:59:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 406 @ 39118 updates, score 13.544) (writing took 2.2645892021246254 seconds)
2022-03-07 20:59:57 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 20:59:57 | INFO | train | epoch 406 | loss 1.593 | nll_loss 0.56 | ppl 1.47 | wps 22088.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39118 | lr 0.000159886 | gnorm 0.744 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 115709
2022-03-07 20:59:57 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 20:59:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:03:52 | INFO | train_inner | epoch 407:     82 / 97 loss=1.594, nll_loss=0.56, ppl=1.47, wps=22326.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39200, lr=0.000159719, gnorm=0.752, loss_scale=32, train_wall=263, gb_free=8.1, wall=115943
2022-03-07 21:04:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:04:39 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.473 | nll_loss 13.031 | ppl 8367.44 | wps 43370.7 | wpb 510.9 | bsz 1 | num_updates 39215 | best_loss 7.981
2022-03-07 21:04:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 39215 updates
2022-03-07 21:04:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:04:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:04:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 407 @ 39215 updates, score 13.473) (writing took 2.3628743798471987 seconds)
2022-03-07 21:04:42 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 21:04:42 | INFO | train | epoch 407 | loss 1.593 | nll_loss 0.559 | ppl 1.47 | wps 22304.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39215 | lr 0.000159689 | gnorm 0.75 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 115994
2022-03-07 21:04:42 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 21:04:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:06:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:08:48 | INFO | train_inner | epoch 408:     86 / 97 loss=1.593, nll_loss=0.559, ppl=1.47, wps=22117.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=39300, lr=0.000159516, gnorm=0.757, loss_scale=16, train_wall=266, gb_free=8.1, wall=116240
2022-03-07 21:09:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:09:24 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 13.435 | nll_loss 12.994 | ppl 8156.22 | wps 42954.7 | wpb 510.9 | bsz 1 | num_updates 39311 | best_loss 7.981
2022-03-07 21:09:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 39311 updates
2022-03-07 21:09:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:09:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:09:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 408 @ 39311 updates, score 13.435) (writing took 2.2630695831030607 seconds)
2022-03-07 21:09:26 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 21:09:26 | INFO | train | epoch 408 | loss 1.592 | nll_loss 0.559 | ppl 1.47 | wps 22090.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39311 | lr 0.000159493 | gnorm 0.759 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 116278
2022-03-07 21:09:26 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 21:09:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:13:41 | INFO | train_inner | epoch 409:     89 / 97 loss=1.592, nll_loss=0.558, ppl=1.47, wps=22329.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=39400, lr=0.000159313, gnorm=0.75, loss_scale=32, train_wall=263, gb_free=8.1, wall=116533
2022-03-07 21:14:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:14:09 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.444 | nll_loss 13.005 | ppl 8222.79 | wps 43007.9 | wpb 510.9 | bsz 1 | num_updates 39408 | best_loss 7.981
2022-03-07 21:14:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 39408 updates
2022-03-07 21:14:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:14:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:14:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 409 @ 39408 updates, score 13.444) (writing took 2.400233021005988 seconds)
2022-03-07 21:14:11 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 21:14:11 | INFO | train | epoch 409 | loss 1.591 | nll_loss 0.558 | ppl 1.47 | wps 22299.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39408 | lr 0.000159297 | gnorm 0.75 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 116563
2022-03-07 21:14:11 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 21:14:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:14:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:18:37 | INFO | train_inner | epoch 410:     93 / 97 loss=1.592, nll_loss=0.559, ppl=1.47, wps=22110.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39500, lr=0.000159111, gnorm=0.754, loss_scale=16, train_wall=266, gb_free=8.1, wall=116829
2022-03-07 21:18:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:18:53 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 13.493 | nll_loss 13.052 | ppl 8490.04 | wps 43107.8 | wpb 510.9 | bsz 1 | num_updates 39504 | best_loss 7.981
2022-03-07 21:18:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 39504 updates
2022-03-07 21:18:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:18:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:18:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 410 @ 39504 updates, score 13.493) (writing took 2.3602073062211275 seconds)
2022-03-07 21:18:56 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 21:18:56 | INFO | train | epoch 410 | loss 1.591 | nll_loss 0.558 | ppl 1.47 | wps 22083.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39504 | lr 0.000159103 | gnorm 0.752 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 116848
2022-03-07 21:18:56 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 21:18:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:23:31 | INFO | train_inner | epoch 411:     96 / 97 loss=1.59, nll_loss=0.556, ppl=1.47, wps=22311.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39600, lr=0.00015891, gnorm=0.754, loss_scale=32, train_wall=263, gb_free=8.1, wall=117123
2022-03-07 21:23:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:23:38 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.462 | nll_loss 13.022 | ppl 8318.8 | wps 42729.3 | wpb 510.9 | bsz 1 | num_updates 39601 | best_loss 7.981
2022-03-07 21:23:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 39601 updates
2022-03-07 21:23:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:23:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:23:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 411 @ 39601 updates, score 13.462) (writing took 2.286633206065744 seconds)
2022-03-07 21:23:41 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 21:23:41 | INFO | train | epoch 411 | loss 1.589 | nll_loss 0.556 | ppl 1.47 | wps 22295.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39601 | lr 0.000158908 | gnorm 0.754 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 117133
2022-03-07 21:23:41 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 21:23:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:24:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:28:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:28:23 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.512 | nll_loss 13.074 | ppl 8623.39 | wps 42940.6 | wpb 510.9 | bsz 1 | num_updates 39697 | best_loss 7.981
2022-03-07 21:28:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 39697 updates
2022-03-07 21:28:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:28:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:28:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 412 @ 39697 updates, score 13.512) (writing took 2.306723569985479 seconds)
2022-03-07 21:28:25 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 21:28:25 | INFO | train | epoch 412 | loss 1.588 | nll_loss 0.555 | ppl 1.47 | wps 22096.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39697 | lr 0.000158716 | gnorm 0.749 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 117417
2022-03-07 21:28:25 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 21:28:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:28:34 | INFO | train_inner | epoch 413:      3 / 97 loss=1.587, nll_loss=0.554, ppl=1.47, wps=21579.5, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=39700, lr=0.00015871, gnorm=0.748, loss_scale=16, train_wall=265, gb_free=8.1, wall=117426
2022-03-07 21:31:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:33:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:33:08 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 13.454 | nll_loss 13.015 | ppl 8277.76 | wps 43129.5 | wpb 510.9 | bsz 1 | num_updates 39793 | best_loss 7.981
2022-03-07 21:33:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 39793 updates
2022-03-07 21:33:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:33:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:33:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 413 @ 39793 updates, score 13.454) (writing took 2.2605332070961595 seconds)
2022-03-07 21:33:10 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 21:33:10 | INFO | train | epoch 413 | loss 1.588 | nll_loss 0.555 | ppl 1.47 | wps 22082.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39793 | lr 0.000158525 | gnorm 0.751 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 117702
2022-03-07 21:33:10 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 21:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:33:30 | INFO | train_inner | epoch 414:      7 / 97 loss=1.588, nll_loss=0.555, ppl=1.47, wps=22114.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39800, lr=0.000158511, gnorm=0.75, loss_scale=16, train_wall=266, gb_free=8.1, wall=117722
2022-03-07 21:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:37:53 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.477 | nll_loss 13.039 | ppl 8415.38 | wps 42989.8 | wpb 510.9 | bsz 1 | num_updates 39890 | best_loss 7.981
2022-03-07 21:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 39890 updates
2022-03-07 21:37:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 414 @ 39890 updates, score 13.477) (writing took 2.3295564390718937 seconds)
2022-03-07 21:37:55 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 21:37:55 | INFO | train | epoch 414 | loss 1.587 | nll_loss 0.554 | ppl 1.47 | wps 22291.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39890 | lr 0.000158332 | gnorm 0.741 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 117987
2022-03-07 21:37:55 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 21:37:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:38:24 | INFO | train_inner | epoch 415:     10 / 97 loss=1.587, nll_loss=0.553, ppl=1.47, wps=22311.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39900, lr=0.000158312, gnorm=0.741, loss_scale=32, train_wall=263, gb_free=8.1, wall=118016
2022-03-07 21:40:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:42:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:42:38 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.491 | nll_loss 13.051 | ppl 8489.46 | wps 42738.4 | wpb 510.9 | bsz 1 | num_updates 39986 | best_loss 7.981
2022-03-07 21:42:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 39986 updates
2022-03-07 21:42:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:42:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:42:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 415 @ 39986 updates, score 13.491) (writing took 2.286162932869047 seconds)
2022-03-07 21:42:40 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 21:42:40 | INFO | train | epoch 415 | loss 1.587 | nll_loss 0.554 | ppl 1.47 | wps 22075.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39986 | lr 0.000158142 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 118272
2022-03-07 21:42:40 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 21:42:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:43:20 | INFO | train_inner | epoch 416:     14 / 97 loss=1.586, nll_loss=0.553, ppl=1.47, wps=22105.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40000, lr=0.000158114, gnorm=0.753, loss_scale=16, train_wall=266, gb_free=8.1, wall=118312
2022-03-07 21:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:47:22 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.461 | nll_loss 13.023 | ppl 8320.77 | wps 42887 | wpb 510.9 | bsz 1 | num_updates 40083 | best_loss 7.981
2022-03-07 21:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 40083 updates
2022-03-07 21:47:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:47:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 416 @ 40083 updates, score 13.461) (writing took 2.3453948949463665 seconds)
2022-03-07 21:47:25 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 21:47:25 | INFO | train | epoch 416 | loss 1.585 | nll_loss 0.552 | ppl 1.47 | wps 22296.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40083 | lr 0.00015795 | gnorm 0.743 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 118557
2022-03-07 21:47:25 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 21:47:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:13 | INFO | train_inner | epoch 417:     17 / 97 loss=1.584, nll_loss=0.551, ppl=1.47, wps=22317.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=40100, lr=0.000157917, gnorm=0.745, loss_scale=32, train_wall=263, gb_free=8.1, wall=118605
2022-03-07 21:49:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:52:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:52:07 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.508 | nll_loss 13.072 | ppl 8612.37 | wps 42589.1 | wpb 510.9 | bsz 1 | num_updates 40179 | best_loss 7.981
2022-03-07 21:52:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 40179 updates
2022-03-07 21:52:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:52:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:52:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 417 @ 40179 updates, score 13.508) (writing took 2.310708952601999 seconds)
2022-03-07 21:52:10 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 21:52:10 | INFO | train | epoch 417 | loss 1.585 | nll_loss 0.552 | ppl 1.47 | wps 22077.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40179 | lr 0.000157761 | gnorm 0.753 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 118841
2022-03-07 21:52:10 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 21:52:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:53:10 | INFO | train_inner | epoch 418:     21 / 97 loss=1.584, nll_loss=0.552, ppl=1.47, wps=22106.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40200, lr=0.00015772, gnorm=0.748, loss_scale=16, train_wall=266, gb_free=8.1, wall=118902
2022-03-07 21:55:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:56:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:56:52 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.519 | nll_loss 13.082 | ppl 8672.39 | wps 42910.7 | wpb 510.9 | bsz 1 | num_updates 40275 | best_loss 7.981
2022-03-07 21:56:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 40275 updates
2022-03-07 21:56:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:56:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:56:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 418 @ 40275 updates, score 13.519) (writing took 2.3501926828175783 seconds)
2022-03-07 21:56:54 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 21:56:54 | INFO | train | epoch 418 | loss 1.584 | nll_loss 0.552 | ppl 1.47 | wps 22066.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40275 | lr 0.000157573 | gnorm 0.731 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 119126
2022-03-07 21:56:54 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 21:56:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:58:06 | INFO | train_inner | epoch 419:     25 / 97 loss=1.584, nll_loss=0.551, ppl=1.46, wps=22103.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=40300, lr=0.000157524, gnorm=0.734, loss_scale=16, train_wall=266, gb_free=8.1, wall=119198
2022-03-07 22:01:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:01:37 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.454 | nll_loss 13.013 | ppl 8263.89 | wps 42993.1 | wpb 510.9 | bsz 1 | num_updates 40372 | best_loss 7.981
2022-03-07 22:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 40372 updates
2022-03-07 22:01:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:01:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:01:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 419 @ 40372 updates, score 13.454) (writing took 2.2992487200535834 seconds)
2022-03-07 22:01:39 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 22:01:39 | INFO | train | epoch 419 | loss 1.584 | nll_loss 0.552 | ppl 1.47 | wps 22302 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40372 | lr 0.000157384 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 119411
2022-03-07 22:01:39 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 22:01:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:03:00 | INFO | train_inner | epoch 420:     28 / 97 loss=1.583, nll_loss=0.55, ppl=1.46, wps=22309.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=40400, lr=0.000157329, gnorm=0.752, loss_scale=32, train_wall=263, gb_free=8.1, wall=119491
2022-03-07 22:03:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:06:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:06:22 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.484 | nll_loss 13.044 | ppl 8448.24 | wps 43009.8 | wpb 510.9 | bsz 1 | num_updates 40468 | best_loss 7.981
2022-03-07 22:06:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 40468 updates
2022-03-07 22:06:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:06:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:06:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 420 @ 40468 updates, score 13.484) (writing took 2.2781462213024497 seconds)
2022-03-07 22:06:24 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 22:06:24 | INFO | train | epoch 420 | loss 1.583 | nll_loss 0.55 | ppl 1.46 | wps 22073.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40468 | lr 0.000157197 | gnorm 0.75 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 119696
2022-03-07 22:06:24 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 22:06:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:07:56 | INFO | train_inner | epoch 421:     32 / 97 loss=1.583, nll_loss=0.55, ppl=1.46, wps=22108.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40500, lr=0.000157135, gnorm=0.748, loss_scale=16, train_wall=266, gb_free=8.1, wall=119788
2022-03-07 22:11:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:11:07 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.527 | nll_loss 13.089 | ppl 8711.79 | wps 42763.6 | wpb 510.9 | bsz 1 | num_updates 40565 | best_loss 7.981
2022-03-07 22:11:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 40565 updates
2022-03-07 22:11:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:11:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:11:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 421 @ 40565 updates, score 13.527) (writing took 2.312787444330752 seconds)
2022-03-07 22:11:09 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 22:11:09 | INFO | train | epoch 421 | loss 1.583 | nll_loss 0.55 | ppl 1.46 | wps 22293.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40565 | lr 0.000157009 | gnorm 0.749 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 119981
2022-03-07 22:11:09 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 22:11:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:11:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:12:52 | INFO | train_inner | epoch 422:     36 / 97 loss=1.583, nll_loss=0.55, ppl=1.46, wps=22099.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=40600, lr=0.000156941, gnorm=0.748, loss_scale=16, train_wall=266, gb_free=8.1, wall=120084
2022-03-07 22:15:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:15:52 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.485 | nll_loss 13.049 | ppl 8473.25 | wps 42755.2 | wpb 510.9 | bsz 1 | num_updates 40661 | best_loss 7.981
2022-03-07 22:15:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 40661 updates
2022-03-07 22:15:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:15:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:15:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 422 @ 40661 updates, score 13.485) (writing took 2.284116982948035 seconds)
2022-03-07 22:15:54 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 22:15:54 | INFO | train | epoch 422 | loss 1.58 | nll_loss 0.547 | ppl 1.46 | wps 22063.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40661 | lr 0.000156823 | gnorm 0.738 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 120266
2022-03-07 22:15:54 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 22:15:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:17:46 | INFO | train_inner | epoch 423:     39 / 97 loss=1.58, nll_loss=0.547, ppl=1.46, wps=22313.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=40700, lr=0.000156748, gnorm=0.741, loss_scale=32, train_wall=263, gb_free=8.1, wall=120378
2022-03-07 22:20:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:20:36 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.456 | nll_loss 13.017 | ppl 8289.25 | wps 42915.7 | wpb 510.9 | bsz 1 | num_updates 40758 | best_loss 7.981
2022-03-07 22:20:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 40758 updates
2022-03-07 22:20:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:20:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:20:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 423 @ 40758 updates, score 13.456) (writing took 2.289345839060843 seconds)
2022-03-07 22:20:39 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 22:20:39 | INFO | train | epoch 423 | loss 1.581 | nll_loss 0.548 | ppl 1.46 | wps 22309.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40758 | lr 0.000156637 | gnorm 0.75 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 120551
2022-03-07 22:20:39 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 22:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:22:39 | INFO | train_inner | epoch 424:     42 / 97 loss=1.581, nll_loss=0.548, ppl=1.46, wps=22326, ups=0.34, wpb=65495, bsz=127.9, num_updates=40800, lr=0.000156556, gnorm=0.751, loss_scale=32, train_wall=263, gb_free=8.1, wall=120671
2022-03-07 22:23:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:25:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:25:21 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.443 | nll_loss 13.001 | ppl 8197.25 | wps 42948 | wpb 510.9 | bsz 1 | num_updates 40853 | best_loss 7.981
2022-03-07 22:25:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 40853 updates
2022-03-07 22:25:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:25:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 424 @ 40853 updates, score 13.443) (writing took 2.3936557108536363 seconds)
2022-03-07 22:25:24 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 22:25:24 | INFO | train | epoch 424 | loss 1.579 | nll_loss 0.547 | ppl 1.46 | wps 21839.2 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 40853 | lr 0.000156454 | gnorm 0.741 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 120836
2022-03-07 22:25:24 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 22:25:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:27:38 | INFO | train_inner | epoch 425:     47 / 97 loss=1.579, nll_loss=0.547, ppl=1.46, wps=21889.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=40900, lr=0.000156365, gnorm=0.739, loss_scale=16, train_wall=268, gb_free=8.1, wall=120970
2022-03-07 22:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:30:06 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.477 | nll_loss 13.039 | ppl 8415.12 | wps 43021.3 | wpb 510.9 | bsz 1 | num_updates 40950 | best_loss 7.981
2022-03-07 22:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 40950 updates
2022-03-07 22:30:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:30:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 425 @ 40950 updates, score 13.477) (writing took 2.2627870799042284 seconds)
2022-03-07 22:30:08 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 22:30:08 | INFO | train | epoch 425 | loss 1.58 | nll_loss 0.547 | ppl 1.46 | wps 22304.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40950 | lr 0.000156269 | gnorm 0.746 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 121120
2022-03-07 22:30:08 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 22:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:32:32 | INFO | train_inner | epoch 426:     50 / 97 loss=1.578, nll_loss=0.546, ppl=1.46, wps=22315.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41000, lr=0.000156174, gnorm=0.743, loss_scale=32, train_wall=263, gb_free=8.1, wall=121264
2022-03-07 22:34:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:34:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:34:51 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.501 | nll_loss 13.064 | ppl 8562.88 | wps 42940.7 | wpb 510.9 | bsz 1 | num_updates 41046 | best_loss 7.981
2022-03-07 22:34:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 41046 updates
2022-03-07 22:34:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:34:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:34:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 426 @ 41046 updates, score 13.501) (writing took 2.340088321827352 seconds)
2022-03-07 22:34:53 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 22:34:53 | INFO | train | epoch 426 | loss 1.578 | nll_loss 0.546 | ppl 1.46 | wps 22057.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41046 | lr 0.000156086 | gnorm 0.741 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 121405
2022-03-07 22:34:54 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 22:34:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:37:28 | INFO | train_inner | epoch 427:     54 / 97 loss=1.578, nll_loss=0.546, ppl=1.46, wps=22103.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41100, lr=0.000155984, gnorm=0.743, loss_scale=16, train_wall=266, gb_free=8.1, wall=121560
2022-03-07 22:39:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:39:36 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.489 | nll_loss 13.053 | ppl 8495.93 | wps 42909.9 | wpb 510.9 | bsz 1 | num_updates 41143 | best_loss 7.981
2022-03-07 22:39:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 41143 updates
2022-03-07 22:39:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:39:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:39:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 427 @ 41143 updates, score 13.489) (writing took 2.315461440011859 seconds)
2022-03-07 22:39:38 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 22:39:38 | INFO | train | epoch 427 | loss 1.578 | nll_loss 0.545 | ppl 1.46 | wps 22304.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41143 | lr 0.000155902 | gnorm 0.747 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 121690
2022-03-07 22:39:38 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 22:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:42:21 | INFO | train_inner | epoch 428:     57 / 97 loss=1.578, nll_loss=0.545, ppl=1.46, wps=22314.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41200, lr=0.000155794, gnorm=0.744, loss_scale=32, train_wall=263, gb_free=8.1, wall=121853
2022-03-07 22:43:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:44:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:44:21 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.529 | nll_loss 13.094 | ppl 8744.38 | wps 43048.5 | wpb 510.9 | bsz 1 | num_updates 41239 | best_loss 7.981
2022-03-07 22:44:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 41239 updates
2022-03-07 22:44:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:44:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:44:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 428 @ 41239 updates, score 13.529) (writing took 2.2971755587495863 seconds)
2022-03-07 22:44:23 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 22:44:23 | INFO | train | epoch 428 | loss 1.577 | nll_loss 0.545 | ppl 1.46 | wps 22069.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41239 | lr 0.000155721 | gnorm 0.742 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 121975
2022-03-07 22:44:23 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 22:44:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:47:18 | INFO | train_inner | epoch 429:     61 / 97 loss=1.578, nll_loss=0.545, ppl=1.46, wps=22095.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41300, lr=0.000155606, gnorm=0.745, loss_scale=16, train_wall=266, gb_free=8.1, wall=122150
2022-03-07 22:49:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:49:06 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 13.486 | nll_loss 13.049 | ppl 8475.7 | wps 42778.5 | wpb 510.9 | bsz 1 | num_updates 41336 | best_loss 7.981
2022-03-07 22:49:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 41336 updates
2022-03-07 22:49:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:49:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:49:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 429 @ 41336 updates, score 13.486) (writing took 2.2818272239528596 seconds)
2022-03-07 22:49:08 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 22:49:08 | INFO | train | epoch 429 | loss 1.578 | nll_loss 0.545 | ppl 1.46 | wps 22294.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41336 | lr 0.000155538 | gnorm 0.741 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 122260
2022-03-07 22:49:08 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 22:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:52:11 | INFO | train_inner | epoch 430:     64 / 97 loss=1.576, nll_loss=0.544, ppl=1.46, wps=22319.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41400, lr=0.000155417, gnorm=0.744, loss_scale=32, train_wall=263, gb_free=8.1, wall=122443
2022-03-07 22:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:53:51 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.513 | nll_loss 13.078 | ppl 8646.28 | wps 42990.6 | wpb 510.9 | bsz 1 | num_updates 41433 | best_loss 7.981
2022-03-07 22:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 41433 updates
2022-03-07 22:53:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:53:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:53:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 430 @ 41433 updates, score 13.513) (writing took 2.363258687313646 seconds)
2022-03-07 22:53:53 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 22:53:53 | INFO | train | epoch 430 | loss 1.576 | nll_loss 0.544 | ppl 1.46 | wps 22297.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41433 | lr 0.000155356 | gnorm 0.748 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 122545
2022-03-07 22:53:53 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 22:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:54:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:57:08 | INFO | train_inner | epoch 431:     68 / 97 loss=1.576, nll_loss=0.544, ppl=1.46, wps=22096.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=41500, lr=0.00015523, gnorm=0.746, loss_scale=16, train_wall=266, gb_free=8.1, wall=122740
2022-03-07 22:58:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:58:36 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.44 | nll_loss 12.999 | ppl 8187.73 | wps 42782.9 | wpb 510.9 | bsz 1 | num_updates 41529 | best_loss 7.981
2022-03-07 22:58:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 41529 updates
2022-03-07 22:58:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:58:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:58:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 431 @ 41529 updates, score 13.44) (writing took 2.3006212078034878 seconds)
2022-03-07 22:58:38 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 22:58:38 | INFO | train | epoch 431 | loss 1.574 | nll_loss 0.542 | ppl 1.46 | wps 22065.2 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 41529 | lr 0.000155176 | gnorm 0.741 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 122830
2022-03-07 22:58:38 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 22:58:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:01:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:02:04 | INFO | train_inner | epoch 432:     72 / 97 loss=1.574, nll_loss=0.542, ppl=1.46, wps=22095.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=41600, lr=0.000155043, gnorm=0.732, loss_scale=16, train_wall=266, gb_free=8.1, wall=123036
2022-03-07 23:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:03:21 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.489 | nll_loss 13.052 | ppl 8495.47 | wps 42711.5 | wpb 510.9 | bsz 1 | num_updates 41625 | best_loss 7.981
2022-03-07 23:03:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 41625 updates
2022-03-07 23:03:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:03:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:03:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 432 @ 41625 updates, score 13.489) (writing took 2.2656912598758936 seconds)
2022-03-07 23:03:23 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 23:03:23 | INFO | train | epoch 432 | loss 1.574 | nll_loss 0.542 | ppl 1.46 | wps 22061.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41625 | lr 0.000154997 | gnorm 0.736 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 123115
2022-03-07 23:03:23 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 23:03:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:06:58 | INFO | train_inner | epoch 433:     75 / 97 loss=1.574, nll_loss=0.542, ppl=1.46, wps=22296.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41700, lr=0.000154857, gnorm=0.746, loss_scale=16, train_wall=263, gb_free=8.1, wall=123330
2022-03-07 23:08:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:08:06 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.471 | nll_loss 13.032 | ppl 8375.22 | wps 42934.5 | wpb 510.9 | bsz 1 | num_updates 41722 | best_loss 7.981
2022-03-07 23:08:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 41722 updates
2022-03-07 23:08:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:08:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 433 @ 41722 updates, score 13.471) (writing took 2.2650575120933354 seconds)
2022-03-07 23:08:08 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 23:08:08 | INFO | train | epoch 433 | loss 1.574 | nll_loss 0.542 | ppl 1.46 | wps 22281.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41722 | lr 0.000154817 | gnorm 0.749 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 123400
2022-03-07 23:08:08 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 23:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:10:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:11:54 | INFO | train_inner | epoch 434:     79 / 97 loss=1.574, nll_loss=0.542, ppl=1.46, wps=22099.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41800, lr=0.000154672, gnorm=0.744, loss_scale=16, train_wall=266, gb_free=8.1, wall=123626
2022-03-07 23:12:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:12:51 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.465 | nll_loss 13.029 | ppl 8356.57 | wps 43038.3 | wpb 510.9 | bsz 1 | num_updates 41818 | best_loss 7.981
2022-03-07 23:12:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 41818 updates
2022-03-07 23:12:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:12:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:12:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 434 @ 41818 updates, score 13.465) (writing took 2.197831830009818 seconds)
2022-03-07 23:12:53 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 23:12:53 | INFO | train | epoch 434 | loss 1.573 | nll_loss 0.54 | ppl 1.45 | wps 22071.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41818 | lr 0.000154639 | gnorm 0.737 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 123685
2022-03-07 23:12:53 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 23:12:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:16:48 | INFO | train_inner | epoch 435:     82 / 97 loss=1.573, nll_loss=0.541, ppl=1.45, wps=22326.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41900, lr=0.000154487, gnorm=0.739, loss_scale=32, train_wall=263, gb_free=8.1, wall=123919
2022-03-07 23:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:17:35 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.447 | nll_loss 13.011 | ppl 8251.94 | wps 42913.8 | wpb 510.9 | bsz 1 | num_updates 41915 | best_loss 7.981
2022-03-07 23:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 41915 updates
2022-03-07 23:17:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:17:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:17:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 435 @ 41915 updates, score 13.447) (writing took 2.2377262669615448 seconds)
2022-03-07 23:17:38 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 23:17:38 | INFO | train | epoch 435 | loss 1.573 | nll_loss 0.541 | ppl 1.45 | wps 22311.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41915 | lr 0.00015446 | gnorm 0.74 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 123970
2022-03-07 23:17:38 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 23:17:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:18:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:21:44 | INFO | train_inner | epoch 436:     86 / 97 loss=1.572, nll_loss=0.54, ppl=1.45, wps=22103.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42000, lr=0.000154303, gnorm=0.735, loss_scale=16, train_wall=266, gb_free=8.1, wall=124216
2022-03-07 23:22:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:22:20 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.477 | nll_loss 13.042 | ppl 8431.28 | wps 43358.1 | wpb 510.9 | bsz 1 | num_updates 42011 | best_loss 7.981
2022-03-07 23:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 42011 updates
2022-03-07 23:22:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:22:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:22:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 436 @ 42011 updates, score 13.477) (writing took 2.301645761821419 seconds)
2022-03-07 23:22:23 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 23:22:23 | INFO | train | epoch 436 | loss 1.572 | nll_loss 0.54 | ppl 1.45 | wps 22070.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42011 | lr 0.000154283 | gnorm 0.734 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 124254
2022-03-07 23:22:23 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 23:22:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:26:37 | INFO | train_inner | epoch 437:     89 / 97 loss=1.572, nll_loss=0.54, ppl=1.45, wps=22303.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42100, lr=0.00015412, gnorm=0.743, loss_scale=32, train_wall=263, gb_free=8.1, wall=124509
2022-03-07 23:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:27:05 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.466 | nll_loss 13.027 | ppl 8347.96 | wps 42841.4 | wpb 510.9 | bsz 1 | num_updates 42108 | best_loss 7.981
2022-03-07 23:27:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 42108 updates
2022-03-07 23:27:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:27:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:27:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 437 @ 42108 updates, score 13.466) (writing took 2.2422723560594022 seconds)
2022-03-07 23:27:08 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 23:27:08 | INFO | train | epoch 437 | loss 1.571 | nll_loss 0.539 | ppl 1.45 | wps 22286.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42108 | lr 0.000154105 | gnorm 0.743 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 124539
2022-03-07 23:27:08 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 23:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:27:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:31:34 | INFO | train_inner | epoch 438:     93 / 97 loss=1.571, nll_loss=0.539, ppl=1.45, wps=22110.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42200, lr=0.000153937, gnorm=0.743, loss_scale=16, train_wall=266, gb_free=8.1, wall=124806
2022-03-07 23:31:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:31:50 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.509 | nll_loss 13.073 | ppl 8616.54 | wps 42866.2 | wpb 510.9 | bsz 1 | num_updates 42204 | best_loss 7.981
2022-03-07 23:31:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 42204 updates
2022-03-07 23:31:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:31:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:31:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 438 @ 42204 updates, score 13.509) (writing took 2.2444909792393446 seconds)
2022-03-07 23:31:52 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 23:31:52 | INFO | train | epoch 438 | loss 1.57 | nll_loss 0.538 | ppl 1.45 | wps 22077.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42204 | lr 0.00015393 | gnorm 0.743 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 124824
2022-03-07 23:31:52 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 23:31:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:36:27 | INFO | train_inner | epoch 439:     96 / 97 loss=1.57, nll_loss=0.538, ppl=1.45, wps=22317.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42300, lr=0.000153755, gnorm=0.733, loss_scale=32, train_wall=263, gb_free=8.1, wall=125099
2022-03-07 23:36:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:36:35 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.492 | nll_loss 13.057 | ppl 8524.62 | wps 42885.7 | wpb 510.9 | bsz 1 | num_updates 42301 | best_loss 7.981
2022-03-07 23:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 42301 updates
2022-03-07 23:36:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:36:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:36:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 439 @ 42301 updates, score 13.492) (writing took 2.260091600008309 seconds)
2022-03-07 23:36:37 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 23:36:37 | INFO | train | epoch 439 | loss 1.57 | nll_loss 0.538 | ppl 1.45 | wps 22298.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42301 | lr 0.000153753 | gnorm 0.732 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 125109
2022-03-07 23:36:37 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 23:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:37:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:41:20 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 13.459 | nll_loss 13.022 | ppl 8318.4 | wps 43040.3 | wpb 510.9 | bsz 1 | num_updates 42397 | best_loss 7.981
2022-03-07 23:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 42397 updates
2022-03-07 23:41:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:41:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:41:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 440 @ 42397 updates, score 13.459) (writing took 2.2463714610785246 seconds)
2022-03-07 23:41:22 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 23:41:22 | INFO | train | epoch 440 | loss 1.57 | nll_loss 0.538 | ppl 1.45 | wps 22072.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42397 | lr 0.000153579 | gnorm 0.743 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 125394
2022-03-07 23:41:22 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 23:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:41:31 | INFO | train_inner | epoch 441:      3 / 97 loss=1.569, nll_loss=0.537, ppl=1.45, wps=21560.5, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=42400, lr=0.000153574, gnorm=0.742, loss_scale=16, train_wall=266, gb_free=8.1, wall=125403
2022-03-07 23:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:46:05 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.496 | nll_loss 13.06 | ppl 8537.04 | wps 42934.3 | wpb 510.9 | bsz 1 | num_updates 42494 | best_loss 7.981
2022-03-07 23:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 42494 updates
2022-03-07 23:46:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:46:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:46:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 441 @ 42494 updates, score 13.496) (writing took 2.2953427438624203 seconds)
2022-03-07 23:46:07 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 23:46:07 | INFO | train | epoch 441 | loss 1.569 | nll_loss 0.538 | ppl 1.45 | wps 22300 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42494 | lr 0.000153404 | gnorm 0.738 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 125679
2022-03-07 23:46:07 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 23:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:46:24 | INFO | train_inner | epoch 442:      6 / 97 loss=1.569, nll_loss=0.537, ppl=1.45, wps=22315.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42500, lr=0.000153393, gnorm=0.739, loss_scale=32, train_wall=263, gb_free=8.1, wall=125696
2022-03-07 23:46:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:50:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:50:50 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.457 | nll_loss 13.023 | ppl 8322.24 | wps 42842.3 | wpb 510.9 | bsz 1 | num_updates 42590 | best_loss 7.981
2022-03-07 23:50:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 42590 updates
2022-03-07 23:50:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:50:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:50:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 442 @ 42590 updates, score 13.457) (writing took 2.263732277788222 seconds)
2022-03-07 23:50:52 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 23:50:52 | INFO | train | epoch 442 | loss 1.567 | nll_loss 0.535 | ppl 1.45 | wps 22063.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42590 | lr 0.000153231 | gnorm 0.746 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 125964
2022-03-07 23:50:52 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 23:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:51:21 | INFO | train_inner | epoch 443:     10 / 97 loss=1.567, nll_loss=0.535, ppl=1.45, wps=22096.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42600, lr=0.000153213, gnorm=0.744, loss_scale=16, train_wall=266, gb_free=8.1, wall=125993
2022-03-07 23:53:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:55:35 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.488 | nll_loss 13.055 | ppl 8511.1 | wps 42944.2 | wpb 510.9 | bsz 1 | num_updates 42686 | best_loss 7.981
2022-03-07 23:55:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 42686 updates
2022-03-07 23:55:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:55:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 443 @ 42686 updates, score 13.488) (writing took 2.2279504481703043 seconds)
2022-03-07 23:55:37 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 23:55:37 | INFO | train | epoch 443 | loss 1.567 | nll_loss 0.536 | ppl 1.45 | wps 22061.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42686 | lr 0.000153058 | gnorm 0.738 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 126249
2022-03-07 23:55:37 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 23:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:56:17 | INFO | train_inner | epoch 444:     14 / 97 loss=1.567, nll_loss=0.535, ppl=1.45, wps=22094.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42700, lr=0.000153033, gnorm=0.735, loss_scale=16, train_wall=266, gb_free=8.1, wall=126289
2022-03-07 23:59:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:00:20 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.484 | nll_loss 13.053 | ppl 8499.38 | wps 43241.1 | wpb 510.9 | bsz 1 | num_updates 42782 | best_loss 7.981
2022-03-08 00:00:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 42782 updates
2022-03-08 00:00:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:00:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:00:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 444 @ 42782 updates, score 13.484) (writing took 2.2561889379285276 seconds)
2022-03-08 00:00:22 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-08 00:00:22 | INFO | train | epoch 444 | loss 1.566 | nll_loss 0.534 | ppl 1.45 | wps 22064 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42782 | lr 0.000152887 | gnorm 0.733 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 126534
2022-03-08 00:00:22 | INFO | fairseq.trainer | begin training epoch 445
2022-03-08 00:00:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:01:13 | INFO | train_inner | epoch 445:     18 / 97 loss=1.565, nll_loss=0.534, ppl=1.45, wps=22096.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42800, lr=0.000152854, gnorm=0.735, loss_scale=16, train_wall=266, gb_free=8.1, wall=126585
2022-03-08 00:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:05:05 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.514 | nll_loss 13.083 | ppl 8675.56 | wps 42977.8 | wpb 510.9 | bsz 1 | num_updates 42879 | best_loss 7.981
2022-03-08 00:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 42879 updates
2022-03-08 00:05:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:05:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 445 @ 42879 updates, score 13.514) (writing took 2.23752954415977 seconds)
2022-03-08 00:05:07 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-08 00:05:07 | INFO | train | epoch 445 | loss 1.566 | nll_loss 0.535 | ppl 1.45 | wps 22294.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42879 | lr 0.000152714 | gnorm 0.74 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 126819
2022-03-08 00:05:07 | INFO | fairseq.trainer | begin training epoch 446
2022-03-08 00:05:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:06:07 | INFO | train_inner | epoch 446:     21 / 97 loss=1.566, nll_loss=0.534, ppl=1.45, wps=22307, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42900, lr=0.000152676, gnorm=0.74, loss_scale=16, train_wall=263, gb_free=8.1, wall=126879
2022-03-08 00:09:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:09:50 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.459 | nll_loss 13.021 | ppl 8312.38 | wps 43077.8 | wpb 510.9 | bsz 1 | num_updates 42976 | best_loss 7.981
2022-03-08 00:09:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 42976 updates
2022-03-08 00:09:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:09:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:09:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 446 @ 42976 updates, score 13.459) (writing took 2.2946901409886777 seconds)
2022-03-08 00:09:52 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-08 00:09:52 | INFO | train | epoch 446 | loss 1.566 | nll_loss 0.534 | ppl 1.45 | wps 22282.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42976 | lr 0.000152541 | gnorm 0.735 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 127104
2022-03-08 00:09:52 | INFO | fairseq.trainer | begin training epoch 447
2022-03-08 00:09:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:11:01 | INFO | train_inner | epoch 447:     24 / 97 loss=1.566, nll_loss=0.535, ppl=1.45, wps=22305.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43000, lr=0.000152499, gnorm=0.735, loss_scale=32, train_wall=263, gb_free=8.1, wall=127173
2022-03-08 00:12:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:14:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:14:35 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.497 | nll_loss 13.064 | ppl 8564.18 | wps 42703.5 | wpb 510.9 | bsz 1 | num_updates 43072 | best_loss 7.981
2022-03-08 00:14:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 43072 updates
2022-03-08 00:14:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:14:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:14:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 447 @ 43072 updates, score 13.497) (writing took 2.2095213909633458 seconds)
2022-03-08 00:14:37 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-08 00:14:37 | INFO | train | epoch 447 | loss 1.565 | nll_loss 0.533 | ppl 1.45 | wps 22063 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43072 | lr 0.000152371 | gnorm 0.735 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 127389
2022-03-08 00:14:37 | INFO | fairseq.trainer | begin training epoch 448
2022-03-08 00:14:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:15:57 | INFO | train_inner | epoch 448:     28 / 97 loss=1.564, nll_loss=0.532, ppl=1.45, wps=22095.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43100, lr=0.000152322, gnorm=0.73, loss_scale=32, train_wall=266, gb_free=8.1, wall=127469
2022-03-08 00:18:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:18:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:19:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:19:20 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.464 | nll_loss 13.028 | ppl 8354.39 | wps 42716.2 | wpb 510.9 | bsz 1 | num_updates 43167 | best_loss 7.981
2022-03-08 00:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 43167 updates
2022-03-08 00:19:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:19:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:19:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 448 @ 43167 updates, score 13.464) (writing took 2.2636589938774705 seconds)
2022-03-08 00:19:22 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-08 00:19:22 | INFO | train | epoch 448 | loss 1.564 | nll_loss 0.533 | ppl 1.45 | wps 21817.7 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 43167 | lr 0.000152203 | gnorm 0.728 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 127674
2022-03-08 00:19:22 | INFO | fairseq.trainer | begin training epoch 449
2022-03-08 00:19:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:20:57 | INFO | train_inner | epoch 449:     33 / 97 loss=1.563, nll_loss=0.532, ppl=1.45, wps=21865, ups=0.33, wpb=65495, bsz=127.9, num_updates=43200, lr=0.000152145, gnorm=0.733, loss_scale=16, train_wall=269, gb_free=8.1, wall=127768
2022-03-08 00:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:24:05 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.503 | nll_loss 13.07 | ppl 8600.43 | wps 42095.6 | wpb 510.9 | bsz 1 | num_updates 43264 | best_loss 7.981
2022-03-08 00:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 43264 updates
2022-03-08 00:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:24:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 449 @ 43264 updates, score 13.503) (writing took 2.270698050968349 seconds)
2022-03-08 00:24:07 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-08 00:24:07 | INFO | train | epoch 449 | loss 1.564 | nll_loss 0.532 | ppl 1.45 | wps 22272.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43264 | lr 0.000152033 | gnorm 0.74 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 127959
2022-03-08 00:24:07 | INFO | fairseq.trainer | begin training epoch 450
2022-03-08 00:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:25:50 | INFO | train_inner | epoch 450:     36 / 97 loss=1.564, nll_loss=0.532, ppl=1.45, wps=22292.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43300, lr=0.000151969, gnorm=0.735, loss_scale=32, train_wall=263, gb_free=8.1, wall=128062
2022-03-08 00:28:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:28:50 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.515 | nll_loss 13.082 | ppl 8669.27 | wps 42973.1 | wpb 510.9 | bsz 1 | num_updates 43360 | best_loss 7.981
2022-03-08 00:28:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 43360 updates
2022-03-08 00:28:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:28:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 450 @ 43360 updates, score 13.515) (writing took 2.230595522094518 seconds)
2022-03-08 00:28:52 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-08 00:28:52 | INFO | train | epoch 450 | loss 1.562 | nll_loss 0.531 | ppl 1.44 | wps 22063.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43360 | lr 0.000151864 | gnorm 0.728 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 128244
2022-03-08 00:28:52 | INFO | fairseq.trainer | begin training epoch 451
2022-03-08 00:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:30:47 | INFO | train_inner | epoch 451:     40 / 97 loss=1.563, nll_loss=0.531, ppl=1.45, wps=22092.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43400, lr=0.000151794, gnorm=0.737, loss_scale=16, train_wall=266, gb_free=8.1, wall=128359
2022-03-08 00:33:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:33:35 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.55 | nll_loss 13.118 | ppl 8890.59 | wps 43046 | wpb 510.9 | bsz 1 | num_updates 43457 | best_loss 7.981
2022-03-08 00:33:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 43457 updates
2022-03-08 00:33:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:33:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 451 @ 43457 updates, score 13.55) (writing took 2.1756654349155724 seconds)
2022-03-08 00:33:37 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-08 00:33:37 | INFO | train | epoch 451 | loss 1.563 | nll_loss 0.531 | ppl 1.45 | wps 22295.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43457 | lr 0.000151695 | gnorm 0.739 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 128529
2022-03-08 00:33:37 | INFO | fairseq.trainer | begin training epoch 452
2022-03-08 00:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:35:40 | INFO | train_inner | epoch 452:     43 / 97 loss=1.561, nll_loss=0.53, ppl=1.44, wps=22324.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43500, lr=0.00015162, gnorm=0.732, loss_scale=32, train_wall=263, gb_free=8.1, wall=128652
2022-03-08 00:38:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:38:20 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.486 | nll_loss 13.053 | ppl 8501.11 | wps 42837.1 | wpb 510.9 | bsz 1 | num_updates 43554 | best_loss 7.981
2022-03-08 00:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 43554 updates
2022-03-08 00:38:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:38:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 452 @ 43554 updates, score 13.486) (writing took 2.2923922389745712 seconds)
2022-03-08 00:38:22 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-08 00:38:22 | INFO | train | epoch 452 | loss 1.562 | nll_loss 0.531 | ppl 1.44 | wps 22294.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43554 | lr 0.000151526 | gnorm 0.729 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 128814
2022-03-08 00:38:22 | INFO | fairseq.trainer | begin training epoch 453
2022-03-08 00:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:39:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:40:37 | INFO | train_inner | epoch 453:     47 / 97 loss=1.561, nll_loss=0.53, ppl=1.44, wps=22098.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43600, lr=0.000151446, gnorm=0.728, loss_scale=16, train_wall=266, gb_free=8.1, wall=128948
2022-03-08 00:42:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:43:05 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.502 | nll_loss 13.069 | ppl 8594.76 | wps 43081.5 | wpb 510.9 | bsz 1 | num_updates 43650 | best_loss 7.981
2022-03-08 00:43:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 43650 updates
2022-03-08 00:43:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:43:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:43:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 453 @ 43650 updates, score 13.502) (writing took 2.3152829222381115 seconds)
2022-03-08 00:43:07 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-08 00:43:07 | INFO | train | epoch 453 | loss 1.561 | nll_loss 0.53 | ppl 1.44 | wps 22074.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43650 | lr 0.000151359 | gnorm 0.73 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 129099
2022-03-08 00:43:07 | INFO | fairseq.trainer | begin training epoch 454
2022-03-08 00:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:45:30 | INFO | train_inner | epoch 454:     50 / 97 loss=1.561, nll_loss=0.53, ppl=1.44, wps=22321.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=43700, lr=0.000151272, gnorm=0.73, loss_scale=32, train_wall=263, gb_free=8.1, wall=129242
2022-03-08 00:47:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:47:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:47:49 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.49 | nll_loss 13.056 | ppl 8517.52 | wps 42696 | wpb 510.9 | bsz 1 | num_updates 43746 | best_loss 7.981
2022-03-08 00:47:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 43746 updates
2022-03-08 00:47:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:47:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:47:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 454 @ 43746 updates, score 13.49) (writing took 2.2972069960087538 seconds)
2022-03-08 00:47:52 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-08 00:47:52 | INFO | train | epoch 454 | loss 1.56 | nll_loss 0.528 | ppl 1.44 | wps 22068.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43746 | lr 0.000151193 | gnorm 0.731 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 129384
2022-03-08 00:47:52 | INFO | fairseq.trainer | begin training epoch 455
2022-03-08 00:47:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:50:26 | INFO | train_inner | epoch 455:     54 / 97 loss=1.56, nll_loss=0.529, ppl=1.44, wps=22096.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43800, lr=0.000151099, gnorm=0.736, loss_scale=16, train_wall=266, gb_free=8.1, wall=129538
2022-03-08 00:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:52:34 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.554 | nll_loss 13.125 | ppl 8931.74 | wps 42736.8 | wpb 510.9 | bsz 1 | num_updates 43843 | best_loss 7.981
2022-03-08 00:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 43843 updates
2022-03-08 00:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:52:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:52:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 455 @ 43843 updates, score 13.554) (writing took 2.341728932224214 seconds)
2022-03-08 00:52:37 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-08 00:52:37 | INFO | train | epoch 455 | loss 1.559 | nll_loss 0.528 | ppl 1.44 | wps 22295.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43843 | lr 0.000151025 | gnorm 0.731 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 129669
2022-03-08 00:52:37 | INFO | fairseq.trainer | begin training epoch 456
2022-03-08 00:52:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:54:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:55:23 | INFO | train_inner | epoch 456:     58 / 97 loss=1.56, nll_loss=0.529, ppl=1.44, wps=22111.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=43900, lr=0.000150927, gnorm=0.725, loss_scale=16, train_wall=266, gb_free=8.1, wall=129834
2022-03-08 00:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:57:19 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.462 | nll_loss 13.025 | ppl 8334.82 | wps 42989.1 | wpb 510.9 | bsz 1 | num_updates 43939 | best_loss 7.981
2022-03-08 00:57:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 43939 updates
2022-03-08 00:57:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:57:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 456 @ 43939 updates, score 13.462) (writing took 2.3327675904147327 seconds)
2022-03-08 00:57:21 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-08 00:57:21 | INFO | train | epoch 456 | loss 1.559 | nll_loss 0.528 | ppl 1.44 | wps 22082 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43939 | lr 0.00015086 | gnorm 0.731 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 129953
2022-03-08 00:57:21 | INFO | fairseq.trainer | begin training epoch 457
2022-03-08 00:57:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:00:16 | INFO | train_inner | epoch 457:     61 / 97 loss=1.558, nll_loss=0.527, ppl=1.44, wps=22334, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44000, lr=0.000150756, gnorm=0.732, loss_scale=16, train_wall=263, gb_free=8.1, wall=130128
2022-03-08 01:01:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:02:04 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.533 | nll_loss 13.101 | ppl 8787.44 | wps 42956.7 | wpb 510.9 | bsz 1 | num_updates 44036 | best_loss 7.981
2022-03-08 01:02:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 44036 updates
2022-03-08 01:02:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:02:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:02:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 457 @ 44036 updates, score 13.533) (writing took 2.326816398650408 seconds)
2022-03-08 01:02:06 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-08 01:02:06 | INFO | train | epoch 457 | loss 1.558 | nll_loss 0.527 | ppl 1.44 | wps 22319.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44036 | lr 0.000150694 | gnorm 0.731 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 130238
2022-03-08 01:02:06 | INFO | fairseq.trainer | begin training epoch 458
2022-03-08 01:02:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:02:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:05:12 | INFO | train_inner | epoch 458:     65 / 97 loss=1.557, nll_loss=0.526, ppl=1.44, wps=22111.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=44100, lr=0.000150585, gnorm=0.731, loss_scale=16, train_wall=266, gb_free=8.1, wall=130424
2022-03-08 01:06:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:06:49 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.463 | nll_loss 13.028 | ppl 8350 | wps 42870.7 | wpb 510.9 | bsz 1 | num_updates 44132 | best_loss 7.981
2022-03-08 01:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 44132 updates
2022-03-08 01:06:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:06:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 458 @ 44132 updates, score 13.463) (writing took 2.3010661606676877 seconds)
2022-03-08 01:06:51 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-08 01:06:51 | INFO | train | epoch 458 | loss 1.557 | nll_loss 0.526 | ppl 1.44 | wps 22076.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44132 | lr 0.00015053 | gnorm 0.727 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 130523
2022-03-08 01:06:51 | INFO | fairseq.trainer | begin training epoch 459
2022-03-08 01:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:09:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:10:08 | INFO | train_inner | epoch 459:     69 / 97 loss=1.558, nll_loss=0.527, ppl=1.44, wps=22111.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44200, lr=0.000150414, gnorm=0.731, loss_scale=16, train_wall=266, gb_free=8.1, wall=130720
2022-03-08 01:11:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:11:33 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.549 | nll_loss 13.117 | ppl 8882.94 | wps 42854.1 | wpb 510.9 | bsz 1 | num_updates 44228 | best_loss 7.981
2022-03-08 01:11:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 44228 updates
2022-03-08 01:11:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:11:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:11:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 459 @ 44228 updates, score 13.549) (writing took 2.2768665961921215 seconds)
2022-03-08 01:11:36 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-08 01:11:36 | INFO | train | epoch 459 | loss 1.557 | nll_loss 0.526 | ppl 1.44 | wps 22086.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44228 | lr 0.000150367 | gnorm 0.736 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 130807
2022-03-08 01:11:36 | INFO | fairseq.trainer | begin training epoch 460
2022-03-08 01:11:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:15:02 | INFO | train_inner | epoch 460:     72 / 97 loss=1.557, nll_loss=0.526, ppl=1.44, wps=22327.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44300, lr=0.000150244, gnorm=0.73, loss_scale=16, train_wall=263, gb_free=8.1, wall=131013
2022-03-08 01:16:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:16:18 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.525 | nll_loss 13.09 | ppl 8716.73 | wps 42720.2 | wpb 510.9 | bsz 1 | num_updates 44325 | best_loss 7.981
2022-03-08 01:16:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 44325 updates
2022-03-08 01:16:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:16:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:16:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 460 @ 44325 updates, score 13.525) (writing took 2.424170028883964 seconds)
2022-03-08 01:16:21 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-08 01:16:21 | INFO | train | epoch 460 | loss 1.556 | nll_loss 0.524 | ppl 1.44 | wps 22290.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44325 | lr 0.000150202 | gnorm 0.725 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 131092
2022-03-08 01:16:21 | INFO | fairseq.trainer | begin training epoch 461
2022-03-08 01:16:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:19:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:19:58 | INFO | train_inner | epoch 461:     76 / 97 loss=1.556, nll_loss=0.525, ppl=1.44, wps=22097, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44400, lr=0.000150075, gnorm=0.733, loss_scale=16, train_wall=266, gb_free=8.1, wall=131310
2022-03-08 01:20:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:21:03 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.49 | nll_loss 13.056 | ppl 8514.93 | wps 42858.3 | wpb 510.9 | bsz 1 | num_updates 44421 | best_loss 7.981
2022-03-08 01:21:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 44421 updates
2022-03-08 01:21:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:21:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:21:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 461 @ 44421 updates, score 13.49) (writing took 2.2665096279233694 seconds)
2022-03-08 01:21:05 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-08 01:21:05 | INFO | train | epoch 461 | loss 1.556 | nll_loss 0.525 | ppl 1.44 | wps 22075.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44421 | lr 0.00015004 | gnorm 0.738 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 131377
2022-03-08 01:21:05 | INFO | fairseq.trainer | begin training epoch 462
2022-03-08 01:21:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:24:51 | INFO | train_inner | epoch 462:     79 / 97 loss=1.556, nll_loss=0.525, ppl=1.44, wps=22321.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44500, lr=0.000149906, gnorm=0.729, loss_scale=16, train_wall=263, gb_free=8.1, wall=131603
2022-03-08 01:25:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:25:48 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.463 | nll_loss 13.03 | ppl 8364.54 | wps 43014 | wpb 510.9 | bsz 1 | num_updates 44518 | best_loss 7.981
2022-03-08 01:25:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 44518 updates
2022-03-08 01:25:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:25:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:25:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 462 @ 44518 updates, score 13.463) (writing took 2.3443214679136872 seconds)
2022-03-08 01:25:50 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-08 01:25:50 | INFO | train | epoch 462 | loss 1.555 | nll_loss 0.525 | ppl 1.44 | wps 22308.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44518 | lr 0.000149876 | gnorm 0.725 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 131662
2022-03-08 01:25:50 | INFO | fairseq.trainer | begin training epoch 463
2022-03-08 01:25:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:27:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:29:48 | INFO | train_inner | epoch 463:     83 / 97 loss=1.556, nll_loss=0.525, ppl=1.44, wps=22106.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44600, lr=0.000149738, gnorm=0.732, loss_scale=16, train_wall=266, gb_free=8.1, wall=131900
2022-03-08 01:30:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:30:33 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.483 | nll_loss 13.05 | ppl 8478.11 | wps 43026.5 | wpb 510.9 | bsz 1 | num_updates 44614 | best_loss 7.981
2022-03-08 01:30:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 44614 updates
2022-03-08 01:30:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:30:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:30:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 463 @ 44614 updates, score 13.483) (writing took 2.294861624017358 seconds)
2022-03-08 01:30:35 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-08 01:30:35 | INFO | train | epoch 463 | loss 1.554 | nll_loss 0.523 | ppl 1.44 | wps 22075.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44614 | lr 0.000149715 | gnorm 0.735 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 131947
2022-03-08 01:30:35 | INFO | fairseq.trainer | begin training epoch 464
2022-03-08 01:30:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:34:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:34:44 | INFO | train_inner | epoch 464:     87 / 97 loss=1.553, nll_loss=0.522, ppl=1.44, wps=22117.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=44700, lr=0.000149571, gnorm=0.728, loss_scale=16, train_wall=266, gb_free=8.1, wall=132196
2022-03-08 01:35:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:35:17 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.46 | nll_loss 13.025 | ppl 8334.82 | wps 42896 | wpb 510.9 | bsz 1 | num_updates 44710 | best_loss 7.981
2022-03-08 01:35:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 44710 updates
2022-03-08 01:35:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:35:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:35:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 464 @ 44710 updates, score 13.46) (writing took 2.2969094151630998 seconds)
2022-03-08 01:35:20 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-08 01:35:20 | INFO | train | epoch 464 | loss 1.553 | nll_loss 0.522 | ppl 1.44 | wps 22080.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44710 | lr 0.000149554 | gnorm 0.726 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 132232
2022-03-08 01:35:20 | INFO | fairseq.trainer | begin training epoch 465
2022-03-08 01:35:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:39:37 | INFO | train_inner | epoch 465:     90 / 97 loss=1.554, nll_loss=0.523, ppl=1.44, wps=22330.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=44800, lr=0.000149404, gnorm=0.723, loss_scale=16, train_wall=263, gb_free=8.1, wall=132489
2022-03-08 01:39:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:40:02 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.469 | nll_loss 13.035 | ppl 8391.57 | wps 42908.7 | wpb 510.9 | bsz 1 | num_updates 44807 | best_loss 7.981
2022-03-08 01:40:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 44807 updates
2022-03-08 01:40:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:40:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:40:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 465 @ 44807 updates, score 13.469) (writing took 2.31960684992373 seconds)
2022-03-08 01:40:04 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-08 01:40:04 | INFO | train | epoch 465 | loss 1.554 | nll_loss 0.523 | ppl 1.44 | wps 22315.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44807 | lr 0.000149392 | gnorm 0.722 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 132516
2022-03-08 01:40:04 | INFO | fairseq.trainer | begin training epoch 466
2022-03-08 01:40:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:40:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:44:33 | INFO | train_inner | epoch 466:     94 / 97 loss=1.554, nll_loss=0.523, ppl=1.44, wps=22107.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44900, lr=0.000149237, gnorm=0.734, loss_scale=16, train_wall=266, gb_free=8.1, wall=132785
2022-03-08 01:44:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:44:47 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.509 | nll_loss 13.076 | ppl 8637.27 | wps 43022.6 | wpb 510.9 | bsz 1 | num_updates 44903 | best_loss 7.981
2022-03-08 01:44:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 44903 updates
2022-03-08 01:44:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:44:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:44:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 466 @ 44903 updates, score 13.509) (writing took 2.3243174622766674 seconds)
2022-03-08 01:44:49 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-08 01:44:49 | INFO | train | epoch 466 | loss 1.553 | nll_loss 0.522 | ppl 1.44 | wps 22076.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44903 | lr 0.000149232 | gnorm 0.733 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 132801
2022-03-08 01:44:49 | INFO | fairseq.trainer | begin training epoch 467
2022-03-08 01:44:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:47:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:49:32 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.498 | nll_loss 13.066 | ppl 8574.26 | wps 42984.2 | wpb 510.9 | bsz 1 | num_updates 44999 | best_loss 7.981
2022-03-08 01:49:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 44999 updates
2022-03-08 01:49:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:49:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:49:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 467 @ 44999 updates, score 13.498) (writing took 2.3978136447258294 seconds)
2022-03-08 01:49:34 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-08 01:49:34 | INFO | train | epoch 467 | loss 1.553 | nll_loss 0.522 | ppl 1.44 | wps 22066.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44999 | lr 0.000149073 | gnorm 0.73 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133086
2022-03-08 01:49:34 | INFO | fairseq.trainer | begin training epoch 468
2022-03-08 01:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:49:37 | INFO | train_inner | epoch 468:      1 / 97 loss=1.553, nll_loss=0.522, ppl=1.44, wps=21552, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=45000, lr=0.000149071, gnorm=0.73, loss_scale=16, train_wall=265, gb_free=8.1, wall=133089
2022-03-08 01:54:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:54:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:54:16 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.524 | nll_loss 13.091 | ppl 8726.86 | wps 42551 | wpb 510.9 | bsz 1 | num_updates 45095 | best_loss 7.981
2022-03-08 01:54:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 45095 updates
2022-03-08 01:54:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:54:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:54:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 468 @ 45095 updates, score 13.524) (writing took 2.3412764468230307 seconds)
2022-03-08 01:54:19 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-08 01:54:19 | INFO | train | epoch 468 | loss 1.552 | nll_loss 0.521 | ppl 1.44 | wps 22074.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45095 | lr 0.000148914 | gnorm 0.726 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133371
2022-03-08 01:54:19 | INFO | fairseq.trainer | begin training epoch 469
2022-03-08 01:54:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:54:33 | INFO | train_inner | epoch 469:      5 / 97 loss=1.551, nll_loss=0.52, ppl=1.43, wps=22106, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45100, lr=0.000148906, gnorm=0.727, loss_scale=16, train_wall=266, gb_free=8.1, wall=133385
2022-03-08 01:58:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:59:01 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.515 | nll_loss 13.083 | ppl 8674.19 | wps 42963.4 | wpb 510.9 | bsz 1 | num_updates 45192 | best_loss 7.981
2022-03-08 01:59:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 45192 updates
2022-03-08 01:59:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:59:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:59:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 469 @ 45192 updates, score 13.515) (writing took 2.348838809877634 seconds)
2022-03-08 01:59:04 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-08 01:59:04 | INFO | train | epoch 469 | loss 1.552 | nll_loss 0.521 | ppl 1.44 | wps 22303.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45192 | lr 0.000148754 | gnorm 0.736 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133656
2022-03-08 01:59:04 | INFO | fairseq.trainer | begin training epoch 470
2022-03-08 01:59:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:59:27 | INFO | train_inner | epoch 470:      8 / 97 loss=1.552, nll_loss=0.521, ppl=1.44, wps=22321.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=45200, lr=0.000148741, gnorm=0.733, loss_scale=16, train_wall=263, gb_free=8.1, wall=133679
2022-03-08 02:03:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:03:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:03:46 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.479 | nll_loss 13.05 | ppl 8481.24 | wps 42630.9 | wpb 510.9 | bsz 1 | num_updates 45288 | best_loss 7.981
2022-03-08 02:03:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 45288 updates
2022-03-08 02:03:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:03:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 470 @ 45288 updates, score 13.479) (writing took 2.3533522840589285 seconds)
2022-03-08 02:03:48 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-08 02:03:48 | INFO | train | epoch 470 | loss 1.55 | nll_loss 0.52 | ppl 1.43 | wps 22072.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45288 | lr 0.000148596 | gnorm 0.724 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133940
2022-03-08 02:03:49 | INFO | fairseq.trainer | begin training epoch 471
2022-03-08 02:03:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:04:23 | INFO | train_inner | epoch 471:     12 / 97 loss=1.549, nll_loss=0.519, ppl=1.43, wps=22104, ups=0.34, wpb=65495, bsz=127.9, num_updates=45300, lr=0.000148577, gnorm=0.724, loss_scale=16, train_wall=266, gb_free=8.1, wall=133975
2022-03-08 02:08:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:08:31 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.554 | nll_loss 13.122 | ppl 8914.68 | wps 42927.2 | wpb 510.9 | bsz 1 | num_updates 45385 | best_loss 7.981
2022-03-08 02:08:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 45385 updates
2022-03-08 02:08:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:08:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:08:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 471 @ 45385 updates, score 13.554) (writing took 2.296807849314064 seconds)
2022-03-08 02:08:33 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-08 02:08:33 | INFO | train | epoch 471 | loss 1.551 | nll_loss 0.521 | ppl 1.43 | wps 22297.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45385 | lr 0.000148438 | gnorm 0.729 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 134225
2022-03-08 02:08:33 | INFO | fairseq.trainer | begin training epoch 472
2022-03-08 02:08:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:09:16 | INFO | train_inner | epoch 472:     15 / 97 loss=1.55, nll_loss=0.52, ppl=1.43, wps=22316.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45400, lr=0.000148413, gnorm=0.729, loss_scale=16, train_wall=263, gb_free=8.1, wall=134268
2022-03-08 02:10:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:13:16 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.446 | nll_loss 13.016 | ppl 8280.79 | wps 42732.2 | wpb 510.9 | bsz 1 | num_updates 45481 | best_loss 7.981
2022-03-08 02:13:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 45481 updates
2022-03-08 02:13:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:13:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 472 @ 45481 updates, score 13.446) (writing took 2.28165997331962 seconds)
2022-03-08 02:13:18 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-08 02:13:18 | INFO | train | epoch 472 | loss 1.549 | nll_loss 0.519 | ppl 1.43 | wps 22072.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45481 | lr 0.000148281 | gnorm 0.733 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 134510
2022-03-08 02:13:18 | INFO | fairseq.trainer | begin training epoch 473
2022-03-08 02:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:14:13 | INFO | train_inner | epoch 473:     19 / 97 loss=1.549, nll_loss=0.518, ppl=1.43, wps=22105.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45500, lr=0.00014825, gnorm=0.732, loss_scale=16, train_wall=266, gb_free=8.1, wall=134565
2022-03-08 02:16:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:17:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:18:01 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.519 | nll_loss 13.087 | ppl 8698.99 | wps 42984.6 | wpb 510.9 | bsz 1 | num_updates 45577 | best_loss 7.981
2022-03-08 02:18:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 45577 updates
2022-03-08 02:18:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:18:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:18:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 473 @ 45577 updates, score 13.519) (writing took 2.395179694984108 seconds)
2022-03-08 02:18:03 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-08 02:18:03 | INFO | train | epoch 473 | loss 1.549 | nll_loss 0.518 | ppl 1.43 | wps 22063.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45577 | lr 0.000148125 | gnorm 0.725 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 134795
2022-03-08 02:18:03 | INFO | fairseq.trainer | begin training epoch 474
2022-03-08 02:18:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:19:09 | INFO | train_inner | epoch 474:     23 / 97 loss=1.549, nll_loss=0.518, ppl=1.43, wps=22099.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45600, lr=0.000148087, gnorm=0.728, loss_scale=16, train_wall=266, gb_free=8.1, wall=134861
2022-03-08 02:22:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:22:46 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.535 | nll_loss 13.105 | ppl 8811.82 | wps 42946.8 | wpb 510.9 | bsz 1 | num_updates 45674 | best_loss 7.981
2022-03-08 02:22:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 45674 updates
2022-03-08 02:22:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:22:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:22:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 474 @ 45674 updates, score 13.535) (writing took 2.326516520231962 seconds)
2022-03-08 02:22:48 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-08 02:22:48 | INFO | train | epoch 474 | loss 1.549 | nll_loss 0.519 | ppl 1.43 | wps 22301.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45674 | lr 0.000147967 | gnorm 0.737 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135080
2022-03-08 02:22:48 | INFO | fairseq.trainer | begin training epoch 475
2022-03-08 02:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:24:03 | INFO | train_inner | epoch 475:     26 / 97 loss=1.549, nll_loss=0.519, ppl=1.43, wps=22314.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45700, lr=0.000147925, gnorm=0.738, loss_scale=32, train_wall=263, gb_free=8.1, wall=135154
2022-03-08 02:24:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:27:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:27:31 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.502 | nll_loss 13.072 | ppl 8610.93 | wps 43043.8 | wpb 510.9 | bsz 1 | num_updates 45770 | best_loss 7.981
2022-03-08 02:27:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 45770 updates
2022-03-08 02:27:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:27:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:27:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 475 @ 45770 updates, score 13.502) (writing took 2.2791792950592935 seconds)
2022-03-08 02:27:33 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-08 02:27:33 | INFO | train | epoch 475 | loss 1.548 | nll_loss 0.518 | ppl 1.43 | wps 22077.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45770 | lr 0.000147812 | gnorm 0.736 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135365
2022-03-08 02:27:33 | INFO | fairseq.trainer | begin training epoch 476
2022-03-08 02:27:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:28:59 | INFO | train_inner | epoch 476:     30 / 97 loss=1.547, nll_loss=0.517, ppl=1.43, wps=22113.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45800, lr=0.000147764, gnorm=0.732, loss_scale=16, train_wall=266, gb_free=8.1, wall=135451
2022-03-08 02:31:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:32:15 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.486 | nll_loss 13.055 | ppl 8510.13 | wps 42760.5 | wpb 510.9 | bsz 1 | num_updates 45866 | best_loss 7.981
2022-03-08 02:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 45866 updates
2022-03-08 02:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:32:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 476 @ 45866 updates, score 13.486) (writing took 2.32224456127733 seconds)
2022-03-08 02:32:18 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-08 02:32:18 | INFO | train | epoch 476 | loss 1.547 | nll_loss 0.516 | ppl 1.43 | wps 22070.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45866 | lr 0.000147657 | gnorm 0.728 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135650
2022-03-08 02:32:18 | INFO | fairseq.trainer | begin training epoch 477
2022-03-08 02:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:33:55 | INFO | train_inner | epoch 477:     34 / 97 loss=1.547, nll_loss=0.516, ppl=1.43, wps=22096.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45900, lr=0.000147602, gnorm=0.73, loss_scale=16, train_wall=266, gb_free=8.1, wall=135747
2022-03-08 02:36:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:37:00 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.477 | nll_loss 13.046 | ppl 8460.21 | wps 42779 | wpb 510.9 | bsz 1 | num_updates 45963 | best_loss 7.981
2022-03-08 02:37:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 45963 updates
2022-03-08 02:37:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:37:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:37:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 477 @ 45963 updates, score 13.477) (writing took 2.319997552782297 seconds)
2022-03-08 02:37:03 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-08 02:37:03 | INFO | train | epoch 477 | loss 1.547 | nll_loss 0.517 | ppl 1.43 | wps 22287.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45963 | lr 0.000147501 | gnorm 0.728 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135935
2022-03-08 02:37:03 | INFO | fairseq.trainer | begin training epoch 478
2022-03-08 02:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:38:49 | INFO | train_inner | epoch 478:     37 / 97 loss=1.546, nll_loss=0.516, ppl=1.43, wps=22308.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46000, lr=0.000147442, gnorm=0.727, loss_scale=32, train_wall=263, gb_free=8.1, wall=136041
2022-03-08 02:38:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:41:45 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.482 | nll_loss 13.047 | ppl 8466.17 | wps 42959.6 | wpb 510.9 | bsz 1 | num_updates 46059 | best_loss 7.981
2022-03-08 02:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 46059 updates
2022-03-08 02:41:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:41:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:41:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 478 @ 46059 updates, score 13.482) (writing took 2.3803726928308606 seconds)
2022-03-08 02:41:48 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-08 02:41:48 | INFO | train | epoch 478 | loss 1.545 | nll_loss 0.515 | ppl 1.43 | wps 22066.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46059 | lr 0.000147347 | gnorm 0.726 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 136220
2022-03-08 02:41:48 | INFO | fairseq.trainer | begin training epoch 479
2022-03-08 02:41:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:43:45 | INFO | train_inner | epoch 479:     41 / 97 loss=1.545, nll_loss=0.515, ppl=1.43, wps=22102.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=46100, lr=0.000147282, gnorm=0.723, loss_scale=16, train_wall=266, gb_free=8.1, wall=136337
2022-03-08 02:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:46:30 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.513 | nll_loss 13.085 | ppl 8688.9 | wps 42669.4 | wpb 510.9 | bsz 1 | num_updates 46156 | best_loss 7.981
2022-03-08 02:46:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 46156 updates
2022-03-08 02:46:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:46:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:46:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 479 @ 46156 updates, score 13.513) (writing took 2.2606802857480943 seconds)
2022-03-08 02:46:33 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-08 02:46:33 | INFO | train | epoch 479 | loss 1.546 | nll_loss 0.516 | ppl 1.43 | wps 22300.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46156 | lr 0.000147193 | gnorm 0.727 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 136504
2022-03-08 02:46:33 | INFO | fairseq.trainer | begin training epoch 480
2022-03-08 02:46:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:48:38 | INFO | train_inner | epoch 480:     44 / 97 loss=1.546, nll_loss=0.516, ppl=1.43, wps=22330.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46200, lr=0.000147122, gnorm=0.728, loss_scale=32, train_wall=263, gb_free=8.1, wall=136630
2022-03-08 02:50:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:51:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:51:15 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.486 | nll_loss 13.053 | ppl 8500.36 | wps 42914.1 | wpb 510.9 | bsz 1 | num_updates 46252 | best_loss 7.981
2022-03-08 02:51:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 46252 updates
2022-03-08 02:51:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:51:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:51:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 480 @ 46252 updates, score 13.486) (writing took 2.3021659520454705 seconds)
2022-03-08 02:51:17 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-08 02:51:17 | INFO | train | epoch 480 | loss 1.544 | nll_loss 0.514 | ppl 1.43 | wps 22103.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46252 | lr 0.00014704 | gnorm 0.723 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 136789
2022-03-08 02:51:17 | INFO | fairseq.trainer | begin training epoch 481
2022-03-08 02:51:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:53:34 | INFO | train_inner | epoch 481:     48 / 97 loss=1.544, nll_loss=0.514, ppl=1.43, wps=22115.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46300, lr=0.000146964, gnorm=0.728, loss_scale=16, train_wall=266, gb_free=8.1, wall=136926
2022-03-08 02:55:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:56:00 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.483 | nll_loss 13.052 | ppl 8492.58 | wps 42961.4 | wpb 510.9 | bsz 1 | num_updates 46349 | best_loss 7.981
2022-03-08 02:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 46349 updates
2022-03-08 02:56:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:56:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:56:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 481 @ 46349 updates, score 13.483) (writing took 2.2963013579137623 seconds)
2022-03-08 02:56:02 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-08 02:56:02 | INFO | train | epoch 481 | loss 1.544 | nll_loss 0.514 | ppl 1.43 | wps 22295.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46349 | lr 0.000146886 | gnorm 0.731 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 137074
2022-03-08 02:56:02 | INFO | fairseq.trainer | begin training epoch 482
2022-03-08 02:56:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:57:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:58:31 | INFO | train_inner | epoch 482:     52 / 97 loss=1.543, nll_loss=0.513, ppl=1.43, wps=22110.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46400, lr=0.000146805, gnorm=0.726, loss_scale=16, train_wall=266, gb_free=8.1, wall=137223
2022-03-08 03:00:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:00:44 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 13.504 | nll_loss 13.072 | ppl 8610.56 | wps 42949.8 | wpb 510.9 | bsz 1 | num_updates 46445 | best_loss 7.981
2022-03-08 03:00:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 46445 updates
2022-03-08 03:00:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 482 @ 46445 updates, score 13.504) (writing took 2.2831287109293044 seconds)
2022-03-08 03:00:47 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-08 03:00:47 | INFO | train | epoch 482 | loss 1.544 | nll_loss 0.514 | ppl 1.43 | wps 22073.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46445 | lr 0.000146734 | gnorm 0.725 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 137359
2022-03-08 03:00:47 | INFO | fairseq.trainer | begin training epoch 483
2022-03-08 03:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:03:24 | INFO | train_inner | epoch 483:     55 / 97 loss=1.544, nll_loss=0.514, ppl=1.43, wps=22320.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=46500, lr=0.000146647, gnorm=0.729, loss_scale=16, train_wall=263, gb_free=8.1, wall=137516
2022-03-08 03:05:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:05:29 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.55 | nll_loss 13.119 | ppl 8897.18 | wps 43027.8 | wpb 510.9 | bsz 1 | num_updates 46542 | best_loss 7.981
2022-03-08 03:05:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 46542 updates
2022-03-08 03:05:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:05:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:05:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 483 @ 46542 updates, score 13.55) (writing took 2.380916840862483 seconds)
2022-03-08 03:05:32 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-08 03:05:32 | INFO | train | epoch 483 | loss 1.544 | nll_loss 0.514 | ppl 1.43 | wps 22303.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46542 | lr 0.000146581 | gnorm 0.73 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 137643
2022-03-08 03:05:32 | INFO | fairseq.trainer | begin training epoch 484
2022-03-08 03:05:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:06:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:08:20 | INFO | train_inner | epoch 484:     59 / 97 loss=1.544, nll_loss=0.514, ppl=1.43, wps=22107, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46600, lr=0.00014649, gnorm=0.726, loss_scale=16, train_wall=266, gb_free=8.1, wall=137812
2022-03-08 03:10:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:10:14 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.538 | nll_loss 13.109 | ppl 8832.38 | wps 42722 | wpb 510.9 | bsz 1 | num_updates 46638 | best_loss 7.981
2022-03-08 03:10:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 46638 updates
2022-03-08 03:10:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:10:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:10:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 484 @ 46638 updates, score 13.538) (writing took 2.3009061878547072 seconds)
2022-03-08 03:10:16 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-08 03:10:16 | INFO | train | epoch 484 | loss 1.543 | nll_loss 0.513 | ppl 1.43 | wps 22079.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46638 | lr 0.00014643 | gnorm 0.727 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 137928
2022-03-08 03:10:16 | INFO | fairseq.trainer | begin training epoch 485
2022-03-08 03:10:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:13:14 | INFO | train_inner | epoch 485:     62 / 97 loss=1.543, nll_loss=0.513, ppl=1.43, wps=22324.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=46700, lr=0.000146333, gnorm=0.727, loss_scale=32, train_wall=263, gb_free=8.1, wall=138106
2022-03-08 03:13:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:14:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:14:59 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.533 | nll_loss 13.104 | ppl 8804.6 | wps 42878.5 | wpb 510.9 | bsz 1 | num_updates 46734 | best_loss 7.981
2022-03-08 03:14:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 46734 updates
2022-03-08 03:14:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:15:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:15:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 485 @ 46734 updates, score 13.533) (writing took 2.2601960082538426 seconds)
2022-03-08 03:15:01 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-08 03:15:01 | INFO | train | epoch 485 | loss 1.543 | nll_loss 0.513 | ppl 1.43 | wps 22079.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46734 | lr 0.00014628 | gnorm 0.726 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 138213
2022-03-08 03:15:01 | INFO | fairseq.trainer | begin training epoch 486
2022-03-08 03:15:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:18:10 | INFO | train_inner | epoch 486:     66 / 97 loss=1.542, nll_loss=0.512, ppl=1.43, wps=22114.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46800, lr=0.000146176, gnorm=0.722, loss_scale=16, train_wall=266, gb_free=8.1, wall=138402
2022-03-08 03:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:19:44 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 13.517 | nll_loss 13.084 | ppl 8684.22 | wps 42843.7 | wpb 510.9 | bsz 1 | num_updates 46831 | best_loss 7.981
2022-03-08 03:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 46831 updates
2022-03-08 03:19:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:19:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:19:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 486 @ 46831 updates, score 13.517) (writing took 2.2849870012141764 seconds)
2022-03-08 03:19:46 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-08 03:19:46 | INFO | train | epoch 486 | loss 1.541 | nll_loss 0.511 | ppl 1.43 | wps 22308.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46831 | lr 0.000146128 | gnorm 0.72 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 138498
2022-03-08 03:19:46 | INFO | fairseq.trainer | begin training epoch 487
2022-03-08 03:19:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:22:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:23:06 | INFO | train_inner | epoch 487:     70 / 97 loss=1.541, nll_loss=0.511, ppl=1.43, wps=22113.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46900, lr=0.00014602, gnorm=0.721, loss_scale=16, train_wall=266, gb_free=8.1, wall=138698
2022-03-08 03:24:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:24:28 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.493 | nll_loss 13.061 | ppl 8547.72 | wps 43000.1 | wpb 510.9 | bsz 1 | num_updates 46927 | best_loss 7.981
2022-03-08 03:24:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 46927 updates
2022-03-08 03:24:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:24:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:24:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 487 @ 46927 updates, score 13.493) (writing took 2.292479812167585 seconds)
2022-03-08 03:24:30 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-08 03:24:30 | INFO | train | epoch 487 | loss 1.541 | nll_loss 0.511 | ppl 1.43 | wps 22087.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46927 | lr 0.000145978 | gnorm 0.72 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 138782
2022-03-08 03:24:30 | INFO | fairseq.trainer | begin training epoch 488
2022-03-08 03:24:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:27:59 | INFO | train_inner | epoch 488:     73 / 97 loss=1.541, nll_loss=0.511, ppl=1.43, wps=22327.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=47000, lr=0.000145865, gnorm=0.721, loss_scale=16, train_wall=263, gb_free=8.1, wall=138991
2022-03-08 03:29:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:29:13 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.457 | nll_loss 13.024 | ppl 8329.63 | wps 43182.9 | wpb 510.9 | bsz 1 | num_updates 47024 | best_loss 7.981
2022-03-08 03:29:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 47024 updates
2022-03-08 03:29:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:29:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 488 @ 47024 updates, score 13.457) (writing took 2.367023809812963 seconds)
2022-03-08 03:29:15 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-08 03:29:15 | INFO | train | epoch 488 | loss 1.541 | nll_loss 0.511 | ppl 1.42 | wps 22302.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47024 | lr 0.000145828 | gnorm 0.724 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 139067
2022-03-08 03:29:15 | INFO | fairseq.trainer | begin training epoch 489
2022-03-08 03:29:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:29:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:32:56 | INFO | train_inner | epoch 489:     77 / 97 loss=1.541, nll_loss=0.511, ppl=1.43, wps=22091, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=47100, lr=0.00014571, gnorm=0.723, loss_scale=16, train_wall=266, gb_free=8.1, wall=139288
2022-03-08 03:33:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:33:58 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.488 | nll_loss 13.057 | ppl 8520.45 | wps 42921.9 | wpb 510.9 | bsz 1 | num_updates 47120 | best_loss 7.981
2022-03-08 03:33:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 47120 updates
2022-03-08 03:33:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:34:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:34:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 489 @ 47120 updates, score 13.488) (writing took 2.310198673978448 seconds)
2022-03-08 03:34:00 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-08 03:34:00 | INFO | train | epoch 489 | loss 1.54 | nll_loss 0.51 | ppl 1.42 | wps 22063 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47120 | lr 0.000145679 | gnorm 0.719 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139352
2022-03-08 03:34:00 | INFO | fairseq.trainer | begin training epoch 490
2022-03-08 03:34:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:37:49 | INFO | train_inner | epoch 490:     80 / 97 loss=1.54, nll_loss=0.511, ppl=1.42, wps=22354, ups=0.34, wpb=65495, bsz=127.9, num_updates=47200, lr=0.000145556, gnorm=0.717, loss_scale=32, train_wall=263, gb_free=8.1, wall=139581
2022-03-08 03:38:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:38:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:38:42 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.504 | nll_loss 13.074 | ppl 8624.91 | wps 42674.2 | wpb 510.9 | bsz 1 | num_updates 47216 | best_loss 7.981
2022-03-08 03:38:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 47216 updates
2022-03-08 03:38:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:38:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:38:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 490 @ 47216 updates, score 13.504) (writing took 2.2986239031888545 seconds)
2022-03-08 03:38:45 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-08 03:38:45 | INFO | train | epoch 490 | loss 1.539 | nll_loss 0.509 | ppl 1.42 | wps 22117.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47216 | lr 0.000145531 | gnorm 0.718 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139636
2022-03-08 03:38:45 | INFO | fairseq.trainer | begin training epoch 491
2022-03-08 03:38:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:42:44 | INFO | train_inner | epoch 491:     84 / 97 loss=1.539, nll_loss=0.509, ppl=1.42, wps=22163.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47300, lr=0.000145402, gnorm=0.728, loss_scale=16, train_wall=265, gb_free=8.1, wall=139876
2022-03-08 03:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:43:26 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.467 | nll_loss 13.035 | ppl 8390.69 | wps 42929.8 | wpb 510.9 | bsz 1 | num_updates 47313 | best_loss 7.981
2022-03-08 03:43:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 47313 updates
2022-03-08 03:43:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:43:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:43:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 491 @ 47313 updates, score 13.467) (writing took 2.3019880861975253 seconds)
2022-03-08 03:43:29 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-08 03:43:29 | INFO | train | epoch 491 | loss 1.54 | nll_loss 0.51 | ppl 1.42 | wps 22357.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47313 | lr 0.000145382 | gnorm 0.727 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139921
2022-03-08 03:43:29 | INFO | fairseq.trainer | begin training epoch 492
2022-03-08 03:43:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:47:37 | INFO | train_inner | epoch 492:     87 / 97 loss=1.539, nll_loss=0.51, ppl=1.42, wps=22370.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=47400, lr=0.000145248, gnorm=0.714, loss_scale=32, train_wall=263, gb_free=8.1, wall=140169
2022-03-08 03:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:48:11 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.507 | nll_loss 13.078 | ppl 8646.05 | wps 42931.9 | wpb 510.9 | bsz 1 | num_updates 47410 | best_loss 7.981
2022-03-08 03:48:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 47410 updates
2022-03-08 03:48:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:48:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:48:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 492 @ 47410 updates, score 13.507) (writing took 2.2712148120626807 seconds)
2022-03-08 03:48:13 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-08 03:48:13 | INFO | train | epoch 492 | loss 1.538 | nll_loss 0.509 | ppl 1.42 | wps 22358.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47410 | lr 0.000145233 | gnorm 0.715 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 140205
2022-03-08 03:48:13 | INFO | fairseq.trainer | begin training epoch 493
2022-03-08 03:48:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:48:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:52:32 | INFO | train_inner | epoch 493:     91 / 97 loss=1.539, nll_loss=0.509, ppl=1.42, wps=22168, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47500, lr=0.000145095, gnorm=0.728, loss_scale=16, train_wall=265, gb_free=8.1, wall=140464
2022-03-08 03:52:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:52:55 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.516 | nll_loss 13.087 | ppl 8701.65 | wps 42761.3 | wpb 510.9 | bsz 1 | num_updates 47506 | best_loss 7.981
2022-03-08 03:52:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 47506 updates
2022-03-08 03:52:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:52:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:52:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 493 @ 47506 updates, score 13.516) (writing took 2.3889295789413154 seconds)
2022-03-08 03:52:57 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-08 03:52:57 | INFO | train | epoch 493 | loss 1.538 | nll_loss 0.509 | ppl 1.42 | wps 22126.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47506 | lr 0.000145086 | gnorm 0.726 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 140489
2022-03-08 03:52:57 | INFO | fairseq.trainer | begin training epoch 494
2022-03-08 03:52:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:55:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:57:28 | INFO | train_inner | epoch 494:     95 / 97 loss=1.537, nll_loss=0.508, ppl=1.42, wps=22142.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47600, lr=0.000144943, gnorm=0.727, loss_scale=16, train_wall=265, gb_free=8.1, wall=140760
2022-03-08 03:57:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:57:39 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.462 | nll_loss 13.03 | ppl 8362.89 | wps 43092.5 | wpb 510.9 | bsz 1 | num_updates 47602 | best_loss 7.981
2022-03-08 03:57:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 47602 updates
2022-03-08 03:57:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:57:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:57:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 494 @ 47602 updates, score 13.462) (writing took 2.2778473990038037 seconds)
2022-03-08 03:57:41 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-08 03:57:41 | INFO | train | epoch 494 | loss 1.537 | nll_loss 0.507 | ppl 1.42 | wps 22118.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47602 | lr 0.00014494 | gnorm 0.728 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 140773
2022-03-08 03:57:41 | INFO | fairseq.trainer | begin training epoch 495
2022-03-08 03:57:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:02:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:02:23 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 13.531 | nll_loss 13.102 | ppl 8789.16 | wps 42589.2 | wpb 510.9 | bsz 1 | num_updates 47699 | best_loss 7.981
2022-03-08 04:02:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 47699 updates
2022-03-08 04:02:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:02:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:02:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 495 @ 47699 updates, score 13.531) (writing took 2.315601081587374 seconds)
2022-03-08 04:02:26 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-08 04:02:26 | INFO | train | epoch 495 | loss 1.536 | nll_loss 0.507 | ppl 1.42 | wps 22339.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47699 | lr 0.000144792 | gnorm 0.711 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 141057
2022-03-08 04:02:26 | INFO | fairseq.trainer | begin training epoch 496
2022-03-08 04:02:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:02:28 | INFO | train_inner | epoch 496:      1 / 97 loss=1.536, nll_loss=0.507, ppl=1.42, wps=21799.8, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=47700, lr=0.000144791, gnorm=0.711, loss_scale=32, train_wall=263, gb_free=8.1, wall=141060
2022-03-08 04:06:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:07:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:07:08 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.491 | nll_loss 13.063 | ppl 8560.55 | wps 42992.6 | wpb 510.9 | bsz 1 | num_updates 47795 | best_loss 7.981
2022-03-08 04:07:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 47795 updates
2022-03-08 04:07:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:07:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:07:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 496 @ 47795 updates, score 13.491) (writing took 2.30384981026873 seconds)
2022-03-08 04:07:10 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-08 04:07:10 | INFO | train | epoch 496 | loss 1.536 | nll_loss 0.507 | ppl 1.42 | wps 22117.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47795 | lr 0.000144647 | gnorm 0.72 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 141342
2022-03-08 04:07:10 | INFO | fairseq.trainer | begin training epoch 497
2022-03-08 04:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:07:24 | INFO | train_inner | epoch 497:      5 / 97 loss=1.536, nll_loss=0.506, ppl=1.42, wps=22149.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47800, lr=0.000144639, gnorm=0.72, loss_scale=16, train_wall=265, gb_free=8.1, wall=141356
2022-03-08 04:11:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:11:52 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.451 | nll_loss 13.018 | ppl 8295.1 | wps 43045.5 | wpb 510.9 | bsz 1 | num_updates 47892 | best_loss 7.981
2022-03-08 04:11:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 47892 updates
2022-03-08 04:11:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:11:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:11:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 497 @ 47892 updates, score 13.451) (writing took 2.3275012858211994 seconds)
2022-03-08 04:11:54 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-08 04:11:54 | INFO | train | epoch 497 | loss 1.535 | nll_loss 0.505 | ppl 1.42 | wps 22331.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47892 | lr 0.0001445 | gnorm 0.719 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 141626
2022-03-08 04:11:54 | INFO | fairseq.trainer | begin training epoch 498
2022-03-08 04:11:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:12:17 | INFO | train_inner | epoch 498:      8 / 97 loss=1.535, nll_loss=0.505, ppl=1.42, wps=22351.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47900, lr=0.000144488, gnorm=0.719, loss_scale=16, train_wall=263, gb_free=8.1, wall=141649
2022-03-08 04:14:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:16:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:16:36 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.461 | nll_loss 13.028 | ppl 8354.8 | wps 43228.7 | wpb 510.9 | bsz 1 | num_updates 47988 | best_loss 7.981
2022-03-08 04:16:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 47988 updates
2022-03-08 04:16:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:16:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:16:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 498 @ 47988 updates, score 13.461) (writing took 2.357148720882833 seconds)
2022-03-08 04:16:38 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-08 04:16:38 | INFO | train | epoch 498 | loss 1.536 | nll_loss 0.506 | ppl 1.42 | wps 22149 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47988 | lr 0.000144356 | gnorm 0.717 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 141910
2022-03-08 04:16:38 | INFO | fairseq.trainer | begin training epoch 499
2022-03-08 04:16:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:17:12 | INFO | train_inner | epoch 499:     12 / 97 loss=1.535, nll_loss=0.506, ppl=1.42, wps=22184.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48000, lr=0.000144338, gnorm=0.715, loss_scale=16, train_wall=265, gb_free=8.1, wall=141944
2022-03-08 04:20:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:21:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:21:20 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.521 | nll_loss 13.094 | ppl 8742.83 | wps 42958.5 | wpb 510.9 | bsz 1 | num_updates 48084 | best_loss 7.981
2022-03-08 04:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 48084 updates
2022-03-08 04:21:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:21:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:21:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 499 @ 48084 updates, score 13.521) (writing took 2.3683701590634882 seconds)
2022-03-08 04:21:22 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-08 04:21:22 | INFO | train | epoch 499 | loss 1.534 | nll_loss 0.505 | ppl 1.42 | wps 22147.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48084 | lr 0.000144211 | gnorm 0.717 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 142194
2022-03-08 04:21:22 | INFO | fairseq.trainer | begin training epoch 500
2022-03-08 04:21:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:22:08 | INFO | train_inner | epoch 500:     16 / 97 loss=1.534, nll_loss=0.505, ppl=1.42, wps=22182, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48100, lr=0.000144187, gnorm=0.718, loss_scale=16, train_wall=265, gb_free=8.1, wall=142240
2022-03-08 04:25:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:26:03 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.514 | nll_loss 13.085 | ppl 8686.38 | wps 42745.3 | wpb 510.9 | bsz 1 | num_updates 48181 | best_loss 7.981
2022-03-08 04:26:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 48181 updates
2022-03-08 04:26:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:26:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:26:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 500 @ 48181 updates, score 13.514) (writing took 2.409296619705856 seconds)
2022-03-08 04:26:06 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-08 04:26:06 | INFO | train | epoch 500 | loss 1.534 | nll_loss 0.505 | ppl 1.42 | wps 22377.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48181 | lr 0.000144066 | gnorm 0.723 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 142478
2022-03-08 04:26:06 | INFO | fairseq.trainer | begin training epoch 501
2022-03-08 04:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:27:00 | INFO | train_inner | epoch 501:     19 / 97 loss=1.534, nll_loss=0.504, ppl=1.42, wps=22393.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48200, lr=0.000144038, gnorm=0.724, loss_scale=16, train_wall=262, gb_free=8.1, wall=142532
2022-03-08 04:29:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:30:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:30:48 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.511 | nll_loss 13.085 | ppl 8689.33 | wps 43274.7 | wpb 510.9 | bsz 1 | num_updates 48277 | best_loss 7.981
2022-03-08 04:30:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 48277 updates
2022-03-08 04:30:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:30:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:30:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 501 @ 48277 updates, score 13.511) (writing took 2.346009099856019 seconds)
2022-03-08 04:30:50 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-08 04:30:50 | INFO | train | epoch 501 | loss 1.534 | nll_loss 0.505 | ppl 1.42 | wps 22138.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48277 | lr 0.000143923 | gnorm 0.721 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 142762
2022-03-08 04:30:50 | INFO | fairseq.trainer | begin training epoch 502
2022-03-08 04:30:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:31:55 | INFO | train_inner | epoch 502:     23 / 97 loss=1.533, nll_loss=0.504, ppl=1.42, wps=22180.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48300, lr=0.000143889, gnorm=0.717, loss_scale=16, train_wall=265, gb_free=8.1, wall=142827
2022-03-08 04:35:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:35:31 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.513 | nll_loss 13.083 | ppl 8676.12 | wps 43043.4 | wpb 510.9 | bsz 1 | num_updates 48374 | best_loss 7.981
2022-03-08 04:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 48374 updates
2022-03-08 04:35:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:35:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 502 @ 48374 updates, score 13.513) (writing took 2.382572944276035 seconds)
2022-03-08 04:35:34 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-08 04:35:34 | INFO | train | epoch 502 | loss 1.533 | nll_loss 0.504 | ppl 1.42 | wps 22396.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48374 | lr 0.000143779 | gnorm 0.713 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 143045
2022-03-08 04:35:34 | INFO | fairseq.trainer | begin training epoch 503
2022-03-08 04:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:36:48 | INFO | train_inner | epoch 503:     26 / 97 loss=1.533, nll_loss=0.504, ppl=1.42, wps=22404.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48400, lr=0.00014374, gnorm=0.713, loss_scale=32, train_wall=262, gb_free=8.1, wall=143120
2022-03-08 04:39:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:40:15 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.478 | nll_loss 13.046 | ppl 8455.76 | wps 43306.8 | wpb 510.9 | bsz 1 | num_updates 48470 | best_loss 7.981
2022-03-08 04:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 48470 updates
2022-03-08 04:40:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:40:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:40:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 503 @ 48470 updates, score 13.478) (writing took 2.435536160133779 seconds)
2022-03-08 04:40:18 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-08 04:40:18 | INFO | train | epoch 503 | loss 1.533 | nll_loss 0.504 | ppl 1.42 | wps 22138.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48470 | lr 0.000143636 | gnorm 0.717 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 143329
2022-03-08 04:40:18 | INFO | fairseq.trainer | begin training epoch 504
2022-03-08 04:40:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:41:43 | INFO | train_inner | epoch 504:     30 / 97 loss=1.533, nll_loss=0.504, ppl=1.42, wps=22178.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48500, lr=0.000143592, gnorm=0.721, loss_scale=16, train_wall=265, gb_free=8.1, wall=143415
2022-03-08 04:44:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:44:59 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.517 | nll_loss 13.088 | ppl 8708.3 | wps 42683.1 | wpb 510.9 | bsz 1 | num_updates 48567 | best_loss 7.981
2022-03-08 04:44:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 48567 updates
2022-03-08 04:44:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:45:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:45:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 504 @ 48567 updates, score 13.517) (writing took 2.419673691969365 seconds)
2022-03-08 04:45:01 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-08 04:45:01 | INFO | train | epoch 504 | loss 1.533 | nll_loss 0.504 | ppl 1.42 | wps 22383 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48567 | lr 0.000143493 | gnorm 0.726 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 143613
2022-03-08 04:45:01 | INFO | fairseq.trainer | begin training epoch 505
2022-03-08 04:45:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:46:35 | INFO | train_inner | epoch 505:     33 / 97 loss=1.532, nll_loss=0.503, ppl=1.42, wps=22395.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48600, lr=0.000143444, gnorm=0.72, loss_scale=32, train_wall=262, gb_free=8.1, wall=143707
2022-03-08 04:49:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:49:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:49:43 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.515 | nll_loss 13.088 | ppl 8705.44 | wps 42918.9 | wpb 510.9 | bsz 1 | num_updates 48663 | best_loss 7.981
2022-03-08 04:49:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 48663 updates
2022-03-08 04:49:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:49:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:49:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 505 @ 48663 updates, score 13.515) (writing took 2.3780083707533777 seconds)
2022-03-08 04:49:45 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-08 04:49:45 | INFO | train | epoch 505 | loss 1.531 | nll_loss 0.502 | ppl 1.42 | wps 22143.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48663 | lr 0.000143351 | gnorm 0.715 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 143897
2022-03-08 04:49:45 | INFO | fairseq.trainer | begin training epoch 506
2022-03-08 04:49:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:51:31 | INFO | train_inner | epoch 506:     37 / 97 loss=1.531, nll_loss=0.502, ppl=1.42, wps=22184.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=48700, lr=0.000143296, gnorm=0.715, loss_scale=16, train_wall=265, gb_free=8.1, wall=144003
2022-03-08 04:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:54:27 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.429 | nll_loss 12.998 | ppl 8178.62 | wps 43065.4 | wpb 510.9 | bsz 1 | num_updates 48760 | best_loss 7.981
2022-03-08 04:54:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 48760 updates
2022-03-08 04:54:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:54:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:54:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 506 @ 48760 updates, score 13.429) (writing took 2.405238145031035 seconds)
2022-03-08 04:54:29 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-08 04:54:29 | INFO | train | epoch 506 | loss 1.531 | nll_loss 0.502 | ppl 1.42 | wps 22382.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48760 | lr 0.000143208 | gnorm 0.712 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 144181
2022-03-08 04:54:29 | INFO | fairseq.trainer | begin training epoch 507
2022-03-08 04:54:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:56:23 | INFO | train_inner | epoch 507:     40 / 97 loss=1.531, nll_loss=0.502, ppl=1.42, wps=22394.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48800, lr=0.00014315, gnorm=0.71, loss_scale=32, train_wall=262, gb_free=8.1, wall=144295
2022-03-08 04:57:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:59:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:59:11 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.498 | nll_loss 13.068 | ppl 8588.1 | wps 42544.5 | wpb 510.9 | bsz 1 | num_updates 48856 | best_loss 7.981
2022-03-08 04:59:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 48856 updates
2022-03-08 04:59:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:59:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:59:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 507 @ 48856 updates, score 13.498) (writing took 2.3486657473258674 seconds)
2022-03-08 04:59:13 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-08 04:59:13 | INFO | train | epoch 507 | loss 1.531 | nll_loss 0.502 | ppl 1.42 | wps 22153.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48856 | lr 0.000143068 | gnorm 0.717 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 144465
2022-03-08 04:59:13 | INFO | fairseq.trainer | begin training epoch 508
2022-03-08 04:59:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:01:18 | INFO | train_inner | epoch 508:     44 / 97 loss=1.53, nll_loss=0.501, ppl=1.42, wps=22195.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48900, lr=0.000143003, gnorm=0.722, loss_scale=16, train_wall=265, gb_free=8.1, wall=144590
2022-03-08 05:03:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:03:54 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.563 | nll_loss 13.138 | ppl 9016.58 | wps 42830.7 | wpb 510.9 | bsz 1 | num_updates 48953 | best_loss 7.981
2022-03-08 05:03:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 48953 updates
2022-03-08 05:03:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:03:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:03:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 508 @ 48953 updates, score 13.563) (writing took 2.3925988767296076 seconds)
2022-03-08 05:03:57 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-08 05:03:57 | INFO | train | epoch 508 | loss 1.53 | nll_loss 0.501 | ppl 1.42 | wps 22387 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48953 | lr 0.000142926 | gnorm 0.719 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 144749
2022-03-08 05:03:57 | INFO | fairseq.trainer | begin training epoch 509
2022-03-08 05:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:06:11 | INFO | train_inner | epoch 509:     47 / 97 loss=1.531, nll_loss=0.502, ppl=1.42, wps=22395.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=49000, lr=0.000142857, gnorm=0.721, loss_scale=32, train_wall=262, gb_free=8.1, wall=144883
2022-03-08 05:06:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:08:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:08:38 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.467 | nll_loss 13.036 | ppl 8401.73 | wps 42850 | wpb 510.9 | bsz 1 | num_updates 49049 | best_loss 7.981
2022-03-08 05:08:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 49049 updates
2022-03-08 05:08:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:08:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:08:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 509 @ 49049 updates, score 13.467) (writing took 2.396959674078971 seconds)
2022-03-08 05:08:40 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-08 05:08:40 | INFO | train | epoch 509 | loss 1.53 | nll_loss 0.501 | ppl 1.42 | wps 22157.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49049 | lr 0.000142786 | gnorm 0.716 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 145032
2022-03-08 05:08:40 | INFO | fairseq.trainer | begin training epoch 510
2022-03-08 05:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:11:06 | INFO | train_inner | epoch 510:     51 / 97 loss=1.529, nll_loss=0.5, ppl=1.41, wps=22202.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49100, lr=0.000142712, gnorm=0.717, loss_scale=16, train_wall=265, gb_free=8.1, wall=145178
2022-03-08 05:13:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:13:22 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.529 | nll_loss 13.101 | ppl 8787.68 | wps 43174 | wpb 510.9 | bsz 1 | num_updates 49146 | best_loss 7.981
2022-03-08 05:13:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 49146 updates
2022-03-08 05:13:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:13:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:13:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 510 @ 49146 updates, score 13.529) (writing took 2.312011439818889 seconds)
2022-03-08 05:13:24 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-08 05:13:24 | INFO | train | epoch 510 | loss 1.529 | nll_loss 0.5 | ppl 1.41 | wps 22402.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49146 | lr 0.000142645 | gnorm 0.718 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 145316
2022-03-08 05:13:24 | INFO | fairseq.trainer | begin training epoch 511
2022-03-08 05:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:15:58 | INFO | train_inner | epoch 511:     54 / 97 loss=1.529, nll_loss=0.5, ppl=1.41, wps=22401.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49200, lr=0.000142566, gnorm=0.714, loss_scale=32, train_wall=262, gb_free=8.1, wall=145470
2022-03-08 05:17:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:18:06 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.503 | nll_loss 13.075 | ppl 8630.93 | wps 42823.9 | wpb 510.9 | bsz 1 | num_updates 49242 | best_loss 7.981
2022-03-08 05:18:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 49242 updates
2022-03-08 05:18:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:18:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:18:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 511 @ 49242 updates, score 13.503) (writing took 2.2544475169852376 seconds)
2022-03-08 05:18:08 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-08 05:18:08 | INFO | train | epoch 511 | loss 1.528 | nll_loss 0.5 | ppl 1.41 | wps 22150.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49242 | lr 0.000142506 | gnorm 0.715 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 145600
2022-03-08 05:18:08 | INFO | fairseq.trainer | begin training epoch 512
2022-03-08 05:18:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:20:53 | INFO | train_inner | epoch 512:     58 / 97 loss=1.528, nll_loss=0.499, ppl=1.41, wps=22166.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=49300, lr=0.000142422, gnorm=0.716, loss_scale=16, train_wall=265, gb_free=8.1, wall=145765
2022-03-08 05:22:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:22:50 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.493 | nll_loss 13.062 | ppl 8550.71 | wps 42684.8 | wpb 510.9 | bsz 1 | num_updates 49339 | best_loss 7.981
2022-03-08 05:22:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 49339 updates
2022-03-08 05:22:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:22:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:22:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 512 @ 49339 updates, score 13.493) (writing took 2.2255373899824917 seconds)
2022-03-08 05:22:52 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-08 05:22:52 | INFO | train | epoch 512 | loss 1.528 | nll_loss 0.5 | ppl 1.41 | wps 22368.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49339 | lr 0.000142366 | gnorm 0.719 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 145884
2022-03-08 05:22:52 | INFO | fairseq.trainer | begin training epoch 513
2022-03-08 05:22:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:25:46 | INFO | train_inner | epoch 513:     61 / 97 loss=1.527, nll_loss=0.499, ppl=1.41, wps=22425.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49400, lr=0.000142278, gnorm=0.717, loss_scale=32, train_wall=262, gb_free=8.1, wall=146057
2022-03-08 05:27:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:27:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:27:33 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.494 | nll_loss 13.063 | ppl 8560.44 | wps 42906.9 | wpb 510.9 | bsz 1 | num_updates 49435 | best_loss 7.981
2022-03-08 05:27:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 49435 updates
2022-03-08 05:27:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:27:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:27:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 513 @ 49435 updates, score 13.494) (writing took 2.3072767183184624 seconds)
2022-03-08 05:27:35 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-08 05:27:35 | INFO | train | epoch 513 | loss 1.528 | nll_loss 0.499 | ppl 1.41 | wps 22174.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49435 | lr 0.000142227 | gnorm 0.715 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 146167
2022-03-08 05:27:35 | INFO | fairseq.trainer | begin training epoch 514
2022-03-08 05:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:30:41 | INFO | train_inner | epoch 514:     65 / 97 loss=1.528, nll_loss=0.5, ppl=1.41, wps=22191.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49500, lr=0.000142134, gnorm=0.719, loss_scale=16, train_wall=265, gb_free=8.1, wall=146353
2022-03-08 05:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:32:17 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.528 | nll_loss 13.101 | ppl 8784.96 | wps 42768.8 | wpb 510.9 | bsz 1 | num_updates 49532 | best_loss 7.981
2022-03-08 05:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 49532 updates
2022-03-08 05:32:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 514 @ 49532 updates, score 13.528) (writing took 2.2829965841956437 seconds)
2022-03-08 05:32:19 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-08 05:32:19 | INFO | train | epoch 514 | loss 1.527 | nll_loss 0.498 | ppl 1.41 | wps 22381 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49532 | lr 0.000142088 | gnorm 0.715 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 146451
2022-03-08 05:32:19 | INFO | fairseq.trainer | begin training epoch 515
2022-03-08 05:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:35:33 | INFO | train_inner | epoch 515:     68 / 97 loss=1.527, nll_loss=0.499, ppl=1.41, wps=22403.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=49600, lr=0.00014199, gnorm=0.709, loss_scale=32, train_wall=262, gb_free=8.1, wall=146645
2022-03-08 05:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:37:01 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.497 | nll_loss 13.067 | ppl 8580 | wps 42732.1 | wpb 510.9 | bsz 1 | num_updates 49629 | best_loss 7.981
2022-03-08 05:37:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 49629 updates
2022-03-08 05:37:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:37:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:37:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 515 @ 49629 updates, score 13.497) (writing took 2.2637777226045728 seconds)
2022-03-08 05:37:03 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-08 05:37:03 | INFO | train | epoch 515 | loss 1.527 | nll_loss 0.498 | ppl 1.41 | wps 22383.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49629 | lr 0.000141949 | gnorm 0.712 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 146735
2022-03-08 05:37:03 | INFO | fairseq.trainer | begin training epoch 516
2022-03-08 05:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:38:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:40:28 | INFO | train_inner | epoch 516:     72 / 97 loss=1.525, nll_loss=0.496, ppl=1.41, wps=22169.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49700, lr=0.000141848, gnorm=0.714, loss_scale=16, train_wall=265, gb_free=8.1, wall=146940
2022-03-08 05:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:41:45 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.46 | nll_loss 13.029 | ppl 8356.56 | wps 42968.2 | wpb 510.9 | bsz 1 | num_updates 49725 | best_loss 7.981
2022-03-08 05:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 49725 updates
2022-03-08 05:41:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:41:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:41:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 516 @ 49725 updates, score 13.46) (writing took 2.2947473148815334 seconds)
2022-03-08 05:41:47 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-08 05:41:47 | INFO | train | epoch 516 | loss 1.525 | nll_loss 0.496 | ppl 1.41 | wps 22139.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49725 | lr 0.000141812 | gnorm 0.713 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 147019
2022-03-08 05:41:47 | INFO | fairseq.trainer | begin training epoch 517
2022-03-08 05:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:45:21 | INFO | train_inner | epoch 517:     75 / 97 loss=1.527, nll_loss=0.498, ppl=1.41, wps=22389, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49800, lr=0.000141705, gnorm=0.714, loss_scale=32, train_wall=262, gb_free=8.1, wall=147233
2022-03-08 05:46:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:46:29 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.514 | nll_loss 13.086 | ppl 8692.93 | wps 42846.6 | wpb 510.9 | bsz 1 | num_updates 49822 | best_loss 7.981
2022-03-08 05:46:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 49822 updates
2022-03-08 05:46:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:46:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:46:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 517 @ 49822 updates, score 13.514) (writing took 2.295298459008336 seconds)
2022-03-08 05:46:31 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-08 05:46:31 | INFO | train | epoch 517 | loss 1.527 | nll_loss 0.498 | ppl 1.41 | wps 22370.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49822 | lr 0.000141674 | gnorm 0.713 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 147303
2022-03-08 05:46:31 | INFO | fairseq.trainer | begin training epoch 518
2022-03-08 05:46:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:46:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:50:16 | INFO | train_inner | epoch 518:     79 / 97 loss=1.526, nll_loss=0.497, ppl=1.41, wps=22170.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49900, lr=0.000141563, gnorm=0.713, loss_scale=16, train_wall=265, gb_free=8.1, wall=147528
2022-03-08 05:51:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:51:13 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.506 | nll_loss 13.079 | ppl 8650.75 | wps 42907.4 | wpb 510.9 | bsz 1 | num_updates 49918 | best_loss 7.981
2022-03-08 05:51:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 49918 updates
2022-03-08 05:51:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:51:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:51:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 518 @ 49918 updates, score 13.506) (writing took 2.2949238177388906 seconds)
2022-03-08 05:51:15 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-08 05:51:15 | INFO | train | epoch 518 | loss 1.525 | nll_loss 0.496 | ppl 1.41 | wps 22140.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49918 | lr 0.000141537 | gnorm 0.712 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 147587
2022-03-08 05:51:15 | INFO | fairseq.trainer | begin training epoch 519
2022-03-08 05:51:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:55:08 | INFO | train_inner | epoch 519:     82 / 97 loss=1.525, nll_loss=0.496, ppl=1.41, wps=22485.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=50000, lr=0.000141421, gnorm=0.713, loss_scale=32, train_wall=261, gb_free=8.1, wall=147819
2022-03-08 05:55:08 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 05:55:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:55:13 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.476 | nll_loss 13.047 | ppl 8464.38 | wps 43530.8 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 7.981
2022-03-08 05:55:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 50000 updates
2022-03-08 05:55:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:55:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 05:55:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 519 @ 50000 updates, score 13.476) (writing took 2.249539675656706 seconds)
2022-03-08 05:55:15 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-08 05:55:15 | INFO | train | epoch 519 | loss 1.522 | nll_loss 0.493 | ppl 1.41 | wps 22393.2 | ups 0.34 | wpb 65533.4 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.71 | loss_scale 32 | train_wall 214 | gb_free 8.1 | wall 147827
2022-03-08 05:55:15 | INFO | fairseq_cli.train | done training in 147826.6 seconds
