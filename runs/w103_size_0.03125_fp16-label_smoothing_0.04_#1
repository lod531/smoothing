Sender: LSF System <lsfadmin@eu-g3-067>
Subject: Job 207263905: <w103_size_0.03125_fp16_label_smoothing_0.04_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.04_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:18:14 2022
Job was executed on host(s) <eu-g3-067>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:18:45 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:18:45 2022
Terminated at Sat Mar  5 14:18:54 2022
Results reported at Sat Mar  5 14:18:54 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.04 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   3.63 sec.
    Max Memory :                                 367 MB
    Average Memory :                             361.33 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               19633.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   9 sec.
    Turnaround time :                            40 sec.

The output (if any) follows:

2022-03-05 14:18:54 | ERROR | fairseq.dataclass.utils | Error when composing. Overrides: ['common.no_progress_bar=False', 'common.log_interval=100', 'common.log_format=null', 'common.log_file=null', 'common.tensorboard_logdir=null', 'common.wandb_project=null', 'common.azureml_logging=False', 'common.seed=66575611', 'common.cpu=False', 'common.tpu=False', 'common.bf16=False', 'common.memory_efficient_bf16=False', 'common.fp16=True', 'common.memory_efficient_fp16=False', 'common.fp16_no_flatten_grads=False', 'common.fp16_init_scale=128', 'common.fp16_scale_window=null', 'common.fp16_scale_tolerance=0.0', 'common.on_cpu_convert_precision=False', 'common.min_loss_scale=0.0001', 'common.threshold_loss_scale=null', 'common.amp=False', 'common.amp_batch_retries=2', 'common.amp_init_scale=128', 'common.amp_scale_window=null', 'common.user_dir=null', 'common.empty_cache_freq=0', 'common.all_gather_list_size=16384', 'common.model_parallel_size=1', 'common.quantization_config_path=null', 'common.profile=False', 'common.reset_logging=False', 'common.suppress_crashes=False', 'common.use_plasma_view=False', "common.plasma_path='/tmp/plasma'", 'common_eval.path=null', 'common_eval.post_process=null', 'common_eval.quiet=False', "common_eval.model_overrides='{}'", 'common_eval.results_path=null', 'distributed_training.distributed_world_size=1', 'distributed_training.distributed_num_procs=1', 'distributed_training.distributed_rank=0', "distributed_training.distributed_backend='nccl'", 'distributed_training.distributed_init_method=null', 'distributed_training.distributed_port=-1', 'distributed_training.device_id=0', 'distributed_training.distributed_no_spawn=False', "distributed_training.ddp_backend='pytorch_ddp'", "distributed_training.ddp_comm_hook='none'", 'distributed_training.bucket_cap_mb=25', 'distributed_training.fix_batches_to_gpus=False', 'distributed_training.find_unused_parameters=False', 'distributed_training.gradient_as_bucket_view=False', 'distributed_training.fast_stat_sync=False', 'distributed_training.heartbeat_timeout=-1', 'distributed_training.broadcast_buffers=False', 'distributed_training.slowmo_momentum=null', "distributed_training.slowmo_algorithm='LocalSGD'", 'distributed_training.localsgd_frequency=3', 'distributed_training.nprocs_per_node=1', 'distributed_training.pipeline_model_parallel=False', 'distributed_training.pipeline_balance=null', 'distributed_training.pipeline_devices=null', 'distributed_training.pipeline_chunks=0', 'distributed_training.pipeline_encoder_balance=null', 'distributed_training.pipeline_encoder_devices=null', 'distributed_training.pipeline_decoder_balance=null', 'distributed_training.pipeline_decoder_devices=null', "distributed_training.pipeline_checkpoint='never'", "distributed_training.zero_sharding='none'", 'distributed_training.fp16=True', 'distributed_training.memory_efficient_fp16=False', 'distributed_training.tpu=False', 'distributed_training.no_reshard_after_forward=False', 'distributed_training.fp32_reduce_scatter=False', 'distributed_training.cpu_offload=False', 'distributed_training.use_sharded_state=False', 'dataset.num_workers=1', 'dataset.skip_invalid_size_inputs_valid_test=False', 'dataset.max_tokens=512', 'dataset.batch_size=null', 'dataset.required_batch_size_multiple=8', 'dataset.required_seq_len_multiple=1', 'dataset.dataset_impl=null', 'dataset.data_buffer_size=10', "dataset.train_subset='train'", "dataset.valid_subset='valid'", 'dataset.combine_valid_subsets=null', 'dataset.ignore_unused_valid_subsets=False', 'dataset.validate_interval=1', 'dataset.validate_interval_updates=0', 'dataset.validate_after_updates=0', 'dataset.fixed_validation_seed=null', 'dataset.disable_validation=False', 'dataset.max_tokens_valid=512', 'dataset.batch_size_valid=null', 'dataset.max_valid_steps=null', 'dataset.curriculum=0', "dataset.gen_subset='test'", 'dataset.num_shards=1', 'dataset.shard_id=0', 'optimization.max_epoch=0', 'optimization.max_update=50000', 'optimization.stop_time_hours=0.0', 'optimization.clip_norm=0.0', 'optimization.sentence_avg=False', 'optimization.update_freq=[128]', 'optimization.lr=[0.0005]', 'optimization.stop_min_lr=-1.0', 'optimization.use_bmuf=False', "checkpoint.save_dir='/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1'", "checkpoint.restore_file='checkpoint_last.pt'", 'checkpoint.finetune_from_model=null', 'checkpoint.reset_dataloader=False', 'checkpoint.reset_lr_scheduler=False', 'checkpoint.reset_meters=False', 'checkpoint.reset_optimizer=False', "checkpoint.optimizer_overrides='{}'", 'checkpoint.save_interval=1', 'checkpoint.save_interval_updates=0', 'checkpoint.keep_interval_updates=-1', 'checkpoint.keep_interval_updates_pattern=-1', 'checkpoint.keep_last_epochs=-1', 'checkpoint.keep_best_checkpoints=-1', 'checkpoint.no_save=False', 'checkpoint.no_epoch_checkpoints=True', 'checkpoint.no_last_checkpoints=False', 'checkpoint.no_save_optimizer_state=False', "checkpoint.best_checkpoint_metric='loss'", 'checkpoint.maximize_best_checkpoint_metric=False', 'checkpoint.patience=-1', "checkpoint.checkpoint_suffix=''", 'checkpoint.checkpoint_shard_count=1', 'checkpoint.load_checkpoint_on_all_dp_ranks=False', 'checkpoint.write_checkpoints_asynchronously=False', 'checkpoint.model_parallel_size=1', 'bmuf.block_lr=1.0', 'bmuf.block_momentum=0.875', 'bmuf.global_sync_iter=50', 'bmuf.warmup_iterations=500', 'bmuf.use_nbm=False', 'bmuf.average_sync=False', 'bmuf.distributed_world_size=1', 'generation.beam=5', 'generation.nbest=1', 'generation.max_len_a=0.0', 'generation.max_len_b=200', 'generation.min_len=1', 'generation.match_source_len=False', 'generation.unnormalized=False', 'generation.no_early_stop=False', 'generation.no_beamable_mm=False', 'generation.lenpen=1.0', 'generation.unkpen=0.0', 'generation.replace_unk=null', 'generation.sacrebleu=False', 'generation.score_reference=False', 'generation.prefix_size=0', 'generation.no_repeat_ngram_size=0', 'generation.sampling=False', 'generation.sampling_topk=-1', 'generation.sampling_topp=-1.0', 'generation.constraints=null', 'generation.temperature=1.0', 'generation.diverse_beam_groups=-1', 'generation.diverse_beam_strength=0.5', 'generation.diversity_rate=-1.0', 'generation.print_alignment=null', 'generation.print_step=False', 'generation.lm_path=null', 'generation.lm_weight=0.0', 'generation.iter_decode_eos_penalty=0.0', 'generation.iter_decode_max_iter=10', 'generation.iter_decode_force_max_iter=False', 'generation.iter_decode_with_beam=1', 'generation.iter_decode_with_external_reranker=False', 'generation.retain_iter_history=False', 'generation.retain_dropout=False', 'generation.retain_dropout_modules=null', 'generation.decoding_format=null', 'generation.no_seed_provided=False', 'eval_lm.output_word_probs=False', 'eval_lm.output_word_stats=False', 'eval_lm.context_window=0', 'eval_lm.softmax_batch=9223372036854775807', 'interactive.buffer_size=0', "interactive.input='-'", 'ema.store_ema=False', 'ema.ema_decay=0.9999', 'ema.ema_start_update=0', 'ema.ema_seed_model=null', 'ema.ema_update_freq=1', 'ema.ema_fp32=False', 'task=language_modeling', 'task._name=language_modeling', "task.data='data-bin/wikitext-103-raw-size-0.0625'", "task.sample_break_mode='none'", 'task.tokens_per_sample=512', 'task.output_dictionary_size=-1', 'task.self_target=False', 'task.future_target=False', 'task.past_target=False', 'task.add_bos_token=False', 'task.max_target_positions=null', "task.shorten_method='none'", "task.shorten_data_split_list=''", 'task.pad_to_fixed_length=False', 'task.pad_to_fixed_bsz=False', 'task.seed=66575611', 'task.batch_size=null', 'task.batch_size_valid=null', 'task.dataset_impl=null', 'task.data_buffer_size=10', 'task.tpu=False', 'task.use_plasma_view=False', "task.plasma_path='/tmp/plasma'", 'criterion=label_smoothed_cross_entropy', 'criterion._name=label_smoothed_cross_entropy', 'criterion.label_smoothing=0.04', 'criterion.report_accuracy=False', 'criterion.ignore_prefix_size=0', 'criterion.sentence_avg=False', 'optimizer=adam', 'optimizer._name=adam', "optimizer.adam_betas='(0.9, 0.98)'", 'optimizer.adam_eps=1e-08', 'optimizer.weight_decay=0.01', 'optimizer.use_old_adam=False', 'optimizer.fp16_adam_stats=False', 'optimizer.tpu=False', 'optimizer.lr=[0.0005]', 'lr_scheduler=inverse_sqrt', 'lr_scheduler._name=inverse_sqrt', 'lr_scheduler.warmup_updates=4000', 'lr_scheduler.warmup_init_lr=1e-07', 'lr_scheduler.lr=[0.0005]', 'scoring=bleu', 'scoring._name=bleu', 'scoring.pad=1', 'scoring.eos=2', 'scoring.unk=3', 'model=transformer_lm', 'model._name=transformer_lm', "model.activation_fn='relu'", 'model.dropout=0.1', 'model.attention_dropout=0.0', 'model.activation_dropout=0.0', 'model.relu_dropout=0.0', 'model.decoder_embed_dim=512', 'model.decoder_output_dim=512', 'model.decoder_input_dim=512', 'model.decoder_ffn_embed_dim=2048', 'model.decoder_layers=6', 'model.decoder_attention_heads=8', 'model.decoder_normalize_before=False', 'model.no_decoder_final_norm=False', 'model.adaptive_softmax_cutoff=null', 'model.adaptive_softmax_dropout=0.0', 'model.adaptive_softmax_factor=4.0', 'model.no_token_positional_embeddings=False', 'model.share_decoder_input_output_embed=True', 'model.character_embeddings=False', "model.character_filters='[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]'", 'model.character_embedding_dim=4', 'model.char_embedder_highway_layers=2', 'model.adaptive_input=False', 'model.adaptive_input_factor=4.0', 'model.adaptive_input_cutoff=null', 'model.tie_adaptive_weights=False', 'model.tie_adaptive_proj=False', 'model.decoder_learned_pos=False', 'model.layernorm_embedding=False', 'model.no_scale_embedding=False', 'model.checkpoint_activations=False', 'model.offload_activations=False', 'model.decoder_layerdrop=0.0', 'model.decoder_layers_to_keep=null', 'model.quant_noise_pq=0.0', 'model.quant_noise_pq_block_size=8', 'model.quant_noise_scalar=0.0', 'model.min_params_to_wrap=100000000', 'model.base_layers=0', 'model.base_sublayers=1', 'model.base_shuffle=1', 'model.scale_fc=False', 'model.scale_attn=False', 'model.scale_heads=False', 'model.scale_resids=False', 'model.add_bos_token=False', 'model.tokens_per_sample=512', 'model.max_target_positions=null', 'model.tpu=False']
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 533, in cli_main
    cfg = convert_namespace_to_omegaconf(args)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/dataclass/utils.py", line 389, in convert_namespace_to_omegaconf
    composed_cfg = compose("config", overrides=overrides, strict=False)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/experimental/compose.py", line 31, in compose
    cfg = gh.hydra.compose_config(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/hydra.py", line 507, in compose_config
    cfg = self.config_loader.load_configuration(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 151, in load_configuration
    return self._load_configuration(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 224, in _load_configuration
    job_cfg, job_cfg_load_trace = self._load_primary_config(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 819, in _load_primary_config
    ret, load_trace = self._load_config_impl(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 614, in _load_config_impl
    schema.config = OmegaConf.merge(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/omegaconf.py", line 321, in merge
    target.merge_with(*others[1:])
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 329, in merge_with
    self._merge_with(*others)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 347, in _merge_with
    BaseContainer._map_merge(self, other)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 312, in _map_merge
    dest[key] = src._get_node(key)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 256, in __setitem__
    self.__set_impl(key=key, value=value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 266, in __set_impl
    self._set_item_impl(key, value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 475, in _set_item_impl
    assign(key, value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 452, in assign
    v = copy.deepcopy(value_to_assign)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/nodes.py", line 273, in __deepcopy__
    self._deepcopy_impl(res, memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/nodes.py", line 76, in _deepcopy_impl
    res.__dict__ = copy.deepcopy(self.__dict__, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 270, in _reconstruct
    state = deepcopy(state, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 229, in _deepcopy_dict
    for key, value in x.items():
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g3-067>
Subject: Job 207264054: <w103_size_0.03125_fp16_label_smoothing_0.04_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.04_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:21:34 2022
Job was executed on host(s) <eu-g3-067>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:21:45 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:21:45 2022
Terminated at Sun Mar  6 08:56:02 2022
Results reported at Sun Mar  6 08:56:02 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.04 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   66789.28 sec.
    Max Memory :                                 7673 MB
    Average Memory :                             4703.37 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               12327.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   66856 sec.
    Turnaround time :                            66868 sec.

The output (if any) follows:

2022-03-05 14:21:52 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.04, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-05 14:21:52 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-05 14:21:54 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-05 14:21:54 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-05 14:21:54 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-05 14:21:54 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-05 14:21:54 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-05 14:21:54 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-05 14:21:54 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-05 14:22:03 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-05 14:22:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:22:03 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-05 14:22:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:22:03 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-05 14:22:03 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-05 14:22:03 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 14:22:03 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 14:22:03 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-05 14:22:03 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-05 14:22:03 | INFO | fairseq.trainer | begin training epoch 1
2022-03-05 14:22:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:22:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-05 14:22:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:22:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:22:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 14:22:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-05 14:24:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:24:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.472 | nll_loss 15.394 | ppl 43058.5 | wps 45857.7 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-05 14:24:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-05 14:24:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:24:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:24:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.472) (writing took 3.7042588591575623 seconds)
2022-03-05 14:24:17 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-05 14:24:17 | INFO | train | epoch 001 | loss 16.558 | nll_loss 16.526 | ppl 94335.6 | wps 26760.3 | ups 0.41 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 4.885 | loss_scale 4 | train_wall 114 | gb_free 21.6 | wall 134
2022-03-05 14:24:17 | INFO | fairseq.trainer | begin training epoch 2
2022-03-05 14:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:26:11 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 14.018 | nll_loss 13.879 | ppl 15065.2 | wps 45723.1 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 14.018
2022-03-05 14:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-05 14:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:26:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 2 @ 93 updates, score 14.018) (writing took 3.816278735175729 seconds)
2022-03-05 14:26:14 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-05 14:26:14 | INFO | train | epoch 002 | loss 14.696 | nll_loss 14.586 | ppl 24589.8 | wps 27068.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.214 | loss_scale 4 | train_wall 98 | gb_free 21.6 | wall 251
2022-03-05 14:26:14 | INFO | fairseq.trainer | begin training epoch 3
2022-03-05 14:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:26:30 | INFO | train_inner | epoch 003:      7 / 49 loss=15.469, nll_loss=15.391, ppl=42962.6, wps=27062.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.342, loss_scale=4, train_wall=226, gb_free=21.6, wall=267
2022-03-05 14:28:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:28:08 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.352 | nll_loss 13.187 | ppl 9325.73 | wps 45832.6 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.352
2022-03-05 14:28:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-05 14:28:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:28:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:28:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.352) (writing took 3.981717520393431 seconds)
2022-03-05 14:28:12 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-05 14:28:12 | INFO | train | epoch 003 | loss 13.76 | nll_loss 13.612 | ppl 12519.2 | wps 26987.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.467 | loss_scale 8 | train_wall 98 | gb_free 21.6 | wall 369
2022-03-05 14:28:12 | INFO | fairseq.trainer | begin training epoch 4
2022-03-05 14:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:30:06 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.516 | nll_loss 12.312 | ppl 5083.97 | wps 45843.5 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.516
2022-03-05 14:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-05 14:30:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:30:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.516) (writing took 3.877384301275015 seconds)
2022-03-05 14:30:10 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-05 14:30:10 | INFO | train | epoch 004 | loss 13.001 | nll_loss 12.821 | ppl 7237.98 | wps 27005 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.258 | loss_scale 8 | train_wall 98 | gb_free 21.6 | wall 487
2022-03-05 14:30:10 | INFO | fairseq.trainer | begin training epoch 5
2022-03-05 14:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:30:30 | INFO | train_inner | epoch 005:      9 / 49 loss=13.251, nll_loss=13.082, ppl=8669.03, wps=27035.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.323, loss_scale=8, train_wall=200, gb_free=21.6, wall=507
2022-03-05 14:31:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:32:04 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.754 | nll_loss 11.509 | ppl 2915.34 | wps 45957.8 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.754
2022-03-05 14:32:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-05 14:32:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:32:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.754) (writing took 3.8492368161678314 seconds)
2022-03-05 14:32:07 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-05 14:32:07 | INFO | train | epoch 005 | loss 12.154 | nll_loss 11.933 | ppl 3909.66 | wps 27019.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.957 | loss_scale 8 | train_wall 98 | gb_free 21.6 | wall 604
2022-03-05 14:32:07 | INFO | fairseq.trainer | begin training epoch 6
2022-03-05 14:32:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:33:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:34:01 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.146 | nll_loss 10.862 | ppl 1861.24 | wps 45890.1 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.146
2022-03-05 14:34:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-05 14:34:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:34:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.146) (writing took 3.8893379168584943 seconds)
2022-03-05 14:34:05 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-05 14:34:05 | INFO | train | epoch 006 | loss 11.437 | nll_loss 11.176 | ppl 2313.87 | wps 27016.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.742 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 722
2022-03-05 14:34:05 | INFO | fairseq.trainer | begin training epoch 7
2022-03-05 14:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:34:30 | INFO | train_inner | epoch 007:     11 / 49 loss=11.651, nll_loss=11.401, ppl=2704.99, wps=27059.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.808, loss_scale=16, train_wall=199, gb_free=21.6, wall=747
2022-03-05 14:35:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:35:59 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.758 | nll_loss 10.441 | ppl 1390.22 | wps 45719.8 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.758
2022-03-05 14:35:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-05 14:35:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:36:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:36:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.758) (writing took 3.8512189546599984 seconds)
2022-03-05 14:36:03 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-05 14:36:03 | INFO | train | epoch 007 | loss 10.908 | nll_loss 10.609 | ppl 1561.48 | wps 26999.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.607 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 840
2022-03-05 14:36:03 | INFO | fairseq.trainer | begin training epoch 8
2022-03-05 14:36:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:37:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:37:57 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.523 | nll_loss 10.179 | ppl 1159.41 | wps 45922.5 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.523
2022-03-05 14:37:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-05 14:37:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:37:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:38:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.523) (writing took 3.8575820988044143 seconds)
2022-03-05 14:38:01 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-05 14:38:01 | INFO | train | epoch 008 | loss 10.583 | nll_loss 10.253 | ppl 1220.09 | wps 26967.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.462 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 957
2022-03-05 14:38:01 | INFO | fairseq.trainer | begin training epoch 9
2022-03-05 14:38:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:38:30 | INFO | train_inner | epoch 009:     13 / 49 loss=10.668, nll_loss=10.347, ppl=1302.22, wps=27020.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.509, loss_scale=32, train_wall=200, gb_free=21.6, wall=987
2022-03-05 14:39:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:39:55 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.349 | nll_loss 9.987 | ppl 1014.74 | wps 46048.7 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.349
2022-03-05 14:39:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-05 14:39:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:39:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:39:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.349) (writing took 3.86315250210464 seconds)
2022-03-05 14:39:59 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-05 14:39:59 | INFO | train | epoch 009 | loss 10.37 | nll_loss 10.017 | ppl 1036.13 | wps 26954.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.497 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 1075
2022-03-05 14:39:59 | INFO | fairseq.trainer | begin training epoch 10
2022-03-05 14:39:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:41:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:41:53 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.188 | nll_loss 9.812 | ppl 898.85 | wps 46028.7 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.188
2022-03-05 14:41:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-05 14:41:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:41:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:41:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.188) (writing took 3.8472624262794852 seconds)
2022-03-05 14:41:57 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-05 14:41:57 | INFO | train | epoch 010 | loss 10.193 | nll_loss 9.823 | ppl 905.91 | wps 26928.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.516 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 1193
2022-03-05 14:41:57 | INFO | fairseq.trainer | begin training epoch 11
2022-03-05 14:41:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:42:30 | INFO | train_inner | epoch 011:     15 / 49 loss=10.233, nll_loss=9.867, ppl=933.6, wps=26983.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.525, loss_scale=32, train_wall=200, gb_free=21.6, wall=1227
2022-03-05 14:43:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:43:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:43:51 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.048 | nll_loss 9.661 | ppl 809.51 | wps 45735.8 | wpb 510.9 | bsz 1 | num_updates 533 | best_loss 10.048
2022-03-05 14:43:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 533 updates
2022-03-05 14:43:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:43:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 11 @ 533 updates, score 10.048) (writing took 3.862637988291681 seconds)
2022-03-05 14:43:54 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-05 14:43:54 | INFO | train | epoch 011 | loss 10.029 | nll_loss 9.647 | ppl 801.72 | wps 26416.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 533 | lr 6.67117e-05 | gnorm 0.551 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 1311
2022-03-05 14:43:54 | INFO | fairseq.trainer | begin training epoch 12
2022-03-05 14:43:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:45:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:45:49 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.907 | nll_loss 9.51 | ppl 729.13 | wps 45699.6 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 9.907
2022-03-05 14:45:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-05 14:45:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:45:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:45:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 12 @ 582 updates, score 9.907) (writing took 3.8787482902407646 seconds)
2022-03-05 14:45:52 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-05 14:45:52 | INFO | train | epoch 012 | loss 9.874 | nll_loss 9.481 | ppl 714.65 | wps 26918.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.621 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 1429
2022-03-05 14:45:52 | INFO | fairseq.trainer | begin training epoch 13
2022-03-05 14:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:46:33 | INFO | train_inner | epoch 013:     18 / 49 loss=9.896, nll_loss=9.505, ppl=726.63, wps=26724.6, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.599, loss_scale=32, train_wall=202, gb_free=21.6, wall=1470
2022-03-05 14:47:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:47:46 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.796 | nll_loss 9.392 | ppl 671.97 | wps 45930.9 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.796
2022-03-05 14:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-05 14:47:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:47:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:47:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.796) (writing took 3.8183545265346766 seconds)
2022-03-05 14:47:50 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-05 14:47:50 | INFO | train | epoch 013 | loss 9.728 | nll_loss 9.325 | ppl 641.37 | wps 26971.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.692 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 1547
2022-03-05 14:47:50 | INFO | fairseq.trainer | begin training epoch 14
2022-03-05 14:47:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:47:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:49:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:49:44 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.674 | nll_loss 9.26 | ppl 613.04 | wps 45735.7 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.674
2022-03-05 14:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-05 14:49:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:49:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.674) (writing took 3.914554938673973 seconds)
2022-03-05 14:49:48 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-05 14:49:48 | INFO | train | epoch 014 | loss 9.591 | nll_loss 9.179 | ppl 579.63 | wps 26409.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.708 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 1665
2022-03-05 14:49:48 | INFO | fairseq.trainer | begin training epoch 15
2022-03-05 14:49:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:50:36 | INFO | train_inner | epoch 015:     21 / 49 loss=9.604, nll_loss=9.193, ppl=585.29, wps=26765.8, ups=0.41, wpb=64876.2, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.71, loss_scale=16, train_wall=202, gb_free=21.6, wall=1712
2022-03-05 14:51:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:51:42 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.577 | nll_loss 9.157 | ppl 570.68 | wps 45846.1 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.577
2022-03-05 14:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-05 14:51:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:51:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:51:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.577) (writing took 4.109930083155632 seconds)
2022-03-05 14:51:46 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-05 14:51:46 | INFO | train | epoch 015 | loss 9.458 | nll_loss 9.037 | ppl 525.45 | wps 26877.7 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.735 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 1783
2022-03-05 14:51:46 | INFO | fairseq.trainer | begin training epoch 16
2022-03-05 14:51:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:53:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:53:40 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.491 | nll_loss 9.063 | ppl 534.7 | wps 45805.9 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.491
2022-03-05 14:53:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-05 14:53:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:53:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:53:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.491) (writing took 3.912527455948293 seconds)
2022-03-05 14:53:44 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-05 14:53:44 | INFO | train | epoch 016 | loss 9.328 | nll_loss 8.899 | ppl 477.4 | wps 26989.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.825 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 1901
2022-03-05 14:53:44 | INFO | fairseq.trainer | begin training epoch 17
2022-03-05 14:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:54:36 | INFO | train_inner | epoch 017:     23 / 49 loss=9.336, nll_loss=8.907, ppl=480, wps=26986.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.807, loss_scale=32, train_wall=200, gb_free=21.6, wall=1953
2022-03-05 14:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:55:38 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.385 | nll_loss 8.949 | ppl 494.06 | wps 45639.4 | wpb 510.9 | bsz 1 | num_updates 826 | best_loss 9.385
2022-03-05 14:55:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 826 updates
2022-03-05 14:55:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:55:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:55:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 17 @ 826 updates, score 9.385) (writing took 3.883123875595629 seconds)
2022-03-05 14:55:42 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-05 14:55:42 | INFO | train | epoch 017 | loss 9.2 | nll_loss 8.762 | ppl 434.09 | wps 27004.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 826 | lr 0.000103329 | gnorm 0.811 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 2019
2022-03-05 14:55:42 | INFO | fairseq.trainer | begin training epoch 18
2022-03-05 14:55:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:57:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:57:35 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.301 | nll_loss 8.864 | ppl 466.04 | wps 45588 | wpb 510.9 | bsz 1 | num_updates 875 | best_loss 9.301
2022-03-05 14:57:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 875 updates
2022-03-05 14:57:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:57:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 18 @ 875 updates, score 9.301) (writing took 3.912310074083507 seconds)
2022-03-05 14:57:39 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-05 14:57:39 | INFO | train | epoch 018 | loss 9.078 | nll_loss 8.631 | ppl 396.49 | wps 27039.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 875 | lr 0.000109453 | gnorm 0.887 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 2136
2022-03-05 14:57:39 | INFO | fairseq.trainer | begin training epoch 19
2022-03-05 14:57:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:58:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:58:38 | INFO | train_inner | epoch 019:     26 / 49 loss=9.077, nll_loss=8.631, ppl=396.37, wps=26827.8, ups=0.41, wpb=64876.2, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.883, loss_scale=32, train_wall=201, gb_free=21.6, wall=2195
2022-03-05 14:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:59:33 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.211 | nll_loss 8.756 | ppl 432.39 | wps 45710.6 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.211
2022-03-05 14:59:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-05 14:59:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:59:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 14:59:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.211) (writing took 3.877973065711558 seconds)
2022-03-05 14:59:37 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-05 14:59:37 | INFO | train | epoch 019 | loss 8.96 | nll_loss 8.506 | ppl 363.49 | wps 26477.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.942 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 2254
2022-03-05 14:59:37 | INFO | fairseq.trainer | begin training epoch 20
2022-03-05 14:59:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:01:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:01:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:01:31 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.145 | nll_loss 8.686 | ppl 411.88 | wps 46166.6 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 9.145
2022-03-05 15:01:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-05 15:01:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:01:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:01:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 20 @ 971 updates, score 9.145) (writing took 3.8733573965728283 seconds)
2022-03-05 15:01:35 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-05 15:01:35 | INFO | train | epoch 020 | loss 8.846 | nll_loss 8.384 | ppl 334.07 | wps 26448.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.889 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 2371
2022-03-05 15:01:35 | INFO | fairseq.trainer | begin training epoch 21
2022-03-05 15:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:02:40 | INFO | train_inner | epoch 021:     29 / 49 loss=8.84, nll_loss=8.377, ppl=332.54, wps=26782, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.91, loss_scale=16, train_wall=202, gb_free=21.6, wall=2437
2022-03-05 15:03:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:03:29 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.068 | nll_loss 8.603 | ppl 388.86 | wps 45652 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 9.068
2022-03-05 15:03:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-05 15:03:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:03:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:03:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 21 @ 1020 updates, score 9.068) (writing took 3.895628231577575 seconds)
2022-03-05 15:03:33 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-05 15:03:33 | INFO | train | epoch 021 | loss 8.737 | nll_loss 8.267 | ppl 308.11 | wps 26958.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.912 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 2489
2022-03-05 15:03:33 | INFO | fairseq.trainer | begin training epoch 22
2022-03-05 15:03:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:05:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:05:26 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.006 | nll_loss 8.537 | ppl 371.37 | wps 45571.8 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 9.006
2022-03-05 15:05:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-05 15:05:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:05:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:05:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 22 @ 1069 updates, score 9.006) (writing took 3.9061239836737514 seconds)
2022-03-05 15:05:30 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-05 15:05:30 | INFO | train | epoch 022 | loss 8.628 | nll_loss 8.151 | ppl 284.18 | wps 27025.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.866 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 2607
2022-03-05 15:05:30 | INFO | fairseq.trainer | begin training epoch 23
2022-03-05 15:05:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:06:40 | INFO | train_inner | epoch 023:     31 / 49 loss=8.618, nll_loss=8.14, ppl=282.12, wps=27048.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.914, loss_scale=32, train_wall=199, gb_free=21.6, wall=2677
2022-03-05 15:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:07:24 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.944 | nll_loss 8.474 | ppl 355.61 | wps 45683.7 | wpb 510.9 | bsz 1 | num_updates 1118 | best_loss 8.944
2022-03-05 15:07:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1118 updates
2022-03-05 15:07:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:07:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:07:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 23 @ 1118 updates, score 8.944) (writing took 3.857877098955214 seconds)
2022-03-05 15:07:28 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-05 15:07:28 | INFO | train | epoch 023 | loss 8.529 | nll_loss 8.046 | ppl 264.23 | wps 27018.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1118 | lr 0.000139822 | gnorm 1.014 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 2725
2022-03-05 15:07:28 | INFO | fairseq.trainer | begin training epoch 24
2022-03-05 15:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:09:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:09:21 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.902 | nll_loss 8.421 | ppl 342.85 | wps 45281.6 | wpb 510.9 | bsz 1 | num_updates 1167 | best_loss 8.902
2022-03-05 15:09:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1167 updates
2022-03-05 15:09:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:09:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:09:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 24 @ 1167 updates, score 8.902) (writing took 3.950027057901025 seconds)
2022-03-05 15:09:25 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-05 15:09:25 | INFO | train | epoch 024 | loss 8.426 | nll_loss 7.936 | ppl 244.81 | wps 27007 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1167 | lr 0.000145946 | gnorm 0.918 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 2842
2022-03-05 15:09:25 | INFO | fairseq.trainer | begin training epoch 25
2022-03-05 15:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:10:39 | INFO | train_inner | epoch 025:     33 / 49 loss=8.409, nll_loss=7.918, ppl=241.79, wps=27080.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.938, loss_scale=32, train_wall=199, gb_free=21.6, wall=2916
2022-03-05 15:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:11:19 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.832 | nll_loss 8.349 | ppl 325.98 | wps 45790 | wpb 510.9 | bsz 1 | num_updates 1216 | best_loss 8.832
2022-03-05 15:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1216 updates
2022-03-05 15:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:11:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:11:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 25 @ 1216 updates, score 8.832) (writing took 3.8618922801688313 seconds)
2022-03-05 15:11:23 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-05 15:11:23 | INFO | train | epoch 025 | loss 8.326 | nll_loss 7.828 | ppl 227.28 | wps 27053 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1216 | lr 0.00015207 | gnorm 0.897 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 2960
2022-03-05 15:11:23 | INFO | fairseq.trainer | begin training epoch 26
2022-03-05 15:11:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:11:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:13:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:13:17 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.787 | nll_loss 8.302 | ppl 315.52 | wps 45626.9 | wpb 510.9 | bsz 1 | num_updates 1264 | best_loss 8.787
2022-03-05 15:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1264 updates
2022-03-05 15:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:13:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 26 @ 1264 updates, score 8.787) (writing took 3.8528491044417024 seconds)
2022-03-05 15:13:21 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-05 15:13:21 | INFO | train | epoch 026 | loss 8.232 | nll_loss 7.729 | ppl 212.1 | wps 26431.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1264 | lr 0.000158068 | gnorm 1.01 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 3077
2022-03-05 15:13:21 | INFO | fairseq.trainer | begin training epoch 27
2022-03-05 15:13:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:14:42 | INFO | train_inner | epoch 027:     36 / 49 loss=8.213, nll_loss=7.708, ppl=209.04, wps=26782.7, ups=0.41, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.972, loss_scale=32, train_wall=202, gb_free=21.6, wall=3158
2022-03-05 15:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:15:14 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.75 | nll_loss 8.258 | ppl 306.13 | wps 45801.1 | wpb 510.9 | bsz 1 | num_updates 1313 | best_loss 8.75
2022-03-05 15:15:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1313 updates
2022-03-05 15:15:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:15:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 27 @ 1313 updates, score 8.75) (writing took 3.8319103261455894 seconds)
2022-03-05 15:15:18 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-05 15:15:18 | INFO | train | epoch 027 | loss 8.135 | nll_loss 7.624 | ppl 197.31 | wps 27022.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1313 | lr 0.000164192 | gnorm 0.973 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 3195
2022-03-05 15:15:18 | INFO | fairseq.trainer | begin training epoch 28
2022-03-05 15:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:17:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:17:12 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.716 | nll_loss 8.22 | ppl 298.17 | wps 45554.9 | wpb 510.9 | bsz 1 | num_updates 1362 | best_loss 8.716
2022-03-05 15:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1362 updates
2022-03-05 15:17:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:17:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:17:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 28 @ 1362 updates, score 8.716) (writing took 3.818180655129254 seconds)
2022-03-05 15:17:16 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-05 15:17:16 | INFO | train | epoch 028 | loss 8.039 | nll_loss 7.522 | ppl 183.84 | wps 26996.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1362 | lr 0.000170316 | gnorm 0.992 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 3313
2022-03-05 15:17:16 | INFO | fairseq.trainer | begin training epoch 29
2022-03-05 15:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:17:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:18:44 | INFO | train_inner | epoch 029:     39 / 49 loss=8.01, nll_loss=7.492, ppl=179.99, wps=26810.3, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.983, loss_scale=32, train_wall=201, gb_free=21.6, wall=3400
2022-03-05 15:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:19:10 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.663 | nll_loss 8.161 | ppl 286.14 | wps 46390.2 | wpb 510.9 | bsz 1 | num_updates 1410 | best_loss 8.663
2022-03-05 15:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1410 updates
2022-03-05 15:19:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:19:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:19:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 29 @ 1410 updates, score 8.663) (writing took 3.929694451391697 seconds)
2022-03-05 15:19:14 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-05 15:19:14 | INFO | train | epoch 029 | loss 7.94 | nll_loss 7.417 | ppl 170.86 | wps 26464.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1410 | lr 0.000176315 | gnorm 0.975 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 3430
2022-03-05 15:19:14 | INFO | fairseq.trainer | begin training epoch 30
2022-03-05 15:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:21:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:21:07 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.662 | nll_loss 8.162 | ppl 286.43 | wps 45349.4 | wpb 510.9 | bsz 1 | num_updates 1459 | best_loss 8.662
2022-03-05 15:21:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1459 updates
2022-03-05 15:21:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:21:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:21:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 30 @ 1459 updates, score 8.662) (writing took 3.890209295786917 seconds)
2022-03-05 15:21:11 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-05 15:21:11 | INFO | train | epoch 030 | loss 7.846 | nll_loss 7.316 | ppl 159.34 | wps 26974.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1459 | lr 0.000182439 | gnorm 1.01 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 3548
2022-03-05 15:21:11 | INFO | fairseq.trainer | begin training epoch 31
2022-03-05 15:21:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:22:44 | INFO | train_inner | epoch 031:     41 / 49 loss=7.814, nll_loss=7.282, ppl=155.68, wps=27029, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.997, loss_scale=32, train_wall=200, gb_free=21.6, wall=3640
2022-03-05 15:23:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:23:05 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.597 | nll_loss 8.081 | ppl 270.79 | wps 45410.4 | wpb 510.9 | bsz 1 | num_updates 1508 | best_loss 8.597
2022-03-05 15:23:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1508 updates
2022-03-05 15:23:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:23:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:23:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 31 @ 1508 updates, score 8.597) (writing took 3.9183281790465117 seconds)
2022-03-05 15:23:09 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-05 15:23:09 | INFO | train | epoch 031 | loss 7.748 | nll_loss 7.212 | ppl 148.22 | wps 26995.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1508 | lr 0.000188562 | gnorm 0.993 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 3666
2022-03-05 15:23:09 | INFO | fairseq.trainer | begin training epoch 32
2022-03-05 15:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:23:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:24:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:25:03 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.59 | nll_loss 8.072 | ppl 269.05 | wps 45526.8 | wpb 510.9 | bsz 1 | num_updates 1556 | best_loss 8.59
2022-03-05 15:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1556 updates
2022-03-05 15:25:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:25:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 32 @ 1556 updates, score 8.59) (writing took 3.8802213529124856 seconds)
2022-03-05 15:25:07 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-05 15:25:07 | INFO | train | epoch 032 | loss 7.652 | nll_loss 7.109 | ppl 138.06 | wps 26436.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1556 | lr 0.000194561 | gnorm 0.991 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 3784
2022-03-05 15:25:07 | INFO | fairseq.trainer | begin training epoch 33
2022-03-05 15:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:26:46 | INFO | train_inner | epoch 033:     44 / 49 loss=7.616, nll_loss=7.071, ppl=134.43, wps=26792.7, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=1.019, loss_scale=32, train_wall=201, gb_free=21.6, wall=3882
2022-03-05 15:26:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:27:01 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.56 | nll_loss 8.043 | ppl 263.78 | wps 46017.5 | wpb 510.9 | bsz 1 | num_updates 1605 | best_loss 8.56
2022-03-05 15:27:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1605 updates
2022-03-05 15:27:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:27:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:27:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 33 @ 1605 updates, score 8.56) (writing took 3.9067309526726604 seconds)
2022-03-05 15:27:04 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-05 15:27:04 | INFO | train | epoch 033 | loss 7.557 | nll_loss 7.008 | ppl 128.67 | wps 27020 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1605 | lr 0.000200685 | gnorm 1.043 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 3901
2022-03-05 15:27:04 | INFO | fairseq.trainer | begin training epoch 34
2022-03-05 15:27:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:28:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:28:59 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.552 | nll_loss 8.037 | ppl 262.7 | wps 45486.9 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 8.552
2022-03-05 15:28:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-05 15:28:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:29:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:29:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 34 @ 1653 updates, score 8.552) (writing took 3.9156301096081734 seconds)
2022-03-05 15:29:02 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-05 15:29:02 | INFO | train | epoch 034 | loss 7.461 | nll_loss 6.905 | ppl 119.84 | wps 26383.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 0.996 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 4019
2022-03-05 15:29:02 | INFO | fairseq.trainer | begin training epoch 35
2022-03-05 15:29:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:30:48 | INFO | train_inner | epoch 035:     47 / 49 loss=7.422, nll_loss=6.863, ppl=116.42, wps=26742.4, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=1.022, loss_scale=32, train_wall=202, gb_free=21.6, wall=4125
2022-03-05 15:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:30:56 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.546 | nll_loss 8.029 | ppl 261.26 | wps 45485.5 | wpb 510.9 | bsz 1 | num_updates 1702 | best_loss 8.546
2022-03-05 15:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1702 updates
2022-03-05 15:30:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:31:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 35 @ 1702 updates, score 8.546) (writing took 3.830259680747986 seconds)
2022-03-05 15:31:00 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-05 15:31:00 | INFO | train | epoch 035 | loss 7.369 | nll_loss 6.806 | ppl 111.91 | wps 26959.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1702 | lr 0.000212807 | gnorm 1.059 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 4137
2022-03-05 15:31:00 | INFO | fairseq.trainer | begin training epoch 36
2022-03-05 15:31:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:32:54 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.512 | nll_loss 7.985 | ppl 253.39 | wps 45743.1 | wpb 510.9 | bsz 1 | num_updates 1751 | best_loss 8.512
2022-03-05 15:32:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1751 updates
2022-03-05 15:32:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:32:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:32:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 36 @ 1751 updates, score 8.512) (writing took 3.854664821177721 seconds)
2022-03-05 15:32:58 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-05 15:32:58 | INFO | train | epoch 036 | loss 7.274 | nll_loss 6.706 | ppl 104.37 | wps 27010.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1751 | lr 0.000218931 | gnorm 1.069 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 4255
2022-03-05 15:32:58 | INFO | fairseq.trainer | begin training epoch 37
2022-03-05 15:32:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:34:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:34:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:34:52 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.502 | nll_loss 7.975 | ppl 251.61 | wps 45686.7 | wpb 510.9 | bsz 1 | num_updates 1799 | best_loss 8.502
2022-03-05 15:34:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1799 updates
2022-03-05 15:34:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:34:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 37 @ 1799 updates, score 8.502) (writing took 3.833587523549795 seconds)
2022-03-05 15:34:55 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-05 15:34:55 | INFO | train | epoch 037 | loss 7.179 | nll_loss 6.603 | ppl 97.23 | wps 26489.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1799 | lr 0.00022493 | gnorm 1.038 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 4372
2022-03-05 15:34:55 | INFO | fairseq.trainer | begin training epoch 38
2022-03-05 15:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:34:58 | INFO | train_inner | epoch 038:      1 / 49 loss=7.227, nll_loss=6.655, ppl=100.74, wps=25858.4, ups=0.4, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.055, loss_scale=32, train_wall=200, gb_free=21.6, wall=4375
2022-03-05 15:36:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:36:49 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.499 | nll_loss 7.968 | ppl 250.35 | wps 45809.9 | wpb 510.9 | bsz 1 | num_updates 1848 | best_loss 8.499
2022-03-05 15:36:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1848 updates
2022-03-05 15:36:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:36:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt
2022-03-05 15:36:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_best.pt (epoch 38 @ 1848 updates, score 8.499) (writing took 3.8322870396077633 seconds)
2022-03-05 15:36:53 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-05 15:36:53 | INFO | train | epoch 038 | loss 7.09 | nll_loss 6.508 | ppl 91.02 | wps 27003.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1848 | lr 0.000231054 | gnorm 1.077 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 4490
2022-03-05 15:36:53 | INFO | fairseq.trainer | begin training epoch 39
2022-03-05 15:36:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:38:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:38:47 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.515 | nll_loss 7.984 | ppl 253.26 | wps 46185.3 | wpb 510.9 | bsz 1 | num_updates 1897 | best_loss 8.499
2022-03-05 15:38:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1897 updates
2022-03-05 15:38:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:38:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:38:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 39 @ 1897 updates, score 8.515) (writing took 1.7892895489931107 seconds)
2022-03-05 15:38:49 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-05 15:38:49 | INFO | train | epoch 039 | loss 6.996 | nll_loss 6.407 | ppl 84.86 | wps 27518.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1897 | lr 0.000237178 | gnorm 1.071 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 4605
2022-03-05 15:38:49 | INFO | fairseq.trainer | begin training epoch 40
2022-03-05 15:38:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:38:55 | INFO | train_inner | epoch 040:      3 / 49 loss=7.039, nll_loss=6.453, ppl=87.61, wps=27296, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.071, loss_scale=32, train_wall=200, gb_free=21.6, wall=4612
2022-03-05 15:39:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:39:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:40:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:40:42 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.546 | nll_loss 8.003 | ppl 256.48 | wps 46110.1 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.499
2022-03-05 15:40:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-05 15:40:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:40:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:40:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 40 @ 1944 updates, score 8.546) (writing took 1.7355650318786502 seconds)
2022-03-05 15:40:44 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-05 15:40:44 | INFO | train | epoch 040 | loss 6.904 | nll_loss 6.309 | ppl 79.27 | wps 26378.6 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 1944 | lr 0.000243051 | gnorm 1.051 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 4721
2022-03-05 15:40:44 | INFO | fairseq.trainer | begin training epoch 41
2022-03-05 15:40:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:42:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:42:38 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.54 | nll_loss 8.007 | ppl 257.22 | wps 45948.5 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.499
2022-03-05 15:42:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-05 15:42:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:42:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:42:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 41 @ 1993 updates, score 8.54) (writing took 1.698453402146697 seconds)
2022-03-05 15:42:40 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-05 15:42:40 | INFO | train | epoch 041 | loss 6.819 | nll_loss 6.218 | ppl 74.44 | wps 27536.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 1.118 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 4836
2022-03-05 15:42:40 | INFO | fairseq.trainer | begin training epoch 42
2022-03-05 15:42:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:42:55 | INFO | train_inner | epoch 042:      7 / 49 loss=6.849, nll_loss=6.25, ppl=76.12, wps=27038.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.085, loss_scale=16, train_wall=203, gb_free=21.6, wall=4852
2022-03-05 15:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:44:34 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.559 | nll_loss 8.022 | ppl 259.88 | wps 45416.2 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 8.499
2022-03-05 15:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-05 15:44:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:44:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:44:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 42 @ 2042 updates, score 8.559) (writing took 1.7584510128945112 seconds)
2022-03-05 15:44:35 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-05 15:44:35 | INFO | train | epoch 042 | loss 6.725 | nll_loss 6.118 | ppl 69.43 | wps 27453.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.065 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 4952
2022-03-05 15:44:35 | INFO | fairseq.trainer | begin training epoch 43
2022-03-05 15:44:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:46:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:46:29 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.604 | nll_loss 8.071 | ppl 268.85 | wps 45660.7 | wpb 510.9 | bsz 1 | num_updates 2091 | best_loss 8.499
2022-03-05 15:46:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2091 updates
2022-03-05 15:46:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:46:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:46:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 43 @ 2091 updates, score 8.604) (writing took 1.6803895002231002 seconds)
2022-03-05 15:46:31 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-05 15:46:31 | INFO | train | epoch 043 | loss 6.64 | nll_loss 6.026 | ppl 65.15 | wps 27527.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2091 | lr 0.000261423 | gnorm 1.144 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 5068
2022-03-05 15:46:31 | INFO | fairseq.trainer | begin training epoch 44
2022-03-05 15:46:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:46:51 | INFO | train_inner | epoch 044:      9 / 49 loss=6.665, nll_loss=6.053, ppl=66.41, wps=27526.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.112, loss_scale=32, train_wall=200, gb_free=21.6, wall=5088
2022-03-05 15:48:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:48:25 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.61 | nll_loss 8.073 | ppl 269.35 | wps 45655.8 | wpb 510.9 | bsz 1 | num_updates 2140 | best_loss 8.499
2022-03-05 15:48:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2140 updates
2022-03-05 15:48:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:48:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:48:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 44 @ 2140 updates, score 8.61) (writing took 1.7566196341067553 seconds)
2022-03-05 15:48:26 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-05 15:48:26 | INFO | train | epoch 044 | loss 6.555 | nll_loss 5.935 | ppl 61.18 | wps 27490.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2140 | lr 0.000267547 | gnorm 1.207 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 5183
2022-03-05 15:48:26 | INFO | fairseq.trainer | begin training epoch 45
2022-03-05 15:48:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:50:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:50:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:50:20 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.705 | nll_loss 8.179 | ppl 289.9 | wps 45766.1 | wpb 510.9 | bsz 1 | num_updates 2188 | best_loss 8.499
2022-03-05 15:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2188 updates
2022-03-05 15:50:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 45 @ 2188 updates, score 8.705) (writing took 1.7140898061916232 seconds)
2022-03-05 15:50:22 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-05 15:50:22 | INFO | train | epoch 045 | loss 6.456 | nll_loss 5.829 | ppl 56.83 | wps 26959.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2188 | lr 0.000273545 | gnorm 1.065 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 5299
2022-03-05 15:50:22 | INFO | fairseq.trainer | begin training epoch 46
2022-03-05 15:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:50:49 | INFO | train_inner | epoch 046:     12 / 49 loss=6.487, nll_loss=5.862, ppl=58.18, wps=27277.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.142, loss_scale=32, train_wall=201, gb_free=21.6, wall=5326
2022-03-05 15:52:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:52:16 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.704 | nll_loss 8.175 | ppl 289 | wps 45994.5 | wpb 510.9 | bsz 1 | num_updates 2237 | best_loss 8.499
2022-03-05 15:52:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2237 updates
2022-03-05 15:52:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:52:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:52:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 46 @ 2237 updates, score 8.704) (writing took 1.754463487304747 seconds)
2022-03-05 15:52:17 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-05 15:52:17 | INFO | train | epoch 046 | loss 6.375 | nll_loss 5.742 | ppl 53.51 | wps 27525.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2237 | lr 0.000279669 | gnorm 1.189 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 5414
2022-03-05 15:52:17 | INFO | fairseq.trainer | begin training epoch 47
2022-03-05 15:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:54:11 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.74 | nll_loss 8.213 | ppl 296.76 | wps 46340.4 | wpb 510.9 | bsz 1 | num_updates 2286 | best_loss 8.499
2022-03-05 15:54:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2286 updates
2022-03-05 15:54:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:54:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:54:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 47 @ 2286 updates, score 8.74) (writing took 1.706342057324946 seconds)
2022-03-05 15:54:13 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-05 15:54:13 | INFO | train | epoch 047 | loss 6.288 | nll_loss 5.648 | ppl 50.15 | wps 27517.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2286 | lr 0.000285793 | gnorm 1.2 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 5530
2022-03-05 15:54:13 | INFO | fairseq.trainer | begin training epoch 48
2022-03-05 15:54:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:54:44 | INFO | train_inner | epoch 048:     14 / 49 loss=6.308, nll_loss=5.669, ppl=50.89, wps=27556, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.181, loss_scale=32, train_wall=199, gb_free=21.6, wall=5561
2022-03-05 15:54:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:56:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:56:07 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.761 | nll_loss 8.222 | ppl 298.52 | wps 45676.7 | wpb 510.9 | bsz 1 | num_updates 2334 | best_loss 8.499
2022-03-05 15:56:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2334 updates
2022-03-05 15:56:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:56:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:56:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 48 @ 2334 updates, score 8.761) (writing took 1.7497485652565956 seconds)
2022-03-05 15:56:08 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-05 15:56:08 | INFO | train | epoch 048 | loss 6.198 | nll_loss 5.551 | ppl 46.89 | wps 26954.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2334 | lr 0.000291792 | gnorm 1.133 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 5645
2022-03-05 15:56:08 | INFO | fairseq.trainer | begin training epoch 49
2022-03-05 15:56:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:58:02 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.811 | nll_loss 8.273 | ppl 309.38 | wps 45818.9 | wpb 510.9 | bsz 1 | num_updates 2383 | best_loss 8.499
2022-03-05 15:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2383 updates
2022-03-05 15:58:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:58:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:58:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 49 @ 2383 updates, score 8.811) (writing took 1.7058670837432146 seconds)
2022-03-05 15:58:04 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-05 15:58:04 | INFO | train | epoch 049 | loss 6.114 | nll_loss 5.461 | ppl 44.05 | wps 27494.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2383 | lr 0.000297915 | gnorm 1.235 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 5761
2022-03-05 15:58:04 | INFO | fairseq.trainer | begin training epoch 50
2022-03-05 15:58:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:58:42 | INFO | train_inner | epoch 050:     17 / 49 loss=6.129, nll_loss=5.477, ppl=44.53, wps=27289.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.206, loss_scale=16, train_wall=201, gb_free=21.6, wall=5799
2022-03-05 15:59:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:59:58 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.883 | nll_loss 8.349 | ppl 326.12 | wps 45392.3 | wpb 510.9 | bsz 1 | num_updates 2432 | best_loss 8.499
2022-03-05 15:59:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2432 updates
2022-03-05 15:59:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:59:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 15:59:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 50 @ 2432 updates, score 8.883) (writing took 1.7416064022108912 seconds)
2022-03-05 15:59:59 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-05 15:59:59 | INFO | train | epoch 050 | loss 6.027 | nll_loss 5.368 | ppl 41.29 | wps 27503.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2432 | lr 0.000304039 | gnorm 1.223 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 5876
2022-03-05 15:59:59 | INFO | fairseq.trainer | begin training epoch 51
2022-03-05 15:59:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:01:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:01:53 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.881 | nll_loss 8.335 | ppl 322.99 | wps 45320.5 | wpb 510.9 | bsz 1 | num_updates 2481 | best_loss 8.499
2022-03-05 16:01:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2481 updates
2022-03-05 16:01:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:01:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:01:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 51 @ 2481 updates, score 8.881) (writing took 1.65589280705899 seconds)
2022-03-05 16:01:55 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-05 16:01:55 | INFO | train | epoch 051 | loss 5.938 | nll_loss 5.272 | ppl 38.63 | wps 27534.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2481 | lr 0.000310163 | gnorm 1.222 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 5992
2022-03-05 16:01:55 | INFO | fairseq.trainer | begin training epoch 52
2022-03-05 16:01:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:02:38 | INFO | train_inner | epoch 052:     19 / 49 loss=5.942, nll_loss=5.276, ppl=38.76, wps=27535.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.206, loss_scale=32, train_wall=199, gb_free=21.6, wall=6034
2022-03-05 16:02:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:03:49 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.905 | nll_loss 8.371 | ppl 331 | wps 45962 | wpb 510.9 | bsz 1 | num_updates 2529 | best_loss 8.499
2022-03-05 16:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2529 updates
2022-03-05 16:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:03:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:03:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 52 @ 2529 updates, score 8.905) (writing took 1.7354001691564918 seconds)
2022-03-05 16:03:50 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-05 16:03:50 | INFO | train | epoch 052 | loss 5.856 | nll_loss 5.184 | ppl 36.35 | wps 26939.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2529 | lr 0.000316162 | gnorm 1.293 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 6107
2022-03-05 16:03:50 | INFO | fairseq.trainer | begin training epoch 53
2022-03-05 16:03:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:05:44 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.019 | nll_loss 8.494 | ppl 360.51 | wps 45511.1 | wpb 510.9 | bsz 1 | num_updates 2578 | best_loss 8.499
2022-03-05 16:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2578 updates
2022-03-05 16:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:05:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 53 @ 2578 updates, score 9.019) (writing took 1.7009285483509302 seconds)
2022-03-05 16:05:46 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-05 16:05:46 | INFO | train | epoch 053 | loss 5.766 | nll_loss 5.087 | ppl 33.98 | wps 27504.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2578 | lr 0.000322286 | gnorm 1.196 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 6223
2022-03-05 16:05:46 | INFO | fairseq.trainer | begin training epoch 54
2022-03-05 16:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:06:35 | INFO | train_inner | epoch 054:     22 / 49 loss=5.781, nll_loss=5.103, ppl=34.37, wps=27292.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.31, loss_scale=16, train_wall=201, gb_free=21.6, wall=6272
2022-03-05 16:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:07:40 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.018 | nll_loss 8.482 | ppl 357.44 | wps 44474.1 | wpb 510.9 | bsz 1 | num_updates 2627 | best_loss 8.499
2022-03-05 16:07:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2627 updates
2022-03-05 16:07:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:07:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:07:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 54 @ 2627 updates, score 9.018) (writing took 1.724347796291113 seconds)
2022-03-05 16:07:42 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-05 16:07:42 | INFO | train | epoch 054 | loss 5.689 | nll_loss 5.004 | ppl 32.08 | wps 27330.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2627 | lr 0.000328409 | gnorm 1.344 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 6339
2022-03-05 16:07:42 | INFO | fairseq.trainer | begin training epoch 55
2022-03-05 16:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:08:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:09:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:09:37 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.061 | nll_loss 8.514 | ppl 365.56 | wps 45856.2 | wpb 510.9 | bsz 1 | num_updates 2675 | best_loss 8.499
2022-03-05 16:09:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2675 updates
2022-03-05 16:09:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:09:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 55 @ 2675 updates, score 9.061) (writing took 1.6319330409169197 seconds)
2022-03-05 16:09:39 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-05 16:09:39 | INFO | train | epoch 055 | loss 5.608 | nll_loss 4.916 | ppl 30.2 | wps 26635 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 2675 | lr 0.000334408 | gnorm 1.373 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 6456
2022-03-05 16:09:39 | INFO | fairseq.trainer | begin training epoch 56
2022-03-05 16:09:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:10:36 | INFO | train_inner | epoch 056:     25 / 49 loss=5.603, nll_loss=4.911, ppl=30.08, wps=26984.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.296, loss_scale=16, train_wall=204, gb_free=21.6, wall=6513
2022-03-05 16:11:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:11:34 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.068 | nll_loss 8.531 | ppl 369.8 | wps 45312.6 | wpb 510.9 | bsz 1 | num_updates 2724 | best_loss 8.499
2022-03-05 16:11:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2724 updates
2022-03-05 16:11:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:11:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:11:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 56 @ 2724 updates, score 9.068) (writing took 1.6658415347337723 seconds)
2022-03-05 16:11:35 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-05 16:11:35 | INFO | train | epoch 056 | loss 5.515 | nll_loss 4.816 | ppl 28.16 | wps 27316.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2724 | lr 0.000340532 | gnorm 1.268 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 6572
2022-03-05 16:11:35 | INFO | fairseq.trainer | begin training epoch 57
2022-03-05 16:11:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:13:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:13:30 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.199 | nll_loss 8.671 | ppl 407.72 | wps 45340.6 | wpb 510.9 | bsz 1 | num_updates 2773 | best_loss 8.499
2022-03-05 16:13:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2773 updates
2022-03-05 16:13:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:13:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:13:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 57 @ 2773 updates, score 9.199) (writing took 1.6370439203456044 seconds)
2022-03-05 16:13:32 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-05 16:13:32 | INFO | train | epoch 057 | loss 5.432 | nll_loss 4.726 | ppl 26.47 | wps 27330 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2773 | lr 0.000346656 | gnorm 1.294 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 6689
2022-03-05 16:13:32 | INFO | fairseq.trainer | begin training epoch 58
2022-03-05 16:13:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:14:33 | INFO | train_inner | epoch 058:     27 / 49 loss=5.432, nll_loss=4.726, ppl=26.47, wps=27363, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.351, loss_scale=32, train_wall=201, gb_free=21.6, wall=6750
2022-03-05 16:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:15:26 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.164 | nll_loss 8.615 | ppl 391.97 | wps 44552.7 | wpb 510.9 | bsz 1 | num_updates 2822 | best_loss 8.499
2022-03-05 16:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2822 updates
2022-03-05 16:15:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 58 @ 2822 updates, score 9.164) (writing took 1.6795057309791446 seconds)
2022-03-05 16:15:28 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-05 16:15:28 | INFO | train | epoch 058 | loss 5.358 | nll_loss 4.646 | ppl 25.04 | wps 27304.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2822 | lr 0.000352779 | gnorm 1.465 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 6805
2022-03-05 16:15:28 | INFO | fairseq.trainer | begin training epoch 59
2022-03-05 16:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:17:23 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.223 | nll_loss 8.675 | ppl 408.62 | wps 45760.7 | wpb 510.9 | bsz 1 | num_updates 2871 | best_loss 8.499
2022-03-05 16:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2871 updates
2022-03-05 16:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:17:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 59 @ 2871 updates, score 9.223) (writing took 1.6567757409065962 seconds)
2022-03-05 16:17:24 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-05 16:17:24 | INFO | train | epoch 059 | loss 5.266 | nll_loss 4.547 | ppl 23.38 | wps 27340.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2871 | lr 0.000358903 | gnorm 1.293 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 6921
2022-03-05 16:17:24 | INFO | fairseq.trainer | begin training epoch 60
2022-03-05 16:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:17:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:18:32 | INFO | train_inner | epoch 060:     30 / 49 loss=5.268, nll_loss=4.549, ppl=23.41, wps=27092.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.398, loss_scale=16, train_wall=203, gb_free=21.6, wall=6989
2022-03-05 16:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:19:19 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.284 | nll_loss 8.733 | ppl 425.55 | wps 45443.7 | wpb 510.9 | bsz 1 | num_updates 2919 | best_loss 8.499
2022-03-05 16:19:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2919 updates
2022-03-05 16:19:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:19:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:19:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 60 @ 2919 updates, score 9.284) (writing took 1.6794696701690555 seconds)
2022-03-05 16:19:21 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-05 16:19:21 | INFO | train | epoch 060 | loss 5.187 | nll_loss 4.461 | ppl 22.02 | wps 26752.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 2919 | lr 0.000364902 | gnorm 1.371 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 7037
2022-03-05 16:19:21 | INFO | fairseq.trainer | begin training epoch 61
2022-03-05 16:19:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:21:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:21:15 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.313 | nll_loss 8.755 | ppl 432.11 | wps 44705.1 | wpb 510.9 | bsz 1 | num_updates 2968 | best_loss 8.499
2022-03-05 16:21:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2968 updates
2022-03-05 16:21:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:21:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:21:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 61 @ 2968 updates, score 9.313) (writing took 1.6713272202759981 seconds)
2022-03-05 16:21:17 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-05 16:21:17 | INFO | train | epoch 061 | loss 5.11 | nll_loss 4.378 | ppl 20.8 | wps 27295.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 2968 | lr 0.000371026 | gnorm 1.466 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 7154
2022-03-05 16:21:17 | INFO | fairseq.trainer | begin training epoch 62
2022-03-05 16:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:22:30 | INFO | train_inner | epoch 062:     32 / 49 loss=5.088, nll_loss=4.355, ppl=20.46, wps=27264.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.356, loss_scale=16, train_wall=201, gb_free=21.6, wall=7227
2022-03-05 16:23:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:23:13 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.348 | nll_loss 8.791 | ppl 443 | wps 44544.5 | wpb 510.9 | bsz 1 | num_updates 3017 | best_loss 8.499
2022-03-05 16:23:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3017 updates
2022-03-05 16:23:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 62 @ 3017 updates, score 9.348) (writing took 1.6352435443550348 seconds)
2022-03-05 16:23:14 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-05 16:23:14 | INFO | train | epoch 062 | loss 5.021 | nll_loss 4.282 | ppl 19.45 | wps 27084.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3017 | lr 0.00037715 | gnorm 1.374 | loss_scale 32 | train_wall 99 | gb_free 21.6 | wall 7271
2022-03-05 16:23:14 | INFO | fairseq.trainer | begin training epoch 63
2022-03-05 16:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:24:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:25:10 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.407 | nll_loss 8.855 | ppl 463.01 | wps 45090.9 | wpb 510.9 | bsz 1 | num_updates 3065 | best_loss 8.499
2022-03-05 16:25:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3065 updates
2022-03-05 16:25:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:25:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:25:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 63 @ 3065 updates, score 9.407) (writing took 1.6431953590363264 seconds)
2022-03-05 16:25:12 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-05 16:25:12 | INFO | train | epoch 063 | loss 4.95 | nll_loss 4.205 | ppl 18.44 | wps 26580.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3065 | lr 0.000383148 | gnorm 1.492 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 7388
2022-03-05 16:25:12 | INFO | fairseq.trainer | begin training epoch 64
2022-03-05 16:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:26:32 | INFO | train_inner | epoch 064:     35 / 49 loss=4.929, nll_loss=4.182, ppl=18.15, wps=26880.1, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.409, loss_scale=16, train_wall=204, gb_free=21.6, wall=7468
2022-03-05 16:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:27:07 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.463 | nll_loss 8.903 | ppl 478.71 | wps 44639.8 | wpb 510.9 | bsz 1 | num_updates 3114 | best_loss 8.499
2022-03-05 16:27:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3114 updates
2022-03-05 16:27:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:27:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:27:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 64 @ 3114 updates, score 9.463) (writing took 1.64969436917454 seconds)
2022-03-05 16:27:09 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-05 16:27:09 | INFO | train | epoch 064 | loss 4.859 | nll_loss 4.106 | ppl 17.22 | wps 27047.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3114 | lr 0.000389272 | gnorm 1.358 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 7506
2022-03-05 16:27:09 | INFO | fairseq.trainer | begin training epoch 65
2022-03-05 16:27:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:29:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:29:05 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.536 | nll_loss 8.972 | ppl 502.3 | wps 44815 | wpb 510.9 | bsz 1 | num_updates 3163 | best_loss 8.499
2022-03-05 16:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3163 updates
2022-03-05 16:29:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 65 @ 3163 updates, score 9.536) (writing took 1.6140725277364254 seconds)
2022-03-05 16:29:06 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-05 16:29:06 | INFO | train | epoch 065 | loss 4.785 | nll_loss 4.025 | ppl 16.28 | wps 27136.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3163 | lr 0.000395396 | gnorm 1.429 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 7623
2022-03-05 16:29:06 | INFO | fairseq.trainer | begin training epoch 66
2022-03-05 16:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:30:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:30:33 | INFO | train_inner | epoch 066:     38 / 49 loss=4.77, nll_loss=4.009, ppl=16.1, wps=26867, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.481, loss_scale=16, train_wall=204, gb_free=21.6, wall=7710
2022-03-05 16:30:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:31:02 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.574 | nll_loss 9.014 | ppl 517.17 | wps 44632.3 | wpb 510.9 | bsz 1 | num_updates 3211 | best_loss 8.499
2022-03-05 16:31:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3211 updates
2022-03-05 16:31:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:31:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:31:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 66 @ 3211 updates, score 9.574) (writing took 1.658076154999435 seconds)
2022-03-05 16:31:04 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-05 16:31:04 | INFO | train | epoch 066 | loss 4.703 | nll_loss 3.936 | ppl 15.31 | wps 26513.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3211 | lr 0.000401395 | gnorm 1.481 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 7740
2022-03-05 16:31:04 | INFO | fairseq.trainer | begin training epoch 67
2022-03-05 16:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:32:59 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.64 | nll_loss 9.091 | ppl 545.41 | wps 44819.6 | wpb 510.9 | bsz 1 | num_updates 3260 | best_loss 8.499
2022-03-05 16:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3260 updates
2022-03-05 16:32:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:33:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:33:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 67 @ 3260 updates, score 9.64) (writing took 1.6360195390880108 seconds)
2022-03-05 16:33:01 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-05 16:33:01 | INFO | train | epoch 067 | loss 4.625 | nll_loss 3.851 | ppl 14.43 | wps 27126.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3260 | lr 0.000407519 | gnorm 1.463 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 7858
2022-03-05 16:33:01 | INFO | fairseq.trainer | begin training epoch 68
2022-03-05 16:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:34:32 | INFO | train_inner | epoch 068:     40 / 49 loss=4.606, nll_loss=3.831, ppl=14.23, wps=27143.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.475, loss_scale=16, train_wall=202, gb_free=21.6, wall=7949
2022-03-05 16:34:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:34:56 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.743 | nll_loss 9.199 | ppl 587.74 | wps 44664.1 | wpb 510.9 | bsz 1 | num_updates 3309 | best_loss 8.499
2022-03-05 16:34:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3309 updates
2022-03-05 16:34:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:34:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:34:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 68 @ 3309 updates, score 9.743) (writing took 1.6463010273873806 seconds)
2022-03-05 16:34:58 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-05 16:34:58 | INFO | train | epoch 068 | loss 4.56 | nll_loss 3.78 | ppl 13.74 | wps 27096.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3309 | lr 0.000413642 | gnorm 1.505 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 7975
2022-03-05 16:34:58 | INFO | fairseq.trainer | begin training epoch 69
2022-03-05 16:34:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:36:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:36:54 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.775 | nll_loss 9.221 | ppl 596.81 | wps 45078.2 | wpb 510.9 | bsz 1 | num_updates 3358 | best_loss 8.499
2022-03-05 16:36:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3358 updates
2022-03-05 16:36:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:36:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 69 @ 3358 updates, score 9.775) (writing took 1.705665891058743 seconds)
2022-03-05 16:36:55 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-05 16:36:55 | INFO | train | epoch 069 | loss 4.476 | nll_loss 3.689 | ppl 12.9 | wps 27090.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3358 | lr 0.000419766 | gnorm 1.508 | loss_scale 32 | train_wall 99 | gb_free 21.6 | wall 8092
2022-03-05 16:36:55 | INFO | fairseq.trainer | begin training epoch 70
2022-03-05 16:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:38:31 | INFO | train_inner | epoch 070:     42 / 49 loss=4.45, nll_loss=3.66, ppl=12.64, wps=27150.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.483, loss_scale=32, train_wall=202, gb_free=21.6, wall=8188
2022-03-05 16:38:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:38:51 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.89 | nll_loss 9.334 | ppl 645.44 | wps 44662.8 | wpb 510.9 | bsz 1 | num_updates 3406 | best_loss 8.499
2022-03-05 16:38:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3406 updates
2022-03-05 16:38:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:38:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:38:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 70 @ 3406 updates, score 9.89) (writing took 1.7897052485495806 seconds)
2022-03-05 16:38:52 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-05 16:38:52 | INFO | train | epoch 070 | loss 4.397 | nll_loss 3.603 | ppl 12.15 | wps 26583.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3406 | lr 0.000425765 | gnorm 1.478 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 8209
2022-03-05 16:38:52 | INFO | fairseq.trainer | begin training epoch 71
2022-03-05 16:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:40:48 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.936 | nll_loss 9.377 | ppl 664.77 | wps 45299.6 | wpb 510.9 | bsz 1 | num_updates 3455 | best_loss 8.499
2022-03-05 16:40:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3455 updates
2022-03-05 16:40:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:40:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:40:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 71 @ 3455 updates, score 9.936) (writing took 1.6924601374194026 seconds)
2022-03-05 16:40:50 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-05 16:40:50 | INFO | train | epoch 071 | loss 4.324 | nll_loss 3.523 | ppl 11.49 | wps 27125.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3455 | lr 0.000431889 | gnorm 1.487 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 8326
2022-03-05 16:40:50 | INFO | fairseq.trainer | begin training epoch 72
2022-03-05 16:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:42:32 | INFO | train_inner | epoch 072:     45 / 49 loss=4.3, nll_loss=3.497, ppl=11.29, wps=26917.9, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.524, loss_scale=16, train_wall=204, gb_free=21.6, wall=8429
2022-03-05 16:42:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:42:45 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.996 | nll_loss 9.437 | ppl 693.09 | wps 44793 | wpb 510.9 | bsz 1 | num_updates 3504 | best_loss 8.499
2022-03-05 16:42:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3504 updates
2022-03-05 16:42:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:42:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:42:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 72 @ 3504 updates, score 9.996) (writing took 1.666386492550373 seconds)
2022-03-05 16:42:46 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-05 16:42:46 | INFO | train | epoch 072 | loss 4.257 | nll_loss 3.45 | ppl 10.93 | wps 27181.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3504 | lr 0.000438012 | gnorm 1.518 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 8443
2022-03-05 16:42:46 | INFO | fairseq.trainer | begin training epoch 73
2022-03-05 16:42:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:44:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:44:42 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.071 | nll_loss 9.503 | ppl 725.51 | wps 45102.8 | wpb 510.9 | bsz 1 | num_updates 3553 | best_loss 8.499
2022-03-05 16:44:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3553 updates
2022-03-05 16:44:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:44:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:44:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 73 @ 3553 updates, score 10.071) (writing took 1.6696963720023632 seconds)
2022-03-05 16:44:43 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-05 16:44:43 | INFO | train | epoch 073 | loss 4.185 | nll_loss 3.371 | ppl 10.34 | wps 27186.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3553 | lr 0.000444136 | gnorm 1.564 | loss_scale 32 | train_wall 99 | gb_free 21.6 | wall 8560
2022-03-05 16:44:43 | INFO | fairseq.trainer | begin training epoch 74
2022-03-05 16:44:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:45:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:46:32 | INFO | train_inner | epoch 074:     48 / 49 loss=4.154, nll_loss=3.337, ppl=10.1, wps=26977.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3600, lr=0.00045001, gnorm=1.544, loss_scale=16, train_wall=204, gb_free=21.6, wall=8669
2022-03-05 16:46:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:46:38 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.175 | nll_loss 9.616 | ppl 784.8 | wps 44768.3 | wpb 510.9 | bsz 1 | num_updates 3601 | best_loss 8.499
2022-03-05 16:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3601 updates
2022-03-05 16:46:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:46:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:46:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 74 @ 3601 updates, score 10.175) (writing took 1.6709539666771889 seconds)
2022-03-05 16:46:40 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-05 16:46:40 | INFO | train | epoch 074 | loss 4.112 | nll_loss 3.291 | ppl 9.78 | wps 26653.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3601 | lr 0.000450135 | gnorm 1.549 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 8677
2022-03-05 16:46:40 | INFO | fairseq.trainer | begin training epoch 75
2022-03-05 16:46:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:48:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:48:35 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.261 | nll_loss 9.701 | ppl 832.04 | wps 44592.5 | wpb 510.9 | bsz 1 | num_updates 3650 | best_loss 8.499
2022-03-05 16:48:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3650 updates
2022-03-05 16:48:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:48:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:48:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 75 @ 3650 updates, score 10.261) (writing took 1.68534754216671 seconds)
2022-03-05 16:48:37 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-05 16:48:37 | INFO | train | epoch 075 | loss 4.042 | nll_loss 3.214 | ppl 9.28 | wps 27173.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3650 | lr 0.000456259 | gnorm 1.557 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 8794
2022-03-05 16:48:37 | INFO | fairseq.trainer | begin training epoch 76
2022-03-05 16:48:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:50:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:50:33 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.32 | nll_loss 9.77 | ppl 873.21 | wps 44649.8 | wpb 510.9 | bsz 1 | num_updates 3699 | best_loss 8.499
2022-03-05 16:50:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3699 updates
2022-03-05 16:50:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:50:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 76 @ 3699 updates, score 10.32) (writing took 1.6809907853603363 seconds)
2022-03-05 16:50:34 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-05 16:50:34 | INFO | train | epoch 076 | loss 3.971 | nll_loss 3.136 | ppl 8.79 | wps 27142.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3699 | lr 0.000462383 | gnorm 1.558 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 8911
2022-03-05 16:50:34 | INFO | fairseq.trainer | begin training epoch 77
2022-03-05 16:50:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:50:37 | INFO | train_inner | epoch 077:      1 / 49 loss=4.006, nll_loss=3.175, ppl=9.03, wps=26432.5, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=3700, lr=0.000462508, gnorm=1.559, loss_scale=16, train_wall=201, gb_free=21.6, wall=8913
2022-03-05 16:52:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:52:29 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.442 | nll_loss 9.865 | ppl 932.72 | wps 45408.5 | wpb 510.9 | bsz 1 | num_updates 3747 | best_loss 8.499
2022-03-05 16:52:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3747 updates
2022-03-05 16:52:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:52:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:52:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 77 @ 3747 updates, score 10.442) (writing took 1.6636387407779694 seconds)
2022-03-05 16:52:31 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-05 16:52:31 | INFO | train | epoch 077 | loss 3.898 | nll_loss 3.056 | ppl 8.32 | wps 26659.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 3747 | lr 0.000468381 | gnorm 1.494 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 9028
2022-03-05 16:52:31 | INFO | fairseq.trainer | begin training epoch 78
2022-03-05 16:52:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:54:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:54:26 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.458 | nll_loss 9.908 | ppl 960.61 | wps 45151.9 | wpb 510.9 | bsz 1 | num_updates 3796 | best_loss 8.499
2022-03-05 16:54:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3796 updates
2022-03-05 16:54:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:54:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:54:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 78 @ 3796 updates, score 10.458) (writing took 1.6792403450235724 seconds)
2022-03-05 16:54:28 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-05 16:54:28 | INFO | train | epoch 078 | loss 3.845 | nll_loss 2.997 | ppl 7.98 | wps 27158 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3796 | lr 0.000474505 | gnorm 1.486 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 9145
2022-03-05 16:54:28 | INFO | fairseq.trainer | begin training epoch 79
2022-03-05 16:54:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:54:37 | INFO | train_inner | epoch 079:      4 / 49 loss=3.864, nll_loss=3.019, ppl=8.11, wps=26957.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.485, loss_scale=16, train_wall=204, gb_free=21.6, wall=9154
2022-03-05 16:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:56:23 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.539 | nll_loss 9.983 | ppl 1011.72 | wps 44731.4 | wpb 510.9 | bsz 1 | num_updates 3845 | best_loss 8.499
2022-03-05 16:56:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3845 updates
2022-03-05 16:56:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:56:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 79 @ 3845 updates, score 10.539) (writing took 1.6545731956139207 seconds)
2022-03-05 16:56:25 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-05 16:56:25 | INFO | train | epoch 079 | loss 3.771 | nll_loss 2.916 | ppl 7.55 | wps 27171.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3845 | lr 0.000480629 | gnorm 1.559 | loss_scale 16 | train_wall 99 | gb_free 21.6 | wall 9262
2022-03-05 16:56:25 | INFO | fairseq.trainer | begin training epoch 80
2022-03-05 16:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:58:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:58:20 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.642 | nll_loss 10.084 | ppl 1085.15 | wps 46003.3 | wpb 510.9 | bsz 1 | num_updates 3894 | best_loss 8.499
2022-03-05 16:58:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3894 updates
2022-03-05 16:58:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:58:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 16:58:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 80 @ 3894 updates, score 10.642) (writing took 1.672710945829749 seconds)
2022-03-05 16:58:22 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-05 16:58:22 | INFO | train | epoch 080 | loss 3.709 | nll_loss 2.847 | ppl 7.2 | wps 27239.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3894 | lr 0.000486753 | gnorm 1.542 | loss_scale 32 | train_wall 99 | gb_free 21.6 | wall 9378
2022-03-05 16:58:22 | INFO | fairseq.trainer | begin training epoch 81
2022-03-05 16:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:58:35 | INFO | train_inner | epoch 081:      6 / 49 loss=3.731, nll_loss=2.872, ppl=7.32, wps=27260.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.544, loss_scale=32, train_wall=201, gb_free=21.6, wall=9392
2022-03-05 16:58:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:00:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:00:15 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.732 | nll_loss 10.17 | ppl 1152.11 | wps 45982.8 | wpb 510.9 | bsz 1 | num_updates 3942 | best_loss 8.499
2022-03-05 17:00:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3942 updates
2022-03-05 17:00:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:00:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:00:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 81 @ 3942 updates, score 10.732) (writing took 1.7724654208868742 seconds)
2022-03-05 17:00:17 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-05 17:00:17 | INFO | train | epoch 081 | loss 3.64 | nll_loss 2.772 | ppl 6.83 | wps 26992.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3942 | lr 0.000492751 | gnorm 1.549 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 9494
2022-03-05 17:00:17 | INFO | fairseq.trainer | begin training epoch 82
2022-03-05 17:00:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:02:10 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 10.785 | nll_loss 10.238 | ppl 1207.93 | wps 45893.2 | wpb 510.9 | bsz 1 | num_updates 3991 | best_loss 8.499
2022-03-05 17:02:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3991 updates
2022-03-05 17:02:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:02:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:02:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 82 @ 3991 updates, score 10.785) (writing took 2.0696266600862145 seconds)
2022-03-05 17:02:12 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-05 17:02:12 | INFO | train | epoch 082 | loss 3.582 | nll_loss 2.707 | ppl 6.53 | wps 27528.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 3991 | lr 0.000498875 | gnorm 1.537 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9609
2022-03-05 17:02:12 | INFO | fairseq.trainer | begin training epoch 83
2022-03-05 17:02:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:02:33 | INFO | train_inner | epoch 083:      9 / 49 loss=3.598, nll_loss=2.726, ppl=6.61, wps=27322.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.541, loss_scale=16, train_wall=201, gb_free=21.6, wall=9629
2022-03-05 17:04:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:04:06 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 10.908 | nll_loss 10.359 | ppl 1313.3 | wps 45825.6 | wpb 510.9 | bsz 1 | num_updates 4040 | best_loss 8.499
2022-03-05 17:04:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4040 updates
2022-03-05 17:04:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:04:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:04:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 83 @ 4040 updates, score 10.908) (writing took 2.1640460593625903 seconds)
2022-03-05 17:04:08 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-05 17:04:08 | INFO | train | epoch 083 | loss 3.516 | nll_loss 2.635 | ppl 6.21 | wps 27458.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4040 | lr 0.000497519 | gnorm 1.523 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 9725
2022-03-05 17:04:08 | INFO | fairseq.trainer | begin training epoch 84
2022-03-05 17:04:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:04:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:05:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:06:02 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.006 | nll_loss 10.463 | ppl 1411.38 | wps 45610.8 | wpb 510.9 | bsz 1 | num_updates 4088 | best_loss 8.499
2022-03-05 17:06:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4088 updates
2022-03-05 17:06:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:06:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:06:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 84 @ 4088 updates, score 11.006) (writing took 2.0769733767956495 seconds)
2022-03-05 17:06:04 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-05 17:06:04 | INFO | train | epoch 084 | loss 3.45 | nll_loss 2.562 | ppl 5.9 | wps 26921.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4088 | lr 0.000494589 | gnorm 1.487 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9841
2022-03-05 17:06:04 | INFO | fairseq.trainer | begin training epoch 85
2022-03-05 17:06:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:06:31 | INFO | train_inner | epoch 085:     12 / 49 loss=3.469, nll_loss=2.584, ppl=5.99, wps=27244, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.491, loss_scale=16, train_wall=201, gb_free=21.6, wall=9868
2022-03-05 17:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:07:57 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.103 | nll_loss 10.572 | ppl 1522.46 | wps 45694.1 | wpb 510.9 | bsz 1 | num_updates 4137 | best_loss 8.499
2022-03-05 17:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4137 updates
2022-03-05 17:07:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:07:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:07:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 85 @ 4137 updates, score 11.103) (writing took 2.196378811262548 seconds)
2022-03-05 17:07:59 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-05 17:07:59 | INFO | train | epoch 085 | loss 3.387 | nll_loss 2.492 | ppl 5.63 | wps 27452.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4137 | lr 0.000491651 | gnorm 1.494 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9956
2022-03-05 17:07:59 | INFO | fairseq.trainer | begin training epoch 86
2022-03-05 17:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:09:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:09:53 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.157 | nll_loss 10.606 | ppl 1558.7 | wps 46077.9 | wpb 510.9 | bsz 1 | num_updates 4186 | best_loss 8.499
2022-03-05 17:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4186 updates
2022-03-05 17:09:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 86 @ 4186 updates, score 11.157) (writing took 1.9723302498459816 seconds)
2022-03-05 17:09:55 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-05 17:09:55 | INFO | train | epoch 086 | loss 3.322 | nll_loss 2.422 | ppl 5.36 | wps 27532.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4186 | lr 0.000488765 | gnorm 1.449 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10072
2022-03-05 17:09:55 | INFO | fairseq.trainer | begin training epoch 87
2022-03-05 17:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:10:26 | INFO | train_inner | epoch 087:     14 / 49 loss=3.336, nll_loss=2.437, ppl=5.41, wps=27535.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.478, loss_scale=32, train_wall=199, gb_free=21.6, wall=10103
2022-03-05 17:11:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:11:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:11:48 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.307 | nll_loss 10.773 | ppl 1749.67 | wps 45545.5 | wpb 510.9 | bsz 1 | num_updates 4234 | best_loss 8.499
2022-03-05 17:11:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4234 updates
2022-03-05 17:11:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:11:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:11:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 87 @ 4234 updates, score 11.307) (writing took 3.6605591913685203 seconds)
2022-03-05 17:11:52 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-05 17:11:52 | INFO | train | epoch 087 | loss 3.267 | nll_loss 2.36 | ppl 5.13 | wps 26571.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 4234 | lr 0.000485987 | gnorm 1.505 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10189
2022-03-05 17:11:52 | INFO | fairseq.trainer | begin training epoch 88
2022-03-05 17:11:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:13:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:13:45 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.373 | nll_loss 10.808 | ppl 1792.49 | wps 46146.1 | wpb 510.9 | bsz 1 | num_updates 4283 | best_loss 8.499
2022-03-05 17:13:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4283 updates
2022-03-05 17:13:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:13:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:13:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 88 @ 4283 updates, score 11.373) (writing took 1.8839143672958016 seconds)
2022-03-05 17:13:47 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-05 17:13:47 | INFO | train | epoch 088 | loss 3.204 | nll_loss 2.291 | ppl 4.89 | wps 27576.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4283 | lr 0.000483199 | gnorm 1.406 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10304
2022-03-05 17:13:47 | INFO | fairseq.trainer | begin training epoch 89
2022-03-05 17:13:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:14:25 | INFO | train_inner | epoch 089:     17 / 49 loss=3.216, nll_loss=2.304, ppl=4.94, wps=27130.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.457, loss_scale=16, train_wall=201, gb_free=21.6, wall=10342
2022-03-05 17:15:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:15:41 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.468 | nll_loss 10.927 | ppl 1946.98 | wps 45546.6 | wpb 510.9 | bsz 1 | num_updates 4332 | best_loss 8.499
2022-03-05 17:15:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4332 updates
2022-03-05 17:15:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:15:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:15:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 89 @ 4332 updates, score 11.468) (writing took 1.8866413021460176 seconds)
2022-03-05 17:15:43 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-05 17:15:43 | INFO | train | epoch 089 | loss 3.151 | nll_loss 2.232 | ppl 4.7 | wps 27532.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4332 | lr 0.000480458 | gnorm 1.455 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10420
2022-03-05 17:15:43 | INFO | fairseq.trainer | begin training epoch 90
2022-03-05 17:15:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:17:36 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.537 | nll_loss 10.991 | ppl 2034.63 | wps 46387.1 | wpb 510.9 | bsz 1 | num_updates 4381 | best_loss 8.499
2022-03-05 17:17:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4381 updates
2022-03-05 17:17:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:17:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:17:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 90 @ 4381 updates, score 11.537) (writing took 1.896880628541112 seconds)
2022-03-05 17:17:38 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-05 17:17:38 | INFO | train | epoch 090 | loss 3.092 | nll_loss 2.167 | ppl 4.49 | wps 27551.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4381 | lr 0.000477764 | gnorm 1.406 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 10535
2022-03-05 17:17:38 | INFO | fairseq.trainer | begin training epoch 91
2022-03-05 17:17:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:17:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:18:23 | INFO | train_inner | epoch 091:     20 / 49 loss=3.101, nll_loss=2.177, ppl=4.52, wps=27325.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.416, loss_scale=16, train_wall=201, gb_free=21.6, wall=10580
2022-03-05 17:19:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:19:31 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.634 | nll_loss 11.1 | ppl 2195.21 | wps 45873.4 | wpb 510.9 | bsz 1 | num_updates 4429 | best_loss 8.499
2022-03-05 17:19:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4429 updates
2022-03-05 17:19:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:19:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:19:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 91 @ 4429 updates, score 11.634) (writing took 1.866769495420158 seconds)
2022-03-05 17:19:33 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-05 17:19:33 | INFO | train | epoch 091 | loss 3.036 | nll_loss 2.105 | ppl 4.3 | wps 27021.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4429 | lr 0.000475168 | gnorm 1.37 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10650
2022-03-05 17:19:33 | INFO | fairseq.trainer | begin training epoch 92
2022-03-05 17:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:21:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:21:27 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.736 | nll_loss 11.199 | ppl 2351.44 | wps 46175 | wpb 510.9 | bsz 1 | num_updates 4478 | best_loss 8.499
2022-03-05 17:21:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4478 updates
2022-03-05 17:21:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:21:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:21:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 92 @ 4478 updates, score 11.736) (writing took 1.898760112002492 seconds)
2022-03-05 17:21:29 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-05 17:21:29 | INFO | train | epoch 092 | loss 2.994 | nll_loss 2.058 | ppl 4.16 | wps 27537.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4478 | lr 0.000472561 | gnorm 1.431 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 10765
2022-03-05 17:21:29 | INFO | fairseq.trainer | begin training epoch 93
2022-03-05 17:21:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:22:18 | INFO | train_inner | epoch 093:     22 / 49 loss=2.993, nll_loss=2.057, ppl=4.16, wps=27592.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.39, loss_scale=16, train_wall=199, gb_free=21.6, wall=10815
2022-03-05 17:23:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:23:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:23:22 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.823 | nll_loss 11.287 | ppl 2498.66 | wps 45751.6 | wpb 510.9 | bsz 1 | num_updates 4526 | best_loss 8.499
2022-03-05 17:23:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4526 updates
2022-03-05 17:23:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:23:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:23:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 93 @ 4526 updates, score 11.823) (writing took 1.8395248744636774 seconds)
2022-03-05 17:23:24 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-05 17:23:24 | INFO | train | epoch 093 | loss 2.939 | nll_loss 1.997 | ppl 3.99 | wps 26993.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4526 | lr 0.000470049 | gnorm 1.327 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10881
2022-03-05 17:23:24 | INFO | fairseq.trainer | begin training epoch 94
2022-03-05 17:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:25:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:25:17 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.941 | nll_loss 11.419 | ppl 2738.97 | wps 45817.3 | wpb 510.9 | bsz 1 | num_updates 4575 | best_loss 8.499
2022-03-05 17:25:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4575 updates
2022-03-05 17:25:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:25:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:25:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 94 @ 4575 updates, score 11.941) (writing took 1.813016819767654 seconds)
2022-03-05 17:25:19 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-05 17:25:19 | INFO | train | epoch 094 | loss 2.895 | nll_loss 1.948 | ppl 3.86 | wps 27555.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4575 | lr 0.000467525 | gnorm 1.362 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10996
2022-03-05 17:25:19 | INFO | fairseq.trainer | begin training epoch 95
2022-03-05 17:25:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:26:15 | INFO | train_inner | epoch 095:     25 / 49 loss=2.892, nll_loss=1.945, ppl=3.85, wps=27320, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.34, loss_scale=16, train_wall=201, gb_free=21.6, wall=11052
2022-03-05 17:27:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:27:13 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 12.001 | nll_loss 11.468 | ppl 2833.52 | wps 45642.2 | wpb 510.9 | bsz 1 | num_updates 4624 | best_loss 8.499
2022-03-05 17:27:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4624 updates
2022-03-05 17:27:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:27:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:27:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 95 @ 4624 updates, score 12.001) (writing took 1.8256831709295511 seconds)
2022-03-05 17:27:15 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-05 17:27:15 | INFO | train | epoch 095 | loss 2.845 | nll_loss 1.893 | ppl 3.71 | wps 27537.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4624 | lr 0.000465041 | gnorm 1.323 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11112
2022-03-05 17:27:15 | INFO | fairseq.trainer | begin training epoch 96
2022-03-05 17:27:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:29:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:29:08 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 12.108 | nll_loss 11.59 | ppl 3082.73 | wps 46273.8 | wpb 510.9 | bsz 1 | num_updates 4673 | best_loss 8.499
2022-03-05 17:29:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4673 updates
2022-03-05 17:29:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:29:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 96 @ 4673 updates, score 12.108) (writing took 1.8334208391606808 seconds)
2022-03-05 17:29:10 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-05 17:29:10 | INFO | train | epoch 096 | loss 2.808 | nll_loss 1.851 | ppl 3.61 | wps 27567 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4673 | lr 0.000462596 | gnorm 1.37 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 11227
2022-03-05 17:29:10 | INFO | fairseq.trainer | begin training epoch 97
2022-03-05 17:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:30:11 | INFO | train_inner | epoch 097:     27 / 49 loss=2.803, nll_loss=1.846, ppl=3.6, wps=27587.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.335, loss_scale=32, train_wall=199, gb_free=21.6, wall=11287
2022-03-05 17:30:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:31:03 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 12.18 | nll_loss 11.663 | ppl 3242.03 | wps 46193.2 | wpb 510.9 | bsz 1 | num_updates 4721 | best_loss 8.499
2022-03-05 17:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4721 updates
2022-03-05 17:31:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:31:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:31:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 97 @ 4721 updates, score 12.18) (writing took 1.8303755801171064 seconds)
2022-03-05 17:31:05 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-05 17:31:05 | INFO | train | epoch 097 | loss 2.757 | nll_loss 1.796 | ppl 3.47 | wps 26998.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4721 | lr 0.000460239 | gnorm 1.3 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11342
2022-03-05 17:31:05 | INFO | fairseq.trainer | begin training epoch 98
2022-03-05 17:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:32:59 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.277 | nll_loss 11.756 | ppl 3459.58 | wps 45922.7 | wpb 510.9 | bsz 1 | num_updates 4770 | best_loss 8.499
2022-03-05 17:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4770 updates
2022-03-05 17:32:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:33:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:33:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 98 @ 4770 updates, score 12.277) (writing took 1.7999119758605957 seconds)
2022-03-05 17:33:01 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-05 17:33:01 | INFO | train | epoch 098 | loss 2.722 | nll_loss 1.756 | ppl 3.38 | wps 27576.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4770 | lr 0.000457869 | gnorm 1.312 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11457
2022-03-05 17:33:01 | INFO | fairseq.trainer | begin training epoch 99
2022-03-05 17:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:34:08 | INFO | train_inner | epoch 099:     30 / 49 loss=2.72, nll_loss=1.754, ppl=3.37, wps=27352.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.316, loss_scale=16, train_wall=201, gb_free=21.6, wall=11524
2022-03-05 17:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:34:54 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.336 | nll_loss 11.824 | ppl 3624.92 | wps 46270 | wpb 510.9 | bsz 1 | num_updates 4819 | best_loss 8.499
2022-03-05 17:34:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4819 updates
2022-03-05 17:34:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:34:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:34:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 99 @ 4819 updates, score 12.336) (writing took 1.7689290409907699 seconds)
2022-03-05 17:34:56 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-05 17:34:56 | INFO | train | epoch 099 | loss 2.683 | nll_loss 1.712 | ppl 3.28 | wps 27588.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4819 | lr 0.000455535 | gnorm 1.334 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 11573
2022-03-05 17:34:56 | INFO | fairseq.trainer | begin training epoch 100
2022-03-05 17:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:35:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:36:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:36:49 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.419 | nll_loss 11.902 | ppl 3826.74 | wps 46586.3 | wpb 510.9 | bsz 1 | num_updates 4867 | best_loss 8.499
2022-03-05 17:36:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4867 updates
2022-03-05 17:36:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:36:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:36:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 100 @ 4867 updates, score 12.419) (writing took 1.7801324678584933 seconds)
2022-03-05 17:36:51 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-05 17:36:51 | INFO | train | epoch 100 | loss 2.641 | nll_loss 1.666 | ppl 3.17 | wps 27020 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4867 | lr 0.000453283 | gnorm 1.288 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11688
2022-03-05 17:36:51 | INFO | fairseq.trainer | begin training epoch 101
2022-03-05 17:36:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:38:05 | INFO | train_inner | epoch 101:     33 / 49 loss=2.637, nll_loss=1.662, ppl=3.16, wps=27351.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.298, loss_scale=16, train_wall=201, gb_free=21.6, wall=11762
2022-03-05 17:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:38:44 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.531 | nll_loss 12.023 | ppl 4162.83 | wps 46194.9 | wpb 510.9 | bsz 1 | num_updates 4916 | best_loss 8.499
2022-03-05 17:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4916 updates
2022-03-05 17:38:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:38:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:38:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 101 @ 4916 updates, score 12.531) (writing took 1.7744990149512887 seconds)
2022-03-05 17:38:46 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-05 17:38:46 | INFO | train | epoch 101 | loss 2.605 | nll_loss 1.626 | ppl 3.09 | wps 27580.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4916 | lr 0.000451018 | gnorm 1.265 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 11803
2022-03-05 17:38:46 | INFO | fairseq.trainer | begin training epoch 102
2022-03-05 17:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:40:40 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.542 | nll_loss 12.025 | ppl 4167.37 | wps 46092.3 | wpb 510.9 | bsz 1 | num_updates 4965 | best_loss 8.499
2022-03-05 17:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4965 updates
2022-03-05 17:40:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:40:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:40:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 102 @ 4965 updates, score 12.542) (writing took 1.7699612816795707 seconds)
2022-03-05 17:40:41 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-05 17:40:41 | INFO | train | epoch 102 | loss 2.573 | nll_loss 1.59 | ppl 3.01 | wps 27593.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4965 | lr 0.000448787 | gnorm 1.28 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 11918
2022-03-05 17:40:41 | INFO | fairseq.trainer | begin training epoch 103
2022-03-05 17:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:40:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:42:02 | INFO | train_inner | epoch 103:     36 / 49 loss=2.564, nll_loss=1.581, ppl=2.99, wps=27371.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.268, loss_scale=16, train_wall=201, gb_free=21.6, wall=11999
2022-03-05 17:42:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:42:35 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.647 | nll_loss 12.145 | ppl 4530.06 | wps 45475.2 | wpb 510.9 | bsz 1 | num_updates 5013 | best_loss 8.499
2022-03-05 17:42:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5013 updates
2022-03-05 17:42:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:42:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:42:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 103 @ 5013 updates, score 12.647) (writing took 1.8117426596581936 seconds)
2022-03-05 17:42:37 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-05 17:42:37 | INFO | train | epoch 103 | loss 2.536 | nll_loss 1.549 | ppl 2.93 | wps 27016.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5013 | lr 0.000446633 | gnorm 1.251 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12033
2022-03-05 17:42:37 | INFO | fairseq.trainer | begin training epoch 104
2022-03-05 17:42:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:44:30 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.753 | nll_loss 12.244 | ppl 4849.42 | wps 45800.7 | wpb 510.9 | bsz 1 | num_updates 5062 | best_loss 8.499
2022-03-05 17:44:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5062 updates
2022-03-05 17:44:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:44:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:44:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 104 @ 5062 updates, score 12.753) (writing took 1.7454474465921521 seconds)
2022-03-05 17:44:32 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-05 17:44:32 | INFO | train | epoch 104 | loss 2.504 | nll_loss 1.514 | ppl 2.86 | wps 27573.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5062 | lr 0.000444466 | gnorm 1.251 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12149
2022-03-05 17:44:32 | INFO | fairseq.trainer | begin training epoch 105
2022-03-05 17:44:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:45:57 | INFO | train_inner | epoch 105:     38 / 49 loss=2.496, nll_loss=1.505, ppl=2.84, wps=27597.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.225, loss_scale=32, train_wall=199, gb_free=21.6, wall=12234
2022-03-05 17:46:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:46:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:46:25 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.82 | nll_loss 12.316 | ppl 5099.42 | wps 46134 | wpb 510.9 | bsz 1 | num_updates 5110 | best_loss 8.499
2022-03-05 17:46:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5110 updates
2022-03-05 17:46:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:46:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:46:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 105 @ 5110 updates, score 12.82) (writing took 1.7776757879182696 seconds)
2022-03-05 17:46:27 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-05 17:46:27 | INFO | train | epoch 105 | loss 2.474 | nll_loss 1.481 | ppl 2.79 | wps 27005.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5110 | lr 0.000442374 | gnorm 1.247 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12264
2022-03-05 17:46:27 | INFO | fairseq.trainer | begin training epoch 106
2022-03-05 17:46:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:48:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:48:20 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.989 | nll_loss 12.501 | ppl 5797.74 | wps 45280.3 | wpb 510.9 | bsz 1 | num_updates 5159 | best_loss 8.499
2022-03-05 17:48:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5159 updates
2022-03-05 17:48:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:48:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:48:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 106 @ 5159 updates, score 12.989) (writing took 1.7601439142599702 seconds)
2022-03-05 17:48:22 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-05 17:48:22 | INFO | train | epoch 106 | loss 2.439 | nll_loss 1.442 | ppl 2.72 | wps 27598.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5159 | lr 0.000440268 | gnorm 1.183 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12379
2022-03-05 17:48:22 | INFO | fairseq.trainer | begin training epoch 107
2022-03-05 17:48:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:49:54 | INFO | train_inner | epoch 107:     41 / 49 loss=2.434, nll_loss=1.436, ppl=2.71, wps=27367, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.21, loss_scale=16, train_wall=201, gb_free=21.6, wall=12471
2022-03-05 17:50:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:50:16 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.932 | nll_loss 12.444 | ppl 5570.84 | wps 45724.3 | wpb 510.9 | bsz 1 | num_updates 5208 | best_loss 8.499
2022-03-05 17:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5208 updates
2022-03-05 17:50:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:50:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 107 @ 5208 updates, score 12.932) (writing took 1.7809861600399017 seconds)
2022-03-05 17:50:17 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-05 17:50:17 | INFO | train | epoch 107 | loss 2.411 | nll_loss 1.412 | ppl 2.66 | wps 27579.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5208 | lr 0.000438192 | gnorm 1.204 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12494
2022-03-05 17:50:17 | INFO | fairseq.trainer | begin training epoch 108
2022-03-05 17:50:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:52:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:52:11 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 13.041 | nll_loss 12.555 | ppl 6017.72 | wps 46007.8 | wpb 510.9 | bsz 1 | num_updates 5257 | best_loss 8.499
2022-03-05 17:52:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5257 updates
2022-03-05 17:52:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:52:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:52:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 108 @ 5257 updates, score 13.041) (writing took 1.7259237375110388 seconds)
2022-03-05 17:52:13 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-05 17:52:13 | INFO | train | epoch 108 | loss 2.384 | nll_loss 1.381 | ppl 2.61 | wps 27598.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5257 | lr 0.000436145 | gnorm 1.18 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 12609
2022-03-05 17:52:13 | INFO | fairseq.trainer | begin training epoch 109
2022-03-05 17:52:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:52:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:53:51 | INFO | train_inner | epoch 109:     44 / 49 loss=2.376, nll_loss=1.372, ppl=2.59, wps=27355, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.199, loss_scale=16, train_wall=201, gb_free=21.6, wall=12708
2022-03-05 17:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:54:06 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 13.088 | nll_loss 12.606 | ppl 6236 | wps 45972.7 | wpb 510.9 | bsz 1 | num_updates 5305 | best_loss 8.499
2022-03-05 17:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5305 updates
2022-03-05 17:54:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:54:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 109 @ 5305 updates, score 13.088) (writing took 1.7426449423655868 seconds)
2022-03-05 17:54:08 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-05 17:54:08 | INFO | train | epoch 109 | loss 2.355 | nll_loss 1.349 | ppl 2.55 | wps 27011.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5305 | lr 0.000434167 | gnorm 1.182 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 12725
2022-03-05 17:54:08 | INFO | fairseq.trainer | begin training epoch 110
2022-03-05 17:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:56:01 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 13.15 | nll_loss 12.666 | ppl 6497.87 | wps 45621 | wpb 510.9 | bsz 1 | num_updates 5354 | best_loss 8.499
2022-03-05 17:56:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5354 updates
2022-03-05 17:56:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:56:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:56:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 110 @ 5354 updates, score 13.15) (writing took 1.761314544826746 seconds)
2022-03-05 17:56:03 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-05 17:56:03 | INFO | train | epoch 110 | loss 2.333 | nll_loss 1.325 | ppl 2.5 | wps 27577.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5354 | lr 0.000432176 | gnorm 1.2 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12840
2022-03-05 17:56:03 | INFO | fairseq.trainer | begin training epoch 111
2022-03-05 17:56:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:57:46 | INFO | train_inner | epoch 111:     46 / 49 loss=2.322, nll_loss=1.313, ppl=2.48, wps=27613, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5400, lr=0.000430331, gnorm=1.185, loss_scale=32, train_wall=199, gb_free=21.6, wall=12943
2022-03-05 17:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:57:56 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 13.175 | nll_loss 12.7 | ppl 6655.3 | wps 46171 | wpb 510.9 | bsz 1 | num_updates 5403 | best_loss 8.499
2022-03-05 17:57:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5403 updates
2022-03-05 17:57:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:57:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:57:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 111 @ 5403 updates, score 13.175) (writing took 1.7374031664803624 seconds)
2022-03-05 17:57:58 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-05 17:57:58 | INFO | train | epoch 111 | loss 2.306 | nll_loss 1.295 | ppl 2.45 | wps 27590.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5403 | lr 0.000430212 | gnorm 1.172 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 12955
2022-03-05 17:57:58 | INFO | fairseq.trainer | begin training epoch 112
2022-03-05 17:57:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:58:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:59:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:59:52 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 13.193 | nll_loss 12.707 | ppl 6686.32 | wps 46214.1 | wpb 510.9 | bsz 1 | num_updates 5451 | best_loss 8.499
2022-03-05 17:59:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5451 updates
2022-03-05 17:59:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:59:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 17:59:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 112 @ 5451 updates, score 13.193) (writing took 1.74735976010561 seconds)
2022-03-05 17:59:53 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-05 17:59:53 | INFO | train | epoch 112 | loss 2.279 | nll_loss 1.265 | ppl 2.4 | wps 27015 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5451 | lr 0.000428314 | gnorm 1.157 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13070
2022-03-05 17:59:53 | INFO | fairseq.trainer | begin training epoch 113
2022-03-05 17:59:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:01:42 | INFO | train_inner | epoch 113:     49 / 49 loss=2.269, nll_loss=1.255, ppl=2.39, wps=27350, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=5500, lr=0.000426401, gnorm=1.156, loss_scale=16, train_wall=200, gb_free=21.6, wall=13179
2022-03-05 18:01:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:01:47 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 13.253 | nll_loss 12.784 | ppl 7054.18 | wps 45871.5 | wpb 510.9 | bsz 1 | num_updates 5500 | best_loss 8.499
2022-03-05 18:01:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5500 updates
2022-03-05 18:01:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:01:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:01:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 113 @ 5500 updates, score 13.253) (writing took 1.727763107046485 seconds)
2022-03-05 18:01:49 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-05 18:01:49 | INFO | train | epoch 113 | loss 2.256 | nll_loss 1.24 | ppl 2.36 | wps 27598.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5500 | lr 0.000426401 | gnorm 1.149 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13185
2022-03-05 18:01:49 | INFO | fairseq.trainer | begin training epoch 114
2022-03-05 18:01:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:03:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:03:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:03:42 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 13.209 | nll_loss 12.724 | ppl 6764.61 | wps 46511.4 | wpb 510.9 | bsz 1 | num_updates 5548 | best_loss 8.499
2022-03-05 18:03:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5548 updates
2022-03-05 18:03:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:03:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:03:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 114 @ 5548 updates, score 13.209) (writing took 1.7326602563261986 seconds)
2022-03-05 18:03:44 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-05 18:03:44 | INFO | train | epoch 114 | loss 2.236 | nll_loss 1.218 | ppl 2.33 | wps 27069 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5548 | lr 0.000424553 | gnorm 1.177 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13300
2022-03-05 18:03:44 | INFO | fairseq.trainer | begin training epoch 115
2022-03-05 18:03:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:05:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:05:37 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 13.37 | nll_loss 12.896 | ppl 7623.43 | wps 45709.9 | wpb 510.9 | bsz 1 | num_updates 5597 | best_loss 8.499
2022-03-05 18:05:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5597 updates
2022-03-05 18:05:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:05:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:05:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 115 @ 5597 updates, score 13.37) (writing took 1.7345378706231713 seconds)
2022-03-05 18:05:39 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-05 18:05:39 | INFO | train | epoch 115 | loss 2.212 | nll_loss 1.192 | ppl 2.28 | wps 27580.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5597 | lr 0.00042269 | gnorm 1.132 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13416
2022-03-05 18:05:39 | INFO | fairseq.trainer | begin training epoch 116
2022-03-05 18:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:05:46 | INFO | train_inner | epoch 116:      3 / 49 loss=2.222, nll_loss=1.202, ppl=2.3, wps=26630, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.155, loss_scale=16, train_wall=201, gb_free=21.6, wall=13422
2022-03-05 18:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:07:32 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 13.461 | nll_loss 12.992 | ppl 8148.1 | wps 46212.4 | wpb 510.9 | bsz 1 | num_updates 5646 | best_loss 8.499
2022-03-05 18:07:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5646 updates
2022-03-05 18:07:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:07:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:07:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 116 @ 5646 updates, score 13.461) (writing took 1.7710614819079638 seconds)
2022-03-05 18:07:34 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-05 18:07:34 | INFO | train | epoch 116 | loss 2.189 | nll_loss 1.166 | ppl 2.24 | wps 27568.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5646 | lr 0.000420852 | gnorm 1.082 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 13531
2022-03-05 18:07:34 | INFO | fairseq.trainer | begin training epoch 117
2022-03-05 18:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:09:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:09:28 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 13.368 | nll_loss 12.893 | ppl 7607.31 | wps 46377 | wpb 510.9 | bsz 1 | num_updates 5694 | best_loss 8.499
2022-03-05 18:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5694 updates
2022-03-05 18:09:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:09:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:09:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 117 @ 5694 updates, score 13.368) (writing took 1.7611789694055915 seconds)
2022-03-05 18:09:29 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-05 18:09:29 | INFO | train | epoch 117 | loss 2.169 | nll_loss 1.144 | ppl 2.21 | wps 27018.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5694 | lr 0.000419075 | gnorm 1.105 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13646
2022-03-05 18:09:29 | INFO | fairseq.trainer | begin training epoch 118
2022-03-05 18:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:09:43 | INFO | train_inner | epoch 118:      6 / 49 loss=2.176, nll_loss=1.153, ppl=2.22, wps=27351, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.091, loss_scale=16, train_wall=201, gb_free=21.6, wall=13660
2022-03-05 18:11:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:11:23 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.434 | nll_loss 12.969 | ppl 8017.08 | wps 45799.9 | wpb 510.9 | bsz 1 | num_updates 5743 | best_loss 8.499
2022-03-05 18:11:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5743 updates
2022-03-05 18:11:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:11:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:11:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 118 @ 5743 updates, score 13.434) (writing took 1.7582417698577046 seconds)
2022-03-05 18:11:25 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-05 18:11:25 | INFO | train | epoch 118 | loss 2.151 | nll_loss 1.126 | ppl 2.18 | wps 27563.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5743 | lr 0.000417283 | gnorm 1.111 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 13761
2022-03-05 18:11:25 | INFO | fairseq.trainer | begin training epoch 119
2022-03-05 18:11:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:13:18 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 13.419 | nll_loss 12.941 | ppl 7862.97 | wps 45936.7 | wpb 510.9 | bsz 1 | num_updates 5792 | best_loss 8.499
2022-03-05 18:13:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5792 updates
2022-03-05 18:13:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:13:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:13:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 119 @ 5792 updates, score 13.419) (writing took 1.7164048803970218 seconds)
2022-03-05 18:13:20 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-05 18:13:20 | INFO | train | epoch 119 | loss 2.13 | nll_loss 1.103 | ppl 2.15 | wps 27596.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5792 | lr 0.000415514 | gnorm 1.091 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13877
2022-03-05 18:13:20 | INFO | fairseq.trainer | begin training epoch 120
2022-03-05 18:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:13:38 | INFO | train_inner | epoch 120:      8 / 49 loss=2.137, nll_loss=1.111, ppl=2.16, wps=27614.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.1, loss_scale=16, train_wall=199, gb_free=21.6, wall=13895
2022-03-05 18:14:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:15:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:15:13 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13.451 | nll_loss 12.984 | ppl 8102.28 | wps 46499.8 | wpb 510.9 | bsz 1 | num_updates 5840 | best_loss 8.499
2022-03-05 18:15:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5840 updates
2022-03-05 18:15:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:15:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:15:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 120 @ 5840 updates, score 13.451) (writing took 1.750165487639606 seconds)
2022-03-05 18:15:15 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-05 18:15:15 | INFO | train | epoch 120 | loss 2.111 | nll_loss 1.082 | ppl 2.12 | wps 27026.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5840 | lr 0.000413803 | gnorm 1.078 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13992
2022-03-05 18:15:15 | INFO | fairseq.trainer | begin training epoch 121
2022-03-05 18:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:17:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:17:08 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.594 | nll_loss 13.138 | ppl 9014.23 | wps 46054.3 | wpb 510.9 | bsz 1 | num_updates 5889 | best_loss 8.499
2022-03-05 18:17:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5889 updates
2022-03-05 18:17:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:17:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:17:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 121 @ 5889 updates, score 13.594) (writing took 1.6973901744931936 seconds)
2022-03-05 18:17:10 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-05 18:17:10 | INFO | train | epoch 121 | loss 2.096 | nll_loss 1.066 | ppl 2.09 | wps 27607.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5889 | lr 0.000412078 | gnorm 1.081 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14107
2022-03-05 18:17:10 | INFO | fairseq.trainer | begin training epoch 122
2022-03-05 18:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:17:35 | INFO | train_inner | epoch 122:     11 / 49 loss=2.099, nll_loss=1.069, ppl=2.1, wps=27374.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.08, loss_scale=16, train_wall=201, gb_free=21.6, wall=14132
2022-03-05 18:18:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:19:03 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.556 | nll_loss 13.085 | ppl 8687.83 | wps 45362.6 | wpb 510.9 | bsz 1 | num_updates 5938 | best_loss 8.499
2022-03-05 18:19:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5938 updates
2022-03-05 18:19:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:19:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:19:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 122 @ 5938 updates, score 13.556) (writing took 2.158183293417096 seconds)
2022-03-05 18:19:06 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-05 18:19:06 | INFO | train | epoch 122 | loss 2.079 | nll_loss 1.047 | ppl 2.07 | wps 27504 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 5938 | lr 0.000410374 | gnorm 1.077 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14222
2022-03-05 18:19:06 | INFO | fairseq.trainer | begin training epoch 123
2022-03-05 18:19:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:20:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:20:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:20:59 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 13.624 | nll_loss 13.169 | ppl 9209.82 | wps 46507.1 | wpb 510.9 | bsz 1 | num_updates 5986 | best_loss 8.499
2022-03-05 18:20:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5986 updates
2022-03-05 18:20:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:21:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:21:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 123 @ 5986 updates, score 13.624) (writing took 1.7083675526082516 seconds)
2022-03-05 18:21:01 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-05 18:21:01 | INFO | train | epoch 123 | loss 2.057 | nll_loss 1.024 | ppl 2.03 | wps 27038.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5986 | lr 0.000408725 | gnorm 1.03 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14338
2022-03-05 18:21:01 | INFO | fairseq.trainer | begin training epoch 124
2022-03-05 18:21:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:21:32 | INFO | train_inner | epoch 124:     14 / 49 loss=2.064, nll_loss=1.031, ppl=2.04, wps=27322.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.045, loss_scale=16, train_wall=201, gb_free=21.6, wall=14369
2022-03-05 18:22:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:22:54 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.622 | nll_loss 13.159 | ppl 9144.71 | wps 46039.4 | wpb 510.9 | bsz 1 | num_updates 6035 | best_loss 8.499
2022-03-05 18:22:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6035 updates
2022-03-05 18:22:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:22:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:22:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 124 @ 6035 updates, score 13.622) (writing took 1.7509679794311523 seconds)
2022-03-05 18:22:56 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-05 18:22:56 | INFO | train | epoch 124 | loss 2.046 | nll_loss 1.012 | ppl 2.02 | wps 27579.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6035 | lr 0.000407063 | gnorm 1.057 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14453
2022-03-05 18:22:56 | INFO | fairseq.trainer | begin training epoch 125
2022-03-05 18:22:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:24:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:24:49 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.682 | nll_loss 13.222 | ppl 9554.71 | wps 45777 | wpb 510.9 | bsz 1 | num_updates 6084 | best_loss 8.499
2022-03-05 18:24:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6084 updates
2022-03-05 18:24:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:24:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:24:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 125 @ 6084 updates, score 13.682) (writing took 1.6912650875747204 seconds)
2022-03-05 18:24:51 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-05 18:24:51 | INFO | train | epoch 125 | loss 2.026 | nll_loss 0.991 | ppl 1.99 | wps 27574.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6084 | lr 0.00040542 | gnorm 1.029 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 14568
2022-03-05 18:24:51 | INFO | fairseq.trainer | begin training epoch 126
2022-03-05 18:24:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:25:27 | INFO | train_inner | epoch 126:     16 / 49 loss=2.03, nll_loss=0.995, ppl=1.99, wps=27619.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=1.04, loss_scale=32, train_wall=199, gb_free=21.6, wall=14604
2022-03-05 18:25:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:26:45 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.631 | nll_loss 13.177 | ppl 9262.81 | wps 45806.9 | wpb 510.9 | bsz 1 | num_updates 6132 | best_loss 8.499
2022-03-05 18:26:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6132 updates
2022-03-05 18:26:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:26:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 126 @ 6132 updates, score 13.631) (writing took 1.7356527615338564 seconds)
2022-03-05 18:26:46 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-05 18:26:46 | INFO | train | epoch 126 | loss 2.015 | nll_loss 0.978 | ppl 1.97 | wps 27033.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6132 | lr 0.00040383 | gnorm 1.033 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14683
2022-03-05 18:26:46 | INFO | fairseq.trainer | begin training epoch 127
2022-03-05 18:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:28:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:28:40 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.728 | nll_loss 13.275 | ppl 9913.56 | wps 46075.4 | wpb 510.9 | bsz 1 | num_updates 6181 | best_loss 8.499
2022-03-05 18:28:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6181 updates
2022-03-05 18:28:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:28:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:28:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 127 @ 6181 updates, score 13.728) (writing took 1.6934705758467317 seconds)
2022-03-05 18:28:41 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-05 18:28:41 | INFO | train | epoch 127 | loss 2 | nll_loss 0.962 | ppl 1.95 | wps 27599.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6181 | lr 0.000402226 | gnorm 1.016 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14798
2022-03-05 18:28:41 | INFO | fairseq.trainer | begin training epoch 128
2022-03-05 18:28:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:29:24 | INFO | train_inner | epoch 128:     19 / 49 loss=2.001, nll_loss=0.964, ppl=1.95, wps=27376.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=1.025, loss_scale=16, train_wall=201, gb_free=21.6, wall=14841
2022-03-05 18:29:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:30:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:30:35 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.703 | nll_loss 13.249 | ppl 9733.35 | wps 46323.2 | wpb 510.9 | bsz 1 | num_updates 6229 | best_loss 8.499
2022-03-05 18:30:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6229 updates
2022-03-05 18:30:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:30:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:30:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 128 @ 6229 updates, score 13.703) (writing took 1.7087201671674848 seconds)
2022-03-05 18:30:37 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-05 18:30:37 | INFO | train | epoch 128 | loss 1.985 | nll_loss 0.947 | ppl 1.93 | wps 27037.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6229 | lr 0.000400674 | gnorm 1.029 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14913
2022-03-05 18:30:37 | INFO | fairseq.trainer | begin training epoch 129
2022-03-05 18:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:32:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:32:30 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.706 | nll_loss 13.256 | ppl 9781.84 | wps 46067.7 | wpb 510.9 | bsz 1 | num_updates 6278 | best_loss 8.499
2022-03-05 18:32:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6278 updates
2022-03-05 18:32:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:32:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:32:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 129 @ 6278 updates, score 13.706) (writing took 1.6863080328330398 seconds)
2022-03-05 18:32:32 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-05 18:32:32 | INFO | train | epoch 129 | loss 1.972 | nll_loss 0.933 | ppl 1.91 | wps 27626.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6278 | lr 0.000399107 | gnorm 1.009 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15028
2022-03-05 18:32:32 | INFO | fairseq.trainer | begin training epoch 130
2022-03-05 18:32:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:33:21 | INFO | train_inner | epoch 130:     22 / 49 loss=1.973, nll_loss=0.934, ppl=1.91, wps=27375.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=1.011, loss_scale=8, train_wall=201, gb_free=21.6, wall=15078
2022-03-05 18:34:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:34:25 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.759 | nll_loss 13.297 | ppl 10066.2 | wps 46021.1 | wpb 510.9 | bsz 1 | num_updates 6327 | best_loss 8.499
2022-03-05 18:34:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6327 updates
2022-03-05 18:34:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:34:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:34:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 130 @ 6327 updates, score 13.759) (writing took 1.7258162666112185 seconds)
2022-03-05 18:34:27 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-05 18:34:27 | INFO | train | epoch 130 | loss 1.958 | nll_loss 0.918 | ppl 1.89 | wps 27597.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6327 | lr 0.000397559 | gnorm 0.983 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15144
2022-03-05 18:34:27 | INFO | fairseq.trainer | begin training epoch 131
2022-03-05 18:34:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:36:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:36:20 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.777 | nll_loss 13.325 | ppl 10258.4 | wps 45850.6 | wpb 510.9 | bsz 1 | num_updates 6376 | best_loss 8.499
2022-03-05 18:36:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6376 updates
2022-03-05 18:36:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:36:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:36:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 131 @ 6376 updates, score 13.777) (writing took 1.7134361239150167 seconds)
2022-03-05 18:36:22 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-05 18:36:22 | INFO | train | epoch 131 | loss 1.944 | nll_loss 0.903 | ppl 1.87 | wps 27595 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6376 | lr 0.000396028 | gnorm 0.982 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15259
2022-03-05 18:36:22 | INFO | fairseq.trainer | begin training epoch 132
2022-03-05 18:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:37:16 | INFO | train_inner | epoch 132:     24 / 49 loss=1.943, nll_loss=0.903, ppl=1.87, wps=27628, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.974, loss_scale=16, train_wall=199, gb_free=21.6, wall=15313
2022-03-05 18:38:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:38:16 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 13.818 | nll_loss 13.371 | ppl 10593.9 | wps 45651.4 | wpb 510.9 | bsz 1 | num_updates 6425 | best_loss 8.499
2022-03-05 18:38:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6425 updates
2022-03-05 18:38:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:38:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 132 @ 6425 updates, score 13.818) (writing took 1.707647561095655 seconds)
2022-03-05 18:38:17 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-05 18:38:17 | INFO | train | epoch 132 | loss 1.929 | nll_loss 0.887 | ppl 1.85 | wps 27569.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6425 | lr 0.000394515 | gnorm 0.96 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 15374
2022-03-05 18:38:17 | INFO | fairseq.trainer | begin training epoch 133
2022-03-05 18:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:39:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:40:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:40:11 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 13.822 | nll_loss 13.368 | ppl 10572.5 | wps 45730.4 | wpb 510.9 | bsz 1 | num_updates 6473 | best_loss 8.499
2022-03-05 18:40:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6473 updates
2022-03-05 18:40:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:40:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:40:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 133 @ 6473 updates, score 13.822) (writing took 1.6970042064785957 seconds)
2022-03-05 18:40:12 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-05 18:40:12 | INFO | train | epoch 133 | loss 1.918 | nll_loss 0.876 | ppl 1.84 | wps 27025.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6473 | lr 0.000393049 | gnorm 0.98 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15489
2022-03-05 18:40:12 | INFO | fairseq.trainer | begin training epoch 134
2022-03-05 18:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:41:13 | INFO | train_inner | epoch 134:     27 / 49 loss=1.917, nll_loss=0.875, ppl=1.83, wps=27364, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.97, loss_scale=16, train_wall=201, gb_free=21.6, wall=15550
2022-03-05 18:42:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:42:06 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 13.825 | nll_loss 13.381 | ppl 10664.9 | wps 45996.5 | wpb 510.9 | bsz 1 | num_updates 6522 | best_loss 8.499
2022-03-05 18:42:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6522 updates
2022-03-05 18:42:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:42:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:42:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 134 @ 6522 updates, score 13.825) (writing took 1.703006953932345 seconds)
2022-03-05 18:42:07 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-05 18:42:07 | INFO | train | epoch 134 | loss 1.907 | nll_loss 0.865 | ppl 1.82 | wps 27627.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6522 | lr 0.00039157 | gnorm 0.966 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15604
2022-03-05 18:42:07 | INFO | fairseq.trainer | begin training epoch 135
2022-03-05 18:42:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:43:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:44:01 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 13.779 | nll_loss 13.332 | ppl 10310.4 | wps 45978 | wpb 510.9 | bsz 1 | num_updates 6571 | best_loss 8.499
2022-03-05 18:44:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6571 updates
2022-03-05 18:44:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:44:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:44:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 135 @ 6571 updates, score 13.779) (writing took 1.706961794756353 seconds)
2022-03-05 18:44:03 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-05 18:44:03 | INFO | train | epoch 135 | loss 1.896 | nll_loss 0.853 | ppl 1.81 | wps 27598.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6571 | lr 0.000390107 | gnorm 0.943 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15719
2022-03-05 18:44:03 | INFO | fairseq.trainer | begin training epoch 136
2022-03-05 18:44:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:44:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:45:10 | INFO | train_inner | epoch 136:     30 / 49 loss=1.896, nll_loss=0.853, ppl=1.81, wps=27411.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.954, loss_scale=16, train_wall=201, gb_free=21.6, wall=15786
2022-03-05 18:45:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:45:55 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 13.945 | nll_loss 13.51 | ppl 11662.6 | wps 46844.3 | wpb 510.9 | bsz 1 | num_updates 6619 | best_loss 8.499
2022-03-05 18:45:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6619 updates
2022-03-05 18:45:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:45:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 136 @ 6619 updates, score 13.945) (writing took 1.6887768795713782 seconds)
2022-03-05 18:45:57 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-05 18:45:57 | INFO | train | epoch 136 | loss 1.884 | nll_loss 0.84 | ppl 1.79 | wps 27175.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6619 | lr 0.00038869 | gnorm 0.957 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15834
2022-03-05 18:45:57 | INFO | fairseq.trainer | begin training epoch 137
2022-03-05 18:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:46:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:47:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:47:50 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 13.852 | nll_loss 13.412 | ppl 10897.9 | wps 46795.7 | wpb 510.9 | bsz 1 | num_updates 6667 | best_loss 8.499
2022-03-05 18:47:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6667 updates
2022-03-05 18:47:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:47:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:47:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 137 @ 6667 updates, score 13.852) (writing took 1.6999868089333177 seconds)
2022-03-05 18:47:51 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-05 18:47:51 | INFO | train | epoch 137 | loss 1.873 | nll_loss 0.829 | ppl 1.78 | wps 27234.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6667 | lr 0.000387289 | gnorm 0.949 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15948
2022-03-05 18:47:51 | INFO | fairseq.trainer | begin training epoch 138
2022-03-05 18:47:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:49:05 | INFO | train_inner | epoch 138:     33 / 49 loss=1.872, nll_loss=0.828, ppl=1.77, wps=27570.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.948, loss_scale=8, train_wall=200, gb_free=21.6, wall=16022
2022-03-05 18:49:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:49:44 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 13.858 | nll_loss 13.418 | ppl 10944.4 | wps 47054 | wpb 510.9 | bsz 1 | num_updates 6716 | best_loss 8.499
2022-03-05 18:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6716 updates
2022-03-05 18:49:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:49:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:49:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 138 @ 6716 updates, score 13.858) (writing took 1.7140032341703773 seconds)
2022-03-05 18:49:46 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-05 18:49:46 | INFO | train | epoch 138 | loss 1.861 | nll_loss 0.817 | ppl 1.76 | wps 27806.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6716 | lr 0.000385873 | gnorm 0.931 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16063
2022-03-05 18:49:46 | INFO | fairseq.trainer | begin training epoch 139
2022-03-05 18:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:51:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:51:38 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 13.853 | nll_loss 13.411 | ppl 10894.1 | wps 46495.8 | wpb 510.9 | bsz 1 | num_updates 6765 | best_loss 8.499
2022-03-05 18:51:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6765 updates
2022-03-05 18:51:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:51:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:51:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 139 @ 6765 updates, score 13.853) (writing took 1.6697948016226292 seconds)
2022-03-05 18:51:40 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-05 18:51:40 | INFO | train | epoch 139 | loss 1.852 | nll_loss 0.808 | ppl 1.75 | wps 27802.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6765 | lr 0.000384473 | gnorm 0.921 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16177
2022-03-05 18:51:40 | INFO | fairseq.trainer | begin training epoch 140
2022-03-05 18:51:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:52:58 | INFO | train_inner | epoch 140:     35 / 49 loss=1.85, nll_loss=0.805, ppl=1.75, wps=27835.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.92, loss_scale=16, train_wall=198, gb_free=21.6, wall=16255
2022-03-05 18:53:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:53:33 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 13.841 | nll_loss 13.41 | ppl 10882.1 | wps 46733.6 | wpb 510.9 | bsz 1 | num_updates 6814 | best_loss 8.499
2022-03-05 18:53:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6814 updates
2022-03-05 18:53:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:53:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:53:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 140 @ 6814 updates, score 13.841) (writing took 1.6983061712235212 seconds)
2022-03-05 18:53:34 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-05 18:53:34 | INFO | train | epoch 140 | loss 1.841 | nll_loss 0.796 | ppl 1.74 | wps 27795.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6814 | lr 0.000383088 | gnorm 0.915 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16291
2022-03-05 18:53:34 | INFO | fairseq.trainer | begin training epoch 141
2022-03-05 18:53:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:55:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:55:27 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 13.912 | nll_loss 13.476 | ppl 11393.9 | wps 46863.6 | wpb 510.9 | bsz 1 | num_updates 6863 | best_loss 8.499
2022-03-05 18:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6863 updates
2022-03-05 18:55:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:55:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:55:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 141 @ 6863 updates, score 13.912) (writing took 1.7189055746421218 seconds)
2022-03-05 18:55:29 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-05 18:55:29 | INFO | train | epoch 141 | loss 1.832 | nll_loss 0.787 | ppl 1.73 | wps 27771.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6863 | lr 0.000381718 | gnorm 0.924 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16406
2022-03-05 18:55:29 | INFO | fairseq.trainer | begin training epoch 142
2022-03-05 18:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:56:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:56:53 | INFO | train_inner | epoch 142:     38 / 49 loss=1.829, nll_loss=0.784, ppl=1.72, wps=27544.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.922, loss_scale=16, train_wall=200, gb_free=21.6, wall=16490
2022-03-05 18:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:57:22 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 13.917 | nll_loss 13.483 | ppl 11453.3 | wps 46589.2 | wpb 510.9 | bsz 1 | num_updates 6911 | best_loss 8.499
2022-03-05 18:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6911 updates
2022-03-05 18:57:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:57:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:57:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 142 @ 6911 updates, score 13.917) (writing took 1.6878726398572326 seconds)
2022-03-05 18:57:23 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-05 18:57:23 | INFO | train | epoch 142 | loss 1.821 | nll_loss 0.775 | ppl 1.71 | wps 27182.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6911 | lr 0.00038039 | gnorm 0.926 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16520
2022-03-05 18:57:23 | INFO | fairseq.trainer | begin training epoch 143
2022-03-05 18:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:59:16 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 13.956 | nll_loss 13.522 | ppl 11760.7 | wps 46568.8 | wpb 510.9 | bsz 1 | num_updates 6960 | best_loss 8.499
2022-03-05 18:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6960 updates
2022-03-05 18:59:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 18:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 143 @ 6960 updates, score 13.956) (writing took 1.6837298115715384 seconds)
2022-03-05 18:59:18 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-05 18:59:18 | INFO | train | epoch 143 | loss 1.812 | nll_loss 0.767 | ppl 1.7 | wps 27758.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6960 | lr 0.000379049 | gnorm 0.911 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16635
2022-03-05 18:59:18 | INFO | fairseq.trainer | begin training epoch 144
2022-03-05 18:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:00:47 | INFO | train_inner | epoch 144:     40 / 49 loss=1.811, nll_loss=0.766, ppl=1.7, wps=27802.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.915, loss_scale=16, train_wall=198, gb_free=21.6, wall=16724
2022-03-05 19:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:01:10 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 13.962 | nll_loss 13.523 | ppl 11771.5 | wps 46928.8 | wpb 510.9 | bsz 1 | num_updates 7009 | best_loss 8.499
2022-03-05 19:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7009 updates
2022-03-05 19:01:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:01:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:01:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 144 @ 7009 updates, score 13.962) (writing took 1.6916746450588107 seconds)
2022-03-05 19:01:12 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-05 19:01:12 | INFO | train | epoch 144 | loss 1.806 | nll_loss 0.76 | ppl 1.69 | wps 27799 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7009 | lr 0.000377722 | gnorm 0.904 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16749
2022-03-05 19:01:12 | INFO | fairseq.trainer | begin training epoch 145
2022-03-05 19:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:01:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:03:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:03:05 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 14.001 | nll_loss 13.568 | ppl 12146.2 | wps 46606.9 | wpb 510.9 | bsz 1 | num_updates 7057 | best_loss 8.499
2022-03-05 19:03:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7057 updates
2022-03-05 19:03:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:03:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:03:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 145 @ 7057 updates, score 14.001) (writing took 1.7213551942259073 seconds)
2022-03-05 19:03:07 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-05 19:03:07 | INFO | train | epoch 145 | loss 1.792 | nll_loss 0.746 | ppl 1.68 | wps 27194.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7057 | lr 0.000376435 | gnorm 0.865 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16863
2022-03-05 19:03:07 | INFO | fairseq.trainer | begin training epoch 146
2022-03-05 19:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:04:43 | INFO | train_inner | epoch 146:     43 / 49 loss=1.791, nll_loss=0.745, ppl=1.68, wps=27484.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.871, loss_scale=16, train_wall=200, gb_free=21.6, wall=16960
2022-03-05 19:04:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:05:00 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 13.926 | nll_loss 13.492 | ppl 11524.1 | wps 45603.5 | wpb 510.9 | bsz 1 | num_updates 7106 | best_loss 8.499
2022-03-05 19:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7106 updates
2022-03-05 19:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:05:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:05:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 146 @ 7106 updates, score 13.926) (writing took 1.6982326284050941 seconds)
2022-03-05 19:05:02 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-05 19:05:02 | INFO | train | epoch 146 | loss 1.786 | nll_loss 0.74 | ppl 1.67 | wps 27605.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7106 | lr 0.000375135 | gnorm 0.882 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16978
2022-03-05 19:05:02 | INFO | fairseq.trainer | begin training epoch 147
2022-03-05 19:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:06:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 19:06:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:06:55 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 14.025 | nll_loss 13.599 | ppl 12410.9 | wps 45745.6 | wpb 510.9 | bsz 1 | num_updates 7154 | best_loss 8.499
2022-03-05 19:06:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7154 updates
2022-03-05 19:06:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:06:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:06:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 147 @ 7154 updates, score 14.025) (writing took 1.733927994966507 seconds)
2022-03-05 19:06:57 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-05 19:06:57 | INFO | train | epoch 147 | loss 1.777 | nll_loss 0.731 | ppl 1.66 | wps 27000.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7154 | lr 0.000373874 | gnorm 0.873 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 17094
2022-03-05 19:06:57 | INFO | fairseq.trainer | begin training epoch 148
2022-03-05 19:06:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:08:40 | INFO | train_inner | epoch 148:     46 / 49 loss=1.776, nll_loss=0.73, ppl=1.66, wps=27334, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.879, loss_scale=8, train_wall=201, gb_free=21.6, wall=17197
2022-03-05 19:08:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:08:50 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 14.026 | nll_loss 13.602 | ppl 12431.4 | wps 46508.2 | wpb 510.9 | bsz 1 | num_updates 7203 | best_loss 8.499
2022-03-05 19:08:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7203 updates
2022-03-05 19:08:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:08:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:08:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 148 @ 7203 updates, score 14.026) (writing took 1.7056186916306615 seconds)
2022-03-05 19:08:52 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-05 19:08:52 | INFO | train | epoch 148 | loss 1.771 | nll_loss 0.725 | ppl 1.65 | wps 27571.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7203 | lr 0.0003726 | gnorm 0.884 | loss_scale 8 | train_wall 98 | gb_free 21.6 | wall 17209
2022-03-05 19:08:52 | INFO | fairseq.trainer | begin training epoch 149
2022-03-05 19:08:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:10:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:10:46 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 13.973 | nll_loss 13.547 | ppl 11972.6 | wps 45927.6 | wpb 510.9 | bsz 1 | num_updates 7252 | best_loss 8.499
2022-03-05 19:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7252 updates
2022-03-05 19:10:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:10:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:10:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 149 @ 7252 updates, score 13.973) (writing took 1.69248460046947 seconds)
2022-03-05 19:10:47 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-05 19:10:47 | INFO | train | epoch 149 | loss 1.761 | nll_loss 0.714 | ppl 1.64 | wps 27637.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7252 | lr 0.000371339 | gnorm 0.861 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 17324
2022-03-05 19:10:47 | INFO | fairseq.trainer | begin training epoch 150
2022-03-05 19:10:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:12:35 | INFO | train_inner | epoch 150:     48 / 49 loss=1.759, nll_loss=0.712, ppl=1.64, wps=27645.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7300, lr=0.000370117, gnorm=0.868, loss_scale=16, train_wall=199, gb_free=21.6, wall=17432
2022-03-05 19:12:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:12:41 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 14.008 | nll_loss 13.588 | ppl 12311.8 | wps 46203.9 | wpb 510.9 | bsz 1 | num_updates 7301 | best_loss 8.499
2022-03-05 19:12:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7301 updates
2022-03-05 19:12:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:12:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 150 @ 7301 updates, score 14.008) (writing took 1.6684328792616725 seconds)
2022-03-05 19:12:42 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-05 19:12:42 | INFO | train | epoch 150 | loss 1.755 | nll_loss 0.708 | ppl 1.63 | wps 27594.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7301 | lr 0.000370091 | gnorm 0.872 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 17439
2022-03-05 19:12:42 | INFO | fairseq.trainer | begin training epoch 151
2022-03-05 19:12:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:14:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:14:35 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 13.973 | nll_loss 13.541 | ppl 11919.4 | wps 46846.1 | wpb 510.9 | bsz 1 | num_updates 7350 | best_loss 8.499
2022-03-05 19:14:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7350 updates
2022-03-05 19:14:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:14:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:14:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 151 @ 7350 updates, score 13.973) (writing took 1.6597582073882222 seconds)
2022-03-05 19:14:37 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-05 19:14:37 | INFO | train | epoch 151 | loss 1.745 | nll_loss 0.699 | ppl 1.62 | wps 27695.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7350 | lr 0.000368856 | gnorm 0.854 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17554
2022-03-05 19:14:37 | INFO | fairseq.trainer | begin training epoch 152
2022-03-05 19:14:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:16:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 19:16:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:16:30 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 13.888 | nll_loss 13.455 | ppl 11226.6 | wps 46353.4 | wpb 510.9 | bsz 1 | num_updates 7398 | best_loss 8.499
2022-03-05 19:16:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7398 updates
2022-03-05 19:16:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:16:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:16:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 152 @ 7398 updates, score 13.888) (writing took 1.689535092562437 seconds)
2022-03-05 19:16:31 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-05 19:16:31 | INFO | train | epoch 152 | loss 1.739 | nll_loss 0.693 | ppl 1.62 | wps 27221.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7398 | lr 0.000367657 | gnorm 0.882 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 17668
2022-03-05 19:16:31 | INFO | fairseq.trainer | begin training epoch 153
2022-03-05 19:16:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:16:36 | INFO | train_inner | epoch 153:      2 / 49 loss=1.742, nll_loss=0.695, ppl=1.62, wps=26754.7, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=7400, lr=0.000367607, gnorm=0.869, loss_scale=8, train_wall=199, gb_free=21.6, wall=17673
2022-03-05 19:18:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:18:24 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 14.006 | nll_loss 13.579 | ppl 12238 | wps 46712.7 | wpb 510.9 | bsz 1 | num_updates 7447 | best_loss 8.499
2022-03-05 19:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7447 updates
2022-03-05 19:18:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:18:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:18:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 153 @ 7447 updates, score 14.006) (writing took 1.6740919640287757 seconds)
2022-03-05 19:18:26 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-05 19:18:26 | INFO | train | epoch 153 | loss 1.731 | nll_loss 0.684 | ppl 1.61 | wps 27795.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7447 | lr 0.000366445 | gnorm 0.824 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 17783
2022-03-05 19:18:26 | INFO | fairseq.trainer | begin training epoch 154
2022-03-05 19:18:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:20:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:20:18 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 13.898 | nll_loss 13.474 | ppl 11379 | wps 46732.7 | wpb 510.9 | bsz 1 | num_updates 7496 | best_loss 8.499
2022-03-05 19:20:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7496 updates
2022-03-05 19:20:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:20:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:20:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 154 @ 7496 updates, score 13.898) (writing took 1.6582737360149622 seconds)
2022-03-05 19:20:20 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-05 19:20:20 | INFO | train | epoch 154 | loss 1.723 | nll_loss 0.676 | ppl 1.6 | wps 27818.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7496 | lr 0.000365246 | gnorm 0.831 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 17897
2022-03-05 19:20:20 | INFO | fairseq.trainer | begin training epoch 155
2022-03-05 19:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:20:29 | INFO | train_inner | epoch 155:      4 / 49 loss=1.725, nll_loss=0.679, ppl=1.6, wps=27840.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.827, loss_scale=8, train_wall=198, gb_free=21.6, wall=17906
2022-03-05 19:22:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:22:13 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 14.001 | nll_loss 13.575 | ppl 12203.8 | wps 47047.9 | wpb 510.9 | bsz 1 | num_updates 7545 | best_loss 8.499
2022-03-05 19:22:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7545 updates
2022-03-05 19:22:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:22:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:22:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 155 @ 7545 updates, score 14.001) (writing took 1.6654263325035572 seconds)
2022-03-05 19:22:14 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-05 19:22:14 | INFO | train | epoch 155 | loss 1.716 | nll_loss 0.67 | ppl 1.59 | wps 27803.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7545 | lr 0.000364058 | gnorm 0.836 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18011
2022-03-05 19:22:14 | INFO | fairseq.trainer | begin training epoch 156
2022-03-05 19:22:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:24:07 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 14.052 | nll_loss 13.633 | ppl 12708.2 | wps 46977.9 | wpb 510.9 | bsz 1 | num_updates 7594 | best_loss 8.499
2022-03-05 19:24:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7594 updates
2022-03-05 19:24:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:24:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:24:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 156 @ 7594 updates, score 14.052) (writing took 1.6491582235321403 seconds)
2022-03-05 19:24:09 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-05 19:24:09 | INFO | train | epoch 156 | loss 1.71 | nll_loss 0.663 | ppl 1.58 | wps 27801.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7594 | lr 0.000362881 | gnorm 0.825 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18125
2022-03-05 19:24:09 | INFO | fairseq.trainer | begin training epoch 157
2022-03-05 19:24:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:24:22 | INFO | train_inner | epoch 157:      6 / 49 loss=1.712, nll_loss=0.666, ppl=1.59, wps=27836, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.832, loss_scale=16, train_wall=198, gb_free=21.6, wall=18139
2022-03-05 19:25:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:26:01 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 14.045 | nll_loss 13.624 | ppl 12627.7 | wps 46361.7 | wpb 510.9 | bsz 1 | num_updates 7643 | best_loss 8.499
2022-03-05 19:26:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7643 updates
2022-03-05 19:26:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:26:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:26:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 157 @ 7643 updates, score 14.045) (writing took 1.6668883124366403 seconds)
2022-03-05 19:26:03 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-05 19:26:03 | INFO | train | epoch 157 | loss 1.704 | nll_loss 0.657 | ppl 1.58 | wps 27804.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7643 | lr 0.000361716 | gnorm 0.828 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18240
2022-03-05 19:26:03 | INFO | fairseq.trainer | begin training epoch 158
2022-03-05 19:26:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:26:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 19:27:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:27:56 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 14.011 | nll_loss 13.588 | ppl 12313.4 | wps 47169.8 | wpb 510.9 | bsz 1 | num_updates 7691 | best_loss 8.499
2022-03-05 19:27:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7691 updates
2022-03-05 19:27:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:27:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:27:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 158 @ 7691 updates, score 14.011) (writing took 1.6609118627384305 seconds)
2022-03-05 19:27:57 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-05 19:27:57 | INFO | train | epoch 158 | loss 1.698 | nll_loss 0.652 | ppl 1.57 | wps 27248.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7691 | lr 0.000360586 | gnorm 0.82 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 18354
2022-03-05 19:27:57 | INFO | fairseq.trainer | begin training epoch 159
2022-03-05 19:27:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:28:17 | INFO | train_inner | epoch 159:      9 / 49 loss=1.699, nll_loss=0.653, ppl=1.57, wps=27581.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.819, loss_scale=8, train_wall=200, gb_free=21.6, wall=18374
2022-03-05 19:29:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:29:50 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 14.013 | nll_loss 13.589 | ppl 12321.9 | wps 47579.2 | wpb 510.9 | bsz 1 | num_updates 7740 | best_loss 8.499
2022-03-05 19:29:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7740 updates
2022-03-05 19:29:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:29:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:29:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 159 @ 7740 updates, score 14.013) (writing took 1.6856955671682954 seconds)
2022-03-05 19:29:51 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-05 19:29:51 | INFO | train | epoch 159 | loss 1.689 | nll_loss 0.643 | ppl 1.56 | wps 27844.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7740 | lr 0.000359443 | gnorm 0.806 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 18468
2022-03-05 19:29:51 | INFO | fairseq.trainer | begin training epoch 160
2022-03-05 19:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:31:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:31:44 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 14.072 | nll_loss 13.661 | ppl 12949.1 | wps 47450.7 | wpb 510.9 | bsz 1 | num_updates 7789 | best_loss 8.499
2022-03-05 19:31:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7789 updates
2022-03-05 19:31:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:31:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:31:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 160 @ 7789 updates, score 14.072) (writing took 1.6631300067529082 seconds)
2022-03-05 19:31:45 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-05 19:31:45 | INFO | train | epoch 160 | loss 1.684 | nll_loss 0.638 | ppl 1.56 | wps 27912.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7789 | lr 0.00035831 | gnorm 0.801 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18582
2022-03-05 19:31:45 | INFO | fairseq.trainer | begin training epoch 161
2022-03-05 19:31:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:32:10 | INFO | train_inner | epoch 161:     11 / 49 loss=1.686, nll_loss=0.64, ppl=1.56, wps=27927.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.804, loss_scale=16, train_wall=197, gb_free=21.6, wall=18606
2022-03-05 19:33:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:33:37 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 13.972 | nll_loss 13.558 | ppl 12056.9 | wps 47727.3 | wpb 510.9 | bsz 1 | num_updates 7838 | best_loss 8.499
2022-03-05 19:33:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7838 updates
2022-03-05 19:33:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:33:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 161 @ 7838 updates, score 13.972) (writing took 1.6964515270665288 seconds)
2022-03-05 19:33:39 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-05 19:33:39 | INFO | train | epoch 161 | loss 1.678 | nll_loss 0.632 | ppl 1.55 | wps 27935.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7838 | lr 0.000357188 | gnorm 0.791 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18696
2022-03-05 19:33:39 | INFO | fairseq.trainer | begin training epoch 162
2022-03-05 19:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:35:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:35:31 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 14.069 | nll_loss 13.657 | ppl 12921.5 | wps 47224.7 | wpb 510.9 | bsz 1 | num_updates 7887 | best_loss 8.499
2022-03-05 19:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7887 updates
2022-03-05 19:35:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:35:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:35:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 162 @ 7887 updates, score 14.069) (writing took 1.5796928368508816 seconds)
2022-03-05 19:35:33 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-05 19:35:33 | INFO | train | epoch 162 | loss 1.672 | nll_loss 0.627 | ppl 1.54 | wps 27925.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7887 | lr 0.000356077 | gnorm 0.805 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18810
2022-03-05 19:35:33 | INFO | fairseq.trainer | begin training epoch 163
2022-03-05 19:35:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:36:02 | INFO | train_inner | epoch 163:     13 / 49 loss=1.673, nll_loss=0.627, ppl=1.54, wps=27956.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.8, loss_scale=16, train_wall=197, gb_free=21.6, wall=18838
2022-03-05 19:36:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:37:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:37:25 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 14.083 | nll_loss 13.672 | ppl 13055.8 | wps 46998 | wpb 510.9 | bsz 1 | num_updates 7935 | best_loss 8.499
2022-03-05 19:37:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7935 updates
2022-03-05 19:37:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:37:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:37:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 163 @ 7935 updates, score 14.083) (writing took 1.6061659986153245 seconds)
2022-03-05 19:37:27 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-05 19:37:27 | INFO | train | epoch 163 | loss 1.668 | nll_loss 0.622 | ppl 1.54 | wps 27274.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7935 | lr 0.000354999 | gnorm 0.808 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18924
2022-03-05 19:37:27 | INFO | fairseq.trainer | begin training epoch 164
2022-03-05 19:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:38:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 19:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:39:19 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 13.996 | nll_loss 13.58 | ppl 12249.6 | wps 47281.6 | wpb 510.9 | bsz 1 | num_updates 7983 | best_loss 8.499
2022-03-05 19:39:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7983 updates
2022-03-05 19:39:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:39:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:39:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 164 @ 7983 updates, score 13.996) (writing took 1.603585010394454 seconds)
2022-03-05 19:39:21 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-05 19:39:21 | INFO | train | epoch 164 | loss 1.66 | nll_loss 0.614 | ppl 1.53 | wps 27266.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7983 | lr 0.00035393 | gnorm 0.773 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 19038
2022-03-05 19:39:21 | INFO | fairseq.trainer | begin training epoch 165
2022-03-05 19:39:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:39:59 | INFO | train_inner | epoch 165:     17 / 49 loss=1.66, nll_loss=0.615, ppl=1.53, wps=27356.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.78, loss_scale=8, train_wall=202, gb_free=21.6, wall=19076
2022-03-05 19:41:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:41:13 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 14.008 | nll_loss 13.596 | ppl 12381.2 | wps 47214.1 | wpb 510.9 | bsz 1 | num_updates 8032 | best_loss 8.499
2022-03-05 19:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8032 updates
2022-03-05 19:41:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 165 @ 8032 updates, score 14.008) (writing took 1.6205821270123124 seconds)
2022-03-05 19:41:15 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-05 19:41:15 | INFO | train | epoch 165 | loss 1.655 | nll_loss 0.61 | ppl 1.53 | wps 27930.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8032 | lr 0.000352848 | gnorm 0.769 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 19152
2022-03-05 19:41:15 | INFO | fairseq.trainer | begin training epoch 166
2022-03-05 19:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:43:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:43:07 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 13.963 | nll_loss 13.547 | ppl 11967 | wps 47780.9 | wpb 510.9 | bsz 1 | num_updates 8081 | best_loss 8.499
2022-03-05 19:43:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8081 updates
2022-03-05 19:43:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:43:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:43:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 166 @ 8081 updates, score 13.963) (writing took 1.6717926487326622 seconds)
2022-03-05 19:43:09 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-05 19:43:09 | INFO | train | epoch 166 | loss 1.65 | nll_loss 0.605 | ppl 1.52 | wps 27901.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8081 | lr 0.000351777 | gnorm 0.784 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 19266
2022-03-05 19:43:09 | INFO | fairseq.trainer | begin training epoch 167
2022-03-05 19:43:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:43:51 | INFO | train_inner | epoch 167:     19 / 49 loss=1.651, nll_loss=0.606, ppl=1.52, wps=27949.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.78, loss_scale=16, train_wall=197, gb_free=21.6, wall=19308
2022-03-05 19:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:45:01 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 14.156 | nll_loss 13.755 | ppl 13821.3 | wps 47809.6 | wpb 510.9 | bsz 1 | num_updates 8130 | best_loss 8.499
2022-03-05 19:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8130 updates
2022-03-05 19:45:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:45:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:45:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 167 @ 8130 updates, score 14.156) (writing took 1.6192025560885668 seconds)
2022-03-05 19:45:03 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-05 19:45:03 | INFO | train | epoch 167 | loss 1.643 | nll_loss 0.598 | ppl 1.51 | wps 27927.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8130 | lr 0.000350715 | gnorm 0.773 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19379
2022-03-05 19:45:03 | INFO | fairseq.trainer | begin training epoch 168
2022-03-05 19:45:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:46:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:46:55 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 14.005 | nll_loss 13.588 | ppl 12316 | wps 45913.2 | wpb 510.9 | bsz 1 | num_updates 8179 | best_loss 8.499
2022-03-05 19:46:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8179 updates
2022-03-05 19:46:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:46:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 168 @ 8179 updates, score 14.005) (writing took 1.6292845970019698 seconds)
2022-03-05 19:46:57 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-05 19:46:57 | INFO | train | epoch 168 | loss 1.639 | nll_loss 0.595 | ppl 1.51 | wps 27837.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8179 | lr 0.000349663 | gnorm 0.776 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19494
2022-03-05 19:46:57 | INFO | fairseq.trainer | begin training epoch 169
2022-03-05 19:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:47:44 | INFO | train_inner | epoch 169:     21 / 49 loss=1.639, nll_loss=0.595, ppl=1.51, wps=27848.5, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.774, loss_scale=16, train_wall=198, gb_free=21.6, wall=19541
2022-03-05 19:48:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:48:50 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 14.03 | nll_loss 13.62 | ppl 12587.5 | wps 46005 | wpb 510.9 | bsz 1 | num_updates 8228 | best_loss 8.499
2022-03-05 19:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8228 updates
2022-03-05 19:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:48:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:48:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 169 @ 8228 updates, score 14.03) (writing took 1.66656544059515 seconds)
2022-03-05 19:48:52 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-05 19:48:52 | INFO | train | epoch 169 | loss 1.633 | nll_loss 0.589 | ppl 1.5 | wps 27555.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8228 | lr 0.00034862 | gnorm 0.77 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 19609
2022-03-05 19:48:52 | INFO | fairseq.trainer | begin training epoch 170
2022-03-05 19:48:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:48:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:50:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:50:46 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 14.208 | nll_loss 13.806 | ppl 14321.4 | wps 45586 | wpb 510.9 | bsz 1 | num_updates 8276 | best_loss 8.499
2022-03-05 19:50:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8276 updates
2022-03-05 19:50:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:50:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:50:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 170 @ 8276 updates, score 14.208) (writing took 1.684300354681909 seconds)
2022-03-05 19:50:47 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-05 19:50:47 | INFO | train | epoch 170 | loss 1.627 | nll_loss 0.583 | ppl 1.5 | wps 26986.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8276 | lr 0.000347608 | gnorm 0.764 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 19724
2022-03-05 19:50:47 | INFO | fairseq.trainer | begin training epoch 171
2022-03-05 19:50:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:51:41 | INFO | train_inner | epoch 171:     24 / 49 loss=1.628, nll_loss=0.584, ppl=1.5, wps=27338.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.765, loss_scale=16, train_wall=201, gb_free=21.6, wall=19778
2022-03-05 19:52:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:52:41 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 14.093 | nll_loss 13.691 | ppl 13223.7 | wps 45768.1 | wpb 510.9 | bsz 1 | num_updates 8325 | best_loss 8.499
2022-03-05 19:52:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8325 updates
2022-03-05 19:52:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:52:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:52:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 171 @ 8325 updates, score 14.093) (writing took 1.6573755582794547 seconds)
2022-03-05 19:52:43 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-05 19:52:43 | INFO | train | epoch 171 | loss 1.622 | nll_loss 0.578 | ppl 1.49 | wps 27599.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8325 | lr 0.000346583 | gnorm 0.759 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19839
2022-03-05 19:52:43 | INFO | fairseq.trainer | begin training epoch 172
2022-03-05 19:52:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:54:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:54:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:54:36 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 13.977 | nll_loss 13.559 | ppl 12072.1 | wps 45581.5 | wpb 510.9 | bsz 1 | num_updates 8373 | best_loss 8.499
2022-03-05 19:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8373 updates
2022-03-05 19:54:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:54:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 172 @ 8373 updates, score 13.977) (writing took 1.691748752258718 seconds)
2022-03-05 19:54:38 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-05 19:54:38 | INFO | train | epoch 172 | loss 1.617 | nll_loss 0.574 | ppl 1.49 | wps 26982.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8373 | lr 0.000345589 | gnorm 0.751 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 19955
2022-03-05 19:54:38 | INFO | fairseq.trainer | begin training epoch 173
2022-03-05 19:54:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:55:38 | INFO | train_inner | epoch 173:     27 / 49 loss=1.617, nll_loss=0.573, ppl=1.49, wps=27388.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.752, loss_scale=16, train_wall=201, gb_free=21.6, wall=20015
2022-03-05 19:56:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:56:31 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 14.082 | nll_loss 13.681 | ppl 13132.3 | wps 47189.6 | wpb 510.9 | bsz 1 | num_updates 8422 | best_loss 8.499
2022-03-05 19:56:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8422 updates
2022-03-05 19:56:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:56:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:56:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 173 @ 8422 updates, score 14.082) (writing took 1.6796072479337454 seconds)
2022-03-05 19:56:32 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-05 19:56:32 | INFO | train | epoch 173 | loss 1.613 | nll_loss 0.569 | ppl 1.48 | wps 27777.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8422 | lr 0.000344582 | gnorm 0.75 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20069
2022-03-05 19:56:32 | INFO | fairseq.trainer | begin training epoch 174
2022-03-05 19:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:58:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:58:26 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 14.007 | nll_loss 13.6 | ppl 12420.9 | wps 45810.4 | wpb 510.9 | bsz 1 | num_updates 8471 | best_loss 8.499
2022-03-05 19:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8471 updates
2022-03-05 19:58:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:58:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 19:58:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 174 @ 8471 updates, score 14.007) (writing took 1.6987330000847578 seconds)
2022-03-05 19:58:28 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-05 19:58:28 | INFO | train | epoch 174 | loss 1.609 | nll_loss 0.566 | ppl 1.48 | wps 27556.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8471 | lr 0.000343584 | gnorm 0.741 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 20184
2022-03-05 19:58:28 | INFO | fairseq.trainer | begin training epoch 175
2022-03-05 19:58:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:59:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:59:35 | INFO | train_inner | epoch 175:     30 / 49 loss=1.609, nll_loss=0.566, ppl=1.48, wps=27382.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.751, loss_scale=16, train_wall=201, gb_free=21.6, wall=20252
2022-03-05 20:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:00:21 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 13.993 | nll_loss 13.586 | ppl 12292.8 | wps 45925.3 | wpb 510.9 | bsz 1 | num_updates 8519 | best_loss 8.499
2022-03-05 20:00:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8519 updates
2022-03-05 20:00:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:00:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:00:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 175 @ 8519 updates, score 13.993) (writing took 1.6312442673370242 seconds)
2022-03-05 20:00:23 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-05 20:00:23 | INFO | train | epoch 175 | loss 1.605 | nll_loss 0.562 | ppl 1.48 | wps 26999.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8519 | lr 0.000342614 | gnorm 0.761 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 20300
2022-03-05 20:00:23 | INFO | fairseq.trainer | begin training epoch 176
2022-03-05 20:00:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:02:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:02:16 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 13.991 | nll_loss 13.582 | ppl 12265 | wps 45915.9 | wpb 510.9 | bsz 1 | num_updates 8568 | best_loss 8.499
2022-03-05 20:02:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8568 updates
2022-03-05 20:02:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:02:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:02:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 176 @ 8568 updates, score 13.991) (writing took 1.7167978193610907 seconds)
2022-03-05 20:02:18 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-05 20:02:18 | INFO | train | epoch 176 | loss 1.599 | nll_loss 0.557 | ppl 1.47 | wps 27570.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8568 | lr 0.000341633 | gnorm 0.738 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 20415
2022-03-05 20:02:18 | INFO | fairseq.trainer | begin training epoch 177
2022-03-05 20:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:03:30 | INFO | train_inner | epoch 177:     32 / 49 loss=1.598, nll_loss=0.556, ppl=1.47, wps=27614.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.735, loss_scale=16, train_wall=199, gb_free=21.6, wall=20487
2022-03-05 20:04:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:04:12 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 14.11 | nll_loss 13.713 | ppl 13426.7 | wps 46095.5 | wpb 510.9 | bsz 1 | num_updates 8617 | best_loss 8.499
2022-03-05 20:04:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8617 updates
2022-03-05 20:04:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:04:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:04:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 177 @ 8617 updates, score 14.11) (writing took 1.6715365732088685 seconds)
2022-03-05 20:04:13 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-05 20:04:13 | INFO | train | epoch 177 | loss 1.595 | nll_loss 0.552 | ppl 1.47 | wps 27609.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8617 | lr 0.000340661 | gnorm 0.735 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20530
2022-03-05 20:04:13 | INFO | fairseq.trainer | begin training epoch 178
2022-03-05 20:04:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:05:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:06:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:06:06 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 14.015 | nll_loss 13.615 | ppl 12544.8 | wps 46722.7 | wpb 510.9 | bsz 1 | num_updates 8665 | best_loss 8.499
2022-03-05 20:06:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8665 updates
2022-03-05 20:06:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:06:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 178 @ 8665 updates, score 14.015) (writing took 1.7082145940512419 seconds)
2022-03-05 20:06:08 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-05 20:06:08 | INFO | train | epoch 178 | loss 1.589 | nll_loss 0.547 | ppl 1.46 | wps 27138.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8665 | lr 0.000339716 | gnorm 0.737 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20645
2022-03-05 20:06:08 | INFO | fairseq.trainer | begin training epoch 179
2022-03-05 20:06:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:07:26 | INFO | train_inner | epoch 179:     35 / 49 loss=1.59, nll_loss=0.548, ppl=1.46, wps=27478.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.735, loss_scale=16, train_wall=200, gb_free=21.6, wall=20723
2022-03-05 20:07:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:08:01 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 14.03 | nll_loss 13.626 | ppl 12641.8 | wps 46065.6 | wpb 510.9 | bsz 1 | num_updates 8714 | best_loss 8.499
2022-03-05 20:08:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8714 updates
2022-03-05 20:08:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:08:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:08:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 179 @ 8714 updates, score 14.03) (writing took 1.6721023693680763 seconds)
2022-03-05 20:08:03 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-05 20:08:03 | INFO | train | epoch 179 | loss 1.585 | nll_loss 0.544 | ppl 1.46 | wps 27714.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8714 | lr 0.000338759 | gnorm 0.723 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20759
2022-03-05 20:08:03 | INFO | fairseq.trainer | begin training epoch 180
2022-03-05 20:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:09:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:09:56 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 14.081 | nll_loss 13.681 | ppl 13130 | wps 45919.7 | wpb 510.9 | bsz 1 | num_updates 8763 | best_loss 8.499
2022-03-05 20:09:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8763 updates
2022-03-05 20:09:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:09:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:09:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 180 @ 8763 updates, score 14.081) (writing took 1.691751316189766 seconds)
2022-03-05 20:09:58 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-05 20:09:58 | INFO | train | epoch 180 | loss 1.58 | nll_loss 0.539 | ppl 1.45 | wps 27592.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8763 | lr 0.000337811 | gnorm 0.727 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20875
2022-03-05 20:09:58 | INFO | fairseq.trainer | begin training epoch 181
2022-03-05 20:09:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:11:21 | INFO | train_inner | epoch 181:     37 / 49 loss=1.579, nll_loss=0.538, ppl=1.45, wps=27606.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.72, loss_scale=32, train_wall=199, gb_free=21.6, wall=20958
2022-03-05 20:11:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:11:52 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 13.978 | nll_loss 13.571 | ppl 12172.6 | wps 46244.6 | wpb 510.9 | bsz 1 | num_updates 8812 | best_loss 8.499
2022-03-05 20:11:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8812 updates
2022-03-05 20:11:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:11:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:11:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 181 @ 8812 updates, score 13.978) (writing took 1.705722321756184 seconds)
2022-03-05 20:11:53 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-05 20:11:53 | INFO | train | epoch 181 | loss 1.576 | nll_loss 0.535 | ppl 1.45 | wps 27534.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8812 | lr 0.00033687 | gnorm 0.717 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 20990
2022-03-05 20:11:53 | INFO | fairseq.trainer | begin training epoch 182
2022-03-05 20:11:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:12:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:13:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:13:47 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 14.086 | nll_loss 13.695 | ppl 13265.6 | wps 45637.3 | wpb 510.9 | bsz 1 | num_updates 8860 | best_loss 8.499
2022-03-05 20:13:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8860 updates
2022-03-05 20:13:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:13:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:13:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 182 @ 8860 updates, score 14.086) (writing took 1.8751220125705004 seconds)
2022-03-05 20:13:49 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-05 20:13:49 | INFO | train | epoch 182 | loss 1.574 | nll_loss 0.533 | ppl 1.45 | wps 26959.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8860 | lr 0.000335957 | gnorm 0.732 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 21105
2022-03-05 20:13:49 | INFO | fairseq.trainer | begin training epoch 183
2022-03-05 20:13:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:15:18 | INFO | train_inner | epoch 183:     40 / 49 loss=1.572, nll_loss=0.532, ppl=1.45, wps=27341.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.73, loss_scale=16, train_wall=201, gb_free=21.6, wall=21195
2022-03-05 20:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:15:42 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 14.106 | nll_loss 13.713 | ppl 13426.6 | wps 45309.3 | wpb 510.9 | bsz 1 | num_updates 8909 | best_loss 8.499
2022-03-05 20:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8909 updates
2022-03-05 20:15:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:15:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 183 @ 8909 updates, score 14.106) (writing took 1.8812559638172388 seconds)
2022-03-05 20:15:44 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-05 20:15:44 | INFO | train | epoch 183 | loss 1.568 | nll_loss 0.528 | ppl 1.44 | wps 27562.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8909 | lr 0.000335031 | gnorm 0.719 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21221
2022-03-05 20:15:44 | INFO | fairseq.trainer | begin training epoch 184
2022-03-05 20:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:17:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:17:37 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 14.028 | nll_loss 13.633 | ppl 12705.7 | wps 46037.1 | wpb 510.9 | bsz 1 | num_updates 8958 | best_loss 8.499
2022-03-05 20:17:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8958 updates
2022-03-05 20:17:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 184 @ 8958 updates, score 14.028) (writing took 1.9152766186743975 seconds)
2022-03-05 20:17:39 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-05 20:17:39 | INFO | train | epoch 184 | loss 1.562 | nll_loss 0.522 | ppl 1.44 | wps 27560.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 8958 | lr 0.000334114 | gnorm 0.692 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 21336
2022-03-05 20:17:39 | INFO | fairseq.trainer | begin training epoch 185
2022-03-05 20:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:17:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:19:16 | INFO | train_inner | epoch 185:     43 / 49 loss=1.562, nll_loss=0.523, ppl=1.44, wps=27320.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.698, loss_scale=16, train_wall=201, gb_free=21.6, wall=21432
2022-03-05 20:19:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:19:33 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 13.98 | nll_loss 13.58 | ppl 12243 | wps 45439.4 | wpb 510.9 | bsz 1 | num_updates 9006 | best_loss 8.499
2022-03-05 20:19:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9006 updates
2022-03-05 20:19:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:19:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:19:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 185 @ 9006 updates, score 13.98) (writing took 1.8652316257357597 seconds)
2022-03-05 20:19:35 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-05 20:19:35 | INFO | train | epoch 185 | loss 1.56 | nll_loss 0.521 | ppl 1.43 | wps 26965.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9006 | lr 0.000333222 | gnorm 0.709 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 21452
2022-03-05 20:19:35 | INFO | fairseq.trainer | begin training epoch 186
2022-03-05 20:19:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:21:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:21:28 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 14.121 | nll_loss 13.735 | ppl 13632.8 | wps 45763.8 | wpb 510.9 | bsz 1 | num_updates 9055 | best_loss 8.499
2022-03-05 20:21:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9055 updates
2022-03-05 20:21:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:21:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:21:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 186 @ 9055 updates, score 14.121) (writing took 1.930871325545013 seconds)
2022-03-05 20:21:30 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-05 20:21:30 | INFO | train | epoch 186 | loss 1.556 | nll_loss 0.516 | ppl 1.43 | wps 27543.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9055 | lr 0.000332319 | gnorm 0.699 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21567
2022-03-05 20:21:30 | INFO | fairseq.trainer | begin training epoch 187
2022-03-05 20:21:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:23:11 | INFO | train_inner | epoch 187:     45 / 49 loss=1.556, nll_loss=0.517, ppl=1.43, wps=27560.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9100, lr=0.000331497, gnorm=0.706, loss_scale=32, train_wall=199, gb_free=21.6, wall=21668
2022-03-05 20:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:23:24 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 14.012 | nll_loss 13.615 | ppl 12545.8 | wps 45970.8 | wpb 510.9 | bsz 1 | num_updates 9104 | best_loss 8.499
2022-03-05 20:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9104 updates
2022-03-05 20:23:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:23:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 187 @ 9104 updates, score 14.012) (writing took 1.9131040591746569 seconds)
2022-03-05 20:23:26 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-05 20:23:26 | INFO | train | epoch 187 | loss 1.554 | nll_loss 0.515 | ppl 1.43 | wps 27511.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9104 | lr 0.000331424 | gnorm 0.709 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 21682
2022-03-05 20:23:26 | INFO | fairseq.trainer | begin training epoch 188
2022-03-05 20:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:25:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:25:19 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 14.03 | nll_loss 13.638 | ppl 12744.7 | wps 45914.7 | wpb 510.9 | bsz 1 | num_updates 9152 | best_loss 8.499
2022-03-05 20:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9152 updates
2022-03-05 20:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:25:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:25:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 188 @ 9152 updates, score 14.03) (writing took 1.9382842918857932 seconds)
2022-03-05 20:25:21 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-05 20:25:21 | INFO | train | epoch 188 | loss 1.549 | nll_loss 0.51 | ppl 1.42 | wps 26906.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 9152 | lr 0.000330554 | gnorm 0.699 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 21798
2022-03-05 20:25:21 | INFO | fairseq.trainer | begin training epoch 189
2022-03-05 20:25:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:27:09 | INFO | train_inner | epoch 189:     48 / 49 loss=1.548, nll_loss=0.51, ppl=1.42, wps=27267.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9200, lr=0.00032969, gnorm=0.697, loss_scale=16, train_wall=201, gb_free=21.6, wall=21906
2022-03-05 20:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:27:15 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 14.022 | nll_loss 13.629 | ppl 12672.6 | wps 45591.8 | wpb 510.9 | bsz 1 | num_updates 9201 | best_loss 8.499
2022-03-05 20:27:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9201 updates
2022-03-05 20:27:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:27:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:27:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 189 @ 9201 updates, score 14.022) (writing took 1.8982221633195877 seconds)
2022-03-05 20:27:17 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-05 20:27:17 | INFO | train | epoch 189 | loss 1.546 | nll_loss 0.508 | ppl 1.42 | wps 27501.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9201 | lr 0.000329672 | gnorm 0.696 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 21914
2022-03-05 20:27:17 | INFO | fairseq.trainer | begin training epoch 190
2022-03-05 20:27:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:29:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:29:10 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 14.019 | nll_loss 13.626 | ppl 12638.9 | wps 46363.8 | wpb 510.9 | bsz 1 | num_updates 9250 | best_loss 8.499
2022-03-05 20:29:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9250 updates
2022-03-05 20:29:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:29:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:29:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 190 @ 9250 updates, score 14.019) (writing took 1.896511873230338 seconds)
2022-03-05 20:29:12 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-05 20:29:12 | INFO | train | epoch 190 | loss 1.541 | nll_loss 0.503 | ppl 1.42 | wps 27555.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9250 | lr 0.000328798 | gnorm 0.689 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22029
2022-03-05 20:29:12 | INFO | fairseq.trainer | begin training epoch 191
2022-03-05 20:29:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:30:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:31:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:31:06 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 14.014 | nll_loss 13.619 | ppl 12580.6 | wps 46364.7 | wpb 510.9 | bsz 1 | num_updates 9298 | best_loss 8.499
2022-03-05 20:31:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9298 updates
2022-03-05 20:31:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:31:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:31:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 191 @ 9298 updates, score 14.014) (writing took 1.8895111652091146 seconds)
2022-03-05 20:31:08 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-05 20:31:08 | INFO | train | epoch 191 | loss 1.536 | nll_loss 0.498 | ppl 1.41 | wps 26958.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9298 | lr 0.000327948 | gnorm 0.683 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 22144
2022-03-05 20:31:08 | INFO | fairseq.trainer | begin training epoch 192
2022-03-05 20:31:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:31:12 | INFO | train_inner | epoch 192:      2 / 49 loss=1.538, nll_loss=0.5, ppl=1.41, wps=26533.7, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=9300, lr=0.000327913, gnorm=0.688, loss_scale=16, train_wall=200, gb_free=21.6, wall=22149
2022-03-05 20:32:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:33:01 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 14.028 | nll_loss 13.642 | ppl 12779.3 | wps 45853.5 | wpb 510.9 | bsz 1 | num_updates 9347 | best_loss 8.499
2022-03-05 20:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9347 updates
2022-03-05 20:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:33:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:33:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 192 @ 9347 updates, score 14.028) (writing took 1.8526047840714455 seconds)
2022-03-05 20:33:03 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-05 20:33:03 | INFO | train | epoch 192 | loss 1.533 | nll_loss 0.496 | ppl 1.41 | wps 27541.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9347 | lr 0.000327087 | gnorm 0.688 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22260
2022-03-05 20:33:03 | INFO | fairseq.trainer | begin training epoch 193
2022-03-05 20:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:34:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:34:57 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 14.028 | nll_loss 13.641 | ppl 12772.7 | wps 45714.5 | wpb 510.9 | bsz 1 | num_updates 9396 | best_loss 8.499
2022-03-05 20:34:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9396 updates
2022-03-05 20:34:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:34:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:34:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 193 @ 9396 updates, score 14.028) (writing took 1.8562263250350952 seconds)
2022-03-05 20:34:59 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-05 20:34:59 | INFO | train | epoch 193 | loss 1.532 | nll_loss 0.495 | ppl 1.41 | wps 27498.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9396 | lr 0.000326233 | gnorm 0.698 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 22375
2022-03-05 20:34:59 | INFO | fairseq.trainer | begin training epoch 194
2022-03-05 20:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:35:08 | INFO | train_inner | epoch 194:      4 / 49 loss=1.532, nll_loss=0.495, ppl=1.41, wps=27554.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.692, loss_scale=16, train_wall=199, gb_free=21.6, wall=22384
2022-03-05 20:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:36:51 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 13.995 | nll_loss 13.602 | ppl 12438 | wps 47192.4 | wpb 510.9 | bsz 1 | num_updates 9445 | best_loss 8.499
2022-03-05 20:36:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9445 updates
2022-03-05 20:36:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:36:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:36:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 194 @ 9445 updates, score 13.995) (writing took 1.8486999617889524 seconds)
2022-03-05 20:36:53 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-05 20:36:53 | INFO | train | epoch 194 | loss 1.526 | nll_loss 0.49 | ppl 1.4 | wps 27717 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9445 | lr 0.000325386 | gnorm 0.684 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 22490
2022-03-05 20:36:53 | INFO | fairseq.trainer | begin training epoch 195
2022-03-05 20:36:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:37:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:38:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:38:46 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 14.031 | nll_loss 13.645 | ppl 12807.8 | wps 47620.9 | wpb 510.9 | bsz 1 | num_updates 9493 | best_loss 8.499
2022-03-05 20:38:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9493 updates
2022-03-05 20:38:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:38:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:38:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 195 @ 9493 updates, score 14.031) (writing took 1.9718602811917663 seconds)
2022-03-05 20:38:48 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-05 20:38:48 | INFO | train | epoch 195 | loss 1.522 | nll_loss 0.486 | ppl 1.4 | wps 27240.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9493 | lr 0.000324562 | gnorm 0.673 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22604
2022-03-05 20:38:48 | INFO | fairseq.trainer | begin training epoch 196
2022-03-05 20:38:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:39:03 | INFO | train_inner | epoch 196:      7 / 49 loss=1.523, nll_loss=0.487, ppl=1.4, wps=27544.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.678, loss_scale=16, train_wall=200, gb_free=21.6, wall=22620
2022-03-05 20:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:40:40 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 13.983 | nll_loss 13.59 | ppl 12331.3 | wps 47671.2 | wpb 510.9 | bsz 1 | num_updates 9542 | best_loss 8.499
2022-03-05 20:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9542 updates
2022-03-05 20:40:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:40:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 196 @ 9542 updates, score 13.983) (writing took 1.8702038088813424 seconds)
2022-03-05 20:40:42 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-05 20:40:42 | INFO | train | epoch 196 | loss 1.521 | nll_loss 0.485 | ppl 1.4 | wps 27860.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9542 | lr 0.000323728 | gnorm 0.694 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22718
2022-03-05 20:40:42 | INFO | fairseq.trainer | begin training epoch 197
2022-03-05 20:40:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:42:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:42:34 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 13.994 | nll_loss 13.607 | ppl 12477.3 | wps 47440.3 | wpb 510.9 | bsz 1 | num_updates 9590 | best_loss 8.499
2022-03-05 20:42:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9590 updates
2022-03-05 20:42:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:42:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:42:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 197 @ 9590 updates, score 13.994) (writing took 1.856736927293241 seconds)
2022-03-05 20:42:36 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-05 20:42:36 | INFO | train | epoch 197 | loss 1.516 | nll_loss 0.48 | ppl 1.39 | wps 27279.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9590 | lr 0.000322917 | gnorm 0.674 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22833
2022-03-05 20:42:36 | INFO | fairseq.trainer | begin training epoch 198
2022-03-05 20:42:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:42:58 | INFO | train_inner | epoch 198:     10 / 49 loss=1.518, nll_loss=0.482, ppl=1.4, wps=27632.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.682, loss_scale=16, train_wall=199, gb_free=21.6, wall=22855
2022-03-05 20:44:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:44:28 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 13.946 | nll_loss 13.558 | ppl 12062.9 | wps 48103.6 | wpb 510.9 | bsz 1 | num_updates 9639 | best_loss 8.499
2022-03-05 20:44:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9639 updates
2022-03-05 20:44:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:44:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 198 @ 9639 updates, score 13.946) (writing took 1.8513063648715615 seconds)
2022-03-05 20:44:30 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-05 20:44:30 | INFO | train | epoch 198 | loss 1.514 | nll_loss 0.479 | ppl 1.39 | wps 27891 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9639 | lr 0.000322095 | gnorm 0.676 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22946
2022-03-05 20:44:30 | INFO | fairseq.trainer | begin training epoch 199
2022-03-05 20:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:46:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:46:22 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 14.037 | nll_loss 13.653 | ppl 12883.7 | wps 47297.7 | wpb 510.9 | bsz 1 | num_updates 9688 | best_loss 8.499
2022-03-05 20:46:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9688 updates
2022-03-05 20:46:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:46:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:46:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 199 @ 9688 updates, score 14.037) (writing took 1.8766268296167254 seconds)
2022-03-05 20:46:24 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-05 20:46:24 | INFO | train | epoch 199 | loss 1.508 | nll_loss 0.473 | ppl 1.39 | wps 27855.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9688 | lr 0.000321279 | gnorm 0.662 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23061
2022-03-05 20:46:24 | INFO | fairseq.trainer | begin training epoch 200
2022-03-05 20:46:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:46:50 | INFO | train_inner | epoch 200:     12 / 49 loss=1.51, nll_loss=0.475, ppl=1.39, wps=27910.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.669, loss_scale=16, train_wall=197, gb_free=21.6, wall=23087
2022-03-05 20:48:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:48:16 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 13.99 | nll_loss 13.606 | ppl 12468.6 | wps 46843 | wpb 510.9 | bsz 1 | num_updates 9737 | best_loss 8.499
2022-03-05 20:48:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9737 updates
2022-03-05 20:48:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:48:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 200 @ 9737 updates, score 13.99) (writing took 1.8590204566717148 seconds)
2022-03-05 20:48:18 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-05 20:48:18 | INFO | train | epoch 200 | loss 1.508 | nll_loss 0.473 | ppl 1.39 | wps 27834.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9737 | lr 0.00032047 | gnorm 0.667 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23175
2022-03-05 20:48:18 | INFO | fairseq.trainer | begin training epoch 201
2022-03-05 20:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:49:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:50:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:50:10 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 14.012 | nll_loss 13.626 | ppl 12641.9 | wps 46348.5 | wpb 510.9 | bsz 1 | num_updates 9785 | best_loss 8.499
2022-03-05 20:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9785 updates
2022-03-05 20:50:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:50:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 201 @ 9785 updates, score 14.012) (writing took 1.8483365755528212 seconds)
2022-03-05 20:50:12 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-05 20:50:12 | INFO | train | epoch 201 | loss 1.503 | nll_loss 0.469 | ppl 1.38 | wps 27245.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9785 | lr 0.000319683 | gnorm 0.651 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23289
2022-03-05 20:50:12 | INFO | fairseq.trainer | begin training epoch 202
2022-03-05 20:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:50:46 | INFO | train_inner | epoch 202:     15 / 49 loss=1.505, nll_loss=0.47, ppl=1.39, wps=27551, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.66, loss_scale=16, train_wall=200, gb_free=21.6, wall=23323
2022-03-05 20:52:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:52:06 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 14.071 | nll_loss 13.689 | ppl 13208.6 | wps 46263.6 | wpb 510.9 | bsz 1 | num_updates 9834 | best_loss 8.499
2022-03-05 20:52:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9834 updates
2022-03-05 20:52:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:52:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:52:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 202 @ 9834 updates, score 14.071) (writing took 1.8053816528990865 seconds)
2022-03-05 20:52:08 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-05 20:52:08 | INFO | train | epoch 202 | loss 1.502 | nll_loss 0.468 | ppl 1.38 | wps 27527.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9834 | lr 0.000318886 | gnorm 0.659 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 23404
2022-03-05 20:52:08 | INFO | fairseq.trainer | begin training epoch 203
2022-03-05 20:52:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:53:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:54:01 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 14.047 | nll_loss 13.672 | ppl 13048.6 | wps 46076.4 | wpb 510.9 | bsz 1 | num_updates 9883 | best_loss 8.499
2022-03-05 20:54:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9883 updates
2022-03-05 20:54:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:54:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:54:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 203 @ 9883 updates, score 14.047) (writing took 1.8089141519740224 seconds)
2022-03-05 20:54:03 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-05 20:54:03 | INFO | train | epoch 203 | loss 1.497 | nll_loss 0.464 | ppl 1.38 | wps 27543.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9883 | lr 0.000318094 | gnorm 0.641 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23520
2022-03-05 20:54:03 | INFO | fairseq.trainer | begin training epoch 204
2022-03-05 20:54:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:54:41 | INFO | train_inner | epoch 204:     17 / 49 loss=1.499, nll_loss=0.465, ppl=1.38, wps=27561.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.647, loss_scale=32, train_wall=199, gb_free=21.6, wall=23558
2022-03-05 20:55:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:55:57 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 13.951 | nll_loss 13.561 | ppl 12089.5 | wps 45793.1 | wpb 510.9 | bsz 1 | num_updates 9931 | best_loss 8.499
2022-03-05 20:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9931 updates
2022-03-05 20:55:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:55:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:55:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 204 @ 9931 updates, score 13.951) (writing took 1.8041720753535628 seconds)
2022-03-05 20:55:58 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-05 20:55:58 | INFO | train | epoch 204 | loss 1.496 | nll_loss 0.463 | ppl 1.38 | wps 26968.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9931 | lr 0.000317324 | gnorm 0.652 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 23635
2022-03-05 20:55:58 | INFO | fairseq.trainer | begin training epoch 205
2022-03-05 20:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:57:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:57:52 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 13.934 | nll_loss 13.544 | ppl 11940.5 | wps 46020.8 | wpb 510.9 | bsz 1 | num_updates 9980 | best_loss 8.499
2022-03-05 20:57:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9980 updates
2022-03-05 20:57:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:57:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:57:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 205 @ 9980 updates, score 13.934) (writing took 1.8379329182207584 seconds)
2022-03-05 20:57:54 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-05 20:57:54 | INFO | train | epoch 205 | loss 1.493 | nll_loss 0.46 | ppl 1.38 | wps 27537.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 9980 | lr 0.000316544 | gnorm 0.659 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 23751
2022-03-05 20:57:54 | INFO | fairseq.trainer | begin training epoch 206
2022-03-05 20:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:58:39 | INFO | train_inner | epoch 206:     20 / 49 loss=1.493, nll_loss=0.46, ppl=1.38, wps=27318.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.654, loss_scale=16, train_wall=201, gb_free=21.6, wall=23795
2022-03-05 20:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:59:47 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 13.975 | nll_loss 13.587 | ppl 12309.5 | wps 46031.9 | wpb 510.9 | bsz 1 | num_updates 10029 | best_loss 8.499
2022-03-05 20:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10029 updates
2022-03-05 20:59:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:59:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 20:59:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 206 @ 10029 updates, score 13.975) (writing took 1.8193862941116095 seconds)
2022-03-05 20:59:49 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-05 20:59:49 | INFO | train | epoch 206 | loss 1.49 | nll_loss 0.457 | ppl 1.37 | wps 27541.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 10029 | lr 0.00031577 | gnorm 0.651 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 23866
2022-03-05 20:59:49 | INFO | fairseq.trainer | begin training epoch 207
2022-03-05 20:59:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:01:42 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 13.922 | nll_loss 13.535 | ppl 11869.5 | wps 47090.3 | wpb 510.9 | bsz 1 | num_updates 10078 | best_loss 8.499
2022-03-05 21:01:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10078 updates
2022-03-05 21:01:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:01:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:01:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 207 @ 10078 updates, score 13.922) (writing took 1.8407276785001159 seconds)
2022-03-05 21:01:43 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-05 21:01:43 | INFO | train | epoch 207 | loss 1.487 | nll_loss 0.455 | ppl 1.37 | wps 27816.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10078 | lr 0.000315002 | gnorm 0.645 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23980
2022-03-05 21:01:43 | INFO | fairseq.trainer | begin training epoch 208
2022-03-05 21:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:02:32 | INFO | train_inner | epoch 208:     22 / 49 loss=1.487, nll_loss=0.455, ppl=1.37, wps=27758.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.652, loss_scale=32, train_wall=198, gb_free=21.6, wall=24029
2022-03-05 21:02:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:03:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:03:36 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 13.952 | nll_loss 13.574 | ppl 12195.8 | wps 47375.9 | wpb 510.9 | bsz 1 | num_updates 10126 | best_loss 8.499
2022-03-05 21:03:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10126 updates
2022-03-05 21:03:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:03:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:03:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 208 @ 10126 updates, score 13.952) (writing took 1.822181824594736 seconds)
2022-03-05 21:03:37 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-05 21:03:37 | INFO | train | epoch 208 | loss 1.484 | nll_loss 0.452 | ppl 1.37 | wps 27320.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10126 | lr 0.000314254 | gnorm 0.652 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24094
2022-03-05 21:03:37 | INFO | fairseq.trainer | begin training epoch 209
2022-03-05 21:03:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:05:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:05:30 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 13.909 | nll_loss 13.523 | ppl 11775.1 | wps 47745 | wpb 510.9 | bsz 1 | num_updates 10175 | best_loss 8.499
2022-03-05 21:05:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10175 updates
2022-03-05 21:05:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:05:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:05:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 209 @ 10175 updates, score 13.909) (writing took 1.811463770456612 seconds)
2022-03-05 21:05:31 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-05 21:05:31 | INFO | train | epoch 209 | loss 1.482 | nll_loss 0.45 | ppl 1.37 | wps 27870.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10175 | lr 0.000313497 | gnorm 0.648 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24208
2022-03-05 21:05:31 | INFO | fairseq.trainer | begin training epoch 210
2022-03-05 21:05:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:06:27 | INFO | train_inner | epoch 210:     25 / 49 loss=1.481, nll_loss=0.45, ppl=1.37, wps=27668.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.649, loss_scale=16, train_wall=199, gb_free=21.6, wall=24264
2022-03-05 21:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:07:24 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 13.995 | nll_loss 13.612 | ppl 12519.6 | wps 47702.7 | wpb 510.9 | bsz 1 | num_updates 10224 | best_loss 8.499
2022-03-05 21:07:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10224 updates
2022-03-05 21:07:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:07:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:07:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 210 @ 10224 updates, score 13.995) (writing took 1.8290547421202064 seconds)
2022-03-05 21:07:25 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-05 21:07:25 | INFO | train | epoch 210 | loss 1.478 | nll_loss 0.447 | ppl 1.36 | wps 27897 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10224 | lr 0.000312744 | gnorm 0.655 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 24322
2022-03-05 21:07:25 | INFO | fairseq.trainer | begin training epoch 211
2022-03-05 21:07:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:08:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:09:18 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 14.003 | nll_loss 13.623 | ppl 12620.1 | wps 47253.9 | wpb 510.9 | bsz 1 | num_updates 10272 | best_loss 8.499
2022-03-05 21:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10272 updates
2022-03-05 21:09:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:09:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:09:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 211 @ 10272 updates, score 14.003) (writing took 1.802786665968597 seconds)
2022-03-05 21:09:19 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-05 21:09:19 | INFO | train | epoch 211 | loss 1.473 | nll_loss 0.442 | ppl 1.36 | wps 27297.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10272 | lr 0.000312013 | gnorm 0.628 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24436
2022-03-05 21:09:19 | INFO | fairseq.trainer | begin training epoch 212
2022-03-05 21:09:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:10:21 | INFO | train_inner | epoch 212:     28 / 49 loss=1.474, nll_loss=0.443, ppl=1.36, wps=27652.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.634, loss_scale=16, train_wall=199, gb_free=21.6, wall=24498
2022-03-05 21:11:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:11:12 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 13.826 | nll_loss 13.441 | ppl 11124.1 | wps 47715.5 | wpb 510.9 | bsz 1 | num_updates 10321 | best_loss 8.499
2022-03-05 21:11:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10321 updates
2022-03-05 21:11:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:11:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:11:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 212 @ 10321 updates, score 13.826) (writing took 1.7914864150807261 seconds)
2022-03-05 21:11:13 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-05 21:11:13 | INFO | train | epoch 212 | loss 1.473 | nll_loss 0.442 | ppl 1.36 | wps 27853.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10321 | lr 0.000311271 | gnorm 0.634 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24550
2022-03-05 21:11:13 | INFO | fairseq.trainer | begin training epoch 213
2022-03-05 21:11:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:13:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:13:05 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 13.932 | nll_loss 13.547 | ppl 11968.5 | wps 47707.2 | wpb 510.9 | bsz 1 | num_updates 10370 | best_loss 8.499
2022-03-05 21:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10370 updates
2022-03-05 21:13:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:13:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:13:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 213 @ 10370 updates, score 13.932) (writing took 1.7919093193486333 seconds)
2022-03-05 21:13:07 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-05 21:13:07 | INFO | train | epoch 213 | loss 1.47 | nll_loss 0.44 | ppl 1.36 | wps 27933.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10370 | lr 0.000310535 | gnorm 0.63 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 24664
2022-03-05 21:13:07 | INFO | fairseq.trainer | begin training epoch 214
2022-03-05 21:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:14:14 | INFO | train_inner | epoch 214:     30 / 49 loss=1.47, nll_loss=0.439, ppl=1.36, wps=27911.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.63, loss_scale=32, train_wall=197, gb_free=21.6, wall=24731
2022-03-05 21:14:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:15:00 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 13.901 | nll_loss 13.522 | ppl 11766.2 | wps 46748 | wpb 510.9 | bsz 1 | num_updates 10419 | best_loss 8.499
2022-03-05 21:15:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10419 updates
2022-03-05 21:15:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:15:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:15:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 214 @ 10419 updates, score 13.901) (writing took 1.7595055857673287 seconds)
2022-03-05 21:15:01 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-05 21:15:01 | INFO | train | epoch 214 | loss 1.467 | nll_loss 0.437 | ppl 1.35 | wps 27850.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10419 | lr 0.000309804 | gnorm 0.636 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 24778
2022-03-05 21:15:01 | INFO | fairseq.trainer | begin training epoch 215
2022-03-05 21:15:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:15:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:16:53 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 13.976 | nll_loss 13.603 | ppl 12438.3 | wps 47694.1 | wpb 510.9 | bsz 1 | num_updates 10467 | best_loss 8.499
2022-03-05 21:16:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10467 updates
2022-03-05 21:16:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:16:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 215 @ 10467 updates, score 13.976) (writing took 1.8518554270267487 seconds)
2022-03-05 21:16:55 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-05 21:16:55 | INFO | train | epoch 215 | loss 1.463 | nll_loss 0.433 | ppl 1.35 | wps 27298.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10467 | lr 0.000309093 | gnorm 0.63 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24892
2022-03-05 21:16:55 | INFO | fairseq.trainer | begin training epoch 216
2022-03-05 21:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:18:09 | INFO | train_inner | epoch 216:     33 / 49 loss=1.463, nll_loss=0.434, ppl=1.35, wps=27642.6, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.63, loss_scale=16, train_wall=199, gb_free=21.6, wall=24965
2022-03-05 21:18:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:18:48 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 13.993 | nll_loss 13.615 | ppl 12543.2 | wps 47670.7 | wpb 510.9 | bsz 1 | num_updates 10516 | best_loss 8.499
2022-03-05 21:18:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10516 updates
2022-03-05 21:18:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:18:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:18:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 216 @ 10516 updates, score 13.993) (writing took 1.7785482462495565 seconds)
2022-03-05 21:18:50 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-05 21:18:50 | INFO | train | epoch 216 | loss 1.462 | nll_loss 0.433 | ppl 1.35 | wps 27836.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10516 | lr 0.000308372 | gnorm 0.624 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25006
2022-03-05 21:18:50 | INFO | fairseq.trainer | begin training epoch 217
2022-03-05 21:18:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:20:42 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 13.992 | nll_loss 13.616 | ppl 12553.4 | wps 47707.9 | wpb 510.9 | bsz 1 | num_updates 10565 | best_loss 8.499
2022-03-05 21:20:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10565 updates
2022-03-05 21:20:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:20:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:20:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 217 @ 10565 updates, score 13.992) (writing took 1.8229568181559443 seconds)
2022-03-05 21:20:44 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-05 21:20:44 | INFO | train | epoch 217 | loss 1.46 | nll_loss 0.431 | ppl 1.35 | wps 27883.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10565 | lr 0.000307656 | gnorm 0.632 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 25120
2022-03-05 21:20:44 | INFO | fairseq.trainer | begin training epoch 218
2022-03-05 21:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:22:01 | INFO | train_inner | epoch 218:     35 / 49 loss=1.46, nll_loss=0.431, ppl=1.35, wps=27894.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.629, loss_scale=32, train_wall=197, gb_free=21.6, wall=25198
2022-03-05 21:22:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:22:36 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 13.951 | nll_loss 13.571 | ppl 12170 | wps 47477.3 | wpb 510.9 | bsz 1 | num_updates 10614 | best_loss 8.499
2022-03-05 21:22:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10614 updates
2022-03-05 21:22:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:22:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:22:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 218 @ 10614 updates, score 13.951) (writing took 1.7774816239252687 seconds)
2022-03-05 21:22:37 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-05 21:22:37 | INFO | train | epoch 218 | loss 1.458 | nll_loss 0.429 | ppl 1.35 | wps 27889.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10614 | lr 0.000306945 | gnorm 0.622 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25234
2022-03-05 21:22:37 | INFO | fairseq.trainer | begin training epoch 219
2022-03-05 21:22:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:23:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:24:30 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 13.876 | nll_loss 13.495 | ppl 11541.7 | wps 47645.9 | wpb 510.9 | bsz 1 | num_updates 10662 | best_loss 8.499
2022-03-05 21:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10662 updates
2022-03-05 21:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:24:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:24:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 219 @ 10662 updates, score 13.876) (writing took 1.808508973568678 seconds)
2022-03-05 21:24:31 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-05 21:24:31 | INFO | train | epoch 219 | loss 1.455 | nll_loss 0.426 | ppl 1.34 | wps 27307.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10662 | lr 0.000306253 | gnorm 0.616 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25348
2022-03-05 21:24:31 | INFO | fairseq.trainer | begin training epoch 220
2022-03-05 21:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:25:56 | INFO | train_inner | epoch 220:     38 / 49 loss=1.454, nll_loss=0.426, ppl=1.34, wps=27656.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.611, loss_scale=16, train_wall=199, gb_free=21.6, wall=25432
2022-03-05 21:26:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:26:24 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 14.001 | nll_loss 13.63 | ppl 12673.4 | wps 47636.1 | wpb 510.9 | bsz 1 | num_updates 10711 | best_loss 8.499
2022-03-05 21:26:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10711 updates
2022-03-05 21:26:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:26:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:26:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 220 @ 10711 updates, score 14.001) (writing took 1.7742241770029068 seconds)
2022-03-05 21:26:25 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-05 21:26:25 | INFO | train | epoch 220 | loss 1.452 | nll_loss 0.423 | ppl 1.34 | wps 27896.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10711 | lr 0.000305552 | gnorm 0.6 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25462
2022-03-05 21:26:25 | INFO | fairseq.trainer | begin training epoch 221
2022-03-05 21:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:28:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:28:18 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 14.038 | nll_loss 13.669 | ppl 13025.4 | wps 47764.2 | wpb 510.9 | bsz 1 | num_updates 10760 | best_loss 8.499
2022-03-05 21:28:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10760 updates
2022-03-05 21:28:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:28:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:28:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 221 @ 10760 updates, score 14.038) (writing took 1.8027348406612873 seconds)
2022-03-05 21:28:19 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-05 21:28:19 | INFO | train | epoch 221 | loss 1.451 | nll_loss 0.424 | ppl 1.34 | wps 27885.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10760 | lr 0.000304855 | gnorm 0.622 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25576
2022-03-05 21:28:19 | INFO | fairseq.trainer | begin training epoch 222
2022-03-05 21:28:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:28:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:29:50 | INFO | train_inner | epoch 222:     41 / 49 loss=1.45, nll_loss=0.422, ppl=1.34, wps=27653.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.616, loss_scale=16, train_wall=199, gb_free=21.6, wall=25667
2022-03-05 21:30:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:30:12 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 13.957 | nll_loss 13.583 | ppl 12269.7 | wps 47443.1 | wpb 510.9 | bsz 1 | num_updates 10808 | best_loss 8.499
2022-03-05 21:30:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10808 updates
2022-03-05 21:30:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:30:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:30:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 222 @ 10808 updates, score 13.957) (writing took 1.786810272373259 seconds)
2022-03-05 21:30:13 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-05 21:30:13 | INFO | train | epoch 222 | loss 1.448 | nll_loss 0.42 | ppl 1.34 | wps 27311.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10808 | lr 0.000304178 | gnorm 0.61 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 25690
2022-03-05 21:30:13 | INFO | fairseq.trainer | begin training epoch 223
2022-03-05 21:30:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:32:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:32:06 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 14.004 | nll_loss 13.637 | ppl 12740.3 | wps 47586.7 | wpb 510.9 | bsz 1 | num_updates 10857 | best_loss 8.499
2022-03-05 21:32:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10857 updates
2022-03-05 21:32:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:32:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 223 @ 10857 updates, score 14.004) (writing took 1.803193231113255 seconds)
2022-03-05 21:32:07 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-05 21:32:07 | INFO | train | epoch 223 | loss 1.446 | nll_loss 0.418 | ppl 1.34 | wps 27847.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10857 | lr 0.00030349 | gnorm 0.615 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25804
2022-03-05 21:32:07 | INFO | fairseq.trainer | begin training epoch 224
2022-03-05 21:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:33:43 | INFO | train_inner | epoch 224:     43 / 49 loss=1.445, nll_loss=0.417, ppl=1.34, wps=27889.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.609, loss_scale=16, train_wall=197, gb_free=21.6, wall=25900
2022-03-05 21:33:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:34:00 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.887 | nll_loss 13.51 | ppl 11661.9 | wps 47192.5 | wpb 510.9 | bsz 1 | num_updates 10906 | best_loss 8.499
2022-03-05 21:34:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10906 updates
2022-03-05 21:34:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:34:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 224 @ 10906 updates, score 13.887) (writing took 1.7720390250906348 seconds)
2022-03-05 21:34:02 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-05 21:34:02 | INFO | train | epoch 224 | loss 1.442 | nll_loss 0.415 | ppl 1.33 | wps 27858.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10906 | lr 0.000302808 | gnorm 0.603 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25918
2022-03-05 21:34:02 | INFO | fairseq.trainer | begin training epoch 225
2022-03-05 21:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:35:54 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 13.895 | nll_loss 13.513 | ppl 11693.6 | wps 47709.2 | wpb 510.9 | bsz 1 | num_updates 10955 | best_loss 8.499
2022-03-05 21:35:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10955 updates
2022-03-05 21:35:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:35:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:35:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 225 @ 10955 updates, score 13.895) (writing took 1.818971392698586 seconds)
2022-03-05 21:35:56 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-05 21:35:56 | INFO | train | epoch 225 | loss 1.441 | nll_loss 0.415 | ppl 1.33 | wps 27849.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10955 | lr 0.00030213 | gnorm 0.604 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26032
2022-03-05 21:35:56 | INFO | fairseq.trainer | begin training epoch 226
2022-03-05 21:35:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:37:36 | INFO | train_inner | epoch 226:     45 / 49 loss=1.44, nll_loss=0.413, ppl=1.33, wps=27875.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11000, lr=0.000301511, gnorm=0.603, loss_scale=32, train_wall=197, gb_free=21.6, wall=26132
2022-03-05 21:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:37:48 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 13.968 | nll_loss 13.598 | ppl 12400.7 | wps 47691 | wpb 510.9 | bsz 1 | num_updates 11004 | best_loss 8.499
2022-03-05 21:37:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 11004 updates
2022-03-05 21:37:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:37:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 226 @ 11004 updates, score 13.968) (writing took 1.7662387387827039 seconds)
2022-03-05 21:37:50 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-05 21:37:50 | INFO | train | epoch 226 | loss 1.438 | nll_loss 0.411 | ppl 1.33 | wps 27847.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11004 | lr 0.000301457 | gnorm 0.603 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26147
2022-03-05 21:37:50 | INFO | fairseq.trainer | begin training epoch 227
2022-03-05 21:37:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:38:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:39:42 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.895 | nll_loss 13.521 | ppl 11756.6 | wps 47625.7 | wpb 510.9 | bsz 1 | num_updates 11052 | best_loss 8.499
2022-03-05 21:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11052 updates
2022-03-05 21:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 227 @ 11052 updates, score 13.895) (writing took 1.8080443041399121 seconds)
2022-03-05 21:39:44 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-05 21:39:44 | INFO | train | epoch 227 | loss 1.436 | nll_loss 0.41 | ppl 1.33 | wps 27326.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11052 | lr 0.000300801 | gnorm 0.605 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 26260
2022-03-05 21:39:44 | INFO | fairseq.trainer | begin training epoch 228
2022-03-05 21:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:41:30 | INFO | train_inner | epoch 228:     48 / 49 loss=1.435, nll_loss=0.41, ppl=1.33, wps=27673.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.604, loss_scale=16, train_wall=199, gb_free=21.6, wall=26367
2022-03-05 21:41:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:41:36 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.941 | nll_loss 13.567 | ppl 12139.9 | wps 47115.9 | wpb 510.9 | bsz 1 | num_updates 11101 | best_loss 8.499
2022-03-05 21:41:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11101 updates
2022-03-05 21:41:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:41:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:41:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 228 @ 11101 updates, score 13.941) (writing took 1.8233429370447993 seconds)
2022-03-05 21:41:38 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-05 21:41:38 | INFO | train | epoch 228 | loss 1.434 | nll_loss 0.408 | ppl 1.33 | wps 27872.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11101 | lr 0.000300137 | gnorm 0.601 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 26374
2022-03-05 21:41:38 | INFO | fairseq.trainer | begin training epoch 229
2022-03-05 21:41:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:43:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:43:30 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.843 | nll_loss 13.471 | ppl 11356.9 | wps 47438.4 | wpb 510.9 | bsz 1 | num_updates 11150 | best_loss 8.499
2022-03-05 21:43:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11150 updates
2022-03-05 21:43:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:43:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:43:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 229 @ 11150 updates, score 13.843) (writing took 1.801422723568976 seconds)
2022-03-05 21:43:32 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-05 21:43:32 | INFO | train | epoch 229 | loss 1.432 | nll_loss 0.407 | ppl 1.33 | wps 27910.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11150 | lr 0.000299476 | gnorm 0.603 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 26488
2022-03-05 21:43:32 | INFO | fairseq.trainer | begin training epoch 230
2022-03-05 21:43:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:45:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:45:24 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 13.935 | nll_loss 13.558 | ppl 12059.6 | wps 47117.8 | wpb 510.9 | bsz 1 | num_updates 11199 | best_loss 8.499
2022-03-05 21:45:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11199 updates
2022-03-05 21:45:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:45:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 230 @ 11199 updates, score 13.935) (writing took 1.765686429105699 seconds)
2022-03-05 21:45:26 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-05 21:45:26 | INFO | train | epoch 230 | loss 1.429 | nll_loss 0.404 | ppl 1.32 | wps 27878.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11199 | lr 0.00029882 | gnorm 0.588 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26602
2022-03-05 21:45:26 | INFO | fairseq.trainer | begin training epoch 231
2022-03-05 21:45:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:45:28 | INFO | train_inner | epoch 231:      1 / 49 loss=1.431, nll_loss=0.405, ppl=1.32, wps=27138.7, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=11200, lr=0.000298807, gnorm=0.597, loss_scale=32, train_wall=196, gb_free=21.6, wall=26605
2022-03-05 21:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:47:18 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 14.008 | nll_loss 13.64 | ppl 12768.4 | wps 47773.8 | wpb 510.9 | bsz 1 | num_updates 11248 | best_loss 8.499
2022-03-05 21:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11248 updates
2022-03-05 21:47:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:47:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:47:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 231 @ 11248 updates, score 14.008) (writing took 1.8108294121921062 seconds)
2022-03-05 21:47:20 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-05 21:47:20 | INFO | train | epoch 231 | loss 1.427 | nll_loss 0.402 | ppl 1.32 | wps 27867.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11248 | lr 0.000298169 | gnorm 0.599 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26716
2022-03-05 21:47:20 | INFO | fairseq.trainer | begin training epoch 232
2022-03-05 21:47:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:48:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:48:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:49:12 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.944 | nll_loss 13.577 | ppl 12216.3 | wps 47557 | wpb 510.9 | bsz 1 | num_updates 11295 | best_loss 8.499
2022-03-05 21:49:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11295 updates
2022-03-05 21:49:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:49:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:49:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 232 @ 11295 updates, score 13.944) (writing took 1.7658308278769255 seconds)
2022-03-05 21:49:14 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-05 21:49:14 | INFO | train | epoch 232 | loss 1.424 | nll_loss 0.399 | ppl 1.32 | wps 26733 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 11295 | lr 0.000297548 | gnorm 0.586 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26830
2022-03-05 21:49:14 | INFO | fairseq.trainer | begin training epoch 233
2022-03-05 21:49:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:49:25 | INFO | train_inner | epoch 233:      5 / 49 loss=1.425, nll_loss=0.4, ppl=1.32, wps=27387.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.595, loss_scale=16, train_wall=201, gb_free=21.6, wall=26841
2022-03-05 21:51:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:51:06 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 13.947 | nll_loss 13.58 | ppl 12248.8 | wps 47403.5 | wpb 510.9 | bsz 1 | num_updates 11344 | best_loss 8.499
2022-03-05 21:51:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11344 updates
2022-03-05 21:51:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:51:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:51:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 233 @ 11344 updates, score 13.947) (writing took 1.796980015002191 seconds)
2022-03-05 21:51:08 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-05 21:51:08 | INFO | train | epoch 233 | loss 1.424 | nll_loss 0.4 | ppl 1.32 | wps 27886.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11344 | lr 0.000296905 | gnorm 0.607 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 26944
2022-03-05 21:51:08 | INFO | fairseq.trainer | begin training epoch 234
2022-03-05 21:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:52:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:53:00 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 13.894 | nll_loss 13.526 | ppl 11791.9 | wps 47563.3 | wpb 510.9 | bsz 1 | num_updates 11393 | best_loss 8.499
2022-03-05 21:53:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11393 updates
2022-03-05 21:53:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:53:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:53:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 234 @ 11393 updates, score 13.894) (writing took 1.741278343833983 seconds)
2022-03-05 21:53:02 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-05 21:53:02 | INFO | train | epoch 234 | loss 1.422 | nll_loss 0.398 | ppl 1.32 | wps 27878.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11393 | lr 0.000296265 | gnorm 0.589 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27058
2022-03-05 21:53:02 | INFO | fairseq.trainer | begin training epoch 235
2022-03-05 21:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:53:17 | INFO | train_inner | epoch 235:      7 / 49 loss=1.423, nll_loss=0.399, ppl=1.32, wps=27917.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.597, loss_scale=16, train_wall=197, gb_free=21.6, wall=27074
2022-03-05 21:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:54:54 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 13.888 | nll_loss 13.513 | ppl 11691.2 | wps 47673.8 | wpb 510.9 | bsz 1 | num_updates 11442 | best_loss 8.499
2022-03-05 21:54:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11442 updates
2022-03-05 21:54:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 235 @ 11442 updates, score 13.888) (writing took 1.7977852383628488 seconds)
2022-03-05 21:54:55 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-05 21:54:55 | INFO | train | epoch 235 | loss 1.42 | nll_loss 0.396 | ppl 1.32 | wps 27917.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11442 | lr 0.00029563 | gnorm 0.591 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27172
2022-03-05 21:54:55 | INFO | fairseq.trainer | begin training epoch 236
2022-03-05 21:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:54:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:56:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:56:48 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.983 | nll_loss 13.614 | ppl 12535.3 | wps 47856.9 | wpb 510.9 | bsz 1 | num_updates 11490 | best_loss 8.499
2022-03-05 21:56:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11490 updates
2022-03-05 21:56:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:56:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:56:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 236 @ 11490 updates, score 13.983) (writing took 1.7605482209473848 seconds)
2022-03-05 21:56:49 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-05 21:56:49 | INFO | train | epoch 236 | loss 1.418 | nll_loss 0.394 | ppl 1.31 | wps 27315.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11490 | lr 0.000295012 | gnorm 0.592 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27286
2022-03-05 21:56:49 | INFO | fairseq.trainer | begin training epoch 237
2022-03-05 21:56:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:57:11 | INFO | train_inner | epoch 237:     10 / 49 loss=1.418, nll_loss=0.394, ppl=1.31, wps=27673.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.589, loss_scale=16, train_wall=199, gb_free=21.6, wall=27308
2022-03-05 21:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:58:41 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 13.928 | nll_loss 13.562 | ppl 12091.2 | wps 47654.3 | wpb 510.9 | bsz 1 | num_updates 11539 | best_loss 8.499
2022-03-05 21:58:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11539 updates
2022-03-05 21:58:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:58:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 21:58:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 237 @ 11539 updates, score 13.928) (writing took 1.803195497021079 seconds)
2022-03-05 21:58:43 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-05 21:58:43 | INFO | train | epoch 237 | loss 1.416 | nll_loss 0.392 | ppl 1.31 | wps 27911.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11539 | lr 0.000294385 | gnorm 0.58 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 27400
2022-03-05 21:58:43 | INFO | fairseq.trainer | begin training epoch 238
2022-03-05 21:58:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:00:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:00:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:00:35 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.962 | nll_loss 13.593 | ppl 12354.3 | wps 47549.7 | wpb 510.9 | bsz 1 | num_updates 11587 | best_loss 8.499
2022-03-05 22:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11587 updates
2022-03-05 22:00:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:00:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:00:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 238 @ 11587 updates, score 13.962) (writing took 1.755446414463222 seconds)
2022-03-05 22:00:37 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-05 22:00:37 | INFO | train | epoch 238 | loss 1.413 | nll_loss 0.39 | ppl 1.31 | wps 27311.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11587 | lr 0.000293775 | gnorm 0.576 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27514
2022-03-05 22:00:37 | INFO | fairseq.trainer | begin training epoch 239
2022-03-05 22:00:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:01:06 | INFO | train_inner | epoch 239:     13 / 49 loss=1.414, nll_loss=0.391, ppl=1.31, wps=27665.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.576, loss_scale=16, train_wall=199, gb_free=21.6, wall=27543
2022-03-05 22:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:02:29 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.985 | nll_loss 13.614 | ppl 12537.2 | wps 47661.4 | wpb 510.9 | bsz 1 | num_updates 11636 | best_loss 8.499
2022-03-05 22:02:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11636 updates
2022-03-05 22:02:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:02:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:02:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 239 @ 11636 updates, score 13.985) (writing took 1.7712611174210906 seconds)
2022-03-05 22:02:31 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-05 22:02:31 | INFO | train | epoch 239 | loss 1.412 | nll_loss 0.389 | ppl 1.31 | wps 27906.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11636 | lr 0.000293156 | gnorm 0.578 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 27628
2022-03-05 22:02:31 | INFO | fairseq.trainer | begin training epoch 240
2022-03-05 22:02:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:04:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:04:23 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.945 | nll_loss 13.58 | ppl 12242.6 | wps 47621.2 | wpb 510.9 | bsz 1 | num_updates 11685 | best_loss 8.499
2022-03-05 22:04:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11685 updates
2022-03-05 22:04:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:04:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:04:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 240 @ 11685 updates, score 13.945) (writing took 1.7555899927392602 seconds)
2022-03-05 22:04:25 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-05 22:04:25 | INFO | train | epoch 240 | loss 1.41 | nll_loss 0.387 | ppl 1.31 | wps 27874.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11685 | lr 0.00029254 | gnorm 0.578 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27742
2022-03-05 22:04:25 | INFO | fairseq.trainer | begin training epoch 241
2022-03-05 22:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:04:58 | INFO | train_inner | epoch 241:     15 / 49 loss=1.41, nll_loss=0.388, ppl=1.31, wps=27926.2, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.58, loss_scale=16, train_wall=197, gb_free=21.6, wall=27775
2022-03-05 22:06:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:06:17 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 13.936 | nll_loss 13.569 | ppl 12155 | wps 47254.5 | wpb 510.9 | bsz 1 | num_updates 11734 | best_loss 8.499
2022-03-05 22:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11734 updates
2022-03-05 22:06:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:06:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:06:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 241 @ 11734 updates, score 13.936) (writing took 1.799581028521061 seconds)
2022-03-05 22:06:19 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-05 22:06:19 | INFO | train | epoch 241 | loss 1.409 | nll_loss 0.387 | ppl 1.31 | wps 27911.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11734 | lr 0.000291929 | gnorm 0.577 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27856
2022-03-05 22:06:19 | INFO | fairseq.trainer | begin training epoch 242
2022-03-05 22:06:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:08:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:08:11 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.933 | nll_loss 13.563 | ppl 12106.2 | wps 47714.8 | wpb 510.9 | bsz 1 | num_updates 11783 | best_loss 8.499
2022-03-05 22:08:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11783 updates
2022-03-05 22:08:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:08:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:08:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 242 @ 11783 updates, score 13.933) (writing took 1.7444737367331982 seconds)
2022-03-05 22:08:13 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-05 22:08:13 | INFO | train | epoch 242 | loss 1.407 | nll_loss 0.385 | ppl 1.31 | wps 27916.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11783 | lr 0.000291321 | gnorm 0.583 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27970
2022-03-05 22:08:13 | INFO | fairseq.trainer | begin training epoch 243
2022-03-05 22:08:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:08:50 | INFO | train_inner | epoch 243:     17 / 49 loss=1.407, nll_loss=0.385, ppl=1.31, wps=27946.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.577, loss_scale=32, train_wall=197, gb_free=21.6, wall=28007
2022-03-05 22:10:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:10:06 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.87 | nll_loss 13.5 | ppl 11582.5 | wps 45798.7 | wpb 510.9 | bsz 1 | num_updates 11832 | best_loss 8.499
2022-03-05 22:10:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11832 updates
2022-03-05 22:10:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:10:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:10:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 243 @ 11832 updates, score 13.87) (writing took 1.9929505456238985 seconds)
2022-03-05 22:10:08 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-05 22:10:08 | INFO | train | epoch 243 | loss 1.405 | nll_loss 0.383 | ppl 1.3 | wps 27553.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11832 | lr 0.000290717 | gnorm 0.57 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28085
2022-03-05 22:10:08 | INFO | fairseq.trainer | begin training epoch 244
2022-03-05 22:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:10:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:12:03 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.929 | nll_loss 13.565 | ppl 12118.7 | wps 45815.6 | wpb 510.9 | bsz 1 | num_updates 11880 | best_loss 8.499
2022-03-05 22:12:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11880 updates
2022-03-05 22:12:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:12:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 244 @ 11880 updates, score 13.929) (writing took 1.8818739335983992 seconds)
2022-03-05 22:12:05 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-05 22:12:05 | INFO | train | epoch 244 | loss 1.402 | nll_loss 0.381 | ppl 1.3 | wps 26548.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 11880 | lr 0.000290129 | gnorm 0.574 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 28202
2022-03-05 22:12:05 | INFO | fairseq.trainer | begin training epoch 245
2022-03-05 22:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:12:50 | INFO | train_inner | epoch 245:     20 / 49 loss=1.403, nll_loss=0.382, ppl=1.3, wps=27035.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.573, loss_scale=32, train_wall=202, gb_free=21.6, wall=28247
2022-03-05 22:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:13:59 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.934 | nll_loss 13.569 | ppl 12155.4 | wps 45623.6 | wpb 510.9 | bsz 1 | num_updates 11929 | best_loss 8.499
2022-03-05 22:13:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11929 updates
2022-03-05 22:13:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:14:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:14:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 245 @ 11929 updates, score 13.934) (writing took 1.8810476455837488 seconds)
2022-03-05 22:14:01 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-05 22:14:01 | INFO | train | epoch 245 | loss 1.401 | nll_loss 0.38 | ppl 1.3 | wps 27434.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 11929 | lr 0.000289533 | gnorm 0.566 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 28318
2022-03-05 22:14:01 | INFO | fairseq.trainer | begin training epoch 246
2022-03-05 22:14:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:15:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:15:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:15:55 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.939 | nll_loss 13.575 | ppl 12207.4 | wps 46195.1 | wpb 510.9 | bsz 1 | num_updates 11977 | best_loss 8.499
2022-03-05 22:15:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11977 updates
2022-03-05 22:15:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:15:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:15:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 246 @ 11977 updates, score 13.939) (writing took 1.9800074007362127 seconds)
2022-03-05 22:15:57 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-05 22:15:57 | INFO | train | epoch 246 | loss 1.398 | nll_loss 0.377 | ppl 1.3 | wps 26863.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 11977 | lr 0.000288952 | gnorm 0.561 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 28434
2022-03-05 22:15:57 | INFO | fairseq.trainer | begin training epoch 247
2022-03-05 22:15:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:16:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:16:51 | INFO | train_inner | epoch 247:     24 / 49 loss=1.399, nll_loss=0.378, ppl=1.3, wps=26951, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.564, loss_scale=16, train_wall=204, gb_free=21.6, wall=28488
2022-03-05 22:17:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:17:51 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.846 | nll_loss 13.477 | ppl 11399.5 | wps 45840.3 | wpb 510.9 | bsz 1 | num_updates 12025 | best_loss 8.499
2022-03-05 22:17:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12025 updates
2022-03-05 22:17:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:17:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 247 @ 12025 updates, score 13.846) (writing took 1.9657361786812544 seconds)
2022-03-05 22:17:53 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-05 22:17:53 | INFO | train | epoch 247 | loss 1.398 | nll_loss 0.378 | ppl 1.3 | wps 26859.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 12025 | lr 0.000288375 | gnorm 0.576 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 28550
2022-03-05 22:17:53 | INFO | fairseq.trainer | begin training epoch 248
2022-03-05 22:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:19:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:19:48 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 13.952 | nll_loss 13.595 | ppl 12377.6 | wps 45812.7 | wpb 510.9 | bsz 1 | num_updates 12074 | best_loss 8.499
2022-03-05 22:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12074 updates
2022-03-05 22:19:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:19:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 248 @ 12074 updates, score 13.952) (writing took 1.7483777524903417 seconds)
2022-03-05 22:19:50 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-05 22:19:50 | INFO | train | epoch 248 | loss 1.395 | nll_loss 0.375 | ppl 1.3 | wps 27137.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12074 | lr 0.000287789 | gnorm 0.558 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 28667
2022-03-05 22:19:50 | INFO | fairseq.trainer | begin training epoch 249
2022-03-05 22:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:20:48 | INFO | train_inner | epoch 249:     26 / 49 loss=1.395, nll_loss=0.375, ppl=1.3, wps=27326.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.564, loss_scale=16, train_wall=199, gb_free=21.6, wall=28725
2022-03-05 22:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:21:44 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 13.862 | nll_loss 13.495 | ppl 11544.8 | wps 45680.2 | wpb 510.9 | bsz 1 | num_updates 12123 | best_loss 8.499
2022-03-05 22:21:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12123 updates
2022-03-05 22:21:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:21:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:21:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 249 @ 12123 updates, score 13.862) (writing took 2.0338834105059505 seconds)
2022-03-05 22:21:46 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-05 22:21:46 | INFO | train | epoch 249 | loss 1.394 | nll_loss 0.374 | ppl 1.3 | wps 27424 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12123 | lr 0.000287207 | gnorm 0.569 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 28783
2022-03-05 22:21:46 | INFO | fairseq.trainer | begin training epoch 250
2022-03-05 22:21:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:23:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:23:40 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.966 | nll_loss 13.606 | ppl 12471 | wps 45956.2 | wpb 510.9 | bsz 1 | num_updates 12172 | best_loss 8.499
2022-03-05 22:23:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12172 updates
2022-03-05 22:23:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:23:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 250 @ 12172 updates, score 13.966) (writing took 2.2423567874357104 seconds)
2022-03-05 22:23:42 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-05 22:23:42 | INFO | train | epoch 250 | loss 1.392 | nll_loss 0.373 | ppl 1.29 | wps 27370.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12172 | lr 0.000286628 | gnorm 0.57 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 28899
2022-03-05 22:23:42 | INFO | fairseq.trainer | begin training epoch 251
2022-03-05 22:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:24:45 | INFO | train_inner | epoch 251:     28 / 49 loss=1.392, nll_loss=0.372, ppl=1.29, wps=27444.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.568, loss_scale=32, train_wall=199, gb_free=21.6, wall=28962
2022-03-05 22:25:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:25:36 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.928 | nll_loss 13.568 | ppl 12142 | wps 46174.9 | wpb 510.9 | bsz 1 | num_updates 12221 | best_loss 8.499
2022-03-05 22:25:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12221 updates
2022-03-05 22:25:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:25:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:25:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 251 @ 12221 updates, score 13.928) (writing took 1.8941639866679907 seconds)
2022-03-05 22:25:37 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-05 22:25:37 | INFO | train | epoch 251 | loss 1.389 | nll_loss 0.37 | ppl 1.29 | wps 27529.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12221 | lr 0.000286053 | gnorm 0.571 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29014
2022-03-05 22:25:37 | INFO | fairseq.trainer | begin training epoch 252
2022-03-05 22:25:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:26:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:27:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:27:31 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.985 | nll_loss 13.626 | ppl 12644.5 | wps 45563.5 | wpb 510.9 | bsz 1 | num_updates 12269 | best_loss 8.499
2022-03-05 22:27:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12269 updates
2022-03-05 22:27:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:27:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:27:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 252 @ 12269 updates, score 13.985) (writing took 2.0916078547015786 seconds)
2022-03-05 22:27:33 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-05 22:27:33 | INFO | train | epoch 252 | loss 1.388 | nll_loss 0.369 | ppl 1.29 | wps 26843 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 12269 | lr 0.000285493 | gnorm 0.557 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 29130
2022-03-05 22:27:33 | INFO | fairseq.trainer | begin training epoch 253
2022-03-05 22:27:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:28:43 | INFO | train_inner | epoch 253:     31 / 49 loss=1.388, nll_loss=0.369, ppl=1.29, wps=27227.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.56, loss_scale=32, train_wall=201, gb_free=21.6, wall=29200
2022-03-05 22:29:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:29:27 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.834 | nll_loss 13.463 | ppl 11295.1 | wps 46115.1 | wpb 510.9 | bsz 1 | num_updates 12318 | best_loss 8.499
2022-03-05 22:29:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12318 updates
2022-03-05 22:29:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:29:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:29:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 253 @ 12318 updates, score 13.834) (writing took 2.0720167383551598 seconds)
2022-03-05 22:29:29 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-05 22:29:29 | INFO | train | epoch 253 | loss 1.386 | nll_loss 0.367 | ppl 1.29 | wps 27441.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12318 | lr 0.000284925 | gnorm 0.557 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 29246
2022-03-05 22:29:29 | INFO | fairseq.trainer | begin training epoch 254
2022-03-05 22:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:31:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:31:23 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.785 | nll_loss 13.417 | ppl 10937.2 | wps 45480.1 | wpb 510.9 | bsz 1 | num_updates 12367 | best_loss 8.499
2022-03-05 22:31:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12367 updates
2022-03-05 22:31:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:31:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:31:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 254 @ 12367 updates, score 13.785) (writing took 2.1313985344022512 seconds)
2022-03-05 22:31:25 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-05 22:31:25 | INFO | train | epoch 254 | loss 1.385 | nll_loss 0.367 | ppl 1.29 | wps 27417.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12367 | lr 0.00028436 | gnorm 0.553 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 29362
2022-03-05 22:31:25 | INFO | fairseq.trainer | begin training epoch 255
2022-03-05 22:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:31:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:32:42 | INFO | train_inner | epoch 255:     34 / 49 loss=1.385, nll_loss=0.367, ppl=1.29, wps=27202.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.561, loss_scale=32, train_wall=201, gb_free=21.6, wall=29438
2022-03-05 22:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:33:19 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.996 | nll_loss 13.637 | ppl 12735.9 | wps 45690.1 | wpb 510.9 | bsz 1 | num_updates 12415 | best_loss 8.499
2022-03-05 22:33:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12415 updates
2022-03-05 22:33:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:33:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:33:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 255 @ 12415 updates, score 13.996) (writing took 2.0334048001095653 seconds)
2022-03-05 22:33:21 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-05 22:33:21 | INFO | train | epoch 255 | loss 1.384 | nll_loss 0.366 | ppl 1.29 | wps 26866.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 12415 | lr 0.000283809 | gnorm 0.562 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 29478
2022-03-05 22:33:21 | INFO | fairseq.trainer | begin training epoch 256
2022-03-05 22:33:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:35:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:35:15 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.91 | nll_loss 13.543 | ppl 11935 | wps 45780.1 | wpb 510.9 | bsz 1 | num_updates 12464 | best_loss 8.499
2022-03-05 22:35:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12464 updates
2022-03-05 22:35:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:35:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:35:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 256 @ 12464 updates, score 13.91) (writing took 1.9104236317798495 seconds)
2022-03-05 22:35:17 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-05 22:35:17 | INFO | train | epoch 256 | loss 1.383 | nll_loss 0.365 | ppl 1.29 | wps 27478.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12464 | lr 0.000283251 | gnorm 0.562 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 29593
2022-03-05 22:35:17 | INFO | fairseq.trainer | begin training epoch 257
2022-03-05 22:35:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:36:37 | INFO | train_inner | epoch 257:     36 / 49 loss=1.382, nll_loss=0.364, ppl=1.29, wps=27493.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.551, loss_scale=64, train_wall=199, gb_free=21.6, wall=29674
2022-03-05 22:36:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:37:10 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.824 | nll_loss 13.461 | ppl 11274.5 | wps 46102.1 | wpb 510.9 | bsz 1 | num_updates 12512 | best_loss 8.499
2022-03-05 22:37:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12512 updates
2022-03-05 22:37:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:37:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:37:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 257 @ 12512 updates, score 13.824) (writing took 1.9974393406882882 seconds)
2022-03-05 22:37:12 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-05 22:37:12 | INFO | train | epoch 257 | loss 1.38 | nll_loss 0.362 | ppl 1.29 | wps 26901.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 12512 | lr 0.000282707 | gnorm 0.544 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 29709
2022-03-05 22:37:12 | INFO | fairseq.trainer | begin training epoch 258
2022-03-05 22:37:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:39:06 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.884 | nll_loss 13.52 | ppl 11749.5 | wps 45595.9 | wpb 510.9 | bsz 1 | num_updates 12561 | best_loss 8.499
2022-03-05 22:39:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12561 updates
2022-03-05 22:39:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:39:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:39:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 258 @ 12561 updates, score 13.884) (writing took 1.9523758040741086 seconds)
2022-03-05 22:39:08 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-05 22:39:08 | INFO | train | epoch 258 | loss 1.379 | nll_loss 0.362 | ppl 1.28 | wps 27446 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12561 | lr 0.000282155 | gnorm 0.553 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 29825
2022-03-05 22:39:08 | INFO | fairseq.trainer | begin training epoch 259
2022-03-05 22:39:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:39:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:40:38 | INFO | train_inner | epoch 259:     40 / 49 loss=1.378, nll_loss=0.361, ppl=1.28, wps=26976, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.551, loss_scale=16, train_wall=203, gb_free=21.6, wall=29915
2022-03-05 22:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:41:02 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.82 | nll_loss 13.455 | ppl 11230.5 | wps 45830.2 | wpb 510.9 | bsz 1 | num_updates 12609 | best_loss 8.499
2022-03-05 22:41:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12609 updates
2022-03-05 22:41:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:41:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:41:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 259 @ 12609 updates, score 13.82) (writing took 1.9882486062124372 seconds)
2022-03-05 22:41:04 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-05 22:41:04 | INFO | train | epoch 259 | loss 1.376 | nll_loss 0.359 | ppl 1.28 | wps 26883.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 12609 | lr 0.000281618 | gnorm 0.546 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 29941
2022-03-05 22:41:04 | INFO | fairseq.trainer | begin training epoch 260
2022-03-05 22:41:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:42:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:42:57 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.891 | nll_loss 13.533 | ppl 11854 | wps 45947.1 | wpb 510.9 | bsz 1 | num_updates 12658 | best_loss 8.499
2022-03-05 22:42:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12658 updates
2022-03-05 22:42:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:42:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:42:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 260 @ 12658 updates, score 13.891) (writing took 1.9573145359754562 seconds)
2022-03-05 22:42:59 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-05 22:42:59 | INFO | train | epoch 260 | loss 1.376 | nll_loss 0.359 | ppl 1.28 | wps 27502.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12658 | lr 0.000281072 | gnorm 0.557 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 30056
2022-03-05 22:42:59 | INFO | fairseq.trainer | begin training epoch 261
2022-03-05 22:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:44:34 | INFO | train_inner | epoch 261:     42 / 49 loss=1.375, nll_loss=0.359, ppl=1.28, wps=27519.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.551, loss_scale=32, train_wall=199, gb_free=21.6, wall=30150
2022-03-05 22:44:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:44:53 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.903 | nll_loss 13.538 | ppl 11894.6 | wps 45560.2 | wpb 510.9 | bsz 1 | num_updates 12706 | best_loss 8.499
2022-03-05 22:44:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12706 updates
2022-03-05 22:44:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:44:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:44:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 261 @ 12706 updates, score 13.903) (writing took 1.9784281821921468 seconds)
2022-03-05 22:44:55 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-05 22:44:55 | INFO | train | epoch 261 | loss 1.374 | nll_loss 0.357 | ppl 1.28 | wps 26904.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 12706 | lr 0.000280541 | gnorm 0.545 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 30172
2022-03-05 22:44:55 | INFO | fairseq.trainer | begin training epoch 262
2022-03-05 22:44:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:46:49 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.898 | nll_loss 13.538 | ppl 11896.2 | wps 45646.5 | wpb 510.9 | bsz 1 | num_updates 12755 | best_loss 8.499
2022-03-05 22:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12755 updates
2022-03-05 22:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:46:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 262 @ 12755 updates, score 13.898) (writing took 1.9596745409071445 seconds)
2022-03-05 22:46:51 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-05 22:46:51 | INFO | train | epoch 262 | loss 1.373 | nll_loss 0.356 | ppl 1.28 | wps 27464.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12755 | lr 0.000280001 | gnorm 0.548 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 30288
2022-03-05 22:46:51 | INFO | fairseq.trainer | begin training epoch 263
2022-03-05 22:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:48:32 | INFO | train_inner | epoch 263:     45 / 49 loss=1.372, nll_loss=0.356, ppl=1.28, wps=27237.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.546, loss_scale=16, train_wall=201, gb_free=21.6, wall=30389
2022-03-05 22:48:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:48:45 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.836 | nll_loss 13.471 | ppl 11350.8 | wps 45947.4 | wpb 510.9 | bsz 1 | num_updates 12804 | best_loss 8.499
2022-03-05 22:48:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12804 updates
2022-03-05 22:48:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:48:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:48:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 263 @ 12804 updates, score 13.836) (writing took 1.9549930561333895 seconds)
2022-03-05 22:48:47 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-05 22:48:47 | INFO | train | epoch 263 | loss 1.371 | nll_loss 0.355 | ppl 1.28 | wps 27467.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12804 | lr 0.000279465 | gnorm 0.541 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 30403
2022-03-05 22:48:47 | INFO | fairseq.trainer | begin training epoch 264
2022-03-05 22:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:50:40 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.848 | nll_loss 13.484 | ppl 11460.6 | wps 46153.8 | wpb 510.9 | bsz 1 | num_updates 12853 | best_loss 8.499
2022-03-05 22:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12853 updates
2022-03-05 22:50:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:50:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:50:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 264 @ 12853 updates, score 13.848) (writing took 1.9354864759370685 seconds)
2022-03-05 22:50:42 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-05 22:50:42 | INFO | train | epoch 264 | loss 1.37 | nll_loss 0.354 | ppl 1.28 | wps 27479.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12853 | lr 0.000278932 | gnorm 0.545 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 30519
2022-03-05 22:50:42 | INFO | fairseq.trainer | begin training epoch 265
2022-03-05 22:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:52:28 | INFO | train_inner | epoch 265:     47 / 49 loss=1.369, nll_loss=0.353, ppl=1.28, wps=27487.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12900, lr=0.000278423, gnorm=0.546, loss_scale=32, train_wall=199, gb_free=21.6, wall=30625
2022-03-05 22:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:52:36 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.824 | nll_loss 13.46 | ppl 11267.2 | wps 46250 | wpb 510.9 | bsz 1 | num_updates 12902 | best_loss 8.499
2022-03-05 22:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12902 updates
2022-03-05 22:52:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:52:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 265 @ 12902 updates, score 13.824) (writing took 1.962630937807262 seconds)
2022-03-05 22:52:38 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-05 22:52:38 | INFO | train | epoch 265 | loss 1.368 | nll_loss 0.352 | ppl 1.28 | wps 27437.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12902 | lr 0.000278401 | gnorm 0.548 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 30635
2022-03-05 22:52:38 | INFO | fairseq.trainer | begin training epoch 266
2022-03-05 22:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:54:32 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.857 | nll_loss 13.496 | ppl 11551.8 | wps 46155.5 | wpb 510.9 | bsz 1 | num_updates 12951 | best_loss 8.499
2022-03-05 22:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12951 updates
2022-03-05 22:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 266 @ 12951 updates, score 13.857) (writing took 1.8986041024327278 seconds)
2022-03-05 22:54:34 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-05 22:54:34 | INFO | train | epoch 266 | loss 1.367 | nll_loss 0.352 | ppl 1.28 | wps 27485.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 12951 | lr 0.000277874 | gnorm 0.544 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 30750
2022-03-05 22:54:34 | INFO | fairseq.trainer | begin training epoch 267
2022-03-05 22:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:55:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:56:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:56:27 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.846 | nll_loss 13.48 | ppl 11426.6 | wps 45897.7 | wpb 510.9 | bsz 1 | num_updates 12999 | best_loss 8.499
2022-03-05 22:56:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12999 updates
2022-03-05 22:56:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:56:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:56:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 267 @ 12999 updates, score 13.846) (writing took 1.9292755322530866 seconds)
2022-03-05 22:56:29 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-05 22:56:29 | INFO | train | epoch 267 | loss 1.365 | nll_loss 0.349 | ppl 1.27 | wps 26921.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12999 | lr 0.000277361 | gnorm 0.53 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 30866
2022-03-05 22:56:29 | INFO | fairseq.trainer | begin training epoch 268
2022-03-05 22:56:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:56:32 | INFO | train_inner | epoch 268:      1 / 49 loss=1.366, nll_loss=0.35, ppl=1.27, wps=26480.2, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=13000, lr=0.00027735, gnorm=0.539, loss_scale=32, train_wall=200, gb_free=21.6, wall=30868
2022-03-05 22:58:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:58:23 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.839 | nll_loss 13.477 | ppl 11401.6 | wps 45721.1 | wpb 510.9 | bsz 1 | num_updates 13048 | best_loss 8.499
2022-03-05 22:58:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13048 updates
2022-03-05 22:58:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:58:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 22:58:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 268 @ 13048 updates, score 13.839) (writing took 1.9290647516027093 seconds)
2022-03-05 22:58:25 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-05 22:58:25 | INFO | train | epoch 268 | loss 1.364 | nll_loss 0.349 | ppl 1.27 | wps 27449 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13048 | lr 0.000276839 | gnorm 0.538 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 30982
2022-03-05 22:58:25 | INFO | fairseq.trainer | begin training epoch 269
2022-03-05 22:58:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:00:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:00:19 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.847 | nll_loss 13.489 | ppl 11496 | wps 46096.3 | wpb 510.9 | bsz 1 | num_updates 13097 | best_loss 8.499
2022-03-05 23:00:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13097 updates
2022-03-05 23:00:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:00:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:00:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 269 @ 13097 updates, score 13.847) (writing took 1.8812162159010768 seconds)
2022-03-05 23:00:21 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-05 23:00:21 | INFO | train | epoch 269 | loss 1.363 | nll_loss 0.348 | ppl 1.27 | wps 27489.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13097 | lr 0.000276321 | gnorm 0.542 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 31097
2022-03-05 23:00:21 | INFO | fairseq.trainer | begin training epoch 270
2022-03-05 23:00:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:00:28 | INFO | train_inner | epoch 270:      3 / 49 loss=1.363, nll_loss=0.348, ppl=1.27, wps=27498.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.539, loss_scale=64, train_wall=199, gb_free=21.6, wall=31104
2022-03-05 23:00:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:02:14 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.832 | nll_loss 13.474 | ppl 11381.5 | wps 46198.8 | wpb 510.9 | bsz 1 | num_updates 13145 | best_loss 8.499
2022-03-05 23:02:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13145 updates
2022-03-05 23:02:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:02:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:02:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 270 @ 13145 updates, score 13.832) (writing took 1.9193510077893734 seconds)
2022-03-05 23:02:16 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-05 23:02:16 | INFO | train | epoch 270 | loss 1.361 | nll_loss 0.347 | ppl 1.27 | wps 26916.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13145 | lr 0.000275816 | gnorm 0.532 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 31213
2022-03-05 23:02:16 | INFO | fairseq.trainer | begin training epoch 271
2022-03-05 23:02:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:04:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:04:10 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.854 | nll_loss 13.496 | ppl 11550.4 | wps 45583.9 | wpb 510.9 | bsz 1 | num_updates 13194 | best_loss 8.499
2022-03-05 23:04:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13194 updates
2022-03-05 23:04:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:04:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:04:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 271 @ 13194 updates, score 13.854) (writing took 1.9015197772532701 seconds)
2022-03-05 23:04:12 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-05 23:04:12 | INFO | train | epoch 271 | loss 1.359 | nll_loss 0.345 | ppl 1.27 | wps 27469.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13194 | lr 0.000275304 | gnorm 0.531 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 31329
2022-03-05 23:04:12 | INFO | fairseq.trainer | begin training epoch 272
2022-03-05 23:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:04:26 | INFO | train_inner | epoch 272:      6 / 49 loss=1.36, nll_loss=0.346, ppl=1.27, wps=27253.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.533, loss_scale=32, train_wall=201, gb_free=21.6, wall=31342
2022-03-05 23:05:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:06:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:06:06 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.968 | nll_loss 13.611 | ppl 12509.4 | wps 45840.4 | wpb 510.9 | bsz 1 | num_updates 13242 | best_loss 8.499
2022-03-05 23:06:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13242 updates
2022-03-05 23:06:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:06:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 272 @ 13242 updates, score 13.968) (writing took 1.875379215925932 seconds)
2022-03-05 23:06:08 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-05 23:06:08 | INFO | train | epoch 272 | loss 1.36 | nll_loss 0.346 | ppl 1.27 | wps 26922.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13242 | lr 0.000274804 | gnorm 0.543 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 31444
2022-03-05 23:06:08 | INFO | fairseq.trainer | begin training epoch 273
2022-03-05 23:06:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:08:01 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.875 | nll_loss 13.515 | ppl 11705.4 | wps 46052.9 | wpb 510.9 | bsz 1 | num_updates 13291 | best_loss 8.499
2022-03-05 23:08:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13291 updates
2022-03-05 23:08:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:08:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:08:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 273 @ 13291 updates, score 13.875) (writing took 1.9276696117594838 seconds)
2022-03-05 23:08:03 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-05 23:08:03 | INFO | train | epoch 273 | loss 1.357 | nll_loss 0.343 | ppl 1.27 | wps 27474.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13291 | lr 0.000274297 | gnorm 0.527 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 31560
2022-03-05 23:08:03 | INFO | fairseq.trainer | begin training epoch 274
2022-03-05 23:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:08:24 | INFO | train_inner | epoch 274:      9 / 49 loss=1.358, nll_loss=0.344, ppl=1.27, wps=27256.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.533, loss_scale=32, train_wall=201, gb_free=21.6, wall=31580
2022-03-05 23:09:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:09:57 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 14.032 | nll_loss 13.683 | ppl 13153.9 | wps 46174.9 | wpb 510.9 | bsz 1 | num_updates 13340 | best_loss 8.499
2022-03-05 23:09:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13340 updates
2022-03-05 23:09:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:09:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:09:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 274 @ 13340 updates, score 14.032) (writing took 1.8586321538314223 seconds)
2022-03-05 23:09:59 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-05 23:09:59 | INFO | train | epoch 274 | loss 1.356 | nll_loss 0.342 | ppl 1.27 | wps 27505.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 13340 | lr 0.000273793 | gnorm 0.53 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 31676
2022-03-05 23:09:59 | INFO | fairseq.trainer | begin training epoch 275
2022-03-05 23:09:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:10:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:11:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:11:53 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.759 | nll_loss 13.393 | ppl 10759.1 | wps 45731 | wpb 510.9 | bsz 1 | num_updates 13388 | best_loss 8.499
2022-03-05 23:11:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13388 updates
2022-03-05 23:11:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:11:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:11:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 275 @ 13388 updates, score 13.759) (writing took 1.9151729131117463 seconds)
2022-03-05 23:11:55 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-05 23:11:55 | INFO | train | epoch 275 | loss 1.354 | nll_loss 0.341 | ppl 1.27 | wps 26905.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 13388 | lr 0.000273302 | gnorm 0.538 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 31791
2022-03-05 23:11:55 | INFO | fairseq.trainer | begin training epoch 276
2022-03-05 23:11:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:12:21 | INFO | train_inner | epoch 276:     12 / 49 loss=1.355, nll_loss=0.342, ppl=1.27, wps=27270.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.534, loss_scale=32, train_wall=201, gb_free=21.6, wall=31818
2022-03-05 23:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:13:48 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.945 | nll_loss 13.59 | ppl 12327.7 | wps 46236.1 | wpb 510.9 | bsz 1 | num_updates 13437 | best_loss 8.499
2022-03-05 23:13:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13437 updates
2022-03-05 23:13:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:13:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:13:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 276 @ 13437 updates, score 13.945) (writing took 1.830117934383452 seconds)
2022-03-05 23:13:50 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-05 23:13:50 | INFO | train | epoch 276 | loss 1.353 | nll_loss 0.34 | ppl 1.27 | wps 27583.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13437 | lr 0.000272803 | gnorm 0.526 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31907
2022-03-05 23:13:50 | INFO | fairseq.trainer | begin training epoch 277
2022-03-05 23:13:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:15:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:15:43 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.752 | nll_loss 13.392 | ppl 10753.2 | wps 46644.9 | wpb 510.9 | bsz 1 | num_updates 13486 | best_loss 8.499
2022-03-05 23:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13486 updates
2022-03-05 23:15:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:15:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:15:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 277 @ 13486 updates, score 13.752) (writing took 1.8083083173260093 seconds)
2022-03-05 23:15:45 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-05 23:15:45 | INFO | train | epoch 277 | loss 1.353 | nll_loss 0.34 | ppl 1.27 | wps 27622.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13486 | lr 0.000272307 | gnorm 0.54 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32022
2022-03-05 23:15:45 | INFO | fairseq.trainer | begin training epoch 278
2022-03-05 23:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:16:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:16:18 | INFO | train_inner | epoch 278:     15 / 49 loss=1.352, nll_loss=0.339, ppl=1.27, wps=27370.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.533, loss_scale=32, train_wall=201, gb_free=21.6, wall=32055
2022-03-05 23:17:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:17:38 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.968 | nll_loss 13.614 | ppl 12539.1 | wps 46444.8 | wpb 510.9 | bsz 1 | num_updates 13534 | best_loss 8.499
2022-03-05 23:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13534 updates
2022-03-05 23:17:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:17:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:17:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 278 @ 13534 updates, score 13.968) (writing took 1.7606338141486049 seconds)
2022-03-05 23:17:40 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-05 23:17:40 | INFO | train | epoch 278 | loss 1.35 | nll_loss 0.338 | ppl 1.26 | wps 27018.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13534 | lr 0.000271823 | gnorm 0.533 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 32137
2022-03-05 23:17:40 | INFO | fairseq.trainer | begin training epoch 279
2022-03-05 23:17:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:19:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:19:33 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.872 | nll_loss 13.52 | ppl 11747.3 | wps 46360.2 | wpb 510.9 | bsz 1 | num_updates 13583 | best_loss 8.499
2022-03-05 23:19:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13583 updates
2022-03-05 23:19:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:19:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:19:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 279 @ 13583 updates, score 13.872) (writing took 1.8364053908735514 seconds)
2022-03-05 23:19:35 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-05 23:19:35 | INFO | train | epoch 279 | loss 1.349 | nll_loss 0.337 | ppl 1.26 | wps 27587.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13583 | lr 0.000271333 | gnorm 0.522 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 32252
2022-03-05 23:19:35 | INFO | fairseq.trainer | begin training epoch 280
2022-03-05 23:19:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:20:13 | INFO | train_inner | epoch 280:     17 / 49 loss=1.349, nll_loss=0.337, ppl=1.26, wps=27627.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.524, loss_scale=32, train_wall=199, gb_free=21.6, wall=32290
2022-03-05 23:21:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:21:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:21:28 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.83 | nll_loss 13.47 | ppl 11346.7 | wps 46582.9 | wpb 510.9 | bsz 1 | num_updates 13631 | best_loss 8.499
2022-03-05 23:21:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13631 updates
2022-03-05 23:21:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:21:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:21:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 280 @ 13631 updates, score 13.83) (writing took 1.7423750441521406 seconds)
2022-03-05 23:21:30 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-05 23:21:30 | INFO | train | epoch 280 | loss 1.346 | nll_loss 0.334 | ppl 1.26 | wps 27061.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13631 | lr 0.000270855 | gnorm 0.513 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32367
2022-03-05 23:21:30 | INFO | fairseq.trainer | begin training epoch 281
2022-03-05 23:21:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:23:23 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.858 | nll_loss 13.496 | ppl 11549.9 | wps 46739.4 | wpb 510.9 | bsz 1 | num_updates 13680 | best_loss 8.499
2022-03-05 23:23:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13680 updates
2022-03-05 23:23:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:23:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:23:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 281 @ 13680 updates, score 13.858) (writing took 1.8029217580333352 seconds)
2022-03-05 23:23:25 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-05 23:23:25 | INFO | train | epoch 281 | loss 1.347 | nll_loss 0.336 | ppl 1.26 | wps 27637.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13680 | lr 0.000270369 | gnorm 0.524 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32482
2022-03-05 23:23:25 | INFO | fairseq.trainer | begin training epoch 282
2022-03-05 23:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:24:10 | INFO | train_inner | epoch 282:     20 / 49 loss=1.347, nll_loss=0.335, ppl=1.26, wps=27409.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.521, loss_scale=32, train_wall=201, gb_free=21.6, wall=32527
2022-03-05 23:25:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:25:19 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.941 | nll_loss 13.588 | ppl 12311 | wps 46183.8 | wpb 510.9 | bsz 1 | num_updates 13729 | best_loss 8.499
2022-03-05 23:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13729 updates
2022-03-05 23:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:25:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 282 @ 13729 updates, score 13.941) (writing took 1.750012350268662 seconds)
2022-03-05 23:25:20 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-05 23:25:20 | INFO | train | epoch 282 | loss 1.346 | nll_loss 0.334 | ppl 1.26 | wps 27608.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13729 | lr 0.000269886 | gnorm 0.526 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 32597
2022-03-05 23:25:20 | INFO | fairseq.trainer | begin training epoch 283
2022-03-05 23:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:26:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:27:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:27:13 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.945 | nll_loss 13.594 | ppl 12361.8 | wps 46638.8 | wpb 510.9 | bsz 1 | num_updates 13777 | best_loss 8.499
2022-03-05 23:27:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13777 updates
2022-03-05 23:27:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:27:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:27:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 283 @ 13777 updates, score 13.945) (writing took 1.7810827745124698 seconds)
2022-03-05 23:27:15 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-05 23:27:15 | INFO | train | epoch 283 | loss 1.344 | nll_loss 0.333 | ppl 1.26 | wps 27081.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13777 | lr 0.000269416 | gnorm 0.527 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32712
2022-03-05 23:27:15 | INFO | fairseq.trainer | begin training epoch 284
2022-03-05 23:27:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:28:07 | INFO | train_inner | epoch 284:     23 / 49 loss=1.344, nll_loss=0.333, ppl=1.26, wps=27387.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.524, loss_scale=32, train_wall=201, gb_free=21.6, wall=32764
2022-03-05 23:29:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:29:09 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.839 | nll_loss 13.483 | ppl 11450.3 | wps 47227.3 | wpb 510.9 | bsz 1 | num_updates 13826 | best_loss 8.499
2022-03-05 23:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13826 updates
2022-03-05 23:29:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:29:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 284 @ 13826 updates, score 13.839) (writing took 1.7853590184822679 seconds)
2022-03-05 23:29:10 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-05 23:29:10 | INFO | train | epoch 284 | loss 1.342 | nll_loss 0.331 | ppl 1.26 | wps 27612.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13826 | lr 0.000268938 | gnorm 0.519 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32827
2022-03-05 23:29:10 | INFO | fairseq.trainer | begin training epoch 285
2022-03-05 23:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:31:04 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.807 | nll_loss 13.45 | ppl 11193.8 | wps 46392.8 | wpb 510.9 | bsz 1 | num_updates 13875 | best_loss 8.499
2022-03-05 23:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13875 updates
2022-03-05 23:31:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:31:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:31:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 285 @ 13875 updates, score 13.807) (writing took 1.7212521703913808 seconds)
2022-03-05 23:31:05 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-05 23:31:05 | INFO | train | epoch 285 | loss 1.341 | nll_loss 0.331 | ppl 1.26 | wps 27655.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13875 | lr 0.000268462 | gnorm 0.517 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32942
2022-03-05 23:31:05 | INFO | fairseq.trainer | begin training epoch 286
2022-03-05 23:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:31:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:32:03 | INFO | train_inner | epoch 286:     26 / 49 loss=1.342, nll_loss=0.331, ppl=1.26, wps=27411.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.522, loss_scale=32, train_wall=201, gb_free=21.6, wall=33000
2022-03-05 23:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:32:59 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.981 | nll_loss 13.632 | ppl 12697 | wps 47077.5 | wpb 510.9 | bsz 1 | num_updates 13923 | best_loss 8.499
2022-03-05 23:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13923 updates
2022-03-05 23:32:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:33:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:33:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 286 @ 13923 updates, score 13.981) (writing took 1.7166514433920383 seconds)
2022-03-05 23:33:00 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-05 23:33:00 | INFO | train | epoch 286 | loss 1.34 | nll_loss 0.33 | ppl 1.26 | wps 27062 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13923 | lr 0.000267999 | gnorm 0.519 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33057
2022-03-05 23:33:00 | INFO | fairseq.trainer | begin training epoch 287
2022-03-05 23:33:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:33:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 23:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:34:53 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.825 | nll_loss 13.47 | ppl 11350.3 | wps 46730.4 | wpb 510.9 | bsz 1 | num_updates 13971 | best_loss 8.499
2022-03-05 23:34:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13971 updates
2022-03-05 23:34:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 287 @ 13971 updates, score 13.825) (writing took 1.7338438648730516 seconds)
2022-03-05 23:34:55 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-05 23:34:55 | INFO | train | epoch 287 | loss 1.339 | nll_loss 0.329 | ppl 1.26 | wps 27081.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13971 | lr 0.000267538 | gnorm 0.523 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 33172
2022-03-05 23:34:55 | INFO | fairseq.trainer | begin training epoch 288
2022-03-05 23:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:36:00 | INFO | train_inner | epoch 288:     29 / 49 loss=1.338, nll_loss=0.328, ppl=1.26, wps=27419.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.516, loss_scale=16, train_wall=201, gb_free=21.6, wall=33237
2022-03-05 23:36:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:36:48 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.962 | nll_loss 13.608 | ppl 12487.9 | wps 46596.7 | wpb 510.9 | bsz 1 | num_updates 14020 | best_loss 8.499
2022-03-05 23:36:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14020 updates
2022-03-05 23:36:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:36:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:36:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 288 @ 14020 updates, score 13.962) (writing took 1.71719887573272 seconds)
2022-03-05 23:36:50 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-05 23:36:50 | INFO | train | epoch 288 | loss 1.337 | nll_loss 0.327 | ppl 1.25 | wps 27657.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14020 | lr 0.000267071 | gnorm 0.517 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 33287
2022-03-05 23:36:50 | INFO | fairseq.trainer | begin training epoch 289
2022-03-05 23:36:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:38:43 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.972 | nll_loss 13.618 | ppl 12571 | wps 45824 | wpb 510.9 | bsz 1 | num_updates 14069 | best_loss 8.499
2022-03-05 23:38:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14069 updates
2022-03-05 23:38:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:38:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:38:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 289 @ 14069 updates, score 13.972) (writing took 1.712108769454062 seconds)
2022-03-05 23:38:45 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-05 23:38:45 | INFO | train | epoch 289 | loss 1.338 | nll_loss 0.328 | ppl 1.26 | wps 27629.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14069 | lr 0.000266605 | gnorm 0.528 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 33402
2022-03-05 23:38:45 | INFO | fairseq.trainer | begin training epoch 290
2022-03-05 23:38:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:39:54 | INFO | train_inner | epoch 290:     31 / 49 loss=1.337, nll_loss=0.327, ppl=1.25, wps=27674.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.52, loss_scale=32, train_wall=199, gb_free=21.6, wall=33471
2022-03-05 23:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:40:38 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.889 | nll_loss 13.538 | ppl 11890.5 | wps 46392.2 | wpb 510.9 | bsz 1 | num_updates 14118 | best_loss 8.499
2022-03-05 23:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14118 updates
2022-03-05 23:40:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 290 @ 14118 updates, score 13.889) (writing took 1.715172461234033 seconds)
2022-03-05 23:40:40 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-05 23:40:40 | INFO | train | epoch 290 | loss 1.334 | nll_loss 0.324 | ppl 1.25 | wps 27642.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14118 | lr 0.000266142 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33517
2022-03-05 23:40:40 | INFO | fairseq.trainer | begin training epoch 291
2022-03-05 23:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:42:33 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.84 | nll_loss 13.487 | ppl 11479.8 | wps 46572 | wpb 510.9 | bsz 1 | num_updates 14167 | best_loss 8.499
2022-03-05 23:42:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14167 updates
2022-03-05 23:42:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:42:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:42:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 291 @ 14167 updates, score 13.84) (writing took 1.735820927657187 seconds)
2022-03-05 23:42:35 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-05 23:42:35 | INFO | train | epoch 291 | loss 1.334 | nll_loss 0.325 | ppl 1.25 | wps 27627.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14167 | lr 0.000265681 | gnorm 0.513 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 33632
2022-03-05 23:42:35 | INFO | fairseq.trainer | begin training epoch 292
2022-03-05 23:42:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:43:49 | INFO | train_inner | epoch 292:     33 / 49 loss=1.333, nll_loss=0.324, ppl=1.25, wps=27662.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.508, loss_scale=32, train_wall=199, gb_free=21.6, wall=33706
2022-03-05 23:43:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:44:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:44:28 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.848 | nll_loss 13.494 | ppl 11535.3 | wps 46262.2 | wpb 510.9 | bsz 1 | num_updates 14215 | best_loss 8.499
2022-03-05 23:44:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14215 updates
2022-03-05 23:44:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:44:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 292 @ 14215 updates, score 13.848) (writing took 1.6847864175215364 seconds)
2022-03-05 23:44:30 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-05 23:44:30 | INFO | train | epoch 292 | loss 1.332 | nll_loss 0.323 | ppl 1.25 | wps 27063.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14215 | lr 0.000265232 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33747
2022-03-05 23:44:30 | INFO | fairseq.trainer | begin training epoch 293
2022-03-05 23:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:46:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:46:23 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 13.778 | nll_loss 13.425 | ppl 10996.3 | wps 46540.6 | wpb 510.9 | bsz 1 | num_updates 14264 | best_loss 8.499
2022-03-05 23:46:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14264 updates
2022-03-05 23:46:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:46:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:46:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 293 @ 14264 updates, score 13.778) (writing took 1.7115280935540795 seconds)
2022-03-05 23:46:25 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-05 23:46:25 | INFO | train | epoch 293 | loss 1.333 | nll_loss 0.324 | ppl 1.25 | wps 27657.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14264 | lr 0.000264776 | gnorm 0.517 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33862
2022-03-05 23:46:25 | INFO | fairseq.trainer | begin training epoch 294
2022-03-05 23:46:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:47:46 | INFO | train_inner | epoch 294:     36 / 49 loss=1.332, nll_loss=0.323, ppl=1.25, wps=27408.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.511, loss_scale=32, train_wall=201, gb_free=21.6, wall=33942
2022-03-05 23:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:48:18 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.888 | nll_loss 13.536 | ppl 11876 | wps 46410.7 | wpb 510.9 | bsz 1 | num_updates 14313 | best_loss 8.499
2022-03-05 23:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14313 updates
2022-03-05 23:48:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:48:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:48:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 294 @ 14313 updates, score 13.888) (writing took 1.7001457260921597 seconds)
2022-03-05 23:48:20 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-05 23:48:20 | INFO | train | epoch 294 | loss 1.331 | nll_loss 0.322 | ppl 1.25 | wps 27615.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14313 | lr 0.000264323 | gnorm 0.508 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 33977
2022-03-05 23:48:20 | INFO | fairseq.trainer | begin training epoch 295
2022-03-05 23:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:49:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:50:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:50:13 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.795 | nll_loss 13.436 | ppl 11079.6 | wps 46046.1 | wpb 510.9 | bsz 1 | num_updates 14361 | best_loss 8.499
2022-03-05 23:50:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14361 updates
2022-03-05 23:50:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:50:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:50:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 295 @ 14361 updates, score 13.795) (writing took 1.7095346879214048 seconds)
2022-03-05 23:50:15 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-05 23:50:15 | INFO | train | epoch 295 | loss 1.329 | nll_loss 0.321 | ppl 1.25 | wps 27042.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14361 | lr 0.000263881 | gnorm 0.512 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 34092
2022-03-05 23:50:15 | INFO | fairseq.trainer | begin training epoch 296
2022-03-05 23:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:51:42 | INFO | train_inner | epoch 296:     39 / 49 loss=1.33, nll_loss=0.321, ppl=1.25, wps=27397.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.508, loss_scale=32, train_wall=201, gb_free=21.6, wall=34179
2022-03-05 23:52:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:52:08 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 13.888 | nll_loss 13.538 | ppl 11896.1 | wps 46600.6 | wpb 510.9 | bsz 1 | num_updates 14410 | best_loss 8.499
2022-03-05 23:52:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14410 updates
2022-03-05 23:52:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:52:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:52:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 296 @ 14410 updates, score 13.888) (writing took 1.7142983470112085 seconds)
2022-03-05 23:52:10 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-05 23:52:10 | INFO | train | epoch 296 | loss 1.329 | nll_loss 0.321 | ppl 1.25 | wps 27653.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14410 | lr 0.000263432 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34207
2022-03-05 23:52:10 | INFO | fairseq.trainer | begin training epoch 297
2022-03-05 23:52:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:53:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:54:03 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 13.952 | nll_loss 13.604 | ppl 12453.2 | wps 46339.1 | wpb 510.9 | bsz 1 | num_updates 14459 | best_loss 8.499
2022-03-05 23:54:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14459 updates
2022-03-05 23:54:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:54:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:54:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 297 @ 14459 updates, score 13.952) (writing took 1.737084018997848 seconds)
2022-03-05 23:54:05 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-05 23:54:05 | INFO | train | epoch 297 | loss 1.327 | nll_loss 0.319 | ppl 1.25 | wps 27615.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14459 | lr 0.000262985 | gnorm 0.502 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 34322
2022-03-05 23:54:05 | INFO | fairseq.trainer | begin training epoch 298
2022-03-05 23:54:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:54:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:55:39 | INFO | train_inner | epoch 298:     42 / 49 loss=1.328, nll_loss=0.32, ppl=1.25, wps=27395.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.506, loss_scale=32, train_wall=201, gb_free=21.6, wall=34416
2022-03-05 23:55:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:55:58 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.83 | nll_loss 13.472 | ppl 11364.3 | wps 46699.3 | wpb 510.9 | bsz 1 | num_updates 14507 | best_loss 8.499
2022-03-05 23:55:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14507 updates
2022-03-05 23:55:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:56:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:56:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 298 @ 14507 updates, score 13.83) (writing took 1.7101623713970184 seconds)
2022-03-05 23:56:00 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-05 23:56:00 | INFO | train | epoch 298 | loss 1.327 | nll_loss 0.319 | ppl 1.25 | wps 27067.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14507 | lr 0.000262549 | gnorm 0.506 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34437
2022-03-05 23:56:00 | INFO | fairseq.trainer | begin training epoch 299
2022-03-05 23:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:57:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:57:54 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.945 | nll_loss 13.595 | ppl 12371.9 | wps 46091.6 | wpb 510.9 | bsz 1 | num_updates 14556 | best_loss 8.499
2022-03-05 23:57:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14556 updates
2022-03-05 23:57:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:57:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:57:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 299 @ 14556 updates, score 13.945) (writing took 1.7029998768121004 seconds)
2022-03-05 23:57:55 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-05 23:57:55 | INFO | train | epoch 299 | loss 1.325 | nll_loss 0.318 | ppl 1.25 | wps 27618.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14556 | lr 0.000262107 | gnorm 0.498 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34552
2022-03-05 23:57:55 | INFO | fairseq.trainer | begin training epoch 300
2022-03-05 23:57:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:59:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:59:36 | INFO | train_inner | epoch 300:     45 / 49 loss=1.325, nll_loss=0.317, ppl=1.25, wps=27389.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.5, loss_scale=32, train_wall=201, gb_free=21.6, wall=34653
2022-03-05 23:59:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:59:49 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 13.86 | nll_loss 13.506 | ppl 11633.6 | wps 46203.4 | wpb 510.9 | bsz 1 | num_updates 14604 | best_loss 8.499
2022-03-05 23:59:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14604 updates
2022-03-05 23:59:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:59:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-05 23:59:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 300 @ 14604 updates, score 13.86) (writing took 1.7117004804313183 seconds)
2022-03-05 23:59:50 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-05 23:59:50 | INFO | train | epoch 300 | loss 1.324 | nll_loss 0.316 | ppl 1.25 | wps 27034.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14604 | lr 0.000261676 | gnorm 0.503 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 34667
2022-03-05 23:59:50 | INFO | fairseq.trainer | begin training epoch 301
2022-03-05 23:59:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:01:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:01:44 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.855 | nll_loss 13.51 | ppl 11662 | wps 45954.7 | wpb 510.9 | bsz 1 | num_updates 14653 | best_loss 8.499
2022-03-06 00:01:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14653 updates
2022-03-06 00:01:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:01:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:01:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 301 @ 14653 updates, score 13.855) (writing took 1.6944983480498195 seconds)
2022-03-06 00:01:45 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-06 00:01:45 | INFO | train | epoch 301 | loss 1.325 | nll_loss 0.318 | ppl 1.25 | wps 27631.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14653 | lr 0.000261238 | gnorm 0.514 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34782
2022-03-06 00:01:45 | INFO | fairseq.trainer | begin training epoch 302
2022-03-06 00:01:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:03:30 | INFO | train_inner | epoch 302:     47 / 49 loss=1.324, nll_loss=0.316, ppl=1.25, wps=27682.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14700, lr=0.00026082, gnorm=0.508, loss_scale=32, train_wall=199, gb_free=21.6, wall=34887
2022-03-06 00:03:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:03:39 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.907 | nll_loss 13.56 | ppl 12079.1 | wps 46087.1 | wpb 510.9 | bsz 1 | num_updates 14702 | best_loss 8.499
2022-03-06 00:03:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14702 updates
2022-03-06 00:03:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:03:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:03:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 302 @ 14702 updates, score 13.907) (writing took 1.7524215914309025 seconds)
2022-03-06 00:03:40 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-06 00:03:40 | INFO | train | epoch 302 | loss 1.322 | nll_loss 0.315 | ppl 1.24 | wps 27660.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14702 | lr 0.000260803 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34897
2022-03-06 00:03:40 | INFO | fairseq.trainer | begin training epoch 303
2022-03-06 00:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:04:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:05:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:05:33 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.849 | nll_loss 13.496 | ppl 11554.4 | wps 47067.8 | wpb 510.9 | bsz 1 | num_updates 14750 | best_loss 8.499
2022-03-06 00:05:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14750 updates
2022-03-06 00:05:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:05:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:05:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 303 @ 14750 updates, score 13.849) (writing took 1.7568219806998968 seconds)
2022-03-06 00:05:35 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-06 00:05:35 | INFO | train | epoch 303 | loss 1.32 | nll_loss 0.313 | ppl 1.24 | wps 27098.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14750 | lr 0.000260378 | gnorm 0.492 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35012
2022-03-06 00:05:35 | INFO | fairseq.trainer | begin training epoch 304
2022-03-06 00:05:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:07:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:07:28 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 13.766 | nll_loss 13.408 | ppl 10868.1 | wps 46563.5 | wpb 510.9 | bsz 1 | num_updates 14799 | best_loss 8.499
2022-03-06 00:07:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14799 updates
2022-03-06 00:07:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:07:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:07:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 304 @ 14799 updates, score 13.766) (writing took 1.7182095693424344 seconds)
2022-03-06 00:07:30 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-06 00:07:30 | INFO | train | epoch 304 | loss 1.32 | nll_loss 0.313 | ppl 1.24 | wps 27637.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14799 | lr 0.000259946 | gnorm 0.498 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35127
2022-03-06 00:07:30 | INFO | fairseq.trainer | begin training epoch 305
2022-03-06 00:07:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:07:33 | INFO | train_inner | epoch 305:      1 / 49 loss=1.32, nll_loss=0.313, ppl=1.24, wps=26660.4, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=14800, lr=0.000259938, gnorm=0.496, loss_scale=32, train_wall=200, gb_free=21.6, wall=35129
2022-03-06 00:09:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:09:23 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.858 | nll_loss 13.512 | ppl 11682.9 | wps 46442.8 | wpb 510.9 | bsz 1 | num_updates 14848 | best_loss 8.499
2022-03-06 00:09:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14848 updates
2022-03-06 00:09:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:09:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:09:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 305 @ 14848 updates, score 13.858) (writing took 1.6937258392572403 seconds)
2022-03-06 00:09:25 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-06 00:09:25 | INFO | train | epoch 305 | loss 1.32 | nll_loss 0.313 | ppl 1.24 | wps 27634.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14848 | lr 0.000259517 | gnorm 0.501 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 35242
2022-03-06 00:09:25 | INFO | fairseq.trainer | begin training epoch 306
2022-03-06 00:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:09:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:11:18 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 13.839 | nll_loss 13.486 | ppl 11475.6 | wps 46189.7 | wpb 510.9 | bsz 1 | num_updates 14896 | best_loss 8.499
2022-03-06 00:11:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14896 updates
2022-03-06 00:11:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:11:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 306 @ 14896 updates, score 13.839) (writing took 1.6863712733611465 seconds)
2022-03-06 00:11:20 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-06 00:11:20 | INFO | train | epoch 306 | loss 1.318 | nll_loss 0.311 | ppl 1.24 | wps 27079 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14896 | lr 0.000259099 | gnorm 0.492 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35357
2022-03-06 00:11:20 | INFO | fairseq.trainer | begin training epoch 307
2022-03-06 00:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:11:29 | INFO | train_inner | epoch 307:      4 / 49 loss=1.318, nll_loss=0.312, ppl=1.24, wps=27414, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.496, loss_scale=32, train_wall=201, gb_free=21.6, wall=35366
2022-03-06 00:13:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:13:13 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 13.806 | nll_loss 13.457 | ppl 11244.2 | wps 46400.3 | wpb 510.9 | bsz 1 | num_updates 14945 | best_loss 8.499
2022-03-06 00:13:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14945 updates
2022-03-06 00:13:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:13:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:13:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 307 @ 14945 updates, score 13.806) (writing took 1.8106132177636027 seconds)
2022-03-06 00:13:15 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-06 00:13:15 | INFO | train | epoch 307 | loss 1.317 | nll_loss 0.311 | ppl 1.24 | wps 27609.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14945 | lr 0.000258674 | gnorm 0.494 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35472
2022-03-06 00:13:15 | INFO | fairseq.trainer | begin training epoch 308
2022-03-06 00:13:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:13:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 00:15:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:15:09 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 13.817 | nll_loss 13.469 | ppl 11338 | wps 46284.3 | wpb 510.9 | bsz 1 | num_updates 14993 | best_loss 8.499
2022-03-06 00:15:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14993 updates
2022-03-06 00:15:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:15:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:15:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 308 @ 14993 updates, score 13.817) (writing took 1.743721037171781 seconds)
2022-03-06 00:15:11 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-06 00:15:11 | INFO | train | epoch 308 | loss 1.316 | nll_loss 0.31 | ppl 1.24 | wps 26909.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 14993 | lr 0.000258259 | gnorm 0.498 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 35588
2022-03-06 00:15:11 | INFO | fairseq.trainer | begin training epoch 309
2022-03-06 00:15:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:15:27 | INFO | train_inner | epoch 309:      7 / 49 loss=1.316, nll_loss=0.31, ppl=1.24, wps=27303.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.496, loss_scale=16, train_wall=202, gb_free=21.6, wall=35604
2022-03-06 00:17:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:17:05 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 13.871 | nll_loss 13.516 | ppl 11713.8 | wps 45805.3 | wpb 510.9 | bsz 1 | num_updates 15042 | best_loss 8.499
2022-03-06 00:17:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15042 updates
2022-03-06 00:17:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:17:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:17:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 309 @ 15042 updates, score 13.871) (writing took 1.7325923265889287 seconds)
2022-03-06 00:17:07 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-06 00:17:07 | INFO | train | epoch 309 | loss 1.316 | nll_loss 0.31 | ppl 1.24 | wps 27483.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15042 | lr 0.000257838 | gnorm 0.498 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 35703
2022-03-06 00:17:07 | INFO | fairseq.trainer | begin training epoch 310
2022-03-06 00:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:18:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:19:01 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.878 | nll_loss 13.531 | ppl 11836.1 | wps 46394 | wpb 510.9 | bsz 1 | num_updates 15091 | best_loss 8.499
2022-03-06 00:19:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15091 updates
2022-03-06 00:19:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:19:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 310 @ 15091 updates, score 13.878) (writing took 1.7649705642834306 seconds)
2022-03-06 00:19:02 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-06 00:19:02 | INFO | train | epoch 310 | loss 1.314 | nll_loss 0.308 | ppl 1.24 | wps 27437.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15091 | lr 0.000257419 | gnorm 0.494 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 35819
2022-03-06 00:19:02 | INFO | fairseq.trainer | begin training epoch 311
2022-03-06 00:19:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:19:23 | INFO | train_inner | epoch 311:      9 / 49 loss=1.314, nll_loss=0.309, ppl=1.24, wps=27494.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.496, loss_scale=32, train_wall=200, gb_free=21.6, wall=35839
2022-03-06 00:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:20:56 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.904 | nll_loss 13.558 | ppl 12062.7 | wps 45923.2 | wpb 510.9 | bsz 1 | num_updates 15140 | best_loss 8.499
2022-03-06 00:20:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15140 updates
2022-03-06 00:20:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:20:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:20:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 311 @ 15140 updates, score 13.904) (writing took 1.766318304464221 seconds)
2022-03-06 00:20:58 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-06 00:20:58 | INFO | train | epoch 311 | loss 1.312 | nll_loss 0.307 | ppl 1.24 | wps 27440.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15140 | lr 0.000257002 | gnorm 0.491 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 35935
2022-03-06 00:20:58 | INFO | fairseq.trainer | begin training epoch 312
2022-03-06 00:20:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:22:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:22:52 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 13.914 | nll_loss 13.569 | ppl 12151.4 | wps 45917.4 | wpb 510.9 | bsz 1 | num_updates 15189 | best_loss 8.499
2022-03-06 00:22:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15189 updates
2022-03-06 00:22:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:22:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:22:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 312 @ 15189 updates, score 13.914) (writing took 1.7148909624665976 seconds)
2022-03-06 00:22:54 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-06 00:22:54 | INFO | train | epoch 312 | loss 1.313 | nll_loss 0.308 | ppl 1.24 | wps 27493.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15189 | lr 0.000256587 | gnorm 0.502 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 36051
2022-03-06 00:22:54 | INFO | fairseq.trainer | begin training epoch 313
2022-03-06 00:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:23:19 | INFO | train_inner | epoch 313:     11 / 49 loss=1.313, nll_loss=0.307, ppl=1.24, wps=27505.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.498, loss_scale=32, train_wall=200, gb_free=21.6, wall=36075
2022-03-06 00:23:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:24:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:24:48 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 13.925 | nll_loss 13.579 | ppl 12239.1 | wps 46435.7 | wpb 510.9 | bsz 1 | num_updates 15237 | best_loss 8.499
2022-03-06 00:24:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15237 updates
2022-03-06 00:24:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:24:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:24:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 313 @ 15237 updates, score 13.925) (writing took 1.7562816152349114 seconds)
2022-03-06 00:24:49 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-06 00:24:49 | INFO | train | epoch 313 | loss 1.311 | nll_loss 0.307 | ppl 1.24 | wps 26897.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 15237 | lr 0.000256183 | gnorm 0.499 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 36166
2022-03-06 00:24:49 | INFO | fairseq.trainer | begin training epoch 314
2022-03-06 00:24:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:26:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:26:43 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.905 | nll_loss 13.555 | ppl 12035.1 | wps 46443.5 | wpb 510.9 | bsz 1 | num_updates 15286 | best_loss 8.499
2022-03-06 00:26:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15286 updates
2022-03-06 00:26:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:26:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:26:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 314 @ 15286 updates, score 13.905) (writing took 1.7075391383841634 seconds)
2022-03-06 00:26:45 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-06 00:26:45 | INFO | train | epoch 314 | loss 1.31 | nll_loss 0.305 | ppl 1.24 | wps 27497.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15286 | lr 0.000255772 | gnorm 0.484 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 36282
2022-03-06 00:26:45 | INFO | fairseq.trainer | begin training epoch 315
2022-03-06 00:26:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:27:17 | INFO | train_inner | epoch 315:     14 / 49 loss=1.31, nll_loss=0.305, ppl=1.24, wps=27250.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.489, loss_scale=32, train_wall=202, gb_free=21.6, wall=36313
2022-03-06 00:28:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:28:39 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 13.845 | nll_loss 13.493 | ppl 11530.6 | wps 45860.4 | wpb 510.9 | bsz 1 | num_updates 15335 | best_loss 8.499
2022-03-06 00:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15335 updates
2022-03-06 00:28:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:28:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:28:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 315 @ 15335 updates, score 13.845) (writing took 1.7145983511582017 seconds)
2022-03-06 00:28:41 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-06 00:28:41 | INFO | train | epoch 315 | loss 1.309 | nll_loss 0.305 | ppl 1.24 | wps 27479.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15335 | lr 0.000255363 | gnorm 0.488 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 36398
2022-03-06 00:28:41 | INFO | fairseq.trainer | begin training epoch 316
2022-03-06 00:28:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:28:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:30:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:30:35 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 13.85 | nll_loss 13.5 | ppl 11585.8 | wps 45856.8 | wpb 510.9 | bsz 1 | num_updates 15383 | best_loss 8.499
2022-03-06 00:30:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15383 updates
2022-03-06 00:30:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:30:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:30:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 316 @ 15383 updates, score 13.85) (writing took 1.7819914473220706 seconds)
2022-03-06 00:30:37 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-06 00:30:37 | INFO | train | epoch 316 | loss 1.307 | nll_loss 0.303 | ppl 1.23 | wps 26867.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 15383 | lr 0.000254964 | gnorm 0.485 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 36513
2022-03-06 00:30:37 | INFO | fairseq.trainer | begin training epoch 317
2022-03-06 00:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:31:15 | INFO | train_inner | epoch 317:     17 / 49 loss=1.308, nll_loss=0.304, ppl=1.23, wps=27219.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.488, loss_scale=32, train_wall=202, gb_free=21.6, wall=36552
2022-03-06 00:32:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:32:31 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 13.929 | nll_loss 13.586 | ppl 12300.7 | wps 45587.8 | wpb 510.9 | bsz 1 | num_updates 15432 | best_loss 8.499
2022-03-06 00:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15432 updates
2022-03-06 00:32:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:32:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:32:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 317 @ 15432 updates, score 13.929) (writing took 1.728746635839343 seconds)
2022-03-06 00:32:32 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-06 00:32:32 | INFO | train | epoch 317 | loss 1.308 | nll_loss 0.304 | ppl 1.23 | wps 27460.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15432 | lr 0.000254559 | gnorm 0.497 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 36629
2022-03-06 00:32:32 | INFO | fairseq.trainer | begin training epoch 318
2022-03-06 00:32:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:33:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:34:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:34:26 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 13.818 | nll_loss 13.467 | ppl 11324.6 | wps 46064.1 | wpb 510.9 | bsz 1 | num_updates 15480 | best_loss 8.499
2022-03-06 00:34:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15480 updates
2022-03-06 00:34:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:34:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:34:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 318 @ 15480 updates, score 13.818) (writing took 1.6987353302538395 seconds)
2022-03-06 00:34:28 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-06 00:34:28 | INFO | train | epoch 318 | loss 1.306 | nll_loss 0.302 | ppl 1.23 | wps 26951 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15480 | lr 0.000254164 | gnorm 0.484 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 36745
2022-03-06 00:34:28 | INFO | fairseq.trainer | begin training epoch 319
2022-03-06 00:34:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:35:13 | INFO | train_inner | epoch 319:     20 / 49 loss=1.306, nll_loss=0.302, ppl=1.23, wps=27272.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.49, loss_scale=32, train_wall=202, gb_free=21.6, wall=36790
2022-03-06 00:36:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:36:22 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 13.945 | nll_loss 13.601 | ppl 12425.3 | wps 46253.4 | wpb 510.9 | bsz 1 | num_updates 15529 | best_loss 8.499
2022-03-06 00:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15529 updates
2022-03-06 00:36:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:36:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:36:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 319 @ 15529 updates, score 13.945) (writing took 1.78276461455971 seconds)
2022-03-06 00:36:24 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-06 00:36:24 | INFO | train | epoch 319 | loss 1.305 | nll_loss 0.302 | ppl 1.23 | wps 27456.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15529 | lr 0.000253763 | gnorm 0.487 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 36860
2022-03-06 00:36:24 | INFO | fairseq.trainer | begin training epoch 320
2022-03-06 00:36:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:38:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:38:17 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 13.965 | nll_loss 13.623 | ppl 12616.1 | wps 46576.8 | wpb 510.9 | bsz 1 | num_updates 15578 | best_loss 8.499
2022-03-06 00:38:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15578 updates
2022-03-06 00:38:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:38:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:38:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 320 @ 15578 updates, score 13.965) (writing took 1.6974053252488375 seconds)
2022-03-06 00:38:19 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-06 00:38:19 | INFO | train | epoch 320 | loss 1.305 | nll_loss 0.302 | ppl 1.23 | wps 27535.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15578 | lr 0.000253364 | gnorm 0.49 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 36976
2022-03-06 00:38:19 | INFO | fairseq.trainer | begin training epoch 321
2022-03-06 00:38:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:38:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:39:11 | INFO | train_inner | epoch 321:     23 / 49 loss=1.305, nll_loss=0.301, ppl=1.23, wps=27261.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.485, loss_scale=32, train_wall=202, gb_free=21.6, wall=37028
2022-03-06 00:40:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:40:13 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 13.923 | nll_loss 13.58 | ppl 12242.4 | wps 45979.2 | wpb 510.9 | bsz 1 | num_updates 15626 | best_loss 8.499
2022-03-06 00:40:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15626 updates
2022-03-06 00:40:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:40:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:40:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 321 @ 15626 updates, score 13.923) (writing took 1.71780801191926 seconds)
2022-03-06 00:40:14 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-06 00:40:14 | INFO | train | epoch 321 | loss 1.303 | nll_loss 0.3 | ppl 1.23 | wps 26944.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15626 | lr 0.000252974 | gnorm 0.481 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 37091
2022-03-06 00:40:14 | INFO | fairseq.trainer | begin training epoch 322
2022-03-06 00:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:42:08 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 13.849 | nll_loss 13.503 | ppl 11608.6 | wps 46273.8 | wpb 510.9 | bsz 1 | num_updates 15675 | best_loss 8.499
2022-03-06 00:42:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15675 updates
2022-03-06 00:42:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 322 @ 15675 updates, score 13.849) (writing took 1.6581570515409112 seconds)
2022-03-06 00:42:10 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-06 00:42:10 | INFO | train | epoch 322 | loss 1.302 | nll_loss 0.299 | ppl 1.23 | wps 27566.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15675 | lr 0.000252578 | gnorm 0.483 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 37207
2022-03-06 00:42:10 | INFO | fairseq.trainer | begin training epoch 323
2022-03-06 00:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:43:06 | INFO | train_inner | epoch 323:     25 / 49 loss=1.302, nll_loss=0.299, ppl=1.23, wps=27582.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.483, loss_scale=32, train_wall=200, gb_free=21.6, wall=37263
2022-03-06 00:43:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:44:03 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 13.866 | nll_loss 13.52 | ppl 11750.5 | wps 46042.6 | wpb 510.9 | bsz 1 | num_updates 15724 | best_loss 8.499
2022-03-06 00:44:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15724 updates
2022-03-06 00:44:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:44:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 323 @ 15724 updates, score 13.866) (writing took 1.7964038588106632 seconds)
2022-03-06 00:44:05 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-06 00:44:05 | INFO | train | epoch 323 | loss 1.302 | nll_loss 0.3 | ppl 1.23 | wps 27504.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15724 | lr 0.000252185 | gnorm 0.484 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 37322
2022-03-06 00:44:05 | INFO | fairseq.trainer | begin training epoch 324
2022-03-06 00:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:44:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:45:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:45:59 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.881 | nll_loss 13.535 | ppl 11873.3 | wps 45997.4 | wpb 510.9 | bsz 1 | num_updates 15772 | best_loss 8.499
2022-03-06 00:45:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15772 updates
2022-03-06 00:45:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:46:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:46:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 324 @ 15772 updates, score 13.881) (writing took 1.7190667176619172 seconds)
2022-03-06 00:46:01 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-06 00:46:01 | INFO | train | epoch 324 | loss 1.3 | nll_loss 0.298 | ppl 1.23 | wps 26943.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15772 | lr 0.000251801 | gnorm 0.479 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 37438
2022-03-06 00:46:01 | INFO | fairseq.trainer | begin training epoch 325
2022-03-06 00:46:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:47:04 | INFO | train_inner | epoch 325:     28 / 49 loss=1.301, nll_loss=0.298, ppl=1.23, wps=27268.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.48, loss_scale=32, train_wall=202, gb_free=21.6, wall=37501
2022-03-06 00:47:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:47:55 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.941 | nll_loss 13.598 | ppl 12399.3 | wps 46306.8 | wpb 510.9 | bsz 1 | num_updates 15821 | best_loss 8.499
2022-03-06 00:47:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15821 updates
2022-03-06 00:47:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:47:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:47:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 325 @ 15821 updates, score 13.941) (writing took 1.7525920616462827 seconds)
2022-03-06 00:47:56 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-06 00:47:56 | INFO | train | epoch 325 | loss 1.301 | nll_loss 0.299 | ppl 1.23 | wps 27507.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15821 | lr 0.00025141 | gnorm 0.487 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 37553
2022-03-06 00:47:56 | INFO | fairseq.trainer | begin training epoch 326
2022-03-06 00:47:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:49:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:49:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:49:50 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.852 | nll_loss 13.506 | ppl 11634.4 | wps 46794.2 | wpb 510.9 | bsz 1 | num_updates 15869 | best_loss 8.499
2022-03-06 00:49:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15869 updates
2022-03-06 00:49:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:49:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:49:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 326 @ 15869 updates, score 13.852) (writing took 1.7099067689850926 seconds)
2022-03-06 00:49:52 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-06 00:49:52 | INFO | train | epoch 326 | loss 1.299 | nll_loss 0.296 | ppl 1.23 | wps 26967.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15869 | lr 0.00025103 | gnorm 0.477 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 37669
2022-03-06 00:49:52 | INFO | fairseq.trainer | begin training epoch 327
2022-03-06 00:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:51:01 | INFO | train_inner | epoch 327:     31 / 49 loss=1.299, nll_loss=0.297, ppl=1.23, wps=27312.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.482, loss_scale=32, train_wall=202, gb_free=21.6, wall=37738
2022-03-06 00:51:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:51:45 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 13.836 | nll_loss 13.488 | ppl 11492.2 | wps 46116.7 | wpb 510.9 | bsz 1 | num_updates 15918 | best_loss 8.499
2022-03-06 00:51:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15918 updates
2022-03-06 00:51:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:51:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:51:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 327 @ 15918 updates, score 13.836) (writing took 2.191905309446156 seconds)
2022-03-06 00:51:48 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-06 00:51:48 | INFO | train | epoch 327 | loss 1.298 | nll_loss 0.296 | ppl 1.23 | wps 27428.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15918 | lr 0.000250643 | gnorm 0.48 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 37784
2022-03-06 00:51:48 | INFO | fairseq.trainer | begin training epoch 328
2022-03-06 00:51:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:53:41 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 13.892 | nll_loss 13.549 | ppl 11989 | wps 45941.3 | wpb 510.9 | bsz 1 | num_updates 15967 | best_loss 8.499
2022-03-06 00:53:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15967 updates
2022-03-06 00:53:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:53:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:53:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 328 @ 15967 updates, score 13.892) (writing took 1.6728680152446032 seconds)
2022-03-06 00:53:43 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-06 00:53:43 | INFO | train | epoch 328 | loss 1.297 | nll_loss 0.295 | ppl 1.23 | wps 27517.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 15967 | lr 0.000250258 | gnorm 0.479 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 37900
2022-03-06 00:53:43 | INFO | fairseq.trainer | begin training epoch 329
2022-03-06 00:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:54:57 | INFO | train_inner | epoch 329:     33 / 49 loss=1.297, nll_loss=0.295, ppl=1.23, wps=27472.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.477, loss_scale=64, train_wall=200, gb_free=21.6, wall=37974
2022-03-06 00:55:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:55:37 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 13.918 | nll_loss 13.572 | ppl 12180 | wps 46519 | wpb 510.9 | bsz 1 | num_updates 16015 | best_loss 8.499
2022-03-06 00:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16015 updates
2022-03-06 00:55:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:55:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 329 @ 16015 updates, score 13.918) (writing took 1.818964894860983 seconds)
2022-03-06 00:55:39 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-06 00:55:39 | INFO | train | epoch 329 | loss 1.296 | nll_loss 0.295 | ppl 1.23 | wps 26879.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16015 | lr 0.000249883 | gnorm 0.476 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 38016
2022-03-06 00:55:39 | INFO | fairseq.trainer | begin training epoch 330
2022-03-06 00:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:57:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:57:33 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.865 | nll_loss 13.521 | ppl 11756.7 | wps 45847.9 | wpb 510.9 | bsz 1 | num_updates 16064 | best_loss 8.499
2022-03-06 00:57:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16064 updates
2022-03-06 00:57:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:57:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:57:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 330 @ 16064 updates, score 13.865) (writing took 1.6943569257855415 seconds)
2022-03-06 00:57:35 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-06 00:57:35 | INFO | train | epoch 330 | loss 1.296 | nll_loss 0.294 | ppl 1.23 | wps 27464.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16064 | lr 0.000249501 | gnorm 0.476 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 38131
2022-03-06 00:57:35 | INFO | fairseq.trainer | begin training epoch 331
2022-03-06 00:57:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:58:56 | INFO | train_inner | epoch 331:     36 / 49 loss=1.296, nll_loss=0.294, ppl=1.23, wps=27245.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.476, loss_scale=32, train_wall=202, gb_free=21.6, wall=38212
2022-03-06 00:59:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:59:28 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 13.84 | nll_loss 13.495 | ppl 11542.1 | wps 46168.2 | wpb 510.9 | bsz 1 | num_updates 16113 | best_loss 8.499
2022-03-06 00:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16113 updates
2022-03-06 00:59:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:59:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 00:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 331 @ 16113 updates, score 13.84) (writing took 1.7308510905131698 seconds)
2022-03-06 00:59:30 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-06 00:59:30 | INFO | train | epoch 331 | loss 1.294 | nll_loss 0.293 | ppl 1.23 | wps 27508.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16113 | lr 0.000249122 | gnorm 0.476 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 38247
2022-03-06 00:59:30 | INFO | fairseq.trainer | begin training epoch 332
2022-03-06 00:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:00:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:01:24 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 13.941 | nll_loss 13.596 | ppl 12378.2 | wps 46289.4 | wpb 510.9 | bsz 1 | num_updates 16161 | best_loss 8.499
2022-03-06 01:01:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16161 updates
2022-03-06 01:01:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 332 @ 16161 updates, score 13.941) (writing took 1.7377901310101151 seconds)
2022-03-06 01:01:26 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-06 01:01:26 | INFO | train | epoch 332 | loss 1.295 | nll_loss 0.294 | ppl 1.23 | wps 26904.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16161 | lr 0.000248752 | gnorm 0.481 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 38363
2022-03-06 01:01:26 | INFO | fairseq.trainer | begin training epoch 333
2022-03-06 01:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:02:54 | INFO | train_inner | epoch 333:     39 / 49 loss=1.294, nll_loss=0.293, ppl=1.22, wps=27248, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.475, loss_scale=32, train_wall=202, gb_free=21.6, wall=38450
2022-03-06 01:03:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:03:20 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 13.904 | nll_loss 13.564 | ppl 12112.1 | wps 45978.4 | wpb 510.9 | bsz 1 | num_updates 16210 | best_loss 8.499
2022-03-06 01:03:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16210 updates
2022-03-06 01:03:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:03:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:03:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 333 @ 16210 updates, score 13.904) (writing took 1.7773711485788226 seconds)
2022-03-06 01:03:22 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-06 01:03:22 | INFO | train | epoch 333 | loss 1.293 | nll_loss 0.292 | ppl 1.22 | wps 27457.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16210 | lr 0.000248375 | gnorm 0.47 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 38478
2022-03-06 01:03:22 | INFO | fairseq.trainer | begin training epoch 334
2022-03-06 01:03:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:05:16 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 13.795 | nll_loss 13.446 | ppl 11157.3 | wps 46016.1 | wpb 510.9 | bsz 1 | num_updates 16259 | best_loss 8.499
2022-03-06 01:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16259 updates
2022-03-06 01:05:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:05:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 334 @ 16259 updates, score 13.795) (writing took 1.7219753796234727 seconds)
2022-03-06 01:05:17 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-06 01:05:17 | INFO | train | epoch 334 | loss 1.293 | nll_loss 0.292 | ppl 1.22 | wps 27460.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16259 | lr 0.000248001 | gnorm 0.475 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 38594
2022-03-06 01:05:17 | INFO | fairseq.trainer | begin training epoch 335
2022-03-06 01:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:05:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:06:52 | INFO | train_inner | epoch 335:     42 / 49 loss=1.293, nll_loss=0.292, ppl=1.22, wps=27226.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.475, loss_scale=32, train_wall=202, gb_free=21.6, wall=38689
2022-03-06 01:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:07:11 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 13.749 | nll_loss 13.398 | ppl 10792.5 | wps 46130.9 | wpb 510.9 | bsz 1 | num_updates 16307 | best_loss 8.499
2022-03-06 01:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16307 updates
2022-03-06 01:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:07:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:07:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 335 @ 16307 updates, score 13.749) (writing took 1.7646038196980953 seconds)
2022-03-06 01:07:13 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-06 01:07:13 | INFO | train | epoch 335 | loss 1.291 | nll_loss 0.29 | ppl 1.22 | wps 26881.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16307 | lr 0.000247636 | gnorm 0.471 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 38710
2022-03-06 01:07:13 | INFO | fairseq.trainer | begin training epoch 336
2022-03-06 01:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:09:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:09:07 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 14.004 | nll_loss 13.664 | ppl 12981.1 | wps 45709.9 | wpb 510.9 | bsz 1 | num_updates 16356 | best_loss 8.499
2022-03-06 01:09:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16356 updates
2022-03-06 01:09:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:09:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 336 @ 16356 updates, score 14.004) (writing took 1.8100987328216434 seconds)
2022-03-06 01:09:09 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-06 01:09:09 | INFO | train | epoch 336 | loss 1.29 | nll_loss 0.289 | ppl 1.22 | wps 27456.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16356 | lr 0.000247264 | gnorm 0.472 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 38826
2022-03-06 01:09:09 | INFO | fairseq.trainer | begin training epoch 337
2022-03-06 01:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:10:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:10:50 | INFO | train_inner | epoch 337:     45 / 49 loss=1.29, nll_loss=0.289, ppl=1.22, wps=27241.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.472, loss_scale=32, train_wall=202, gb_free=21.6, wall=38927
2022-03-06 01:10:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:11:03 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 13.8 | nll_loss 13.451 | ppl 11198.4 | wps 46329 | wpb 510.9 | bsz 1 | num_updates 16404 | best_loss 8.499
2022-03-06 01:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16404 updates
2022-03-06 01:11:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:11:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:11:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 337 @ 16404 updates, score 13.8) (writing took 1.8114599753171206 seconds)
2022-03-06 01:11:05 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-06 01:11:05 | INFO | train | epoch 337 | loss 1.289 | nll_loss 0.289 | ppl 1.22 | wps 26904.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16404 | lr 0.000246902 | gnorm 0.471 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 38941
2022-03-06 01:11:05 | INFO | fairseq.trainer | begin training epoch 338
2022-03-06 01:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:12:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:12:59 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 13.79 | nll_loss 13.443 | ppl 11138.3 | wps 45852.6 | wpb 510.9 | bsz 1 | num_updates 16453 | best_loss 8.499
2022-03-06 01:12:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16453 updates
2022-03-06 01:12:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:13:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:13:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 338 @ 16453 updates, score 13.79) (writing took 1.704283930361271 seconds)
2022-03-06 01:13:00 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-06 01:13:00 | INFO | train | epoch 338 | loss 1.289 | nll_loss 0.289 | ppl 1.22 | wps 27471 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16453 | lr 0.000246534 | gnorm 0.471 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 39057
2022-03-06 01:13:00 | INFO | fairseq.trainer | begin training epoch 339
2022-03-06 01:13:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:14:46 | INFO | train_inner | epoch 339:     47 / 49 loss=1.29, nll_loss=0.289, ppl=1.22, wps=27497.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16500, lr=0.000246183, gnorm=0.473, loss_scale=32, train_wall=200, gb_free=21.6, wall=39163
2022-03-06 01:14:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:14:54 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 13.845 | nll_loss 13.503 | ppl 11611.5 | wps 46315.8 | wpb 510.9 | bsz 1 | num_updates 16502 | best_loss 8.499
2022-03-06 01:14:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16502 updates
2022-03-06 01:14:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:14:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:14:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 339 @ 16502 updates, score 13.845) (writing took 1.796657227911055 seconds)
2022-03-06 01:14:56 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-06 01:14:56 | INFO | train | epoch 339 | loss 1.289 | nll_loss 0.289 | ppl 1.22 | wps 27465.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16502 | lr 0.000246168 | gnorm 0.474 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 39173
2022-03-06 01:14:56 | INFO | fairseq.trainer | begin training epoch 340
2022-03-06 01:14:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:15:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:16:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:16:50 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 13.876 | nll_loss 13.533 | ppl 11852.8 | wps 45775.2 | wpb 510.9 | bsz 1 | num_updates 16550 | best_loss 8.499
2022-03-06 01:16:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16550 updates
2022-03-06 01:16:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:16:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:16:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 340 @ 16550 updates, score 13.876) (writing took 1.7395505802705884 seconds)
2022-03-06 01:16:52 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-06 01:16:52 | INFO | train | epoch 340 | loss 1.287 | nll_loss 0.287 | ppl 1.22 | wps 26934 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16550 | lr 0.000245811 | gnorm 0.477 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 39288
2022-03-06 01:16:52 | INFO | fairseq.trainer | begin training epoch 341
2022-03-06 01:16:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:18:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:18:45 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 13.903 | nll_loss 13.561 | ppl 12082 | wps 46212.5 | wpb 510.9 | bsz 1 | num_updates 16599 | best_loss 8.499
2022-03-06 01:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16599 updates
2022-03-06 01:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:18:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:18:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 341 @ 16599 updates, score 13.903) (writing took 1.806389612145722 seconds)
2022-03-06 01:18:47 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-06 01:18:47 | INFO | train | epoch 341 | loss 1.286 | nll_loss 0.287 | ppl 1.22 | wps 27447.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16599 | lr 0.000245448 | gnorm 0.472 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 39404
2022-03-06 01:18:47 | INFO | fairseq.trainer | begin training epoch 342
2022-03-06 01:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:18:50 | INFO | train_inner | epoch 342:      1 / 49 loss=1.287, nll_loss=0.287, ppl=1.22, wps=26489.1, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=16600, lr=0.00024544, gnorm=0.475, loss_scale=32, train_wall=201, gb_free=21.6, wall=39406
2022-03-06 01:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:20:41 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 13.829 | nll_loss 13.484 | ppl 11459.5 | wps 46619.1 | wpb 510.9 | bsz 1 | num_updates 16648 | best_loss 8.499
2022-03-06 01:20:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16648 updates
2022-03-06 01:20:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:20:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:20:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 342 @ 16648 updates, score 13.829) (writing took 1.74426488019526 seconds)
2022-03-06 01:20:43 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-06 01:20:43 | INFO | train | epoch 342 | loss 1.285 | nll_loss 0.286 | ppl 1.22 | wps 27460 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16648 | lr 0.000245086 | gnorm 0.463 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 39520
2022-03-06 01:20:43 | INFO | fairseq.trainer | begin training epoch 343
2022-03-06 01:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:20:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:22:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:22:37 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 13.913 | nll_loss 13.57 | ppl 12159.1 | wps 46197.8 | wpb 510.9 | bsz 1 | num_updates 16696 | best_loss 8.499
2022-03-06 01:22:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16696 updates
2022-03-06 01:22:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:22:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:22:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 343 @ 16696 updates, score 13.913) (writing took 1.7728672754019499 seconds)
2022-03-06 01:22:39 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-06 01:22:39 | INFO | train | epoch 343 | loss 1.284 | nll_loss 0.285 | ppl 1.22 | wps 26875.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16696 | lr 0.000244734 | gnorm 0.466 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 39636
2022-03-06 01:22:39 | INFO | fairseq.trainer | begin training epoch 344
2022-03-06 01:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:22:48 | INFO | train_inner | epoch 344:      4 / 49 loss=1.284, nll_loss=0.285, ppl=1.22, wps=27226, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.464, loss_scale=32, train_wall=202, gb_free=21.6, wall=39645
2022-03-06 01:24:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:24:33 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.904 | nll_loss 13.561 | ppl 12082.9 | wps 45617 | wpb 510.9 | bsz 1 | num_updates 16745 | best_loss 8.499
2022-03-06 01:24:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16745 updates
2022-03-06 01:24:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:24:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:24:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 344 @ 16745 updates, score 13.904) (writing took 1.8328720005229115 seconds)
2022-03-06 01:24:35 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-06 01:24:35 | INFO | train | epoch 344 | loss 1.284 | nll_loss 0.285 | ppl 1.22 | wps 27420 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16745 | lr 0.000244375 | gnorm 0.466 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 39752
2022-03-06 01:24:35 | INFO | fairseq.trainer | begin training epoch 345
2022-03-06 01:24:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:26:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:26:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:26:29 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 13.799 | nll_loss 13.453 | ppl 11212.7 | wps 45929.2 | wpb 510.9 | bsz 1 | num_updates 16793 | best_loss 8.499
2022-03-06 01:26:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16793 updates
2022-03-06 01:26:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:26:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:26:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 345 @ 16793 updates, score 13.799) (writing took 1.7921272553503513 seconds)
2022-03-06 01:26:30 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-06 01:26:30 | INFO | train | epoch 345 | loss 1.283 | nll_loss 0.284 | ppl 1.22 | wps 26895.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 16793 | lr 0.000244026 | gnorm 0.466 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 39867
2022-03-06 01:26:30 | INFO | fairseq.trainer | begin training epoch 346
2022-03-06 01:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:26:46 | INFO | train_inner | epoch 346:      7 / 49 loss=1.283, nll_loss=0.284, ppl=1.22, wps=27210.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.466, loss_scale=32, train_wall=202, gb_free=21.6, wall=39883
2022-03-06 01:28:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:28:24 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 13.899 | nll_loss 13.555 | ppl 12035.6 | wps 45930.6 | wpb 510.9 | bsz 1 | num_updates 16842 | best_loss 8.499
2022-03-06 01:28:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16842 updates
2022-03-06 01:28:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:28:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:28:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 346 @ 16842 updates, score 13.899) (writing took 1.7555046249181032 seconds)
2022-03-06 01:28:26 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-06 01:28:26 | INFO | train | epoch 346 | loss 1.282 | nll_loss 0.284 | ppl 1.22 | wps 27468.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16842 | lr 0.000243671 | gnorm 0.465 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 39983
2022-03-06 01:28:26 | INFO | fairseq.trainer | begin training epoch 347
2022-03-06 01:28:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:30:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:30:20 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 13.858 | nll_loss 13.513 | ppl 11687.3 | wps 45676 | wpb 510.9 | bsz 1 | num_updates 16891 | best_loss 8.499
2022-03-06 01:30:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16891 updates
2022-03-06 01:30:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:30:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:30:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 347 @ 16891 updates, score 13.858) (writing took 1.7544198604300618 seconds)
2022-03-06 01:30:22 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-06 01:30:22 | INFO | train | epoch 347 | loss 1.281 | nll_loss 0.283 | ppl 1.22 | wps 27447.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16891 | lr 0.000243317 | gnorm 0.46 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 40099
2022-03-06 01:30:22 | INFO | fairseq.trainer | begin training epoch 348
2022-03-06 01:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:30:42 | INFO | train_inner | epoch 348:      9 / 49 loss=1.282, nll_loss=0.283, ppl=1.22, wps=27497.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.463, loss_scale=32, train_wall=200, gb_free=21.6, wall=40119
2022-03-06 01:31:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:32:16 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 13.883 | nll_loss 13.543 | ppl 11937.7 | wps 46204.5 | wpb 510.9 | bsz 1 | num_updates 16939 | best_loss 8.499
2022-03-06 01:32:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16939 updates
2022-03-06 01:32:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 348 @ 16939 updates, score 13.883) (writing took 1.6724347360432148 seconds)
2022-03-06 01:32:18 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-06 01:32:18 | INFO | train | epoch 348 | loss 1.281 | nll_loss 0.283 | ppl 1.22 | wps 26933.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16939 | lr 0.000242972 | gnorm 0.463 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 40214
2022-03-06 01:32:18 | INFO | fairseq.trainer | begin training epoch 349
2022-03-06 01:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:34:11 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 13.807 | nll_loss 13.462 | ppl 11284.1 | wps 45900.2 | wpb 510.9 | bsz 1 | num_updates 16988 | best_loss 8.499
2022-03-06 01:34:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16988 updates
2022-03-06 01:34:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:34:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:34:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 349 @ 16988 updates, score 13.807) (writing took 1.7411007955670357 seconds)
2022-03-06 01:34:13 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-06 01:34:13 | INFO | train | epoch 349 | loss 1.281 | nll_loss 0.283 | ppl 1.22 | wps 27467 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 16988 | lr 0.000242621 | gnorm 0.465 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 40330
2022-03-06 01:34:13 | INFO | fairseq.trainer | begin training epoch 350
2022-03-06 01:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:34:40 | INFO | train_inner | epoch 350:     12 / 49 loss=1.281, nll_loss=0.283, ppl=1.22, wps=27243.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.463, loss_scale=32, train_wall=202, gb_free=21.6, wall=40357
2022-03-06 01:36:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:36:07 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.899 | nll_loss 13.56 | ppl 12080.9 | wps 45797.2 | wpb 510.9 | bsz 1 | num_updates 17037 | best_loss 8.499
2022-03-06 01:36:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17037 updates
2022-03-06 01:36:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:36:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:36:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 350 @ 17037 updates, score 13.899) (writing took 1.7216087654232979 seconds)
2022-03-06 01:36:09 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-06 01:36:09 | INFO | train | epoch 350 | loss 1.28 | nll_loss 0.282 | ppl 1.22 | wps 27446.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17037 | lr 0.000242272 | gnorm 0.463 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 40446
2022-03-06 01:36:09 | INFO | fairseq.trainer | begin training epoch 351
2022-03-06 01:36:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:36:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:38:03 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 13.819 | nll_loss 13.476 | ppl 11392.6 | wps 46188.7 | wpb 510.9 | bsz 1 | num_updates 17085 | best_loss 8.499
2022-03-06 01:38:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17085 updates
2022-03-06 01:38:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:38:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:38:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 351 @ 17085 updates, score 13.819) (writing took 1.8249900937080383 seconds)
2022-03-06 01:38:05 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-06 01:38:05 | INFO | train | epoch 351 | loss 1.278 | nll_loss 0.28 | ppl 1.21 | wps 26896.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17085 | lr 0.000241932 | gnorm 0.463 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 40562
2022-03-06 01:38:05 | INFO | fairseq.trainer | begin training epoch 352
2022-03-06 01:38:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:38:39 | INFO | train_inner | epoch 352:     15 / 49 loss=1.279, nll_loss=0.281, ppl=1.21, wps=27237.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.463, loss_scale=32, train_wall=202, gb_free=21.6, wall=40595
2022-03-06 01:39:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:39:59 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 13.865 | nll_loss 13.523 | ppl 11773 | wps 45803.8 | wpb 510.9 | bsz 1 | num_updates 17134 | best_loss 8.499
2022-03-06 01:39:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17134 updates
2022-03-06 01:39:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:40:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:40:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 352 @ 17134 updates, score 13.865) (writing took 1.6761553613469005 seconds)
2022-03-06 01:40:00 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-06 01:40:00 | INFO | train | epoch 352 | loss 1.278 | nll_loss 0.28 | ppl 1.21 | wps 27475.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17134 | lr 0.000241585 | gnorm 0.456 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 40677
2022-03-06 01:40:00 | INFO | fairseq.trainer | begin training epoch 353
2022-03-06 01:40:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:41:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:41:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:41:54 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 13.686 | nll_loss 13.336 | ppl 10342.5 | wps 46164.5 | wpb 510.9 | bsz 1 | num_updates 17182 | best_loss 8.499
2022-03-06 01:41:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17182 updates
2022-03-06 01:41:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:41:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:41:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 353 @ 17182 updates, score 13.686) (writing took 1.7799522429704666 seconds)
2022-03-06 01:41:56 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-06 01:41:56 | INFO | train | epoch 353 | loss 1.278 | nll_loss 0.28 | ppl 1.21 | wps 26895.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17182 | lr 0.000241248 | gnorm 0.461 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 40793
2022-03-06 01:41:56 | INFO | fairseq.trainer | begin training epoch 354
2022-03-06 01:41:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:42:37 | INFO | train_inner | epoch 354:     18 / 49 loss=1.277, nll_loss=0.28, ppl=1.21, wps=27234.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.462, loss_scale=32, train_wall=202, gb_free=21.6, wall=40834
2022-03-06 01:43:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:43:50 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 13.857 | nll_loss 13.514 | ppl 11697.3 | wps 45924.6 | wpb 510.9 | bsz 1 | num_updates 17231 | best_loss 8.499
2022-03-06 01:43:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17231 updates
2022-03-06 01:43:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:43:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 354 @ 17231 updates, score 13.857) (writing took 1.763170757330954 seconds)
2022-03-06 01:43:52 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-06 01:43:52 | INFO | train | epoch 354 | loss 1.277 | nll_loss 0.28 | ppl 1.21 | wps 27465.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17231 | lr 0.000240904 | gnorm 0.47 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 40909
2022-03-06 01:43:52 | INFO | fairseq.trainer | begin training epoch 355
2022-03-06 01:43:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:45:46 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 13.904 | nll_loss 13.562 | ppl 12095.3 | wps 46138.2 | wpb 510.9 | bsz 1 | num_updates 17280 | best_loss 8.499
2022-03-06 01:45:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17280 updates
2022-03-06 01:45:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:45:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:45:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 355 @ 17280 updates, score 13.904) (writing took 1.796888972632587 seconds)
2022-03-06 01:45:48 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-06 01:45:48 | INFO | train | epoch 355 | loss 1.276 | nll_loss 0.279 | ppl 1.21 | wps 27460.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17280 | lr 0.000240563 | gnorm 0.461 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 41024
2022-03-06 01:45:48 | INFO | fairseq.trainer | begin training epoch 356
2022-03-06 01:45:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:46:33 | INFO | train_inner | epoch 356:     20 / 49 loss=1.276, nll_loss=0.279, ppl=1.21, wps=27505.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.46, loss_scale=32, train_wall=200, gb_free=21.6, wall=41069
2022-03-06 01:47:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:47:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:47:41 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 13.819 | nll_loss 13.478 | ppl 11411.6 | wps 46360.9 | wpb 510.9 | bsz 1 | num_updates 17328 | best_loss 8.499
2022-03-06 01:47:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17328 updates
2022-03-06 01:47:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:47:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:47:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 356 @ 17328 updates, score 13.819) (writing took 1.7345551177859306 seconds)
2022-03-06 01:47:43 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-06 01:47:43 | INFO | train | epoch 356 | loss 1.274 | nll_loss 0.277 | ppl 1.21 | wps 26931.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17328 | lr 0.000240229 | gnorm 0.454 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 41140
2022-03-06 01:47:43 | INFO | fairseq.trainer | begin training epoch 357
2022-03-06 01:47:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:49:37 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.791 | nll_loss 13.448 | ppl 11175 | wps 45945.1 | wpb 510.9 | bsz 1 | num_updates 17377 | best_loss 8.499
2022-03-06 01:49:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17377 updates
2022-03-06 01:49:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:49:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:49:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 357 @ 17377 updates, score 13.791) (writing took 1.8011515298858285 seconds)
2022-03-06 01:49:39 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-06 01:49:39 | INFO | train | epoch 357 | loss 1.275 | nll_loss 0.278 | ppl 1.21 | wps 27449.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17377 | lr 0.00023989 | gnorm 0.464 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 41256
2022-03-06 01:49:39 | INFO | fairseq.trainer | begin training epoch 358
2022-03-06 01:49:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:50:31 | INFO | train_inner | epoch 358:     23 / 49 loss=1.274, nll_loss=0.277, ppl=1.21, wps=27239.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.46, loss_scale=32, train_wall=202, gb_free=21.6, wall=41308
2022-03-06 01:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:51:33 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.917 | nll_loss 13.581 | ppl 12251.6 | wps 46250.6 | wpb 510.9 | bsz 1 | num_updates 17426 | best_loss 8.499
2022-03-06 01:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17426 updates
2022-03-06 01:51:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 358 @ 17426 updates, score 13.917) (writing took 1.7527771918103099 seconds)
2022-03-06 01:51:35 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-06 01:51:35 | INFO | train | epoch 358 | loss 1.274 | nll_loss 0.277 | ppl 1.21 | wps 27484.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17426 | lr 0.000239553 | gnorm 0.462 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 41371
2022-03-06 01:51:35 | INFO | fairseq.trainer | begin training epoch 359
2022-03-06 01:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:52:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:53:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:53:28 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.856 | nll_loss 13.514 | ppl 11697.1 | wps 45955.2 | wpb 510.9 | bsz 1 | num_updates 17474 | best_loss 8.499
2022-03-06 01:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17474 updates
2022-03-06 01:53:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:53:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 359 @ 17474 updates, score 13.856) (writing took 1.8245213525369763 seconds)
2022-03-06 01:53:30 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-06 01:53:30 | INFO | train | epoch 359 | loss 1.273 | nll_loss 0.277 | ppl 1.21 | wps 26914.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17474 | lr 0.000239223 | gnorm 0.465 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 41487
2022-03-06 01:53:30 | INFO | fairseq.trainer | begin training epoch 360
2022-03-06 01:53:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:54:29 | INFO | train_inner | epoch 360:     26 / 49 loss=1.273, nll_loss=0.277, ppl=1.21, wps=27252.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.461, loss_scale=32, train_wall=202, gb_free=21.6, wall=41546
2022-03-06 01:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:55:24 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.81 | nll_loss 13.467 | ppl 11321.6 | wps 45945.7 | wpb 510.9 | bsz 1 | num_updates 17523 | best_loss 8.499
2022-03-06 01:55:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17523 updates
2022-03-06 01:55:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:55:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:55:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 360 @ 17523 updates, score 13.81) (writing took 1.7575762709602714 seconds)
2022-03-06 01:55:26 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-06 01:55:26 | INFO | train | epoch 360 | loss 1.273 | nll_loss 0.277 | ppl 1.21 | wps 27463 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17523 | lr 0.000238889 | gnorm 0.455 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 41603
2022-03-06 01:55:26 | INFO | fairseq.trainer | begin training epoch 361
2022-03-06 01:55:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:57:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:57:20 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.873 | nll_loss 13.537 | ppl 11887 | wps 46342.2 | wpb 510.9 | bsz 1 | num_updates 17572 | best_loss 8.499
2022-03-06 01:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17572 updates
2022-03-06 01:57:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:57:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 361 @ 17572 updates, score 13.873) (writing took 1.8034702157601714 seconds)
2022-03-06 01:57:22 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-06 01:57:22 | INFO | train | epoch 361 | loss 1.272 | nll_loss 0.275 | ppl 1.21 | wps 27464.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17572 | lr 0.000238555 | gnorm 0.453 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 41718
2022-03-06 01:57:22 | INFO | fairseq.trainer | begin training epoch 362
2022-03-06 01:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:57:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:58:27 | INFO | train_inner | epoch 362:     29 / 49 loss=1.272, nll_loss=0.275, ppl=1.21, wps=27244.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.458, loss_scale=32, train_wall=202, gb_free=21.6, wall=41784
2022-03-06 01:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:59:16 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 13.883 | nll_loss 13.543 | ppl 11933.7 | wps 45773.1 | wpb 510.9 | bsz 1 | num_updates 17620 | best_loss 8.499
2022-03-06 01:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17620 updates
2022-03-06 01:59:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:59:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 01:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 362 @ 17620 updates, score 13.883) (writing took 1.80342161282897 seconds)
2022-03-06 01:59:17 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-06 01:59:17 | INFO | train | epoch 362 | loss 1.27 | nll_loss 0.274 | ppl 1.21 | wps 26877.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17620 | lr 0.00023823 | gnorm 0.462 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 41834
2022-03-06 01:59:17 | INFO | fairseq.trainer | begin training epoch 363
2022-03-06 01:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:01:11 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.823 | nll_loss 13.478 | ppl 11407.3 | wps 45612.5 | wpb 510.9 | bsz 1 | num_updates 17669 | best_loss 8.499
2022-03-06 02:01:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17669 updates
2022-03-06 02:01:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:01:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:01:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 363 @ 17669 updates, score 13.823) (writing took 1.8627402279525995 seconds)
2022-03-06 02:01:13 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-06 02:01:13 | INFO | train | epoch 363 | loss 1.27 | nll_loss 0.274 | ppl 1.21 | wps 27446.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17669 | lr 0.0002379 | gnorm 0.452 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 41950
2022-03-06 02:01:13 | INFO | fairseq.trainer | begin training epoch 364
2022-03-06 02:01:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:02:23 | INFO | train_inner | epoch 364:     31 / 49 loss=1.27, nll_loss=0.274, ppl=1.21, wps=27458.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.454, loss_scale=32, train_wall=200, gb_free=21.6, wall=42020
2022-03-06 02:02:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:03:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:03:07 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 13.855 | nll_loss 13.513 | ppl 11692.3 | wps 46306.1 | wpb 510.9 | bsz 1 | num_updates 17717 | best_loss 8.499
2022-03-06 02:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17717 updates
2022-03-06 02:03:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:03:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:03:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 364 @ 17717 updates, score 13.855) (writing took 1.7906761970371008 seconds)
2022-03-06 02:03:09 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-06 02:03:09 | INFO | train | epoch 364 | loss 1.269 | nll_loss 0.274 | ppl 1.21 | wps 26871 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17717 | lr 0.000237577 | gnorm 0.454 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 42066
2022-03-06 02:03:09 | INFO | fairseq.trainer | begin training epoch 365
2022-03-06 02:03:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:04:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:05:03 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.768 | nll_loss 13.424 | ppl 10988.6 | wps 45843.8 | wpb 510.9 | bsz 1 | num_updates 17766 | best_loss 8.499
2022-03-06 02:05:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17766 updates
2022-03-06 02:05:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:05:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:05:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 365 @ 17766 updates, score 13.768) (writing took 1.9935978697612882 seconds)
2022-03-06 02:05:05 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-06 02:05:05 | INFO | train | epoch 365 | loss 1.27 | nll_loss 0.274 | ppl 1.21 | wps 27391 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17766 | lr 0.000237249 | gnorm 0.458 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 42182
2022-03-06 02:05:05 | INFO | fairseq.trainer | begin training epoch 366
2022-03-06 02:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:06:21 | INFO | train_inner | epoch 366:     34 / 49 loss=1.269, nll_loss=0.274, ppl=1.21, wps=27216, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.455, loss_scale=32, train_wall=202, gb_free=21.6, wall=42258
2022-03-06 02:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:06:59 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.714 | nll_loss 13.368 | ppl 10572.7 | wps 46430.7 | wpb 510.9 | bsz 1 | num_updates 17815 | best_loss 8.499
2022-03-06 02:06:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17815 updates
2022-03-06 02:06:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:07:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 366 @ 17815 updates, score 13.714) (writing took 1.755066618323326 seconds)
2022-03-06 02:07:01 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-06 02:07:01 | INFO | train | epoch 366 | loss 1.268 | nll_loss 0.273 | ppl 1.21 | wps 27527.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17815 | lr 0.000236923 | gnorm 0.45 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 42297
2022-03-06 02:07:01 | INFO | fairseq.trainer | begin training epoch 367
2022-03-06 02:07:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:08:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:08:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:08:54 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 13.832 | nll_loss 13.491 | ppl 11514.3 | wps 45562.2 | wpb 510.9 | bsz 1 | num_updates 17863 | best_loss 8.499
2022-03-06 02:08:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17863 updates
2022-03-06 02:08:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:08:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:08:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 367 @ 17863 updates, score 13.832) (writing took 1.9750433377921581 seconds)
2022-03-06 02:08:56 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-06 02:08:56 | INFO | train | epoch 367 | loss 1.267 | nll_loss 0.272 | ppl 1.21 | wps 26852.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 17863 | lr 0.000236604 | gnorm 0.449 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 42413
2022-03-06 02:08:56 | INFO | fairseq.trainer | begin training epoch 368
2022-03-06 02:08:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:10:20 | INFO | train_inner | epoch 368:     37 / 49 loss=1.268, nll_loss=0.272, ppl=1.21, wps=27229.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.455, loss_scale=32, train_wall=202, gb_free=21.6, wall=42497
2022-03-06 02:10:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:10:50 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.776 | nll_loss 13.432 | ppl 11049.1 | wps 45829.8 | wpb 510.9 | bsz 1 | num_updates 17912 | best_loss 8.499
2022-03-06 02:10:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17912 updates
2022-03-06 02:10:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:10:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:10:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 368 @ 17912 updates, score 13.776) (writing took 1.8216225551441312 seconds)
2022-03-06 02:10:52 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-06 02:10:52 | INFO | train | epoch 368 | loss 1.267 | nll_loss 0.272 | ppl 1.21 | wps 27453.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17912 | lr 0.000236281 | gnorm 0.462 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 42529
2022-03-06 02:10:52 | INFO | fairseq.trainer | begin training epoch 369
2022-03-06 02:10:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:12:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:12:46 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 13.924 | nll_loss 13.588 | ppl 12315.1 | wps 45978.2 | wpb 510.9 | bsz 1 | num_updates 17961 | best_loss 8.499
2022-03-06 02:12:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17961 updates
2022-03-06 02:12:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:12:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:12:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 369 @ 17961 updates, score 13.924) (writing took 1.9526306446641684 seconds)
2022-03-06 02:12:48 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-06 02:12:48 | INFO | train | epoch 369 | loss 1.267 | nll_loss 0.272 | ppl 1.21 | wps 27428.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 17961 | lr 0.000235958 | gnorm 0.461 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 42645
2022-03-06 02:12:48 | INFO | fairseq.trainer | begin training epoch 370
2022-03-06 02:12:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:14:16 | INFO | train_inner | epoch 370:     39 / 49 loss=1.267, nll_loss=0.272, ppl=1.21, wps=27471, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.456, loss_scale=64, train_wall=200, gb_free=21.6, wall=42733
2022-03-06 02:14:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:14:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:14:42 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.868 | nll_loss 13.531 | ppl 11836.8 | wps 45980.2 | wpb 510.9 | bsz 1 | num_updates 18009 | best_loss 8.499
2022-03-06 02:14:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18009 updates
2022-03-06 02:14:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:14:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:14:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 370 @ 18009 updates, score 13.868) (writing took 1.8000732585787773 seconds)
2022-03-06 02:14:44 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-06 02:14:44 | INFO | train | epoch 370 | loss 1.266 | nll_loss 0.271 | ppl 1.21 | wps 26896.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18009 | lr 0.000235643 | gnorm 0.451 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 42761
2022-03-06 02:14:44 | INFO | fairseq.trainer | begin training epoch 371
2022-03-06 02:14:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:16:38 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 13.954 | nll_loss 13.62 | ppl 12592.2 | wps 45928.4 | wpb 510.9 | bsz 1 | num_updates 18058 | best_loss 8.499
2022-03-06 02:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18058 updates
2022-03-06 02:16:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:16:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:16:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 371 @ 18058 updates, score 13.954) (writing took 1.941132484935224 seconds)
2022-03-06 02:16:40 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-06 02:16:40 | INFO | train | epoch 371 | loss 1.264 | nll_loss 0.27 | ppl 1.21 | wps 27432.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18058 | lr 0.000235323 | gnorm 0.449 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 42876
2022-03-06 02:16:40 | INFO | fairseq.trainer | begin training epoch 372
2022-03-06 02:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:18:14 | INFO | train_inner | epoch 372:     42 / 49 loss=1.264, nll_loss=0.27, ppl=1.21, wps=27221.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.452, loss_scale=32, train_wall=202, gb_free=21.6, wall=42971
2022-03-06 02:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:18:34 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.861 | nll_loss 13.524 | ppl 11780.6 | wps 45983.8 | wpb 510.9 | bsz 1 | num_updates 18107 | best_loss 8.499
2022-03-06 02:18:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18107 updates
2022-03-06 02:18:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 372 @ 18107 updates, score 13.861) (writing took 1.81624068133533 seconds)
2022-03-06 02:18:35 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-06 02:18:35 | INFO | train | epoch 372 | loss 1.264 | nll_loss 0.27 | ppl 1.21 | wps 27446.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18107 | lr 0.000235005 | gnorm 0.452 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 42992
2022-03-06 02:18:35 | INFO | fairseq.trainer | begin training epoch 373
2022-03-06 02:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:19:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:20:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:20:29 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 13.95 | nll_loss 13.618 | ppl 12569.4 | wps 46482.8 | wpb 510.9 | bsz 1 | num_updates 18155 | best_loss 8.499
2022-03-06 02:20:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18155 updates
2022-03-06 02:20:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:20:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:20:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 373 @ 18155 updates, score 13.95) (writing took 1.9913221029564738 seconds)
2022-03-06 02:20:31 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-06 02:20:31 | INFO | train | epoch 373 | loss 1.263 | nll_loss 0.269 | ppl 1.2 | wps 26834 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18155 | lr 0.000234694 | gnorm 0.447 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 43108
2022-03-06 02:20:31 | INFO | fairseq.trainer | begin training epoch 374
2022-03-06 02:20:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:22:13 | INFO | train_inner | epoch 374:     45 / 49 loss=1.263, nll_loss=0.269, ppl=1.2, wps=27197.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.448, loss_scale=32, train_wall=202, gb_free=21.6, wall=43210
2022-03-06 02:22:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:22:25 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.767 | nll_loss 13.426 | ppl 11002.2 | wps 46248.3 | wpb 510.9 | bsz 1 | num_updates 18204 | best_loss 8.499
2022-03-06 02:22:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18204 updates
2022-03-06 02:22:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:22:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:22:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 374 @ 18204 updates, score 13.767) (writing took 1.8525096401572227 seconds)
2022-03-06 02:22:27 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-06 02:22:27 | INFO | train | epoch 374 | loss 1.263 | nll_loss 0.268 | ppl 1.2 | wps 27444 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18204 | lr 0.000234378 | gnorm 0.45 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 43224
2022-03-06 02:22:27 | INFO | fairseq.trainer | begin training epoch 375
2022-03-06 02:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:24:21 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.843 | nll_loss 13.501 | ppl 11590.1 | wps 45972.7 | wpb 510.9 | bsz 1 | num_updates 18253 | best_loss 8.499
2022-03-06 02:24:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18253 updates
2022-03-06 02:24:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:24:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:24:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 375 @ 18253 updates, score 13.843) (writing took 2.0777899213135242 seconds)
2022-03-06 02:24:23 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-06 02:24:23 | INFO | train | epoch 375 | loss 1.263 | nll_loss 0.269 | ppl 1.2 | wps 27397.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18253 | lr 0.000234063 | gnorm 0.451 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 43340
2022-03-06 02:24:23 | INFO | fairseq.trainer | begin training epoch 376
2022-03-06 02:24:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:24:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:26:11 | INFO | train_inner | epoch 376:     48 / 49 loss=1.262, nll_loss=0.268, ppl=1.2, wps=27203.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18300, lr=0.000233762, gnorm=0.449, loss_scale=32, train_wall=202, gb_free=21.6, wall=43448
2022-03-06 02:26:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:26:17 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.851 | nll_loss 13.511 | ppl 11676.8 | wps 46081.1 | wpb 510.9 | bsz 1 | num_updates 18301 | best_loss 8.499
2022-03-06 02:26:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18301 updates
2022-03-06 02:26:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:26:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:26:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 376 @ 18301 updates, score 13.851) (writing took 1.8938186867162585 seconds)
2022-03-06 02:26:19 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-06 02:26:19 | INFO | train | epoch 376 | loss 1.261 | nll_loss 0.267 | ppl 1.2 | wps 26883.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18301 | lr 0.000233756 | gnorm 0.447 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 43456
2022-03-06 02:26:19 | INFO | fairseq.trainer | begin training epoch 377
2022-03-06 02:26:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:28:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:28:13 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.956 | nll_loss 13.623 | ppl 12617 | wps 46343.9 | wpb 510.9 | bsz 1 | num_updates 18350 | best_loss 8.499
2022-03-06 02:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18350 updates
2022-03-06 02:28:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:28:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:28:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 377 @ 18350 updates, score 13.956) (writing took 1.932578711770475 seconds)
2022-03-06 02:28:15 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-06 02:28:15 | INFO | train | epoch 377 | loss 1.261 | nll_loss 0.267 | ppl 1.2 | wps 27429 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18350 | lr 0.000233444 | gnorm 0.448 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 43572
2022-03-06 02:28:15 | INFO | fairseq.trainer | begin training epoch 378
2022-03-06 02:28:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:30:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:30:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:30:09 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.932 | nll_loss 13.599 | ppl 12410.6 | wps 46109.8 | wpb 510.9 | bsz 1 | num_updates 18398 | best_loss 8.499
2022-03-06 02:30:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18398 updates
2022-03-06 02:30:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:30:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:30:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 378 @ 18398 updates, score 13.932) (writing took 2.036434126086533 seconds)
2022-03-06 02:30:11 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-06 02:30:11 | INFO | train | epoch 378 | loss 1.259 | nll_loss 0.265 | ppl 1.2 | wps 26852.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18398 | lr 0.000233139 | gnorm 0.443 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 43688
2022-03-06 02:30:11 | INFO | fairseq.trainer | begin training epoch 379
2022-03-06 02:30:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:30:15 | INFO | train_inner | epoch 379:      2 / 49 loss=1.26, nll_loss=0.266, ppl=1.2, wps=26429.6, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=18400, lr=0.000233126, gnorm=0.447, loss_scale=32, train_wall=201, gb_free=21.6, wall=43692
2022-03-06 02:32:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:32:05 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 13.834 | nll_loss 13.497 | ppl 11557.6 | wps 45955.5 | wpb 510.9 | bsz 1 | num_updates 18447 | best_loss 8.499
2022-03-06 02:32:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18447 updates
2022-03-06 02:32:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:32:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 379 @ 18447 updates, score 13.834) (writing took 1.9438471579924226 seconds)
2022-03-06 02:32:07 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-06 02:32:07 | INFO | train | epoch 379 | loss 1.259 | nll_loss 0.266 | ppl 1.2 | wps 27448 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18447 | lr 0.000232829 | gnorm 0.442 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 43803
2022-03-06 02:32:07 | INFO | fairseq.trainer | begin training epoch 380
2022-03-06 02:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:33:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:34:00 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 13.775 | nll_loss 13.434 | ppl 11068.6 | wps 46070.4 | wpb 510.9 | bsz 1 | num_updates 18496 | best_loss 8.499
2022-03-06 02:34:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18496 updates
2022-03-06 02:34:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:34:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 380 @ 18496 updates, score 13.775) (writing took 2.0167649472132325 seconds)
2022-03-06 02:34:02 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-06 02:34:02 | INFO | train | epoch 380 | loss 1.259 | nll_loss 0.266 | ppl 1.2 | wps 27431.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18496 | lr 0.00023252 | gnorm 0.44 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 43919
2022-03-06 02:34:02 | INFO | fairseq.trainer | begin training epoch 381
2022-03-06 02:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:34:12 | INFO | train_inner | epoch 381:      4 / 49 loss=1.259, nll_loss=0.266, ppl=1.2, wps=27473.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.441, loss_scale=32, train_wall=200, gb_free=21.6, wall=43928
2022-03-06 02:35:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:35:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:35:56 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.924 | nll_loss 13.592 | ppl 12344.2 | wps 46157.4 | wpb 510.9 | bsz 1 | num_updates 18544 | best_loss 8.499
2022-03-06 02:35:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18544 updates
2022-03-06 02:35:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:35:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:35:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 381 @ 18544 updates, score 13.924) (writing took 1.9747636569663882 seconds)
2022-03-06 02:35:58 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-06 02:35:58 | INFO | train | epoch 381 | loss 1.258 | nll_loss 0.265 | ppl 1.2 | wps 26871.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18544 | lr 0.000232219 | gnorm 0.445 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 44035
2022-03-06 02:35:58 | INFO | fairseq.trainer | begin training epoch 382
2022-03-06 02:35:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:37:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:37:52 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.809 | nll_loss 13.47 | ppl 11345.5 | wps 46220.1 | wpb 510.9 | bsz 1 | num_updates 18593 | best_loss 8.499
2022-03-06 02:37:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18593 updates
2022-03-06 02:37:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:37:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:37:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 382 @ 18593 updates, score 13.809) (writing took 2.0206534173339605 seconds)
2022-03-06 02:37:54 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-06 02:37:54 | INFO | train | epoch 382 | loss 1.258 | nll_loss 0.265 | ppl 1.2 | wps 27449.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18593 | lr 0.000231913 | gnorm 0.442 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 44151
2022-03-06 02:37:54 | INFO | fairseq.trainer | begin training epoch 383
2022-03-06 02:37:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:38:10 | INFO | train_inner | epoch 383:      7 / 49 loss=1.258, nll_loss=0.265, ppl=1.2, wps=27224, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.442, loss_scale=32, train_wall=202, gb_free=21.6, wall=44167
2022-03-06 02:39:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:39:48 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 13.974 | nll_loss 13.64 | ppl 12770 | wps 45784.4 | wpb 510.9 | bsz 1 | num_updates 18642 | best_loss 8.499
2022-03-06 02:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18642 updates
2022-03-06 02:39:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:39:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:39:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 383 @ 18642 updates, score 13.974) (writing took 2.032595827244222 seconds)
2022-03-06 02:39:50 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-06 02:39:50 | INFO | train | epoch 383 | loss 1.257 | nll_loss 0.264 | ppl 1.2 | wps 27440.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18642 | lr 0.000231608 | gnorm 0.439 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 44267
2022-03-06 02:39:50 | INFO | fairseq.trainer | begin training epoch 384
2022-03-06 02:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:40:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:41:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:41:44 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 13.796 | nll_loss 13.456 | ppl 11238.5 | wps 45632 | wpb 510.9 | bsz 1 | num_updates 18690 | best_loss 8.499
2022-03-06 02:41:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18690 updates
2022-03-06 02:41:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:41:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:41:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 384 @ 18690 updates, score 13.796) (writing took 2.076153571717441 seconds)
2022-03-06 02:41:46 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-06 02:41:46 | INFO | train | epoch 384 | loss 1.257 | nll_loss 0.264 | ppl 1.2 | wps 26856.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18690 | lr 0.000231311 | gnorm 0.44 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 44383
2022-03-06 02:41:46 | INFO | fairseq.trainer | begin training epoch 385
2022-03-06 02:41:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:42:08 | INFO | train_inner | epoch 385:     10 / 49 loss=1.257, nll_loss=0.264, ppl=1.2, wps=27194.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.44, loss_scale=32, train_wall=202, gb_free=21.6, wall=44405
2022-03-06 02:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:43:40 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.898 | nll_loss 13.567 | ppl 12133.1 | wps 46099 | wpb 510.9 | bsz 1 | num_updates 18739 | best_loss 8.499
2022-03-06 02:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18739 updates
2022-03-06 02:43:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:43:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:43:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 385 @ 18739 updates, score 13.898) (writing took 1.989798216149211 seconds)
2022-03-06 02:43:42 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-06 02:43:42 | INFO | train | epoch 385 | loss 1.256 | nll_loss 0.263 | ppl 1.2 | wps 27444.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18739 | lr 0.000231008 | gnorm 0.439 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 44498
2022-03-06 02:43:42 | INFO | fairseq.trainer | begin training epoch 386
2022-03-06 02:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:45:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:45:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:45:36 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.841 | nll_loss 13.507 | ppl 11644.5 | wps 45849.3 | wpb 510.9 | bsz 1 | num_updates 18787 | best_loss 8.499
2022-03-06 02:45:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18787 updates
2022-03-06 02:45:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:45:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:45:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 386 @ 18787 updates, score 13.841) (writing took 2.087988560087979 seconds)
2022-03-06 02:45:38 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-06 02:45:38 | INFO | train | epoch 386 | loss 1.255 | nll_loss 0.263 | ppl 1.2 | wps 26821.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18787 | lr 0.000230713 | gnorm 0.439 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 44614
2022-03-06 02:45:38 | INFO | fairseq.trainer | begin training epoch 387
2022-03-06 02:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:46:07 | INFO | train_inner | epoch 387:     13 / 49 loss=1.255, nll_loss=0.263, ppl=1.2, wps=27198.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.439, loss_scale=32, train_wall=202, gb_free=21.6, wall=44644
2022-03-06 02:47:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:47:31 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.859 | nll_loss 13.526 | ppl 11793.3 | wps 45946.5 | wpb 510.9 | bsz 1 | num_updates 18836 | best_loss 8.499
2022-03-06 02:47:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18836 updates
2022-03-06 02:47:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:47:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 387 @ 18836 updates, score 13.859) (writing took 1.993076752871275 seconds)
2022-03-06 02:47:33 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-06 02:47:33 | INFO | train | epoch 387 | loss 1.255 | nll_loss 0.263 | ppl 1.2 | wps 27455.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18836 | lr 0.000230412 | gnorm 0.438 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 44730
2022-03-06 02:47:33 | INFO | fairseq.trainer | begin training epoch 388
2022-03-06 02:47:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:49:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:49:27 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.997 | nll_loss 13.663 | ppl 12972.4 | wps 45771.7 | wpb 510.9 | bsz 1 | num_updates 18885 | best_loss 8.499
2022-03-06 02:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18885 updates
2022-03-06 02:49:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:49:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:49:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 388 @ 18885 updates, score 13.997) (writing took 2.005290837958455 seconds)
2022-03-06 02:49:29 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-06 02:49:29 | INFO | train | epoch 388 | loss 1.255 | nll_loss 0.263 | ppl 1.2 | wps 27436.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18885 | lr 0.000230113 | gnorm 0.445 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 44846
2022-03-06 02:49:29 | INFO | fairseq.trainer | begin training epoch 389
2022-03-06 02:49:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:50:03 | INFO | train_inner | epoch 389:     15 / 49 loss=1.255, nll_loss=0.263, ppl=1.2, wps=27480.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.442, loss_scale=32, train_wall=200, gb_free=21.6, wall=44880
2022-03-06 02:50:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:51:23 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 13.864 | nll_loss 13.524 | ppl 11778.4 | wps 45782.9 | wpb 510.9 | bsz 1 | num_updates 18933 | best_loss 8.499
2022-03-06 02:51:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18933 updates
2022-03-06 02:51:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:51:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:51:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 389 @ 18933 updates, score 13.864) (writing took 1.9585204692557454 seconds)
2022-03-06 02:51:25 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-06 02:51:25 | INFO | train | epoch 389 | loss 1.254 | nll_loss 0.261 | ppl 1.2 | wps 26896.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 18933 | lr 0.000229821 | gnorm 0.442 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 44962
2022-03-06 02:51:25 | INFO | fairseq.trainer | begin training epoch 390
2022-03-06 02:51:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:53:19 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 13.85 | nll_loss 13.514 | ppl 11695.3 | wps 46239.4 | wpb 510.9 | bsz 1 | num_updates 18982 | best_loss 8.499
2022-03-06 02:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18982 updates
2022-03-06 02:53:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:53:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 390 @ 18982 updates, score 13.85) (writing took 2.0268498668447137 seconds)
2022-03-06 02:53:21 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-06 02:53:21 | INFO | train | epoch 390 | loss 1.253 | nll_loss 0.261 | ppl 1.2 | wps 27420.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 18982 | lr 0.000229524 | gnorm 0.436 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 45078
2022-03-06 02:53:21 | INFO | fairseq.trainer | begin training epoch 391
2022-03-06 02:53:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:54:01 | INFO | train_inner | epoch 391:     18 / 49 loss=1.253, nll_loss=0.261, ppl=1.2, wps=27202.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.437, loss_scale=32, train_wall=202, gb_free=21.6, wall=45118
2022-03-06 02:55:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:55:15 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.735 | nll_loss 13.395 | ppl 10769 | wps 46477.8 | wpb 510.9 | bsz 1 | num_updates 19031 | best_loss 8.499
2022-03-06 02:55:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19031 updates
2022-03-06 02:55:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:55:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:55:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 391 @ 19031 updates, score 13.735) (writing took 2.102934991940856 seconds)
2022-03-06 02:55:17 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-06 02:55:17 | INFO | train | epoch 391 | loss 1.252 | nll_loss 0.26 | ppl 1.2 | wps 27374.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19031 | lr 0.000229229 | gnorm 0.434 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 45194
2022-03-06 02:55:17 | INFO | fairseq.trainer | begin training epoch 392
2022-03-06 02:55:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:55:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:57:11 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 13.79 | nll_loss 13.452 | ppl 11209 | wps 45684.2 | wpb 510.9 | bsz 1 | num_updates 19079 | best_loss 8.499
2022-03-06 02:57:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19079 updates
2022-03-06 02:57:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:57:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:57:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 392 @ 19079 updates, score 13.79) (writing took 2.129178178496659 seconds)
2022-03-06 02:57:13 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-06 02:57:13 | INFO | train | epoch 392 | loss 1.251 | nll_loss 0.259 | ppl 1.2 | wps 26836.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19079 | lr 0.00022894 | gnorm 0.435 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 45310
2022-03-06 02:57:13 | INFO | fairseq.trainer | begin training epoch 393
2022-03-06 02:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:58:00 | INFO | train_inner | epoch 393:     21 / 49 loss=1.251, nll_loss=0.26, ppl=1.2, wps=27155.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.434, loss_scale=32, train_wall=202, gb_free=21.6, wall=45357
2022-03-06 02:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:59:07 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.84 | nll_loss 13.504 | ppl 11620.1 | wps 46118 | wpb 510.9 | bsz 1 | num_updates 19128 | best_loss 8.499
2022-03-06 02:59:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19128 updates
2022-03-06 02:59:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:59:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 02:59:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 393 @ 19128 updates, score 13.84) (writing took 2.10031124856323 seconds)
2022-03-06 02:59:09 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-06 02:59:09 | INFO | train | epoch 393 | loss 1.251 | nll_loss 0.26 | ppl 1.2 | wps 27366.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19128 | lr 0.000228647 | gnorm 0.435 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 45426
2022-03-06 02:59:09 | INFO | fairseq.trainer | begin training epoch 394
2022-03-06 02:59:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:00:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:01:03 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.849 | nll_loss 13.514 | ppl 11696.5 | wps 46125.5 | wpb 510.9 | bsz 1 | num_updates 19177 | best_loss 8.499
2022-03-06 03:01:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19177 updates
2022-03-06 03:01:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:01:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 394 @ 19177 updates, score 13.849) (writing took 2.0117627512663603 seconds)
2022-03-06 03:01:05 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-06 03:01:05 | INFO | train | epoch 394 | loss 1.251 | nll_loss 0.26 | ppl 1.2 | wps 27433.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19177 | lr 0.000228355 | gnorm 0.441 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 45542
2022-03-06 03:01:05 | INFO | fairseq.trainer | begin training epoch 395
2022-03-06 03:01:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:01:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:01:59 | INFO | train_inner | epoch 395:     24 / 49 loss=1.251, nll_loss=0.26, ppl=1.2, wps=27193.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.437, loss_scale=32, train_wall=202, gb_free=21.6, wall=45596
2022-03-06 03:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:02:59 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 13.775 | nll_loss 13.44 | ppl 11111.2 | wps 46120 | wpb 510.9 | bsz 1 | num_updates 19225 | best_loss 8.499
2022-03-06 03:02:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19225 updates
2022-03-06 03:02:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:03:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:03:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 395 @ 19225 updates, score 13.775) (writing took 2.1046078940853477 seconds)
2022-03-06 03:03:01 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-06 03:03:01 | INFO | train | epoch 395 | loss 1.249 | nll_loss 0.258 | ppl 1.2 | wps 26844 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19225 | lr 0.000228069 | gnorm 0.433 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 45658
2022-03-06 03:03:01 | INFO | fairseq.trainer | begin training epoch 396
2022-03-06 03:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:04:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:04:55 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 13.874 | nll_loss 13.538 | ppl 11897.6 | wps 46101.6 | wpb 510.9 | bsz 1 | num_updates 19274 | best_loss 8.499
2022-03-06 03:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19274 updates
2022-03-06 03:04:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:04:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:04:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 396 @ 19274 updates, score 13.874) (writing took 2.058608598075807 seconds)
2022-03-06 03:04:57 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-06 03:04:57 | INFO | train | epoch 396 | loss 1.249 | nll_loss 0.258 | ppl 1.2 | wps 27389.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19274 | lr 0.000227779 | gnorm 0.432 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 45774
2022-03-06 03:04:57 | INFO | fairseq.trainer | begin training epoch 397
2022-03-06 03:04:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:05:55 | INFO | train_inner | epoch 397:     26 / 49 loss=1.249, nll_loss=0.258, ppl=1.2, wps=27441.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.433, loss_scale=32, train_wall=200, gb_free=21.6, wall=45832
2022-03-06 03:06:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:06:51 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.847 | nll_loss 13.51 | ppl 11668.8 | wps 45891.3 | wpb 510.9 | bsz 1 | num_updates 19322 | best_loss 8.499
2022-03-06 03:06:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19322 updates
2022-03-06 03:06:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:06:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:06:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 397 @ 19322 updates, score 13.847) (writing took 2.046019909903407 seconds)
2022-03-06 03:06:53 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-06 03:06:53 | INFO | train | epoch 397 | loss 1.249 | nll_loss 0.258 | ppl 1.2 | wps 26880.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19322 | lr 0.000227496 | gnorm 0.43 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 45889
2022-03-06 03:06:53 | INFO | fairseq.trainer | begin training epoch 398
2022-03-06 03:06:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:08:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:08:46 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.889 | nll_loss 13.555 | ppl 12034.8 | wps 45983.1 | wpb 510.9 | bsz 1 | num_updates 19371 | best_loss 8.499
2022-03-06 03:08:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19371 updates
2022-03-06 03:08:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:08:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:08:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 398 @ 19371 updates, score 13.889) (writing took 1.956570005044341 seconds)
2022-03-06 03:08:48 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-06 03:08:48 | INFO | train | epoch 398 | loss 1.248 | nll_loss 0.257 | ppl 1.2 | wps 27495.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19371 | lr 0.000227208 | gnorm 0.431 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 46005
2022-03-06 03:08:48 | INFO | fairseq.trainer | begin training epoch 399
2022-03-06 03:08:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:09:53 | INFO | train_inner | epoch 399:     29 / 49 loss=1.248, nll_loss=0.258, ppl=1.2, wps=27238.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.432, loss_scale=32, train_wall=202, gb_free=21.6, wall=46070
2022-03-06 03:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:10:42 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 13.934 | nll_loss 13.604 | ppl 12453 | wps 45425.7 | wpb 510.9 | bsz 1 | num_updates 19420 | best_loss 8.499
2022-03-06 03:10:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19420 updates
2022-03-06 03:10:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:10:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 399 @ 19420 updates, score 13.934) (writing took 2.039130626246333 seconds)
2022-03-06 03:10:44 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-06 03:10:44 | INFO | train | epoch 399 | loss 1.248 | nll_loss 0.258 | ppl 1.2 | wps 27437.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19420 | lr 0.000226921 | gnorm 0.441 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 46121
2022-03-06 03:10:44 | INFO | fairseq.trainer | begin training epoch 400
2022-03-06 03:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:12:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:12:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:12:38 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.816 | nll_loss 13.477 | ppl 11402.9 | wps 45562.8 | wpb 510.9 | bsz 1 | num_updates 19468 | best_loss 8.499
2022-03-06 03:12:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19468 updates
2022-03-06 03:12:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:12:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:12:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 400 @ 19468 updates, score 13.816) (writing took 2.0745632834732533 seconds)
2022-03-06 03:12:40 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-06 03:12:40 | INFO | train | epoch 400 | loss 1.247 | nll_loss 0.257 | ppl 1.19 | wps 26839.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19468 | lr 0.000226641 | gnorm 0.434 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 46237
2022-03-06 03:12:40 | INFO | fairseq.trainer | begin training epoch 401
2022-03-06 03:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:13:52 | INFO | train_inner | epoch 401:     32 / 49 loss=1.247, nll_loss=0.257, ppl=1.19, wps=27187.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.435, loss_scale=32, train_wall=202, gb_free=21.6, wall=46309
2022-03-06 03:14:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:14:34 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 13.709 | nll_loss 13.366 | ppl 10554.6 | wps 46042.1 | wpb 510.9 | bsz 1 | num_updates 19517 | best_loss 8.499
2022-03-06 03:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19517 updates
2022-03-06 03:14:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:14:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 401 @ 19517 updates, score 13.709) (writing took 2.071866643615067 seconds)
2022-03-06 03:14:36 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-06 03:14:36 | INFO | train | epoch 401 | loss 1.247 | nll_loss 0.256 | ppl 1.19 | wps 27396.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19517 | lr 0.000226357 | gnorm 0.428 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 46353
2022-03-06 03:14:36 | INFO | fairseq.trainer | begin training epoch 402
2022-03-06 03:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:16:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:16:30 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.858 | nll_loss 13.521 | ppl 11755.6 | wps 45795.9 | wpb 510.9 | bsz 1 | num_updates 19566 | best_loss 8.499
2022-03-06 03:16:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19566 updates
2022-03-06 03:16:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:16:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:16:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 402 @ 19566 updates, score 13.858) (writing took 2.0481739435344934 seconds)
2022-03-06 03:16:32 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-06 03:16:32 | INFO | train | epoch 402 | loss 1.246 | nll_loss 0.256 | ppl 1.19 | wps 27404.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19566 | lr 0.000226073 | gnorm 0.431 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 46469
2022-03-06 03:16:32 | INFO | fairseq.trainer | begin training epoch 403
2022-03-06 03:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:17:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:17:51 | INFO | train_inner | epoch 403:     35 / 49 loss=1.246, nll_loss=0.256, ppl=1.19, wps=27183.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.43, loss_scale=32, train_wall=202, gb_free=21.6, wall=46547
2022-03-06 03:18:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:18:26 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 13.931 | nll_loss 13.597 | ppl 12392 | wps 45972.9 | wpb 510.9 | bsz 1 | num_updates 19614 | best_loss 8.499
2022-03-06 03:18:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19614 updates
2022-03-06 03:18:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:18:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:18:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 403 @ 19614 updates, score 13.931) (writing took 2.073043977841735 seconds)
2022-03-06 03:18:28 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-06 03:18:28 | INFO | train | epoch 403 | loss 1.246 | nll_loss 0.255 | ppl 1.19 | wps 26858.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19614 | lr 0.000225796 | gnorm 0.432 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 46585
2022-03-06 03:18:28 | INFO | fairseq.trainer | begin training epoch 404
2022-03-06 03:18:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:20:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:20:22 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.877 | nll_loss 13.542 | ppl 11930.3 | wps 45222.8 | wpb 510.9 | bsz 1 | num_updates 19663 | best_loss 8.499
2022-03-06 03:20:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19663 updates
2022-03-06 03:20:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:20:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:20:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 404 @ 19663 updates, score 13.877) (writing took 2.0383249865844846 seconds)
2022-03-06 03:20:24 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-06 03:20:24 | INFO | train | epoch 404 | loss 1.245 | nll_loss 0.256 | ppl 1.19 | wps 27369 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19663 | lr 0.000225515 | gnorm 0.435 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 46701
2022-03-06 03:20:24 | INFO | fairseq.trainer | begin training epoch 405
2022-03-06 03:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:21:47 | INFO | train_inner | epoch 405:     37 / 49 loss=1.245, nll_loss=0.255, ppl=1.19, wps=27409, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.435, loss_scale=32, train_wall=200, gb_free=21.6, wall=46784
2022-03-06 03:22:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:22:18 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 13.863 | nll_loss 13.527 | ppl 11805.3 | wps 46083.9 | wpb 510.9 | bsz 1 | num_updates 19712 | best_loss 8.499
2022-03-06 03:22:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19712 updates
2022-03-06 03:22:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:22:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:22:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 405 @ 19712 updates, score 13.863) (writing took 2.1055216444656253 seconds)
2022-03-06 03:22:20 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-06 03:22:20 | INFO | train | epoch 405 | loss 1.244 | nll_loss 0.255 | ppl 1.19 | wps 27366.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19712 | lr 0.000225234 | gnorm 0.432 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 46817
2022-03-06 03:22:20 | INFO | fairseq.trainer | begin training epoch 406
2022-03-06 03:22:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:22:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:24:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:24:14 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.851 | nll_loss 13.52 | ppl 11750.2 | wps 45154.6 | wpb 510.9 | bsz 1 | num_updates 19760 | best_loss 8.499
2022-03-06 03:24:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19760 updates
2022-03-06 03:24:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:24:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:24:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 406 @ 19760 updates, score 13.851) (writing took 2.1771760312840343 seconds)
2022-03-06 03:24:16 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-06 03:24:16 | INFO | train | epoch 406 | loss 1.244 | nll_loss 0.254 | ppl 1.19 | wps 26747.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19760 | lr 0.000224961 | gnorm 0.432 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 46933
2022-03-06 03:24:17 | INFO | fairseq.trainer | begin training epoch 407
2022-03-06 03:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:25:47 | INFO | train_inner | epoch 407:     40 / 49 loss=1.244, nll_loss=0.254, ppl=1.19, wps=27124.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.433, loss_scale=32, train_wall=202, gb_free=21.6, wall=47023
2022-03-06 03:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:26:11 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.76 | nll_loss 13.422 | ppl 10977.3 | wps 45960.1 | wpb 510.9 | bsz 1 | num_updates 19809 | best_loss 8.499
2022-03-06 03:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19809 updates
2022-03-06 03:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:26:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:26:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 407 @ 19809 updates, score 13.76) (writing took 2.1565696485340595 seconds)
2022-03-06 03:26:13 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-06 03:26:13 | INFO | train | epoch 407 | loss 1.243 | nll_loss 0.254 | ppl 1.19 | wps 27344.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19809 | lr 0.000224682 | gnorm 0.438 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 47050
2022-03-06 03:26:13 | INFO | fairseq.trainer | begin training epoch 408
2022-03-06 03:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:27:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:28:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:28:07 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 13.841 | nll_loss 13.509 | ppl 11658.6 | wps 45323 | wpb 510.9 | bsz 1 | num_updates 19857 | best_loss 8.499
2022-03-06 03:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19857 updates
2022-03-06 03:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:28:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:28:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 408 @ 19857 updates, score 13.841) (writing took 2.0607029469683766 seconds)
2022-03-06 03:28:09 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-06 03:28:09 | INFO | train | epoch 408 | loss 1.242 | nll_loss 0.253 | ppl 1.19 | wps 26847.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 19857 | lr 0.000224411 | gnorm 0.429 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 47165
2022-03-06 03:28:09 | INFO | fairseq.trainer | begin training epoch 409
2022-03-06 03:28:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:29:46 | INFO | train_inner | epoch 409:     43 / 49 loss=1.242, nll_loss=0.253, ppl=1.19, wps=27130.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.433, loss_scale=32, train_wall=202, gb_free=21.6, wall=47262
2022-03-06 03:29:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:30:03 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.884 | nll_loss 13.552 | ppl 12006.4 | wps 46223.7 | wpb 510.9 | bsz 1 | num_updates 19906 | best_loss 8.499
2022-03-06 03:30:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19906 updates
2022-03-06 03:30:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:30:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:30:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 409 @ 19906 updates, score 13.884) (writing took 2.123125661164522 seconds)
2022-03-06 03:30:05 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-06 03:30:05 | INFO | train | epoch 409 | loss 1.242 | nll_loss 0.253 | ppl 1.19 | wps 27330.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19906 | lr 0.000224134 | gnorm 0.437 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 47282
2022-03-06 03:30:05 | INFO | fairseq.trainer | begin training epoch 410
2022-03-06 03:30:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:31:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:31:59 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 13.892 | nll_loss 13.558 | ppl 12060.2 | wps 45185.6 | wpb 510.9 | bsz 1 | num_updates 19955 | best_loss 8.499
2022-03-06 03:31:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19955 updates
2022-03-06 03:31:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:32:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:32:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 410 @ 19955 updates, score 13.892) (writing took 2.055187152698636 seconds)
2022-03-06 03:32:01 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-06 03:32:01 | INFO | train | epoch 410 | loss 1.241 | nll_loss 0.252 | ppl 1.19 | wps 27310 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 19955 | lr 0.000223859 | gnorm 0.429 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 47398
2022-03-06 03:32:01 | INFO | fairseq.trainer | begin training epoch 411
2022-03-06 03:32:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:33:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:33:45 | INFO | train_inner | epoch 411:     46 / 49 loss=1.242, nll_loss=0.252, ppl=1.19, wps=27134, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=20000, lr=0.000223607, gnorm=0.43, loss_scale=32, train_wall=202, gb_free=21.6, wall=47502
2022-03-06 03:33:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:33:55 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.896 | nll_loss 13.563 | ppl 12104.5 | wps 46199 | wpb 510.9 | bsz 1 | num_updates 20003 | best_loss 8.499
2022-03-06 03:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20003 updates
2022-03-06 03:33:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:33:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 411 @ 20003 updates, score 13.896) (writing took 2.1656539104878902 seconds)
2022-03-06 03:33:57 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-06 03:33:57 | INFO | train | epoch 411 | loss 1.241 | nll_loss 0.252 | ppl 1.19 | wps 26838.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20003 | lr 0.00022359 | gnorm 0.429 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 47514
2022-03-06 03:33:57 | INFO | fairseq.trainer | begin training epoch 412
2022-03-06 03:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:35:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:35:51 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.858 | nll_loss 13.525 | ppl 11785.8 | wps 45905.8 | wpb 510.9 | bsz 1 | num_updates 20052 | best_loss 8.499
2022-03-06 03:35:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20052 updates
2022-03-06 03:35:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:35:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:35:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 412 @ 20052 updates, score 13.858) (writing took 2.067134958691895 seconds)
2022-03-06 03:35:53 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-06 03:35:53 | INFO | train | epoch 412 | loss 1.241 | nll_loss 0.252 | ppl 1.19 | wps 27385 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20052 | lr 0.000223317 | gnorm 0.426 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 47630
2022-03-06 03:35:53 | INFO | fairseq.trainer | begin training epoch 413
2022-03-06 03:35:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:37:42 | INFO | train_inner | epoch 413:     48 / 49 loss=1.24, nll_loss=0.251, ppl=1.19, wps=27395, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.426, loss_scale=32, train_wall=200, gb_free=21.6, wall=47738
2022-03-06 03:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:37:48 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 13.834 | nll_loss 13.503 | ppl 11608.8 | wps 45062.1 | wpb 510.9 | bsz 1 | num_updates 20101 | best_loss 8.499
2022-03-06 03:37:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20101 updates
2022-03-06 03:37:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:37:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 413 @ 20101 updates, score 13.834) (writing took 2.169885237701237 seconds)
2022-03-06 03:37:50 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-06 03:37:50 | INFO | train | epoch 413 | loss 1.24 | nll_loss 0.251 | ppl 1.19 | wps 27299.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20101 | lr 0.000223044 | gnorm 0.426 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 47747
2022-03-06 03:37:50 | INFO | fairseq.trainer | begin training epoch 414
2022-03-06 03:37:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:38:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:39:44 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.754 | nll_loss 13.418 | ppl 10943.5 | wps 45846.2 | wpb 510.9 | bsz 1 | num_updates 20149 | best_loss 8.499
2022-03-06 03:39:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20149 updates
2022-03-06 03:39:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:39:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:39:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 414 @ 20149 updates, score 13.754) (writing took 2.0950147304683924 seconds)
2022-03-06 03:39:46 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-06 03:39:46 | INFO | train | epoch 414 | loss 1.239 | nll_loss 0.251 | ppl 1.19 | wps 26806.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20149 | lr 0.000222778 | gnorm 0.422 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 47863
2022-03-06 03:39:46 | INFO | fairseq.trainer | begin training epoch 415
2022-03-06 03:39:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:41:40 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.854 | nll_loss 13.518 | ppl 11731.2 | wps 46445.1 | wpb 510.9 | bsz 1 | num_updates 20198 | best_loss 8.499
2022-03-06 03:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20198 updates
2022-03-06 03:41:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:41:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 415 @ 20198 updates, score 13.854) (writing took 2.157860173843801 seconds)
2022-03-06 03:41:42 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-06 03:41:42 | INFO | train | epoch 415 | loss 1.24 | nll_loss 0.251 | ppl 1.19 | wps 27336 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20198 | lr 0.000222508 | gnorm 0.429 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 47979
2022-03-06 03:41:42 | INFO | fairseq.trainer | begin training epoch 416
2022-03-06 03:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:41:47 | INFO | train_inner | epoch 416:      2 / 49 loss=1.239, nll_loss=0.251, ppl=1.19, wps=26321.9, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=20200, lr=0.000222497, gnorm=0.427, loss_scale=32, train_wall=201, gb_free=21.6, wall=47984
2022-03-06 03:43:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:43:36 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.877 | nll_loss 13.548 | ppl 11976.9 | wps 45479.2 | wpb 510.9 | bsz 1 | num_updates 20246 | best_loss 8.499
2022-03-06 03:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20246 updates
2022-03-06 03:43:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:43:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:43:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 416 @ 20246 updates, score 13.877) (writing took 2.0888536516577005 seconds)
2022-03-06 03:43:38 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-06 03:43:38 | INFO | train | epoch 416 | loss 1.239 | nll_loss 0.251 | ppl 1.19 | wps 26756.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20246 | lr 0.000222244 | gnorm 0.431 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 48095
2022-03-06 03:43:38 | INFO | fairseq.trainer | begin training epoch 417
2022-03-06 03:43:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:45:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:45:33 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.892 | nll_loss 13.562 | ppl 12095.1 | wps 44967.6 | wpb 510.9 | bsz 1 | num_updates 20295 | best_loss 8.499
2022-03-06 03:45:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20295 updates
2022-03-06 03:45:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:45:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:45:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 417 @ 20295 updates, score 13.892) (writing took 2.2404110319912434 seconds)
2022-03-06 03:45:35 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-06 03:45:35 | INFO | train | epoch 417 | loss 1.238 | nll_loss 0.25 | ppl 1.19 | wps 27283.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20295 | lr 0.000221976 | gnorm 0.426 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 48212
2022-03-06 03:45:35 | INFO | fairseq.trainer | begin training epoch 418
2022-03-06 03:45:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:45:46 | INFO | train_inner | epoch 418:      5 / 49 loss=1.238, nll_loss=0.25, ppl=1.19, wps=27080.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.428, loss_scale=32, train_wall=202, gb_free=21.6, wall=48223
2022-03-06 03:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:47:29 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.875 | nll_loss 13.544 | ppl 11947 | wps 46060.6 | wpb 510.9 | bsz 1 | num_updates 20344 | best_loss 8.499
2022-03-06 03:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20344 updates
2022-03-06 03:47:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:47:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 418 @ 20344 updates, score 13.875) (writing took 2.113342142663896 seconds)
2022-03-06 03:47:31 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-06 03:47:31 | INFO | train | epoch 418 | loss 1.237 | nll_loss 0.249 | ppl 1.19 | wps 27334.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20344 | lr 0.000221708 | gnorm 0.423 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 48328
2022-03-06 03:47:31 | INFO | fairseq.trainer | begin training epoch 419
2022-03-06 03:47:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:48:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:49:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:49:25 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.822 | nll_loss 13.489 | ppl 11499.5 | wps 45832.5 | wpb 510.9 | bsz 1 | num_updates 20392 | best_loss 8.499
2022-03-06 03:49:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20392 updates
2022-03-06 03:49:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:49:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:49:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 419 @ 20392 updates, score 13.822) (writing took 2.2125083142891526 seconds)
2022-03-06 03:49:27 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-06 03:49:27 | INFO | train | epoch 419 | loss 1.237 | nll_loss 0.249 | ppl 1.19 | wps 26764.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20392 | lr 0.000221447 | gnorm 0.425 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 48444
2022-03-06 03:49:27 | INFO | fairseq.trainer | begin training epoch 420
2022-03-06 03:49:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:49:46 | INFO | train_inner | epoch 420:      8 / 49 loss=1.237, nll_loss=0.249, ppl=1.19, wps=27109.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.424, loss_scale=32, train_wall=202, gb_free=21.6, wall=48462
2022-03-06 03:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:51:22 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.783 | nll_loss 13.449 | ppl 11182.7 | wps 45625.3 | wpb 510.9 | bsz 1 | num_updates 20441 | best_loss 8.499
2022-03-06 03:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20441 updates
2022-03-06 03:51:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:51:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 420 @ 20441 updates, score 13.783) (writing took 2.0487965904176235 seconds)
2022-03-06 03:51:24 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-06 03:51:24 | INFO | train | epoch 420 | loss 1.237 | nll_loss 0.249 | ppl 1.19 | wps 27373.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20441 | lr 0.000221182 | gnorm 0.424 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 48560
2022-03-06 03:51:24 | INFO | fairseq.trainer | begin training epoch 421
2022-03-06 03:51:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:53:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:53:17 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.868 | nll_loss 13.534 | ppl 11859.8 | wps 46301.1 | wpb 510.9 | bsz 1 | num_updates 20490 | best_loss 8.499
2022-03-06 03:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20490 updates
2022-03-06 03:53:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:53:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:53:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 421 @ 20490 updates, score 13.868) (writing took 2.04974218364805 seconds)
2022-03-06 03:53:19 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-06 03:53:19 | INFO | train | epoch 421 | loss 1.237 | nll_loss 0.249 | ppl 1.19 | wps 27425.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20490 | lr 0.000220917 | gnorm 0.429 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 48676
2022-03-06 03:53:19 | INFO | fairseq.trainer | begin training epoch 422
2022-03-06 03:53:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:53:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:53:44 | INFO | train_inner | epoch 422:     11 / 49 loss=1.237, nll_loss=0.249, ppl=1.19, wps=27192, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.427, loss_scale=32, train_wall=202, gb_free=21.6, wall=48701
2022-03-06 03:55:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:55:13 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.787 | nll_loss 13.456 | ppl 11234.2 | wps 46127.7 | wpb 510.9 | bsz 1 | num_updates 20538 | best_loss 8.499
2022-03-06 03:55:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20538 updates
2022-03-06 03:55:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:55:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:55:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 422 @ 20538 updates, score 13.787) (writing took 2.1152076851576567 seconds)
2022-03-06 03:55:15 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-06 03:55:15 | INFO | train | epoch 422 | loss 1.235 | nll_loss 0.248 | ppl 1.19 | wps 26929.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20538 | lr 0.000220659 | gnorm 0.421 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 48792
2022-03-06 03:55:15 | INFO | fairseq.trainer | begin training epoch 423
2022-03-06 03:55:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:57:08 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.909 | nll_loss 13.576 | ppl 12215.2 | wps 45792.4 | wpb 510.9 | bsz 1 | num_updates 20587 | best_loss 8.499
2022-03-06 03:57:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20587 updates
2022-03-06 03:57:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:57:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 423 @ 20587 updates, score 13.909) (writing took 2.1231827242299914 seconds)
2022-03-06 03:57:11 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-06 03:57:11 | INFO | train | epoch 423 | loss 1.235 | nll_loss 0.248 | ppl 1.19 | wps 27510.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20587 | lr 0.000220396 | gnorm 0.422 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48907
2022-03-06 03:57:11 | INFO | fairseq.trainer | begin training epoch 424
2022-03-06 03:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:57:40 | INFO | train_inner | epoch 424:     13 / 49 loss=1.235, nll_loss=0.248, ppl=1.19, wps=27523, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.42, loss_scale=32, train_wall=199, gb_free=21.6, wall=48937
2022-03-06 03:58:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:58:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:59:04 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.91 | nll_loss 13.583 | ppl 12272.9 | wps 46289.8 | wpb 510.9 | bsz 1 | num_updates 20635 | best_loss 8.499
2022-03-06 03:59:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20635 updates
2022-03-06 03:59:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:59:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 03:59:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 424 @ 20635 updates, score 13.91) (writing took 2.167390566319227 seconds)
2022-03-06 03:59:06 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-06 03:59:06 | INFO | train | epoch 424 | loss 1.234 | nll_loss 0.247 | ppl 1.19 | wps 26881.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20635 | lr 0.000220139 | gnorm 0.422 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 49023
2022-03-06 03:59:06 | INFO | fairseq.trainer | begin training epoch 425
2022-03-06 03:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:01:00 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.838 | nll_loss 13.504 | ppl 11617 | wps 46150.6 | wpb 510.9 | bsz 1 | num_updates 20684 | best_loss 8.499
2022-03-06 04:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20684 updates
2022-03-06 04:01:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 425 @ 20684 updates, score 13.838) (writing took 2.146368599496782 seconds)
2022-03-06 04:01:02 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-06 04:01:02 | INFO | train | epoch 425 | loss 1.234 | nll_loss 0.248 | ppl 1.19 | wps 27476 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20684 | lr 0.000219878 | gnorm 0.431 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 49139
2022-03-06 04:01:02 | INFO | fairseq.trainer | begin training epoch 426
2022-03-06 04:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:01:38 | INFO | train_inner | epoch 426:     16 / 49 loss=1.234, nll_loss=0.247, ppl=1.19, wps=27256.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.427, loss_scale=32, train_wall=201, gb_free=21.6, wall=49175
2022-03-06 04:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:02:55 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.915 | nll_loss 13.585 | ppl 12286.5 | wps 46104.9 | wpb 510.9 | bsz 1 | num_updates 20733 | best_loss 8.499
2022-03-06 04:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20733 updates
2022-03-06 04:02:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:02:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 426 @ 20733 updates, score 13.915) (writing took 2.240383330732584 seconds)
2022-03-06 04:02:58 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-06 04:02:58 | INFO | train | epoch 426 | loss 1.233 | nll_loss 0.247 | ppl 1.19 | wps 27470.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20733 | lr 0.000219619 | gnorm 0.422 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 49255
2022-03-06 04:02:58 | INFO | fairseq.trainer | begin training epoch 427
2022-03-06 04:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:04:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:04:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:04:51 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.847 | nll_loss 13.513 | ppl 11686.2 | wps 46024.7 | wpb 510.9 | bsz 1 | num_updates 20781 | best_loss 8.499
2022-03-06 04:04:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20781 updates
2022-03-06 04:04:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:04:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:04:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 427 @ 20781 updates, score 13.847) (writing took 2.2461270997300744 seconds)
2022-03-06 04:04:53 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-06 04:04:53 | INFO | train | epoch 427 | loss 1.233 | nll_loss 0.246 | ppl 1.19 | wps 26897.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 20781 | lr 0.000219365 | gnorm 0.418 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 49370
2022-03-06 04:04:53 | INFO | fairseq.trainer | begin training epoch 428
2022-03-06 04:04:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:05:36 | INFO | train_inner | epoch 428:     19 / 49 loss=1.233, nll_loss=0.246, ppl=1.19, wps=27231.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.419, loss_scale=32, train_wall=201, gb_free=21.6, wall=49413
2022-03-06 04:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:06:47 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.844 | nll_loss 13.511 | ppl 11671.7 | wps 46145.9 | wpb 510.9 | bsz 1 | num_updates 20830 | best_loss 8.499
2022-03-06 04:06:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20830 updates
2022-03-06 04:06:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:06:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:06:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 428 @ 20830 updates, score 13.844) (writing took 2.271913926117122 seconds)
2022-03-06 04:06:49 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-06 04:06:49 | INFO | train | epoch 428 | loss 1.233 | nll_loss 0.247 | ppl 1.19 | wps 27428.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20830 | lr 0.000219107 | gnorm 0.426 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 49486
2022-03-06 04:06:49 | INFO | fairseq.trainer | begin training epoch 429
2022-03-06 04:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:08:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:08:43 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 13.824 | nll_loss 13.488 | ppl 11492.4 | wps 46452.6 | wpb 510.9 | bsz 1 | num_updates 20879 | best_loss 8.499
2022-03-06 04:08:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20879 updates
2022-03-06 04:08:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:08:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:08:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 429 @ 20879 updates, score 13.824) (writing took 2.23131250590086 seconds)
2022-03-06 04:08:45 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-06 04:08:45 | INFO | train | epoch 429 | loss 1.232 | nll_loss 0.246 | ppl 1.19 | wps 27507.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20879 | lr 0.000218849 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49602
2022-03-06 04:08:45 | INFO | fairseq.trainer | begin training epoch 430
2022-03-06 04:08:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:09:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:09:34 | INFO | train_inner | epoch 430:     22 / 49 loss=1.233, nll_loss=0.246, ppl=1.19, wps=27247.9, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.425, loss_scale=32, train_wall=201, gb_free=21.6, wall=49651
2022-03-06 04:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:10:38 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.81 | nll_loss 13.477 | ppl 11405.1 | wps 46535.9 | wpb 510.9 | bsz 1 | num_updates 20927 | best_loss 8.499
2022-03-06 04:10:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20927 updates
2022-03-06 04:10:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:10:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:10:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 430 @ 20927 updates, score 13.81) (writing took 2.25822997931391 seconds)
2022-03-06 04:10:40 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-06 04:10:40 | INFO | train | epoch 430 | loss 1.232 | nll_loss 0.245 | ppl 1.19 | wps 26918.2 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 20927 | lr 0.000218598 | gnorm 0.422 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49717
2022-03-06 04:10:40 | INFO | fairseq.trainer | begin training epoch 431
2022-03-06 04:10:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:12:34 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.815 | nll_loss 13.48 | ppl 11428.5 | wps 46511.8 | wpb 510.9 | bsz 1 | num_updates 20976 | best_loss 8.499
2022-03-06 04:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20976 updates
2022-03-06 04:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 431 @ 20976 updates, score 13.815) (writing took 2.192996086552739 seconds)
2022-03-06 04:12:36 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-06 04:12:36 | INFO | train | epoch 431 | loss 1.231 | nll_loss 0.244 | ppl 1.18 | wps 27460.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 20976 | lr 0.000218343 | gnorm 0.419 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 49833
2022-03-06 04:12:36 | INFO | fairseq.trainer | begin training epoch 432
2022-03-06 04:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:13:30 | INFO | train_inner | epoch 432:     24 / 49 loss=1.231, nll_loss=0.244, ppl=1.18, wps=27508.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.418, loss_scale=32, train_wall=199, gb_free=21.6, wall=49887
2022-03-06 04:14:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:14:30 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.869 | nll_loss 13.542 | ppl 11924.7 | wps 46166.2 | wpb 510.9 | bsz 1 | num_updates 21025 | best_loss 8.499
2022-03-06 04:14:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21025 updates
2022-03-06 04:14:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:14:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:14:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 432 @ 21025 updates, score 13.869) (writing took 2.2772919898852706 seconds)
2022-03-06 04:14:32 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-06 04:14:32 | INFO | train | epoch 432 | loss 1.231 | nll_loss 0.244 | ppl 1.18 | wps 27480.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21025 | lr 0.000218088 | gnorm 0.418 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 49949
2022-03-06 04:14:32 | INFO | fairseq.trainer | begin training epoch 433
2022-03-06 04:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:14:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:16:25 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.84 | nll_loss 13.509 | ppl 11660.4 | wps 45894.8 | wpb 510.9 | bsz 1 | num_updates 21073 | best_loss 8.499
2022-03-06 04:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21073 updates
2022-03-06 04:16:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 433 @ 21073 updates, score 13.84) (writing took 2.2053716415539384 seconds)
2022-03-06 04:16:27 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-06 04:16:27 | INFO | train | epoch 433 | loss 1.23 | nll_loss 0.244 | ppl 1.18 | wps 26921.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21073 | lr 0.00021784 | gnorm 0.417 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50064
2022-03-06 04:16:27 | INFO | fairseq.trainer | begin training epoch 434
2022-03-06 04:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:17:28 | INFO | train_inner | epoch 434:     27 / 49 loss=1.23, nll_loss=0.244, ppl=1.18, wps=27251.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.419, loss_scale=32, train_wall=201, gb_free=21.6, wall=50125
2022-03-06 04:18:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:18:21 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.861 | nll_loss 13.531 | ppl 11838.5 | wps 46314 | wpb 510.9 | bsz 1 | num_updates 21122 | best_loss 8.499
2022-03-06 04:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21122 updates
2022-03-06 04:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 434 @ 21122 updates, score 13.861) (writing took 2.274617901071906 seconds)
2022-03-06 04:18:23 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-06 04:18:23 | INFO | train | epoch 434 | loss 1.23 | nll_loss 0.245 | ppl 1.18 | wps 27473.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21122 | lr 0.000217587 | gnorm 0.422 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50180
2022-03-06 04:18:23 | INFO | fairseq.trainer | begin training epoch 435
2022-03-06 04:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:20:17 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.826 | nll_loss 13.491 | ppl 11515.3 | wps 46620.3 | wpb 510.9 | bsz 1 | num_updates 21171 | best_loss 8.499
2022-03-06 04:20:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21171 updates
2022-03-06 04:20:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:20:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:20:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 435 @ 21171 updates, score 13.826) (writing took 2.196372289210558 seconds)
2022-03-06 04:20:19 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-06 04:20:19 | INFO | train | epoch 435 | loss 1.228 | nll_loss 0.242 | ppl 1.18 | wps 27491 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21171 | lr 0.000217335 | gnorm 0.414 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 50296
2022-03-06 04:20:19 | INFO | fairseq.trainer | begin training epoch 436
2022-03-06 04:20:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:21:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:21:26 | INFO | train_inner | epoch 436:     30 / 49 loss=1.228, nll_loss=0.243, ppl=1.18, wps=27257.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.415, loss_scale=32, train_wall=201, gb_free=21.6, wall=50363
2022-03-06 04:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:22:12 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.901 | nll_loss 13.574 | ppl 12191.8 | wps 47053.2 | wpb 510.9 | bsz 1 | num_updates 21219 | best_loss 8.499
2022-03-06 04:22:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21219 updates
2022-03-06 04:22:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:22:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:22:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 436 @ 21219 updates, score 13.901) (writing took 2.2779047107324004 seconds)
2022-03-06 04:22:14 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-06 04:22:14 | INFO | train | epoch 436 | loss 1.228 | nll_loss 0.243 | ppl 1.18 | wps 26905.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 21219 | lr 0.000217089 | gnorm 0.417 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 50411
2022-03-06 04:22:14 | INFO | fairseq.trainer | begin training epoch 437
2022-03-06 04:22:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:24:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:24:08 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.838 | nll_loss 13.512 | ppl 11684.3 | wps 46207.4 | wpb 510.9 | bsz 1 | num_updates 21268 | best_loss 8.499
2022-03-06 04:24:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21268 updates
2022-03-06 04:24:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:24:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:24:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 437 @ 21268 updates, score 13.838) (writing took 2.2099708318710327 seconds)
2022-03-06 04:24:10 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-06 04:24:10 | INFO | train | epoch 437 | loss 1.228 | nll_loss 0.243 | ppl 1.18 | wps 27501.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21268 | lr 0.000216839 | gnorm 0.418 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50527
2022-03-06 04:24:10 | INFO | fairseq.trainer | begin training epoch 438
2022-03-06 04:24:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:25:22 | INFO | train_inner | epoch 438:     32 / 49 loss=1.228, nll_loss=0.243, ppl=1.18, wps=27536.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.416, loss_scale=32, train_wall=199, gb_free=21.6, wall=50598
2022-03-06 04:25:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:26:03 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.793 | nll_loss 13.462 | ppl 11281.5 | wps 46360.8 | wpb 510.9 | bsz 1 | num_updates 21317 | best_loss 8.499
2022-03-06 04:26:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21317 updates
2022-03-06 04:26:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:26:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:26:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 438 @ 21317 updates, score 13.793) (writing took 2.2455437975004315 seconds)
2022-03-06 04:26:05 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-06 04:26:05 | INFO | train | epoch 438 | loss 1.227 | nll_loss 0.242 | ppl 1.18 | wps 27512.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 21317 | lr 0.000216589 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50642
2022-03-06 04:26:06 | INFO | fairseq.trainer | begin training epoch 439
2022-03-06 04:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:26:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:27:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:27:59 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.797 | nll_loss 13.464 | ppl 11299.7 | wps 46063.2 | wpb 510.9 | bsz 1 | num_updates 21365 | best_loss 8.499
2022-03-06 04:27:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21365 updates
2022-03-06 04:27:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:28:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:28:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 439 @ 21365 updates, score 13.797) (writing took 2.242687586694956 seconds)
2022-03-06 04:28:01 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-06 04:28:01 | INFO | train | epoch 439 | loss 1.228 | nll_loss 0.242 | ppl 1.18 | wps 26931.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21365 | lr 0.000216346 | gnorm 0.412 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50758
2022-03-06 04:28:01 | INFO | fairseq.trainer | begin training epoch 440
2022-03-06 04:28:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:29:19 | INFO | train_inner | epoch 440:     35 / 49 loss=1.228, nll_loss=0.243, ppl=1.18, wps=27286.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.415, loss_scale=32, train_wall=201, gb_free=21.6, wall=50836
2022-03-06 04:29:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:29:54 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 14.015 | nll_loss 13.687 | ppl 13192.9 | wps 47747.2 | wpb 510.9 | bsz 1 | num_updates 21414 | best_loss 8.499
2022-03-06 04:29:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21414 updates
2022-03-06 04:29:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:29:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:29:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 440 @ 21414 updates, score 14.015) (writing took 2.221006875857711 seconds)
2022-03-06 04:29:56 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-06 04:29:56 | INFO | train | epoch 440 | loss 1.228 | nll_loss 0.243 | ppl 1.18 | wps 27633 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21414 | lr 0.000216098 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50873
2022-03-06 04:29:56 | INFO | fairseq.trainer | begin training epoch 441
2022-03-06 04:29:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:31:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:31:48 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.807 | nll_loss 13.473 | ppl 11368.3 | wps 47686.1 | wpb 510.9 | bsz 1 | num_updates 21463 | best_loss 8.499
2022-03-06 04:31:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21463 updates
2022-03-06 04:31:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:31:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:31:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 441 @ 21463 updates, score 13.807) (writing took 2.1584510784596205 seconds)
2022-03-06 04:31:50 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-06 04:31:50 | INFO | train | epoch 441 | loss 1.227 | nll_loss 0.242 | ppl 1.18 | wps 27824.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21463 | lr 0.000215851 | gnorm 0.42 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 50987
2022-03-06 04:31:50 | INFO | fairseq.trainer | begin training epoch 442
2022-03-06 04:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:32:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:33:15 | INFO | train_inner | epoch 442:     38 / 49 loss=1.226, nll_loss=0.241, ppl=1.18, wps=27584.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.418, loss_scale=32, train_wall=199, gb_free=21.6, wall=51071
2022-03-06 04:33:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:33:42 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.793 | nll_loss 13.461 | ppl 11279 | wps 47965.8 | wpb 510.9 | bsz 1 | num_updates 21511 | best_loss 8.499
2022-03-06 04:33:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21511 updates
2022-03-06 04:33:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:33:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:33:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 442 @ 21511 updates, score 13.793) (writing took 2.2353815296664834 seconds)
2022-03-06 04:33:45 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-06 04:33:45 | INFO | train | epoch 442 | loss 1.226 | nll_loss 0.241 | ppl 1.18 | wps 27223.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21511 | lr 0.00021561 | gnorm 0.415 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51101
2022-03-06 04:33:45 | INFO | fairseq.trainer | begin training epoch 443
2022-03-06 04:33:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:35:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:35:37 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.891 | nll_loss 13.565 | ppl 12117.2 | wps 46059.7 | wpb 510.9 | bsz 1 | num_updates 21560 | best_loss 8.499
2022-03-06 04:35:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21560 updates
2022-03-06 04:35:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:35:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:35:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 443 @ 21560 updates, score 13.891) (writing took 2.1418727710843086 seconds)
2022-03-06 04:35:39 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-06 04:35:39 | INFO | train | epoch 443 | loss 1.226 | nll_loss 0.241 | ppl 1.18 | wps 27805.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21560 | lr 0.000215365 | gnorm 0.414 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51216
2022-03-06 04:35:39 | INFO | fairseq.trainer | begin training epoch 444
2022-03-06 04:35:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:37:08 | INFO | train_inner | epoch 444:     40 / 49 loss=1.226, nll_loss=0.241, ppl=1.18, wps=27825, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.413, loss_scale=32, train_wall=197, gb_free=21.6, wall=51304
2022-03-06 04:37:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:37:31 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.848 | nll_loss 13.518 | ppl 11732.5 | wps 48073.1 | wpb 510.9 | bsz 1 | num_updates 21609 | best_loss 8.499
2022-03-06 04:37:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21609 updates
2022-03-06 04:37:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:37:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:37:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 444 @ 21609 updates, score 13.848) (writing took 2.1995374336838722 seconds)
2022-03-06 04:37:33 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-06 04:37:33 | INFO | train | epoch 444 | loss 1.226 | nll_loss 0.241 | ppl 1.18 | wps 27785.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21609 | lr 0.000215121 | gnorm 0.41 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 51330
2022-03-06 04:37:33 | INFO | fairseq.trainer | begin training epoch 445
2022-03-06 04:37:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:37:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:39:26 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.879 | nll_loss 13.549 | ppl 11984.2 | wps 45456.9 | wpb 510.9 | bsz 1 | num_updates 21657 | best_loss 8.499
2022-03-06 04:39:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21657 updates
2022-03-06 04:39:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:39:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:39:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 445 @ 21657 updates, score 13.879) (writing took 2.1693880883976817 seconds)
2022-03-06 04:39:28 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-06 04:39:28 | INFO | train | epoch 445 | loss 1.225 | nll_loss 0.24 | ppl 1.18 | wps 27201.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21657 | lr 0.000214882 | gnorm 0.413 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51445
2022-03-06 04:39:28 | INFO | fairseq.trainer | begin training epoch 446
2022-03-06 04:39:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:41:03 | INFO | train_inner | epoch 446:     43 / 49 loss=1.225, nll_loss=0.24, ppl=1.18, wps=27593.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.411, loss_scale=32, train_wall=199, gb_free=21.6, wall=51540
2022-03-06 04:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:41:20 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.771 | nll_loss 13.442 | ppl 11126.1 | wps 48278.6 | wpb 510.9 | bsz 1 | num_updates 21706 | best_loss 8.499
2022-03-06 04:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21706 updates
2022-03-06 04:41:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:41:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:41:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 446 @ 21706 updates, score 13.771) (writing took 2.1465344950556755 seconds)
2022-03-06 04:41:22 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-06 04:41:22 | INFO | train | epoch 446 | loss 1.224 | nll_loss 0.239 | ppl 1.18 | wps 27893.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21706 | lr 0.00021464 | gnorm 0.41 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51558
2022-03-06 04:41:22 | INFO | fairseq.trainer | begin training epoch 447
2022-03-06 04:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:42:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:43:14 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.835 | nll_loss 13.507 | ppl 11641.9 | wps 48234.1 | wpb 510.9 | bsz 1 | num_updates 21754 | best_loss 8.499
2022-03-06 04:43:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21754 updates
2022-03-06 04:43:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:43:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:43:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 447 @ 21754 updates, score 13.835) (writing took 2.08376479241997 seconds)
2022-03-06 04:43:16 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-06 04:43:16 | INFO | train | epoch 447 | loss 1.224 | nll_loss 0.24 | ppl 1.18 | wps 27287.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21754 | lr 0.000214403 | gnorm 0.419 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51673
2022-03-06 04:43:16 | INFO | fairseq.trainer | begin training epoch 448
2022-03-06 04:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:44:57 | INFO | train_inner | epoch 448:     46 / 49 loss=1.224, nll_loss=0.24, ppl=1.18, wps=27638.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21800, lr=0.000214176, gnorm=0.415, loss_scale=32, train_wall=199, gb_free=21.6, wall=51774
2022-03-06 04:45:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:45:08 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.769 | nll_loss 13.437 | ppl 11087 | wps 47899.8 | wpb 510.9 | bsz 1 | num_updates 21803 | best_loss 8.499
2022-03-06 04:45:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21803 updates
2022-03-06 04:45:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:45:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:45:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 448 @ 21803 updates, score 13.769) (writing took 2.1165793258696795 seconds)
2022-03-06 04:45:10 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-06 04:45:10 | INFO | train | epoch 448 | loss 1.223 | nll_loss 0.239 | ppl 1.18 | wps 27863.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21803 | lr 0.000214162 | gnorm 0.41 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51787
2022-03-06 04:45:10 | INFO | fairseq.trainer | begin training epoch 449
2022-03-06 04:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:47:02 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.778 | nll_loss 13.447 | ppl 11169.8 | wps 47953.4 | wpb 510.9 | bsz 1 | num_updates 21852 | best_loss 8.499
2022-03-06 04:47:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21852 updates
2022-03-06 04:47:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:47:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:47:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 449 @ 21852 updates, score 13.778) (writing took 2.0768432961776853 seconds)
2022-03-06 04:47:04 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-06 04:47:04 | INFO | train | epoch 449 | loss 1.222 | nll_loss 0.238 | ppl 1.18 | wps 27875.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21852 | lr 0.000213921 | gnorm 0.412 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51901
2022-03-06 04:47:04 | INFO | fairseq.trainer | begin training epoch 450
2022-03-06 04:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:47:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:48:51 | INFO | train_inner | epoch 450:     49 / 49 loss=1.222, nll_loss=0.238, ppl=1.18, wps=27599.9, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=21900, lr=0.000213687, gnorm=0.415, loss_scale=32, train_wall=198, gb_free=21.6, wall=52008
2022-03-06 04:48:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:48:56 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.73 | nll_loss 13.395 | ppl 10774.8 | wps 48131 | wpb 510.9 | bsz 1 | num_updates 21900 | best_loss 8.499
2022-03-06 04:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21900 updates
2022-03-06 04:48:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:48:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:48:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 450 @ 21900 updates, score 13.73) (writing took 2.1390021918341517 seconds)
2022-03-06 04:48:58 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-06 04:48:58 | INFO | train | epoch 450 | loss 1.223 | nll_loss 0.239 | ppl 1.18 | wps 27238.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21900 | lr 0.000213687 | gnorm 0.417 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52015
2022-03-06 04:48:58 | INFO | fairseq.trainer | begin training epoch 451
2022-03-06 04:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:50:50 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.83 | nll_loss 13.5 | ppl 11588.3 | wps 46353.1 | wpb 510.9 | bsz 1 | num_updates 21949 | best_loss 8.499
2022-03-06 04:50:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21949 updates
2022-03-06 04:50:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:50:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:50:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 451 @ 21949 updates, score 13.83) (writing took 2.055340447463095 seconds)
2022-03-06 04:50:52 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-06 04:50:52 | INFO | train | epoch 451 | loss 1.222 | nll_loss 0.238 | ppl 1.18 | wps 27810.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21949 | lr 0.000213448 | gnorm 0.411 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52129
2022-03-06 04:50:52 | INFO | fairseq.trainer | begin training epoch 452
2022-03-06 04:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:52:44 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.856 | nll_loss 13.526 | ppl 11798.8 | wps 47916.7 | wpb 510.9 | bsz 1 | num_updates 21998 | best_loss 8.499
2022-03-06 04:52:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21998 updates
2022-03-06 04:52:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:52:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:52:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 452 @ 21998 updates, score 13.856) (writing took 2.069763334468007 seconds)
2022-03-06 04:52:46 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-06 04:52:46 | INFO | train | epoch 452 | loss 1.222 | nll_loss 0.238 | ppl 1.18 | wps 27868.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21998 | lr 0.00021321 | gnorm 0.414 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52243
2022-03-06 04:52:46 | INFO | fairseq.trainer | begin training epoch 453
2022-03-06 04:52:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:52:51 | INFO | train_inner | epoch 453:      2 / 49 loss=1.222, nll_loss=0.238, ppl=1.18, wps=27078.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.413, loss_scale=32, train_wall=197, gb_free=21.6, wall=52248
2022-03-06 04:53:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:54:38 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.838 | nll_loss 13.509 | ppl 11656 | wps 47661.1 | wpb 510.9 | bsz 1 | num_updates 22046 | best_loss 8.499
2022-03-06 04:54:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22046 updates
2022-03-06 04:54:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:54:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:54:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 453 @ 22046 updates, score 13.838) (writing took 2.029578525573015 seconds)
2022-03-06 04:54:40 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-06 04:54:40 | INFO | train | epoch 453 | loss 1.221 | nll_loss 0.237 | ppl 1.18 | wps 27280.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22046 | lr 0.000212978 | gnorm 0.409 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52357
2022-03-06 04:54:40 | INFO | fairseq.trainer | begin training epoch 454
2022-03-06 04:54:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:56:32 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.779 | nll_loss 13.449 | ppl 11183.9 | wps 47679.5 | wpb 510.9 | bsz 1 | num_updates 22095 | best_loss 8.499
2022-03-06 04:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22095 updates
2022-03-06 04:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:56:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:56:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 454 @ 22095 updates, score 13.779) (writing took 2.039178700186312 seconds)
2022-03-06 04:56:34 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-06 04:56:34 | INFO | train | epoch 454 | loss 1.221 | nll_loss 0.238 | ppl 1.18 | wps 27885.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22095 | lr 0.000212742 | gnorm 0.41 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52471
2022-03-06 04:56:34 | INFO | fairseq.trainer | begin training epoch 455
2022-03-06 04:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:46 | INFO | train_inner | epoch 455:      5 / 49 loss=1.221, nll_loss=0.237, ppl=1.18, wps=27641, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.41, loss_scale=32, train_wall=199, gb_free=21.6, wall=52482
2022-03-06 04:58:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:58:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:58:26 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.734 | nll_loss 13.403 | ppl 10831.6 | wps 48301.4 | wpb 510.9 | bsz 1 | num_updates 22143 | best_loss 8.499
2022-03-06 04:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22143 updates
2022-03-06 04:58:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:58:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 04:58:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 455 @ 22143 updates, score 13.734) (writing took 1.9949714867398143 seconds)
2022-03-06 04:58:28 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-06 04:58:28 | INFO | train | epoch 455 | loss 1.22 | nll_loss 0.237 | ppl 1.18 | wps 27332.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22143 | lr 0.000212511 | gnorm 0.409 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52585
2022-03-06 04:58:28 | INFO | fairseq.trainer | begin training epoch 456
2022-03-06 04:58:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:00:20 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.784 | nll_loss 13.452 | ppl 11206.4 | wps 47852.3 | wpb 510.9 | bsz 1 | num_updates 22192 | best_loss 8.499
2022-03-06 05:00:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22192 updates
2022-03-06 05:00:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:00:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:00:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 456 @ 22192 updates, score 13.784) (writing took 2.042105265893042 seconds)
2022-03-06 05:00:22 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-06 05:00:22 | INFO | train | epoch 456 | loss 1.22 | nll_loss 0.237 | ppl 1.18 | wps 27842.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22192 | lr 0.000212276 | gnorm 0.412 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52699
2022-03-06 05:00:22 | INFO | fairseq.trainer | begin training epoch 457
2022-03-06 05:00:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:00:40 | INFO | train_inner | epoch 457:      8 / 49 loss=1.22, nll_loss=0.236, ppl=1.18, wps=27649.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.41, loss_scale=32, train_wall=199, gb_free=21.6, wall=52717
2022-03-06 05:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:02:15 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.768 | nll_loss 13.435 | ppl 11071.7 | wps 45060.3 | wpb 510.9 | bsz 1 | num_updates 22241 | best_loss 8.499
2022-03-06 05:02:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22241 updates
2022-03-06 05:02:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:02:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:02:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 457 @ 22241 updates, score 13.768) (writing took 2.0031606685370207 seconds)
2022-03-06 05:02:17 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-06 05:02:17 | INFO | train | epoch 457 | loss 1.219 | nll_loss 0.236 | ppl 1.18 | wps 27806.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22241 | lr 0.000212042 | gnorm 0.408 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52814
2022-03-06 05:02:17 | INFO | fairseq.trainer | begin training epoch 458
2022-03-06 05:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:03:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:04:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:04:09 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.837 | nll_loss 13.509 | ppl 11655.7 | wps 48141.7 | wpb 510.9 | bsz 1 | num_updates 22289 | best_loss 8.499
2022-03-06 05:04:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22289 updates
2022-03-06 05:04:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:04:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 458 @ 22289 updates, score 13.837) (writing took 2.082375924102962 seconds)
2022-03-06 05:04:11 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-06 05:04:11 | INFO | train | epoch 458 | loss 1.219 | nll_loss 0.235 | ppl 1.18 | wps 27331.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22289 | lr 0.000211814 | gnorm 0.408 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52927
2022-03-06 05:04:11 | INFO | fairseq.trainer | begin training epoch 459
2022-03-06 05:04:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:04:35 | INFO | train_inner | epoch 459:     11 / 49 loss=1.219, nll_loss=0.236, ppl=1.18, wps=27628.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.407, loss_scale=32, train_wall=199, gb_free=21.6, wall=52952
2022-03-06 05:05:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:06:03 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.836 | nll_loss 13.507 | ppl 11641.7 | wps 48085.3 | wpb 510.9 | bsz 1 | num_updates 22338 | best_loss 8.499
2022-03-06 05:06:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22338 updates
2022-03-06 05:06:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:06:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:06:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 459 @ 22338 updates, score 13.836) (writing took 2.0073340823873878 seconds)
2022-03-06 05:06:05 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-06 05:06:05 | INFO | train | epoch 459 | loss 1.218 | nll_loss 0.235 | ppl 1.18 | wps 27865 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22338 | lr 0.000211582 | gnorm 0.408 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53041
2022-03-06 05:06:05 | INFO | fairseq.trainer | begin training epoch 460
2022-03-06 05:06:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:07:57 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.864 | nll_loss 13.534 | ppl 11863.6 | wps 47837.4 | wpb 510.9 | bsz 1 | num_updates 22387 | best_loss 8.499
2022-03-06 05:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22387 updates
2022-03-06 05:07:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:07:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:07:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 460 @ 22387 updates, score 13.864) (writing took 2.0376080721616745 seconds)
2022-03-06 05:07:59 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-06 05:07:59 | INFO | train | epoch 460 | loss 1.218 | nll_loss 0.235 | ppl 1.18 | wps 27878.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22387 | lr 0.00021135 | gnorm 0.409 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53155
2022-03-06 05:07:59 | INFO | fairseq.trainer | begin training epoch 461
2022-03-06 05:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:08:27 | INFO | train_inner | epoch 461:     13 / 49 loss=1.218, nll_loss=0.235, ppl=1.18, wps=27906.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.408, loss_scale=32, train_wall=197, gb_free=21.6, wall=53184
2022-03-06 05:08:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:09:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:09:51 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.874 | nll_loss 13.547 | ppl 11971.7 | wps 47368.5 | wpb 510.9 | bsz 1 | num_updates 22435 | best_loss 8.499
2022-03-06 05:09:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22435 updates
2022-03-06 05:09:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:09:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:09:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 461 @ 22435 updates, score 13.874) (writing took 1.9940070239827037 seconds)
2022-03-06 05:09:53 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-06 05:09:53 | INFO | train | epoch 461 | loss 1.218 | nll_loss 0.235 | ppl 1.18 | wps 27320.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22435 | lr 0.000211124 | gnorm 0.406 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53269
2022-03-06 05:09:53 | INFO | fairseq.trainer | begin training epoch 462
2022-03-06 05:09:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:11:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:11:45 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.771 | nll_loss 13.44 | ppl 11112 | wps 48241.5 | wpb 510.9 | bsz 1 | num_updates 22484 | best_loss 8.499
2022-03-06 05:11:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22484 updates
2022-03-06 05:11:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:11:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:11:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 462 @ 22484 updates, score 13.771) (writing took 2.0065698446705937 seconds)
2022-03-06 05:11:47 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-06 05:11:47 | INFO | train | epoch 462 | loss 1.217 | nll_loss 0.234 | ppl 1.18 | wps 27878.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22484 | lr 0.000210894 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53383
2022-03-06 05:11:47 | INFO | fairseq.trainer | begin training epoch 463
2022-03-06 05:11:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:12:22 | INFO | train_inner | epoch 463:     16 / 49 loss=1.217, nll_loss=0.235, ppl=1.18, wps=27654.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.406, loss_scale=32, train_wall=199, gb_free=21.6, wall=53419
2022-03-06 05:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:13:39 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.917 | nll_loss 13.593 | ppl 12357.6 | wps 48279.4 | wpb 510.9 | bsz 1 | num_updates 22533 | best_loss 8.499
2022-03-06 05:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22533 updates
2022-03-06 05:13:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:13:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:13:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 463 @ 22533 updates, score 13.917) (writing took 1.987223389558494 seconds)
2022-03-06 05:13:41 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-06 05:13:41 | INFO | train | epoch 463 | loss 1.217 | nll_loss 0.235 | ppl 1.18 | wps 27876.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22533 | lr 0.000210664 | gnorm 0.406 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53497
2022-03-06 05:13:41 | INFO | fairseq.trainer | begin training epoch 464
2022-03-06 05:13:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:14:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:15:32 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.834 | nll_loss 13.504 | ppl 11618 | wps 47906.7 | wpb 510.9 | bsz 1 | num_updates 22581 | best_loss 8.499
2022-03-06 05:15:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22581 updates
2022-03-06 05:15:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:15:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:15:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 464 @ 22581 updates, score 13.834) (writing took 2.0173772424459457 seconds)
2022-03-06 05:15:34 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-06 05:15:34 | INFO | train | epoch 464 | loss 1.216 | nll_loss 0.234 | ppl 1.18 | wps 27331.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22581 | lr 0.00021044 | gnorm 0.407 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53611
2022-03-06 05:15:35 | INFO | fairseq.trainer | begin training epoch 465
2022-03-06 05:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:16:17 | INFO | train_inner | epoch 465:     19 / 49 loss=1.217, nll_loss=0.234, ppl=1.18, wps=27653.4, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.407, loss_scale=32, train_wall=199, gb_free=21.6, wall=53653
2022-03-06 05:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:17:26 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.73 | nll_loss 13.399 | ppl 10798.8 | wps 47744.1 | wpb 510.9 | bsz 1 | num_updates 22630 | best_loss 8.499
2022-03-06 05:17:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22630 updates
2022-03-06 05:17:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:17:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:17:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 465 @ 22630 updates, score 13.73) (writing took 1.9506635619327426 seconds)
2022-03-06 05:17:28 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-06 05:17:28 | INFO | train | epoch 465 | loss 1.216 | nll_loss 0.234 | ppl 1.18 | wps 27894.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22630 | lr 0.000210212 | gnorm 0.405 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53725
2022-03-06 05:17:28 | INFO | fairseq.trainer | begin training epoch 466
2022-03-06 05:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:19:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:19:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:19:20 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.802 | nll_loss 13.473 | ppl 11368.1 | wps 48197.8 | wpb 510.9 | bsz 1 | num_updates 22678 | best_loss 8.499
2022-03-06 05:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22678 updates
2022-03-06 05:19:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:19:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:19:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 466 @ 22678 updates, score 13.802) (writing took 1.9805826637893915 seconds)
2022-03-06 05:19:22 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-06 05:19:22 | INFO | train | epoch 466 | loss 1.216 | nll_loss 0.234 | ppl 1.18 | wps 27302 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22678 | lr 0.00020999 | gnorm 0.411 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53839
2022-03-06 05:19:22 | INFO | fairseq.trainer | begin training epoch 467
2022-03-06 05:19:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:20:11 | INFO | train_inner | epoch 467:     22 / 49 loss=1.216, nll_loss=0.234, ppl=1.18, wps=27674.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.408, loss_scale=32, train_wall=199, gb_free=21.6, wall=53888
2022-03-06 05:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:21:14 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.871 | nll_loss 13.544 | ppl 11946.9 | wps 48274 | wpb 510.9 | bsz 1 | num_updates 22727 | best_loss 8.499
2022-03-06 05:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22727 updates
2022-03-06 05:21:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:21:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:21:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 467 @ 22727 updates, score 13.871) (writing took 1.933851676993072 seconds)
2022-03-06 05:21:16 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-06 05:21:16 | INFO | train | epoch 467 | loss 1.216 | nll_loss 0.234 | ppl 1.18 | wps 27940.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22727 | lr 0.000209763 | gnorm 0.406 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53953
2022-03-06 05:21:16 | INFO | fairseq.trainer | begin training epoch 468
2022-03-06 05:21:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:23:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:23:08 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.797 | nll_loss 13.468 | ppl 11333 | wps 47956.3 | wpb 510.9 | bsz 1 | num_updates 22776 | best_loss 8.499
2022-03-06 05:23:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22776 updates
2022-03-06 05:23:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:23:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:23:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 468 @ 22776 updates, score 13.797) (writing took 1.9601377760991454 seconds)
2022-03-06 05:23:10 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-06 05:23:10 | INFO | train | epoch 468 | loss 1.215 | nll_loss 0.233 | ppl 1.18 | wps 27842.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22776 | lr 0.000209537 | gnorm 0.404 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54067
2022-03-06 05:23:10 | INFO | fairseq.trainer | begin training epoch 469
2022-03-06 05:23:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:24:03 | INFO | train_inner | epoch 469:     24 / 49 loss=1.215, nll_loss=0.233, ppl=1.18, wps=27911.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.404, loss_scale=64, train_wall=197, gb_free=21.6, wall=54120
2022-03-06 05:24:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:24:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:25:02 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.844 | nll_loss 13.516 | ppl 11711.8 | wps 48348.4 | wpb 510.9 | bsz 1 | num_updates 22824 | best_loss 8.499
2022-03-06 05:25:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22824 updates
2022-03-06 05:25:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:25:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:25:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 469 @ 22824 updates, score 13.844) (writing took 1.9163921037688851 seconds)
2022-03-06 05:25:04 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-06 05:25:04 | INFO | train | epoch 469 | loss 1.214 | nll_loss 0.233 | ppl 1.18 | wps 27334.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22824 | lr 0.000209317 | gnorm 0.404 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54181
2022-03-06 05:25:04 | INFO | fairseq.trainer | begin training epoch 470
2022-03-06 05:25:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:26:56 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.858 | nll_loss 13.532 | ppl 11845.1 | wps 48278.6 | wpb 510.9 | bsz 1 | num_updates 22873 | best_loss 8.499
2022-03-06 05:26:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22873 updates
2022-03-06 05:26:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:26:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:26:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 470 @ 22873 updates, score 13.858) (writing took 1.9536853935569525 seconds)
2022-03-06 05:26:58 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-06 05:26:58 | INFO | train | epoch 470 | loss 1.214 | nll_loss 0.232 | ppl 1.17 | wps 27879.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22873 | lr 0.000209092 | gnorm 0.409 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54295
2022-03-06 05:26:58 | INFO | fairseq.trainer | begin training epoch 471
2022-03-06 05:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:27:58 | INFO | train_inner | epoch 471:     27 / 49 loss=1.214, nll_loss=0.232, ppl=1.17, wps=27669.3, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.408, loss_scale=32, train_wall=199, gb_free=21.6, wall=54355
2022-03-06 05:28:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:28:50 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.788 | nll_loss 13.459 | ppl 11261 | wps 47534.1 | wpb 510.9 | bsz 1 | num_updates 22922 | best_loss 8.499
2022-03-06 05:28:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22922 updates
2022-03-06 05:28:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:28:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 471 @ 22922 updates, score 13.788) (writing took 1.932034868746996 seconds)
2022-03-06 05:28:52 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-06 05:28:52 | INFO | train | epoch 471 | loss 1.213 | nll_loss 0.231 | ppl 1.17 | wps 27892.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22922 | lr 0.000208869 | gnorm 0.405 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54409
2022-03-06 05:28:52 | INFO | fairseq.trainer | begin training epoch 472
2022-03-06 05:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:29:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:30:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:30:44 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.812 | nll_loss 13.481 | ppl 11434 | wps 48241.5 | wpb 510.9 | bsz 1 | num_updates 22970 | best_loss 8.499
2022-03-06 05:30:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22970 updates
2022-03-06 05:30:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 472 @ 22970 updates, score 13.812) (writing took 1.949245972558856 seconds)
2022-03-06 05:30:46 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-06 05:30:46 | INFO | train | epoch 472 | loss 1.213 | nll_loss 0.232 | ppl 1.17 | wps 27332.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22970 | lr 0.000208651 | gnorm 0.408 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54523
2022-03-06 05:30:46 | INFO | fairseq.trainer | begin training epoch 473
2022-03-06 05:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:31:53 | INFO | train_inner | epoch 473:     30 / 49 loss=1.213, nll_loss=0.232, ppl=1.17, wps=27651.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.406, loss_scale=32, train_wall=199, gb_free=21.6, wall=54589
2022-03-06 05:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:32:38 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.836 | nll_loss 13.51 | ppl 11665.4 | wps 47632.2 | wpb 510.9 | bsz 1 | num_updates 23019 | best_loss 8.499
2022-03-06 05:32:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23019 updates
2022-03-06 05:32:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:32:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 473 @ 23019 updates, score 13.836) (writing took 1.9451723247766495 seconds)
2022-03-06 05:32:40 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-06 05:32:40 | INFO | train | epoch 473 | loss 1.213 | nll_loss 0.232 | ppl 1.17 | wps 27846.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23019 | lr 0.000208428 | gnorm 0.403 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54637
2022-03-06 05:32:40 | INFO | fairseq.trainer | begin training epoch 474
2022-03-06 05:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:34:33 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.93 | nll_loss 13.608 | ppl 12486.2 | wps 46506 | wpb 510.9 | bsz 1 | num_updates 23068 | best_loss 8.499
2022-03-06 05:34:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23068 updates
2022-03-06 05:34:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:34:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:34:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 474 @ 23068 updates, score 13.93) (writing took 1.9772005258128047 seconds)
2022-03-06 05:34:35 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-06 05:34:35 | INFO | train | epoch 474 | loss 1.212 | nll_loss 0.231 | ppl 1.17 | wps 27652 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23068 | lr 0.000208207 | gnorm 0.399 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54752
2022-03-06 05:34:35 | INFO | fairseq.trainer | begin training epoch 475
2022-03-06 05:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:35:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:35:49 | INFO | train_inner | epoch 475:     33 / 49 loss=1.212, nll_loss=0.231, ppl=1.17, wps=27419.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.4, loss_scale=32, train_wall=200, gb_free=21.6, wall=54826
2022-03-06 05:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:36:29 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.907 | nll_loss 13.581 | ppl 12250.7 | wps 45618.2 | wpb 510.9 | bsz 1 | num_updates 23116 | best_loss 8.499
2022-03-06 05:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23116 updates
2022-03-06 05:36:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:36:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 475 @ 23116 updates, score 13.907) (writing took 1.9353123074397445 seconds)
2022-03-06 05:36:31 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-06 05:36:31 | INFO | train | epoch 475 | loss 1.212 | nll_loss 0.231 | ppl 1.17 | wps 26912.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23116 | lr 0.000207991 | gnorm 0.402 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 54868
2022-03-06 05:36:31 | INFO | fairseq.trainer | begin training epoch 476
2022-03-06 05:36:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:38:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:38:24 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.825 | nll_loss 13.5 | ppl 11584.9 | wps 46028.8 | wpb 510.9 | bsz 1 | num_updates 23165 | best_loss 8.499
2022-03-06 05:38:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23165 updates
2022-03-06 05:38:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:38:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:38:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 476 @ 23165 updates, score 13.825) (writing took 1.9519347175955772 seconds)
2022-03-06 05:38:26 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-06 05:38:26 | INFO | train | epoch 476 | loss 1.211 | nll_loss 0.23 | ppl 1.17 | wps 27489.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23165 | lr 0.00020777 | gnorm 0.397 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 54983
2022-03-06 05:38:26 | INFO | fairseq.trainer | begin training epoch 477
2022-03-06 05:38:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:39:45 | INFO | train_inner | epoch 477:     35 / 49 loss=1.211, nll_loss=0.23, ppl=1.17, wps=27513.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.396, loss_scale=32, train_wall=199, gb_free=21.6, wall=55062
2022-03-06 05:40:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:40:20 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.883 | nll_loss 13.557 | ppl 12052.2 | wps 45890.2 | wpb 510.9 | bsz 1 | num_updates 23214 | best_loss 8.499
2022-03-06 05:40:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23214 updates
2022-03-06 05:40:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:40:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:40:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 477 @ 23214 updates, score 13.883) (writing took 1.9317757654935122 seconds)
2022-03-06 05:40:22 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-06 05:40:22 | INFO | train | epoch 477 | loss 1.211 | nll_loss 0.23 | ppl 1.17 | wps 27487.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23214 | lr 0.000207551 | gnorm 0.394 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 55099
2022-03-06 05:40:22 | INFO | fairseq.trainer | begin training epoch 478
2022-03-06 05:40:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:40:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:42:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:42:16 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.944 | nll_loss 13.623 | ppl 12615.4 | wps 46056.9 | wpb 510.9 | bsz 1 | num_updates 23262 | best_loss 8.499
2022-03-06 05:42:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23262 updates
2022-03-06 05:42:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:42:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:42:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 478 @ 23262 updates, score 13.944) (writing took 1.981007187627256 seconds)
2022-03-06 05:42:18 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-06 05:42:18 | INFO | train | epoch 478 | loss 1.211 | nll_loss 0.23 | ppl 1.17 | wps 26914.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23262 | lr 0.000207337 | gnorm 0.406 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 55214
2022-03-06 05:42:18 | INFO | fairseq.trainer | begin training epoch 479
2022-03-06 05:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:43:43 | INFO | train_inner | epoch 479:     38 / 49 loss=1.211, nll_loss=0.231, ppl=1.17, wps=27261.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.404, loss_scale=32, train_wall=201, gb_free=21.6, wall=55300
2022-03-06 05:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:44:11 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.897 | nll_loss 13.572 | ppl 12178.3 | wps 46448.3 | wpb 510.9 | bsz 1 | num_updates 23311 | best_loss 8.499
2022-03-06 05:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23311 updates
2022-03-06 05:44:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:44:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:44:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 479 @ 23311 updates, score 13.897) (writing took 1.918641391210258 seconds)
2022-03-06 05:44:13 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-06 05:44:13 | INFO | train | epoch 479 | loss 1.211 | nll_loss 0.23 | ppl 1.17 | wps 27512.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23311 | lr 0.000207119 | gnorm 0.404 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 55330
2022-03-06 05:44:13 | INFO | fairseq.trainer | begin training epoch 480
2022-03-06 05:44:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:45:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:46:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:46:07 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.817 | nll_loss 13.49 | ppl 11509 | wps 45999 | wpb 510.9 | bsz 1 | num_updates 23359 | best_loss 8.499
2022-03-06 05:46:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23359 updates
2022-03-06 05:46:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:46:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:46:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 480 @ 23359 updates, score 13.817) (writing took 1.959457065910101 seconds)
2022-03-06 05:46:09 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-06 05:46:09 | INFO | train | epoch 480 | loss 1.21 | nll_loss 0.229 | ppl 1.17 | wps 26930.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23359 | lr 0.000206906 | gnorm 0.4 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 55445
2022-03-06 05:46:09 | INFO | fairseq.trainer | begin training epoch 481
2022-03-06 05:46:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:47:41 | INFO | train_inner | epoch 481:     41 / 49 loss=1.21, nll_loss=0.23, ppl=1.17, wps=27271.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.4, loss_scale=32, train_wall=201, gb_free=21.6, wall=55538
2022-03-06 05:47:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:48:02 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.853 | nll_loss 13.521 | ppl 11754.2 | wps 46272.5 | wpb 510.9 | bsz 1 | num_updates 23408 | best_loss 8.499
2022-03-06 05:48:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23408 updates
2022-03-06 05:48:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:48:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:48:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 481 @ 23408 updates, score 13.853) (writing took 1.9285029890015721 seconds)
2022-03-06 05:48:04 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-06 05:48:04 | INFO | train | epoch 481 | loss 1.21 | nll_loss 0.23 | ppl 1.17 | wps 27491.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23408 | lr 0.000206689 | gnorm 0.402 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 55561
2022-03-06 05:48:04 | INFO | fairseq.trainer | begin training epoch 482
2022-03-06 05:48:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:49:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:49:58 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 13.781 | nll_loss 13.451 | ppl 11199.9 | wps 45881.3 | wpb 510.9 | bsz 1 | num_updates 23457 | best_loss 8.499
2022-03-06 05:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23457 updates
2022-03-06 05:49:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:50:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:50:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 482 @ 23457 updates, score 13.781) (writing took 1.9799221884459257 seconds)
2022-03-06 05:50:00 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-06 05:50:00 | INFO | train | epoch 482 | loss 1.209 | nll_loss 0.229 | ppl 1.17 | wps 27472.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23457 | lr 0.000206473 | gnorm 0.404 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 55677
2022-03-06 05:50:00 | INFO | fairseq.trainer | begin training epoch 483
2022-03-06 05:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:50:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:51:39 | INFO | train_inner | epoch 483:     44 / 49 loss=1.209, nll_loss=0.229, ppl=1.17, wps=27262, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.403, loss_scale=32, train_wall=201, gb_free=21.6, wall=55775
2022-03-06 05:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:51:54 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.815 | nll_loss 13.488 | ppl 11489 | wps 45991.5 | wpb 510.9 | bsz 1 | num_updates 23505 | best_loss 8.499
2022-03-06 05:51:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23505 updates
2022-03-06 05:51:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:51:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 483 @ 23505 updates, score 13.815) (writing took 1.9081739680841565 seconds)
2022-03-06 05:51:55 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-06 05:51:55 | INFO | train | epoch 483 | loss 1.209 | nll_loss 0.228 | ppl 1.17 | wps 26942 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23505 | lr 0.000206262 | gnorm 0.401 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 55792
2022-03-06 05:51:56 | INFO | fairseq.trainer | begin training epoch 484
2022-03-06 05:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:53:49 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.9 | nll_loss 13.573 | ppl 12182.6 | wps 45615.3 | wpb 510.9 | bsz 1 | num_updates 23554 | best_loss 8.499
2022-03-06 05:53:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23554 updates
2022-03-06 05:53:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:53:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 484 @ 23554 updates, score 13.9) (writing took 1.95638947468251 seconds)
2022-03-06 05:53:51 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-06 05:53:51 | INFO | train | epoch 484 | loss 1.209 | nll_loss 0.229 | ppl 1.17 | wps 27484.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23554 | lr 0.000206048 | gnorm 0.402 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 55908
2022-03-06 05:53:51 | INFO | fairseq.trainer | begin training epoch 485
2022-03-06 05:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:55:34 | INFO | train_inner | epoch 485:     46 / 49 loss=1.209, nll_loss=0.229, ppl=1.17, wps=27547.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23600, lr=0.000205847, gnorm=0.399, loss_scale=32, train_wall=199, gb_free=21.6, wall=56011
2022-03-06 05:55:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:55:45 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.726 | nll_loss 13.396 | ppl 10776.9 | wps 46223 | wpb 510.9 | bsz 1 | num_updates 23603 | best_loss 8.499
2022-03-06 05:55:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23603 updates
2022-03-06 05:55:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:55:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:55:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 485 @ 23603 updates, score 13.726) (writing took 1.923432475887239 seconds)
2022-03-06 05:55:47 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-06 05:55:47 | INFO | train | epoch 485 | loss 1.208 | nll_loss 0.228 | ppl 1.17 | wps 27540.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23603 | lr 0.000205834 | gnorm 0.395 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 56023
2022-03-06 05:55:47 | INFO | fairseq.trainer | begin training epoch 486
2022-03-06 05:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:56:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:57:40 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 14.009 | nll_loss 13.689 | ppl 13210.9 | wps 45630.3 | wpb 510.9 | bsz 1 | num_updates 23651 | best_loss 8.499
2022-03-06 05:57:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23651 updates
2022-03-06 05:57:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:57:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 486 @ 23651 updates, score 14.009) (writing took 1.9376352550461888 seconds)
2022-03-06 05:57:42 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-06 05:57:42 | INFO | train | epoch 486 | loss 1.207 | nll_loss 0.228 | ppl 1.17 | wps 26927.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23651 | lr 0.000205625 | gnorm 0.395 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 56139
2022-03-06 05:57:42 | INFO | fairseq.trainer | begin training epoch 487
2022-03-06 05:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:59:31 | INFO | train_inner | epoch 487:     49 / 49 loss=1.208, nll_loss=0.228, ppl=1.17, wps=27276.2, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=23700, lr=0.000205412, gnorm=0.4, loss_scale=32, train_wall=200, gb_free=21.6, wall=56248
2022-03-06 05:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:59:36 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.783 | nll_loss 13.457 | ppl 11245.2 | wps 46460.8 | wpb 510.9 | bsz 1 | num_updates 23700 | best_loss 8.499
2022-03-06 05:59:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23700 updates
2022-03-06 05:59:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:59:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 05:59:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 487 @ 23700 updates, score 13.783) (writing took 1.905209206044674 seconds)
2022-03-06 05:59:37 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-06 05:59:37 | INFO | train | epoch 487 | loss 1.208 | nll_loss 0.228 | ppl 1.17 | wps 27549.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23700 | lr 0.000205412 | gnorm 0.402 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 56254
2022-03-06 05:59:37 | INFO | fairseq.trainer | begin training epoch 488
2022-03-06 05:59:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:01:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:01:31 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.959 | nll_loss 13.639 | ppl 12757.8 | wps 46036.2 | wpb 510.9 | bsz 1 | num_updates 23749 | best_loss 8.499
2022-03-06 06:01:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23749 updates
2022-03-06 06:01:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:01:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:01:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 488 @ 23749 updates, score 13.959) (writing took 1.9511857638135552 seconds)
2022-03-06 06:01:33 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-06 06:01:33 | INFO | train | epoch 488 | loss 1.207 | nll_loss 0.227 | ppl 1.17 | wps 27535.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23749 | lr 0.0002052 | gnorm 0.394 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 56370
2022-03-06 06:01:33 | INFO | fairseq.trainer | begin training epoch 489
2022-03-06 06:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:02:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:03:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:03:26 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.86 | nll_loss 13.534 | ppl 11863.8 | wps 45940 | wpb 510.9 | bsz 1 | num_updates 23797 | best_loss 8.499
2022-03-06 06:03:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23797 updates
2022-03-06 06:03:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:03:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:03:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 489 @ 23797 updates, score 13.86) (writing took 1.930535047315061 seconds)
2022-03-06 06:03:28 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-06 06:03:28 | INFO | train | epoch 489 | loss 1.207 | nll_loss 0.227 | ppl 1.17 | wps 26950.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23797 | lr 0.000204993 | gnorm 0.399 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 56485
2022-03-06 06:03:28 | INFO | fairseq.trainer | begin training epoch 490
2022-03-06 06:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:03:35 | INFO | train_inner | epoch 490:      3 / 49 loss=1.207, nll_loss=0.227, ppl=1.17, wps=26547.3, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.396, loss_scale=32, train_wall=201, gb_free=21.6, wall=56492
2022-03-06 06:05:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:05:22 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.802 | nll_loss 13.476 | ppl 11394.3 | wps 45959.4 | wpb 510.9 | bsz 1 | num_updates 23846 | best_loss 8.499
2022-03-06 06:05:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23846 updates
2022-03-06 06:05:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:05:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:05:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 490 @ 23846 updates, score 13.802) (writing took 1.9368359921500087 seconds)
2022-03-06 06:05:24 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-06 06:05:24 | INFO | train | epoch 490 | loss 1.206 | nll_loss 0.227 | ppl 1.17 | wps 27500.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23846 | lr 0.000204782 | gnorm 0.4 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 56601
2022-03-06 06:05:24 | INFO | fairseq.trainer | begin training epoch 491
2022-03-06 06:05:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:07:17 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.942 | nll_loss 13.619 | ppl 12582.3 | wps 46325.7 | wpb 510.9 | bsz 1 | num_updates 23895 | best_loss 8.499
2022-03-06 06:07:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23895 updates
2022-03-06 06:07:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:07:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 491 @ 23895 updates, score 13.942) (writing took 1.9174049012362957 seconds)
2022-03-06 06:07:19 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-06 06:07:19 | INFO | train | epoch 491 | loss 1.206 | nll_loss 0.227 | ppl 1.17 | wps 27526.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23895 | lr 0.000204572 | gnorm 0.399 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 56716
2022-03-06 06:07:19 | INFO | fairseq.trainer | begin training epoch 492
2022-03-06 06:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:07:31 | INFO | train_inner | epoch 492:      5 / 49 loss=1.206, nll_loss=0.227, ppl=1.17, wps=27547.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.4, loss_scale=64, train_wall=199, gb_free=21.6, wall=56727
2022-03-06 06:07:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:09:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:09:13 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.901 | nll_loss 13.579 | ppl 12239.8 | wps 46227.2 | wpb 510.9 | bsz 1 | num_updates 23943 | best_loss 8.499
2022-03-06 06:09:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23943 updates
2022-03-06 06:09:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:09:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:09:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 492 @ 23943 updates, score 13.901) (writing took 1.9889783971011639 seconds)
2022-03-06 06:09:15 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-06 06:09:15 | INFO | train | epoch 492 | loss 1.206 | nll_loss 0.227 | ppl 1.17 | wps 26949.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23943 | lr 0.000204367 | gnorm 0.405 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 56832
2022-03-06 06:09:15 | INFO | fairseq.trainer | begin training epoch 493
2022-03-06 06:09:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:11:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:11:08 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.844 | nll_loss 13.52 | ppl 11749 | wps 46434.9 | wpb 510.9 | bsz 1 | num_updates 23992 | best_loss 8.499
2022-03-06 06:11:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23992 updates
2022-03-06 06:11:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:11:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:11:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 493 @ 23992 updates, score 13.844) (writing took 1.9177834279835224 seconds)
2022-03-06 06:11:10 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-06 06:11:10 | INFO | train | epoch 493 | loss 1.206 | nll_loss 0.226 | ppl 1.17 | wps 27552.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 23992 | lr 0.000204158 | gnorm 0.396 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 56947
2022-03-06 06:11:10 | INFO | fairseq.trainer | begin training epoch 494
2022-03-06 06:11:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:11:28 | INFO | train_inner | epoch 494:      8 / 49 loss=1.206, nll_loss=0.226, ppl=1.17, wps=27304.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.399, loss_scale=32, train_wall=201, gb_free=21.6, wall=56965
2022-03-06 06:12:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:12:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:13:04 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.863 | nll_loss 13.538 | ppl 11897 | wps 46121.8 | wpb 510.9 | bsz 1 | num_updates 24040 | best_loss 8.499
2022-03-06 06:13:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24040 updates
2022-03-06 06:13:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:13:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:13:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 494 @ 24040 updates, score 13.863) (writing took 1.9529472226276994 seconds)
2022-03-06 06:13:06 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-06 06:13:06 | INFO | train | epoch 494 | loss 1.204 | nll_loss 0.225 | ppl 1.17 | wps 26998.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24040 | lr 0.000203954 | gnorm 0.395 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57062
2022-03-06 06:13:06 | INFO | fairseq.trainer | begin training epoch 495
2022-03-06 06:13:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:14:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:14:59 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 13.793 | nll_loss 13.463 | ppl 11293.4 | wps 46024.6 | wpb 510.9 | bsz 1 | num_updates 24089 | best_loss 8.499
2022-03-06 06:14:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24089 updates
2022-03-06 06:14:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:15:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:15:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 495 @ 24089 updates, score 13.793) (writing took 1.944069916382432 seconds)
2022-03-06 06:15:01 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-06 06:15:01 | INFO | train | epoch 495 | loss 1.204 | nll_loss 0.225 | ppl 1.17 | wps 27472.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24089 | lr 0.000203747 | gnorm 0.397 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 57178
2022-03-06 06:15:01 | INFO | fairseq.trainer | begin training epoch 496
2022-03-06 06:15:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:15:26 | INFO | train_inner | epoch 496:     11 / 49 loss=1.204, nll_loss=0.225, ppl=1.17, wps=27292.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.397, loss_scale=32, train_wall=201, gb_free=21.6, wall=57203
2022-03-06 06:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:16:55 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.81 | nll_loss 13.482 | ppl 11445.2 | wps 46435.3 | wpb 510.9 | bsz 1 | num_updates 24138 | best_loss 8.499
2022-03-06 06:16:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24138 updates
2022-03-06 06:16:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:16:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:16:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 496 @ 24138 updates, score 13.81) (writing took 2.0064770318567753 seconds)
2022-03-06 06:16:57 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-06 06:16:57 | INFO | train | epoch 496 | loss 1.204 | nll_loss 0.225 | ppl 1.17 | wps 27482.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24138 | lr 0.00020354 | gnorm 0.401 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 57294
2022-03-06 06:16:57 | INFO | fairseq.trainer | begin training epoch 497
2022-03-06 06:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:17:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:18:50 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.848 | nll_loss 13.523 | ppl 11775 | wps 46193.8 | wpb 510.9 | bsz 1 | num_updates 24186 | best_loss 8.499
2022-03-06 06:18:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24186 updates
2022-03-06 06:18:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:18:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:18:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 497 @ 24186 updates, score 13.848) (writing took 1.9334736112505198 seconds)
2022-03-06 06:18:52 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-06 06:18:52 | INFO | train | epoch 497 | loss 1.204 | nll_loss 0.226 | ppl 1.17 | wps 26976.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24186 | lr 0.000203338 | gnorm 0.395 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57409
2022-03-06 06:18:52 | INFO | fairseq.trainer | begin training epoch 498
2022-03-06 06:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:19:24 | INFO | train_inner | epoch 498:     14 / 49 loss=1.204, nll_loss=0.226, ppl=1.17, wps=27278.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.397, loss_scale=32, train_wall=201, gb_free=21.6, wall=57441
2022-03-06 06:20:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:20:46 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.831 | nll_loss 13.503 | ppl 11608.4 | wps 46290.1 | wpb 510.9 | bsz 1 | num_updates 24235 | best_loss 8.499
2022-03-06 06:20:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24235 updates
2022-03-06 06:20:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:20:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:20:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 498 @ 24235 updates, score 13.831) (writing took 1.9466534107923508 seconds)
2022-03-06 06:20:48 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-06 06:20:48 | INFO | train | epoch 498 | loss 1.204 | nll_loss 0.225 | ppl 1.17 | wps 27517.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24235 | lr 0.000203132 | gnorm 0.395 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 57525
2022-03-06 06:20:48 | INFO | fairseq.trainer | begin training epoch 499
2022-03-06 06:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:22:41 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.827 | nll_loss 13.502 | ppl 11601.4 | wps 46464.3 | wpb 510.9 | bsz 1 | num_updates 24284 | best_loss 8.499
2022-03-06 06:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24284 updates
2022-03-06 06:22:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:22:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:22:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 499 @ 24284 updates, score 13.827) (writing took 1.9319052323698997 seconds)
2022-03-06 06:22:43 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-06 06:22:43 | INFO | train | epoch 499 | loss 1.204 | nll_loss 0.225 | ppl 1.17 | wps 27510.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24284 | lr 0.000202927 | gnorm 0.396 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 57640
2022-03-06 06:22:43 | INFO | fairseq.trainer | begin training epoch 500
2022-03-06 06:22:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:23:19 | INFO | train_inner | epoch 500:     16 / 49 loss=1.204, nll_loss=0.225, ppl=1.17, wps=27552.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.395, loss_scale=64, train_wall=199, gb_free=21.6, wall=57676
2022-03-06 06:23:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:24:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:24:37 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.862 | nll_loss 13.539 | ppl 11900.1 | wps 45988.4 | wpb 510.9 | bsz 1 | num_updates 24332 | best_loss 8.499
2022-03-06 06:24:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24332 updates
2022-03-06 06:24:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:24:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:24:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 500 @ 24332 updates, score 13.862) (writing took 1.9871048796921968 seconds)
2022-03-06 06:24:39 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-06 06:24:39 | INFO | train | epoch 500 | loss 1.203 | nll_loss 0.224 | ppl 1.17 | wps 26913 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24332 | lr 0.000202727 | gnorm 0.397 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 57756
2022-03-06 06:24:39 | INFO | fairseq.trainer | begin training epoch 501
2022-03-06 06:24:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:26:33 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.849 | nll_loss 13.522 | ppl 11759.6 | wps 45258.2 | wpb 510.9 | bsz 1 | num_updates 24381 | best_loss 8.499
2022-03-06 06:26:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24381 updates
2022-03-06 06:26:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:26:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:26:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 501 @ 24381 updates, score 13.849) (writing took 1.9349306439980865 seconds)
2022-03-06 06:26:35 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-06 06:26:35 | INFO | train | epoch 501 | loss 1.202 | nll_loss 0.224 | ppl 1.17 | wps 27468.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24381 | lr 0.000202523 | gnorm 0.396 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 57871
2022-03-06 06:26:35 | INFO | fairseq.trainer | begin training epoch 502
2022-03-06 06:26:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:27:17 | INFO | train_inner | epoch 502:     19 / 49 loss=1.202, nll_loss=0.224, ppl=1.17, wps=27246.9, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.394, loss_scale=32, train_wall=201, gb_free=21.6, wall=57914
2022-03-06 06:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:28:28 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.861 | nll_loss 13.535 | ppl 11866.2 | wps 46078.4 | wpb 510.9 | bsz 1 | num_updates 24430 | best_loss 8.499
2022-03-06 06:28:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24430 updates
2022-03-06 06:28:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:28:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:28:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 502 @ 24430 updates, score 13.861) (writing took 1.9403485786169767 seconds)
2022-03-06 06:28:30 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-06 06:28:30 | INFO | train | epoch 502 | loss 1.202 | nll_loss 0.224 | ppl 1.17 | wps 27491 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24430 | lr 0.00020232 | gnorm 0.392 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 57987
2022-03-06 06:28:30 | INFO | fairseq.trainer | begin training epoch 503
2022-03-06 06:28:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:28:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:30:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:30:24 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.884 | nll_loss 13.563 | ppl 12102.1 | wps 45978.6 | wpb 510.9 | bsz 1 | num_updates 24478 | best_loss 8.499
2022-03-06 06:30:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24478 updates
2022-03-06 06:30:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:30:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:30:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 503 @ 24478 updates, score 13.884) (writing took 2.023228614591062 seconds)
2022-03-06 06:30:26 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-06 06:30:26 | INFO | train | epoch 503 | loss 1.202 | nll_loss 0.224 | ppl 1.17 | wps 26910.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24478 | lr 0.000202121 | gnorm 0.397 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 58103
2022-03-06 06:30:26 | INFO | fairseq.trainer | begin training epoch 504
2022-03-06 06:30:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:31:15 | INFO | train_inner | epoch 504:     22 / 49 loss=1.202, nll_loss=0.224, ppl=1.17, wps=27260.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.395, loss_scale=32, train_wall=201, gb_free=21.6, wall=58152
2022-03-06 06:32:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:32:20 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.73 | nll_loss 13.4 | ppl 10806.5 | wps 46171.9 | wpb 510.9 | bsz 1 | num_updates 24527 | best_loss 8.499
2022-03-06 06:32:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24527 updates
2022-03-06 06:32:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:32:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:32:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 504 @ 24527 updates, score 13.73) (writing took 1.9863762045279145 seconds)
2022-03-06 06:32:21 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-06 06:32:21 | INFO | train | epoch 504 | loss 1.202 | nll_loss 0.224 | ppl 1.17 | wps 27479.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24527 | lr 0.000201919 | gnorm 0.391 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 58218
2022-03-06 06:32:22 | INFO | fairseq.trainer | begin training epoch 505
2022-03-06 06:32:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:33:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:34:15 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.847 | nll_loss 13.523 | ppl 11770.1 | wps 45815.1 | wpb 510.9 | bsz 1 | num_updates 24575 | best_loss 8.499
2022-03-06 06:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24575 updates
2022-03-06 06:34:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:34:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:34:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 505 @ 24575 updates, score 13.847) (writing took 1.9435556819662452 seconds)
2022-03-06 06:34:17 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-06 06:34:17 | INFO | train | epoch 505 | loss 1.201 | nll_loss 0.223 | ppl 1.17 | wps 26886.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 24575 | lr 0.000201722 | gnorm 0.392 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 58334
2022-03-06 06:34:17 | INFO | fairseq.trainer | begin training epoch 506
2022-03-06 06:34:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:35:13 | INFO | train_inner | epoch 506:     25 / 49 loss=1.201, nll_loss=0.223, ppl=1.17, wps=27244.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.392, loss_scale=32, train_wall=201, gb_free=21.6, wall=58390
2022-03-06 06:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:36:11 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.948 | nll_loss 13.629 | ppl 12665.3 | wps 45643 | wpb 510.9 | bsz 1 | num_updates 24624 | best_loss 8.499
2022-03-06 06:36:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24624 updates
2022-03-06 06:36:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:36:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 506 @ 24624 updates, score 13.948) (writing took 1.9631825368851423 seconds)
2022-03-06 06:36:13 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-06 06:36:13 | INFO | train | epoch 506 | loss 1.201 | nll_loss 0.223 | ppl 1.17 | wps 27455.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24624 | lr 0.000201521 | gnorm 0.394 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 58450
2022-03-06 06:36:13 | INFO | fairseq.trainer | begin training epoch 507
2022-03-06 06:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:38:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:38:07 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.806 | nll_loss 13.482 | ppl 11439.6 | wps 46243.7 | wpb 510.9 | bsz 1 | num_updates 24673 | best_loss 8.499
2022-03-06 06:38:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24673 updates
2022-03-06 06:38:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:38:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:38:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 507 @ 24673 updates, score 13.806) (writing took 1.9404974039644003 seconds)
2022-03-06 06:38:08 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-06 06:38:08 | INFO | train | epoch 507 | loss 1.201 | nll_loss 0.223 | ppl 1.17 | wps 27521.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24673 | lr 0.000201321 | gnorm 0.399 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 58565
2022-03-06 06:38:09 | INFO | fairseq.trainer | begin training epoch 508
2022-03-06 06:38:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:38:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:39:11 | INFO | train_inner | epoch 508:     28 / 49 loss=1.201, nll_loss=0.223, ppl=1.17, wps=27262.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.396, loss_scale=32, train_wall=201, gb_free=21.6, wall=58628
2022-03-06 06:39:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:40:02 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.793 | nll_loss 13.466 | ppl 11314.6 | wps 45622.9 | wpb 510.9 | bsz 1 | num_updates 24721 | best_loss 8.499
2022-03-06 06:40:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24721 updates
2022-03-06 06:40:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:40:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:40:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 508 @ 24721 updates, score 13.793) (writing took 1.9508720776066184 seconds)
2022-03-06 06:40:04 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-06 06:40:04 | INFO | train | epoch 508 | loss 1.2 | nll_loss 0.222 | ppl 1.17 | wps 26937.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24721 | lr 0.000201125 | gnorm 0.395 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 58681
2022-03-06 06:40:04 | INFO | fairseq.trainer | begin training epoch 509
2022-03-06 06:40:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:41:58 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.812 | nll_loss 13.488 | ppl 11489 | wps 46026.1 | wpb 510.9 | bsz 1 | num_updates 24770 | best_loss 8.499
2022-03-06 06:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24770 updates
2022-03-06 06:41:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:41:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:41:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 509 @ 24770 updates, score 13.812) (writing took 1.9147561071440578 seconds)
2022-03-06 06:41:59 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-06 06:41:59 | INFO | train | epoch 509 | loss 1.2 | nll_loss 0.222 | ppl 1.17 | wps 27530 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24770 | lr 0.000200926 | gnorm 0.394 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 58796
2022-03-06 06:41:59 | INFO | fairseq.trainer | begin training epoch 510
2022-03-06 06:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:43:07 | INFO | train_inner | epoch 510:     30 / 49 loss=1.2, nll_loss=0.222, ppl=1.17, wps=27551.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.395, loss_scale=32, train_wall=199, gb_free=21.6, wall=58864
2022-03-06 06:43:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:43:53 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.776 | nll_loss 13.448 | ppl 11173.7 | wps 46148.5 | wpb 510.9 | bsz 1 | num_updates 24819 | best_loss 8.499
2022-03-06 06:43:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24819 updates
2022-03-06 06:43:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:43:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:43:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 510 @ 24819 updates, score 13.776) (writing took 2.004828166216612 seconds)
2022-03-06 06:43:55 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-06 06:43:55 | INFO | train | epoch 510 | loss 1.2 | nll_loss 0.222 | ppl 1.17 | wps 27486.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24819 | lr 0.000200728 | gnorm 0.394 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 58912
2022-03-06 06:43:55 | INFO | fairseq.trainer | begin training epoch 511
2022-03-06 06:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:43:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:45:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:45:49 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.837 | nll_loss 13.512 | ppl 11681.2 | wps 46222.3 | wpb 510.9 | bsz 1 | num_updates 24867 | best_loss 8.499
2022-03-06 06:45:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24867 updates
2022-03-06 06:45:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:45:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:45:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 511 @ 24867 updates, score 13.837) (writing took 1.935076242312789 seconds)
2022-03-06 06:45:51 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-06 06:45:51 | INFO | train | epoch 511 | loss 1.198 | nll_loss 0.221 | ppl 1.17 | wps 26933.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24867 | lr 0.000200534 | gnorm 0.388 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 59027
2022-03-06 06:45:51 | INFO | fairseq.trainer | begin training epoch 512
2022-03-06 06:45:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:47:05 | INFO | train_inner | epoch 512:     33 / 49 loss=1.199, nll_loss=0.221, ppl=1.17, wps=27261.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.391, loss_scale=32, train_wall=201, gb_free=21.6, wall=59102
2022-03-06 06:47:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:47:44 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.889 | nll_loss 13.567 | ppl 12132.9 | wps 46307.5 | wpb 510.9 | bsz 1 | num_updates 24916 | best_loss 8.499
2022-03-06 06:47:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24916 updates
2022-03-06 06:47:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:47:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:47:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 512 @ 24916 updates, score 13.889) (writing took 2.0869724210351706 seconds)
2022-03-06 06:47:46 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-06 06:47:46 | INFO | train | epoch 512 | loss 1.199 | nll_loss 0.222 | ppl 1.17 | wps 27465 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24916 | lr 0.000200337 | gnorm 0.396 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 59143
2022-03-06 06:47:46 | INFO | fairseq.trainer | begin training epoch 513
2022-03-06 06:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:49:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:49:40 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.931 | nll_loss 13.609 | ppl 12497.1 | wps 46386.5 | wpb 510.9 | bsz 1 | num_updates 24965 | best_loss 8.499
2022-03-06 06:49:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24965 updates
2022-03-06 06:49:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:49:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:49:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 513 @ 24965 updates, score 13.931) (writing took 1.9078822536394 seconds)
2022-03-06 06:49:42 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-06 06:49:42 | INFO | train | epoch 513 | loss 1.198 | nll_loss 0.221 | ppl 1.17 | wps 27564.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 24965 | lr 0.00020014 | gnorm 0.388 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 59258
2022-03-06 06:49:42 | INFO | fairseq.trainer | begin training epoch 514
2022-03-06 06:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:50:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:51:03 | INFO | train_inner | epoch 514:     36 / 49 loss=1.199, nll_loss=0.222, ppl=1.17, wps=27280.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.393, loss_scale=32, train_wall=201, gb_free=21.6, wall=59339
2022-03-06 06:51:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:51:35 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.867 | nll_loss 13.543 | ppl 11934 | wps 46014.9 | wpb 510.9 | bsz 1 | num_updates 25013 | best_loss 8.499
2022-03-06 06:51:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25013 updates
2022-03-06 06:51:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 514 @ 25013 updates, score 13.867) (writing took 1.977532516233623 seconds)
2022-03-06 06:51:37 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-06 06:51:37 | INFO | train | epoch 514 | loss 1.199 | nll_loss 0.222 | ppl 1.17 | wps 26904.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 25013 | lr 0.000199948 | gnorm 0.396 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 59374
2022-03-06 06:51:37 | INFO | fairseq.trainer | begin training epoch 515
2022-03-06 06:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:53:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:53:31 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.881 | nll_loss 13.559 | ppl 12068 | wps 45708.9 | wpb 510.9 | bsz 1 | num_updates 25062 | best_loss 8.499
2022-03-06 06:53:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25062 updates
2022-03-06 06:53:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:53:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:53:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 515 @ 25062 updates, score 13.881) (writing took 1.9389074891805649 seconds)
2022-03-06 06:53:33 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-06 06:53:33 | INFO | train | epoch 515 | loss 1.198 | nll_loss 0.221 | ppl 1.17 | wps 27484.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25062 | lr 0.000199752 | gnorm 0.389 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 59490
2022-03-06 06:53:33 | INFO | fairseq.trainer | begin training epoch 516
2022-03-06 06:53:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:54:58 | INFO | train_inner | epoch 516:     38 / 49 loss=1.198, nll_loss=0.221, ppl=1.17, wps=27526.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.388, loss_scale=32, train_wall=199, gb_free=21.6, wall=59575
2022-03-06 06:55:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:55:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:55:27 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.945 | nll_loss 13.624 | ppl 12625.8 | wps 46246.5 | wpb 510.9 | bsz 1 | num_updates 25110 | best_loss 8.499
2022-03-06 06:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25110 updates
2022-03-06 06:55:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:55:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 516 @ 25110 updates, score 13.945) (writing took 1.9849648959934711 seconds)
2022-03-06 06:55:28 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-06 06:55:28 | INFO | train | epoch 516 | loss 1.197 | nll_loss 0.22 | ppl 1.16 | wps 26946 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25110 | lr 0.000199561 | gnorm 0.386 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 59605
2022-03-06 06:55:29 | INFO | fairseq.trainer | begin training epoch 517
2022-03-06 06:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:57:22 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.812 | nll_loss 13.485 | ppl 11466.6 | wps 46001.2 | wpb 510.9 | bsz 1 | num_updates 25159 | best_loss 8.499
2022-03-06 06:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25159 updates
2022-03-06 06:57:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:57:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:57:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 517 @ 25159 updates, score 13.812) (writing took 1.941845049150288 seconds)
2022-03-06 06:57:24 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-06 06:57:24 | INFO | train | epoch 517 | loss 1.197 | nll_loss 0.22 | ppl 1.17 | wps 27489 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25159 | lr 0.000199367 | gnorm 0.392 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 59721
2022-03-06 06:57:24 | INFO | fairseq.trainer | begin training epoch 518
2022-03-06 06:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:58:56 | INFO | train_inner | epoch 518:     41 / 49 loss=1.197, nll_loss=0.22, ppl=1.16, wps=27266.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.39, loss_scale=32, train_wall=201, gb_free=21.6, wall=59813
2022-03-06 06:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:59:18 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.905 | nll_loss 13.583 | ppl 12275.5 | wps 45842.4 | wpb 510.9 | bsz 1 | num_updates 25208 | best_loss 8.499
2022-03-06 06:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25208 updates
2022-03-06 06:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 06:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 518 @ 25208 updates, score 13.905) (writing took 1.9706685803830624 seconds)
2022-03-06 06:59:20 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-06 06:59:20 | INFO | train | epoch 518 | loss 1.197 | nll_loss 0.22 | ppl 1.17 | wps 27471.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25208 | lr 0.000199173 | gnorm 0.39 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 59837
2022-03-06 06:59:20 | INFO | fairseq.trainer | begin training epoch 519
2022-03-06 06:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:00:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:01:13 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.844 | nll_loss 13.519 | ppl 11736.8 | wps 46378.8 | wpb 510.9 | bsz 1 | num_updates 25256 | best_loss 8.499
2022-03-06 07:01:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25256 updates
2022-03-06 07:01:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:01:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:01:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 519 @ 25256 updates, score 13.844) (writing took 1.922389043495059 seconds)
2022-03-06 07:01:15 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-06 07:01:15 | INFO | train | epoch 519 | loss 1.196 | nll_loss 0.219 | ppl 1.16 | wps 26949.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25256 | lr 0.000198984 | gnorm 0.388 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 59952
2022-03-06 07:01:15 | INFO | fairseq.trainer | begin training epoch 520
2022-03-06 07:01:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:02:54 | INFO | train_inner | epoch 520:     44 / 49 loss=1.196, nll_loss=0.22, ppl=1.16, wps=27257.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.389, loss_scale=32, train_wall=201, gb_free=21.6, wall=60051
2022-03-06 07:03:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:03:09 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 13.774 | nll_loss 13.448 | ppl 11172.6 | wps 46244.7 | wpb 510.9 | bsz 1 | num_updates 25305 | best_loss 8.499
2022-03-06 07:03:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25305 updates
2022-03-06 07:03:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:03:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:03:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 520 @ 25305 updates, score 13.774) (writing took 1.9765285234898329 seconds)
2022-03-06 07:03:11 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-06 07:03:11 | INFO | train | epoch 520 | loss 1.197 | nll_loss 0.22 | ppl 1.16 | wps 27464.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25305 | lr 0.000198791 | gnorm 0.389 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 60068
2022-03-06 07:03:11 | INFO | fairseq.trainer | begin training epoch 521
2022-03-06 07:03:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:05:05 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 13.836 | nll_loss 13.514 | ppl 11698.7 | wps 46454.7 | wpb 510.9 | bsz 1 | num_updates 25354 | best_loss 8.499
2022-03-06 07:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25354 updates
2022-03-06 07:05:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 521 @ 25354 updates, score 13.836) (writing took 1.928671382367611 seconds)
2022-03-06 07:05:06 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-06 07:05:06 | INFO | train | epoch 521 | loss 1.195 | nll_loss 0.219 | ppl 1.16 | wps 27529.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25354 | lr 0.000198599 | gnorm 0.387 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 60183
2022-03-06 07:05:06 | INFO | fairseq.trainer | begin training epoch 522
2022-03-06 07:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:05:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:06:52 | INFO | train_inner | epoch 522:     47 / 49 loss=1.196, nll_loss=0.22, ppl=1.16, wps=27294.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25400, lr=0.000198419, gnorm=0.39, loss_scale=32, train_wall=201, gb_free=21.6, wall=60289
2022-03-06 07:06:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:07:00 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 13.797 | nll_loss 13.472 | ppl 11360.4 | wps 45371.2 | wpb 510.9 | bsz 1 | num_updates 25402 | best_loss 8.499
2022-03-06 07:07:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25402 updates
2022-03-06 07:07:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:07:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:07:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 522 @ 25402 updates, score 13.797) (writing took 1.9682393344119191 seconds)
2022-03-06 07:07:02 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-06 07:07:02 | INFO | train | epoch 522 | loss 1.196 | nll_loss 0.22 | ppl 1.16 | wps 26932.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25402 | lr 0.000198411 | gnorm 0.392 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 60299
2022-03-06 07:07:02 | INFO | fairseq.trainer | begin training epoch 523
2022-03-06 07:07:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:08:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:08:56 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 13.902 | nll_loss 13.584 | ppl 12276.7 | wps 46495.8 | wpb 510.9 | bsz 1 | num_updates 25451 | best_loss 8.499
2022-03-06 07:08:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25451 updates
2022-03-06 07:08:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:08:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:08:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 523 @ 25451 updates, score 13.902) (writing took 1.9443344175815582 seconds)
2022-03-06 07:08:58 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-06 07:08:58 | INFO | train | epoch 523 | loss 1.196 | nll_loss 0.219 | ppl 1.16 | wps 27516.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25451 | lr 0.00019822 | gnorm 0.39 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 60414
2022-03-06 07:08:58 | INFO | fairseq.trainer | begin training epoch 524
2022-03-06 07:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:10:46 | INFO | train_inner | epoch 524:     49 / 49 loss=1.195, nll_loss=0.219, ppl=1.16, wps=27527.7, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=25500, lr=0.00019803, gnorm=0.391, loss_scale=64, train_wall=198, gb_free=21.6, wall=60523
2022-03-06 07:10:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:10:51 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 13.843 | nll_loss 13.519 | ppl 11736.8 | wps 46730 | wpb 510.9 | bsz 1 | num_updates 25500 | best_loss 8.499
2022-03-06 07:10:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25500 updates
2022-03-06 07:10:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:10:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:10:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 524 @ 25500 updates, score 13.843) (writing took 1.9571763826534152 seconds)
2022-03-06 07:10:53 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-06 07:10:53 | INFO | train | epoch 524 | loss 1.195 | nll_loss 0.219 | ppl 1.16 | wps 27531.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25500 | lr 0.00019803 | gnorm 0.391 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 60530
2022-03-06 07:10:53 | INFO | fairseq.trainer | begin training epoch 525
2022-03-06 07:10:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:10:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:12:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:12:47 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 13.854 | nll_loss 13.534 | ppl 11858.5 | wps 46142.2 | wpb 510.9 | bsz 1 | num_updates 25548 | best_loss 8.499
2022-03-06 07:12:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25548 updates
2022-03-06 07:12:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:12:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:12:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 525 @ 25548 updates, score 13.854) (writing took 1.9178498229011893 seconds)
2022-03-06 07:12:48 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-06 07:12:48 | INFO | train | epoch 525 | loss 1.194 | nll_loss 0.218 | ppl 1.16 | wps 26936.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25548 | lr 0.000197843 | gnorm 0.387 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 60645
2022-03-06 07:12:49 | INFO | fairseq.trainer | begin training epoch 526
2022-03-06 07:12:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:14:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:14:42 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 13.78 | nll_loss 13.455 | ppl 11233.1 | wps 46383.1 | wpb 510.9 | bsz 1 | num_updates 25597 | best_loss 8.499
2022-03-06 07:14:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25597 updates
2022-03-06 07:14:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:14:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:14:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 526 @ 25597 updates, score 13.78) (writing took 1.938834705390036 seconds)
2022-03-06 07:14:44 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-06 07:14:44 | INFO | train | epoch 526 | loss 1.194 | nll_loss 0.218 | ppl 1.16 | wps 27544.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25597 | lr 0.000197654 | gnorm 0.385 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 60761
2022-03-06 07:14:44 | INFO | fairseq.trainer | begin training epoch 527
2022-03-06 07:14:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:14:51 | INFO | train_inner | epoch 527:      3 / 49 loss=1.194, nll_loss=0.218, ppl=1.16, wps=26538.7, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.386, loss_scale=32, train_wall=201, gb_free=21.6, wall=60768
2022-03-06 07:16:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:16:37 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 13.698 | nll_loss 13.37 | ppl 10584.6 | wps 46602.7 | wpb 510.9 | bsz 1 | num_updates 25645 | best_loss 8.499
2022-03-06 07:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25645 updates
2022-03-06 07:16:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:16:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:16:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 527 @ 25645 updates, score 13.698) (writing took 1.9372909059748054 seconds)
2022-03-06 07:16:39 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-06 07:16:39 | INFO | train | epoch 527 | loss 1.194 | nll_loss 0.218 | ppl 1.16 | wps 26982.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25645 | lr 0.000197469 | gnorm 0.387 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 60876
2022-03-06 07:16:39 | INFO | fairseq.trainer | begin training epoch 528
2022-03-06 07:16:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:18:33 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 13.879 | nll_loss 13.559 | ppl 12071.5 | wps 45810.8 | wpb 510.9 | bsz 1 | num_updates 25694 | best_loss 8.499
2022-03-06 07:18:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25694 updates
2022-03-06 07:18:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 528 @ 25694 updates, score 13.879) (writing took 1.962682155892253 seconds)
2022-03-06 07:18:35 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-06 07:18:35 | INFO | train | epoch 528 | loss 1.194 | nll_loss 0.218 | ppl 1.16 | wps 27537.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25694 | lr 0.00019728 | gnorm 0.387 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 60991
2022-03-06 07:18:35 | INFO | fairseq.trainer | begin training epoch 529
2022-03-06 07:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:18:48 | INFO | train_inner | epoch 529:      6 / 49 loss=1.194, nll_loss=0.218, ppl=1.16, wps=27311.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.387, loss_scale=32, train_wall=201, gb_free=21.6, wall=61005
2022-03-06 07:20:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:20:28 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 13.847 | nll_loss 13.523 | ppl 11771.4 | wps 46512.1 | wpb 510.9 | bsz 1 | num_updates 25743 | best_loss 8.499
2022-03-06 07:20:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25743 updates
2022-03-06 07:20:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:20:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:20:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 529 @ 25743 updates, score 13.847) (writing took 1.934122164733708 seconds)
2022-03-06 07:20:30 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-06 07:20:30 | INFO | train | epoch 529 | loss 1.193 | nll_loss 0.217 | ppl 1.16 | wps 27518.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25743 | lr 0.000197093 | gnorm 0.386 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 61107
2022-03-06 07:20:30 | INFO | fairseq.trainer | begin training epoch 530
2022-03-06 07:20:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:21:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:22:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:22:24 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 13.919 | nll_loss 13.599 | ppl 12404.1 | wps 46038.1 | wpb 510.9 | bsz 1 | num_updates 25791 | best_loss 8.499
2022-03-06 07:22:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25791 updates
2022-03-06 07:22:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:22:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:22:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 530 @ 25791 updates, score 13.919) (writing took 1.99065500497818 seconds)
2022-03-06 07:22:26 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-06 07:22:26 | INFO | train | epoch 530 | loss 1.194 | nll_loss 0.218 | ppl 1.16 | wps 26943 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25791 | lr 0.000196909 | gnorm 0.39 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 61222
2022-03-06 07:22:26 | INFO | fairseq.trainer | begin training epoch 531
2022-03-06 07:22:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:22:46 | INFO | train_inner | epoch 531:      9 / 49 loss=1.193, nll_loss=0.217, ppl=1.16, wps=27295.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.388, loss_scale=32, train_wall=201, gb_free=21.6, wall=61243
2022-03-06 07:24:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:24:19 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 13.929 | nll_loss 13.611 | ppl 12511.1 | wps 46129 | wpb 510.9 | bsz 1 | num_updates 25840 | best_loss 8.499
2022-03-06 07:24:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25840 updates
2022-03-06 07:24:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:24:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:24:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 531 @ 25840 updates, score 13.929) (writing took 1.9242777451872826 seconds)
2022-03-06 07:24:21 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-06 07:24:21 | INFO | train | epoch 531 | loss 1.193 | nll_loss 0.218 | ppl 1.16 | wps 27518.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25840 | lr 0.000196722 | gnorm 0.383 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 61338
2022-03-06 07:24:21 | INFO | fairseq.trainer | begin training epoch 532
2022-03-06 07:24:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:26:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:26:15 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 13.905 | nll_loss 13.587 | ppl 12301.6 | wps 46042.7 | wpb 510.9 | bsz 1 | num_updates 25889 | best_loss 8.499
2022-03-06 07:26:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25889 updates
2022-03-06 07:26:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:26:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 532 @ 25889 updates, score 13.905) (writing took 1.9440736826509237 seconds)
2022-03-06 07:26:17 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-06 07:26:17 | INFO | train | epoch 532 | loss 1.192 | nll_loss 0.216 | ppl 1.16 | wps 27533.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25889 | lr 0.000196536 | gnorm 0.381 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 61453
2022-03-06 07:26:17 | INFO | fairseq.trainer | begin training epoch 533
2022-03-06 07:26:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:26:41 | INFO | train_inner | epoch 533:     11 / 49 loss=1.192, nll_loss=0.217, ppl=1.16, wps=27558.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.382, loss_scale=32, train_wall=199, gb_free=21.6, wall=61478
2022-03-06 07:26:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:28:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:28:10 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 13.813 | nll_loss 13.489 | ppl 11498.5 | wps 46787.8 | wpb 510.9 | bsz 1 | num_updates 25937 | best_loss 8.499
2022-03-06 07:28:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25937 updates
2022-03-06 07:28:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:28:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:28:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 533 @ 25937 updates, score 13.813) (writing took 1.934625718742609 seconds)
2022-03-06 07:28:12 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-06 07:28:12 | INFO | train | epoch 533 | loss 1.192 | nll_loss 0.217 | ppl 1.16 | wps 26946.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25937 | lr 0.000196354 | gnorm 0.389 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 61569
2022-03-06 07:28:12 | INFO | fairseq.trainer | begin training epoch 534
2022-03-06 07:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:30:06 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 13.88 | nll_loss 13.558 | ppl 12063.7 | wps 45745 | wpb 510.9 | bsz 1 | num_updates 25986 | best_loss 8.499
2022-03-06 07:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25986 updates
2022-03-06 07:30:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:30:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 534 @ 25986 updates, score 13.88) (writing took 1.941758462227881 seconds)
2022-03-06 07:30:08 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-06 07:30:08 | INFO | train | epoch 534 | loss 1.191 | nll_loss 0.216 | ppl 1.16 | wps 27481.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 25986 | lr 0.000196169 | gnorm 0.381 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 61685
2022-03-06 07:30:08 | INFO | fairseq.trainer | begin training epoch 535
2022-03-06 07:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:30:39 | INFO | train_inner | epoch 535:     14 / 49 loss=1.192, nll_loss=0.216, ppl=1.16, wps=27268.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.385, loss_scale=32, train_wall=201, gb_free=21.6, wall=61716
2022-03-06 07:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:32:01 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 13.86 | nll_loss 13.536 | ppl 11881.6 | wps 46086.3 | wpb 510.9 | bsz 1 | num_updates 26035 | best_loss 8.499
2022-03-06 07:32:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26035 updates
2022-03-06 07:32:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:32:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:32:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 535 @ 26035 updates, score 13.86) (writing took 1.9411525037139654 seconds)
2022-03-06 07:32:03 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-06 07:32:03 | INFO | train | epoch 535 | loss 1.192 | nll_loss 0.216 | ppl 1.16 | wps 27474.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26035 | lr 0.000195984 | gnorm 0.385 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 61800
2022-03-06 07:32:03 | INFO | fairseq.trainer | begin training epoch 536
2022-03-06 07:32:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:32:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:33:57 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 13.775 | nll_loss 13.449 | ppl 11179.2 | wps 45618 | wpb 510.9 | bsz 1 | num_updates 26083 | best_loss 8.499
2022-03-06 07:33:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26083 updates
2022-03-06 07:33:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:33:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:33:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 536 @ 26083 updates, score 13.775) (writing took 1.9458818286657333 seconds)
2022-03-06 07:33:59 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-06 07:33:59 | INFO | train | epoch 536 | loss 1.191 | nll_loss 0.216 | ppl 1.16 | wps 26938.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26083 | lr 0.000195804 | gnorm 0.389 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 61916
2022-03-06 07:33:59 | INFO | fairseq.trainer | begin training epoch 537
2022-03-06 07:33:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:34:37 | INFO | train_inner | epoch 537:     17 / 49 loss=1.191, nll_loss=0.216, ppl=1.16, wps=27264.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.385, loss_scale=32, train_wall=201, gb_free=21.6, wall=61954
2022-03-06 07:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:35:53 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 13.876 | nll_loss 13.557 | ppl 12055.3 | wps 45224 | wpb 510.9 | bsz 1 | num_updates 26132 | best_loss 8.499
2022-03-06 07:35:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26132 updates
2022-03-06 07:35:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:35:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:35:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 537 @ 26132 updates, score 13.876) (writing took 1.9088626829907298 seconds)
2022-03-06 07:35:54 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-06 07:35:54 | INFO | train | epoch 537 | loss 1.19 | nll_loss 0.215 | ppl 1.16 | wps 27499.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26132 | lr 0.00019562 | gnorm 0.379 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 62031
2022-03-06 07:35:55 | INFO | fairseq.trainer | begin training epoch 538
2022-03-06 07:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:37:48 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 13.894 | nll_loss 13.575 | ppl 12201.9 | wps 46406.6 | wpb 510.9 | bsz 1 | num_updates 26181 | best_loss 8.499
2022-03-06 07:37:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26181 updates
2022-03-06 07:37:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:37:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 538 @ 26181 updates, score 13.894) (writing took 1.9452652456238866 seconds)
2022-03-06 07:37:50 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-06 07:37:50 | INFO | train | epoch 538 | loss 1.19 | nll_loss 0.215 | ppl 1.16 | wps 27499.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26181 | lr 0.000195437 | gnorm 0.38 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 62147
2022-03-06 07:37:50 | INFO | fairseq.trainer | begin training epoch 539
2022-03-06 07:37:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:37:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:38:35 | INFO | train_inner | epoch 539:     20 / 49 loss=1.19, nll_loss=0.215, ppl=1.16, wps=27276.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.382, loss_scale=32, train_wall=201, gb_free=21.6, wall=62192
2022-03-06 07:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:39:44 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 13.786 | nll_loss 13.461 | ppl 11279.3 | wps 45540.7 | wpb 510.9 | bsz 1 | num_updates 26229 | best_loss 8.499
2022-03-06 07:39:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26229 updates
2022-03-06 07:39:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:39:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:39:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 539 @ 26229 updates, score 13.786) (writing took 1.9132052371278405 seconds)
2022-03-06 07:39:46 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-06 07:39:46 | INFO | train | epoch 539 | loss 1.191 | nll_loss 0.216 | ppl 1.16 | wps 26949.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26229 | lr 0.000195258 | gnorm 0.39 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 62262
2022-03-06 07:39:46 | INFO | fairseq.trainer | begin training epoch 540
2022-03-06 07:39:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:41:39 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 13.93 | nll_loss 13.614 | ppl 12535.7 | wps 46347.6 | wpb 510.9 | bsz 1 | num_updates 26278 | best_loss 8.499
2022-03-06 07:41:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26278 updates
2022-03-06 07:41:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:41:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:41:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 540 @ 26278 updates, score 13.93) (writing took 1.9898099871352315 seconds)
2022-03-06 07:41:41 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-06 07:41:41 | INFO | train | epoch 540 | loss 1.19 | nll_loss 0.215 | ppl 1.16 | wps 27459 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26278 | lr 0.000195076 | gnorm 0.379 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 62378
2022-03-06 07:41:41 | INFO | fairseq.trainer | begin training epoch 541
2022-03-06 07:41:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:42:31 | INFO | train_inner | epoch 541:     22 / 49 loss=1.19, nll_loss=0.215, ppl=1.16, wps=27519.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.384, loss_scale=32, train_wall=199, gb_free=21.6, wall=62427
2022-03-06 07:43:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:43:35 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 13.87 | nll_loss 13.549 | ppl 11982.2 | wps 46403.8 | wpb 510.9 | bsz 1 | num_updates 26326 | best_loss 8.499
2022-03-06 07:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26326 updates
2022-03-06 07:43:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:43:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:43:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 541 @ 26326 updates, score 13.87) (writing took 1.9268394382670522 seconds)
2022-03-06 07:43:37 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-06 07:43:37 | INFO | train | epoch 541 | loss 1.19 | nll_loss 0.215 | ppl 1.16 | wps 26949.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26326 | lr 0.000194898 | gnorm 0.383 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 62494
2022-03-06 07:43:37 | INFO | fairseq.trainer | begin training epoch 542
2022-03-06 07:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:45:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:45:30 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 13.85 | nll_loss 13.529 | ppl 11823.5 | wps 46278.3 | wpb 510.9 | bsz 1 | num_updates 26375 | best_loss 8.499
2022-03-06 07:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26375 updates
2022-03-06 07:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:45:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 542 @ 26375 updates, score 13.85) (writing took 1.9553806986659765 seconds)
2022-03-06 07:45:32 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-06 07:45:32 | INFO | train | epoch 542 | loss 1.19 | nll_loss 0.215 | ppl 1.16 | wps 27494.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26375 | lr 0.000194717 | gnorm 0.384 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 62609
2022-03-06 07:45:32 | INFO | fairseq.trainer | begin training epoch 543
2022-03-06 07:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:46:28 | INFO | train_inner | epoch 543:     25 / 49 loss=1.189, nll_loss=0.215, ppl=1.16, wps=27285.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.382, loss_scale=32, train_wall=201, gb_free=21.6, wall=62665
2022-03-06 07:47:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:47:26 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 13.818 | nll_loss 13.497 | ppl 11558 | wps 46267.3 | wpb 510.9 | bsz 1 | num_updates 26424 | best_loss 8.499
2022-03-06 07:47:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26424 updates
2022-03-06 07:47:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:47:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:47:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 543 @ 26424 updates, score 13.818) (writing took 1.905585888773203 seconds)
2022-03-06 07:47:28 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-06 07:47:28 | INFO | train | epoch 543 | loss 1.189 | nll_loss 0.215 | ppl 1.16 | wps 27530.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26424 | lr 0.000194536 | gnorm 0.384 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 62725
2022-03-06 07:47:28 | INFO | fairseq.trainer | begin training epoch 544
2022-03-06 07:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:48:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:49:22 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 13.775 | nll_loss 13.45 | ppl 11191.5 | wps 45569 | wpb 510.9 | bsz 1 | num_updates 26472 | best_loss 8.499
2022-03-06 07:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26472 updates
2022-03-06 07:49:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 544 @ 26472 updates, score 13.775) (writing took 1.9309068731963634 seconds)
2022-03-06 07:49:23 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-06 07:49:23 | INFO | train | epoch 544 | loss 1.189 | nll_loss 0.214 | ppl 1.16 | wps 26919.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26472 | lr 0.00019436 | gnorm 0.384 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 62840
2022-03-06 07:49:23 | INFO | fairseq.trainer | begin training epoch 545
2022-03-06 07:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:50:26 | INFO | train_inner | epoch 545:     28 / 49 loss=1.189, nll_loss=0.215, ppl=1.16, wps=27289.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.386, loss_scale=32, train_wall=201, gb_free=21.6, wall=62903
2022-03-06 07:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:51:17 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 13.845 | nll_loss 13.523 | ppl 11774.2 | wps 46000.7 | wpb 510.9 | bsz 1 | num_updates 26521 | best_loss 8.499
2022-03-06 07:51:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26521 updates
2022-03-06 07:51:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:51:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:51:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 545 @ 26521 updates, score 13.845) (writing took 1.9266861639916897 seconds)
2022-03-06 07:51:19 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-06 07:51:19 | INFO | train | epoch 545 | loss 1.189 | nll_loss 0.214 | ppl 1.16 | wps 27541.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26521 | lr 0.00019418 | gnorm 0.385 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 62956
2022-03-06 07:51:19 | INFO | fairseq.trainer | begin training epoch 546
2022-03-06 07:51:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:53:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:53:13 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 13.784 | nll_loss 13.461 | ppl 11278.7 | wps 46034.4 | wpb 510.9 | bsz 1 | num_updates 26570 | best_loss 8.499
2022-03-06 07:53:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26570 updates
2022-03-06 07:53:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:53:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:53:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 546 @ 26570 updates, score 13.784) (writing took 1.9610133934766054 seconds)
2022-03-06 07:53:14 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-06 07:53:14 | INFO | train | epoch 546 | loss 1.188 | nll_loss 0.214 | ppl 1.16 | wps 27482.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26570 | lr 0.000194001 | gnorm 0.379 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 63071
2022-03-06 07:53:14 | INFO | fairseq.trainer | begin training epoch 547
2022-03-06 07:53:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:54:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:54:24 | INFO | train_inner | epoch 547:     31 / 49 loss=1.189, nll_loss=0.214, ppl=1.16, wps=27281.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.38, loss_scale=32, train_wall=201, gb_free=21.6, wall=63141
2022-03-06 07:55:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:55:08 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 13.862 | nll_loss 13.537 | ppl 11888.2 | wps 45954.1 | wpb 510.9 | bsz 1 | num_updates 26618 | best_loss 8.499
2022-03-06 07:55:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26618 updates
2022-03-06 07:55:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:55:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:55:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 547 @ 26618 updates, score 13.862) (writing took 1.9577237227931619 seconds)
2022-03-06 07:55:10 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-06 07:55:10 | INFO | train | epoch 547 | loss 1.188 | nll_loss 0.214 | ppl 1.16 | wps 26952.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26618 | lr 0.000193826 | gnorm 0.38 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 63187
2022-03-06 07:55:10 | INFO | fairseq.trainer | begin training epoch 548
2022-03-06 07:55:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:56:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 07:56:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:57:04 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 13.788 | nll_loss 13.463 | ppl 11293.5 | wps 45893 | wpb 510.9 | bsz 1 | num_updates 26666 | best_loss 8.499
2022-03-06 07:57:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26666 updates
2022-03-06 07:57:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:57:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:57:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 548 @ 26666 updates, score 13.788) (writing took 1.9628887614235282 seconds)
2022-03-06 07:57:06 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-06 07:57:06 | INFO | train | epoch 548 | loss 1.188 | nll_loss 0.214 | ppl 1.16 | wps 26904.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 26666 | lr 0.000193652 | gnorm 0.383 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 63302
2022-03-06 07:57:06 | INFO | fairseq.trainer | begin training epoch 549
2022-03-06 07:57:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:58:22 | INFO | train_inner | epoch 549:     34 / 49 loss=1.188, nll_loss=0.214, ppl=1.16, wps=27256.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.384, loss_scale=16, train_wall=201, gb_free=21.6, wall=63379
2022-03-06 07:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:58:59 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 13.803 | nll_loss 13.48 | ppl 11425.9 | wps 46061.3 | wpb 510.9 | bsz 1 | num_updates 26715 | best_loss 8.499
2022-03-06 07:58:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26715 updates
2022-03-06 07:58:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 07:59:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 549 @ 26715 updates, score 13.803) (writing took 1.940302417613566 seconds)
2022-03-06 07:59:01 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-06 07:59:01 | INFO | train | epoch 549 | loss 1.188 | nll_loss 0.214 | ppl 1.16 | wps 27506.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26715 | lr 0.000193474 | gnorm 0.387 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 63418
2022-03-06 07:59:01 | INFO | fairseq.trainer | begin training epoch 550
2022-03-06 07:59:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:00:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:00:55 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 13.799 | nll_loss 13.478 | ppl 11411 | wps 45832.4 | wpb 510.9 | bsz 1 | num_updates 26764 | best_loss 8.499
2022-03-06 08:00:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26764 updates
2022-03-06 08:00:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:00:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:00:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 550 @ 26764 updates, score 13.799) (writing took 1.976619616150856 seconds)
2022-03-06 08:00:57 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-06 08:00:57 | INFO | train | epoch 550 | loss 1.187 | nll_loss 0.213 | ppl 1.16 | wps 27492.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26764 | lr 0.000193297 | gnorm 0.378 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 63534
2022-03-06 08:00:57 | INFO | fairseq.trainer | begin training epoch 551
2022-03-06 08:00:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:02:17 | INFO | train_inner | epoch 551:     36 / 49 loss=1.187, nll_loss=0.213, ppl=1.16, wps=27550.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.382, loss_scale=32, train_wall=199, gb_free=21.6, wall=63614
2022-03-06 08:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:02:50 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 13.758 | nll_loss 13.434 | ppl 11063.4 | wps 46216.3 | wpb 510.9 | bsz 1 | num_updates 26813 | best_loss 8.499
2022-03-06 08:02:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26813 updates
2022-03-06 08:02:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:02:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:02:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 551 @ 26813 updates, score 13.758) (writing took 1.9291423233225942 seconds)
2022-03-06 08:02:52 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-06 08:02:52 | INFO | train | epoch 551 | loss 1.188 | nll_loss 0.214 | ppl 1.16 | wps 27532.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26813 | lr 0.00019312 | gnorm 0.384 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 63649
2022-03-06 08:02:52 | INFO | fairseq.trainer | begin training epoch 552
2022-03-06 08:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:04:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:04:46 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 13.811 | nll_loss 13.487 | ppl 11481.9 | wps 46046.6 | wpb 510.9 | bsz 1 | num_updates 26862 | best_loss 8.499
2022-03-06 08:04:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26862 updates
2022-03-06 08:04:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:04:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 552 @ 26862 updates, score 13.811) (writing took 1.9626727337017655 seconds)
2022-03-06 08:04:48 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-06 08:04:48 | INFO | train | epoch 552 | loss 1.187 | nll_loss 0.213 | ppl 1.16 | wps 27547 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26862 | lr 0.000192944 | gnorm 0.383 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63764
2022-03-06 08:04:48 | INFO | fairseq.trainer | begin training epoch 553
2022-03-06 08:04:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:06:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:06:15 | INFO | train_inner | epoch 553:     39 / 49 loss=1.187, nll_loss=0.213, ppl=1.16, wps=27291, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.382, loss_scale=32, train_wall=201, gb_free=21.6, wall=63852
2022-03-06 08:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:06:41 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 13.835 | nll_loss 13.513 | ppl 11689 | wps 46244.4 | wpb 510.9 | bsz 1 | num_updates 26910 | best_loss 8.499
2022-03-06 08:06:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26910 updates
2022-03-06 08:06:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:06:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 553 @ 26910 updates, score 13.835) (writing took 1.9370833793655038 seconds)
2022-03-06 08:06:43 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-06 08:06:43 | INFO | train | epoch 553 | loss 1.186 | nll_loss 0.212 | ppl 1.16 | wps 26941.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26910 | lr 0.000192772 | gnorm 0.383 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 63880
2022-03-06 08:06:43 | INFO | fairseq.trainer | begin training epoch 554
2022-03-06 08:06:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:08:37 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 13.84 | nll_loss 13.521 | ppl 11752.3 | wps 46242.4 | wpb 510.9 | bsz 1 | num_updates 26959 | best_loss 8.499
2022-03-06 08:08:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26959 updates
2022-03-06 08:08:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:08:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:08:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 554 @ 26959 updates, score 13.84) (writing took 1.9546161033213139 seconds)
2022-03-06 08:08:39 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-06 08:08:39 | INFO | train | epoch 554 | loss 1.186 | nll_loss 0.213 | ppl 1.16 | wps 27510 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 26959 | lr 0.000192596 | gnorm 0.378 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 63995
2022-03-06 08:08:39 | INFO | fairseq.trainer | begin training epoch 555
2022-03-06 08:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:10:11 | INFO | train_inner | epoch 555:     41 / 49 loss=1.186, nll_loss=0.213, ppl=1.16, wps=27546.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.38, loss_scale=32, train_wall=199, gb_free=21.6, wall=64087
2022-03-06 08:10:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:10:32 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 13.81 | nll_loss 13.488 | ppl 11485.3 | wps 46667.5 | wpb 510.9 | bsz 1 | num_updates 27008 | best_loss 8.499
2022-03-06 08:10:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27008 updates
2022-03-06 08:10:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:10:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:10:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 555 @ 27008 updates, score 13.81) (writing took 1.9173644185066223 seconds)
2022-03-06 08:10:34 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-06 08:10:34 | INFO | train | epoch 555 | loss 1.186 | nll_loss 0.212 | ppl 1.16 | wps 27520.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27008 | lr 0.000192422 | gnorm 0.381 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 64111
2022-03-06 08:10:34 | INFO | fairseq.trainer | begin training epoch 556
2022-03-06 08:10:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:11:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:12:28 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 13.77 | nll_loss 13.442 | ppl 11130.5 | wps 45952.1 | wpb 510.9 | bsz 1 | num_updates 27056 | best_loss 8.499
2022-03-06 08:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27056 updates
2022-03-06 08:12:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:12:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:12:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 556 @ 27056 updates, score 13.77) (writing took 1.944478358142078 seconds)
2022-03-06 08:12:30 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-06 08:12:30 | INFO | train | epoch 556 | loss 1.186 | nll_loss 0.212 | ppl 1.16 | wps 26927.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27056 | lr 0.000192251 | gnorm 0.378 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 64227
2022-03-06 08:12:30 | INFO | fairseq.trainer | begin training epoch 557
2022-03-06 08:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:14:08 | INFO | train_inner | epoch 557:     44 / 49 loss=1.185, nll_loss=0.212, ppl=1.16, wps=27299.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.379, loss_scale=32, train_wall=201, gb_free=21.6, wall=64325
2022-03-06 08:14:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:14:23 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 13.796 | nll_loss 13.474 | ppl 11379.3 | wps 46361.5 | wpb 510.9 | bsz 1 | num_updates 27105 | best_loss 8.499
2022-03-06 08:14:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27105 updates
2022-03-06 08:14:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:14:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:14:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 557 @ 27105 updates, score 13.796) (writing took 1.9359610844403505 seconds)
2022-03-06 08:14:25 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-06 08:14:25 | INFO | train | epoch 557 | loss 1.185 | nll_loss 0.212 | ppl 1.16 | wps 27554.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27105 | lr 0.000192077 | gnorm 0.38 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64342
2022-03-06 08:14:25 | INFO | fairseq.trainer | begin training epoch 558
2022-03-06 08:14:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:16:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:16:19 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 13.828 | nll_loss 13.508 | ppl 11651.4 | wps 46119.8 | wpb 510.9 | bsz 1 | num_updates 27154 | best_loss 8.499
2022-03-06 08:16:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27154 updates
2022-03-06 08:16:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:16:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:16:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 558 @ 27154 updates, score 13.828) (writing took 1.9621981754899025 seconds)
2022-03-06 08:16:20 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-06 08:16:20 | INFO | train | epoch 558 | loss 1.185 | nll_loss 0.212 | ppl 1.16 | wps 27531.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27154 | lr 0.000191904 | gnorm 0.381 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 64457
2022-03-06 08:16:20 | INFO | fairseq.trainer | begin training epoch 559
2022-03-06 08:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:17:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:18:06 | INFO | train_inner | epoch 559:     47 / 49 loss=1.185, nll_loss=0.212, ppl=1.16, wps=27314.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.38, loss_scale=32, train_wall=201, gb_free=21.6, wall=64563
2022-03-06 08:18:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:18:14 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 13.822 | nll_loss 13.5 | ppl 11588 | wps 46278.6 | wpb 510.9 | bsz 1 | num_updates 27202 | best_loss 8.499
2022-03-06 08:18:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27202 updates
2022-03-06 08:18:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:18:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:18:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 559 @ 27202 updates, score 13.822) (writing took 1.9319354807958007 seconds)
2022-03-06 08:18:16 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-06 08:18:16 | INFO | train | epoch 559 | loss 1.185 | nll_loss 0.212 | ppl 1.16 | wps 26981.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27202 | lr 0.000191734 | gnorm 0.379 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 64573
2022-03-06 08:18:16 | INFO | fairseq.trainer | begin training epoch 560
2022-03-06 08:18:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:20:09 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 13.856 | nll_loss 13.537 | ppl 11886.1 | wps 46331.8 | wpb 510.9 | bsz 1 | num_updates 27251 | best_loss 8.499
2022-03-06 08:20:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27251 updates
2022-03-06 08:20:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:20:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:20:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 560 @ 27251 updates, score 13.856) (writing took 1.9670361643657088 seconds)
2022-03-06 08:20:11 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-06 08:20:11 | INFO | train | epoch 560 | loss 1.184 | nll_loss 0.211 | ppl 1.16 | wps 27553 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27251 | lr 0.000191562 | gnorm 0.379 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64688
2022-03-06 08:20:11 | INFO | fairseq.trainer | begin training epoch 561
2022-03-06 08:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:22:00 | INFO | train_inner | epoch 561:     49 / 49 loss=1.184, nll_loss=0.211, ppl=1.16, wps=27566, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=27300, lr=0.00019139, gnorm=0.378, loss_scale=64, train_wall=198, gb_free=21.6, wall=64797
2022-03-06 08:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:22:05 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 13.78 | nll_loss 13.457 | ppl 11242.2 | wps 46362.5 | wpb 510.9 | bsz 1 | num_updates 27300 | best_loss 8.499
2022-03-06 08:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27300 updates
2022-03-06 08:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:22:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 561 @ 27300 updates, score 13.78) (writing took 1.918827765621245 seconds)
2022-03-06 08:22:07 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-06 08:22:07 | INFO | train | epoch 561 | loss 1.184 | nll_loss 0.211 | ppl 1.16 | wps 27540.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27300 | lr 0.00019139 | gnorm 0.375 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 64803
2022-03-06 08:22:07 | INFO | fairseq.trainer | begin training epoch 562
2022-03-06 08:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:22:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:23:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:24:00 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 13.774 | nll_loss 13.452 | ppl 11202.4 | wps 46419.1 | wpb 510.9 | bsz 1 | num_updates 27348 | best_loss 8.499
2022-03-06 08:24:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27348 updates
2022-03-06 08:24:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:24:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:24:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 562 @ 27348 updates, score 13.774) (writing took 1.937783032655716 seconds)
2022-03-06 08:24:02 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-06 08:24:02 | INFO | train | epoch 562 | loss 1.183 | nll_loss 0.21 | ppl 1.16 | wps 26973.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27348 | lr 0.000191222 | gnorm 0.377 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 64919
2022-03-06 08:24:02 | INFO | fairseq.trainer | begin training epoch 563
2022-03-06 08:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:25:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:25:55 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 13.776 | nll_loss 13.452 | ppl 11205.6 | wps 45796.1 | wpb 510.9 | bsz 1 | num_updates 27397 | best_loss 8.499
2022-03-06 08:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27397 updates
2022-03-06 08:25:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:25:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:25:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 563 @ 27397 updates, score 13.776) (writing took 1.914133494719863 seconds)
2022-03-06 08:25:57 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-06 08:25:57 | INFO | train | epoch 563 | loss 1.184 | nll_loss 0.212 | ppl 1.16 | wps 27528.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27397 | lr 0.000191051 | gnorm 0.382 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 65034
2022-03-06 08:25:57 | INFO | fairseq.trainer | begin training epoch 564
2022-03-06 08:25:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:26:04 | INFO | train_inner | epoch 564:      3 / 49 loss=1.184, nll_loss=0.211, ppl=1.16, wps=26549, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.379, loss_scale=32, train_wall=201, gb_free=21.6, wall=65041
2022-03-06 08:27:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:27:51 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 13.747 | nll_loss 13.423 | ppl 10982.3 | wps 46315.3 | wpb 510.9 | bsz 1 | num_updates 27445 | best_loss 8.499
2022-03-06 08:27:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27445 updates
2022-03-06 08:27:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:27:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:27:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 564 @ 27445 updates, score 13.747) (writing took 1.9042806271463633 seconds)
2022-03-06 08:27:53 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-06 08:27:53 | INFO | train | epoch 564 | loss 1.183 | nll_loss 0.21 | ppl 1.16 | wps 26949.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27445 | lr 0.000190883 | gnorm 0.377 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 65150
2022-03-06 08:27:53 | INFO | fairseq.trainer | begin training epoch 565
2022-03-06 08:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:29:46 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 13.871 | nll_loss 13.551 | ppl 12004.7 | wps 46180.2 | wpb 510.9 | bsz 1 | num_updates 27494 | best_loss 8.499
2022-03-06 08:29:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27494 updates
2022-03-06 08:29:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:29:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:29:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 565 @ 27494 updates, score 13.871) (writing took 1.8998305145651102 seconds)
2022-03-06 08:29:48 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-06 08:29:48 | INFO | train | epoch 565 | loss 1.183 | nll_loss 0.211 | ppl 1.16 | wps 27546.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27494 | lr 0.000190713 | gnorm 0.379 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 65265
2022-03-06 08:29:48 | INFO | fairseq.trainer | begin training epoch 566
2022-03-06 08:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:30:02 | INFO | train_inner | epoch 566:      6 / 49 loss=1.183, nll_loss=0.21, ppl=1.16, wps=27309.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.378, loss_scale=32, train_wall=201, gb_free=21.6, wall=65279
2022-03-06 08:31:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:31:42 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 13.83 | nll_loss 13.508 | ppl 11650.9 | wps 46032.4 | wpb 510.9 | bsz 1 | num_updates 27543 | best_loss 8.499
2022-03-06 08:31:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27543 updates
2022-03-06 08:31:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:31:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:31:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 566 @ 27543 updates, score 13.83) (writing took 1.900565599091351 seconds)
2022-03-06 08:31:44 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-06 08:31:44 | INFO | train | epoch 566 | loss 1.183 | nll_loss 0.21 | ppl 1.16 | wps 27541.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27543 | lr 0.000190544 | gnorm 0.38 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 65380
2022-03-06 08:31:44 | INFO | fairseq.trainer | begin training epoch 567
2022-03-06 08:31:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:32:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:33:37 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 13.922 | nll_loss 13.605 | ppl 12458.4 | wps 46151.4 | wpb 510.9 | bsz 1 | num_updates 27591 | best_loss 8.499
2022-03-06 08:33:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27591 updates
2022-03-06 08:33:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:33:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 567 @ 27591 updates, score 13.922) (writing took 1.8954387791454792 seconds)
2022-03-06 08:33:39 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-06 08:33:39 | INFO | train | epoch 567 | loss 1.182 | nll_loss 0.21 | ppl 1.16 | wps 26949.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27591 | lr 0.000190378 | gnorm 0.377 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 65496
2022-03-06 08:33:39 | INFO | fairseq.trainer | begin training epoch 568
2022-03-06 08:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:33:59 | INFO | train_inner | epoch 568:      9 / 49 loss=1.182, nll_loss=0.21, ppl=1.16, wps=27301.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.379, loss_scale=32, train_wall=201, gb_free=21.6, wall=65516
2022-03-06 08:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:35:33 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 13.734 | nll_loss 13.409 | ppl 10873.5 | wps 45963 | wpb 510.9 | bsz 1 | num_updates 27640 | best_loss 8.499
2022-03-06 08:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27640 updates
2022-03-06 08:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:35:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:35:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 568 @ 27640 updates, score 13.734) (writing took 1.9073281437158585 seconds)
2022-03-06 08:35:35 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-06 08:35:35 | INFO | train | epoch 568 | loss 1.181 | nll_loss 0.209 | ppl 1.16 | wps 27538 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27640 | lr 0.000190209 | gnorm 0.375 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 65611
2022-03-06 08:35:35 | INFO | fairseq.trainer | begin training epoch 569
2022-03-06 08:35:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:37:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:37:28 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 13.853 | nll_loss 13.532 | ppl 11848.1 | wps 46235.5 | wpb 510.9 | bsz 1 | num_updates 27689 | best_loss 8.499
2022-03-06 08:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27689 updates
2022-03-06 08:37:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:37:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:37:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 569 @ 27689 updates, score 13.853) (writing took 1.898865475319326 seconds)
2022-03-06 08:37:30 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-06 08:37:30 | INFO | train | epoch 569 | loss 1.182 | nll_loss 0.21 | ppl 1.16 | wps 27483.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27689 | lr 0.000190041 | gnorm 0.377 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 65727
2022-03-06 08:37:30 | INFO | fairseq.trainer | begin training epoch 570
2022-03-06 08:37:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:37:55 | INFO | train_inner | epoch 570:     11 / 49 loss=1.182, nll_loss=0.21, ppl=1.16, wps=27534.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.376, loss_scale=64, train_wall=199, gb_free=21.6, wall=65752
2022-03-06 08:38:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:39:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:39:24 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 13.827 | nll_loss 13.506 | ppl 11632.7 | wps 45991.5 | wpb 510.9 | bsz 1 | num_updates 27737 | best_loss 8.499
2022-03-06 08:39:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27737 updates
2022-03-06 08:39:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:39:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:39:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 570 @ 27737 updates, score 13.827) (writing took 1.9000646518543363 seconds)
2022-03-06 08:39:26 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-06 08:39:26 | INFO | train | epoch 570 | loss 1.182 | nll_loss 0.209 | ppl 1.16 | wps 26915.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27737 | lr 0.000189876 | gnorm 0.378 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 65843
2022-03-06 08:39:26 | INFO | fairseq.trainer | begin training epoch 571
2022-03-06 08:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:41:20 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 13.856 | nll_loss 13.536 | ppl 11876.9 | wps 45984.5 | wpb 510.9 | bsz 1 | num_updates 27786 | best_loss 8.499
2022-03-06 08:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27786 updates
2022-03-06 08:41:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:41:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:41:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 571 @ 27786 updates, score 13.856) (writing took 1.881868563592434 seconds)
2022-03-06 08:41:21 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-06 08:41:21 | INFO | train | epoch 571 | loss 1.182 | nll_loss 0.209 | ppl 1.16 | wps 27484.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27786 | lr 0.000189709 | gnorm 0.373 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 65958
2022-03-06 08:41:21 | INFO | fairseq.trainer | begin training epoch 572
2022-03-06 08:41:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:41:53 | INFO | train_inner | epoch 572:     14 / 49 loss=1.182, nll_loss=0.209, ppl=1.16, wps=27255.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.376, loss_scale=32, train_wall=202, gb_free=21.6, wall=65990
2022-03-06 08:43:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:43:15 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 13.854 | nll_loss 13.534 | ppl 11857.7 | wps 46338.6 | wpb 510.9 | bsz 1 | num_updates 27835 | best_loss 8.499
2022-03-06 08:43:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27835 updates
2022-03-06 08:43:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:43:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:43:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 572 @ 27835 updates, score 13.854) (writing took 1.9028929118067026 seconds)
2022-03-06 08:43:17 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-06 08:43:17 | INFO | train | epoch 572 | loss 1.181 | nll_loss 0.209 | ppl 1.16 | wps 27503.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27835 | lr 0.000189542 | gnorm 0.378 | loss_scale 64 | train_wall 98 | gb_free 21.6 | wall 66074
2022-03-06 08:43:17 | INFO | fairseq.trainer | begin training epoch 573
2022-03-06 08:43:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:43:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:45:11 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 13.859 | nll_loss 13.537 | ppl 11885.4 | wps 46327 | wpb 510.9 | bsz 1 | num_updates 27883 | best_loss 8.499
2022-03-06 08:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27883 updates
2022-03-06 08:45:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:45:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:45:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 573 @ 27883 updates, score 13.859) (writing took 1.8721177782863379 seconds)
2022-03-06 08:45:12 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-06 08:45:12 | INFO | train | epoch 573 | loss 1.181 | nll_loss 0.208 | ppl 1.16 | wps 26956.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27883 | lr 0.000189378 | gnorm 0.37 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 66189
2022-03-06 08:45:13 | INFO | fairseq.trainer | begin training epoch 574
2022-03-06 08:45:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:45:51 | INFO | train_inner | epoch 574:     17 / 49 loss=1.181, nll_loss=0.209, ppl=1.16, wps=27306.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.373, loss_scale=32, train_wall=201, gb_free=21.6, wall=66227
2022-03-06 08:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:47:06 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 13.886 | nll_loss 13.566 | ppl 12130.9 | wps 45789.5 | wpb 510.9 | bsz 1 | num_updates 27932 | best_loss 8.499
2022-03-06 08:47:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27932 updates
2022-03-06 08:47:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:47:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:47:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 574 @ 27932 updates, score 13.886) (writing took 1.9216165896505117 seconds)
2022-03-06 08:47:08 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-06 08:47:08 | INFO | train | epoch 574 | loss 1.181 | nll_loss 0.209 | ppl 1.16 | wps 27559.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 27932 | lr 0.000189212 | gnorm 0.375 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66305
2022-03-06 08:47:08 | INFO | fairseq.trainer | begin training epoch 575
2022-03-06 08:47:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:48:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:49:01 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 13.784 | nll_loss 13.464 | ppl 11295.9 | wps 46169.1 | wpb 510.9 | bsz 1 | num_updates 27980 | best_loss 8.499
2022-03-06 08:49:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27980 updates
2022-03-06 08:49:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:49:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:49:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 575 @ 27980 updates, score 13.784) (writing took 1.9019056670367718 seconds)
2022-03-06 08:49:03 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-06 08:49:03 | INFO | train | epoch 575 | loss 1.181 | nll_loss 0.209 | ppl 1.16 | wps 26974.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27980 | lr 0.00018905 | gnorm 0.376 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 66420
2022-03-06 08:49:03 | INFO | fairseq.trainer | begin training epoch 576
2022-03-06 08:49:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:49:48 | INFO | train_inner | epoch 576:     20 / 49 loss=1.181, nll_loss=0.209, ppl=1.16, wps=27296.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.376, loss_scale=32, train_wall=201, gb_free=21.6, wall=66465
2022-03-06 08:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:50:57 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 13.832 | nll_loss 13.511 | ppl 11674.1 | wps 45791.6 | wpb 510.9 | bsz 1 | num_updates 28029 | best_loss 8.499
2022-03-06 08:50:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28029 updates
2022-03-06 08:50:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:50:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:50:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 576 @ 28029 updates, score 13.832) (writing took 1.901119596324861 seconds)
2022-03-06 08:50:59 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-06 08:50:59 | INFO | train | epoch 576 | loss 1.18 | nll_loss 0.208 | ppl 1.16 | wps 27492.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 28029 | lr 0.000188884 | gnorm 0.376 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 66536
2022-03-06 08:50:59 | INFO | fairseq.trainer | begin training epoch 577
2022-03-06 08:50:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:52:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:52:52 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 13.869 | nll_loss 13.547 | ppl 11971.8 | wps 45890 | wpb 510.9 | bsz 1 | num_updates 28078 | best_loss 8.499
2022-03-06 08:52:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28078 updates
2022-03-06 08:52:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:52:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:52:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 577 @ 28078 updates, score 13.869) (writing took 1.865718737244606 seconds)
2022-03-06 08:52:54 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-06 08:52:54 | INFO | train | epoch 577 | loss 1.179 | nll_loss 0.208 | ppl 1.15 | wps 27582.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28078 | lr 0.00018872 | gnorm 0.368 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66651
2022-03-06 08:52:54 | INFO | fairseq.trainer | begin training epoch 578
2022-03-06 08:52:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:53:43 | INFO | train_inner | epoch 578:     22 / 49 loss=1.18, nll_loss=0.208, ppl=1.15, wps=27594.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.371, loss_scale=32, train_wall=199, gb_free=21.6, wall=66700
2022-03-06 08:53:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:54:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:54:47 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 13.902 | nll_loss 13.585 | ppl 12284.5 | wps 45800.9 | wpb 510.9 | bsz 1 | num_updates 28126 | best_loss 8.499
2022-03-06 08:54:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28126 updates
2022-03-06 08:54:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:54:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt
2022-03-06 08:54:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#1/checkpoint_last.pt (epoch 578 @ 28126 updates, score 13.902) (writing took 1.9267553919926286 seconds)
2022-03-06 08:54:49 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-06 08:54:49 | INFO | train | epoch 578 | loss 1.18 | nll_loss 0.208 | ppl 1.16 | wps 26974.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28126 | lr 0.000188558 | gnorm 0.377 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66766
2022-03-06 08:54:49 | INFO | fairseq.trainer | begin training epoch 579
2022-03-06 08:54:49 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/label_smoothed_cross_entropy.py", line 79, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 340, in extract_features_scriptable
    x, layer_attn, _ = layer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/transformer_layer.py", line 428, in forward
    x = self.dropout_module(x)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/fairseq_dropout.py", line 25, in forward
    return F.dropout(x, p=self.p, training=True, inplace=inplace)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 983, in dropout
    else _VF.dropout(input, p, training))
KeyboardInterrupt
