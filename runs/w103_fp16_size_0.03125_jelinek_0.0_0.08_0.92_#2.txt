Sender: LSF System <lsfadmin@eu-g3-074>
Subject: Job 207362713: <w103_fp16_size_0.03125_jelinek_0.0_0.08_0.92_#2> in cluster <euler> Exited

Job <w103_fp16_size_0.03125_jelinek_0.0_0.08_0.92_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 20:41:43 2022
Job was executed on host(s) <eu-g3-074>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Sun Mar  6 20:42:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 20:42:15 2022
Terminated at Tue Mar  8 06:20:45 2022
Results reported at Tue Mar  8 06:20:45 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.0, 0.08, 0.92)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --no-epoch-checkpoints --no-last-checkpoints --seed 66575622 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   121031.98 sec.
    Max Memory :                                 5802 MB
    Average Memory :                             2725.31 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14198.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                16
    Run time :                                   121110 sec.
    Turnaround time :                            121142 sec.

The output (if any) follows:

2022-03-06 20:42:20 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575622, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575622, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.0, 0.08, 0.92)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 20:42:20 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-06 20:42:22 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
Calculating frequency stats:
  0%|          | 0/56292 [00:00<?, ?it/s]  1%|          | 666/56292 [00:00<00:08, 6638.83it/s]  2%|▏         | 1330/56292 [00:00<00:09, 5911.76it/s]  3%|▎         | 1927/56292 [00:00<00:09, 5739.99it/s]  4%|▍         | 2504/56292 [00:00<00:09, 5692.97it/s]  6%|▌         | 3222/56292 [00:00<00:08, 6197.96it/s]  7%|▋         | 3845/56292 [00:00<00:08, 6207.93it/s]  8%|▊         | 4564/56292 [00:00<00:07, 6517.54it/s]  9%|▉         | 5268/56292 [00:00<00:07, 6678.74it/s] 11%|█         | 5979/56292 [00:00<00:07, 6805.05it/s] 12%|█▏        | 6661/56292 [00:01<00:08, 6192.01it/s] 13%|█▎        | 7292/56292 [00:01<00:07, 6207.44it/s] 14%|█▍        | 7921/56292 [00:01<00:07, 6140.31it/s] 15%|█▌        | 8541/56292 [00:01<00:08, 5893.29it/s] 16%|█▋        | 9179/56292 [00:01<00:07, 6030.73it/s] 17%|█▋        | 9818/56292 [00:01<00:07, 6126.38it/s] 19%|█▊        | 10435/56292 [00:01<00:07, 6125.68it/s] 20%|█▉        | 11050/56292 [00:01<00:07, 6083.41it/s] 21%|██        | 11660/56292 [00:01<00:07, 5926.83it/s] 22%|██▏       | 12298/56292 [00:02<00:07, 6053.60it/s] 23%|██▎       | 12908/56292 [00:02<00:07, 6063.20it/s] 24%|██▍       | 13605/56292 [00:02<00:06, 6325.27it/s] 25%|██▌       | 14239/56292 [00:02<00:06, 6152.88it/s] 26%|██▋       | 14886/56292 [00:02<00:06, 6238.65it/s] 28%|██▊       | 15512/56292 [00:02<00:06, 6096.45it/s] 29%|██▊       | 16124/56292 [00:02<00:06, 5961.01it/s] 30%|██▉       | 16722/56292 [00:02<00:06, 5885.91it/s] 31%|███       | 17383/56292 [00:02<00:06, 6086.72it/s] 32%|███▏      | 17993/56292 [00:02<00:06, 6060.46it/s] 33%|███▎      | 18600/56292 [00:03<00:06, 5903.20it/s] 35%|███▍      | 19425/56292 [00:03<00:05, 6580.54it/s] 36%|███▌      | 20087/56292 [00:03<00:05, 6118.25it/s] 37%|███▋      | 20707/56292 [00:03<00:05, 5997.07it/s] 38%|███▊      | 21313/56292 [00:03<00:06, 5767.92it/s] 39%|███▉      | 21919/56292 [00:03<00:05, 5848.16it/s] 40%|████      | 22572/56292 [00:03<00:05, 6040.29it/s] 41%|████      | 23215/56292 [00:03<00:05, 6150.58it/s] 43%|████▎     | 23956/56292 [00:03<00:04, 6517.77it/s] 44%|████▍     | 24716/56292 [00:03<00:04, 6834.42it/s] 45%|████▌     | 25403/56292 [00:04<00:04, 6746.98it/s] 46%|████▋     | 26080/56292 [00:04<00:04, 6359.58it/s] 47%|████▋     | 26722/56292 [00:04<00:04, 6141.68it/s] 49%|████▊     | 27341/56292 [00:04<00:04, 5895.92it/s] 50%|████▉     | 27935/56292 [00:04<00:04, 5825.93it/s] 51%|█████     | 28695/56292 [00:04<00:04, 6324.14it/s] 52%|█████▏    | 29333/56292 [00:04<00:04, 6045.76it/s] 53%|█████▎    | 30011/56292 [00:04<00:04, 6249.32it/s] 54%|█████▍    | 30642/56292 [00:04<00:04, 5922.10it/s] 55%|█████▌    | 31241/56292 [00:05<00:04, 5777.89it/s] 57%|█████▋    | 31864/56292 [00:05<00:04, 5900.91it/s] 58%|█████▊    | 32458/56292 [00:05<00:04, 5848.98it/s] 59%|█████▊    | 33046/56292 [00:05<00:04, 5732.52it/s] 60%|█████▉    | 33642/56292 [00:05<00:03, 5797.56it/s] 61%|██████    | 34225/56292 [00:05<00:03, 5806.29it/s] 62%|██████▏   | 34951/56292 [00:05<00:03, 6229.10it/s] 63%|██████▎   | 35576/56292 [00:05<00:03, 6053.11it/s] 64%|██████▍   | 36199/56292 [00:05<00:03, 6101.58it/s] 65%|██████▌   | 36811/56292 [00:06<00:03, 6078.83it/s] 66%|██████▋   | 37420/56292 [00:06<00:03, 5691.36it/s] 68%|██████▊   | 38004/56292 [00:06<00:03, 5724.82it/s] 69%|██████▊   | 38612/56292 [00:06<00:03, 5824.22it/s] 70%|██████▉   | 39257/56292 [00:06<00:02, 6004.45it/s] 71%|███████   | 39861/56292 [00:06<00:02, 5973.18it/s] 72%|███████▏  | 40537/56292 [00:06<00:02, 6204.30it/s] 73%|███████▎  | 41160/56292 [00:06<00:02, 6167.48it/s] 74%|███████▍  | 41779/56292 [00:06<00:02, 5906.52it/s] 75%|███████▌  | 42373/56292 [00:06<00:02, 5737.48it/s] 76%|███████▋  | 42951/56292 [00:07<00:02, 5745.36it/s] 77%|███████▋  | 43553/56292 [00:07<00:02, 5822.62it/s] 78%|███████▊  | 44184/56292 [00:07<00:02, 5960.81it/s] 80%|███████▉  | 44863/56292 [00:07<00:01, 6201.90it/s] 81%|████████  | 45485/56292 [00:07<00:01, 6182.95it/s] 82%|████████▏ | 46164/56292 [00:07<00:01, 6352.29it/s] 83%|████████▎ | 46801/56292 [00:07<00:01, 6288.39it/s] 85%|████████▍ | 47803/56292 [00:07<00:01, 7387.61it/s] 86%|████████▌ | 48544/56292 [00:07<00:01, 7097.73it/s] 88%|████████▊ | 49273/56292 [00:08<00:00, 7150.18it/s] 89%|████████▉ | 49991/56292 [00:08<00:00, 6912.71it/s] 90%|█████████ | 50686/56292 [00:08<00:00, 6372.28it/s] 91%|█████████ | 51333/56292 [00:08<00:00, 6162.75it/s] 92%|█████████▏| 52057/56292 [00:08<00:00, 6457.61it/s] 94%|█████████▍| 52817/56292 [00:08<00:00, 6778.55it/s] 95%|█████████▌| 53503/56292 [00:08<00:00, 6443.31it/s] 96%|█████████▌| 54155/56292 [00:08<00:00, 6309.35it/s] 97%|█████████▋| 54792/56292 [00:08<00:00, 6070.12it/s] 98%|█████████▊| 55425/56292 [00:09<00:00, 6139.53it/s]100%|█████████▉| 56140/56292 [00:09<00:00, 6424.14it/s]100%|██████████| 56292/56292 [00:09<00:00, 6162.88it/s]

gathering stats for n=1
  0%|          | 0/56292 [00:00<?, ?it/s]  3%|▎         | 1894/56292 [00:00<00:02, 18912.56it/s]  7%|▋         | 3933/56292 [00:00<00:02, 19777.61it/s] 11%|█         | 6131/56292 [00:00<00:02, 20780.59it/s] 15%|█▍        | 8210/56292 [00:00<00:02, 19700.57it/s] 18%|█▊        | 10206/56292 [00:00<00:02, 19787.78it/s] 22%|██▏       | 12191/56292 [00:00<00:02, 19624.98it/s] 25%|██▌       | 14177/56292 [00:00<00:02, 19692.79it/s] 29%|██▊       | 16149/56292 [00:00<00:02, 19542.19it/s] 32%|███▏      | 18123/56292 [00:00<00:01, 19597.22it/s] 36%|███▌      | 20200/56292 [00:01<00:01, 19947.42it/s] 39%|███▉      | 22196/56292 [00:01<00:01, 19609.46it/s] 43%|████▎     | 24445/56292 [00:01<00:01, 20469.66it/s] 47%|████▋     | 26495/56292 [00:01<00:01, 20303.80it/s] 51%|█████     | 28528/56292 [00:01<00:01, 20072.40it/s] 54%|█████▍    | 30538/56292 [00:01<00:01, 19757.25it/s] 58%|█████▊    | 32516/56292 [00:01<00:01, 19294.91it/s] 61%|██████    | 34449/56292 [00:01<00:01, 19213.31it/s] 65%|██████▍   | 36428/56292 [00:01<00:01, 19376.55it/s] 68%|██████▊   | 38368/56292 [00:01<00:00, 18932.49it/s] 72%|███████▏  | 40376/56292 [00:02<00:00, 19263.32it/s] 75%|███████▌  | 42306/56292 [00:02<00:00, 19024.14it/s] 79%|███████▊  | 44211/56292 [00:02<00:00, 19010.03it/s] 82%|████████▏ | 46280/56292 [00:02<00:00, 19501.17it/s] 86%|████████▌ | 48537/56292 [00:02<00:00, 20409.46it/s] 90%|████████▉ | 50581/56292 [00:02<00:00, 20314.42it/s] 94%|█████████▎| 52762/56292 [00:02<00:00, 20751.44it/s] 97%|█████████▋| 54839/56292 [00:02<00:00, 20105.68it/s]100%|██████████| 56292/56292 [00:02<00:00, 19786.16it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 164.45it/s]2022-03-06 20:42:38 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-06 20:42:38 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 20:42:38 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 20:42:38 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-06 20:42:38 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-06 20:42:38 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 20:42:38 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-06 20:42:38 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 20:42:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 20:42:38 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-06 20:42:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 20:42:38 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 20:42:38 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 20:42:38 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_last.pt
2022-03-06 20:42:38 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_last.pt
2022-03-06 20:42:38 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 20:42:38 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-06 20:42:38 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 20:42:38 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-06 20:42:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 20:42:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:42:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:43:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:44:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 20:45:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:45:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.316 | ppl 40800.9 | wps 39014.1 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-06 20:45:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-06 20:45:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:45:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:45:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.316) (writing took 1.8725987747311592 seconds)
2022-03-06 20:45:19 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 20:45:19 | INFO | train | epoch 001 | loss 16.507 | ppl 93141.8 | wps 21149.7 | ups 0.33 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 5.238 | loss_scale 4 | train_wall 142 | gb_free 21.5 | wall 161
2022-03-06 20:45:19 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 20:45:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:47:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:47:44 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.831 | ppl 14573.7 | wps 38996.9 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 13.831
2022-03-06 20:47:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-06 20:47:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:47:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:47:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 2 @ 93 updates, score 13.831) (writing took 1.8325964687392116 seconds)
2022-03-06 20:47:45 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 20:47:45 | INFO | train | epoch 002 | loss 14.591 | ppl 24686.5 | wps 21735.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.254 | loss_scale 4 | train_wall 128 | gb_free 21.5 | wall 307
2022-03-06 20:47:46 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 20:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:48:06 | INFO | train_inner | epoch 003:      7 / 49 loss=15.385, ppl=42793.8, wps=21551.2, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.516, loss_scale=4, train_wall=288, gb_free=21.5, wall=327
2022-03-06 20:50:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:50:10 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.16 | ppl 9151.36 | wps 38981 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.16
2022-03-06 20:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-06 20:50:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:50:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.16) (writing took 2.0306269489228725 seconds)
2022-03-06 20:50:12 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 20:50:12 | INFO | train | epoch 003 | loss 13.632 | ppl 12694.2 | wps 21714.9 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.435 | loss_scale 4 | train_wall 128 | gb_free 21.5 | wall 454
2022-03-06 20:50:12 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 20:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:52:36 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.348 | ppl 5214.84 | wps 38879.4 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.348
2022-03-06 20:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-06 20:52:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:52:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.348) (writing took 1.8250275366008282 seconds)
2022-03-06 20:52:38 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 20:52:38 | INFO | train | epoch 004 | loss 12.891 | ppl 7598.3 | wps 21748 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.261 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 600
2022-03-06 20:52:38 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 20:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:53:04 | INFO | train_inner | epoch 005:      9 / 49 loss=13.134, ppl=8989.6, wps=21748.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.314, loss_scale=8, train_wall=260, gb_free=21.5, wall=626
2022-03-06 20:54:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:55:03 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.546 | ppl 2989.2 | wps 38857.2 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.546
2022-03-06 20:55:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-06 20:55:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:55:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.546) (writing took 1.8451189156621695 seconds)
2022-03-06 20:55:04 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 20:55:04 | INFO | train | epoch 005 | loss 12.024 | ppl 4164.07 | wps 21710.1 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 1.002 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 746
2022-03-06 20:55:04 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 20:55:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:57:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:57:29 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.903 | ppl 1915.36 | wps 38854.9 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 10.903
2022-03-06 20:57:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-06 20:57:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:57:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:57:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 6 @ 289 updates, score 10.903) (writing took 1.8227769127115607 seconds)
2022-03-06 20:57:31 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 20:57:31 | INFO | train | epoch 006 | loss 11.262 | ppl 2456.04 | wps 21724 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.773 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 892
2022-03-06 20:57:31 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 20:57:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:58:02 | INFO | train_inner | epoch 007:     11 / 49 loss=11.491, ppl=2878.11, wps=21747.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.846, loss_scale=16, train_wall=261, gb_free=21.5, wall=924
2022-03-06 20:59:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:59:55 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.491 | ppl 1439.34 | wps 38952 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.491
2022-03-06 20:59:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-06 20:59:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:59:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 20:59:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.491) (writing took 1.8802589783445 seconds)
2022-03-06 20:59:57 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 20:59:57 | INFO | train | epoch 007 | loss 10.693 | ppl 1655.79 | wps 21719.7 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.6 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 1039
2022-03-06 20:59:57 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 20:59:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:02:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:02:21 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.248 | ppl 1216.14 | wps 38955.8 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.248
2022-03-06 21:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-06 21:02:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:02:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.248) (writing took 1.9099140651524067 seconds)
2022-03-06 21:02:23 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 21:02:23 | INFO | train | epoch 008 | loss 10.341 | ppl 1297.31 | wps 21714.4 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.474 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 1185
2022-03-06 21:02:23 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 21:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:03:01 | INFO | train_inner | epoch 009:     13 / 49 loss=10.436, ppl=1385.33, wps=21742.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.503, loss_scale=16, train_wall=261, gb_free=21.5, wall=1222
2022-03-06 21:04:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:04:48 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.088 | ppl 1088.23 | wps 39065.9 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.088
2022-03-06 21:04:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-06 21:04:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:04:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:04:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.088) (writing took 1.854537596926093 seconds)
2022-03-06 21:04:50 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 21:04:50 | INFO | train | epoch 009 | loss 10.126 | ppl 1117.14 | wps 21732.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.454 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 1331
2022-03-06 21:04:50 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 21:04:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:07:14 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.956 | ppl 992.91 | wps 38970.7 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 9.956
2022-03-06 21:07:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-06 21:07:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:07:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:07:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 10 @ 485 updates, score 9.956) (writing took 1.874041398987174 seconds)
2022-03-06 21:07:16 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 21:07:16 | INFO | train | epoch 010 | loss 9.961 | ppl 996.9 | wps 21737.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.472 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 1478
2022-03-06 21:07:16 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 21:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:07:59 | INFO | train_inner | epoch 011:     15 / 49 loss=9.995, ppl=1020.31, wps=21753.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.469, loss_scale=32, train_wall=260, gb_free=21.5, wall=1520
2022-03-06 21:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:09:40 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.831 | ppl 910.53 | wps 39064.8 | wpb 510.9 | bsz 1 | num_updates 534 | best_loss 9.831
2022-03-06 21:09:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 534 updates
2022-03-06 21:09:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:09:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:09:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 11 @ 534 updates, score 9.831) (writing took 1.8941009799018502 seconds)
2022-03-06 21:09:42 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 21:09:42 | INFO | train | epoch 011 | loss 9.811 | ppl 898.39 | wps 21730.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 534 | lr 6.68367e-05 | gnorm 0.52 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 1624
2022-03-06 21:09:42 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 21:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:10:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:12:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:12:06 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.721 | ppl 843.91 | wps 38965.1 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 9.721
2022-03-06 21:12:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-06 21:12:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:12:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:12:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 12 @ 582 updates, score 9.721) (writing took 1.8617989793419838 seconds)
2022-03-06 21:12:08 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 21:12:08 | INFO | train | epoch 012 | loss 9.669 | ppl 813.98 | wps 21282 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.581 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 1770
2022-03-06 21:12:08 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 21:12:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:13:00 | INFO | train_inner | epoch 013:     18 / 49 loss=9.692, ppl=827.12, wps=21550.1, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.573, loss_scale=32, train_wall=263, gb_free=21.5, wall=1822
2022-03-06 21:14:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:14:33 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.621 | ppl 787.65 | wps 38882.6 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.621
2022-03-06 21:14:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-06 21:14:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:14:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.621) (writing took 1.8213254064321518 seconds)
2022-03-06 21:14:34 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 21:14:34 | INFO | train | epoch 013 | loss 9.535 | ppl 741.62 | wps 21735.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.617 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 1916
2022-03-06 21:14:35 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 21:14:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:16:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:16:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:16:59 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.535 | ppl 741.71 | wps 39044.9 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.535
2022-03-06 21:16:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-06 21:16:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:17:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:17:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.535) (writing took 1.835279111750424 seconds)
2022-03-06 21:17:01 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 21:17:01 | INFO | train | epoch 014 | loss 9.406 | ppl 678.23 | wps 21292 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.658 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 2062
2022-03-06 21:17:01 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 21:17:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:18:01 | INFO | train_inner | epoch 015:     21 / 49 loss=9.419, ppl=684.51, wps=21554.8, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.657, loss_scale=32, train_wall=263, gb_free=21.5, wall=2122
2022-03-06 21:19:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:19:25 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.444 | ppl 696.43 | wps 38816 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.444
2022-03-06 21:19:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-06 21:19:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:19:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:19:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.444) (writing took 1.8763817008584738 seconds)
2022-03-06 21:19:27 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 21:19:27 | INFO | train | epoch 015 | loss 9.28 | ppl 621.64 | wps 21727.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.704 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 2209
2022-03-06 21:19:27 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 21:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:21:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:21:51 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.356 | ppl 655.52 | wps 38982.1 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.356
2022-03-06 21:21:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-06 21:21:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:21:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:21:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.356) (writing took 1.866639801301062 seconds)
2022-03-06 21:21:53 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 21:21:53 | INFO | train | epoch 016 | loss 9.157 | ppl 570.86 | wps 21704.3 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.773 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 2355
2022-03-06 21:21:53 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 21:21:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:22:59 | INFO | train_inner | epoch 017:     23 / 49 loss=9.163, ppl=573.08, wps=21741.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.747, loss_scale=32, train_wall=261, gb_free=21.5, wall=2421
2022-03-06 21:23:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:24:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:24:18 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.278 | ppl 621.01 | wps 39082 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.278
2022-03-06 21:24:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-06 21:24:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:24:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:24:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.278) (writing took 2.072564226575196 seconds)
2022-03-06 21:24:20 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 21:24:20 | INFO | train | epoch 017 | loss 9.037 | ppl 525.23 | wps 21260.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.771 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 2502
2022-03-06 21:24:20 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 21:24:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:26:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:26:44 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.208 | ppl 591.57 | wps 38974.2 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 9.208
2022-03-06 21:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-06 21:26:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:26:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 18 @ 874 updates, score 9.208) (writing took 1.8815285665914416 seconds)
2022-03-06 21:26:46 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 21:26:46 | INFO | train | epoch 018 | loss 8.922 | ppl 484.95 | wps 21736.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.818 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 2648
2022-03-06 21:26:46 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 21:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:28:00 | INFO | train_inner | epoch 019:     26 / 49 loss=8.92, ppl=484.38, wps=21530, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.811, loss_scale=32, train_wall=263, gb_free=21.5, wall=2722
2022-03-06 21:29:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:29:11 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.136 | ppl 562.71 | wps 38940.4 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.136
2022-03-06 21:29:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-06 21:29:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:29:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:29:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.136) (writing took 1.8711185790598392 seconds)
2022-03-06 21:29:12 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 21:29:12 | INFO | train | epoch 019 | loss 8.811 | ppl 449.01 | wps 21705.7 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.872 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 2794
2022-03-06 21:29:12 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 21:29:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:29:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:31:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:31:37 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.091 | ppl 545.32 | wps 39091.6 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 9.091
2022-03-06 21:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-06 21:31:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:31:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:31:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 20 @ 971 updates, score 9.091) (writing took 1.8754520481452346 seconds)
2022-03-06 21:31:39 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 21:31:39 | INFO | train | epoch 020 | loss 8.702 | ppl 416.58 | wps 21267.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.843 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 2940
2022-03-06 21:31:39 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 21:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:33:02 | INFO | train_inner | epoch 021:     29 / 49 loss=8.696, ppl=414.83, wps=21531, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.848, loss_scale=32, train_wall=263, gb_free=21.5, wall=3023
2022-03-06 21:33:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:34:03 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.035 | ppl 524.51 | wps 38899.2 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 9.035
2022-03-06 21:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-06 21:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 21 @ 1020 updates, score 9.035) (writing took 1.871571734547615 seconds)
2022-03-06 21:34:05 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 21:34:05 | INFO | train | epoch 021 | loss 8.599 | ppl 387.74 | wps 21708.3 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.808 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 3087
2022-03-06 21:34:05 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 21:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:36:30 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.989 | ppl 508.1 | wps 39130.7 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 8.989
2022-03-06 21:36:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-06 21:36:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:36:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 22 @ 1069 updates, score 8.989) (writing took 1.8222488081082702 seconds)
2022-03-06 21:36:31 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 21:36:31 | INFO | train | epoch 022 | loss 8.5 | ppl 361.99 | wps 21729.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.895 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 3233
2022-03-06 21:36:31 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 21:36:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:36:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:38:03 | INFO | train_inner | epoch 023:     32 / 49 loss=8.487, ppl=358.86, wps=21537.2, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.863, loss_scale=32, train_wall=263, gb_free=21.5, wall=3325
2022-03-06 21:38:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:38:56 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.972 | ppl 502.24 | wps 38761 | wpb 510.9 | bsz 1 | num_updates 1117 | best_loss 8.972
2022-03-06 21:38:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1117 updates
2022-03-06 21:38:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:38:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:38:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 23 @ 1117 updates, score 8.972) (writing took 1.8499848432838917 seconds)
2022-03-06 21:38:58 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 21:38:58 | INFO | train | epoch 023 | loss 8.403 | ppl 338.59 | wps 21272.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1117 | lr 0.000139697 | gnorm 0.857 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 3379
2022-03-06 21:38:58 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 21:38:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:41:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:41:22 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.927 | ppl 486.82 | wps 38850.2 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 8.927
2022-03-06 21:41:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-06 21:41:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:41:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:41:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 24 @ 1166 updates, score 8.927) (writing took 1.8555980892851949 seconds)
2022-03-06 21:41:24 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 21:41:24 | INFO | train | epoch 024 | loss 8.307 | ppl 316.66 | wps 21714.7 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.864 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 3526
2022-03-06 21:41:24 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 21:41:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:43:01 | INFO | train_inner | epoch 025:     34 / 49 loss=8.291, ppl=313.16, wps=21733.5, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.87, loss_scale=64, train_wall=261, gb_free=21.5, wall=3623
2022-03-06 21:43:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:43:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:43:49 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.879 | ppl 470.73 | wps 38994.1 | wpb 510.9 | bsz 1 | num_updates 1214 | best_loss 8.879
2022-03-06 21:43:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1214 updates
2022-03-06 21:43:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:43:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:43:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 25 @ 1214 updates, score 8.879) (writing took 1.8583894334733486 seconds)
2022-03-06 21:43:50 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 21:43:50 | INFO | train | epoch 025 | loss 8.211 | ppl 296.36 | wps 21264.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1214 | lr 0.00015182 | gnorm 0.839 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 3672
2022-03-06 21:43:50 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 21:43:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:46:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:46:15 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.871 | ppl 468.07 | wps 38959 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 8.871
2022-03-06 21:46:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-06 21:46:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:46:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:46:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 26 @ 1263 updates, score 8.871) (writing took 1.8919938346371055 seconds)
2022-03-06 21:46:17 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 21:46:17 | INFO | train | epoch 026 | loss 8.121 | ppl 278.44 | wps 21726.2 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 0.909 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 3818
2022-03-06 21:46:17 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 21:46:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:48:03 | INFO | train_inner | epoch 027:     37 / 49 loss=8.098, ppl=274.04, wps=21535.3, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.881, loss_scale=32, train_wall=263, gb_free=21.5, wall=3924
2022-03-06 21:48:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:48:41 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.836 | ppl 457.04 | wps 38974 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 8.836
2022-03-06 21:48:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-06 21:48:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:48:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:48:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 27 @ 1312 updates, score 8.836) (writing took 1.8380215987563133 seconds)
2022-03-06 21:48:43 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 21:48:43 | INFO | train | epoch 027 | loss 8.027 | ppl 260.86 | wps 21715.8 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.878 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 3965
2022-03-06 21:48:43 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 21:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:50:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:51:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:51:08 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.798 | ppl 444.98 | wps 38524.3 | wpb 510.9 | bsz 1 | num_updates 1360 | best_loss 8.798
2022-03-06 21:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1360 updates
2022-03-06 21:51:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:51:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:51:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 28 @ 1360 updates, score 8.798) (writing took 1.8372062090784311 seconds)
2022-03-06 21:51:09 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 21:51:09 | INFO | train | epoch 028 | loss 7.934 | ppl 244.54 | wps 21273.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1360 | lr 0.000170066 | gnorm 0.931 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 4111
2022-03-06 21:51:09 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 21:51:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:53:04 | INFO | train_inner | epoch 029:     40 / 49 loss=7.907, ppl=240.03, wps=21536.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.911, loss_scale=32, train_wall=263, gb_free=21.5, wall=4226
2022-03-06 21:53:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:53:34 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.784 | ppl 440.74 | wps 38933.4 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 8.784
2022-03-06 21:53:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-06 21:53:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:53:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:53:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 29 @ 1409 updates, score 8.784) (writing took 1.8779492443427444 seconds)
2022-03-06 21:53:36 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 21:53:36 | INFO | train | epoch 029 | loss 7.843 | ppl 229.56 | wps 21717.1 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 0.884 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 4257
2022-03-06 21:53:36 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 21:53:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:55:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:56:00 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.746 | ppl 429.47 | wps 39052.6 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 8.746
2022-03-06 21:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-06 21:56:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:56:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 21:56:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 30 @ 1458 updates, score 8.746) (writing took 1.862041413784027 seconds)
2022-03-06 21:56:02 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 21:56:02 | INFO | train | epoch 030 | loss 7.751 | ppl 215.38 | wps 21714.5 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 0.92 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 4404
2022-03-06 21:56:02 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 21:56:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:57:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:58:05 | INFO | train_inner | epoch 031:     43 / 49 loss=7.717, ppl=210.37, wps=21542.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.894, loss_scale=32, train_wall=263, gb_free=21.5, wall=4527
2022-03-06 21:58:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:58:26 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.75 | ppl 430.56 | wps 38915.9 | wpb 510.9 | bsz 1 | num_updates 1506 | best_loss 8.746
2022-03-06 21:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1506 updates
2022-03-06 21:58:26 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 21:58:26 | INFO | train | epoch 031 | loss 7.655 | ppl 201.6 | wps 21564.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1506 | lr 0.000188312 | gnorm 0.883 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 4548
2022-03-06 21:58:26 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 21:58:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:00:51 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.723 | ppl 422.53 | wps 38858.9 | wpb 510.9 | bsz 1 | num_updates 1555 | best_loss 8.723
2022-03-06 22:00:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1555 updates
2022-03-06 22:00:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 22:00:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt
2022-03-06 22:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.0_0.08_0.92_#2/checkpoint_best.pt (epoch 32 @ 1555 updates, score 8.723) (writing took 1.8680267203599215 seconds)
2022-03-06 22:00:53 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 22:00:53 | INFO | train | epoch 032 | loss 7.567 | ppl 189.58 | wps 21709.1 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 1555 | lr 0.000194436 | gnorm 0.923 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 4695
2022-03-06 22:00:53 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 22:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:03:02 | INFO | train_inner | epoch 033:     45 / 49 loss=7.529, ppl=184.69, wps=21874, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=0.919, loss_scale=32, train_wall=261, gb_free=21.5, wall=4823
2022-03-06 22:03:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:03:17 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.724 | ppl 422.95 | wps 38948.3 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.723
2022-03-06 22:03:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-06 22:03:17 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 22:03:17 | INFO | train | epoch 033 | loss 7.473 | ppl 177.61 | wps 21997.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 0.912 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 4839
2022-03-06 22:03:17 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 22:03:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:04:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:05:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:05:42 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.748 | ppl 429.88 | wps 39105.5 | wpb 510.9 | bsz 1 | num_updates 1652 | best_loss 8.723
2022-03-06 22:05:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1652 updates
2022-03-06 22:05:42 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 22:05:42 | INFO | train | epoch 034 | loss 7.381 | ppl 166.72 | wps 21541.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1652 | lr 0.000206559 | gnorm 0.918 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 4984
2022-03-06 22:05:42 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 22:05:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:07:59 | INFO | train_inner | epoch 035:     48 / 49 loss=7.341, ppl=162.18, wps=21805.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=0.922, loss_scale=32, train_wall=263, gb_free=21.5, wall=5121
2022-03-06 22:08:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:08:06 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.747 | ppl 429.52 | wps 38996.6 | wpb 510.9 | bsz 1 | num_updates 1701 | best_loss 8.723
2022-03-06 22:08:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1701 updates
2022-03-06 22:08:06 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 22:08:06 | INFO | train | epoch 035 | loss 7.292 | ppl 156.76 | wps 22006.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1701 | lr 0.000212682 | gnorm 0.933 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 5128
2022-03-06 22:08:06 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 22:08:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:10:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:10:31 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.748 | ppl 430.01 | wps 39056.2 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 8.723
2022-03-06 22:10:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-06 22:10:31 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 22:10:31 | INFO | train | epoch 036 | loss 7.2 | ppl 147.07 | wps 21979 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 0.955 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 5273
2022-03-06 22:10:31 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 22:10:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:12:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:12:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:12:55 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.762 | ppl 434.15 | wps 38901.7 | wpb 510.9 | bsz 1 | num_updates 1798 | best_loss 8.723
2022-03-06 22:12:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1798 updates
2022-03-06 22:12:55 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 22:12:55 | INFO | train | epoch 037 | loss 7.11 | ppl 138.12 | wps 21545.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1798 | lr 0.000224805 | gnorm 0.918 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 5417
2022-03-06 22:12:55 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 22:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:13:01 | INFO | train_inner | epoch 038:      2 / 49 loss=7.154, ppl=142.42, wps=21374.6, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=0.944, loss_scale=32, train_wall=262, gb_free=21.5, wall=5423
2022-03-06 22:15:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:15:20 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.811 | ppl 449.22 | wps 39197.5 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.723
2022-03-06 22:15:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-06 22:15:20 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 22:15:20 | INFO | train | epoch 038 | loss 7.025 | ppl 130.26 | wps 22007.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 0.971 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 5561
2022-03-06 22:15:20 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 22:15:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:17:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:17:44 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.833 | ppl 455.97 | wps 39089.4 | wpb 510.9 | bsz 1 | num_updates 1896 | best_loss 8.723
2022-03-06 22:17:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1896 updates
2022-03-06 22:17:44 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 22:17:44 | INFO | train | epoch 039 | loss 6.937 | ppl 122.5 | wps 21999 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1896 | lr 0.000237053 | gnorm 0.974 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 5706
2022-03-06 22:17:44 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 22:17:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:17:56 | INFO | train_inner | epoch 040:      4 / 49 loss=6.974, ppl=125.67, wps=22021, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=0.964, loss_scale=32, train_wall=260, gb_free=21.5, wall=5717
2022-03-06 22:19:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:20:09 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.835 | ppl 456.69 | wps 38883.2 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.723
2022-03-06 22:20:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-06 22:20:09 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 22:20:09 | INFO | train | epoch 040 | loss 6.853 | ppl 115.59 | wps 21524.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1944 | lr 0.000243051 | gnorm 1.005 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 5850
2022-03-06 22:20:09 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 22:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:22:33 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.863 | ppl 465.73 | wps 38948.2 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.723
2022-03-06 22:22:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-06 22:22:33 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 22:22:33 | INFO | train | epoch 041 | loss 6.764 | ppl 108.68 | wps 22010.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 0.929 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 5995
2022-03-06 22:22:33 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 22:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:22:53 | INFO | train_inner | epoch 042:      7 / 49 loss=6.798, ppl=111.3, wps=21802.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=0.993, loss_scale=32, train_wall=263, gb_free=21.5, wall=6015
2022-03-06 22:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:24:58 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.973 | ppl 502.43 | wps 38892.7 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 8.723
2022-03-06 22:24:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-06 22:24:58 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 22:24:58 | INFO | train | epoch 042 | loss 6.682 | ppl 102.69 | wps 21990.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.062 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 6139
2022-03-06 22:24:58 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 22:24:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:26:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:26:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:27:22 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.023 | ppl 520.35 | wps 38892.8 | wpb 510.9 | bsz 1 | num_updates 2089 | best_loss 8.723
2022-03-06 22:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2089 updates
2022-03-06 22:27:22 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 22:27:22 | INFO | train | epoch 043 | loss 6.596 | ppl 96.74 | wps 21085.9 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 2089 | lr 0.000261173 | gnorm 1.063 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 6284
2022-03-06 22:27:22 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 22:27:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:27:54 | INFO | train_inner | epoch 044:     11 / 49 loss=6.622, ppl=98.49, wps=21590.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.044, loss_scale=16, train_wall=266, gb_free=21.5, wall=6315
2022-03-06 22:29:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:29:47 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.039 | ppl 526.07 | wps 38943.1 | wpb 510.9 | bsz 1 | num_updates 2138 | best_loss 8.723
2022-03-06 22:29:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2138 updates
2022-03-06 22:29:47 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 22:29:47 | INFO | train | epoch 044 | loss 6.514 | ppl 91.37 | wps 21996.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2138 | lr 0.000267297 | gnorm 0.992 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 6428
2022-03-06 22:29:47 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 22:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:32:11 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.082 | ppl 541.83 | wps 39014.5 | wpb 510.9 | bsz 1 | num_updates 2187 | best_loss 8.723
2022-03-06 22:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2187 updates
2022-03-06 22:32:11 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 22:32:11 | INFO | train | epoch 045 | loss 6.433 | ppl 86.4 | wps 22005.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2187 | lr 0.00027342 | gnorm 1.081 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 6573
2022-03-06 22:32:11 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 22:32:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:32:48 | INFO | train_inner | epoch 046:     13 / 49 loss=6.452, ppl=87.55, wps=22022.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.025, loss_scale=16, train_wall=261, gb_free=21.5, wall=6610
2022-03-06 22:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:34:35 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.145 | ppl 566.21 | wps 39209.3 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 8.723
2022-03-06 22:34:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-06 22:34:35 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 22:34:35 | INFO | train | epoch 046 | loss 6.348 | ppl 81.49 | wps 22016.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.016 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 6717
2022-03-06 22:34:35 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 22:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:36:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:37:00 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.202 | ppl 588.92 | wps 38896.1 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.723
2022-03-06 22:37:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-06 22:37:00 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 22:37:00 | INFO | train | epoch 047 | loss 6.266 | ppl 76.94 | wps 22006.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.073 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 6862
2022-03-06 22:37:00 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 22:37:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:37:43 | INFO | train_inner | epoch 048:     15 / 49 loss=6.282, ppl=77.8, wps=22022.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.06, loss_scale=32, train_wall=261, gb_free=21.5, wall=6905
2022-03-06 22:39:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:39:24 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.234 | ppl 602.09 | wps 39066.6 | wpb 510.9 | bsz 1 | num_updates 2334 | best_loss 8.723
2022-03-06 22:39:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2334 updates
2022-03-06 22:39:24 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 22:39:24 | INFO | train | epoch 048 | loss 6.185 | ppl 72.76 | wps 21993.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2334 | lr 0.000291792 | gnorm 1.125 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 7006
2022-03-06 22:39:24 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 22:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:40:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:41:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:41:49 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.336 | ppl 646.41 | wps 39004.9 | wpb 510.9 | bsz 1 | num_updates 2382 | best_loss 8.723
2022-03-06 22:41:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2382 updates
2022-03-06 22:41:49 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 22:41:49 | INFO | train | epoch 049 | loss 6.1 | ppl 68.59 | wps 21545.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2382 | lr 0.00029779 | gnorm 1.079 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 7150
2022-03-06 22:41:49 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 22:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:42:40 | INFO | train_inner | epoch 050:     18 / 49 loss=6.113, ppl=69.24, wps=21805, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.071, loss_scale=32, train_wall=263, gb_free=21.5, wall=7202
2022-03-06 22:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:44:13 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.323 | ppl 640.28 | wps 38973.8 | wpb 510.9 | bsz 1 | num_updates 2431 | best_loss 8.723
2022-03-06 22:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2431 updates
2022-03-06 22:44:13 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 22:44:13 | INFO | train | epoch 050 | loss 6.023 | ppl 65.01 | wps 22006.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2431 | lr 0.000303914 | gnorm 1.089 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 7295
2022-03-06 22:44:13 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 22:44:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:46:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:46:38 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.381 | ppl 666.54 | wps 38888.3 | wpb 510.9 | bsz 1 | num_updates 2479 | best_loss 8.723
2022-03-06 22:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2479 updates
2022-03-06 22:46:38 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 22:46:38 | INFO | train | epoch 051 | loss 5.942 | ppl 61.49 | wps 21549 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2479 | lr 0.000309913 | gnorm 1.165 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 7439
2022-03-06 22:46:38 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 22:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:47:38 | INFO | train_inner | epoch 052:     21 / 49 loss=5.952, ppl=61.91, wps=21814.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.151, loss_scale=32, train_wall=263, gb_free=21.5, wall=7499
2022-03-06 22:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:49:02 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.526 | ppl 737.16 | wps 39063.3 | wpb 510.9 | bsz 1 | num_updates 2528 | best_loss 8.723
2022-03-06 22:49:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2528 updates
2022-03-06 22:49:02 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 22:49:02 | INFO | train | epoch 052 | loss 5.859 | ppl 58.03 | wps 22016.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2528 | lr 0.000316037 | gnorm 1.038 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 7584
2022-03-06 22:49:02 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 22:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:51:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:51:26 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.569 | ppl 759.38 | wps 38948.3 | wpb 510.9 | bsz 1 | num_updates 2577 | best_loss 8.723
2022-03-06 22:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2577 updates
2022-03-06 22:51:26 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 22:51:26 | INFO | train | epoch 053 | loss 5.783 | ppl 55.06 | wps 21986.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2577 | lr 0.000322161 | gnorm 1.181 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 7728
2022-03-06 22:51:26 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 22:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:52:32 | INFO | train_inner | epoch 054:     23 / 49 loss=5.783, ppl=55.05, wps=22017.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.114, loss_scale=32, train_wall=261, gb_free=21.5, wall=7794
2022-03-06 22:52:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:53:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:53:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:53:51 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.65 | ppl 803.21 | wps 39035.2 | wpb 510.9 | bsz 1 | num_updates 2624 | best_loss 8.723
2022-03-06 22:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2624 updates
2022-03-06 22:53:51 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 22:53:51 | INFO | train | epoch 054 | loss 5.711 | ppl 52.39 | wps 21085.2 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 2624 | lr 0.000328034 | gnorm 1.337 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 7873
2022-03-06 22:53:51 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 22:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:56:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:56:15 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.818 | ppl 902.37 | wps 39024.8 | wpb 510.9 | bsz 1 | num_updates 2673 | best_loss 8.723
2022-03-06 22:56:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2673 updates
2022-03-06 22:56:15 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 22:56:15 | INFO | train | epoch 055 | loss 5.628 | ppl 49.47 | wps 22027 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2673 | lr 0.000334158 | gnorm 1 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 8017
2022-03-06 22:56:15 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 22:56:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:57:33 | INFO | train_inner | epoch 056:     27 / 49 loss=5.632, ppl=49.61, wps=21607.4, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.223, loss_scale=16, train_wall=266, gb_free=21.5, wall=8094
2022-03-06 22:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:58:40 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.849 | ppl 922.51 | wps 39020 | wpb 510.9 | bsz 1 | num_updates 2722 | best_loss 8.723
2022-03-06 22:58:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2722 updates
2022-03-06 22:58:40 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 22:58:40 | INFO | train | epoch 056 | loss 5.551 | ppl 46.87 | wps 22011.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2722 | lr 0.000340282 | gnorm 1.196 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 8161
2022-03-06 22:58:40 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 22:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:00:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:01:04 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.901 | ppl 956.25 | wps 39086.2 | wpb 510.9 | bsz 1 | num_updates 2771 | best_loss 8.723
2022-03-06 23:01:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2771 updates
2022-03-06 23:01:04 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 23:01:04 | INFO | train | epoch 057 | loss 5.477 | ppl 44.55 | wps 21985.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2771 | lr 0.000346406 | gnorm 1.253 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 8306
2022-03-06 23:01:04 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 23:01:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:02:27 | INFO | train_inner | epoch 058:     29 / 49 loss=5.463, ppl=44.1, wps=22011.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.192, loss_scale=32, train_wall=261, gb_free=21.5, wall=8389
2022-03-06 23:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:03:29 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.891 | ppl 949.27 | wps 39012.3 | wpb 510.9 | bsz 1 | num_updates 2820 | best_loss 8.723
2022-03-06 23:03:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2820 updates
2022-03-06 23:03:29 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 23:03:29 | INFO | train | epoch 058 | loss 5.396 | ppl 42.11 | wps 21994.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2820 | lr 0.00035253 | gnorm 1.24 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 8450
2022-03-06 23:03:29 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 23:03:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:05:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:05:53 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.99 | ppl 1016.79 | wps 39032.3 | wpb 510.9 | bsz 1 | num_updates 2869 | best_loss 8.723
2022-03-06 23:05:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2869 updates
2022-03-06 23:05:53 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 23:05:53 | INFO | train | epoch 059 | loss 5.316 | ppl 39.82 | wps 21998.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2869 | lr 0.000358653 | gnorm 1.185 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 8595
2022-03-06 23:05:53 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 23:05:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:06:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:06:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:07:27 | INFO | train_inner | epoch 060:     33 / 49 loss=5.316, ppl=39.83, wps=21607.8, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.282, loss_scale=16, train_wall=266, gb_free=21.5, wall=8689
2022-03-06 23:08:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:08:17 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 10.075 | ppl 1078.77 | wps 38849.5 | wpb 510.9 | bsz 1 | num_updates 2916 | best_loss 8.723
2022-03-06 23:08:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2916 updates
2022-03-06 23:08:17 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 23:08:17 | INFO | train | epoch 060 | loss 5.249 | ppl 38.03 | wps 21113.8 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 2916 | lr 0.000364527 | gnorm 1.317 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 8739
2022-03-06 23:08:17 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 23:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:10:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:10:42 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 10.176 | ppl 1157.06 | wps 38987.9 | wpb 510.9 | bsz 1 | num_updates 2965 | best_loss 8.723
2022-03-06 23:10:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2965 updates
2022-03-06 23:10:42 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 23:10:42 | INFO | train | epoch 061 | loss 5.169 | ppl 35.98 | wps 22007.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2965 | lr 0.000370651 | gnorm 1.256 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 8884
2022-03-06 23:10:42 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 23:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:12:22 | INFO | train_inner | epoch 062:     35 / 49 loss=5.152, ppl=35.55, wps=22017.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.226, loss_scale=16, train_wall=261, gb_free=21.5, wall=8984
2022-03-06 23:13:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:13:06 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 10.158 | ppl 1142.31 | wps 39119.8 | wpb 510.9 | bsz 1 | num_updates 3014 | best_loss 8.723
2022-03-06 23:13:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3014 updates
2022-03-06 23:13:06 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 23:13:06 | INFO | train | epoch 062 | loss 5.092 | ppl 34.11 | wps 21996.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3014 | lr 0.000376775 | gnorm 1.192 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 9028
2022-03-06 23:13:06 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 23:13:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:13:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:15:31 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 10.227 | ppl 1198.8 | wps 38939.1 | wpb 510.9 | bsz 1 | num_updates 3062 | best_loss 8.723
2022-03-06 23:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3062 updates
2022-03-06 23:15:31 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 23:15:31 | INFO | train | epoch 063 | loss 5.02 | ppl 32.45 | wps 21558.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3062 | lr 0.000382773 | gnorm 1.285 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 9172
2022-03-06 23:15:31 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 23:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:17:19 | INFO | train_inner | epoch 064:     38 / 49 loss=5.005, ppl=32.11, wps=21814.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.262, loss_scale=16, train_wall=263, gb_free=21.5, wall=9281
2022-03-06 23:17:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:17:55 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 10.272 | ppl 1236.81 | wps 38918.5 | wpb 510.9 | bsz 1 | num_updates 3111 | best_loss 8.723
2022-03-06 23:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3111 updates
2022-03-06 23:17:55 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 23:17:55 | INFO | train | epoch 064 | loss 4.947 | ppl 30.84 | wps 22004.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3111 | lr 0.000388897 | gnorm 1.26 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 9317
2022-03-06 23:17:55 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 23:17:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:20:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:20:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:20:20 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.409 | ppl 1359.73 | wps 38972.2 | wpb 510.9 | bsz 1 | num_updates 3159 | best_loss 8.723
2022-03-06 23:20:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3159 updates
2022-03-06 23:20:20 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 23:20:20 | INFO | train | epoch 065 | loss 4.877 | ppl 29.38 | wps 21559.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3159 | lr 0.000394896 | gnorm 1.309 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 9461
2022-03-06 23:20:20 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 23:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:22:17 | INFO | train_inner | epoch 066:     41 / 49 loss=4.854, ppl=28.92, wps=21820.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.318, loss_scale=16, train_wall=263, gb_free=21.5, wall=9579
2022-03-06 23:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:22:44 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.394 | ppl 1345.88 | wps 39026.7 | wpb 510.9 | bsz 1 | num_updates 3208 | best_loss 8.723
2022-03-06 23:22:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3208 updates
2022-03-06 23:22:44 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 23:22:44 | INFO | train | epoch 066 | loss 4.806 | ppl 27.98 | wps 22011.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3208 | lr 0.00040102 | gnorm 1.34 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 9606
2022-03-06 23:22:44 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 23:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:25:08 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.408 | ppl 1359.07 | wps 38871.9 | wpb 510.9 | bsz 1 | num_updates 3257 | best_loss 8.723
2022-03-06 23:25:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3257 updates
2022-03-06 23:25:08 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 23:25:08 | INFO | train | epoch 067 | loss 4.733 | ppl 26.6 | wps 21997.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3257 | lr 0.000407144 | gnorm 1.346 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 9750
2022-03-06 23:25:08 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 23:25:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:27:11 | INFO | train_inner | epoch 068:     43 / 49 loss=4.709, ppl=26.15, wps=22028.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.291, loss_scale=32, train_wall=260, gb_free=21.5, wall=9873
2022-03-06 23:27:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:27:33 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.464 | ppl 1412.85 | wps 39073.8 | wpb 510.9 | bsz 1 | num_updates 3306 | best_loss 8.723
2022-03-06 23:27:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3306 updates
2022-03-06 23:27:33 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 23:27:33 | INFO | train | epoch 068 | loss 4.662 | ppl 25.31 | wps 22030.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3306 | lr 0.000413267 | gnorm 1.26 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 9894
2022-03-06 23:27:33 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 23:27:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:27:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:29:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:29:57 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.652 | ppl 1609.4 | wps 38864.6 | wpb 510.9 | bsz 1 | num_updates 3354 | best_loss 8.723
2022-03-06 23:29:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3354 updates
2022-03-06 23:29:57 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 23:29:57 | INFO | train | epoch 069 | loss 4.596 | ppl 24.19 | wps 21548.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3354 | lr 0.000419266 | gnorm 1.38 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 10039
2022-03-06 23:29:57 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 23:29:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:32:09 | INFO | train_inner | epoch 070:     46 / 49 loss=4.565, ppl=23.66, wps=21814.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.336, loss_scale=16, train_wall=263, gb_free=21.5, wall=10170
2022-03-06 23:32:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:32:21 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.737 | ppl 1706.93 | wps 38805.9 | wpb 510.9 | bsz 1 | num_updates 3403 | best_loss 8.723
2022-03-06 23:32:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3403 updates
2022-03-06 23:32:21 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 23:32:21 | INFO | train | epoch 070 | loss 4.521 | ppl 22.96 | wps 22007 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3403 | lr 0.00042539 | gnorm 1.319 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 10183
2022-03-06 23:32:22 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 23:32:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:34:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:34:46 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.754 | ppl 1726.69 | wps 38893.2 | wpb 510.9 | bsz 1 | num_updates 3451 | best_loss 8.723
2022-03-06 23:34:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3451 updates
2022-03-06 23:34:46 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 23:34:46 | INFO | train | epoch 071 | loss 4.462 | ppl 22.04 | wps 21537.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3451 | lr 0.000431389 | gnorm 1.415 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 10328
2022-03-06 23:34:46 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 23:34:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:37:05 | INFO | train_inner | epoch 072:     49 / 49 loss=4.43, ppl=21.55, wps=21790.9, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=3500, lr=0.000437513, gnorm=1.369, loss_scale=16, train_wall=262, gb_free=21.5, wall=10467
2022-03-06 23:37:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:37:10 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.737 | ppl 1706.86 | wps 38904.1 | wpb 510.9 | bsz 1 | num_updates 3500 | best_loss 8.723
2022-03-06 23:37:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3500 updates
2022-03-06 23:37:10 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 23:37:10 | INFO | train | epoch 072 | loss 4.389 | ppl 20.95 | wps 21995.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3500 | lr 0.000437513 | gnorm 1.305 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 10472
2022-03-06 23:37:11 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 23:37:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:39:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:39:35 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.783 | ppl 1762.43 | wps 38894.4 | wpb 510.9 | bsz 1 | num_updates 3549 | best_loss 8.723
2022-03-06 23:39:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3549 updates
2022-03-06 23:39:35 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 23:39:35 | INFO | train | epoch 073 | loss 4.326 | ppl 20.05 | wps 22005.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3549 | lr 0.000443636 | gnorm 1.324 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 10617
2022-03-06 23:39:35 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 23:39:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:41:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:41:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:41:59 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.929 | ppl 1950.09 | wps 39143.3 | wpb 510.9 | bsz 1 | num_updates 3597 | best_loss 8.723
2022-03-06 23:41:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3597 updates
2022-03-06 23:41:59 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 23:41:59 | INFO | train | epoch 074 | loss 4.263 | ppl 19.19 | wps 21547.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3597 | lr 0.000449635 | gnorm 1.422 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 10761
2022-03-06 23:41:59 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 23:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:42:08 | INFO | train_inner | epoch 075:      3 / 49 loss=4.291, ppl=19.57, wps=21396.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=3600, lr=0.00045001, gnorm=1.376, loss_scale=16, train_wall=263, gb_free=21.5, wall=10770
2022-03-06 23:44:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:44:24 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.827 | ppl 1816.29 | wps 39044.9 | wpb 510.9 | bsz 1 | num_updates 3646 | best_loss 8.723
2022-03-06 23:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3646 updates
2022-03-06 23:44:24 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 23:44:24 | INFO | train | epoch 075 | loss 4.195 | ppl 18.32 | wps 21995.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3646 | lr 0.000455759 | gnorm 1.29 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 10906
2022-03-06 23:44:24 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 23:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:46:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:46:48 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.996 | ppl 2041.73 | wps 38874.9 | wpb 510.9 | bsz 1 | num_updates 3695 | best_loss 8.723
2022-03-06 23:46:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3695 updates
2022-03-06 23:46:48 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 23:46:48 | INFO | train | epoch 076 | loss 4.136 | ppl 17.58 | wps 22022.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3695 | lr 0.000461883 | gnorm 1.373 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 11050
2022-03-06 23:46:48 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 23:46:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:47:03 | INFO | train_inner | epoch 077:      5 / 49 loss=4.158, ppl=17.86, wps=22023.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.326, loss_scale=16, train_wall=260, gb_free=21.5, wall=11064
2022-03-06 23:48:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:49:13 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.918 | ppl 1934.85 | wps 38834.1 | wpb 510.9 | bsz 1 | num_updates 3743 | best_loss 8.723
2022-03-06 23:49:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3743 updates
2022-03-06 23:49:13 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 23:49:13 | INFO | train | epoch 077 | loss 4.089 | ppl 17.02 | wps 21553.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3743 | lr 0.000467881 | gnorm 1.543 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 11194
2022-03-06 23:49:13 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 23:49:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:51:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:51:37 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.077 | ppl 2160.21 | wps 38846 | wpb 510.9 | bsz 1 | num_updates 3792 | best_loss 8.723
2022-03-06 23:51:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3792 updates
2022-03-06 23:51:37 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 23:51:37 | INFO | train | epoch 078 | loss 4.016 | ppl 16.18 | wps 22010 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3792 | lr 0.000474005 | gnorm 1.156 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 11339
2022-03-06 23:51:37 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 23:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:52:00 | INFO | train_inner | epoch 079:      8 / 49 loss=4.042, ppl=16.47, wps=21821.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.351, loss_scale=16, train_wall=263, gb_free=21.5, wall=11362
2022-03-06 23:53:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:53:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:54:01 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.15 | ppl 2272.39 | wps 38961.2 | wpb 510.9 | bsz 1 | num_updates 3840 | best_loss 8.723
2022-03-06 23:54:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3840 updates
2022-03-06 23:54:01 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 23:54:01 | INFO | train | epoch 079 | loss 3.966 | ppl 15.63 | wps 21573.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3840 | lr 0.000480004 | gnorm 1.486 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 11483
2022-03-06 23:54:01 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 23:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:56:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:56:26 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.038 | ppl 2102.01 | wps 38998.2 | wpb 510.9 | bsz 1 | num_updates 3889 | best_loss 8.723
2022-03-06 23:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3889 updates
2022-03-06 23:56:26 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 23:56:26 | INFO | train | epoch 080 | loss 3.895 | ppl 14.88 | wps 22025 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3889 | lr 0.000486128 | gnorm 1.267 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 11627
2022-03-06 23:56:26 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 23:56:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:56:57 | INFO | train_inner | epoch 081:     11 / 49 loss=3.917, ppl=15.11, wps=21828.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.362, loss_scale=8, train_wall=263, gb_free=21.5, wall=11659
2022-03-06 23:58:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:58:50 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.197 | ppl 2347.87 | wps 38365.2 | wpb 510.9 | bsz 1 | num_updates 3938 | best_loss 8.723
2022-03-06 23:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3938 updates
2022-03-06 23:58:50 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 23:58:50 | INFO | train | epoch 081 | loss 3.84 | ppl 14.32 | wps 21988 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3938 | lr 0.000492252 | gnorm 1.375 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 11772
2022-03-06 23:58:50 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 23:58:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:01:14 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.406 | ppl 2713.79 | wps 38853.9 | wpb 510.9 | bsz 1 | num_updates 3987 | best_loss 8.723
2022-03-07 00:01:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3987 updates
2022-03-07 00:01:14 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-07 00:01:14 | INFO | train | epoch 082 | loss 3.785 | ppl 13.78 | wps 22008.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3987 | lr 0.000498375 | gnorm 1.351 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 11916
2022-03-07 00:01:14 | INFO | fairseq.trainer | begin training epoch 83
2022-03-07 00:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:01:52 | INFO | train_inner | epoch 083:     13 / 49 loss=3.797, ppl=13.9, wps=22016.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.362, loss_scale=16, train_wall=260, gb_free=21.5, wall=11953
2022-03-07 00:03:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:03:39 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.211 | ppl 2370.93 | wps 38427.8 | wpb 510.9 | bsz 1 | num_updates 4036 | best_loss 8.723
2022-03-07 00:03:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4036 updates
2022-03-07 00:03:39 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-07 00:03:39 | INFO | train | epoch 083 | loss 3.726 | ppl 13.23 | wps 21982.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4036 | lr 0.000497765 | gnorm 1.306 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 12061
2022-03-07 00:03:39 | INFO | fairseq.trainer | begin training epoch 84
2022-03-07 00:03:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:05:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:05:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:06:03 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.197 | ppl 2348.43 | wps 38892.3 | wpb 510.9 | bsz 1 | num_updates 4084 | best_loss 8.723
2022-03-07 00:06:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4084 updates
2022-03-07 00:06:03 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-07 00:06:03 | INFO | train | epoch 084 | loss 3.662 | ppl 12.65 | wps 21559.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4084 | lr 0.000494831 | gnorm 1.251 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 12205
2022-03-07 00:06:03 | INFO | fairseq.trainer | begin training epoch 85
2022-03-07 00:06:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:06:49 | INFO | train_inner | epoch 085:     16 / 49 loss=3.679, ppl=12.81, wps=21804.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.316, loss_scale=16, train_wall=263, gb_free=21.5, wall=12251
2022-03-07 00:08:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:08:28 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.271 | ppl 2470.98 | wps 38911 | wpb 510.9 | bsz 1 | num_updates 4133 | best_loss 8.723
2022-03-07 00:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4133 updates
2022-03-07 00:08:28 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-07 00:08:28 | INFO | train | epoch 085 | loss 3.616 | ppl 12.26 | wps 21996.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4133 | lr 0.000491889 | gnorm 1.334 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 12350
2022-03-07 00:08:28 | INFO | fairseq.trainer | begin training epoch 86
2022-03-07 00:08:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:10:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:10:52 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.402 | ppl 2706.06 | wps 38483.8 | wpb 510.9 | bsz 1 | num_updates 4182 | best_loss 8.723
2022-03-07 00:10:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4182 updates
2022-03-07 00:10:52 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-07 00:10:52 | INFO | train | epoch 086 | loss 3.557 | ppl 11.77 | wps 21986.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4182 | lr 0.000488999 | gnorm 1.287 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 12494
2022-03-07 00:10:52 | INFO | fairseq.trainer | begin training epoch 87
2022-03-07 00:10:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:11:44 | INFO | train_inner | epoch 087:     18 / 49 loss=3.564, ppl=11.82, wps=22012.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.278, loss_scale=16, train_wall=261, gb_free=21.5, wall=12546
2022-03-07 00:12:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:13:17 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.575 | ppl 3049.82 | wps 38889.7 | wpb 510.9 | bsz 1 | num_updates 4230 | best_loss 8.723
2022-03-07 00:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4230 updates
2022-03-07 00:13:17 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-07 00:13:17 | INFO | train | epoch 087 | loss 3.496 | ppl 11.28 | wps 21566.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4230 | lr 0.000486217 | gnorm 1.245 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 12639
2022-03-07 00:13:17 | INFO | fairseq.trainer | begin training epoch 88
2022-03-07 00:13:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:15:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:15:41 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.554 | ppl 3006.74 | wps 38768 | wpb 510.9 | bsz 1 | num_updates 4279 | best_loss 8.723
2022-03-07 00:15:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4279 updates
2022-03-07 00:15:41 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-07 00:15:41 | INFO | train | epoch 088 | loss 3.453 | ppl 10.95 | wps 21989.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4279 | lr 0.000483425 | gnorm 1.231 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 12783
2022-03-07 00:15:41 | INFO | fairseq.trainer | begin training epoch 89
2022-03-07 00:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:16:41 | INFO | train_inner | epoch 089:     21 / 49 loss=3.453, ppl=10.95, wps=21806.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.233, loss_scale=16, train_wall=263, gb_free=21.5, wall=12843
2022-03-07 00:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:18:06 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.589 | ppl 3081 | wps 38947.8 | wpb 510.9 | bsz 1 | num_updates 4328 | best_loss 8.723
2022-03-07 00:18:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4328 updates
2022-03-07 00:18:06 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-07 00:18:06 | INFO | train | epoch 089 | loss 3.404 | ppl 10.58 | wps 22004.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4328 | lr 0.00048068 | gnorm 1.285 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 12927
2022-03-07 00:18:06 | INFO | fairseq.trainer | begin training epoch 90
2022-03-07 00:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:19:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:20:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:20:30 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.53 | ppl 2956.18 | wps 38828.6 | wpb 510.9 | bsz 1 | num_updates 4376 | best_loss 8.723
2022-03-07 00:20:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4376 updates
2022-03-07 00:20:30 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-07 00:20:30 | INFO | train | epoch 090 | loss 3.356 | ppl 10.24 | wps 21542.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4376 | lr 0.000478037 | gnorm 1.265 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 13072
2022-03-07 00:20:30 | INFO | fairseq.trainer | begin training epoch 91
2022-03-07 00:20:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:21:39 | INFO | train_inner | epoch 091:     24 / 49 loss=3.357, ppl=10.24, wps=21806.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.229, loss_scale=16, train_wall=263, gb_free=21.5, wall=13141
2022-03-07 00:22:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:22:55 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.619 | ppl 3145.75 | wps 38771.3 | wpb 510.9 | bsz 1 | num_updates 4425 | best_loss 8.723
2022-03-07 00:22:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4425 updates
2022-03-07 00:22:55 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-07 00:22:55 | INFO | train | epoch 091 | loss 3.299 | ppl 9.85 | wps 21995.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4425 | lr 0.000475383 | gnorm 1.136 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 13216
2022-03-07 00:22:55 | INFO | fairseq.trainer | begin training epoch 92
2022-03-07 00:22:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:25:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:25:19 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.69 | ppl 3304.17 | wps 38850.4 | wpb 510.9 | bsz 1 | num_updates 4474 | best_loss 8.723
2022-03-07 00:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4474 updates
2022-03-07 00:25:19 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-07 00:25:19 | INFO | train | epoch 092 | loss 3.263 | ppl 9.6 | wps 22014.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4474 | lr 0.000472772 | gnorm 1.23 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 13361
2022-03-07 00:25:19 | INFO | fairseq.trainer | begin training epoch 93
2022-03-07 00:25:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:26:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:26:36 | INFO | train_inner | epoch 093:     27 / 49 loss=3.258, ppl=9.56, wps=21807.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.199, loss_scale=16, train_wall=263, gb_free=21.5, wall=13438
2022-03-07 00:27:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:27:44 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.687 | ppl 3297.74 | wps 38959.2 | wpb 510.9 | bsz 1 | num_updates 4522 | best_loss 8.723
2022-03-07 00:27:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4522 updates
2022-03-07 00:27:44 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-07 00:27:44 | INFO | train | epoch 093 | loss 3.211 | ppl 9.26 | wps 21540 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4522 | lr 0.000470256 | gnorm 1.166 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 13505
2022-03-07 00:27:44 | INFO | fairseq.trainer | begin training epoch 94
2022-03-07 00:27:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:30:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:30:08 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.689 | ppl 3301.58 | wps 38965.7 | wpb 510.9 | bsz 1 | num_updates 4571 | best_loss 8.723
2022-03-07 00:30:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4571 updates
2022-03-07 00:30:08 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-07 00:30:08 | INFO | train | epoch 094 | loss 3.175 | ppl 9.03 | wps 21994.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4571 | lr 0.000467729 | gnorm 1.204 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 13650
2022-03-07 00:30:08 | INFO | fairseq.trainer | begin training epoch 95
2022-03-07 00:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:31:31 | INFO | train_inner | epoch 095:     29 / 49 loss=3.173, ppl=9.02, wps=22025.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.186, loss_scale=16, train_wall=260, gb_free=21.5, wall=13733
2022-03-07 00:32:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:32:32 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.781 | ppl 3520.33 | wps 38844.3 | wpb 510.9 | bsz 1 | num_updates 4620 | best_loss 8.723
2022-03-07 00:32:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4620 updates
2022-03-07 00:32:32 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-07 00:32:32 | INFO | train | epoch 095 | loss 3.135 | ppl 8.79 | wps 22027.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4620 | lr 0.000465242 | gnorm 1.158 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 13794
2022-03-07 00:32:32 | INFO | fairseq.trainer | begin training epoch 96
2022-03-07 00:32:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:33:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:34:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:34:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:34:57 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.709 | ppl 3347.99 | wps 38955.8 | wpb 510.9 | bsz 1 | num_updates 4667 | best_loss 8.723
2022-03-07 00:34:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4667 updates
2022-03-07 00:34:57 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-07 00:34:57 | INFO | train | epoch 096 | loss 3.093 | ppl 8.53 | wps 21095.1 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 4667 | lr 0.000462894 | gnorm 1.134 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 13939
2022-03-07 00:34:57 | INFO | fairseq.trainer | begin training epoch 97
2022-03-07 00:34:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:36:31 | INFO | train_inner | epoch 097:     33 / 49 loss=3.088, ppl=8.51, wps=21609.2, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.132, loss_scale=8, train_wall=266, gb_free=21.5, wall=14033
2022-03-07 00:37:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:37:21 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 11.743 | ppl 3428.64 | wps 39005.6 | wpb 510.9 | bsz 1 | num_updates 4716 | best_loss 8.723
2022-03-07 00:37:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4716 updates
2022-03-07 00:37:21 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-07 00:37:21 | INFO | train | epoch 097 | loss 3.058 | ppl 8.33 | wps 22026.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4716 | lr 0.000460482 | gnorm 1.138 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 14083
2022-03-07 00:37:21 | INFO | fairseq.trainer | begin training epoch 98
2022-03-07 00:37:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:39:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:39:45 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 11.827 | ppl 3633.52 | wps 38933.9 | wpb 510.9 | bsz 1 | num_updates 4765 | best_loss 8.723
2022-03-07 00:39:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4765 updates
2022-03-07 00:39:45 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-07 00:39:45 | INFO | train | epoch 098 | loss 3.023 | ppl 8.13 | wps 22013.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4765 | lr 0.000458109 | gnorm 1.124 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 14227
2022-03-07 00:39:45 | INFO | fairseq.trainer | begin training epoch 99
2022-03-07 00:39:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:41:26 | INFO | train_inner | epoch 099:     35 / 49 loss=3.018, ppl=8.1, wps=22034.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.142, loss_scale=16, train_wall=260, gb_free=21.5, wall=14327
2022-03-07 00:42:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:42:10 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 11.875 | ppl 3756.38 | wps 38881.2 | wpb 510.9 | bsz 1 | num_updates 4814 | best_loss 8.723
2022-03-07 00:42:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4814 updates
2022-03-07 00:42:10 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-07 00:42:10 | INFO | train | epoch 099 | loss 2.99 | ppl 7.94 | wps 22015.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4814 | lr 0.000455771 | gnorm 1.161 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 14372
2022-03-07 00:42:10 | INFO | fairseq.trainer | begin training epoch 100
2022-03-07 00:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:44:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:44:34 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 11.961 | ppl 3987.64 | wps 39022.9 | wpb 510.9 | bsz 1 | num_updates 4863 | best_loss 8.723
2022-03-07 00:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4863 updates
2022-03-07 00:44:34 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-07 00:44:34 | INFO | train | epoch 100 | loss 2.95 | ppl 7.73 | wps 22017.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4863 | lr 0.000453469 | gnorm 1.077 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 14516
2022-03-07 00:44:34 | INFO | fairseq.trainer | begin training epoch 101
2022-03-07 00:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:46:20 | INFO | train_inner | epoch 101:     37 / 49 loss=2.944, ppl=7.7, wps=22041.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.082, loss_scale=16, train_wall=260, gb_free=21.5, wall=14622
2022-03-07 00:46:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:46:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:46:58 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 11.9 | ppl 3822.06 | wps 38876.1 | wpb 510.9 | bsz 1 | num_updates 4911 | best_loss 8.723
2022-03-07 00:46:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4911 updates
2022-03-07 00:46:58 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-07 00:46:58 | INFO | train | epoch 101 | loss 2.919 | ppl 7.56 | wps 21566.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4911 | lr 0.000451248 | gnorm 1.092 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 14660
2022-03-07 00:46:58 | INFO | fairseq.trainer | begin training epoch 102
2022-03-07 00:46:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:47:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:49:23 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 11.88 | ppl 3769.15 | wps 38885.3 | wpb 510.9 | bsz 1 | num_updates 4959 | best_loss 8.723
2022-03-07 00:49:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4959 updates
2022-03-07 00:49:23 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-07 00:49:23 | INFO | train | epoch 102 | loss 2.887 | ppl 7.4 | wps 21564.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4959 | lr 0.000449059 | gnorm 1.065 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 14805
2022-03-07 00:49:23 | INFO | fairseq.trainer | begin training epoch 103
2022-03-07 00:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:51:20 | INFO | train_inner | epoch 103:     41 / 49 loss=2.88, ppl=7.36, wps=21607, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.095, loss_scale=8, train_wall=266, gb_free=21.5, wall=14922
2022-03-07 00:51:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:51:47 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 11.894 | ppl 3806.12 | wps 38857.8 | wpb 510.9 | bsz 1 | num_updates 5008 | best_loss 8.723
2022-03-07 00:51:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5008 updates
2022-03-07 00:51:47 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-07 00:51:47 | INFO | train | epoch 103 | loss 2.861 | ppl 7.26 | wps 22004.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5008 | lr 0.000446856 | gnorm 1.087 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 14949
2022-03-07 00:51:47 | INFO | fairseq.trainer | begin training epoch 104
2022-03-07 00:51:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:54:12 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 11.907 | ppl 3841.49 | wps 38833.8 | wpb 510.9 | bsz 1 | num_updates 5057 | best_loss 8.723
2022-03-07 00:54:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5057 updates
2022-03-07 00:54:12 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-07 00:54:12 | INFO | train | epoch 104 | loss 2.828 | ppl 7.1 | wps 22010.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5057 | lr 0.000444686 | gnorm 1.022 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 15093
2022-03-07 00:54:12 | INFO | fairseq.trainer | begin training epoch 105
2022-03-07 00:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:56:14 | INFO | train_inner | epoch 105:     43 / 49 loss=2.82, ppl=7.06, wps=22034.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.033, loss_scale=16, train_wall=260, gb_free=21.5, wall=15216
2022-03-07 00:56:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:56:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:56:36 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.026 | ppl 4170.6 | wps 38570.2 | wpb 510.9 | bsz 1 | num_updates 5105 | best_loss 8.723
2022-03-07 00:56:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5105 updates
2022-03-07 00:56:36 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-07 00:56:36 | INFO | train | epoch 105 | loss 2.8 | ppl 6.96 | wps 21567.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5105 | lr 0.000442591 | gnorm 1.052 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 15238
2022-03-07 00:56:36 | INFO | fairseq.trainer | begin training epoch 106
2022-03-07 00:56:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:58:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:59:00 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.054 | ppl 4251.1 | wps 38662 | wpb 510.9 | bsz 1 | num_updates 5154 | best_loss 8.723
2022-03-07 00:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5154 updates
2022-03-07 00:59:00 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-07 00:59:00 | INFO | train | epoch 106 | loss 2.778 | ppl 6.86 | wps 21985.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5154 | lr 0.000440482 | gnorm 1.071 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 15382
2022-03-07 00:59:00 | INFO | fairseq.trainer | begin training epoch 107
2022-03-07 00:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:01:12 | INFO | train_inner | epoch 107:     46 / 49 loss=2.766, ppl=6.8, wps=21799.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.052, loss_scale=8, train_wall=263, gb_free=21.5, wall=15514
2022-03-07 01:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:01:25 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 11.952 | ppl 3962.54 | wps 38626.5 | wpb 510.9 | bsz 1 | num_updates 5203 | best_loss 8.723
2022-03-07 01:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5203 updates
2022-03-07 01:01:25 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-07 01:01:25 | INFO | train | epoch 107 | loss 2.746 | ppl 6.71 | wps 21994.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5203 | lr 0.000438403 | gnorm 1.014 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 15527
2022-03-07 01:01:25 | INFO | fairseq.trainer | begin training epoch 108
2022-03-07 01:01:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:03:49 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 11.941 | ppl 3931.51 | wps 38818.4 | wpb 510.9 | bsz 1 | num_updates 5252 | best_loss 8.723
2022-03-07 01:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5252 updates
2022-03-07 01:03:49 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-07 01:03:49 | INFO | train | epoch 108 | loss 2.723 | ppl 6.6 | wps 22002.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5252 | lr 0.000436353 | gnorm 1.018 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 15671
2022-03-07 01:03:49 | INFO | fairseq.trainer | begin training epoch 109
2022-03-07 01:03:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:06:07 | INFO | train_inner | epoch 109:     48 / 49 loss=2.713, ppl=6.56, wps=22022.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.014, loss_scale=16, train_wall=260, gb_free=21.5, wall=15808
2022-03-07 01:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:06:14 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.045 | ppl 4224.43 | wps 38981.6 | wpb 510.9 | bsz 1 | num_updates 5301 | best_loss 8.723
2022-03-07 01:06:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5301 updates
2022-03-07 01:06:14 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-07 01:06:14 | INFO | train | epoch 109 | loss 2.699 | ppl 6.49 | wps 22013.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5301 | lr 0.000434331 | gnorm 1.011 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 15816
2022-03-07 01:06:14 | INFO | fairseq.trainer | begin training epoch 110
2022-03-07 01:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:08:38 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.071 | ppl 4301.39 | wps 39023.3 | wpb 510.9 | bsz 1 | num_updates 5350 | best_loss 8.723
2022-03-07 01:08:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5350 updates
2022-03-07 01:08:38 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-07 01:08:38 | INFO | train | epoch 110 | loss 2.675 | ppl 6.39 | wps 22012.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5350 | lr 0.000432338 | gnorm 1.011 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 15960
2022-03-07 01:08:38 | INFO | fairseq.trainer | begin training epoch 111
2022-03-07 01:08:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:09:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:11:03 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.036 | ppl 4199.61 | wps 38966.4 | wpb 510.9 | bsz 1 | num_updates 5398 | best_loss 8.723
2022-03-07 01:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5398 updates
2022-03-07 01:11:03 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-07 01:11:03 | INFO | train | epoch 111 | loss 2.65 | ppl 6.28 | wps 21549.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5398 | lr 0.000430411 | gnorm 0.975 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 16104
2022-03-07 01:11:03 | INFO | fairseq.trainer | begin training epoch 112
2022-03-07 01:11:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:11:08 | INFO | train_inner | epoch 112:      2 / 49 loss=2.661, ppl=6.33, wps=21391.7, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=5400, lr=0.000430331, gnorm=0.996, loss_scale=16, train_wall=262, gb_free=21.5, wall=16110
2022-03-07 01:13:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:13:27 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 11.983 | ppl 4049.1 | wps 38875.3 | wpb 510.9 | bsz 1 | num_updates 5447 | best_loss 8.723
2022-03-07 01:13:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5447 updates
2022-03-07 01:13:27 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-07 01:13:27 | INFO | train | epoch 112 | loss 2.632 | ppl 6.2 | wps 22001.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5447 | lr 0.000428471 | gnorm 1.005 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 16249
2022-03-07 01:13:27 | INFO | fairseq.trainer | begin training epoch 113
2022-03-07 01:13:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:15:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:15:51 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 11.975 | ppl 4026.83 | wps 38906.4 | wpb 510.9 | bsz 1 | num_updates 5496 | best_loss 8.723
2022-03-07 01:15:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5496 updates
2022-03-07 01:15:51 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-07 01:15:51 | INFO | train | epoch 113 | loss 2.611 | ppl 6.11 | wps 22014.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5496 | lr 0.000426557 | gnorm 0.977 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 16393
2022-03-07 01:15:51 | INFO | fairseq.trainer | begin training epoch 114
2022-03-07 01:15:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:15:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:16:06 | INFO | train_inner | epoch 114:      5 / 49 loss=2.62, ppl=6.15, wps=21815.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5500, lr=0.000426401, gnorm=0.996, loss_scale=16, train_wall=263, gb_free=21.5, wall=16407
2022-03-07 01:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:18:16 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 12.101 | ppl 4393.45 | wps 38909.8 | wpb 510.9 | bsz 1 | num_updates 5544 | best_loss 8.723
2022-03-07 01:18:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5544 updates
2022-03-07 01:18:16 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-07 01:18:16 | INFO | train | epoch 114 | loss 2.586 | ppl 6.01 | wps 21555.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5544 | lr 0.000424706 | gnorm 0.956 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 16538
2022-03-07 01:18:16 | INFO | fairseq.trainer | begin training epoch 115
2022-03-07 01:18:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:19:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:20:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:20:40 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 12.069 | ppl 4297.99 | wps 38873.9 | wpb 510.9 | bsz 1 | num_updates 5592 | best_loss 8.723
2022-03-07 01:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5592 updates
2022-03-07 01:20:40 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-07 01:20:40 | INFO | train | epoch 115 | loss 2.569 | ppl 5.93 | wps 21560.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5592 | lr 0.000422879 | gnorm 0.957 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 16682
2022-03-07 01:20:40 | INFO | fairseq.trainer | begin training epoch 116
2022-03-07 01:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:21:03 | INFO | train_inner | epoch 116:      8 / 49 loss=2.573, ppl=5.95, wps=21817.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=0.943, loss_scale=8, train_wall=263, gb_free=21.5, wall=16705
2022-03-07 01:22:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:23:04 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 12.145 | ppl 4529.51 | wps 39153.4 | wpb 510.9 | bsz 1 | num_updates 5641 | best_loss 8.723
2022-03-07 01:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5641 updates
2022-03-07 01:23:04 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-07 01:23:04 | INFO | train | epoch 116 | loss 2.552 | ppl 5.86 | wps 22020.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5641 | lr 0.000421039 | gnorm 0.955 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 16826
2022-03-07 01:23:04 | INFO | fairseq.trainer | begin training epoch 117
2022-03-07 01:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:25:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:25:29 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 12.079 | ppl 4326 | wps 38868 | wpb 510.9 | bsz 1 | num_updates 5690 | best_loss 8.723
2022-03-07 01:25:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5690 updates
2022-03-07 01:25:29 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-07 01:25:29 | INFO | train | epoch 117 | loss 2.534 | ppl 5.79 | wps 22011 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5690 | lr 0.000419222 | gnorm 0.97 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 16971
2022-03-07 01:25:29 | INFO | fairseq.trainer | begin training epoch 118
2022-03-07 01:25:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:25:57 | INFO | train_inner | epoch 118:     10 / 49 loss=2.539, ppl=5.81, wps=22034.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=0.964, loss_scale=16, train_wall=260, gb_free=21.5, wall=16999
2022-03-07 01:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:27:53 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 12.112 | ppl 4427.37 | wps 38931 | wpb 510.9 | bsz 1 | num_updates 5739 | best_loss 8.723
2022-03-07 01:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5739 updates
2022-03-07 01:27:53 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-07 01:27:53 | INFO | train | epoch 118 | loss 2.511 | ppl 5.7 | wps 22016.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5739 | lr 0.000417428 | gnorm 0.903 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 17115
2022-03-07 01:27:53 | INFO | fairseq.trainer | begin training epoch 119
2022-03-07 01:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:30:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:30:18 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 12.138 | ppl 4508 | wps 38806.3 | wpb 510.9 | bsz 1 | num_updates 5788 | best_loss 8.723
2022-03-07 01:30:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5788 updates
2022-03-07 01:30:18 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-07 01:30:18 | INFO | train | epoch 119 | loss 2.497 | ppl 5.65 | wps 22008.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5788 | lr 0.000415658 | gnorm 0.931 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 17259
2022-03-07 01:30:18 | INFO | fairseq.trainer | begin training epoch 120
2022-03-07 01:30:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:30:52 | INFO | train_inner | epoch 120:     12 / 49 loss=2.501, ppl=5.66, wps=22036.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=0.913, loss_scale=16, train_wall=260, gb_free=21.5, wall=17294
2022-03-07 01:31:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:32:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:32:42 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 12.067 | ppl 4289.33 | wps 38847.6 | wpb 510.9 | bsz 1 | num_updates 5836 | best_loss 8.723
2022-03-07 01:32:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5836 updates
2022-03-07 01:32:42 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-07 01:32:42 | INFO | train | epoch 120 | loss 2.477 | ppl 5.57 | wps 21564.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5836 | lr 0.000413945 | gnorm 0.904 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 17404
2022-03-07 01:32:42 | INFO | fairseq.trainer | begin training epoch 121
2022-03-07 01:32:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:33:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:35:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:35:06 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 12.124 | ppl 4463.12 | wps 39053.4 | wpb 510.9 | bsz 1 | num_updates 5884 | best_loss 8.723
2022-03-07 01:35:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5884 updates
2022-03-07 01:35:06 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-07 01:35:06 | INFO | train | epoch 121 | loss 2.461 | ppl 5.51 | wps 21561.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 5884 | lr 0.000412253 | gnorm 0.874 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 17548
2022-03-07 01:35:06 | INFO | fairseq.trainer | begin training epoch 122
2022-03-07 01:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:35:52 | INFO | train_inner | epoch 122:     16 / 49 loss=2.464, ppl=5.52, wps=21611.1, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=0.894, loss_scale=8, train_wall=266, gb_free=21.5, wall=17594
2022-03-07 01:37:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:37:31 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 12.113 | ppl 4430.45 | wps 39018.1 | wpb 510.9 | bsz 1 | num_updates 5933 | best_loss 8.723
2022-03-07 01:37:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5933 updates
2022-03-07 01:37:31 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-07 01:37:31 | INFO | train | epoch 122 | loss 2.449 | ppl 5.46 | wps 22004.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5933 | lr 0.000410547 | gnorm 0.908 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 17692
2022-03-07 01:37:31 | INFO | fairseq.trainer | begin training epoch 123
2022-03-07 01:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:39:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:39:55 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 12.103 | ppl 4400.53 | wps 38848 | wpb 510.9 | bsz 1 | num_updates 5982 | best_loss 8.723
2022-03-07 01:39:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5982 updates
2022-03-07 01:39:55 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-07 01:39:55 | INFO | train | epoch 123 | loss 2.434 | ppl 5.4 | wps 22014.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5982 | lr 0.000408862 | gnorm 0.906 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 17837
2022-03-07 01:39:55 | INFO | fairseq.trainer | begin training epoch 124
2022-03-07 01:39:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:40:47 | INFO | train_inner | epoch 124:     18 / 49 loss=2.437, ppl=5.41, wps=22025.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=0.896, loss_scale=16, train_wall=261, gb_free=21.5, wall=17888
2022-03-07 01:41:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:42:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:42:19 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 12.176 | ppl 4627.83 | wps 38978.7 | wpb 510.9 | bsz 1 | num_updates 6030 | best_loss 8.723
2022-03-07 01:42:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6030 updates
2022-03-07 01:42:19 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-07 01:42:19 | INFO | train | epoch 124 | loss 2.417 | ppl 5.34 | wps 21563.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 6030 | lr 0.000407231 | gnorm 0.872 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 17981
2022-03-07 01:42:19 | INFO | fairseq.trainer | begin training epoch 125
2022-03-07 01:42:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:44:44 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 12.143 | ppl 4522.86 | wps 38913 | wpb 510.9 | bsz 1 | num_updates 6079 | best_loss 8.723
2022-03-07 01:44:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6079 updates
2022-03-07 01:44:44 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-07 01:44:44 | INFO | train | epoch 125 | loss 2.403 | ppl 5.29 | wps 22017 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6079 | lr 0.000405587 | gnorm 0.854 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 18126
2022-03-07 01:44:44 | INFO | fairseq.trainer | begin training epoch 126
2022-03-07 01:44:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:45:44 | INFO | train_inner | epoch 126:     21 / 49 loss=2.405, ppl=5.3, wps=21825.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=0.868, loss_scale=8, train_wall=263, gb_free=21.5, wall=18186
2022-03-07 01:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:47:08 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 12.144 | ppl 4525.86 | wps 38944.3 | wpb 510.9 | bsz 1 | num_updates 6128 | best_loss 8.723
2022-03-07 01:47:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6128 updates
2022-03-07 01:47:08 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-07 01:47:08 | INFO | train | epoch 126 | loss 2.391 | ppl 5.25 | wps 22007.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6128 | lr 0.000403962 | gnorm 0.867 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 18270
2022-03-07 01:47:08 | INFO | fairseq.trainer | begin training epoch 127
2022-03-07 01:47:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:49:32 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 12.146 | ppl 4531.47 | wps 38966.2 | wpb 510.9 | bsz 1 | num_updates 6177 | best_loss 8.723
2022-03-07 01:49:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6177 updates
2022-03-07 01:49:32 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-07 01:49:32 | INFO | train | epoch 127 | loss 2.377 | ppl 5.19 | wps 22027.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6177 | lr 0.000402357 | gnorm 0.848 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 18414
2022-03-07 01:49:32 | INFO | fairseq.trainer | begin training epoch 128
2022-03-07 01:49:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:50:38 | INFO | train_inner | epoch 128:     23 / 49 loss=2.376, ppl=5.19, wps=22037.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=0.845, loss_scale=16, train_wall=260, gb_free=21.5, wall=18480
2022-03-07 01:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:51:57 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 12.076 | ppl 4316.46 | wps 38840.4 | wpb 510.9 | bsz 1 | num_updates 6226 | best_loss 8.723
2022-03-07 01:51:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6226 updates
2022-03-07 01:51:57 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-07 01:51:57 | INFO | train | epoch 128 | loss 2.365 | ppl 5.15 | wps 22011.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6226 | lr 0.00040077 | gnorm 0.882 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 18559
2022-03-07 01:51:57 | INFO | fairseq.trainer | begin training epoch 129
2022-03-07 01:51:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:53:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:54:21 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 12.184 | ppl 4652.78 | wps 38924.6 | wpb 510.9 | bsz 1 | num_updates 6274 | best_loss 8.723
2022-03-07 01:54:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6274 updates
2022-03-07 01:54:21 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-07 01:54:21 | INFO | train | epoch 129 | loss 2.349 | ppl 5.09 | wps 21553.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 6274 | lr 0.000399234 | gnorm 0.837 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 18703
2022-03-07 01:54:21 | INFO | fairseq.trainer | begin training epoch 130
2022-03-07 01:54:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:55:36 | INFO | train_inner | epoch 130:     26 / 49 loss=2.351, ppl=5.1, wps=21804.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=0.854, loss_scale=8, train_wall=263, gb_free=21.5, wall=18777
2022-03-07 01:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:56:46 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 12.08 | ppl 4330.41 | wps 38965.3 | wpb 510.9 | bsz 1 | num_updates 6323 | best_loss 8.723
2022-03-07 01:56:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6323 updates
2022-03-07 01:56:46 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-07 01:56:46 | INFO | train | epoch 130 | loss 2.336 | ppl 5.05 | wps 22008.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6323 | lr 0.000397684 | gnorm 0.807 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 18847
2022-03-07 01:56:46 | INFO | fairseq.trainer | begin training epoch 131
2022-03-07 01:56:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:59:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:59:10 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 12.075 | ppl 4313.83 | wps 38695.7 | wpb 510.9 | bsz 1 | num_updates 6372 | best_loss 8.723
2022-03-07 01:59:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6372 updates
2022-03-07 01:59:10 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-07 01:59:10 | INFO | train | epoch 131 | loss 2.327 | ppl 5.02 | wps 21999.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6372 | lr 0.000396152 | gnorm 0.858 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 18992
2022-03-07 01:59:10 | INFO | fairseq.trainer | begin training epoch 132
2022-03-07 01:59:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:00:30 | INFO | train_inner | epoch 132:     28 / 49 loss=2.324, ppl=5.01, wps=22026.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.831, loss_scale=16, train_wall=260, gb_free=21.5, wall=19072
2022-03-07 02:01:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 02:01:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:01:35 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 12.128 | ppl 4475.21 | wps 38844.4 | wpb 510.9 | bsz 1 | num_updates 6420 | best_loss 8.723
2022-03-07 02:01:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6420 updates
2022-03-07 02:01:35 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-07 02:01:35 | INFO | train | epoch 132 | loss 2.312 | ppl 4.96 | wps 21549.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 6420 | lr 0.000394669 | gnorm 0.822 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 19136
2022-03-07 02:01:35 | INFO | fairseq.trainer | begin training epoch 133
2022-03-07 02:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:03:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:03:59 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 12.112 | ppl 4425.72 | wps 38887.1 | wpb 510.9 | bsz 1 | num_updates 6469 | best_loss 8.723
2022-03-07 02:03:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6469 updates
2022-03-07 02:03:59 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-07 02:03:59 | INFO | train | epoch 133 | loss 2.303 | ppl 4.93 | wps 22003.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6469 | lr 0.000393171 | gnorm 0.806 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 19281
2022-03-07 02:03:59 | INFO | fairseq.trainer | begin training epoch 134
2022-03-07 02:03:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:05:28 | INFO | train_inner | epoch 134:     31 / 49 loss=2.302, ppl=4.93, wps=21811.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.819, loss_scale=8, train_wall=263, gb_free=21.5, wall=19369
2022-03-07 02:06:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:06:23 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 12.114 | ppl 4433.94 | wps 39021.5 | wpb 510.9 | bsz 1 | num_updates 6518 | best_loss 8.723
2022-03-07 02:06:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6518 updates
2022-03-07 02:06:23 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-07 02:06:23 | INFO | train | epoch 134 | loss 2.292 | ppl 4.9 | wps 22019.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6518 | lr 0.00039169 | gnorm 0.81 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 19425
2022-03-07 02:06:23 | INFO | fairseq.trainer | begin training epoch 135
2022-03-07 02:06:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:08:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:08:48 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 12.031 | ppl 4185.29 | wps 38899.9 | wpb 510.9 | bsz 1 | num_updates 6567 | best_loss 8.723
2022-03-07 02:08:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6567 updates
2022-03-07 02:08:48 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-07 02:08:48 | INFO | train | epoch 135 | loss 2.28 | ppl 4.86 | wps 22005.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6567 | lr 0.000390226 | gnorm 0.814 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 19569
2022-03-07 02:08:48 | INFO | fairseq.trainer | begin training epoch 136
2022-03-07 02:08:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:10:22 | INFO | train_inner | epoch 136:     33 / 49 loss=2.279, ppl=4.85, wps=22032.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.81, loss_scale=16, train_wall=260, gb_free=21.5, wall=19664
2022-03-07 02:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:11:12 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 12.073 | ppl 4309.6 | wps 38813.4 | wpb 510.9 | bsz 1 | num_updates 6616 | best_loss 8.723
2022-03-07 02:11:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6616 updates
2022-03-07 02:11:12 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-07 02:11:12 | INFO | train | epoch 136 | loss 2.272 | ppl 4.83 | wps 22008 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6616 | lr 0.000388779 | gnorm 0.81 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 19714
2022-03-07 02:11:12 | INFO | fairseq.trainer | begin training epoch 137
2022-03-07 02:11:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:13:37 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 12.076 | ppl 4316.06 | wps 38731.8 | wpb 510.9 | bsz 1 | num_updates 6665 | best_loss 8.723
2022-03-07 02:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6665 updates
2022-03-07 02:13:37 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-07 02:13:37 | INFO | train | epoch 137 | loss 2.257 | ppl 4.78 | wps 22007 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6665 | lr 0.000387347 | gnorm 0.776 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 19858
2022-03-07 02:13:37 | INFO | fairseq.trainer | begin training epoch 138
2022-03-07 02:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:13:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:15:20 | INFO | train_inner | epoch 138:     36 / 49 loss=2.257, ppl=4.78, wps=21810.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.785, loss_scale=16, train_wall=263, gb_free=21.5, wall=19961
2022-03-07 02:15:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:16:01 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 12.029 | ppl 4178.3 | wps 38931.5 | wpb 510.9 | bsz 1 | num_updates 6713 | best_loss 8.723
2022-03-07 02:16:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6713 updates
2022-03-07 02:16:01 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-07 02:16:01 | INFO | train | epoch 138 | loss 2.249 | ppl 4.75 | wps 21562.4 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 6713 | lr 0.000385959 | gnorm 0.789 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 20003
2022-03-07 02:16:01 | INFO | fairseq.trainer | begin training epoch 139
2022-03-07 02:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:18:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:18:25 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 12.063 | ppl 4279.79 | wps 38856.2 | wpb 510.9 | bsz 1 | num_updates 6762 | best_loss 8.723
2022-03-07 02:18:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6762 updates
2022-03-07 02:18:25 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-07 02:18:25 | INFO | train | epoch 139 | loss 2.24 | ppl 4.72 | wps 21999.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6762 | lr 0.000384559 | gnorm 0.791 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 20147
2022-03-07 02:18:25 | INFO | fairseq.trainer | begin training epoch 140
2022-03-07 02:18:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:20:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:20:17 | INFO | train_inner | epoch 140:     39 / 49 loss=2.237, ppl=4.72, wps=21811.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.783, loss_scale=16, train_wall=263, gb_free=21.5, wall=20259
2022-03-07 02:20:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:20:50 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 12.042 | ppl 4218.36 | wps 39053.1 | wpb 510.9 | bsz 1 | num_updates 6810 | best_loss 8.723
2022-03-07 02:20:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6810 updates
2022-03-07 02:20:50 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-07 02:20:50 | INFO | train | epoch 140 | loss 2.229 | ppl 4.69 | wps 21553.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 6810 | lr 0.000383201 | gnorm 0.773 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 20292
2022-03-07 02:20:50 | INFO | fairseq.trainer | begin training epoch 141
2022-03-07 02:20:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:23:14 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 12.088 | ppl 4352.7 | wps 39000.4 | wpb 510.9 | bsz 1 | num_updates 6859 | best_loss 8.723
2022-03-07 02:23:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6859 updates
2022-03-07 02:23:14 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-07 02:23:14 | INFO | train | epoch 141 | loss 2.221 | ppl 4.66 | wps 22009.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6859 | lr 0.00038183 | gnorm 0.77 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 20436
2022-03-07 02:23:14 | INFO | fairseq.trainer | begin training epoch 142
2022-03-07 02:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:25:11 | INFO | train_inner | epoch 142:     41 / 49 loss=2.219, ppl=4.66, wps=22026.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.773, loss_scale=16, train_wall=260, gb_free=21.5, wall=20553
2022-03-07 02:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:25:39 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 11.987 | ppl 4058.01 | wps 38913.1 | wpb 510.9 | bsz 1 | num_updates 6908 | best_loss 8.723
2022-03-07 02:25:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6908 updates
2022-03-07 02:25:39 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-07 02:25:39 | INFO | train | epoch 142 | loss 2.213 | ppl 4.64 | wps 22009.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6908 | lr 0.000380473 | gnorm 0.781 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 20580
2022-03-07 02:25:39 | INFO | fairseq.trainer | begin training epoch 143
2022-03-07 02:25:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:26:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:28:03 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 12.081 | ppl 4331.32 | wps 38912.7 | wpb 510.9 | bsz 1 | num_updates 6956 | best_loss 8.723
2022-03-07 02:28:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6956 updates
2022-03-07 02:28:03 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-07 02:28:03 | INFO | train | epoch 143 | loss 2.202 | ppl 4.6 | wps 21544.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 6956 | lr 0.000379158 | gnorm 0.769 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 20725
2022-03-07 02:28:03 | INFO | fairseq.trainer | begin training epoch 144
2022-03-07 02:28:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:30:09 | INFO | train_inner | epoch 144:     44 / 49 loss=2.2, ppl=4.59, wps=21808.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.76, loss_scale=16, train_wall=263, gb_free=21.5, wall=20851
2022-03-07 02:30:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:30:27 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 11.996 | ppl 4085.43 | wps 39092.4 | wpb 510.9 | bsz 1 | num_updates 7005 | best_loss 8.723
2022-03-07 02:30:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7005 updates
2022-03-07 02:30:27 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-07 02:30:27 | INFO | train | epoch 144 | loss 2.193 | ppl 4.57 | wps 22011.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7005 | lr 0.00037783 | gnorm 0.744 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 20869
2022-03-07 02:30:27 | INFO | fairseq.trainer | begin training epoch 145
2022-03-07 02:30:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:32:52 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 12.015 | ppl 4138.19 | wps 38939.1 | wpb 510.9 | bsz 1 | num_updates 7054 | best_loss 8.723
2022-03-07 02:32:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7054 updates
2022-03-07 02:32:52 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-07 02:32:52 | INFO | train | epoch 145 | loss 2.185 | ppl 4.55 | wps 22019.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7054 | lr 0.000376515 | gnorm 0.744 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 21013
2022-03-07 02:32:52 | INFO | fairseq.trainer | begin training epoch 146
2022-03-07 02:32:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:33:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:35:06 | INFO | train_inner | epoch 146:     47 / 49 loss=2.184, ppl=4.54, wps=21814.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.753, loss_scale=16, train_wall=263, gb_free=21.5, wall=21148
2022-03-07 02:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:35:16 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 11.998 | ppl 4090.87 | wps 38839.7 | wpb 510.9 | bsz 1 | num_updates 7102 | best_loss 8.723
2022-03-07 02:35:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7102 updates
2022-03-07 02:35:16 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-07 02:35:16 | INFO | train | epoch 146 | loss 2.179 | ppl 4.53 | wps 21535 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7102 | lr 0.00037524 | gnorm 0.761 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 21158
2022-03-07 02:35:16 | INFO | fairseq.trainer | begin training epoch 147
2022-03-07 02:35:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:35:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 02:37:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:37:41 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 12.077 | ppl 4319.37 | wps 39010.2 | wpb 510.9 | bsz 1 | num_updates 7150 | best_loss 8.723
2022-03-07 02:37:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7150 updates
2022-03-07 02:37:41 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-07 02:37:41 | INFO | train | epoch 147 | loss 2.17 | ppl 4.5 | wps 21559.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7150 | lr 0.000373979 | gnorm 0.742 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 21302
2022-03-07 02:37:41 | INFO | fairseq.trainer | begin training epoch 148
2022-03-07 02:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:39:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:40:05 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 12 | ppl 4094.79 | wps 38870.1 | wpb 510.9 | bsz 1 | num_updates 7199 | best_loss 8.723
2022-03-07 02:40:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7199 updates
2022-03-07 02:40:05 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-07 02:40:05 | INFO | train | epoch 148 | loss 2.162 | ppl 4.48 | wps 22014.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7199 | lr 0.000372704 | gnorm 0.741 | loss_scale 8 | train_wall 128 | gb_free 21.5 | wall 21447
2022-03-07 02:40:05 | INFO | fairseq.trainer | begin training epoch 149
2022-03-07 02:40:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:40:08 | INFO | train_inner | epoch 149:      1 / 49 loss=2.166, ppl=4.49, wps=21397.2, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=7200, lr=0.000372678, gnorm=0.744, loss_scale=8, train_wall=262, gb_free=21.5, wall=21450
2022-03-07 02:42:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:42:29 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 11.951 | ppl 3959.85 | wps 38983.7 | wpb 510.9 | bsz 1 | num_updates 7248 | best_loss 8.723
2022-03-07 02:42:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7248 updates
2022-03-07 02:42:29 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-07 02:42:29 | INFO | train | epoch 149 | loss 2.152 | ppl 4.45 | wps 22010.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7248 | lr 0.000371442 | gnorm 0.715 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 21591
2022-03-07 02:42:29 | INFO | fairseq.trainer | begin training epoch 150
2022-03-07 02:42:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:44:54 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 11.967 | ppl 4003.17 | wps 38871.4 | wpb 510.9 | bsz 1 | num_updates 7297 | best_loss 8.723
2022-03-07 02:44:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7297 updates
2022-03-07 02:44:54 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-07 02:44:54 | INFO | train | epoch 150 | loss 2.147 | ppl 4.43 | wps 21992.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7297 | lr 0.000370193 | gnorm 0.721 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 21736
2022-03-07 02:44:54 | INFO | fairseq.trainer | begin training epoch 151
2022-03-07 02:44:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:45:03 | INFO | train_inner | epoch 151:      3 / 49 loss=2.148, ppl=4.43, wps=22019.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7300, lr=0.000370117, gnorm=0.719, loss_scale=16, train_wall=260, gb_free=21.5, wall=21744
2022-03-07 02:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:47:18 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 12.006 | ppl 4113.89 | wps 38953.4 | wpb 510.9 | bsz 1 | num_updates 7346 | best_loss 8.723
2022-03-07 02:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7346 updates
2022-03-07 02:47:18 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-07 02:47:18 | INFO | train | epoch 151 | loss 2.14 | ppl 4.41 | wps 22002.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7346 | lr 0.000368956 | gnorm 0.738 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 21880
2022-03-07 02:47:18 | INFO | fairseq.trainer | begin training epoch 152
2022-03-07 02:47:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:48:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:49:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:49:43 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 11.941 | ppl 3931.75 | wps 38985.9 | wpb 510.9 | bsz 1 | num_updates 7394 | best_loss 8.723
2022-03-07 02:49:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7394 updates
2022-03-07 02:49:43 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-07 02:49:43 | INFO | train | epoch 152 | loss 2.131 | ppl 4.38 | wps 21578.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7394 | lr 0.000367756 | gnorm 0.715 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22024
2022-03-07 02:49:43 | INFO | fairseq.trainer | begin training epoch 153
2022-03-07 02:49:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:50:00 | INFO | train_inner | epoch 153:      6 / 49 loss=2.134, ppl=4.39, wps=21820.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.721, loss_scale=16, train_wall=263, gb_free=21.5, wall=22042
2022-03-07 02:52:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:52:07 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 12.048 | ppl 4235.67 | wps 38873.7 | wpb 510.9 | bsz 1 | num_updates 7443 | best_loss 8.723
2022-03-07 02:52:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7443 updates
2022-03-07 02:52:07 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-07 02:52:07 | INFO | train | epoch 153 | loss 2.124 | ppl 4.36 | wps 22007.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7443 | lr 0.000366544 | gnorm 0.697 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 22169
2022-03-07 02:52:07 | INFO | fairseq.trainer | begin training epoch 154
2022-03-07 02:52:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:54:31 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 11.932 | ppl 3907.52 | wps 38969.8 | wpb 510.9 | bsz 1 | num_updates 7492 | best_loss 8.723
2022-03-07 02:54:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7492 updates
2022-03-07 02:54:31 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-07 02:54:31 | INFO | train | epoch 154 | loss 2.118 | ppl 4.34 | wps 22007 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7492 | lr 0.000365343 | gnorm 0.713 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 22313
2022-03-07 02:54:31 | INFO | fairseq.trainer | begin training epoch 155
2022-03-07 02:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:54:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:54:57 | INFO | train_inner | epoch 155:      9 / 49 loss=2.12, ppl=4.35, wps=21817.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.707, loss_scale=16, train_wall=263, gb_free=21.5, wall=22339
2022-03-07 02:56:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:56:56 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 11.972 | ppl 4016.2 | wps 38499.2 | wpb 510.9 | bsz 1 | num_updates 7540 | best_loss 8.723
2022-03-07 02:56:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7540 updates
2022-03-07 02:56:56 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-07 02:56:56 | INFO | train | epoch 155 | loss 2.111 | ppl 4.32 | wps 21555.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7540 | lr 0.000364179 | gnorm 0.703 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 22458
2022-03-07 02:56:56 | INFO | fairseq.trainer | begin training epoch 156
2022-03-07 02:56:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:59:20 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 11.921 | ppl 3876.65 | wps 39053.1 | wpb 510.9 | bsz 1 | num_updates 7589 | best_loss 8.723
2022-03-07 02:59:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7589 updates
2022-03-07 02:59:20 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-07 02:59:20 | INFO | train | epoch 156 | loss 2.104 | ppl 4.3 | wps 22028.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7589 | lr 0.000363001 | gnorm 0.688 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22602
2022-03-07 02:59:20 | INFO | fairseq.trainer | begin training epoch 157
2022-03-07 02:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:59:52 | INFO | train_inner | epoch 157:     11 / 49 loss=2.106, ppl=4.3, wps=22034.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.698, loss_scale=16, train_wall=260, gb_free=21.5, wall=22633
2022-03-07 03:00:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:01:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:01:45 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 11.975 | ppl 4024.54 | wps 39019.6 | wpb 510.9 | bsz 1 | num_updates 7637 | best_loss 8.723
2022-03-07 03:01:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7637 updates
2022-03-07 03:01:45 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-07 03:01:45 | INFO | train | epoch 157 | loss 2.096 | ppl 4.28 | wps 21547.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7637 | lr 0.000361858 | gnorm 0.692 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 22746
2022-03-07 03:01:45 | INFO | fairseq.trainer | begin training epoch 158
2022-03-07 03:01:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:04:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:04:09 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 11.897 | ppl 3814.76 | wps 39021.2 | wpb 510.9 | bsz 1 | num_updates 7686 | best_loss 8.723
2022-03-07 03:04:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7686 updates
2022-03-07 03:04:09 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-07 03:04:09 | INFO | train | epoch 158 | loss 2.093 | ppl 4.27 | wps 22011.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7686 | lr 0.000360703 | gnorm 0.702 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 22891
2022-03-07 03:04:09 | INFO | fairseq.trainer | begin training epoch 159
2022-03-07 03:04:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:04:49 | INFO | train_inner | epoch 159:     14 / 49 loss=2.093, ppl=4.27, wps=21813.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.694, loss_scale=16, train_wall=263, gb_free=21.5, wall=22931
2022-03-07 03:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:06:33 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 11.897 | ppl 3814.65 | wps 38988.8 | wpb 510.9 | bsz 1 | num_updates 7735 | best_loss 8.723
2022-03-07 03:06:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7735 updates
2022-03-07 03:06:33 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-07 03:06:33 | INFO | train | epoch 159 | loss 2.085 | ppl 4.24 | wps 22026.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7735 | lr 0.000359559 | gnorm 0.674 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 23035
2022-03-07 03:06:33 | INFO | fairseq.trainer | begin training epoch 160
2022-03-07 03:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:07:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:08:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:08:58 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 11.917 | ppl 3866.97 | wps 38925.8 | wpb 510.9 | bsz 1 | num_updates 7783 | best_loss 8.723
2022-03-07 03:08:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7783 updates
2022-03-07 03:08:58 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-07 03:08:58 | INFO | train | epoch 160 | loss 2.079 | ppl 4.22 | wps 21548.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7783 | lr 0.000358448 | gnorm 0.676 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 23179
2022-03-07 03:08:58 | INFO | fairseq.trainer | begin training epoch 161
2022-03-07 03:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:09:46 | INFO | train_inner | epoch 161:     17 / 49 loss=2.08, ppl=4.23, wps=21822.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.669, loss_scale=16, train_wall=263, gb_free=21.5, wall=23228
2022-03-07 03:11:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:11:22 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 11.914 | ppl 3859.35 | wps 38991.1 | wpb 510.9 | bsz 1 | num_updates 7832 | best_loss 8.723
2022-03-07 03:11:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7832 updates
2022-03-07 03:11:22 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-07 03:11:22 | INFO | train | epoch 161 | loss 2.073 | ppl 4.21 | wps 22023.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7832 | lr 0.000357325 | gnorm 0.676 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 23324
2022-03-07 03:11:22 | INFO | fairseq.trainer | begin training epoch 162
2022-03-07 03:11:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:13:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:13:46 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 11.898 | ppl 3816.07 | wps 39006.3 | wpb 510.9 | bsz 1 | num_updates 7881 | best_loss 8.723
2022-03-07 03:13:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7881 updates
2022-03-07 03:13:46 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-07 03:13:46 | INFO | train | epoch 162 | loss 2.067 | ppl 4.19 | wps 21995.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7881 | lr 0.000356213 | gnorm 0.658 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 23468
2022-03-07 03:13:46 | INFO | fairseq.trainer | begin training epoch 163
2022-03-07 03:13:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:14:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:14:44 | INFO | train_inner | epoch 163:     20 / 49 loss=2.068, ppl=4.19, wps=21816.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.676, loss_scale=16, train_wall=263, gb_free=21.5, wall=23525
2022-03-07 03:16:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:16:11 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 11.917 | ppl 3866.22 | wps 38994.7 | wpb 510.9 | bsz 1 | num_updates 7929 | best_loss 8.723
2022-03-07 03:16:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7929 updates
2022-03-07 03:16:11 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-07 03:16:11 | INFO | train | epoch 163 | loss 2.064 | ppl 4.18 | wps 21571.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7929 | lr 0.000355133 | gnorm 0.688 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 23612
2022-03-07 03:16:11 | INFO | fairseq.trainer | begin training epoch 164
2022-03-07 03:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:18:35 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 11.919 | ppl 3872.84 | wps 38971.6 | wpb 510.9 | bsz 1 | num_updates 7978 | best_loss 8.723
2022-03-07 03:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7978 updates
2022-03-07 03:18:35 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-07 03:18:35 | INFO | train | epoch 164 | loss 2.056 | ppl 4.16 | wps 22020.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7978 | lr 0.000354041 | gnorm 0.681 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 23757
2022-03-07 03:18:35 | INFO | fairseq.trainer | begin training epoch 165
2022-03-07 03:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:19:38 | INFO | train_inner | epoch 165:     22 / 49 loss=2.057, ppl=4.16, wps=22036.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.676, loss_scale=16, train_wall=260, gb_free=21.5, wall=23820
2022-03-07 03:20:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:20:59 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 11.904 | ppl 3831.5 | wps 38982.8 | wpb 510.9 | bsz 1 | num_updates 8027 | best_loss 8.723
2022-03-07 03:20:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8027 updates
2022-03-07 03:20:59 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-07 03:20:59 | INFO | train | epoch 165 | loss 2.049 | ppl 4.14 | wps 22001.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8027 | lr 0.000352958 | gnorm 0.662 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 23901
2022-03-07 03:20:59 | INFO | fairseq.trainer | begin training epoch 166
2022-03-07 03:20:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:21:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:23:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:23:24 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 11.853 | ppl 3698.41 | wps 38924.7 | wpb 510.9 | bsz 1 | num_updates 8075 | best_loss 8.723
2022-03-07 03:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8075 updates
2022-03-07 03:23:24 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-07 03:23:24 | INFO | train | epoch 166 | loss 2.044 | ppl 4.12 | wps 21578.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8075 | lr 0.000351908 | gnorm 0.659 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 24045
2022-03-07 03:23:24 | INFO | fairseq.trainer | begin training epoch 167
2022-03-07 03:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:24:35 | INFO | train_inner | epoch 167:     25 / 49 loss=2.044, ppl=4.12, wps=21819.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.661, loss_scale=16, train_wall=263, gb_free=21.5, wall=24117
2022-03-07 03:25:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:25:48 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 11.911 | ppl 3851.69 | wps 39151.3 | wpb 510.9 | bsz 1 | num_updates 8124 | best_loss 8.723
2022-03-07 03:25:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8124 updates
2022-03-07 03:25:48 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-07 03:25:48 | INFO | train | epoch 167 | loss 2.039 | ppl 4.11 | wps 22018 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8124 | lr 0.000350845 | gnorm 0.653 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 24190
2022-03-07 03:25:48 | INFO | fairseq.trainer | begin training epoch 168
2022-03-07 03:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:28:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:28:12 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 11.91 | ppl 3847.45 | wps 38919.9 | wpb 510.9 | bsz 1 | num_updates 8173 | best_loss 8.723
2022-03-07 03:28:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8173 updates
2022-03-07 03:28:12 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-07 03:28:12 | INFO | train | epoch 168 | loss 2.034 | ppl 4.1 | wps 22013.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8173 | lr 0.000349791 | gnorm 0.644 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 24334
2022-03-07 03:28:12 | INFO | fairseq.trainer | begin training epoch 169
2022-03-07 03:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:29:30 | INFO | train_inner | epoch 169:     27 / 49 loss=2.034, ppl=4.1, wps=22037.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.645, loss_scale=32, train_wall=260, gb_free=21.5, wall=24411
2022-03-07 03:30:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:30:37 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 11.853 | ppl 3698.32 | wps 38888.2 | wpb 510.9 | bsz 1 | num_updates 8222 | best_loss 8.723
2022-03-07 03:30:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8222 updates
2022-03-07 03:30:37 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-07 03:30:37 | INFO | train | epoch 169 | loss 2.029 | ppl 4.08 | wps 22016.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8222 | lr 0.000348748 | gnorm 0.653 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 24479
2022-03-07 03:30:37 | INFO | fairseq.trainer | begin training epoch 170
2022-03-07 03:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:30:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:32:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:33:01 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 11.865 | ppl 3730.93 | wps 38991 | wpb 510.9 | bsz 1 | num_updates 8270 | best_loss 8.723
2022-03-07 03:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8270 updates
2022-03-07 03:33:01 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-07 03:33:01 | INFO | train | epoch 170 | loss 2.023 | ppl 4.06 | wps 21566.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8270 | lr 0.000347734 | gnorm 0.638 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 24623
2022-03-07 03:33:01 | INFO | fairseq.trainer | begin training epoch 171
2022-03-07 03:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:34:27 | INFO | train_inner | epoch 171:     30 / 49 loss=2.022, ppl=4.06, wps=21828.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.64, loss_scale=16, train_wall=263, gb_free=21.5, wall=24709
2022-03-07 03:35:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:35:25 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 11.843 | ppl 3673.38 | wps 38986.9 | wpb 510.9 | bsz 1 | num_updates 8319 | best_loss 8.723
2022-03-07 03:35:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8319 updates
2022-03-07 03:35:25 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-07 03:35:25 | INFO | train | epoch 171 | loss 2.019 | ppl 4.05 | wps 22018.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8319 | lr 0.000346708 | gnorm 0.637 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 24767
2022-03-07 03:35:25 | INFO | fairseq.trainer | begin training epoch 172
2022-03-07 03:35:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:37:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:37:50 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 11.836 | ppl 3654.95 | wps 39085.1 | wpb 510.9 | bsz 1 | num_updates 8367 | best_loss 8.723
2022-03-07 03:37:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8367 updates
2022-03-07 03:37:50 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-07 03:37:50 | INFO | train | epoch 172 | loss 2.015 | ppl 4.04 | wps 21572.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8367 | lr 0.000345713 | gnorm 0.639 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 24911
2022-03-07 03:37:50 | INFO | fairseq.trainer | begin training epoch 173
2022-03-07 03:37:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:39:24 | INFO | train_inner | epoch 173:     33 / 49 loss=2.015, ppl=4.04, wps=21824.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.636, loss_scale=16, train_wall=263, gb_free=21.5, wall=25006
2022-03-07 03:40:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:40:14 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 11.842 | ppl 3670.36 | wps 38900.1 | wpb 510.9 | bsz 1 | num_updates 8416 | best_loss 8.723
2022-03-07 03:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8416 updates
2022-03-07 03:40:14 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-07 03:40:14 | INFO | train | epoch 173 | loss 2.01 | ppl 4.03 | wps 22010.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8416 | lr 0.000344705 | gnorm 0.631 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 25056
2022-03-07 03:40:14 | INFO | fairseq.trainer | begin training epoch 174
2022-03-07 03:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:42:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:42:39 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 11.848 | ppl 3687.36 | wps 38819.3 | wpb 510.9 | bsz 1 | num_updates 8465 | best_loss 8.723
2022-03-07 03:42:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8465 updates
2022-03-07 03:42:39 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-07 03:42:39 | INFO | train | epoch 174 | loss 2.005 | ppl 4.01 | wps 22005.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8465 | lr 0.000343706 | gnorm 0.636 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 25200
2022-03-07 03:42:39 | INFO | fairseq.trainer | begin training epoch 175
2022-03-07 03:42:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:43:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:44:21 | INFO | train_inner | epoch 175:     36 / 49 loss=2.004, ppl=4.01, wps=21817.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.638, loss_scale=16, train_wall=263, gb_free=21.5, wall=25303
2022-03-07 03:44:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:45:03 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 11.806 | ppl 3581.35 | wps 39035.3 | wpb 510.9 | bsz 1 | num_updates 8513 | best_loss 8.723
2022-03-07 03:45:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8513 updates
2022-03-07 03:45:03 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-07 03:45:03 | INFO | train | epoch 175 | loss 1.999 | ppl 4 | wps 21576.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8513 | lr 0.000342735 | gnorm 0.64 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 25345
2022-03-07 03:45:03 | INFO | fairseq.trainer | begin training epoch 176
2022-03-07 03:45:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:47:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:47:27 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 11.744 | ppl 3430.74 | wps 39050.4 | wpb 510.9 | bsz 1 | num_updates 8562 | best_loss 8.723
2022-03-07 03:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8562 updates
2022-03-07 03:47:27 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-07 03:47:27 | INFO | train | epoch 176 | loss 1.996 | ppl 3.99 | wps 22024.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8562 | lr 0.000341753 | gnorm 0.636 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 25489
2022-03-07 03:47:27 | INFO | fairseq.trainer | begin training epoch 177
2022-03-07 03:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:49:16 | INFO | train_inner | epoch 177:     38 / 49 loss=1.994, ppl=3.98, wps=22048.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.634, loss_scale=16, train_wall=260, gb_free=21.5, wall=25597
2022-03-07 03:49:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:49:51 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 11.796 | ppl 3555.05 | wps 38929.3 | wpb 510.9 | bsz 1 | num_updates 8611 | best_loss 8.723
2022-03-07 03:49:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8611 updates
2022-03-07 03:49:51 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-07 03:49:51 | INFO | train | epoch 177 | loss 1.991 | ppl 3.97 | wps 22032.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8611 | lr 0.000340779 | gnorm 0.631 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 25633
2022-03-07 03:49:51 | INFO | fairseq.trainer | begin training epoch 178
2022-03-07 03:49:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:50:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:52:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:52:16 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 11.817 | ppl 3608.33 | wps 39060.9 | wpb 510.9 | bsz 1 | num_updates 8659 | best_loss 8.723
2022-03-07 03:52:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8659 updates
2022-03-07 03:52:16 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-07 03:52:16 | INFO | train | epoch 178 | loss 1.986 | ppl 3.96 | wps 21559.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8659 | lr 0.000339833 | gnorm 0.623 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 25777
2022-03-07 03:52:16 | INFO | fairseq.trainer | begin training epoch 179
2022-03-07 03:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:54:13 | INFO | train_inner | epoch 179:     41 / 49 loss=1.985, ppl=3.96, wps=21826.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.624, loss_scale=16, train_wall=263, gb_free=21.5, wall=25895
2022-03-07 03:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:54:40 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 11.748 | ppl 3438.73 | wps 38942.4 | wpb 510.9 | bsz 1 | num_updates 8708 | best_loss 8.723
2022-03-07 03:54:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8708 updates
2022-03-07 03:54:40 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-07 03:54:40 | INFO | train | epoch 179 | loss 1.982 | ppl 3.95 | wps 22030 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8708 | lr 0.000338876 | gnorm 0.618 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 25922
2022-03-07 03:54:40 | INFO | fairseq.trainer | begin training epoch 180
2022-03-07 03:54:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:56:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:57:04 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 11.742 | ppl 3424.92 | wps 39009.4 | wpb 510.9 | bsz 1 | num_updates 8757 | best_loss 8.723
2022-03-07 03:57:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8757 updates
2022-03-07 03:57:04 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-07 03:57:04 | INFO | train | epoch 180 | loss 1.976 | ppl 3.93 | wps 22014.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8757 | lr 0.000337927 | gnorm 0.609 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 26066
2022-03-07 03:57:04 | INFO | fairseq.trainer | begin training epoch 181
2022-03-07 03:57:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:57:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:59:10 | INFO | train_inner | epoch 181:     44 / 49 loss=1.976, ppl=3.93, wps=21825, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.605, loss_scale=16, train_wall=263, gb_free=21.5, wall=26192
2022-03-07 03:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:59:29 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 11.741 | ppl 3423.36 | wps 38942 | wpb 510.9 | bsz 1 | num_updates 8805 | best_loss 8.723
2022-03-07 03:59:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8805 updates
2022-03-07 03:59:29 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-07 03:59:29 | INFO | train | epoch 181 | loss 1.972 | ppl 3.92 | wps 21559.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8805 | lr 0.000337004 | gnorm 0.602 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 26210
2022-03-07 03:59:29 | INFO | fairseq.trainer | begin training epoch 182
2022-03-07 03:59:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:01:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:01:53 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 11.773 | ppl 3499.99 | wps 39031 | wpb 510.9 | bsz 1 | num_updates 8854 | best_loss 8.723
2022-03-07 04:01:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8854 updates
2022-03-07 04:01:53 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-07 04:01:53 | INFO | train | epoch 182 | loss 1.971 | ppl 3.92 | wps 22021.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8854 | lr 0.00033607 | gnorm 0.622 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 26355
2022-03-07 04:01:53 | INFO | fairseq.trainer | begin training epoch 183
2022-03-07 04:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:04:05 | INFO | train_inner | epoch 183:     46 / 49 loss=1.968, ppl=3.91, wps=22033, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.615, loss_scale=32, train_wall=260, gb_free=21.5, wall=26486
2022-03-07 04:04:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:04:17 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 11.743 | ppl 3428.53 | wps 39075.5 | wpb 510.9 | bsz 1 | num_updates 8903 | best_loss 8.723
2022-03-07 04:04:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8903 updates
2022-03-07 04:04:17 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-07 04:04:17 | INFO | train | epoch 183 | loss 1.965 | ppl 3.9 | wps 22019 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8903 | lr 0.000335144 | gnorm 0.606 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 26499
2022-03-07 04:04:17 | INFO | fairseq.trainer | begin training epoch 184
2022-03-07 04:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:05:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:06:42 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 11.775 | ppl 3504.05 | wps 38898.1 | wpb 510.9 | bsz 1 | num_updates 8951 | best_loss 8.723
2022-03-07 04:06:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8951 updates
2022-03-07 04:06:42 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-07 04:06:42 | INFO | train | epoch 184 | loss 1.959 | ppl 3.89 | wps 21563.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8951 | lr 0.000334244 | gnorm 0.602 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 26643
2022-03-07 04:06:42 | INFO | fairseq.trainer | begin training epoch 185
2022-03-07 04:06:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:09:00 | INFO | train_inner | epoch 185:     49 / 49 loss=1.959, ppl=3.89, wps=21820.4, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=9000, lr=0.000333333, gnorm=0.608, loss_scale=16, train_wall=262, gb_free=21.5, wall=26782
2022-03-07 04:09:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:09:06 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 11.739 | ppl 3419.1 | wps 38874.5 | wpb 510.9 | bsz 1 | num_updates 9000 | best_loss 8.723
2022-03-07 04:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9000 updates
2022-03-07 04:09:06 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-07 04:09:06 | INFO | train | epoch 185 | loss 1.957 | ppl 3.88 | wps 22019.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9000 | lr 0.000333333 | gnorm 0.61 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 26788
2022-03-07 04:09:06 | INFO | fairseq.trainer | begin training epoch 186
2022-03-07 04:09:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:11:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:11:30 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 11.814 | ppl 3600.32 | wps 39046.6 | wpb 510.9 | bsz 1 | num_updates 9049 | best_loss 8.723
2022-03-07 04:11:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9049 updates
2022-03-07 04:11:30 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-07 04:11:30 | INFO | train | epoch 186 | loss 1.953 | ppl 3.87 | wps 22015.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9049 | lr 0.00033243 | gnorm 0.595 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 26932
2022-03-07 04:11:30 | INFO | fairseq.trainer | begin training epoch 187
2022-03-07 04:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:11:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:13:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:13:55 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 11.755 | ppl 3456.25 | wps 38839.2 | wpb 510.9 | bsz 1 | num_updates 9097 | best_loss 8.723
2022-03-07 04:13:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9097 updates
2022-03-07 04:13:55 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-07 04:13:55 | INFO | train | epoch 187 | loss 1.949 | ppl 3.86 | wps 21564.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9097 | lr 0.000331551 | gnorm 0.596 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 27076
2022-03-07 04:13:55 | INFO | fairseq.trainer | begin training epoch 188
2022-03-07 04:13:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:14:03 | INFO | train_inner | epoch 188:      3 / 49 loss=1.95, ppl=3.86, wps=21409.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=9100, lr=0.000331497, gnorm=0.596, loss_scale=16, train_wall=263, gb_free=21.5, wall=27085
2022-03-07 04:16:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:16:19 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 11.744 | ppl 3430.51 | wps 38938.9 | wpb 510.9 | bsz 1 | num_updates 9146 | best_loss 8.723
2022-03-07 04:16:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9146 updates
2022-03-07 04:16:19 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-07 04:16:19 | INFO | train | epoch 188 | loss 1.947 | ppl 3.86 | wps 22000 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9146 | lr 0.000330662 | gnorm 0.607 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 27221
2022-03-07 04:16:19 | INFO | fairseq.trainer | begin training epoch 189
2022-03-07 04:16:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:18:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:18:44 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 11.756 | ppl 3459.84 | wps 38933.7 | wpb 510.9 | bsz 1 | num_updates 9195 | best_loss 8.723
2022-03-07 04:18:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9195 updates
2022-03-07 04:18:44 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-07 04:18:44 | INFO | train | epoch 189 | loss 1.942 | ppl 3.84 | wps 21998.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9195 | lr 0.00032978 | gnorm 0.591 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 27365
2022-03-07 04:18:44 | INFO | fairseq.trainer | begin training epoch 190
2022-03-07 04:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:18:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:19:01 | INFO | train_inner | epoch 190:      6 / 49 loss=1.943, ppl=3.85, wps=21806.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9200, lr=0.00032969, gnorm=0.599, loss_scale=16, train_wall=263, gb_free=21.5, wall=27383
2022-03-07 04:21:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:21:08 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 11.775 | ppl 3504.16 | wps 38998.4 | wpb 510.9 | bsz 1 | num_updates 9243 | best_loss 8.723
2022-03-07 04:21:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9243 updates
2022-03-07 04:21:08 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-07 04:21:08 | INFO | train | epoch 190 | loss 1.938 | ppl 3.83 | wps 21559.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9243 | lr 0.000328922 | gnorm 0.6 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 27510
2022-03-07 04:21:08 | INFO | fairseq.trainer | begin training epoch 191
2022-03-07 04:21:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:23:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:23:32 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 11.71 | ppl 3348.98 | wps 39078.9 | wpb 510.9 | bsz 1 | num_updates 9292 | best_loss 8.723
2022-03-07 04:23:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9292 updates
2022-03-07 04:23:32 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-07 04:23:32 | INFO | train | epoch 191 | loss 1.935 | ppl 3.82 | wps 22001.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9292 | lr 0.000328054 | gnorm 0.585 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 27654
2022-03-07 04:23:32 | INFO | fairseq.trainer | begin training epoch 192
2022-03-07 04:23:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:23:55 | INFO | train_inner | epoch 192:      8 / 49 loss=1.936, ppl=3.83, wps=22024.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.591, loss_scale=16, train_wall=260, gb_free=21.5, wall=27677
2022-03-07 04:25:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:25:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:25:57 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 11.745 | ppl 3432.18 | wps 38447.9 | wpb 510.9 | bsz 1 | num_updates 9340 | best_loss 8.723
2022-03-07 04:25:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9340 updates
2022-03-07 04:25:57 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-07 04:25:57 | INFO | train | epoch 192 | loss 1.931 | ppl 3.81 | wps 21555.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9340 | lr 0.00032721 | gnorm 0.579 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 27799
2022-03-07 04:25:57 | INFO | fairseq.trainer | begin training epoch 193
2022-03-07 04:25:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:28:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:28:21 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 11.728 | ppl 3392.46 | wps 38958.3 | wpb 510.9 | bsz 1 | num_updates 9389 | best_loss 8.723
2022-03-07 04:28:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9389 updates
2022-03-07 04:28:21 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-07 04:28:21 | INFO | train | epoch 193 | loss 1.929 | ppl 3.81 | wps 22014 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9389 | lr 0.000326355 | gnorm 0.59 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 27943
2022-03-07 04:28:21 | INFO | fairseq.trainer | begin training epoch 194
2022-03-07 04:28:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:28:53 | INFO | train_inner | epoch 194:     11 / 49 loss=1.929, ppl=3.81, wps=21818.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.585, loss_scale=16, train_wall=263, gb_free=21.5, wall=27974
2022-03-07 04:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:30:46 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 11.711 | ppl 3351.36 | wps 38958.8 | wpb 510.9 | bsz 1 | num_updates 9438 | best_loss 8.723
2022-03-07 04:30:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9438 updates
2022-03-07 04:30:46 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-07 04:30:46 | INFO | train | epoch 194 | loss 1.924 | ppl 3.8 | wps 22018.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9438 | lr 0.000325507 | gnorm 0.573 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 28087
2022-03-07 04:30:46 | INFO | fairseq.trainer | begin training epoch 195
2022-03-07 04:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:33:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:33:10 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 11.758 | ppl 3462.38 | wps 39036.5 | wpb 510.9 | bsz 1 | num_updates 9487 | best_loss 8.723
2022-03-07 04:33:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9487 updates
2022-03-07 04:33:10 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-07 04:33:10 | INFO | train | epoch 195 | loss 1.921 | ppl 3.79 | wps 22020.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9487 | lr 0.000324665 | gnorm 0.575 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 28232
2022-03-07 04:33:10 | INFO | fairseq.trainer | begin training epoch 196
2022-03-07 04:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:33:47 | INFO | train_inner | epoch 196:     13 / 49 loss=1.922, ppl=3.79, wps=22034.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.572, loss_scale=32, train_wall=260, gb_free=21.5, wall=28269
2022-03-07 04:34:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:35:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:35:34 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 11.742 | ppl 3425.23 | wps 39024.2 | wpb 510.9 | bsz 1 | num_updates 9535 | best_loss 8.723
2022-03-07 04:35:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9535 updates
2022-03-07 04:35:34 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-07 04:35:34 | INFO | train | epoch 196 | loss 1.917 | ppl 3.78 | wps 21562.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9535 | lr 0.000323847 | gnorm 0.571 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 28376
2022-03-07 04:35:34 | INFO | fairseq.trainer | begin training epoch 197
2022-03-07 04:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:37:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:37:59 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 11.744 | ppl 3429.6 | wps 38848.5 | wpb 510.9 | bsz 1 | num_updates 9584 | best_loss 8.723
2022-03-07 04:37:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9584 updates
2022-03-07 04:37:59 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-07 04:37:59 | INFO | train | epoch 197 | loss 1.915 | ppl 3.77 | wps 22016.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9584 | lr 0.000323018 | gnorm 0.58 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 28520
2022-03-07 04:37:59 | INFO | fairseq.trainer | begin training epoch 198
2022-03-07 04:37:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:38:44 | INFO | train_inner | epoch 198:     16 / 49 loss=1.914, ppl=3.77, wps=21826.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.579, loss_scale=16, train_wall=263, gb_free=21.5, wall=28566
2022-03-07 04:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:40:23 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 11.734 | ppl 3407.38 | wps 38997.9 | wpb 510.9 | bsz 1 | num_updates 9633 | best_loss 8.723
2022-03-07 04:40:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9633 updates
2022-03-07 04:40:23 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-07 04:40:23 | INFO | train | epoch 198 | loss 1.911 | ppl 3.76 | wps 22020.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9633 | lr 0.000322195 | gnorm 0.581 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 28665
2022-03-07 04:40:23 | INFO | fairseq.trainer | begin training epoch 199
2022-03-07 04:40:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:40:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:42:47 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 11.692 | ppl 3307.69 | wps 38909.4 | wpb 510.9 | bsz 1 | num_updates 9681 | best_loss 8.723
2022-03-07 04:42:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9681 updates
2022-03-07 04:42:47 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-07 04:42:47 | INFO | train | epoch 199 | loss 1.907 | ppl 3.75 | wps 21562.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9681 | lr 0.000321396 | gnorm 0.574 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 28809
2022-03-07 04:42:47 | INFO | fairseq.trainer | begin training epoch 200
2022-03-07 04:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:43:42 | INFO | train_inner | epoch 200:     19 / 49 loss=1.908, ppl=3.75, wps=21824.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.576, loss_scale=16, train_wall=263, gb_free=21.5, wall=28863
2022-03-07 04:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:45:12 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 11.732 | ppl 3400.52 | wps 38923.5 | wpb 510.9 | bsz 1 | num_updates 9730 | best_loss 8.723
2022-03-07 04:45:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9730 updates
2022-03-07 04:45:12 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-07 04:45:12 | INFO | train | epoch 200 | loss 1.905 | ppl 3.74 | wps 22018.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9730 | lr 0.000320585 | gnorm 0.581 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 28953
2022-03-07 04:45:12 | INFO | fairseq.trainer | begin training epoch 201
2022-03-07 04:45:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:47:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:47:36 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 11.707 | ppl 3343.37 | wps 38985.2 | wpb 510.9 | bsz 1 | num_updates 9779 | best_loss 8.723
2022-03-07 04:47:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9779 updates
2022-03-07 04:47:36 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-07 04:47:36 | INFO | train | epoch 201 | loss 1.901 | ppl 3.73 | wps 22033 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9779 | lr 0.000319781 | gnorm 0.568 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 29098
2022-03-07 04:47:36 | INFO | fairseq.trainer | begin training epoch 202
2022-03-07 04:47:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:48:36 | INFO | train_inner | epoch 202:     21 / 49 loss=1.902, ppl=3.74, wps=22038.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.569, loss_scale=32, train_wall=260, gb_free=21.5, wall=29158
2022-03-07 04:49:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:50:00 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 11.68 | ppl 3281.52 | wps 38889.3 | wpb 510.9 | bsz 1 | num_updates 9828 | best_loss 8.723
2022-03-07 04:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9828 updates
2022-03-07 04:50:00 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-07 04:50:00 | INFO | train | epoch 202 | loss 1.898 | ppl 3.73 | wps 22006.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9828 | lr 0.000318983 | gnorm 0.56 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 29242
2022-03-07 04:50:00 | INFO | fairseq.trainer | begin training epoch 203
2022-03-07 04:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:51:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:52:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:52:25 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 11.622 | ppl 3151.92 | wps 38985.2 | wpb 510.9 | bsz 1 | num_updates 9876 | best_loss 8.723
2022-03-07 04:52:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9876 updates
2022-03-07 04:52:25 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-07 04:52:25 | INFO | train | epoch 203 | loss 1.895 | ppl 3.72 | wps 21565.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 9876 | lr 0.000318207 | gnorm 0.564 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 29386
2022-03-07 04:52:25 | INFO | fairseq.trainer | begin training epoch 204
2022-03-07 04:52:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:53:33 | INFO | train_inner | epoch 204:     24 / 49 loss=1.895, ppl=3.72, wps=21821.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.56, loss_scale=16, train_wall=263, gb_free=21.5, wall=29455
2022-03-07 04:54:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:54:49 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 11.683 | ppl 3287.52 | wps 39014.4 | wpb 510.9 | bsz 1 | num_updates 9925 | best_loss 8.723
2022-03-07 04:54:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9925 updates
2022-03-07 04:54:49 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-07 04:54:49 | INFO | train | epoch 204 | loss 1.891 | ppl 3.71 | wps 22034.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9925 | lr 0.00031742 | gnorm 0.559 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 29531
2022-03-07 04:54:49 | INFO | fairseq.trainer | begin training epoch 205
2022-03-07 04:54:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:57:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:57:13 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 11.69 | ppl 3305.07 | wps 38906.3 | wpb 510.9 | bsz 1 | num_updates 9974 | best_loss 8.723
2022-03-07 04:57:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9974 updates
2022-03-07 04:57:13 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-07 04:57:13 | INFO | train | epoch 205 | loss 1.889 | ppl 3.7 | wps 22008.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9974 | lr 0.00031664 | gnorm 0.558 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 29675
2022-03-07 04:57:13 | INFO | fairseq.trainer | begin training epoch 206
2022-03-07 04:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:58:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:58:30 | INFO | train_inner | epoch 206:     27 / 49 loss=1.889, ppl=3.7, wps=21830.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.563, loss_scale=16, train_wall=263, gb_free=21.5, wall=29752
2022-03-07 04:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:59:38 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 11.717 | ppl 3367.52 | wps 39055.2 | wpb 510.9 | bsz 1 | num_updates 10022 | best_loss 8.723
2022-03-07 04:59:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10022 updates
2022-03-07 04:59:38 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-07 04:59:38 | INFO | train | epoch 206 | loss 1.886 | ppl 3.7 | wps 21565.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10022 | lr 0.00031588 | gnorm 0.564 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 29819
2022-03-07 04:59:38 | INFO | fairseq.trainer | begin training epoch 207
2022-03-07 04:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:01:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:02:02 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 11.682 | ppl 3286.27 | wps 38989.7 | wpb 510.9 | bsz 1 | num_updates 10071 | best_loss 8.723
2022-03-07 05:02:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10071 updates
2022-03-07 05:02:02 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-07 05:02:02 | INFO | train | epoch 207 | loss 1.884 | ppl 3.69 | wps 22012.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10071 | lr 0.000315111 | gnorm 0.561 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 29964
2022-03-07 05:02:02 | INFO | fairseq.trainer | begin training epoch 208
2022-03-07 05:02:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:03:25 | INFO | train_inner | epoch 208:     29 / 49 loss=1.884, ppl=3.69, wps=22031, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.559, loss_scale=16, train_wall=260, gb_free=21.5, wall=30047
2022-03-07 05:04:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:04:26 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 11.659 | ppl 3234.66 | wps 38904.7 | wpb 510.9 | bsz 1 | num_updates 10120 | best_loss 8.723
2022-03-07 05:04:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10120 updates
2022-03-07 05:04:26 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-07 05:04:26 | INFO | train | epoch 208 | loss 1.881 | ppl 3.68 | wps 22018.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10120 | lr 0.000314347 | gnorm 0.551 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 30108
2022-03-07 05:04:26 | INFO | fairseq.trainer | begin training epoch 209
2022-03-07 05:04:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:06:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:06:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:06:51 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 11.699 | ppl 3324.35 | wps 39036.9 | wpb 510.9 | bsz 1 | num_updates 10168 | best_loss 8.723
2022-03-07 05:06:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10168 updates
2022-03-07 05:06:51 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-07 05:06:51 | INFO | train | epoch 209 | loss 1.877 | ppl 3.67 | wps 21560.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10168 | lr 0.000313604 | gnorm 0.548 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 30252
2022-03-07 05:06:51 | INFO | fairseq.trainer | begin training epoch 210
2022-03-07 05:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:08:22 | INFO | train_inner | epoch 210:     32 / 49 loss=1.877, ppl=3.67, wps=21821.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.548, loss_scale=16, train_wall=263, gb_free=21.5, wall=30344
2022-03-07 05:09:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:09:15 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 11.632 | ppl 3173.88 | wps 39055.5 | wpb 510.9 | bsz 1 | num_updates 10217 | best_loss 8.723
2022-03-07 05:09:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10217 updates
2022-03-07 05:09:15 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-07 05:09:15 | INFO | train | epoch 210 | loss 1.875 | ppl 3.67 | wps 22018.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10217 | lr 0.000312852 | gnorm 0.548 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 30397
2022-03-07 05:09:15 | INFO | fairseq.trainer | begin training epoch 211
2022-03-07 05:09:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:11:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:11:39 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 11.636 | ppl 3182.71 | wps 38987.6 | wpb 510.9 | bsz 1 | num_updates 10266 | best_loss 8.723
2022-03-07 05:11:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10266 updates
2022-03-07 05:11:39 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-07 05:11:39 | INFO | train | epoch 211 | loss 1.872 | ppl 3.66 | wps 22037.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10266 | lr 0.000312104 | gnorm 0.546 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 30541
2022-03-07 05:11:39 | INFO | fairseq.trainer | begin training epoch 212
2022-03-07 05:11:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:12:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:13:19 | INFO | train_inner | epoch 212:     35 / 49 loss=1.872, ppl=3.66, wps=21833.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.544, loss_scale=16, train_wall=263, gb_free=21.5, wall=30641
2022-03-07 05:13:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:14:03 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 11.702 | ppl 3332.34 | wps 38863.3 | wpb 510.9 | bsz 1 | num_updates 10314 | best_loss 8.723
2022-03-07 05:14:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10314 updates
2022-03-07 05:14:03 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-07 05:14:03 | INFO | train | epoch 212 | loss 1.869 | ppl 3.65 | wps 21559.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10314 | lr 0.000311377 | gnorm 0.544 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 30685
2022-03-07 05:14:04 | INFO | fairseq.trainer | begin training epoch 213
2022-03-07 05:14:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:16:28 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 11.676 | ppl 3271.22 | wps 38885.3 | wpb 510.9 | bsz 1 | num_updates 10363 | best_loss 8.723
2022-03-07 05:16:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10363 updates
2022-03-07 05:16:28 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-07 05:16:28 | INFO | train | epoch 213 | loss 1.868 | ppl 3.65 | wps 21995.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10363 | lr 0.00031064 | gnorm 0.558 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 30830
2022-03-07 05:16:28 | INFO | fairseq.trainer | begin training epoch 214
2022-03-07 05:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:18:14 | INFO | train_inner | epoch 214:     37 / 49 loss=1.867, ppl=3.65, wps=22023.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.551, loss_scale=16, train_wall=260, gb_free=21.5, wall=30936
2022-03-07 05:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:18:52 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 11.617 | ppl 3141.25 | wps 38971.4 | wpb 510.9 | bsz 1 | num_updates 10412 | best_loss 8.723
2022-03-07 05:18:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10412 updates
2022-03-07 05:18:52 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-07 05:18:52 | INFO | train | epoch 214 | loss 1.865 | ppl 3.64 | wps 22017.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10412 | lr 0.000309908 | gnorm 0.542 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 30974
2022-03-07 05:18:52 | INFO | fairseq.trainer | begin training epoch 215
2022-03-07 05:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:21:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:21:17 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 11.656 | ppl 3227.62 | wps 38863.2 | wpb 510.9 | bsz 1 | num_updates 10461 | best_loss 8.723
2022-03-07 05:21:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10461 updates
2022-03-07 05:21:17 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-07 05:21:17 | INFO | train | epoch 215 | loss 1.861 | ppl 3.63 | wps 22014.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10461 | lr 0.000309181 | gnorm 0.533 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 31118
2022-03-07 05:21:17 | INFO | fairseq.trainer | begin training epoch 216
2022-03-07 05:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:21:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:23:11 | INFO | train_inner | epoch 216:     40 / 49 loss=1.861, ppl=3.63, wps=21814.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.531, loss_scale=16, train_wall=263, gb_free=21.5, wall=31233
2022-03-07 05:23:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:23:41 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 11.571 | ppl 3041.54 | wps 38925.4 | wpb 510.9 | bsz 1 | num_updates 10509 | best_loss 8.723
2022-03-07 05:23:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10509 updates
2022-03-07 05:23:41 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-07 05:23:41 | INFO | train | epoch 216 | loss 1.859 | ppl 3.63 | wps 21546.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10509 | lr 0.000308475 | gnorm 0.531 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 31263
2022-03-07 05:23:41 | INFO | fairseq.trainer | begin training epoch 217
2022-03-07 05:23:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:26:06 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 11.696 | ppl 3317.09 | wps 38784.9 | wpb 510.9 | bsz 1 | num_updates 10558 | best_loss 8.723
2022-03-07 05:26:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10558 updates
2022-03-07 05:26:06 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-07 05:26:06 | INFO | train | epoch 217 | loss 1.857 | ppl 3.62 | wps 22002 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10558 | lr 0.000307758 | gnorm 0.536 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 31407
2022-03-07 05:26:06 | INFO | fairseq.trainer | begin training epoch 218
2022-03-07 05:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:28:06 | INFO | train_inner | epoch 218:     42 / 49 loss=1.856, ppl=3.62, wps=22020.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.535, loss_scale=32, train_wall=260, gb_free=21.5, wall=31528
2022-03-07 05:28:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:28:30 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 11.666 | ppl 3248.9 | wps 38942.2 | wpb 510.9 | bsz 1 | num_updates 10607 | best_loss 8.723
2022-03-07 05:28:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10607 updates
2022-03-07 05:28:30 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-07 05:28:30 | INFO | train | epoch 218 | loss 1.854 | ppl 3.61 | wps 22011.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10607 | lr 0.000307046 | gnorm 0.532 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 31552
2022-03-07 05:28:30 | INFO | fairseq.trainer | begin training epoch 219
2022-03-07 05:28:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:30:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:30:54 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 11.64 | ppl 3192.16 | wps 38849.9 | wpb 510.9 | bsz 1 | num_updates 10656 | best_loss 8.723
2022-03-07 05:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10656 updates
2022-03-07 05:30:54 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-07 05:30:54 | INFO | train | epoch 219 | loss 1.853 | ppl 3.61 | wps 22012.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10656 | lr 0.000306339 | gnorm 0.538 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 31696
2022-03-07 05:30:54 | INFO | fairseq.trainer | begin training epoch 220
2022-03-07 05:30:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:33:00 | INFO | train_inner | epoch 220:     44 / 49 loss=1.853, ppl=3.61, wps=22038.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.537, loss_scale=32, train_wall=260, gb_free=21.5, wall=31822
2022-03-07 05:33:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:33:19 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 11.613 | ppl 3131.92 | wps 38903.8 | wpb 510.9 | bsz 1 | num_updates 10705 | best_loss 8.723
2022-03-07 05:33:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10705 updates
2022-03-07 05:33:19 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-07 05:33:19 | INFO | train | epoch 220 | loss 1.851 | ppl 3.61 | wps 22021.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10705 | lr 0.000305638 | gnorm 0.533 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 31840
2022-03-07 05:33:19 | INFO | fairseq.trainer | begin training epoch 221
2022-03-07 05:33:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:34:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:35:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:35:43 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 11.59 | ppl 3082.23 | wps 38957.1 | wpb 510.9 | bsz 1 | num_updates 10753 | best_loss 8.723
2022-03-07 05:35:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10753 updates
2022-03-07 05:35:43 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-07 05:35:43 | INFO | train | epoch 221 | loss 1.847 | ppl 3.6 | wps 21551.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10753 | lr 0.000304955 | gnorm 0.534 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 31985
2022-03-07 05:35:43 | INFO | fairseq.trainer | begin training epoch 222
2022-03-07 05:35:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:37:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:38:00 | INFO | train_inner | epoch 222:     48 / 49 loss=1.846, ppl=3.6, wps=21609.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.539, loss_scale=16, train_wall=266, gb_free=21.5, wall=32122
2022-03-07 05:38:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:38:07 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 11.652 | ppl 3218.1 | wps 39185.4 | wpb 510.9 | bsz 1 | num_updates 10801 | best_loss 8.723
2022-03-07 05:38:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10801 updates
2022-03-07 05:38:07 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-07 05:38:07 | INFO | train | epoch 222 | loss 1.845 | ppl 3.59 | wps 21568.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10801 | lr 0.000304276 | gnorm 0.545 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 32129
2022-03-07 05:38:07 | INFO | fairseq.trainer | begin training epoch 223
2022-03-07 05:38:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:40:32 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 11.592 | ppl 3087.85 | wps 39088.8 | wpb 510.9 | bsz 1 | num_updates 10850 | best_loss 8.723
2022-03-07 05:40:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10850 updates
2022-03-07 05:40:32 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-07 05:40:32 | INFO | train | epoch 223 | loss 1.842 | ppl 3.58 | wps 22007.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10850 | lr 0.000303588 | gnorm 0.516 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 32274
2022-03-07 05:40:32 | INFO | fairseq.trainer | begin training epoch 224
2022-03-07 05:40:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:42:56 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 11.596 | ppl 3094.81 | wps 39165.3 | wpb 510.9 | bsz 1 | num_updates 10899 | best_loss 8.723
2022-03-07 05:42:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10899 updates
2022-03-07 05:42:56 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-07 05:42:56 | INFO | train | epoch 224 | loss 1.839 | ppl 3.58 | wps 22012.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10899 | lr 0.000302905 | gnorm 0.524 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 32418
2022-03-07 05:42:56 | INFO | fairseq.trainer | begin training epoch 225
2022-03-07 05:42:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:42:59 | INFO | train_inner | epoch 225:      1 / 49 loss=1.84, ppl=3.58, wps=21600.7, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=10900, lr=0.000302891, gnorm=0.522, loss_scale=16, train_wall=259, gb_free=21.5, wall=32421
2022-03-07 05:45:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:45:20 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 11.57 | ppl 3041.3 | wps 39107.2 | wpb 510.9 | bsz 1 | num_updates 10948 | best_loss 8.723
2022-03-07 05:45:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10948 updates
2022-03-07 05:45:20 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-07 05:45:20 | INFO | train | epoch 225 | loss 1.838 | ppl 3.57 | wps 22025.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10948 | lr 0.000302227 | gnorm 0.52 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 32562
2022-03-07 05:45:20 | INFO | fairseq.trainer | begin training epoch 226
2022-03-07 05:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:47:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:47:45 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 11.578 | ppl 3058.17 | wps 38926 | wpb 510.9 | bsz 1 | num_updates 10997 | best_loss 8.723
2022-03-07 05:47:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 10997 updates
2022-03-07 05:47:45 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-07 05:47:45 | INFO | train | epoch 226 | loss 1.836 | ppl 3.57 | wps 22028.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10997 | lr 0.000301552 | gnorm 0.523 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 32706
2022-03-07 05:47:45 | INFO | fairseq.trainer | begin training epoch 227
2022-03-07 05:47:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:47:53 | INFO | train_inner | epoch 227:      3 / 49 loss=1.836, ppl=3.57, wps=22044.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11000, lr=0.000301511, gnorm=0.521, loss_scale=32, train_wall=260, gb_free=21.5, wall=32715
2022-03-07 05:48:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:50:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:50:09 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 11.606 | ppl 3116.36 | wps 38727.9 | wpb 510.9 | bsz 1 | num_updates 11045 | best_loss 8.723
2022-03-07 05:50:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11045 updates
2022-03-07 05:50:09 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-07 05:50:09 | INFO | train | epoch 227 | loss 1.834 | ppl 3.57 | wps 21568.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11045 | lr 0.000300897 | gnorm 0.527 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 32851
2022-03-07 05:50:09 | INFO | fairseq.trainer | begin training epoch 228
2022-03-07 05:50:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:52:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:52:34 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 11.556 | ppl 3010.51 | wps 38810.2 | wpb 510.9 | bsz 1 | num_updates 11094 | best_loss 8.723
2022-03-07 05:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11094 updates
2022-03-07 05:52:34 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-07 05:52:34 | INFO | train | epoch 228 | loss 1.831 | ppl 3.56 | wps 21998.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11094 | lr 0.000300231 | gnorm 0.51 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 32995
2022-03-07 05:52:34 | INFO | fairseq.trainer | begin training epoch 229
2022-03-07 05:52:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:52:51 | INFO | train_inner | epoch 229:      6 / 49 loss=1.832, ppl=3.56, wps=21815.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.519, loss_scale=16, train_wall=263, gb_free=21.5, wall=33013
2022-03-07 05:54:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:54:58 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 11.619 | ppl 3145.34 | wps 38826 | wpb 510.9 | bsz 1 | num_updates 11142 | best_loss 8.723
2022-03-07 05:54:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11142 updates
2022-03-07 05:54:58 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-07 05:54:58 | INFO | train | epoch 229 | loss 1.829 | ppl 3.55 | wps 21547.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11142 | lr 0.000299584 | gnorm 0.523 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 33140
2022-03-07 05:54:58 | INFO | fairseq.trainer | begin training epoch 230
2022-03-07 05:54:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:57:22 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 11.599 | ppl 3101.5 | wps 38701.9 | wpb 510.9 | bsz 1 | num_updates 11191 | best_loss 8.723
2022-03-07 05:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11191 updates
2022-03-07 05:57:22 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-07 05:57:22 | INFO | train | epoch 230 | loss 1.826 | ppl 3.55 | wps 22037.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11191 | lr 0.000298927 | gnorm 0.51 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 33284
2022-03-07 05:57:22 | INFO | fairseq.trainer | begin training epoch 231
2022-03-07 05:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:57:48 | INFO | train_inner | epoch 231:      9 / 49 loss=1.826, ppl=3.55, wps=21827.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.516, loss_scale=16, train_wall=263, gb_free=21.5, wall=33310
2022-03-07 05:59:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:59:47 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 11.63 | ppl 3169.02 | wps 38905.4 | wpb 510.9 | bsz 1 | num_updates 11240 | best_loss 8.723
2022-03-07 05:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11240 updates
2022-03-07 05:59:47 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-07 05:59:47 | INFO | train | epoch 231 | loss 1.825 | ppl 3.54 | wps 22015.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11240 | lr 0.000298275 | gnorm 0.515 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 33428
2022-03-07 05:59:47 | INFO | fairseq.trainer | begin training epoch 232
2022-03-07 05:59:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:02:11 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 11.619 | ppl 3145.22 | wps 38913.9 | wpb 510.9 | bsz 1 | num_updates 11289 | best_loss 8.723
2022-03-07 06:02:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11289 updates
2022-03-07 06:02:11 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-07 06:02:11 | INFO | train | epoch 232 | loss 1.822 | ppl 3.54 | wps 22004.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11289 | lr 0.000297627 | gnorm 0.499 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 33573
2022-03-07 06:02:11 | INFO | fairseq.trainer | begin training epoch 233
2022-03-07 06:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:02:42 | INFO | train_inner | epoch 233:     11 / 49 loss=1.823, ppl=3.54, wps=22033.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.506, loss_scale=32, train_wall=260, gb_free=21.5, wall=33604
2022-03-07 06:04:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:04:35 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 11.619 | ppl 3144.32 | wps 38792.1 | wpb 510.9 | bsz 1 | num_updates 11338 | best_loss 8.723
2022-03-07 06:04:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11338 updates
2022-03-07 06:04:35 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-07 06:04:35 | INFO | train | epoch 233 | loss 1.822 | ppl 3.54 | wps 22017.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11338 | lr 0.000296983 | gnorm 0.513 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 33717
2022-03-07 06:04:35 | INFO | fairseq.trainer | begin training epoch 234
2022-03-07 06:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:05:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:07:00 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 11.524 | ppl 2943.98 | wps 38763.1 | wpb 510.9 | bsz 1 | num_updates 11386 | best_loss 8.723
2022-03-07 06:07:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11386 updates
2022-03-07 06:07:00 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-07 06:07:00 | INFO | train | epoch 234 | loss 1.818 | ppl 3.53 | wps 21547.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11386 | lr 0.000296356 | gnorm 0.507 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 33862
2022-03-07 06:07:00 | INFO | fairseq.trainer | begin training epoch 235
2022-03-07 06:07:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:07:40 | INFO | train_inner | epoch 235:     14 / 49 loss=1.82, ppl=3.53, wps=21809.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.511, loss_scale=16, train_wall=263, gb_free=21.5, wall=33902
2022-03-07 06:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:09:24 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 11.642 | ppl 3196.79 | wps 38907.3 | wpb 510.9 | bsz 1 | num_updates 11435 | best_loss 8.723
2022-03-07 06:09:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11435 updates
2022-03-07 06:09:24 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-07 06:09:24 | INFO | train | epoch 235 | loss 1.816 | ppl 3.52 | wps 22018.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11435 | lr 0.000295721 | gnorm 0.5 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 34006
2022-03-07 06:09:24 | INFO | fairseq.trainer | begin training epoch 236
2022-03-07 06:09:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:11:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:11:49 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 11.51 | ppl 2916.2 | wps 38905.9 | wpb 510.9 | bsz 1 | num_updates 11484 | best_loss 8.723
2022-03-07 06:11:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11484 updates
2022-03-07 06:11:49 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-07 06:11:49 | INFO | train | epoch 236 | loss 1.814 | ppl 3.52 | wps 22001.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11484 | lr 0.000295089 | gnorm 0.511 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 34150
2022-03-07 06:11:49 | INFO | fairseq.trainer | begin training epoch 237
2022-03-07 06:11:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:12:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:12:37 | INFO | train_inner | epoch 237:     17 / 49 loss=1.815, ppl=3.52, wps=21815.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.505, loss_scale=16, train_wall=263, gb_free=21.5, wall=34199
2022-03-07 06:14:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:14:13 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 11.534 | ppl 2965.02 | wps 39002.4 | wpb 510.9 | bsz 1 | num_updates 11532 | best_loss 8.723
2022-03-07 06:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11532 updates
2022-03-07 06:14:13 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-07 06:14:13 | INFO | train | epoch 237 | loss 1.812 | ppl 3.51 | wps 21549.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11532 | lr 0.000294474 | gnorm 0.5 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 34295
2022-03-07 06:14:13 | INFO | fairseq.trainer | begin training epoch 238
2022-03-07 06:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:16:37 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 11.604 | ppl 3111.73 | wps 38882.5 | wpb 510.9 | bsz 1 | num_updates 11581 | best_loss 8.723
2022-03-07 06:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11581 updates
2022-03-07 06:16:37 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-07 06:16:37 | INFO | train | epoch 238 | loss 1.811 | ppl 3.51 | wps 22017 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11581 | lr 0.000293851 | gnorm 0.505 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 34439
2022-03-07 06:16:37 | INFO | fairseq.trainer | begin training epoch 239
2022-03-07 06:16:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:17:32 | INFO | train_inner | epoch 239:     19 / 49 loss=1.811, ppl=3.51, wps=22024.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.504, loss_scale=16, train_wall=260, gb_free=21.5, wall=34494
2022-03-07 06:18:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:19:02 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 11.583 | ppl 3067.82 | wps 39067 | wpb 510.9 | bsz 1 | num_updates 11630 | best_loss 8.723
2022-03-07 06:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11630 updates
2022-03-07 06:19:02 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 06:19:02 | INFO | train | epoch 239 | loss 1.808 | ppl 3.5 | wps 22014.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11630 | lr 0.000293231 | gnorm 0.506 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 34583
2022-03-07 06:19:02 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 06:19:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:20:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:21:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:21:26 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 11.547 | ppl 2991.56 | wps 38959.3 | wpb 510.9 | bsz 1 | num_updates 11678 | best_loss 8.723
2022-03-07 06:21:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11678 updates
2022-03-07 06:21:26 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 06:21:26 | INFO | train | epoch 240 | loss 1.806 | ppl 3.5 | wps 21571.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11678 | lr 0.000292628 | gnorm 0.502 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 34728
2022-03-07 06:21:26 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 06:21:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:22:29 | INFO | train_inner | epoch 241:     22 / 49 loss=1.807, ppl=3.5, wps=21828, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.5, loss_scale=16, train_wall=263, gb_free=21.5, wall=34791
2022-03-07 06:23:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:23:50 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 11.538 | ppl 2974.1 | wps 38853.1 | wpb 510.9 | bsz 1 | num_updates 11727 | best_loss 8.723
2022-03-07 06:23:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11727 updates
2022-03-07 06:23:50 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 06:23:50 | INFO | train | epoch 241 | loss 1.805 | ppl 3.5 | wps 22004.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11727 | lr 0.000292016 | gnorm 0.499 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 34872
2022-03-07 06:23:50 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 06:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:26:15 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 11.603 | ppl 3109.72 | wps 39051.6 | wpb 510.9 | bsz 1 | num_updates 11776 | best_loss 8.723
2022-03-07 06:26:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11776 updates
2022-03-07 06:26:15 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 06:26:15 | INFO | train | epoch 242 | loss 1.803 | ppl 3.49 | wps 22025.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11776 | lr 0.000291408 | gnorm 0.495 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 35016
2022-03-07 06:26:15 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 06:26:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:27:23 | INFO | train_inner | epoch 243:     24 / 49 loss=1.803, ppl=3.49, wps=22032.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.499, loss_scale=32, train_wall=260, gb_free=21.5, wall=35085
2022-03-07 06:28:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:28:39 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 11.531 | ppl 2959.59 | wps 39150.6 | wpb 510.9 | bsz 1 | num_updates 11825 | best_loss 8.723
2022-03-07 06:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11825 updates
2022-03-07 06:28:39 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 06:28:39 | INFO | train | epoch 243 | loss 1.802 | ppl 3.49 | wps 22023.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11825 | lr 0.000290803 | gnorm 0.502 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 35161
2022-03-07 06:28:39 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 06:28:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:30:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:31:03 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 11.548 | ppl 2993.93 | wps 39024.7 | wpb 510.9 | bsz 1 | num_updates 11873 | best_loss 8.723
2022-03-07 06:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11873 updates
2022-03-07 06:31:03 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 06:31:03 | INFO | train | epoch 244 | loss 1.799 | ppl 3.48 | wps 21566.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 11873 | lr 0.000290215 | gnorm 0.5 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 35305
2022-03-07 06:31:03 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 06:31:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:32:21 | INFO | train_inner | epoch 245:     27 / 49 loss=1.799, ppl=3.48, wps=21824, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.498, loss_scale=16, train_wall=263, gb_free=21.5, wall=35382
2022-03-07 06:33:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:33:28 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 11.563 | ppl 3025.08 | wps 38954.2 | wpb 510.9 | bsz 1 | num_updates 11922 | best_loss 8.723
2022-03-07 06:33:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11922 updates
2022-03-07 06:33:28 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 06:33:28 | INFO | train | epoch 245 | loss 1.796 | ppl 3.47 | wps 22008.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11922 | lr 0.000289618 | gnorm 0.493 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 35449
2022-03-07 06:33:28 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 06:33:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:35:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:35:52 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 11.572 | ppl 3043.73 | wps 39704.5 | wpb 510.9 | bsz 1 | num_updates 11971 | best_loss 8.723
2022-03-07 06:35:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11971 updates
2022-03-07 06:35:52 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 06:35:52 | INFO | train | epoch 246 | loss 1.796 | ppl 3.47 | wps 22031.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11971 | lr 0.000289025 | gnorm 0.5 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 35594
2022-03-07 06:35:52 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 06:35:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:37:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:37:18 | INFO | train_inner | epoch 247:     30 / 49 loss=1.795, ppl=3.47, wps=21833.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.497, loss_scale=16, train_wall=263, gb_free=21.5, wall=35679
2022-03-07 06:38:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:38:16 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 11.543 | ppl 2983.44 | wps 39202.2 | wpb 510.9 | bsz 1 | num_updates 12019 | best_loss 8.723
2022-03-07 06:38:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12019 updates
2022-03-07 06:38:16 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 06:38:16 | INFO | train | epoch 247 | loss 1.793 | ppl 3.47 | wps 21570.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12019 | lr 0.000288447 | gnorm 0.494 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 35738
2022-03-07 06:38:16 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 06:38:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:40:41 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 11.502 | ppl 2900.03 | wps 38898.8 | wpb 510.9 | bsz 1 | num_updates 12068 | best_loss 8.723
2022-03-07 06:40:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12068 updates
2022-03-07 06:40:41 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 06:40:41 | INFO | train | epoch 248 | loss 1.791 | ppl 3.46 | wps 22001.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12068 | lr 0.000287861 | gnorm 0.482 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 35882
2022-03-07 06:40:41 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 06:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:42:12 | INFO | train_inner | epoch 249:     32 / 49 loss=1.791, ppl=3.46, wps=22020.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.486, loss_scale=16, train_wall=260, gb_free=21.5, wall=35974
2022-03-07 06:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:43:05 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 11.548 | ppl 2994.4 | wps 38720.1 | wpb 510.9 | bsz 1 | num_updates 12117 | best_loss 8.723
2022-03-07 06:43:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12117 updates
2022-03-07 06:43:05 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 06:43:05 | INFO | train | epoch 249 | loss 1.79 | ppl 3.46 | wps 21990.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12117 | lr 0.000287278 | gnorm 0.485 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 36027
2022-03-07 06:43:05 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 06:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:44:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:45:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:45:29 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 11.544 | ppl 2986.56 | wps 38978.4 | wpb 510.9 | bsz 1 | num_updates 12165 | best_loss 8.723
2022-03-07 06:45:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12165 updates
2022-03-07 06:45:29 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 06:45:29 | INFO | train | epoch 250 | loss 1.789 | ppl 3.46 | wps 21578 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12165 | lr 0.000286711 | gnorm 0.494 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 36171
2022-03-07 06:45:30 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 06:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:47:10 | INFO | train_inner | epoch 251:     35 / 49 loss=1.789, ppl=3.46, wps=21821.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.491, loss_scale=16, train_wall=263, gb_free=21.5, wall=36271
2022-03-07 06:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:47:54 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 11.551 | ppl 3000.95 | wps 38959.7 | wpb 510.9 | bsz 1 | num_updates 12214 | best_loss 8.723
2022-03-07 06:47:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12214 updates
2022-03-07 06:47:54 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 06:47:54 | INFO | train | epoch 251 | loss 1.787 | ppl 3.45 | wps 22004.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12214 | lr 0.000286135 | gnorm 0.489 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 36316
2022-03-07 06:47:54 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 06:47:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:50:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:50:18 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 11.535 | ppl 2966.45 | wps 38965.3 | wpb 510.9 | bsz 1 | num_updates 12263 | best_loss 8.723
2022-03-07 06:50:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12263 updates
2022-03-07 06:50:18 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 06:50:18 | INFO | train | epoch 252 | loss 1.785 | ppl 3.45 | wps 22002.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12263 | lr 0.000285563 | gnorm 0.488 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 36460
2022-03-07 06:50:18 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 06:50:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:51:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:52:07 | INFO | train_inner | epoch 253:     38 / 49 loss=1.785, ppl=3.45, wps=21814.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.491, loss_scale=16, train_wall=263, gb_free=21.5, wall=36569
2022-03-07 06:52:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:52:43 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 11.501 | ppl 2897.4 | wps 39318.7 | wpb 510.9 | bsz 1 | num_updates 12311 | best_loss 8.723
2022-03-07 06:52:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12311 updates
2022-03-07 06:52:43 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 06:52:43 | INFO | train | epoch 253 | loss 1.784 | ppl 3.44 | wps 21573.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12311 | lr 0.000285006 | gnorm 0.492 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 36604
2022-03-07 06:52:43 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 06:52:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:55:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:55:07 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 11.547 | ppl 2993.16 | wps 39066.4 | wpb 510.9 | bsz 1 | num_updates 12360 | best_loss 8.723
2022-03-07 06:55:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12360 updates
2022-03-07 06:55:07 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 06:55:07 | INFO | train | epoch 254 | loss 1.781 | ppl 3.44 | wps 22000.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12360 | lr 0.00028444 | gnorm 0.476 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 36749
2022-03-07 06:55:07 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 06:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:57:01 | INFO | train_inner | epoch 255:     40 / 49 loss=1.781, ppl=3.44, wps=22036.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.478, loss_scale=16, train_wall=260, gb_free=21.5, wall=36863
2022-03-07 06:57:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:57:31 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 11.548 | ppl 2994.49 | wps 38878 | wpb 510.9 | bsz 1 | num_updates 12409 | best_loss 8.723
2022-03-07 06:57:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12409 updates
2022-03-07 06:57:31 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 06:57:31 | INFO | train | epoch 255 | loss 1.78 | ppl 3.44 | wps 22021.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12409 | lr 0.000283878 | gnorm 0.479 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 36893
2022-03-07 06:57:31 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 06:57:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:57:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:59:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:59:56 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 11.588 | ppl 3079.16 | wps 39076.9 | wpb 510.9 | bsz 1 | num_updates 12457 | best_loss 8.723
2022-03-07 06:59:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12457 updates
2022-03-07 06:59:56 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 06:59:56 | INFO | train | epoch 256 | loss 1.779 | ppl 3.43 | wps 21565.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12457 | lr 0.00028333 | gnorm 0.485 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 37037
2022-03-07 06:59:56 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 06:59:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:01:59 | INFO | train_inner | epoch 257:     43 / 49 loss=1.779, ppl=3.43, wps=21817.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.481, loss_scale=16, train_wall=263, gb_free=21.5, wall=37160
2022-03-07 07:02:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:02:20 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 11.506 | ppl 2908.42 | wps 38980 | wpb 510.9 | bsz 1 | num_updates 12506 | best_loss 8.723
2022-03-07 07:02:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12506 updates
2022-03-07 07:02:20 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 07:02:20 | INFO | train | epoch 257 | loss 1.778 | ppl 3.43 | wps 22009.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12506 | lr 0.000282775 | gnorm 0.478 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 37182
2022-03-07 07:02:20 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 07:02:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:04:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:04:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:04:44 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 11.553 | ppl 3005.16 | wps 38847.2 | wpb 510.9 | bsz 1 | num_updates 12554 | best_loss 8.723
2022-03-07 07:04:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12554 updates
2022-03-07 07:04:44 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 07:04:44 | INFO | train | epoch 258 | loss 1.775 | ppl 3.42 | wps 21558.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12554 | lr 0.000282234 | gnorm 0.477 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 37326
2022-03-07 07:04:45 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 07:04:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:06:56 | INFO | train_inner | epoch 259:     46 / 49 loss=1.774, ppl=3.42, wps=21815.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.48, loss_scale=16, train_wall=263, gb_free=21.5, wall=37458
2022-03-07 07:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:07:09 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 11.512 | ppl 2920.9 | wps 38731.5 | wpb 510.9 | bsz 1 | num_updates 12603 | best_loss 8.723
2022-03-07 07:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12603 updates
2022-03-07 07:07:09 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 07:07:09 | INFO | train | epoch 259 | loss 1.773 | ppl 3.42 | wps 21999.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12603 | lr 0.000281685 | gnorm 0.482 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 37471
2022-03-07 07:07:09 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 07:07:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:09:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:09:33 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 11.466 | ppl 2829.65 | wps 38420.9 | wpb 510.9 | bsz 1 | num_updates 12652 | best_loss 8.723
2022-03-07 07:09:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12652 updates
2022-03-07 07:09:33 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 07:09:33 | INFO | train | epoch 260 | loss 1.772 | ppl 3.42 | wps 22008.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12652 | lr 0.000281139 | gnorm 0.478 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 37615
2022-03-07 07:09:33 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 07:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:11:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:11:52 | INFO | train_inner | epoch 261:     49 / 49 loss=1.772, ppl=3.41, wps=21810.5, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=12700, lr=0.000280607, gnorm=0.477, loss_scale=16, train_wall=262, gb_free=21.5, wall=37754
2022-03-07 07:11:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:11:58 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 11.552 | ppl 3002.6 | wps 38911.2 | wpb 510.9 | bsz 1 | num_updates 12700 | best_loss 8.723
2022-03-07 07:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12700 updates
2022-03-07 07:11:58 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 07:11:58 | INFO | train | epoch 261 | loss 1.77 | ppl 3.41 | wps 21566.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12700 | lr 0.000280607 | gnorm 0.473 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 37759
2022-03-07 07:11:58 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 07:11:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:14:22 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 11.575 | ppl 3051.27 | wps 39039.1 | wpb 510.9 | bsz 1 | num_updates 12749 | best_loss 8.723
2022-03-07 07:14:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12749 updates
2022-03-07 07:14:22 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 07:14:22 | INFO | train | epoch 262 | loss 1.769 | ppl 3.41 | wps 21998.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12749 | lr 0.000280067 | gnorm 0.469 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 37904
2022-03-07 07:14:22 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 07:14:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:16:47 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 11.513 | ppl 2921.88 | wps 38880.4 | wpb 510.9 | bsz 1 | num_updates 12798 | best_loss 8.723
2022-03-07 07:16:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12798 updates
2022-03-07 07:16:47 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 07:16:47 | INFO | train | epoch 263 | loss 1.768 | ppl 3.41 | wps 22013.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12798 | lr 0.00027953 | gnorm 0.479 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 38048
2022-03-07 07:16:47 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 07:16:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:16:52 | INFO | train_inner | epoch 264:      2 / 49 loss=1.768, ppl=3.41, wps=21603.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.474, loss_scale=16, train_wall=260, gb_free=21.5, wall=38054
2022-03-07 07:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:19:11 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 11.531 | ppl 2958.33 | wps 39114.1 | wpb 510.9 | bsz 1 | num_updates 12847 | best_loss 8.723
2022-03-07 07:19:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12847 updates
2022-03-07 07:19:11 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 07:19:11 | INFO | train | epoch 264 | loss 1.767 | ppl 3.4 | wps 22019 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12847 | lr 0.000278997 | gnorm 0.472 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 38193
2022-03-07 07:19:11 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 07:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:19:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:21:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:21:35 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 11.528 | ppl 2952.23 | wps 38930.5 | wpb 510.9 | bsz 1 | num_updates 12895 | best_loss 8.723
2022-03-07 07:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12895 updates
2022-03-07 07:21:35 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 07:21:35 | INFO | train | epoch 265 | loss 1.764 | ppl 3.4 | wps 21549.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12895 | lr 0.000278477 | gnorm 0.475 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 38337
2022-03-07 07:21:35 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 07:21:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:21:50 | INFO | train_inner | epoch 266:      5 / 49 loss=1.765, ppl=3.4, wps=21817.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=12900, lr=0.000278423, gnorm=0.474, loss_scale=16, train_wall=263, gb_free=21.5, wall=38351
2022-03-07 07:23:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:24:00 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 11.517 | ppl 2930.48 | wps 38909 | wpb 510.9 | bsz 1 | num_updates 12944 | best_loss 8.723
2022-03-07 07:24:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12944 updates
2022-03-07 07:24:00 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 07:24:00 | INFO | train | epoch 266 | loss 1.763 | ppl 3.39 | wps 22030.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12944 | lr 0.000277949 | gnorm 0.475 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 38481
2022-03-07 07:24:00 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 07:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:26:24 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 11.512 | ppl 2921.43 | wps 38952.2 | wpb 510.9 | bsz 1 | num_updates 12993 | best_loss 8.723
2022-03-07 07:26:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12993 updates
2022-03-07 07:26:24 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 07:26:24 | INFO | train | epoch 267 | loss 1.761 | ppl 3.39 | wps 22003.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12993 | lr 0.000277425 | gnorm 0.465 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 38626
2022-03-07 07:26:24 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 07:26:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:26:44 | INFO | train_inner | epoch 268:      7 / 49 loss=1.762, ppl=3.39, wps=22034.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.468, loss_scale=32, train_wall=260, gb_free=21.5, wall=38646
2022-03-07 07:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:28:48 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 11.545 | ppl 2988.87 | wps 38768.3 | wpb 510.9 | bsz 1 | num_updates 13042 | best_loss 8.723
2022-03-07 07:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13042 updates
2022-03-07 07:28:48 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 07:28:48 | INFO | train | epoch 268 | loss 1.761 | ppl 3.39 | wps 21989.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13042 | lr 0.000276903 | gnorm 0.466 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 38770
2022-03-07 07:28:49 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 07:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:30:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:31:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:31:13 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 11.509 | ppl 2914.11 | wps 39016.8 | wpb 510.9 | bsz 1 | num_updates 13090 | best_loss 8.723
2022-03-07 07:31:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13090 updates
2022-03-07 07:31:13 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 07:31:13 | INFO | train | epoch 269 | loss 1.758 | ppl 3.38 | wps 21552.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13090 | lr 0.000276395 | gnorm 0.466 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 38915
2022-03-07 07:31:13 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 07:31:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:31:42 | INFO | train_inner | epoch 270:     10 / 49 loss=1.76, ppl=3.39, wps=21800.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.467, loss_scale=16, train_wall=263, gb_free=21.5, wall=38943
2022-03-07 07:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:33:37 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 11.507 | ppl 2910.79 | wps 38986.7 | wpb 510.9 | bsz 1 | num_updates 13139 | best_loss 8.723
2022-03-07 07:33:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13139 updates
2022-03-07 07:33:37 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 07:33:37 | INFO | train | epoch 270 | loss 1.758 | ppl 3.38 | wps 22006.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13139 | lr 0.000275879 | gnorm 0.466 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 39059
2022-03-07 07:33:37 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 07:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:35:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:36:02 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 11.541 | ppl 2979.96 | wps 38974 | wpb 510.9 | bsz 1 | num_updates 13188 | best_loss 8.723
2022-03-07 07:36:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13188 updates
2022-03-07 07:36:02 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 07:36:02 | INFO | train | epoch 271 | loss 1.757 | ppl 3.38 | wps 22025.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13188 | lr 0.000275366 | gnorm 0.472 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 39203
2022-03-07 07:36:02 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 07:36:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:36:36 | INFO | train_inner | epoch 272:     12 / 49 loss=1.757, ppl=3.38, wps=22035.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.47, loss_scale=32, train_wall=260, gb_free=21.5, wall=39238
2022-03-07 07:38:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:38:26 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 11.488 | ppl 2871.51 | wps 39051.3 | wpb 510.9 | bsz 1 | num_updates 13237 | best_loss 8.723
2022-03-07 07:38:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13237 updates
2022-03-07 07:38:26 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 07:38:26 | INFO | train | epoch 272 | loss 1.754 | ppl 3.37 | wps 22009.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13237 | lr 0.000274856 | gnorm 0.47 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 39348
2022-03-07 07:38:26 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 07:38:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:39:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:40:50 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 11.466 | ppl 2827.95 | wps 38937.2 | wpb 510.9 | bsz 1 | num_updates 13285 | best_loss 8.723
2022-03-07 07:40:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13285 updates
2022-03-07 07:40:50 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 07:40:50 | INFO | train | epoch 273 | loss 1.753 | ppl 3.37 | wps 21546.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13285 | lr 0.000274359 | gnorm 0.469 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 39492
2022-03-07 07:40:50 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 07:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:41:33 | INFO | train_inner | epoch 274:     15 / 49 loss=1.753, ppl=3.37, wps=21814, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.466, loss_scale=16, train_wall=263, gb_free=21.5, wall=39535
2022-03-07 07:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:43:15 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 11.496 | ppl 2887.46 | wps 38961.6 | wpb 510.9 | bsz 1 | num_updates 13334 | best_loss 8.723
2022-03-07 07:43:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13334 updates
2022-03-07 07:43:15 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 07:43:15 | INFO | train | epoch 274 | loss 1.751 | ppl 3.37 | wps 22015.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13334 | lr 0.000273854 | gnorm 0.46 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 39637
2022-03-07 07:43:15 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 07:43:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:45:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:45:39 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 11.459 | ppl 2816.02 | wps 39019.9 | wpb 510.9 | bsz 1 | num_updates 13383 | best_loss 8.723
2022-03-07 07:45:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13383 updates
2022-03-07 07:45:39 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 07:45:39 | INFO | train | epoch 275 | loss 1.75 | ppl 3.36 | wps 22008 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13383 | lr 0.000273353 | gnorm 0.459 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 39781
2022-03-07 07:45:39 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 07:45:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:46:28 | INFO | train_inner | epoch 276:     17 / 49 loss=1.75, ppl=3.36, wps=22032, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.461, loss_scale=32, train_wall=260, gb_free=21.5, wall=39830
2022-03-07 07:47:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:48:04 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 11.459 | ppl 2814.46 | wps 38952.4 | wpb 510.9 | bsz 1 | num_updates 13432 | best_loss 8.723
2022-03-07 07:48:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13432 updates
2022-03-07 07:48:04 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 07:48:04 | INFO | train | epoch 276 | loss 1.749 | ppl 3.36 | wps 22024.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13432 | lr 0.000272854 | gnorm 0.466 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 39925
2022-03-07 07:48:04 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 07:48:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:48:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:50:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:50:28 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 11.53 | ppl 2957.07 | wps 39012.4 | wpb 510.9 | bsz 1 | num_updates 13480 | best_loss 8.723
2022-03-07 07:50:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13480 updates
2022-03-07 07:50:28 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 07:50:28 | INFO | train | epoch 277 | loss 1.749 | ppl 3.36 | wps 21552.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13480 | lr 0.000272367 | gnorm 0.472 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 40070
2022-03-07 07:50:28 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 07:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:51:25 | INFO | train_inner | epoch 278:     20 / 49 loss=1.748, ppl=3.36, wps=21813.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.469, loss_scale=16, train_wall=263, gb_free=21.5, wall=40127
2022-03-07 07:52:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:52:52 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 11.521 | ppl 2938.42 | wps 39137.2 | wpb 510.9 | bsz 1 | num_updates 13529 | best_loss 8.723
2022-03-07 07:52:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13529 updates
2022-03-07 07:52:52 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 07:52:52 | INFO | train | epoch 278 | loss 1.746 | ppl 3.35 | wps 22011.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13529 | lr 0.000271874 | gnorm 0.461 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 40214
2022-03-07 07:52:52 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 07:52:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:55:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:55:17 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 11.499 | ppl 2894.19 | wps 38861.4 | wpb 510.9 | bsz 1 | num_updates 13578 | best_loss 8.723
2022-03-07 07:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13578 updates
2022-03-07 07:55:17 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 07:55:17 | INFO | train | epoch 279 | loss 1.745 | ppl 3.35 | wps 22001.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13578 | lr 0.000271383 | gnorm 0.466 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 40359
2022-03-07 07:55:17 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 07:55:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:56:20 | INFO | train_inner | epoch 280:     22 / 49 loss=1.745, ppl=3.35, wps=22030.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.462, loss_scale=32, train_wall=260, gb_free=21.5, wall=40421
2022-03-07 07:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:57:41 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 11.505 | ppl 2905.67 | wps 38470 | wpb 510.9 | bsz 1 | num_updates 13627 | best_loss 8.723
2022-03-07 07:57:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13627 updates
2022-03-07 07:57:41 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 07:57:41 | INFO | train | epoch 280 | loss 1.743 | ppl 3.35 | wps 22004.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13627 | lr 0.000270894 | gnorm 0.459 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 40503
2022-03-07 07:57:41 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 07:57:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:00:05 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 11.491 | ppl 2877.63 | wps 39018 | wpb 510.9 | bsz 1 | num_updates 13676 | best_loss 8.723
2022-03-07 08:00:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13676 updates
2022-03-07 08:00:05 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 08:00:05 | INFO | train | epoch 281 | loss 1.743 | ppl 3.35 | wps 22026.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13676 | lr 0.000270409 | gnorm 0.457 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 40647
2022-03-07 08:00:05 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 08:00:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:00:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:01:17 | INFO | train_inner | epoch 282:     25 / 49 loss=1.743, ppl=3.35, wps=21820.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.458, loss_scale=16, train_wall=263, gb_free=21.5, wall=40719
2022-03-07 08:02:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:02:30 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 11.472 | ppl 2839.83 | wps 39039.1 | wpb 510.9 | bsz 1 | num_updates 13724 | best_loss 8.723
2022-03-07 08:02:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13724 updates
2022-03-07 08:02:30 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 08:02:30 | INFO | train | epoch 282 | loss 1.741 | ppl 3.34 | wps 21552.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13724 | lr 0.000269935 | gnorm 0.461 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 40792
2022-03-07 08:02:30 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 08:02:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:04:54 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 11.465 | ppl 2827.78 | wps 38995.3 | wpb 510.9 | bsz 1 | num_updates 13773 | best_loss 8.723
2022-03-07 08:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13773 updates
2022-03-07 08:04:54 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 08:04:54 | INFO | train | epoch 283 | loss 1.74 | ppl 3.34 | wps 22013.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13773 | lr 0.000269455 | gnorm 0.458 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 40936
2022-03-07 08:04:54 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 08:04:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:06:12 | INFO | train_inner | epoch 284:     27 / 49 loss=1.74, ppl=3.34, wps=22020.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.458, loss_scale=16, train_wall=261, gb_free=21.5, wall=41013
2022-03-07 08:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:07:19 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 11.441 | ppl 2780.85 | wps 39206.6 | wpb 510.9 | bsz 1 | num_updates 13822 | best_loss 8.723
2022-03-07 08:07:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13822 updates
2022-03-07 08:07:19 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 08:07:19 | INFO | train | epoch 284 | loss 1.738 | ppl 3.34 | wps 22010.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13822 | lr 0.000268977 | gnorm 0.45 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 41080
2022-03-07 08:07:19 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 08:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:08:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:09:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:09:43 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 11.439 | ppl 2776.11 | wps 38914.9 | wpb 510.9 | bsz 1 | num_updates 13870 | best_loss 8.723
2022-03-07 08:09:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13870 updates
2022-03-07 08:09:43 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 08:09:43 | INFO | train | epoch 285 | loss 1.736 | ppl 3.33 | wps 21552.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13870 | lr 0.000268511 | gnorm 0.446 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 41225
2022-03-07 08:09:43 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 08:09:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:11:09 | INFO | train_inner | epoch 286:     30 / 49 loss=1.736, ppl=3.33, wps=21818.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.447, loss_scale=16, train_wall=263, gb_free=21.5, wall=41311
2022-03-07 08:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:12:07 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 11.443 | ppl 2784.58 | wps 38843 | wpb 510.9 | bsz 1 | num_updates 13919 | best_loss 8.723
2022-03-07 08:12:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13919 updates
2022-03-07 08:12:07 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 08:12:07 | INFO | train | epoch 286 | loss 1.736 | ppl 3.33 | wps 22007.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13919 | lr 0.000268038 | gnorm 0.451 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 41369
2022-03-07 08:12:07 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 08:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:14:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:14:32 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 11.419 | ppl 2738.79 | wps 38882.7 | wpb 510.9 | bsz 1 | num_updates 13968 | best_loss 8.723
2022-03-07 08:14:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13968 updates
2022-03-07 08:14:32 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 08:14:32 | INFO | train | epoch 287 | loss 1.735 | ppl 3.33 | wps 22001.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13968 | lr 0.000267567 | gnorm 0.451 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 41514
2022-03-07 08:14:32 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 08:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:15:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:16:06 | INFO | train_inner | epoch 288:     33 / 49 loss=1.735, ppl=3.33, wps=21813.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.452, loss_scale=16, train_wall=263, gb_free=21.5, wall=41608
2022-03-07 08:16:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:16:56 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 11.447 | ppl 2791.07 | wps 38801.1 | wpb 510.9 | bsz 1 | num_updates 14016 | best_loss 8.723
2022-03-07 08:16:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14016 updates
2022-03-07 08:16:56 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 08:16:56 | INFO | train | epoch 288 | loss 1.734 | ppl 3.33 | wps 21556.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14016 | lr 0.000267109 | gnorm 0.453 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 41658
2022-03-07 08:16:56 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 08:16:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:19:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:19:21 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 11.453 | ppl 2803.71 | wps 38889.4 | wpb 510.9 | bsz 1 | num_updates 14065 | best_loss 8.723
2022-03-07 08:19:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14065 updates
2022-03-07 08:19:21 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 08:19:21 | INFO | train | epoch 289 | loss 1.732 | ppl 3.32 | wps 21993 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14065 | lr 0.000266643 | gnorm 0.451 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 41803
2022-03-07 08:19:21 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 08:19:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:21:01 | INFO | train_inner | epoch 290:     35 / 49 loss=1.732, ppl=3.32, wps=22014, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.45, loss_scale=16, train_wall=261, gb_free=21.5, wall=41903
2022-03-07 08:21:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:21:45 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 11.439 | ppl 2776.56 | wps 39059 | wpb 510.9 | bsz 1 | num_updates 14114 | best_loss 8.723
2022-03-07 08:21:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14114 updates
2022-03-07 08:21:45 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 08:21:45 | INFO | train | epoch 290 | loss 1.731 | ppl 3.32 | wps 22000.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14114 | lr 0.00026618 | gnorm 0.445 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 41947
2022-03-07 08:21:45 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 08:21:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:21:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:24:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:24:10 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 11.432 | ppl 2763.51 | wps 38828.3 | wpb 510.9 | bsz 1 | num_updates 14162 | best_loss 8.723
2022-03-07 08:24:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14162 updates
2022-03-07 08:24:10 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 08:24:10 | INFO | train | epoch 291 | loss 1.73 | ppl 3.32 | wps 21534.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14162 | lr 0.000265728 | gnorm 0.449 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 42092
2022-03-07 08:24:10 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 08:24:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:25:58 | INFO | train_inner | epoch 292:     38 / 49 loss=1.73, ppl=3.32, wps=21805.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.448, loss_scale=16, train_wall=263, gb_free=21.5, wall=42200
2022-03-07 08:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:26:34 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 11.379 | ppl 2663.33 | wps 38864.2 | wpb 510.9 | bsz 1 | num_updates 14211 | best_loss 8.723
2022-03-07 08:26:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14211 updates
2022-03-07 08:26:34 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 08:26:34 | INFO | train | epoch 292 | loss 1.729 | ppl 3.31 | wps 22016.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14211 | lr 0.00026527 | gnorm 0.449 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 42236
2022-03-07 08:26:34 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 08:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:28:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:28:59 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 11.391 | ppl 2685.77 | wps 38898.4 | wpb 510.9 | bsz 1 | num_updates 14260 | best_loss 8.723
2022-03-07 08:28:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14260 updates
2022-03-07 08:28:59 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 08:28:59 | INFO | train | epoch 293 | loss 1.728 | ppl 3.31 | wps 22016.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14260 | lr 0.000264814 | gnorm 0.446 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 42380
2022-03-07 08:28:59 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 08:28:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:30:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:30:56 | INFO | train_inner | epoch 294:     41 / 49 loss=1.728, ppl=3.31, wps=21828.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.448, loss_scale=16, train_wall=263, gb_free=21.5, wall=42497
2022-03-07 08:31:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:31:23 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 11.433 | ppl 2764.91 | wps 38494.3 | wpb 510.9 | bsz 1 | num_updates 14308 | best_loss 8.723
2022-03-07 08:31:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14308 updates
2022-03-07 08:31:23 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 08:31:23 | INFO | train | epoch 294 | loss 1.727 | ppl 3.31 | wps 21560.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14308 | lr 0.000264369 | gnorm 0.45 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 42525
2022-03-07 08:31:23 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 08:31:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:33:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:33:47 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 11.443 | ppl 2783.46 | wps 39083.1 | wpb 510.9 | bsz 1 | num_updates 14357 | best_loss 8.723
2022-03-07 08:33:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14357 updates
2022-03-07 08:33:47 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 08:33:47 | INFO | train | epoch 295 | loss 1.725 | ppl 3.31 | wps 22023 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14357 | lr 0.000263917 | gnorm 0.452 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 42669
2022-03-07 08:33:47 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 08:33:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:35:50 | INFO | train_inner | epoch 296:     43 / 49 loss=1.725, ppl=3.31, wps=22030.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.447, loss_scale=16, train_wall=260, gb_free=21.5, wall=42792
2022-03-07 08:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:36:12 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 11.409 | ppl 2719.76 | wps 38881.1 | wpb 510.9 | bsz 1 | num_updates 14406 | best_loss 8.723
2022-03-07 08:36:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14406 updates
2022-03-07 08:36:12 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 08:36:12 | INFO | train | epoch 296 | loss 1.724 | ppl 3.3 | wps 22010.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14406 | lr 0.000263468 | gnorm 0.44 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 42813
2022-03-07 08:36:12 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 08:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:38:36 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 11.424 | ppl 2746.81 | wps 38887.5 | wpb 510.9 | bsz 1 | num_updates 14455 | best_loss 8.723
2022-03-07 08:38:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14455 updates
2022-03-07 08:38:36 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 08:38:36 | INFO | train | epoch 297 | loss 1.724 | ppl 3.3 | wps 22026.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14455 | lr 0.000263021 | gnorm 0.445 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 42958
2022-03-07 08:38:36 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 08:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:40:45 | INFO | train_inner | epoch 298:     45 / 49 loss=1.723, ppl=3.3, wps=22025.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.444, loss_scale=32, train_wall=261, gb_free=21.5, wall=43086
2022-03-07 08:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:41:00 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 11.398 | ppl 2698.89 | wps 39000.8 | wpb 510.9 | bsz 1 | num_updates 14504 | best_loss 8.723
2022-03-07 08:41:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14504 updates
2022-03-07 08:41:00 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 08:41:00 | INFO | train | epoch 298 | loss 1.722 | ppl 3.3 | wps 21991.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14504 | lr 0.000262577 | gnorm 0.444 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 43102
2022-03-07 08:41:00 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 08:41:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:42:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:43:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:43:25 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 11.443 | ppl 2783.37 | wps 38961.8 | wpb 510.9 | bsz 1 | num_updates 14552 | best_loss 8.723
2022-03-07 08:43:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14552 updates
2022-03-07 08:43:25 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 08:43:25 | INFO | train | epoch 299 | loss 1.721 | ppl 3.3 | wps 21551.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14552 | lr 0.000262143 | gnorm 0.441 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 43247
2022-03-07 08:43:25 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 08:43:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:45:42 | INFO | train_inner | epoch 300:     48 / 49 loss=1.721, ppl=3.3, wps=21811.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.441, loss_scale=16, train_wall=263, gb_free=21.5, wall=43384
2022-03-07 08:45:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:45:49 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 11.407 | ppl 2715.86 | wps 39090.2 | wpb 510.9 | bsz 1 | num_updates 14601 | best_loss 8.723
2022-03-07 08:45:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14601 updates
2022-03-07 08:45:49 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 08:45:49 | INFO | train | epoch 300 | loss 1.72 | ppl 3.29 | wps 22008.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14601 | lr 0.000261703 | gnorm 0.441 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 43391
2022-03-07 08:45:49 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 08:45:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:48:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:48:14 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 11.497 | ppl 2889.52 | wps 38943.8 | wpb 510.9 | bsz 1 | num_updates 14650 | best_loss 8.723
2022-03-07 08:48:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14650 updates
2022-03-07 08:48:14 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 08:48:14 | INFO | train | epoch 301 | loss 1.718 | ppl 3.29 | wps 21996.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14650 | lr 0.000261265 | gnorm 0.438 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 43535
2022-03-07 08:48:14 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 08:48:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:50:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:50:38 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 11.418 | ppl 2736.92 | wps 38819.5 | wpb 510.9 | bsz 1 | num_updates 14699 | best_loss 8.723
2022-03-07 08:50:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14699 updates
2022-03-07 08:50:38 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 08:50:38 | INFO | train | epoch 302 | loss 1.718 | ppl 3.29 | wps 22000.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14699 | lr 0.000260829 | gnorm 0.443 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 43680
2022-03-07 08:50:38 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 08:50:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:50:41 | INFO | train_inner | epoch 303:      1 / 49 loss=1.718, ppl=3.29, wps=21589.4, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=14700, lr=0.00026082, gnorm=0.442, loss_scale=32, train_wall=259, gb_free=21.5, wall=43683
2022-03-07 08:51:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:53:02 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 11.416 | ppl 2732.02 | wps 38900.2 | wpb 510.9 | bsz 1 | num_updates 14747 | best_loss 8.723
2022-03-07 08:53:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14747 updates
2022-03-07 08:53:02 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 08:53:02 | INFO | train | epoch 303 | loss 1.716 | ppl 3.29 | wps 21571.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14747 | lr 0.000260404 | gnorm 0.438 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 43824
2022-03-07 08:53:02 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 08:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:55:27 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 11.407 | ppl 2714.71 | wps 39072.7 | wpb 510.9 | bsz 1 | num_updates 14796 | best_loss 8.723
2022-03-07 08:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14796 updates
2022-03-07 08:55:27 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 08:55:27 | INFO | train | epoch 304 | loss 1.715 | ppl 3.28 | wps 22003 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14796 | lr 0.000259973 | gnorm 0.44 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 43969
2022-03-07 08:55:27 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 08:55:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:55:38 | INFO | train_inner | epoch 305:      4 / 49 loss=1.716, ppl=3.28, wps=21819.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.44, loss_scale=16, train_wall=263, gb_free=21.5, wall=43980
2022-03-07 08:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:57:51 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 11.421 | ppl 2742.61 | wps 39111.7 | wpb 510.9 | bsz 1 | num_updates 14845 | best_loss 8.723
2022-03-07 08:57:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14845 updates
2022-03-07 08:57:51 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 08:57:51 | INFO | train | epoch 305 | loss 1.714 | ppl 3.28 | wps 22011.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14845 | lr 0.000259543 | gnorm 0.444 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 44113
2022-03-07 08:57:51 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 08:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:58:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:00:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:00:16 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 11.409 | ppl 2718.82 | wps 39100 | wpb 510.9 | bsz 1 | num_updates 14893 | best_loss 8.723
2022-03-07 09:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14893 updates
2022-03-07 09:00:16 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 09:00:16 | INFO | train | epoch 306 | loss 1.713 | ppl 3.28 | wps 21568.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14893 | lr 0.000259125 | gnorm 0.44 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 44257
2022-03-07 09:00:16 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 09:00:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:00:36 | INFO | train_inner | epoch 307:      7 / 49 loss=1.713, ppl=3.28, wps=21822.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.441, loss_scale=16, train_wall=263, gb_free=21.5, wall=44277
2022-03-07 09:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:02:40 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 11.426 | ppl 2751.17 | wps 38993.7 | wpb 510.9 | bsz 1 | num_updates 14942 | best_loss 8.723
2022-03-07 09:02:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14942 updates
2022-03-07 09:02:40 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 09:02:40 | INFO | train | epoch 307 | loss 1.712 | ppl 3.28 | wps 22016.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14942 | lr 0.0002587 | gnorm 0.434 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 44402
2022-03-07 09:02:40 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 09:02:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:05:04 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 11.392 | ppl 2687.17 | wps 39049.1 | wpb 510.9 | bsz 1 | num_updates 14991 | best_loss 8.723
2022-03-07 09:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14991 updates
2022-03-07 09:05:04 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 09:05:04 | INFO | train | epoch 308 | loss 1.711 | ppl 3.27 | wps 22008.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14991 | lr 0.000258276 | gnorm 0.437 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 44546
2022-03-07 09:05:04 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 09:05:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:05:30 | INFO | train_inner | epoch 309:      9 / 49 loss=1.711, ppl=3.27, wps=22030.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.437, loss_scale=32, train_wall=260, gb_free=21.5, wall=44572
2022-03-07 09:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:07:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:07:29 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 11.401 | ppl 2704.18 | wps 39048.1 | wpb 510.9 | bsz 1 | num_updates 15039 | best_loss 8.723
2022-03-07 09:07:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15039 updates
2022-03-07 09:07:29 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 09:07:29 | INFO | train | epoch 309 | loss 1.711 | ppl 3.27 | wps 21563.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15039 | lr 0.000257864 | gnorm 0.444 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 44690
2022-03-07 09:07:29 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 09:07:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:09:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:09:53 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 11.431 | ppl 2761.31 | wps 39000.7 | wpb 510.9 | bsz 1 | num_updates 15088 | best_loss 8.723
2022-03-07 09:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15088 updates
2022-03-07 09:09:53 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 09:09:53 | INFO | train | epoch 310 | loss 1.709 | ppl 3.27 | wps 22030.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15088 | lr 0.000257445 | gnorm 0.435 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 44835
2022-03-07 09:09:53 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 09:09:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:10:27 | INFO | train_inner | epoch 311:     12 / 49 loss=1.71, ppl=3.27, wps=21824.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.438, loss_scale=16, train_wall=263, gb_free=21.5, wall=44869
2022-03-07 09:12:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:12:17 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 11.388 | ppl 2679.99 | wps 39096.9 | wpb 510.9 | bsz 1 | num_updates 15137 | best_loss 8.723
2022-03-07 09:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15137 updates
2022-03-07 09:12:17 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 09:12:17 | INFO | train | epoch 311 | loss 1.708 | ppl 3.27 | wps 21989.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15137 | lr 0.000257028 | gnorm 0.438 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 44979
2022-03-07 09:12:17 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 09:12:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:14:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:14:42 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 11.4 | ppl 2701.7 | wps 38930.5 | wpb 510.9 | bsz 1 | num_updates 15186 | best_loss 8.723
2022-03-07 09:14:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15186 updates
2022-03-07 09:14:42 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 09:14:42 | INFO | train | epoch 312 | loss 1.708 | ppl 3.27 | wps 21988 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15186 | lr 0.000256613 | gnorm 0.442 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 45124
2022-03-07 09:14:42 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 09:14:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:15:22 | INFO | train_inner | epoch 313:     14 / 49 loss=1.707, ppl=3.27, wps=22009.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.439, loss_scale=32, train_wall=261, gb_free=21.5, wall=45164
2022-03-07 09:17:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:17:06 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 11.418 | ppl 2736.82 | wps 39051.8 | wpb 510.9 | bsz 1 | num_updates 15235 | best_loss 8.723
2022-03-07 09:17:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15235 updates
2022-03-07 09:17:06 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 09:17:06 | INFO | train | epoch 313 | loss 1.706 | ppl 3.26 | wps 22013 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15235 | lr 0.0002562 | gnorm 0.43 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 45268
2022-03-07 09:17:06 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 09:17:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:17:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:19:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:19:31 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 11.384 | ppl 2673.02 | wps 39008.6 | wpb 510.9 | bsz 1 | num_updates 15283 | best_loss 8.723
2022-03-07 09:19:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15283 updates
2022-03-07 09:19:31 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 09:19:31 | INFO | train | epoch 314 | loss 1.705 | ppl 3.26 | wps 21546.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15283 | lr 0.000255797 | gnorm 0.432 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 45413
2022-03-07 09:19:31 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 09:19:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:20:19 | INFO | train_inner | epoch 315:     17 / 49 loss=1.705, ppl=3.26, wps=21815.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.431, loss_scale=16, train_wall=263, gb_free=21.5, wall=45461
2022-03-07 09:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:21:55 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 11.381 | ppl 2667.82 | wps 39014.1 | wpb 510.9 | bsz 1 | num_updates 15332 | best_loss 8.723
2022-03-07 09:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15332 updates
2022-03-07 09:21:55 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 09:21:55 | INFO | train | epoch 315 | loss 1.704 | ppl 3.26 | wps 22003.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15332 | lr 0.000255388 | gnorm 0.435 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 45557
2022-03-07 09:21:55 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 09:21:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:24:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:24:20 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 11.404 | ppl 2709.78 | wps 38899.3 | wpb 510.9 | bsz 1 | num_updates 15381 | best_loss 8.723
2022-03-07 09:24:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15381 updates
2022-03-07 09:24:20 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 09:24:20 | INFO | train | epoch 316 | loss 1.704 | ppl 3.26 | wps 22000.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15381 | lr 0.000254981 | gnorm 0.438 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 45701
2022-03-07 09:24:20 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 09:24:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:25:14 | INFO | train_inner | epoch 317:     19 / 49 loss=1.704, ppl=3.26, wps=22021.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.434, loss_scale=32, train_wall=261, gb_free=21.5, wall=45756
2022-03-07 09:26:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:26:44 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 11.433 | ppl 2764.19 | wps 38924.9 | wpb 510.9 | bsz 1 | num_updates 15430 | best_loss 8.723
2022-03-07 09:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15430 updates
2022-03-07 09:26:44 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 09:26:44 | INFO | train | epoch 317 | loss 1.702 | ppl 3.25 | wps 21998.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15430 | lr 0.000254576 | gnorm 0.428 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 45846
2022-03-07 09:26:44 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 09:26:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:28:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:29:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:29:09 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 11.408 | ppl 2716.94 | wps 38903.8 | wpb 510.9 | bsz 1 | num_updates 15478 | best_loss 8.723
2022-03-07 09:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15478 updates
2022-03-07 09:29:09 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 09:29:09 | INFO | train | epoch 318 | loss 1.701 | ppl 3.25 | wps 21558.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15478 | lr 0.000254181 | gnorm 0.429 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 45990
2022-03-07 09:29:09 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 09:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:30:11 | INFO | train_inner | epoch 319:     22 / 49 loss=1.701, ppl=3.25, wps=21810.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.43, loss_scale=16, train_wall=263, gb_free=21.5, wall=46053
2022-03-07 09:31:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:31:33 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 11.405 | ppl 2711.48 | wps 38945.6 | wpb 510.9 | bsz 1 | num_updates 15527 | best_loss 8.723
2022-03-07 09:31:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15527 updates
2022-03-07 09:31:33 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 09:31:33 | INFO | train | epoch 319 | loss 1.7 | ppl 3.25 | wps 22006.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15527 | lr 0.000253779 | gnorm 0.429 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 46135
2022-03-07 09:31:33 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 09:31:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:33:57 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 11.395 | ppl 2693.5 | wps 38794.2 | wpb 510.9 | bsz 1 | num_updates 15576 | best_loss 8.723
2022-03-07 09:33:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15576 updates
2022-03-07 09:33:57 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 09:33:57 | INFO | train | epoch 320 | loss 1.7 | ppl 3.25 | wps 22009.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15576 | lr 0.00025338 | gnorm 0.429 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 46279
2022-03-07 09:33:57 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 09:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:35:06 | INFO | train_inner | epoch 321:     24 / 49 loss=1.7, ppl=3.25, wps=22023.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.43, loss_scale=32, train_wall=260, gb_free=21.5, wall=46348
2022-03-07 09:35:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:36:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:36:22 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 11.382 | ppl 2669.61 | wps 38922.2 | wpb 510.9 | bsz 1 | num_updates 15624 | best_loss 8.723
2022-03-07 09:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15624 updates
2022-03-07 09:36:22 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 09:36:22 | INFO | train | epoch 321 | loss 1.699 | ppl 3.25 | wps 21544 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15624 | lr 0.00025299 | gnorm 0.433 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 46424
2022-03-07 09:36:22 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 09:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:38:46 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 11.396 | ppl 2695.21 | wps 38908.5 | wpb 510.9 | bsz 1 | num_updates 15673 | best_loss 8.723
2022-03-07 09:38:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15673 updates
2022-03-07 09:38:46 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 09:38:46 | INFO | train | epoch 322 | loss 1.698 | ppl 3.24 | wps 22016.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15673 | lr 0.000252595 | gnorm 0.429 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 46568
2022-03-07 09:38:46 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 09:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:40:03 | INFO | train_inner | epoch 323:     27 / 49 loss=1.697, ppl=3.24, wps=21814, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.43, loss_scale=16, train_wall=263, gb_free=21.5, wall=46645
2022-03-07 09:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:41:10 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 11.402 | ppl 2706.34 | wps 39019.3 | wpb 510.9 | bsz 1 | num_updates 15722 | best_loss 8.723
2022-03-07 09:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15722 updates
2022-03-07 09:41:10 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 09:41:10 | INFO | train | epoch 323 | loss 1.697 | ppl 3.24 | wps 22019.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15722 | lr 0.000252201 | gnorm 0.425 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 46712
2022-03-07 09:41:10 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 09:41:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:43:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:43:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:43:35 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 11.409 | ppl 2719.42 | wps 38965.2 | wpb 510.9 | bsz 1 | num_updates 15770 | best_loss 8.723
2022-03-07 09:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15770 updates
2022-03-07 09:43:35 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 09:43:35 | INFO | train | epoch 324 | loss 1.697 | ppl 3.24 | wps 21564.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15770 | lr 0.000251816 | gnorm 0.433 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 46857
2022-03-07 09:43:35 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 09:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:45:01 | INFO | train_inner | epoch 325:     30 / 49 loss=1.696, ppl=3.24, wps=21820.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.427, loss_scale=16, train_wall=263, gb_free=21.5, wall=46942
2022-03-07 09:45:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:45:59 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 11.373 | ppl 2652.37 | wps 38906.2 | wpb 510.9 | bsz 1 | num_updates 15819 | best_loss 8.723
2022-03-07 09:45:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15819 updates
2022-03-07 09:45:59 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 09:45:59 | INFO | train | epoch 325 | loss 1.694 | ppl 3.23 | wps 21993.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15819 | lr 0.000251426 | gnorm 0.42 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 47001
2022-03-07 09:45:59 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 09:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:48:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:48:24 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 11.412 | ppl 2724.95 | wps 38903.9 | wpb 510.9 | bsz 1 | num_updates 15868 | best_loss 8.723
2022-03-07 09:48:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15868 updates
2022-03-07 09:48:24 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 09:48:24 | INFO | train | epoch 326 | loss 1.693 | ppl 3.23 | wps 22001.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15868 | lr 0.000251038 | gnorm 0.426 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 47146
2022-03-07 09:48:24 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 09:48:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:49:55 | INFO | train_inner | epoch 327:     32 / 49 loss=1.693, ppl=3.23, wps=22016.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.423, loss_scale=32, train_wall=260, gb_free=21.5, wall=47237
2022-03-07 09:50:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:50:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:50:48 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 11.378 | ppl 2662.17 | wps 38759 | wpb 510.9 | bsz 1 | num_updates 15916 | best_loss 8.723
2022-03-07 09:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15916 updates
2022-03-07 09:50:48 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 09:50:48 | INFO | train | epoch 327 | loss 1.693 | ppl 3.23 | wps 21549.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15916 | lr 0.000250659 | gnorm 0.429 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 47290
2022-03-07 09:50:48 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 09:50:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:53:13 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 11.381 | ppl 2666.62 | wps 38903.8 | wpb 510.9 | bsz 1 | num_updates 15965 | best_loss 8.723
2022-03-07 09:53:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15965 updates
2022-03-07 09:53:13 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 09:53:13 | INFO | train | epoch 328 | loss 1.692 | ppl 3.23 | wps 21995.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15965 | lr 0.000250274 | gnorm 0.422 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 47434
2022-03-07 09:53:13 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 09:53:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:54:53 | INFO | train_inner | epoch 329:     35 / 49 loss=1.692, ppl=3.23, wps=21798.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.426, loss_scale=16, train_wall=263, gb_free=21.5, wall=47535
2022-03-07 09:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:55:37 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 11.376 | ppl 2657.99 | wps 38887.8 | wpb 510.9 | bsz 1 | num_updates 16014 | best_loss 8.723
2022-03-07 09:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16014 updates
2022-03-07 09:55:37 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 09:55:37 | INFO | train | epoch 329 | loss 1.692 | ppl 3.23 | wps 21986 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16014 | lr 0.000249891 | gnorm 0.425 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 47579
2022-03-07 09:55:37 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 09:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:57:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:57:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:58:02 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 11.372 | ppl 2650.61 | wps 38784.4 | wpb 510.9 | bsz 1 | num_updates 16062 | best_loss 8.723
2022-03-07 09:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16062 updates
2022-03-07 09:58:02 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 09:58:02 | INFO | train | epoch 330 | loss 1.691 | ppl 3.23 | wps 21553.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16062 | lr 0.000249517 | gnorm 0.423 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 47723
2022-03-07 09:58:02 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 09:58:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:59:50 | INFO | train_inner | epoch 331:     38 / 49 loss=1.69, ppl=3.23, wps=21810.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.418, loss_scale=16, train_wall=263, gb_free=21.5, wall=47832
2022-03-07 10:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:00:26 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 11.349 | ppl 2609.1 | wps 38834.5 | wpb 510.9 | bsz 1 | num_updates 16111 | best_loss 8.723
2022-03-07 10:00:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16111 updates
2022-03-07 10:00:26 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 10:00:26 | INFO | train | epoch 331 | loss 1.689 | ppl 3.22 | wps 21997.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16111 | lr 0.000249137 | gnorm 0.409 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 47868
2022-03-07 10:00:26 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 10:00:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:02:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:02:51 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 11.331 | ppl 2576.61 | wps 38939.5 | wpb 510.9 | bsz 1 | num_updates 16160 | best_loss 8.723
2022-03-07 10:02:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16160 updates
2022-03-07 10:02:51 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 10:02:51 | INFO | train | epoch 332 | loss 1.689 | ppl 3.22 | wps 21995 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16160 | lr 0.000248759 | gnorm 0.42 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 48012
2022-03-07 10:02:51 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 10:02:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:04:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:04:48 | INFO | train_inner | epoch 333:     41 / 49 loss=1.688, ppl=3.22, wps=21810.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.418, loss_scale=16, train_wall=263, gb_free=21.5, wall=48130
2022-03-07 10:05:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:05:15 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 11.39 | ppl 2683.96 | wps 39002.2 | wpb 510.9 | bsz 1 | num_updates 16208 | best_loss 8.723
2022-03-07 10:05:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16208 updates
2022-03-07 10:05:15 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 10:05:15 | INFO | train | epoch 333 | loss 1.688 | ppl 3.22 | wps 21568.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16208 | lr 0.000248391 | gnorm 0.422 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 48157
2022-03-07 10:05:15 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 10:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:07:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:07:39 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 11.343 | ppl 2597.07 | wps 38875.9 | wpb 510.9 | bsz 1 | num_updates 16257 | best_loss 8.723
2022-03-07 10:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16257 updates
2022-03-07 10:07:39 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 10:07:39 | INFO | train | epoch 334 | loss 1.686 | ppl 3.22 | wps 21999.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16257 | lr 0.000248016 | gnorm 0.422 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 48301
2022-03-07 10:07:39 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 10:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:09:42 | INFO | train_inner | epoch 335:     43 / 49 loss=1.686, ppl=3.22, wps=22019.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.423, loss_scale=16, train_wall=261, gb_free=21.5, wall=48424
2022-03-07 10:09:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:10:04 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 11.382 | ppl 2668.85 | wps 38792.1 | wpb 510.9 | bsz 1 | num_updates 16306 | best_loss 8.723
2022-03-07 10:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16306 updates
2022-03-07 10:10:04 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 10:10:04 | INFO | train | epoch 335 | loss 1.686 | ppl 3.22 | wps 21994.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16306 | lr 0.000247643 | gnorm 0.422 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 48446
2022-03-07 10:10:04 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 10:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:12:28 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 11.387 | ppl 2678.74 | wps 38858.6 | wpb 510.9 | bsz 1 | num_updates 16355 | best_loss 8.723
2022-03-07 10:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16355 updates
2022-03-07 10:12:28 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 10:12:28 | INFO | train | epoch 336 | loss 1.686 | ppl 3.22 | wps 22001.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16355 | lr 0.000247272 | gnorm 0.427 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 48590
2022-03-07 10:12:28 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 10:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:14:37 | INFO | train_inner | epoch 337:     45 / 49 loss=1.685, ppl=3.21, wps=22014.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.422, loss_scale=32, train_wall=261, gb_free=21.5, wall=48719
2022-03-07 10:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:14:53 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 11.344 | ppl 2598.68 | wps 38878.6 | wpb 510.9 | bsz 1 | num_updates 16404 | best_loss 8.723
2022-03-07 10:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16404 updates
2022-03-07 10:14:53 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 10:14:53 | INFO | train | epoch 337 | loss 1.683 | ppl 3.21 | wps 21995.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16404 | lr 0.000246902 | gnorm 0.417 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 48735
2022-03-07 10:14:53 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 10:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:15:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:17:17 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 11.399 | ppl 2701.12 | wps 38829.6 | wpb 510.9 | bsz 1 | num_updates 16452 | best_loss 8.723
2022-03-07 10:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16452 updates
2022-03-07 10:17:17 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 10:17:17 | INFO | train | epoch 338 | loss 1.683 | ppl 3.21 | wps 21565 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16452 | lr 0.000246542 | gnorm 0.413 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 48879
2022-03-07 10:17:17 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 10:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:19:35 | INFO | train_inner | epoch 339:     48 / 49 loss=1.684, ppl=3.21, wps=21812.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16500, lr=0.000246183, gnorm=0.417, loss_scale=16, train_wall=263, gb_free=21.5, wall=49016
2022-03-07 10:19:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:19:42 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 11.313 | ppl 2544.3 | wps 38847.6 | wpb 510.9 | bsz 1 | num_updates 16501 | best_loss 8.723
2022-03-07 10:19:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16501 updates
2022-03-07 10:19:42 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 10:19:42 | INFO | train | epoch 339 | loss 1.684 | ppl 3.21 | wps 21994.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16501 | lr 0.000246176 | gnorm 0.423 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 49023
2022-03-07 10:19:42 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 10:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:22:06 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 11.327 | ppl 2568.6 | wps 39043 | wpb 510.9 | bsz 1 | num_updates 16550 | best_loss 8.723
2022-03-07 10:22:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16550 updates
2022-03-07 10:22:06 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 10:22:06 | INFO | train | epoch 340 | loss 1.682 | ppl 3.21 | wps 22017.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16550 | lr 0.000245811 | gnorm 0.416 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 49168
2022-03-07 10:22:06 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 10:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:24:30 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 11.358 | ppl 2624.24 | wps 38806.7 | wpb 510.9 | bsz 1 | num_updates 16599 | best_loss 8.723
2022-03-07 10:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16599 updates
2022-03-07 10:24:30 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 10:24:30 | INFO | train | epoch 341 | loss 1.681 | ppl 3.21 | wps 22017.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16599 | lr 0.000245448 | gnorm 0.408 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 49312
2022-03-07 10:24:30 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 10:24:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:24:33 | INFO | train_inner | epoch 342:      1 / 49 loss=1.681, ppl=3.21, wps=21603.9, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=16600, lr=0.00024544, gnorm=0.414, loss_scale=32, train_wall=259, gb_free=21.5, wall=49315
2022-03-07 10:26:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:26:55 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 11.356 | ppl 2621.2 | wps 38890.7 | wpb 510.9 | bsz 1 | num_updates 16648 | best_loss 8.723
2022-03-07 10:26:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16648 updates
2022-03-07 10:26:55 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 10:26:55 | INFO | train | epoch 342 | loss 1.681 | ppl 3.21 | wps 21997.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16648 | lr 0.000245086 | gnorm 0.423 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 49457
2022-03-07 10:26:55 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 10:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:27:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:29:19 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 11.288 | ppl 2501.25 | wps 38705.6 | wpb 510.9 | bsz 1 | num_updates 16696 | best_loss 8.723
2022-03-07 10:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16696 updates
2022-03-07 10:29:19 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 10:29:19 | INFO | train | epoch 343 | loss 1.679 | ppl 3.2 | wps 21548.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16696 | lr 0.000244734 | gnorm 0.415 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 49601
2022-03-07 10:29:19 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 10:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:29:31 | INFO | train_inner | epoch 344:      4 / 49 loss=1.68, ppl=3.2, wps=21804.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.418, loss_scale=16, train_wall=263, gb_free=21.5, wall=49613
2022-03-07 10:31:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:31:44 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 11.297 | ppl 2516.37 | wps 38902.6 | wpb 510.9 | bsz 1 | num_updates 16745 | best_loss 8.723
2022-03-07 10:31:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16745 updates
2022-03-07 10:31:44 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 10:31:44 | INFO | train | epoch 344 | loss 1.678 | ppl 3.2 | wps 22019.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16745 | lr 0.000244375 | gnorm 0.416 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 49745
2022-03-07 10:31:44 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 10:31:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:34:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:34:08 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 11.327 | ppl 2568.97 | wps 39043.7 | wpb 510.9 | bsz 1 | num_updates 16794 | best_loss 8.723
2022-03-07 10:34:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16794 updates
2022-03-07 10:34:08 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 10:34:08 | INFO | train | epoch 345 | loss 1.678 | ppl 3.2 | wps 22033.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16794 | lr 0.000244019 | gnorm 0.42 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 49890
2022-03-07 10:34:08 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 10:34:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:34:25 | INFO | train_inner | epoch 346:      6 / 49 loss=1.678, ppl=3.2, wps=22045.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.418, loss_scale=32, train_wall=260, gb_free=21.5, wall=49907
2022-03-07 10:36:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:36:32 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 11.294 | ppl 2510.24 | wps 38667.7 | wpb 510.9 | bsz 1 | num_updates 16843 | best_loss 8.723
2022-03-07 10:36:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16843 updates
2022-03-07 10:36:32 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 10:36:32 | INFO | train | epoch 346 | loss 1.676 | ppl 3.2 | wps 22019 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16843 | lr 0.000243663 | gnorm 0.405 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 50034
2022-03-07 10:36:32 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 10:36:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:37:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:38:57 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 11.313 | ppl 2543.56 | wps 38967.5 | wpb 510.9 | bsz 1 | num_updates 16891 | best_loss 8.723
2022-03-07 10:38:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16891 updates
2022-03-07 10:38:57 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 10:38:57 | INFO | train | epoch 347 | loss 1.676 | ppl 3.2 | wps 21558.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16891 | lr 0.000243317 | gnorm 0.413 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 50178
2022-03-07 10:38:57 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 10:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:39:22 | INFO | train_inner | epoch 348:      9 / 49 loss=1.676, ppl=3.2, wps=21821.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.41, loss_scale=16, train_wall=263, gb_free=21.5, wall=50204
2022-03-07 10:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:41:21 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 11.334 | ppl 2582.3 | wps 38772 | wpb 510.9 | bsz 1 | num_updates 16940 | best_loss 8.723
2022-03-07 10:41:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16940 updates
2022-03-07 10:41:21 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 10:41:21 | INFO | train | epoch 348 | loss 1.676 | ppl 3.2 | wps 22001.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16940 | lr 0.000242965 | gnorm 0.418 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 50323
2022-03-07 10:41:21 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 10:41:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:43:45 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 11.31 | ppl 2539.26 | wps 38585.8 | wpb 510.9 | bsz 1 | num_updates 16989 | best_loss 8.723
2022-03-07 10:43:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16989 updates
2022-03-07 10:43:45 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 10:43:45 | INFO | train | epoch 349 | loss 1.675 | ppl 3.19 | wps 21998.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16989 | lr 0.000242614 | gnorm 0.414 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 50467
2022-03-07 10:43:45 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 10:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:44:17 | INFO | train_inner | epoch 350:     11 / 49 loss=1.675, ppl=3.19, wps=22013.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.414, loss_scale=32, train_wall=260, gb_free=21.5, wall=50499
2022-03-07 10:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:46:10 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 11.286 | ppl 2497.34 | wps 38635.5 | wpb 510.9 | bsz 1 | num_updates 17038 | best_loss 8.723
2022-03-07 10:46:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17038 updates
2022-03-07 10:46:10 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 10:46:10 | INFO | train | epoch 350 | loss 1.674 | ppl 3.19 | wps 22007.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17038 | lr 0.000242265 | gnorm 0.411 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 50612
2022-03-07 10:46:10 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 10:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:46:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:48:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:48:34 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 11.341 | ppl 2593.6 | wps 38669.8 | wpb 510.9 | bsz 1 | num_updates 17086 | best_loss 8.723
2022-03-07 10:48:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17086 updates
2022-03-07 10:48:34 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 10:48:34 | INFO | train | epoch 351 | loss 1.673 | ppl 3.19 | wps 21552.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17086 | lr 0.000241924 | gnorm 0.411 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 50756
2022-03-07 10:48:34 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 10:48:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:49:14 | INFO | train_inner | epoch 352:     14 / 49 loss=1.673, ppl=3.19, wps=21820.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.411, loss_scale=16, train_wall=263, gb_free=21.5, wall=50796
2022-03-07 10:50:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:50:59 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 11.336 | ppl 2585.8 | wps 38787.2 | wpb 510.9 | bsz 1 | num_updates 17135 | best_loss 8.723
2022-03-07 10:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17135 updates
2022-03-07 10:50:59 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 10:50:59 | INFO | train | epoch 352 | loss 1.672 | ppl 3.19 | wps 22021.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17135 | lr 0.000241578 | gnorm 0.414 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 50900
2022-03-07 10:50:59 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 10:50:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:53:23 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 11.349 | ppl 2607.74 | wps 38652.8 | wpb 510.9 | bsz 1 | num_updates 17184 | best_loss 8.723
2022-03-07 10:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17184 updates
2022-03-07 10:53:23 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 10:53:23 | INFO | train | epoch 353 | loss 1.671 | ppl 3.18 | wps 22008.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17184 | lr 0.000241234 | gnorm 0.405 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 51045
2022-03-07 10:53:23 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 10:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:54:09 | INFO | train_inner | epoch 354:     16 / 49 loss=1.671, ppl=3.19, wps=22028.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.409, loss_scale=32, train_wall=260, gb_free=21.5, wall=51091
2022-03-07 10:54:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:55:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:55:47 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 11.357 | ppl 2623.56 | wps 38617.4 | wpb 510.9 | bsz 1 | num_updates 17232 | best_loss 8.723
2022-03-07 10:55:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17232 updates
2022-03-07 10:55:47 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 10:55:47 | INFO | train | epoch 354 | loss 1.67 | ppl 3.18 | wps 21548.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17232 | lr 0.000240897 | gnorm 0.407 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 51189
2022-03-07 10:55:47 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 10:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:58:12 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 11.341 | ppl 2594.68 | wps 38804.9 | wpb 510.9 | bsz 1 | num_updates 17281 | best_loss 8.723
2022-03-07 10:58:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17281 updates
2022-03-07 10:58:12 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 10:58:12 | INFO | train | epoch 355 | loss 1.67 | ppl 3.18 | wps 22002.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17281 | lr 0.000240556 | gnorm 0.409 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 51334
2022-03-07 10:58:12 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 10:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:59:06 | INFO | train_inner | epoch 356:     19 / 49 loss=1.67, ppl=3.18, wps=21810.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.408, loss_scale=16, train_wall=263, gb_free=21.5, wall=51388
2022-03-07 11:00:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:00:36 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 11.334 | ppl 2582.14 | wps 38675.5 | wpb 510.9 | bsz 1 | num_updates 17330 | best_loss 8.723
2022-03-07 11:00:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17330 updates
2022-03-07 11:00:36 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 11:00:36 | INFO | train | epoch 356 | loss 1.669 | ppl 3.18 | wps 22013 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17330 | lr 0.000240215 | gnorm 0.404 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 51478
2022-03-07 11:00:36 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 11:00:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:02:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:03:01 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 11.328 | ppl 2570.11 | wps 38875.3 | wpb 510.9 | bsz 1 | num_updates 17379 | best_loss 8.723
2022-03-07 11:03:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17379 updates
2022-03-07 11:03:01 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 11:03:01 | INFO | train | epoch 357 | loss 1.669 | ppl 3.18 | wps 22013.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17379 | lr 0.000239876 | gnorm 0.405 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 51622
2022-03-07 11:03:01 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 11:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:03:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:04:04 | INFO | train_inner | epoch 358:     22 / 49 loss=1.668, ppl=3.18, wps=21819.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.404, loss_scale=16, train_wall=263, gb_free=21.5, wall=51685
2022-03-07 11:05:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:05:25 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 11.33 | ppl 2574.96 | wps 38791.1 | wpb 510.9 | bsz 1 | num_updates 17427 | best_loss 8.723
2022-03-07 11:05:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17427 updates
2022-03-07 11:05:25 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 11:05:25 | INFO | train | epoch 358 | loss 1.668 | ppl 3.18 | wps 21546.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17427 | lr 0.000239546 | gnorm 0.405 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 51767
2022-03-07 11:05:25 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 11:05:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:07:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:07:49 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 11.323 | ppl 2561.36 | wps 38844.4 | wpb 510.9 | bsz 1 | num_updates 17476 | best_loss 8.723
2022-03-07 11:07:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17476 updates
2022-03-07 11:07:49 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 11:07:49 | INFO | train | epoch 359 | loss 1.667 | ppl 3.18 | wps 22026.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17476 | lr 0.00023921 | gnorm 0.408 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 51911
2022-03-07 11:07:49 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 11:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:08:58 | INFO | train_inner | epoch 360:     24 / 49 loss=1.667, ppl=3.18, wps=22036.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.406, loss_scale=16, train_wall=260, gb_free=21.5, wall=51980
2022-03-07 11:09:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:10:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:10:14 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 11.321 | ppl 2559.02 | wps 39034.9 | wpb 510.9 | bsz 1 | num_updates 17524 | best_loss 8.723
2022-03-07 11:10:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17524 updates
2022-03-07 11:10:14 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 11:10:14 | INFO | train | epoch 360 | loss 1.666 | ppl 3.17 | wps 21566.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17524 | lr 0.000238882 | gnorm 0.408 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 52055
2022-03-07 11:10:14 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 11:10:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:12:38 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 11.334 | ppl 2581.67 | wps 38692.7 | wpb 510.9 | bsz 1 | num_updates 17573 | best_loss 8.723
2022-03-07 11:12:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17573 updates
2022-03-07 11:12:38 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 11:12:38 | INFO | train | epoch 361 | loss 1.666 | ppl 3.17 | wps 22015.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17573 | lr 0.000238549 | gnorm 0.405 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 52200
2022-03-07 11:12:38 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 11:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:13:55 | INFO | train_inner | epoch 362:     27 / 49 loss=1.666, ppl=3.17, wps=21815.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.405, loss_scale=16, train_wall=263, gb_free=21.5, wall=52277
2022-03-07 11:14:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:15:02 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 11.361 | ppl 2630.46 | wps 38817 | wpb 510.9 | bsz 1 | num_updates 17622 | best_loss 8.723
2022-03-07 11:15:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17622 updates
2022-03-07 11:15:02 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 11:15:02 | INFO | train | epoch 362 | loss 1.665 | ppl 3.17 | wps 22013 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17622 | lr 0.000238217 | gnorm 0.403 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 52344
2022-03-07 11:15:02 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 11:15:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:17:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:17:27 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 11.313 | ppl 2544.31 | wps 38969.9 | wpb 510.9 | bsz 1 | num_updates 17671 | best_loss 8.723
2022-03-07 11:17:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17671 updates
2022-03-07 11:17:27 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 11:17:27 | INFO | train | epoch 363 | loss 1.664 | ppl 3.17 | wps 22004 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17671 | lr 0.000237886 | gnorm 0.401 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 52489
2022-03-07 11:17:27 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 11:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:18:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:18:53 | INFO | train_inner | epoch 364:     30 / 49 loss=1.664, ppl=3.17, wps=21819.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.403, loss_scale=16, train_wall=263, gb_free=21.5, wall=52574
2022-03-07 11:19:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:19:51 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 11.326 | ppl 2567.71 | wps 38883.8 | wpb 510.9 | bsz 1 | num_updates 17719 | best_loss 8.723
2022-03-07 11:19:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17719 updates
2022-03-07 11:19:51 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 11:19:51 | INFO | train | epoch 364 | loss 1.664 | ppl 3.17 | wps 21552.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17719 | lr 0.000237564 | gnorm 0.406 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 52633
2022-03-07 11:19:51 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 11:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:22:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:22:16 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 11.304 | ppl 2528.05 | wps 38968.6 | wpb 510.9 | bsz 1 | num_updates 17768 | best_loss 8.723
2022-03-07 11:22:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17768 updates
2022-03-07 11:22:16 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 11:22:16 | INFO | train | epoch 365 | loss 1.664 | ppl 3.17 | wps 22010.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17768 | lr 0.000237236 | gnorm 0.41 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 52777
2022-03-07 11:22:16 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 11:22:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:23:47 | INFO | train_inner | epoch 366:     32 / 49 loss=1.663, ppl=3.17, wps=22025.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.406, loss_scale=16, train_wall=260, gb_free=21.5, wall=52869
2022-03-07 11:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:24:40 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 11.374 | ppl 2653.92 | wps 38942.6 | wpb 510.9 | bsz 1 | num_updates 17817 | best_loss 8.723
2022-03-07 11:24:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17817 updates
2022-03-07 11:24:40 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 11:24:40 | INFO | train | epoch 366 | loss 1.662 | ppl 3.17 | wps 22013.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17817 | lr 0.00023691 | gnorm 0.402 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 52922
2022-03-07 11:24:40 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 11:24:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:25:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:26:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:27:04 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 11.348 | ppl 2606.56 | wps 39014.5 | wpb 510.9 | bsz 1 | num_updates 17865 | best_loss 8.723
2022-03-07 11:27:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17865 updates
2022-03-07 11:27:04 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 11:27:04 | INFO | train | epoch 367 | loss 1.661 | ppl 3.16 | wps 21569.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17865 | lr 0.000236591 | gnorm 0.401 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 53066
2022-03-07 11:27:04 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 11:27:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:28:44 | INFO | train_inner | epoch 368:     35 / 49 loss=1.661, ppl=3.16, wps=21821.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.401, loss_scale=16, train_wall=263, gb_free=21.5, wall=53166
2022-03-07 11:29:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:29:29 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 11.353 | ppl 2616.11 | wps 38948.9 | wpb 510.9 | bsz 1 | num_updates 17914 | best_loss 8.723
2022-03-07 11:29:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17914 updates
2022-03-07 11:29:29 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 11:29:29 | INFO | train | epoch 368 | loss 1.661 | ppl 3.16 | wps 22012.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17914 | lr 0.000236267 | gnorm 0.401 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 53210
2022-03-07 11:29:29 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 11:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:31:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:31:53 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 11.3 | ppl 2521.87 | wps 38616.7 | wpb 510.9 | bsz 1 | num_updates 17963 | best_loss 8.723
2022-03-07 11:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17963 updates
2022-03-07 11:31:53 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 11:31:53 | INFO | train | epoch 369 | loss 1.66 | ppl 3.16 | wps 22007.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17963 | lr 0.000235945 | gnorm 0.402 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 53355
2022-03-07 11:31:53 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 11:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:32:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:33:42 | INFO | train_inner | epoch 370:     38 / 49 loss=1.66, ppl=3.16, wps=21824.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.4, loss_scale=16, train_wall=263, gb_free=21.5, wall=53463
2022-03-07 11:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:34:17 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 11.306 | ppl 2531.04 | wps 39087.6 | wpb 510.9 | bsz 1 | num_updates 18011 | best_loss 8.723
2022-03-07 11:34:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18011 updates
2022-03-07 11:34:17 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 11:34:17 | INFO | train | epoch 370 | loss 1.659 | ppl 3.16 | wps 21576.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18011 | lr 0.00023563 | gnorm 0.396 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 53499
2022-03-07 11:34:17 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 11:34:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:36:42 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 11.3 | ppl 2520.57 | wps 39023.7 | wpb 510.9 | bsz 1 | num_updates 18060 | best_loss 8.723
2022-03-07 11:36:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18060 updates
2022-03-07 11:36:42 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 11:36:42 | INFO | train | epoch 371 | loss 1.66 | ppl 3.16 | wps 22011.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18060 | lr 0.00023531 | gnorm 0.405 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 53643
2022-03-07 11:36:42 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 11:36:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:38:36 | INFO | train_inner | epoch 372:     40 / 49 loss=1.659, ppl=3.16, wps=22023.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.404, loss_scale=16, train_wall=261, gb_free=21.5, wall=53758
2022-03-07 11:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:39:06 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 11.304 | ppl 2527.59 | wps 38821.1 | wpb 510.9 | bsz 1 | num_updates 18109 | best_loss 8.723
2022-03-07 11:39:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18109 updates
2022-03-07 11:39:06 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 11:39:06 | INFO | train | epoch 372 | loss 1.658 | ppl 3.16 | wps 21988 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18109 | lr 0.000234992 | gnorm 0.403 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 53788
2022-03-07 11:39:06 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 11:39:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:41:31 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 11.301 | ppl 2523.75 | wps 39062.6 | wpb 510.9 | bsz 1 | num_updates 18158 | best_loss 8.723
2022-03-07 11:41:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18158 updates
2022-03-07 11:41:31 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 11:41:31 | INFO | train | epoch 373 | loss 1.657 | ppl 3.15 | wps 21999.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18158 | lr 0.000234675 | gnorm 0.396 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 53932
2022-03-07 11:41:31 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 11:41:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:43:34 | INFO | train_inner | epoch 374:     43 / 49 loss=1.657, ppl=3.15, wps=21811.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.396, loss_scale=16, train_wall=263, gb_free=21.5, wall=54055
2022-03-07 11:43:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:43:55 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 11.317 | ppl 2551.77 | wps 38943.2 | wpb 510.9 | bsz 1 | num_updates 18206 | best_loss 8.723
2022-03-07 11:43:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18206 updates
2022-03-07 11:43:55 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 11:43:55 | INFO | train | epoch 374 | loss 1.656 | ppl 3.15 | wps 21567.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18206 | lr 0.000234365 | gnorm 0.397 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 54077
2022-03-07 11:43:55 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 11:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:46:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:46:19 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 11.328 | ppl 2570.63 | wps 38918.6 | wpb 510.9 | bsz 1 | num_updates 18255 | best_loss 8.723
2022-03-07 11:46:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18255 updates
2022-03-07 11:46:19 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 11:46:19 | INFO | train | epoch 375 | loss 1.657 | ppl 3.15 | wps 22002.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18255 | lr 0.00023405 | gnorm 0.398 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 54221
2022-03-07 11:46:19 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 11:46:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:48:28 | INFO | train_inner | epoch 376:     45 / 49 loss=1.656, ppl=3.15, wps=22024.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18300, lr=0.000233762, gnorm=0.397, loss_scale=32, train_wall=260, gb_free=21.5, wall=54350
2022-03-07 11:48:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:48:44 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 11.326 | ppl 2567.3 | wps 38855 | wpb 510.9 | bsz 1 | num_updates 18303 | best_loss 8.723
2022-03-07 11:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18303 updates
2022-03-07 11:48:44 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 11:48:44 | INFO | train | epoch 376 | loss 1.655 | ppl 3.15 | wps 21557 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18303 | lr 0.000233743 | gnorm 0.394 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 54366
2022-03-07 11:48:44 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 11:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:51:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:51:08 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 11.327 | ppl 2568.53 | wps 38943.4 | wpb 510.9 | bsz 1 | num_updates 18352 | best_loss 8.723
2022-03-07 11:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18352 updates
2022-03-07 11:51:08 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 11:51:08 | INFO | train | epoch 377 | loss 1.656 | ppl 3.15 | wps 22024.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18352 | lr 0.000233431 | gnorm 0.405 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 54510
2022-03-07 11:51:08 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 11:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:53:25 | INFO | train_inner | epoch 378:     48 / 49 loss=1.655, ppl=3.15, wps=21830.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.4, loss_scale=16, train_wall=263, gb_free=21.5, wall=54647
2022-03-07 11:53:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:53:32 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 11.293 | ppl 2508.91 | wps 38829.6 | wpb 510.9 | bsz 1 | num_updates 18401 | best_loss 8.723
2022-03-07 11:53:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18401 updates
2022-03-07 11:53:32 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 11:53:32 | INFO | train | epoch 378 | loss 1.654 | ppl 3.15 | wps 22023.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18401 | lr 0.00023312 | gnorm 0.395 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 54654
2022-03-07 11:53:32 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 11:53:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:55:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:55:57 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 11.295 | ppl 2512.36 | wps 38938.4 | wpb 510.9 | bsz 1 | num_updates 18450 | best_loss 8.723
2022-03-07 11:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18450 updates
2022-03-07 11:55:57 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 11:55:57 | INFO | train | epoch 379 | loss 1.653 | ppl 3.15 | wps 21998.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18450 | lr 0.00023281 | gnorm 0.4 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 54799
2022-03-07 11:55:57 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 11:55:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:57:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:58:21 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 11.367 | ppl 2640.87 | wps 38966 | wpb 510.9 | bsz 1 | num_updates 18498 | best_loss 8.723
2022-03-07 11:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18498 updates
2022-03-07 11:58:21 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 11:58:21 | INFO | train | epoch 380 | loss 1.653 | ppl 3.14 | wps 21576.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18498 | lr 0.000232508 | gnorm 0.395 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 54943
2022-03-07 11:58:21 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 11:58:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:58:27 | INFO | train_inner | epoch 381:      2 / 49 loss=1.653, ppl=3.14, wps=21397.8, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=18500, lr=0.000232495, gnorm=0.399, loss_scale=16, train_wall=262, gb_free=21.5, wall=54949
2022-03-07 12:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:00:46 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 11.318 | ppl 2552.69 | wps 38938.1 | wpb 510.9 | bsz 1 | num_updates 18547 | best_loss 8.723
2022-03-07 12:00:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18547 updates
2022-03-07 12:00:46 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 12:00:46 | INFO | train | epoch 381 | loss 1.652 | ppl 3.14 | wps 22003.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18547 | lr 0.000232201 | gnorm 0.393 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 55087
2022-03-07 12:00:46 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 12:00:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:03:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:03:10 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 11.367 | ppl 2641.47 | wps 38794.9 | wpb 510.9 | bsz 1 | num_updates 18596 | best_loss 8.723
2022-03-07 12:03:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18596 updates
2022-03-07 12:03:10 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 12:03:10 | INFO | train | epoch 382 | loss 1.652 | ppl 3.14 | wps 22015.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18596 | lr 0.000231894 | gnorm 0.393 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 55232
2022-03-07 12:03:10 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 12:03:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:03:22 | INFO | train_inner | epoch 383:      4 / 49 loss=1.652, ppl=3.14, wps=22023.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.393, loss_scale=32, train_wall=260, gb_free=21.5, wall=55243
2022-03-07 12:03:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:05:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:05:34 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 11.354 | ppl 2618 | wps 38979 | wpb 510.9 | bsz 1 | num_updates 18644 | best_loss 8.723
2022-03-07 12:05:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18644 updates
2022-03-07 12:05:34 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 12:05:34 | INFO | train | epoch 383 | loss 1.651 | ppl 3.14 | wps 21551.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18644 | lr 0.000231596 | gnorm 0.393 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 55376
2022-03-07 12:05:34 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 12:05:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:07:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:07:59 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 11.263 | ppl 2456.75 | wps 38889.9 | wpb 510.9 | bsz 1 | num_updates 18693 | best_loss 8.723
2022-03-07 12:07:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18693 updates
2022-03-07 12:07:59 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 12:07:59 | INFO | train | epoch 384 | loss 1.651 | ppl 3.14 | wps 22008.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18693 | lr 0.000231292 | gnorm 0.394 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 55521
2022-03-07 12:07:59 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 12:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:08:19 | INFO | train_inner | epoch 385:      7 / 49 loss=1.65, ppl=3.14, wps=21815, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.393, loss_scale=16, train_wall=263, gb_free=21.5, wall=55541
2022-03-07 12:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:10:23 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 11.338 | ppl 2588.75 | wps 38837.8 | wpb 510.9 | bsz 1 | num_updates 18742 | best_loss 8.723
2022-03-07 12:10:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18742 updates
2022-03-07 12:10:23 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 12:10:23 | INFO | train | epoch 385 | loss 1.65 | ppl 3.14 | wps 22005.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18742 | lr 0.000230989 | gnorm 0.398 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 55665
2022-03-07 12:10:23 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 12:10:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:11:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:12:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:12:48 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 11.316 | ppl 2549.5 | wps 38829.7 | wpb 510.9 | bsz 1 | num_updates 18790 | best_loss 8.723
2022-03-07 12:12:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18790 updates
2022-03-07 12:12:48 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 12:12:48 | INFO | train | epoch 386 | loss 1.649 | ppl 3.14 | wps 21542.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18790 | lr 0.000230694 | gnorm 0.394 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 55809
2022-03-07 12:12:48 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 12:12:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:13:16 | INFO | train_inner | epoch 387:     10 / 49 loss=1.65, ppl=3.14, wps=21807.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.397, loss_scale=16, train_wall=263, gb_free=21.5, wall=55838
2022-03-07 12:15:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:15:12 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 11.342 | ppl 2595.71 | wps 38827.4 | wpb 510.9 | bsz 1 | num_updates 18839 | best_loss 8.723
2022-03-07 12:15:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18839 updates
2022-03-07 12:15:12 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 12:15:12 | INFO | train | epoch 387 | loss 1.648 | ppl 3.13 | wps 21997.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18839 | lr 0.000230394 | gnorm 0.395 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 55954
2022-03-07 12:15:12 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 12:15:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:17:37 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 11.29 | ppl 2503.48 | wps 38822.8 | wpb 510.9 | bsz 1 | num_updates 18888 | best_loss 8.723
2022-03-07 12:17:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18888 updates
2022-03-07 12:17:37 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 12:17:37 | INFO | train | epoch 388 | loss 1.648 | ppl 3.13 | wps 21985.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18888 | lr 0.000230095 | gnorm 0.391 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 56098
2022-03-07 12:17:37 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 12:17:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:18:11 | INFO | train_inner | epoch 389:     12 / 49 loss=1.648, ppl=3.13, wps=22011.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.392, loss_scale=32, train_wall=261, gb_free=21.5, wall=56133
2022-03-07 12:18:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:20:01 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 11.288 | ppl 2501.16 | wps 39007 | wpb 510.9 | bsz 1 | num_updates 18936 | best_loss 8.723
2022-03-07 12:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18936 updates
2022-03-07 12:20:01 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 12:20:01 | INFO | train | epoch 389 | loss 1.647 | ppl 3.13 | wps 21547.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18936 | lr 0.000229803 | gnorm 0.399 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 56243
2022-03-07 12:20:01 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 12:20:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:22:25 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 11.301 | ppl 2523.6 | wps 39012.5 | wpb 510.9 | bsz 1 | num_updates 18985 | best_loss 8.723
2022-03-07 12:22:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18985 updates
2022-03-07 12:22:25 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 12:22:25 | INFO | train | epoch 390 | loss 1.646 | ppl 3.13 | wps 22021.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18985 | lr 0.000229506 | gnorm 0.391 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 56387
2022-03-07 12:22:25 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 12:22:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:23:08 | INFO | train_inner | epoch 391:     15 / 49 loss=1.646, ppl=3.13, wps=21821.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.395, loss_scale=16, train_wall=263, gb_free=21.5, wall=56430
2022-03-07 12:24:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:24:50 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 11.324 | ppl 2563.41 | wps 38980.1 | wpb 510.9 | bsz 1 | num_updates 19034 | best_loss 8.723
2022-03-07 12:24:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19034 updates
2022-03-07 12:24:50 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 12:24:50 | INFO | train | epoch 391 | loss 1.646 | ppl 3.13 | wps 22020.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19034 | lr 0.000229211 | gnorm 0.397 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 56532
2022-03-07 12:24:50 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 12:24:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:27:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:27:14 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 11.317 | ppl 2551.3 | wps 38897.9 | wpb 510.9 | bsz 1 | num_updates 19083 | best_loss 8.723
2022-03-07 12:27:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19083 updates
2022-03-07 12:27:14 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 12:27:14 | INFO | train | epoch 392 | loss 1.645 | ppl 3.13 | wps 22011.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19083 | lr 0.000228916 | gnorm 0.388 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 56676
2022-03-07 12:27:14 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 12:27:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:28:03 | INFO | train_inner | epoch 393:     17 / 49 loss=1.645, ppl=3.13, wps=22027.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.391, loss_scale=32, train_wall=260, gb_free=21.5, wall=56725
2022-03-07 12:29:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:29:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:29:39 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 11.301 | ppl 2523.6 | wps 38994.5 | wpb 510.9 | bsz 1 | num_updates 19131 | best_loss 8.723
2022-03-07 12:29:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19131 updates
2022-03-07 12:29:39 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 12:29:39 | INFO | train | epoch 393 | loss 1.644 | ppl 3.13 | wps 21541.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19131 | lr 0.000228629 | gnorm 0.388 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 56820
2022-03-07 12:29:39 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 12:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:32:03 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 11.318 | ppl 2553.78 | wps 39008.3 | wpb 510.9 | bsz 1 | num_updates 19180 | best_loss 8.723
2022-03-07 12:32:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19180 updates
2022-03-07 12:32:03 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 12:32:03 | INFO | train | epoch 394 | loss 1.644 | ppl 3.13 | wps 22002.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19180 | lr 0.000228337 | gnorm 0.389 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 56965
2022-03-07 12:32:03 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 12:32:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:33:00 | INFO | train_inner | epoch 395:     20 / 49 loss=1.644, ppl=3.13, wps=21810.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.388, loss_scale=16, train_wall=263, gb_free=21.5, wall=57022
2022-03-07 12:34:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:34:27 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 11.256 | ppl 2445.18 | wps 38903.4 | wpb 510.9 | bsz 1 | num_updates 19229 | best_loss 8.723
2022-03-07 12:34:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19229 updates
2022-03-07 12:34:27 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 12:34:27 | INFO | train | epoch 395 | loss 1.643 | ppl 3.12 | wps 22019.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19229 | lr 0.000228046 | gnorm 0.384 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 57109
2022-03-07 12:34:27 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 12:34:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:36:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:36:52 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 11.27 | ppl 2470.12 | wps 39274.6 | wpb 510.9 | bsz 1 | num_updates 19278 | best_loss 8.723
2022-03-07 12:36:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19278 updates
2022-03-07 12:36:52 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 12:36:52 | INFO | train | epoch 396 | loss 1.643 | ppl 3.12 | wps 22017.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19278 | lr 0.000227756 | gnorm 0.389 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 57254
2022-03-07 12:36:52 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 12:36:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:37:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:37:58 | INFO | train_inner | epoch 397:     23 / 49 loss=1.643, ppl=3.12, wps=21821.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.387, loss_scale=16, train_wall=263, gb_free=21.5, wall=57319
2022-03-07 12:39:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:39:16 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 11.317 | ppl 2551.97 | wps 38881 | wpb 510.9 | bsz 1 | num_updates 19326 | best_loss 8.723
2022-03-07 12:39:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19326 updates
2022-03-07 12:39:16 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 12:39:16 | INFO | train | epoch 397 | loss 1.642 | ppl 3.12 | wps 21548.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19326 | lr 0.000227473 | gnorm 0.387 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 57398
2022-03-07 12:39:16 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 12:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:41:40 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 11.275 | ppl 2477.34 | wps 38955.5 | wpb 510.9 | bsz 1 | num_updates 19375 | best_loss 8.723
2022-03-07 12:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19375 updates
2022-03-07 12:41:40 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 12:41:40 | INFO | train | epoch 398 | loss 1.642 | ppl 3.12 | wps 22031.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19375 | lr 0.000227185 | gnorm 0.388 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 57542
2022-03-07 12:41:40 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 12:41:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:42:52 | INFO | train_inner | epoch 399:     25 / 49 loss=1.642, ppl=3.12, wps=22028.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.389, loss_scale=16, train_wall=260, gb_free=21.5, wall=57614
2022-03-07 12:43:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:44:05 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 11.255 | ppl 2444.45 | wps 39121.7 | wpb 510.9 | bsz 1 | num_updates 19424 | best_loss 8.723
2022-03-07 12:44:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19424 updates
2022-03-07 12:44:05 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 12:44:05 | INFO | train | epoch 399 | loss 1.641 | ppl 3.12 | wps 21996.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19424 | lr 0.000226898 | gnorm 0.388 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 57687
2022-03-07 12:44:05 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 12:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:44:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:46:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:46:29 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 11.321 | ppl 2558.72 | wps 39046.5 | wpb 510.9 | bsz 1 | num_updates 19472 | best_loss 8.723
2022-03-07 12:46:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19472 updates
2022-03-07 12:46:29 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 12:46:29 | INFO | train | epoch 400 | loss 1.641 | ppl 3.12 | wps 21541.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19472 | lr 0.000226618 | gnorm 0.39 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 57831
2022-03-07 12:46:29 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 12:46:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:47:50 | INFO | train_inner | epoch 401:     28 / 49 loss=1.641, ppl=3.12, wps=21808.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.387, loss_scale=16, train_wall=263, gb_free=21.5, wall=57911
2022-03-07 12:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:48:54 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 11.293 | ppl 2508.62 | wps 39556.1 | wpb 510.9 | bsz 1 | num_updates 19521 | best_loss 8.723
2022-03-07 12:48:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19521 updates
2022-03-07 12:48:54 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 12:48:54 | INFO | train | epoch 401 | loss 1.641 | ppl 3.12 | wps 22017.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19521 | lr 0.000226334 | gnorm 0.386 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 57976
2022-03-07 12:48:54 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 12:48:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:51:18 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 11.269 | ppl 2467.69 | wps 38966.9 | wpb 510.9 | bsz 1 | num_updates 19570 | best_loss 8.723
2022-03-07 12:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19570 updates
2022-03-07 12:51:18 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 12:51:18 | INFO | train | epoch 402 | loss 1.64 | ppl 3.12 | wps 21997.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19570 | lr 0.00022605 | gnorm 0.392 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 58120
2022-03-07 12:51:18 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 12:51:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:52:44 | INFO | train_inner | epoch 403:     30 / 49 loss=1.64, ppl=3.12, wps=22021.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.39, loss_scale=32, train_wall=261, gb_free=21.5, wall=58206
2022-03-07 12:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:53:43 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 11.26 | ppl 2452.22 | wps 38821.1 | wpb 510.9 | bsz 1 | num_updates 19619 | best_loss 8.723
2022-03-07 12:53:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19619 updates
2022-03-07 12:53:43 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 12:53:43 | INFO | train | epoch 403 | loss 1.639 | ppl 3.11 | wps 21995 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19619 | lr 0.000225768 | gnorm 0.387 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 58265
2022-03-07 12:53:43 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 12:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:54:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:56:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:56:07 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 11.265 | ppl 2460.29 | wps 38872.1 | wpb 510.9 | bsz 1 | num_updates 19667 | best_loss 8.723
2022-03-07 12:56:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19667 updates
2022-03-07 12:56:07 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 12:56:07 | INFO | train | epoch 404 | loss 1.638 | ppl 3.11 | wps 21546.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19667 | lr 0.000225492 | gnorm 0.386 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 58409
2022-03-07 12:56:07 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 12:56:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:57:42 | INFO | train_inner | epoch 405:     33 / 49 loss=1.638, ppl=3.11, wps=21812.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.386, loss_scale=16, train_wall=263, gb_free=21.5, wall=58503
2022-03-07 12:58:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:58:32 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 11.283 | ppl 2491.11 | wps 38828.3 | wpb 510.9 | bsz 1 | num_updates 19716 | best_loss 8.723
2022-03-07 12:58:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19716 updates
2022-03-07 12:58:32 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 12:58:32 | INFO | train | epoch 405 | loss 1.638 | ppl 3.11 | wps 22011.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19716 | lr 0.000225212 | gnorm 0.385 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 58553
2022-03-07 12:58:32 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 12:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:00:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:00:56 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 11.315 | ppl 2547.43 | wps 38981.1 | wpb 510.9 | bsz 1 | num_updates 19765 | best_loss 8.723
2022-03-07 13:00:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19765 updates
2022-03-07 13:00:56 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 13:00:56 | INFO | train | epoch 406 | loss 1.637 | ppl 3.11 | wps 21997.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19765 | lr 0.000224932 | gnorm 0.385 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 58698
2022-03-07 13:00:56 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 13:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:02:36 | INFO | train_inner | epoch 407:     35 / 49 loss=1.637, ppl=3.11, wps=22010.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.384, loss_scale=32, train_wall=261, gb_free=21.5, wall=58798
2022-03-07 13:03:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:03:21 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 11.293 | ppl 2510.02 | wps 38897.4 | wpb 510.9 | bsz 1 | num_updates 19814 | best_loss 8.723
2022-03-07 13:03:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19814 updates
2022-03-07 13:03:21 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 13:03:21 | INFO | train | epoch 407 | loss 1.637 | ppl 3.11 | wps 21990.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19814 | lr 0.000224654 | gnorm 0.382 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 58842
2022-03-07 13:03:21 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 13:03:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:04:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:05:45 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 11.316 | ppl 2548.86 | wps 39073.2 | wpb 510.9 | bsz 1 | num_updates 19862 | best_loss 8.723
2022-03-07 13:05:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19862 updates
2022-03-07 13:05:45 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 13:05:45 | INFO | train | epoch 408 | loss 1.637 | ppl 3.11 | wps 21546.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19862 | lr 0.000224382 | gnorm 0.389 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 58987
2022-03-07 13:05:45 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 13:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:07:34 | INFO | train_inner | epoch 409:     38 / 49 loss=1.637, ppl=3.11, wps=21811.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.387, loss_scale=16, train_wall=263, gb_free=21.5, wall=59095
2022-03-07 13:08:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:08:09 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 11.277 | ppl 2480.7 | wps 39115.9 | wpb 510.9 | bsz 1 | num_updates 19911 | best_loss 8.723
2022-03-07 13:08:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19911 updates
2022-03-07 13:08:09 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 13:08:09 | INFO | train | epoch 409 | loss 1.636 | ppl 3.11 | wps 22023.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19911 | lr 0.000224106 | gnorm 0.388 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 59131
2022-03-07 13:08:09 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 13:08:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:10:34 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 11.306 | ppl 2531.26 | wps 39074.1 | wpb 510.9 | bsz 1 | num_updates 19960 | best_loss 8.723
2022-03-07 13:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19960 updates
2022-03-07 13:10:34 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 13:10:34 | INFO | train | epoch 410 | loss 1.636 | ppl 3.11 | wps 22007.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19960 | lr 0.000223831 | gnorm 0.387 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 59276
2022-03-07 13:10:34 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 13:10:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:28 | INFO | train_inner | epoch 411:     40 / 49 loss=1.636, ppl=3.11, wps=22030, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20000, lr=0.000223607, gnorm=0.386, loss_scale=32, train_wall=260, gb_free=21.5, wall=59390
2022-03-07 13:12:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:12:58 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 11.256 | ppl 2446.16 | wps 38931.2 | wpb 510.9 | bsz 1 | num_updates 20009 | best_loss 8.723
2022-03-07 13:12:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20009 updates
2022-03-07 13:12:58 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 13:12:58 | INFO | train | epoch 411 | loss 1.635 | ppl 3.11 | wps 21998.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20009 | lr 0.000223557 | gnorm 0.383 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 59420
2022-03-07 13:12:58 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 13:12:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:15:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:15:23 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 11.289 | ppl 2503.04 | wps 38852.8 | wpb 510.9 | bsz 1 | num_updates 20058 | best_loss 8.723
2022-03-07 13:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20058 updates
2022-03-07 13:15:23 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 13:15:23 | INFO | train | epoch 412 | loss 1.635 | ppl 3.11 | wps 22016.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20058 | lr 0.000223283 | gnorm 0.387 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 59564
2022-03-07 13:15:23 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 13:15:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:17:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:17:26 | INFO | train_inner | epoch 413:     43 / 49 loss=1.635, ppl=3.1, wps=21806.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.386, loss_scale=32, train_wall=263, gb_free=21.5, wall=59687
2022-03-07 13:17:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:17:47 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 11.278 | ppl 2483.66 | wps 38859.7 | wpb 510.9 | bsz 1 | num_updates 20106 | best_loss 8.723
2022-03-07 13:17:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20106 updates
2022-03-07 13:17:47 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 13:17:47 | INFO | train | epoch 413 | loss 1.633 | ppl 3.1 | wps 21541.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20106 | lr 0.000223017 | gnorm 0.385 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 59709
2022-03-07 13:17:47 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 13:17:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:18:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:20:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:20:11 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 11.301 | ppl 2522.94 | wps 38781.1 | wpb 510.9 | bsz 1 | num_updates 20154 | best_loss 8.723
2022-03-07 13:20:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20154 updates
2022-03-07 13:20:11 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 13:20:11 | INFO | train | epoch 414 | loss 1.633 | ppl 3.1 | wps 21555.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20154 | lr 0.000222751 | gnorm 0.389 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 59853
2022-03-07 13:20:11 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 13:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:22:23 | INFO | train_inner | epoch 415:     46 / 49 loss=1.633, ppl=3.1, wps=21817.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.387, loss_scale=16, train_wall=263, gb_free=21.5, wall=59985
2022-03-07 13:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:22:36 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 11.258 | ppl 2449.67 | wps 38923.4 | wpb 510.9 | bsz 1 | num_updates 20203 | best_loss 8.723
2022-03-07 13:22:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20203 updates
2022-03-07 13:22:36 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 13:22:36 | INFO | train | epoch 415 | loss 1.632 | ppl 3.1 | wps 22018.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20203 | lr 0.000222481 | gnorm 0.385 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 59998
2022-03-07 13:22:36 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 13:22:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:24:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:25:00 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 11.227 | ppl 2396.68 | wps 38957.6 | wpb 510.9 | bsz 1 | num_updates 20252 | best_loss 8.723
2022-03-07 13:25:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20252 updates
2022-03-07 13:25:00 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 13:25:00 | INFO | train | epoch 416 | loss 1.632 | ppl 3.1 | wps 22003 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20252 | lr 0.000222211 | gnorm 0.384 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 60142
2022-03-07 13:25:00 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 13:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:26:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:27:19 | INFO | train_inner | epoch 417:     49 / 49 loss=1.632, ppl=3.1, wps=21808.5, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=20300, lr=0.000221948, gnorm=0.386, loss_scale=16, train_wall=262, gb_free=21.5, wall=60281
2022-03-07 13:27:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:27:25 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 11.217 | ppl 2380.44 | wps 38894.9 | wpb 510.9 | bsz 1 | num_updates 20300 | best_loss 8.723
2022-03-07 13:27:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20300 updates
2022-03-07 13:27:25 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 13:27:25 | INFO | train | epoch 417 | loss 1.632 | ppl 3.1 | wps 21560.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20300 | lr 0.000221948 | gnorm 0.387 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 60286
2022-03-07 13:27:25 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 13:27:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:29:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:29:49 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 11.298 | ppl 2517.3 | wps 38978.2 | wpb 510.9 | bsz 1 | num_updates 20349 | best_loss 8.723
2022-03-07 13:29:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20349 updates
2022-03-07 13:29:49 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 13:29:49 | INFO | train | epoch 418 | loss 1.631 | ppl 3.1 | wps 22009 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20349 | lr 0.000221681 | gnorm 0.376 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 60431
2022-03-07 13:29:49 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 13:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:32:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:32:13 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 11.297 | ppl 2516.84 | wps 38911.6 | wpb 510.9 | bsz 1 | num_updates 20398 | best_loss 8.723
2022-03-07 13:32:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20398 updates
2022-03-07 13:32:13 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 13:32:13 | INFO | train | epoch 419 | loss 1.631 | ppl 3.1 | wps 22026.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20398 | lr 0.000221415 | gnorm 0.381 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 60575
2022-03-07 13:32:13 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 13:32:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:32:19 | INFO | train_inner | epoch 420:      2 / 49 loss=1.631, ppl=3.1, wps=21612.8, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.378, loss_scale=16, train_wall=260, gb_free=21.5, wall=60581
2022-03-07 13:34:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:34:38 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 11.323 | ppl 2561.74 | wps 38885.8 | wpb 510.9 | bsz 1 | num_updates 20446 | best_loss 8.723
2022-03-07 13:34:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20446 updates
2022-03-07 13:34:38 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 13:34:38 | INFO | train | epoch 420 | loss 1.63 | ppl 3.09 | wps 21542.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20446 | lr 0.000221155 | gnorm 0.381 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 60720
2022-03-07 13:34:38 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 13:34:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:36:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:37:02 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 11.274 | ppl 2475.56 | wps 39066.4 | wpb 510.9 | bsz 1 | num_updates 20495 | best_loss 8.723
2022-03-07 13:37:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20495 updates
2022-03-07 13:37:02 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 13:37:02 | INFO | train | epoch 421 | loss 1.629 | ppl 3.09 | wps 22010.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20495 | lr 0.00022089 | gnorm 0.381 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 60864
2022-03-07 13:37:02 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 13:37:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:37:16 | INFO | train_inner | epoch 422:      5 / 49 loss=1.629, ppl=3.09, wps=21812.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.381, loss_scale=16, train_wall=263, gb_free=21.5, wall=60878
2022-03-07 13:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:39:26 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 11.26 | ppl 2451.94 | wps 39227 | wpb 510.9 | bsz 1 | num_updates 20544 | best_loss 8.723
2022-03-07 13:39:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20544 updates
2022-03-07 13:39:26 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 13:39:26 | INFO | train | epoch 422 | loss 1.629 | ppl 3.09 | wps 22024.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20544 | lr 0.000220626 | gnorm 0.384 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 61008
2022-03-07 13:39:26 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 13:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:41:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:41:51 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 11.269 | ppl 2467.59 | wps 38803.8 | wpb 510.9 | bsz 1 | num_updates 20593 | best_loss 8.723
2022-03-07 13:41:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20593 updates
2022-03-07 13:41:51 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 13:41:51 | INFO | train | epoch 423 | loss 1.628 | ppl 3.09 | wps 22002.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20593 | lr 0.000220364 | gnorm 0.381 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 61153
2022-03-07 13:41:51 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 13:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:42:11 | INFO | train_inner | epoch 424:      7 / 49 loss=1.628, ppl=3.09, wps=22030.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.383, loss_scale=32, train_wall=260, gb_free=21.5, wall=61173
2022-03-07 13:44:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:44:15 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 11.269 | ppl 2468.03 | wps 39057.3 | wpb 510.9 | bsz 1 | num_updates 20642 | best_loss 8.723
2022-03-07 13:44:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20642 updates
2022-03-07 13:44:15 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 13:44:15 | INFO | train | epoch 424 | loss 1.628 | ppl 3.09 | wps 22011.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20642 | lr 0.000220102 | gnorm 0.384 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 61297
2022-03-07 13:44:15 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 13:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:46:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:46:40 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 11.284 | ppl 2493.71 | wps 38818.4 | wpb 510.9 | bsz 1 | num_updates 20691 | best_loss 8.723
2022-03-07 13:46:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20691 updates
2022-03-07 13:46:40 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 13:46:40 | INFO | train | epoch 425 | loss 1.628 | ppl 3.09 | wps 22020.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20691 | lr 0.000219841 | gnorm 0.38 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 61441
2022-03-07 13:46:40 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 13:46:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:46:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:47:08 | INFO | train_inner | epoch 426:     10 / 49 loss=1.628, ppl=3.09, wps=21821.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.381, loss_scale=32, train_wall=263, gb_free=21.5, wall=61470
2022-03-07 13:47:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:48:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:49:04 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 11.308 | ppl 2535.26 | wps 38909.6 | wpb 510.9 | bsz 1 | num_updates 20738 | best_loss 8.723
2022-03-07 13:49:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20738 updates
2022-03-07 13:49:04 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 13:49:04 | INFO | train | epoch 426 | loss 1.626 | ppl 3.09 | wps 21115.5 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 20738 | lr 0.000219592 | gnorm 0.378 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 61586
2022-03-07 13:49:04 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 13:49:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:51:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:51:28 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 11.28 | ppl 2486.43 | wps 38963.2 | wpb 510.9 | bsz 1 | num_updates 20787 | best_loss 8.723
2022-03-07 13:51:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20787 updates
2022-03-07 13:51:28 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 13:51:28 | INFO | train | epoch 427 | loss 1.627 | ppl 3.09 | wps 22001.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20787 | lr 0.000219333 | gnorm 0.378 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 61730
2022-03-07 13:51:28 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 13:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:52:06 | INFO | train_inner | epoch 428:     13 / 49 loss=1.626, ppl=3.09, wps=21820.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.377, loss_scale=16, train_wall=263, gb_free=21.5, wall=61767
2022-03-07 13:53:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:53:53 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 11.243 | ppl 2423.38 | wps 38871.9 | wpb 510.9 | bsz 1 | num_updates 20836 | best_loss 8.723
2022-03-07 13:53:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20836 updates
2022-03-07 13:53:53 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 13:53:53 | INFO | train | epoch 428 | loss 1.627 | ppl 3.09 | wps 22016 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20836 | lr 0.000219075 | gnorm 0.376 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 61874
2022-03-07 13:53:53 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 13:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:56:17 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 11.242 | ppl 2421.68 | wps 38928.3 | wpb 510.9 | bsz 1 | num_updates 20885 | best_loss 8.723
2022-03-07 13:56:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20885 updates
2022-03-07 13:56:17 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 13:56:17 | INFO | train | epoch 429 | loss 1.625 | ppl 3.08 | wps 21993.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20885 | lr 0.000218818 | gnorm 0.372 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 62019
2022-03-07 13:56:17 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 13:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:57:00 | INFO | train_inner | epoch 430:     15 / 49 loss=1.626, ppl=3.09, wps=22024.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.375, loss_scale=32, train_wall=260, gb_free=21.5, wall=62062
2022-03-07 13:58:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:58:42 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 11.255 | ppl 2444.71 | wps 38986.2 | wpb 510.9 | bsz 1 | num_updates 20933 | best_loss 8.723
2022-03-07 13:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20933 updates
2022-03-07 13:58:42 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 13:58:42 | INFO | train | epoch 430 | loss 1.625 | ppl 3.08 | wps 21555.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20933 | lr 0.000218567 | gnorm 0.376 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 62163
2022-03-07 13:58:42 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 13:58:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:01:06 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 11.239 | ppl 2416.26 | wps 39095.3 | wpb 510.9 | bsz 1 | num_updates 20982 | best_loss 8.723
2022-03-07 14:01:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20982 updates
2022-03-07 14:01:06 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 14:01:06 | INFO | train | epoch 431 | loss 1.624 | ppl 3.08 | wps 22015.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20982 | lr 0.000218311 | gnorm 0.375 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 62308
2022-03-07 14:01:06 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 14:01:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:01:57 | INFO | train_inner | epoch 432:     18 / 49 loss=1.625, ppl=3.08, wps=21814.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.375, loss_scale=16, train_wall=263, gb_free=21.5, wall=62359
2022-03-07 14:03:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:03:30 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 11.288 | ppl 2500.48 | wps 38528.5 | wpb 510.9 | bsz 1 | num_updates 21031 | best_loss 8.723
2022-03-07 14:03:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21031 updates
2022-03-07 14:03:30 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 14:03:30 | INFO | train | epoch 432 | loss 1.624 | ppl 3.08 | wps 21999.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21031 | lr 0.000218057 | gnorm 0.376 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 62452
2022-03-07 14:03:30 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 14:03:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:04:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:05:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:05:55 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 11.233 | ppl 2406.85 | wps 39007.6 | wpb 510.9 | bsz 1 | num_updates 21079 | best_loss 8.723
2022-03-07 14:05:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21079 updates
2022-03-07 14:05:55 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 14:05:55 | INFO | train | epoch 433 | loss 1.624 | ppl 3.08 | wps 21575.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21079 | lr 0.000217809 | gnorm 0.377 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 62596
2022-03-07 14:05:55 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 14:05:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:06:55 | INFO | train_inner | epoch 434:     21 / 49 loss=1.624, ppl=3.08, wps=21817.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.377, loss_scale=16, train_wall=263, gb_free=21.5, wall=62657
2022-03-07 14:08:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:08:19 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 11.235 | ppl 2410.32 | wps 39006.8 | wpb 510.9 | bsz 1 | num_updates 21128 | best_loss 8.723
2022-03-07 14:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21128 updates
2022-03-07 14:08:19 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 14:08:19 | INFO | train | epoch 434 | loss 1.623 | ppl 3.08 | wps 22015.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21128 | lr 0.000217556 | gnorm 0.373 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 62741
2022-03-07 14:08:19 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 14:08:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:10:44 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 11.269 | ppl 2468.21 | wps 38883 | wpb 510.9 | bsz 1 | num_updates 21177 | best_loss 8.723
2022-03-07 14:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21177 updates
2022-03-07 14:10:44 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 14:10:44 | INFO | train | epoch 435 | loss 1.623 | ppl 3.08 | wps 21992.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21177 | lr 0.000217304 | gnorm 0.378 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 62885
2022-03-07 14:10:44 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 14:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:11:49 | INFO | train_inner | epoch 436:     23 / 49 loss=1.623, ppl=3.08, wps=22018.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.374, loss_scale=32, train_wall=260, gb_free=21.5, wall=62951
2022-03-07 14:13:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:13:08 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 11.29 | ppl 2503.66 | wps 38747.8 | wpb 510.9 | bsz 1 | num_updates 21226 | best_loss 8.723
2022-03-07 14:13:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21226 updates
2022-03-07 14:13:08 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 14:13:08 | INFO | train | epoch 436 | loss 1.623 | ppl 3.08 | wps 21988.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21226 | lr 0.000217053 | gnorm 0.38 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 63030
2022-03-07 14:13:08 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 14:13:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:15:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:15:33 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 11.266 | ppl 2462.1 | wps 38966 | wpb 510.9 | bsz 1 | num_updates 21275 | best_loss 8.723
2022-03-07 14:15:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21275 updates
2022-03-07 14:15:33 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 14:15:33 | INFO | train | epoch 437 | loss 1.621 | ppl 3.08 | wps 21989.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21275 | lr 0.000216803 | gnorm 0.371 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 63174
2022-03-07 14:15:33 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 14:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:16:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:16:47 | INFO | train_inner | epoch 438:     26 / 49 loss=1.622, ppl=3.08, wps=21799.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.377, loss_scale=16, train_wall=263, gb_free=21.5, wall=63249
2022-03-07 14:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:17:57 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 11.225 | ppl 2393.2 | wps 38930.1 | wpb 510.9 | bsz 1 | num_updates 21323 | best_loss 8.723
2022-03-07 14:17:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21323 updates
2022-03-07 14:17:57 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 14:17:57 | INFO | train | epoch 438 | loss 1.622 | ppl 3.08 | wps 21537 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21323 | lr 0.000216559 | gnorm 0.379 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 63319
2022-03-07 14:17:57 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 14:17:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:20:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:20:22 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 11.248 | ppl 2432.78 | wps 39066.6 | wpb 510.9 | bsz 1 | num_updates 21372 | best_loss 8.723
2022-03-07 14:20:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21372 updates
2022-03-07 14:20:22 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 14:20:22 | INFO | train | epoch 439 | loss 1.62 | ppl 3.07 | wps 22006 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21372 | lr 0.00021631 | gnorm 0.376 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 63463
2022-03-07 14:20:22 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 14:20:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:21:42 | INFO | train_inner | epoch 440:     28 / 49 loss=1.621, ppl=3.08, wps=22012.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.375, loss_scale=16, train_wall=261, gb_free=21.5, wall=63543
2022-03-07 14:22:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:22:46 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 11.25 | ppl 2434.9 | wps 39124.1 | wpb 510.9 | bsz 1 | num_updates 21421 | best_loss 8.723
2022-03-07 14:22:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21421 updates
2022-03-07 14:22:46 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 14:22:46 | INFO | train | epoch 440 | loss 1.62 | ppl 3.07 | wps 21998.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21421 | lr 0.000216063 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 63608
2022-03-07 14:22:46 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 14:22:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:25:10 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 11.25 | ppl 2435.09 | wps 39021.1 | wpb 510.9 | bsz 1 | num_updates 21470 | best_loss 8.723
2022-03-07 14:25:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21470 updates
2022-03-07 14:25:10 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 14:25:10 | INFO | train | epoch 441 | loss 1.62 | ppl 3.07 | wps 22019.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21470 | lr 0.000215816 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 63752
2022-03-07 14:25:10 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 14:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:25:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:26:39 | INFO | train_inner | epoch 442:     31 / 49 loss=1.62, ppl=3.07, wps=21820.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.37, loss_scale=16, train_wall=263, gb_free=21.5, wall=63841
2022-03-07 14:27:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:27:35 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 11.241 | ppl 2420.39 | wps 38940.7 | wpb 510.9 | bsz 1 | num_updates 21518 | best_loss 8.723
2022-03-07 14:27:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21518 updates
2022-03-07 14:27:35 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 14:27:35 | INFO | train | epoch 442 | loss 1.619 | ppl 3.07 | wps 21555.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21518 | lr 0.000215575 | gnorm 0.372 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 63896
2022-03-07 14:27:35 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 14:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:29:59 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 11.257 | ppl 2446.86 | wps 38855.4 | wpb 510.9 | bsz 1 | num_updates 21567 | best_loss 8.723
2022-03-07 14:29:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21567 updates
2022-03-07 14:29:59 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 14:29:59 | INFO | train | epoch 443 | loss 1.619 | ppl 3.07 | wps 22001.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21567 | lr 0.00021533 | gnorm 0.373 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 64041
2022-03-07 14:29:59 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 14:29:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:31:34 | INFO | train_inner | epoch 444:     33 / 49 loss=1.619, ppl=3.07, wps=22025.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.374, loss_scale=16, train_wall=260, gb_free=21.5, wall=64135
2022-03-07 14:31:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:32:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:32:24 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 11.201 | ppl 2353.7 | wps 38934.6 | wpb 510.9 | bsz 1 | num_updates 21615 | best_loss 8.723
2022-03-07 14:32:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21615 updates
2022-03-07 14:32:24 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 14:32:24 | INFO | train | epoch 444 | loss 1.619 | ppl 3.07 | wps 21560.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21615 | lr 0.000215091 | gnorm 0.378 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 64185
2022-03-07 14:32:24 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 14:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:34:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:34:48 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 11.217 | ppl 2380.84 | wps 38883.7 | wpb 510.9 | bsz 1 | num_updates 21664 | best_loss 8.723
2022-03-07 14:34:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21664 updates
2022-03-07 14:34:48 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-07 14:34:48 | INFO | train | epoch 445 | loss 1.618 | ppl 3.07 | wps 21979.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21664 | lr 0.000214848 | gnorm 0.372 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 64330
2022-03-07 14:34:48 | INFO | fairseq.trainer | begin training epoch 446
2022-03-07 14:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:36:31 | INFO | train_inner | epoch 446:     36 / 49 loss=1.618, ppl=3.07, wps=21801.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.374, loss_scale=16, train_wall=263, gb_free=21.5, wall=64433
2022-03-07 14:37:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:37:13 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 11.219 | ppl 2383.67 | wps 39010.3 | wpb 510.9 | bsz 1 | num_updates 21713 | best_loss 8.723
2022-03-07 14:37:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21713 updates
2022-03-07 14:37:13 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-07 14:37:13 | INFO | train | epoch 446 | loss 1.618 | ppl 3.07 | wps 22004.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21713 | lr 0.000214605 | gnorm 0.38 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 64474
2022-03-07 14:37:13 | INFO | fairseq.trainer | begin training epoch 447
2022-03-07 14:37:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:39:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:39:37 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 11.24 | ppl 2418.29 | wps 38787.4 | wpb 510.9 | bsz 1 | num_updates 21762 | best_loss 8.723
2022-03-07 14:39:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21762 updates
2022-03-07 14:39:37 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-07 14:39:37 | INFO | train | epoch 447 | loss 1.617 | ppl 3.07 | wps 22015.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21762 | lr 0.000214363 | gnorm 0.373 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 64619
2022-03-07 14:39:37 | INFO | fairseq.trainer | begin training epoch 448
2022-03-07 14:39:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:41:26 | INFO | train_inner | epoch 448:     38 / 49 loss=1.617, ppl=3.07, wps=22027, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21800, lr=0.000214176, gnorm=0.374, loss_scale=32, train_wall=260, gb_free=21.5, wall=64727
2022-03-07 14:41:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:42:01 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 11.212 | ppl 2372.4 | wps 38962.6 | wpb 510.9 | bsz 1 | num_updates 21811 | best_loss 8.723
2022-03-07 14:42:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21811 updates
2022-03-07 14:42:01 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-07 14:42:01 | INFO | train | epoch 448 | loss 1.616 | ppl 3.07 | wps 22009.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21811 | lr 0.000214122 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 64763
2022-03-07 14:42:01 | INFO | fairseq.trainer | begin training epoch 449
2022-03-07 14:42:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:44:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:44:26 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 11.249 | ppl 2433.94 | wps 38642.3 | wpb 510.9 | bsz 1 | num_updates 21860 | best_loss 8.723
2022-03-07 14:44:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21860 updates
2022-03-07 14:44:26 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-07 14:44:26 | INFO | train | epoch 449 | loss 1.616 | ppl 3.07 | wps 22014.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21860 | lr 0.000213882 | gnorm 0.376 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 64907
2022-03-07 14:44:26 | INFO | fairseq.trainer | begin training epoch 450
2022-03-07 14:44:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:44:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:46:23 | INFO | train_inner | epoch 450:     41 / 49 loss=1.616, ppl=3.07, wps=21822.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.372, loss_scale=32, train_wall=263, gb_free=21.5, wall=65025
2022-03-07 14:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:46:50 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 11.235 | ppl 2410.76 | wps 38788.9 | wpb 510.9 | bsz 1 | num_updates 21908 | best_loss 8.723
2022-03-07 14:46:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21908 updates
2022-03-07 14:46:50 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-07 14:46:50 | INFO | train | epoch 450 | loss 1.615 | ppl 3.06 | wps 21555 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21908 | lr 0.000213648 | gnorm 0.366 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 65052
2022-03-07 14:46:50 | INFO | fairseq.trainer | begin training epoch 451
2022-03-07 14:46:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:49:15 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 11.267 | ppl 2463.61 | wps 38295.1 | wpb 510.9 | bsz 1 | num_updates 21957 | best_loss 8.723
2022-03-07 14:49:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21957 updates
2022-03-07 14:49:15 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-07 14:49:15 | INFO | train | epoch 451 | loss 1.615 | ppl 3.06 | wps 21986.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21957 | lr 0.000213409 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 65196
2022-03-07 14:49:15 | INFO | fairseq.trainer | begin training epoch 452
2022-03-07 14:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:50:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:51:20 | INFO | train_inner | epoch 452:     44 / 49 loss=1.615, ppl=3.06, wps=21804.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.368, loss_scale=16, train_wall=263, gb_free=21.5, wall=65322
2022-03-07 14:51:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:51:39 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 11.209 | ppl 2366.96 | wps 38961.4 | wpb 510.9 | bsz 1 | num_updates 22005 | best_loss 8.723
2022-03-07 14:51:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 22005 updates
2022-03-07 14:51:39 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-07 14:51:39 | INFO | train | epoch 452 | loss 1.615 | ppl 3.06 | wps 21562.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22005 | lr 0.000213176 | gnorm 0.367 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 65341
2022-03-07 14:51:39 | INFO | fairseq.trainer | begin training epoch 453
2022-03-07 14:51:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:53:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:54:03 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 11.244 | ppl 2424.63 | wps 38990.5 | wpb 510.9 | bsz 1 | num_updates 22054 | best_loss 8.723
2022-03-07 14:54:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22054 updates
2022-03-07 14:54:03 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-07 14:54:03 | INFO | train | epoch 453 | loss 1.614 | ppl 3.06 | wps 22007.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22054 | lr 0.00021294 | gnorm 0.371 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 65485
2022-03-07 14:54:03 | INFO | fairseq.trainer | begin training epoch 454
2022-03-07 14:54:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:56:15 | INFO | train_inner | epoch 454:     46 / 49 loss=1.614, ppl=3.06, wps=22023.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.369, loss_scale=16, train_wall=260, gb_free=21.5, wall=65617
2022-03-07 14:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:56:28 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 11.257 | ppl 2447.41 | wps 38836.7 | wpb 510.9 | bsz 1 | num_updates 22103 | best_loss 8.723
2022-03-07 14:56:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22103 updates
2022-03-07 14:56:28 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-07 14:56:28 | INFO | train | epoch 454 | loss 1.613 | ppl 3.06 | wps 21995.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22103 | lr 0.000212703 | gnorm 0.368 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 65630
2022-03-07 14:56:28 | INFO | fairseq.trainer | begin training epoch 455
2022-03-07 14:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:58:52 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 11.234 | ppl 2408.42 | wps 38937.2 | wpb 510.9 | bsz 1 | num_updates 22152 | best_loss 8.723
2022-03-07 14:58:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22152 updates
2022-03-07 14:58:52 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-07 14:58:52 | INFO | train | epoch 455 | loss 1.613 | ppl 3.06 | wps 22010.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22152 | lr 0.000212468 | gnorm 0.367 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 65774
2022-03-07 14:58:52 | INFO | fairseq.trainer | begin training epoch 456
2022-03-07 14:58:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:01:10 | INFO | train_inner | epoch 456:     48 / 49 loss=1.614, ppl=3.06, wps=22018.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.371, loss_scale=32, train_wall=261, gb_free=21.5, wall=65911
2022-03-07 15:01:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:01:17 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 11.198 | ppl 2348.62 | wps 38864.6 | wpb 510.9 | bsz 1 | num_updates 22201 | best_loss 8.723
2022-03-07 15:01:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22201 updates
2022-03-07 15:01:17 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-07 15:01:17 | INFO | train | epoch 456 | loss 1.614 | ppl 3.06 | wps 21992.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22201 | lr 0.000212233 | gnorm 0.373 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 65918
2022-03-07 15:01:17 | INFO | fairseq.trainer | begin training epoch 457
2022-03-07 15:01:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:03:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:03:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:03:41 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 11.252 | ppl 2439.69 | wps 38875.2 | wpb 510.9 | bsz 1 | num_updates 22249 | best_loss 8.723
2022-03-07 15:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22249 updates
2022-03-07 15:03:41 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-07 15:03:41 | INFO | train | epoch 457 | loss 1.612 | ppl 3.06 | wps 21552.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22249 | lr 0.000212004 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 66063
2022-03-07 15:03:41 | INFO | fairseq.trainer | begin training epoch 458
2022-03-07 15:03:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:06:06 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 11.209 | ppl 2366.81 | wps 38988.1 | wpb 510.9 | bsz 1 | num_updates 22298 | best_loss 8.723
2022-03-07 15:06:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22298 updates
2022-03-07 15:06:06 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-07 15:06:06 | INFO | train | epoch 458 | loss 1.612 | ppl 3.06 | wps 21989.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22298 | lr 0.000211771 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 66207
2022-03-07 15:06:06 | INFO | fairseq.trainer | begin training epoch 459
2022-03-07 15:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:06:11 | INFO | train_inner | epoch 459:      2 / 49 loss=1.612, ppl=3.06, wps=21380.6, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=22300, lr=0.000211762, gnorm=0.37, loss_scale=32, train_wall=262, gb_free=21.5, wall=66213
2022-03-07 15:07:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:08:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:08:30 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 11.249 | ppl 2433.25 | wps 38845.9 | wpb 510.9 | bsz 1 | num_updates 22346 | best_loss 8.723
2022-03-07 15:08:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22346 updates
2022-03-07 15:08:30 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-07 15:08:30 | INFO | train | epoch 459 | loss 1.611 | ppl 3.05 | wps 21536.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22346 | lr 0.000211544 | gnorm 0.367 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 66352
2022-03-07 15:08:30 | INFO | fairseq.trainer | begin training epoch 460
2022-03-07 15:08:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:10:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:10:55 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 11.19 | ppl 2336.63 | wps 38940.4 | wpb 510.9 | bsz 1 | num_updates 22395 | best_loss 8.723
2022-03-07 15:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22395 updates
2022-03-07 15:10:55 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-07 15:10:55 | INFO | train | epoch 460 | loss 1.611 | ppl 3.06 | wps 22007.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22395 | lr 0.000211312 | gnorm 0.364 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 66496
2022-03-07 15:10:55 | INFO | fairseq.trainer | begin training epoch 461
2022-03-07 15:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:11:09 | INFO | train_inner | epoch 461:      5 / 49 loss=1.611, ppl=3.05, wps=21804.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.365, loss_scale=16, train_wall=263, gb_free=21.5, wall=66511
2022-03-07 15:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:13:19 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 11.23 | ppl 2401.22 | wps 38659.2 | wpb 510.9 | bsz 1 | num_updates 22444 | best_loss 8.723
2022-03-07 15:13:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22444 updates
2022-03-07 15:13:19 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-07 15:13:19 | INFO | train | epoch 461 | loss 1.611 | ppl 3.05 | wps 21989.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22444 | lr 0.000211081 | gnorm 0.363 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 66641
2022-03-07 15:13:19 | INFO | fairseq.trainer | begin training epoch 462
2022-03-07 15:13:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:15:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:15:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:15:44 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 11.236 | ppl 2411.87 | wps 39107 | wpb 510.9 | bsz 1 | num_updates 22492 | best_loss 8.723
2022-03-07 15:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22492 updates
2022-03-07 15:15:44 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-07 15:15:44 | INFO | train | epoch 462 | loss 1.61 | ppl 3.05 | wps 21549.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22492 | lr 0.000210856 | gnorm 0.365 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 66785
2022-03-07 15:15:44 | INFO | fairseq.trainer | begin training epoch 463
2022-03-07 15:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:16:07 | INFO | train_inner | epoch 463:      8 / 49 loss=1.61, ppl=3.05, wps=21803.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.364, loss_scale=16, train_wall=263, gb_free=21.5, wall=66808
2022-03-07 15:18:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:18:08 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 11.259 | ppl 2451.16 | wps 38954.2 | wpb 510.9 | bsz 1 | num_updates 22541 | best_loss 8.723
2022-03-07 15:18:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22541 updates
2022-03-07 15:18:08 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-07 15:18:08 | INFO | train | epoch 463 | loss 1.61 | ppl 3.05 | wps 22014.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22541 | lr 0.000210627 | gnorm 0.368 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 66930
2022-03-07 15:18:08 | INFO | fairseq.trainer | begin training epoch 464
2022-03-07 15:18:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:20:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:20:32 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 11.224 | ppl 2392.18 | wps 38983.1 | wpb 510.9 | bsz 1 | num_updates 22590 | best_loss 8.723
2022-03-07 15:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22590 updates
2022-03-07 15:20:32 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-07 15:20:32 | INFO | train | epoch 464 | loss 1.61 | ppl 3.05 | wps 21995.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22590 | lr 0.000210398 | gnorm 0.372 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 67074
2022-03-07 15:20:32 | INFO | fairseq.trainer | begin training epoch 465
2022-03-07 15:20:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:21:01 | INFO | train_inner | epoch 465:     10 / 49 loss=1.61, ppl=3.05, wps=22024.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.37, loss_scale=16, train_wall=260, gb_free=21.5, wall=67103
2022-03-07 15:22:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:22:57 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 11.278 | ppl 2482.89 | wps 38836.5 | wpb 510.9 | bsz 1 | num_updates 22639 | best_loss 8.723
2022-03-07 15:22:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22639 updates
2022-03-07 15:22:57 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-07 15:22:57 | INFO | train | epoch 465 | loss 1.609 | ppl 3.05 | wps 21991.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22639 | lr 0.00021017 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 67219
2022-03-07 15:22:57 | INFO | fairseq.trainer | begin training epoch 466
2022-03-07 15:22:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:23:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:25:21 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 11.229 | ppl 2400.47 | wps 39037.1 | wpb 510.9 | bsz 1 | num_updates 22687 | best_loss 8.723
2022-03-07 15:25:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22687 updates
2022-03-07 15:25:21 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-07 15:25:21 | INFO | train | epoch 466 | loss 1.609 | ppl 3.05 | wps 21563.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22687 | lr 0.000209948 | gnorm 0.368 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 67363
2022-03-07 15:25:21 | INFO | fairseq.trainer | begin training epoch 467
2022-03-07 15:25:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:25:58 | INFO | train_inner | epoch 467:     13 / 49 loss=1.609, ppl=3.05, wps=21812.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.367, loss_scale=16, train_wall=263, gb_free=21.5, wall=67400
2022-03-07 15:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:27:46 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 11.24 | ppl 2418.6 | wps 38904.1 | wpb 510.9 | bsz 1 | num_updates 22736 | best_loss 8.723
2022-03-07 15:27:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22736 updates
2022-03-07 15:27:46 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-07 15:27:46 | INFO | train | epoch 467 | loss 1.607 | ppl 3.05 | wps 21999.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22736 | lr 0.000209722 | gnorm 0.362 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 67507
2022-03-07 15:27:46 | INFO | fairseq.trainer | begin training epoch 468
2022-03-07 15:27:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:30:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:30:10 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 11.236 | ppl 2412.24 | wps 38426.2 | wpb 510.9 | bsz 1 | num_updates 22785 | best_loss 8.723
2022-03-07 15:30:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22785 updates
2022-03-07 15:30:10 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-07 15:30:10 | INFO | train | epoch 468 | loss 1.607 | ppl 3.05 | wps 21993.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22785 | lr 0.000209496 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 67652
2022-03-07 15:30:10 | INFO | fairseq.trainer | begin training epoch 469
2022-03-07 15:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:30:53 | INFO | train_inner | epoch 469:     15 / 49 loss=1.607, ppl=3.05, wps=22013.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.364, loss_scale=32, train_wall=260, gb_free=21.5, wall=67695
2022-03-07 15:32:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:32:35 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 11.211 | ppl 2371.16 | wps 38843.4 | wpb 510.9 | bsz 1 | num_updates 22834 | best_loss 8.723
2022-03-07 15:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22834 updates
2022-03-07 15:32:35 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-07 15:32:35 | INFO | train | epoch 469 | loss 1.608 | ppl 3.05 | wps 22015.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22834 | lr 0.000209271 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 67796
2022-03-07 15:32:35 | INFO | fairseq.trainer | begin training epoch 470
2022-03-07 15:32:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:32:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:34:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:34:59 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 11.202 | ppl 2355.89 | wps 38906.7 | wpb 510.9 | bsz 1 | num_updates 22882 | best_loss 8.723
2022-03-07 15:34:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22882 updates
2022-03-07 15:34:59 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-07 15:34:59 | INFO | train | epoch 470 | loss 1.607 | ppl 3.05 | wps 21553.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22882 | lr 0.000209051 | gnorm 0.366 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 67941
2022-03-07 15:34:59 | INFO | fairseq.trainer | begin training epoch 471
2022-03-07 15:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:35:51 | INFO | train_inner | epoch 471:     18 / 49 loss=1.607, ppl=3.05, wps=21814, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.364, loss_scale=16, train_wall=263, gb_free=21.5, wall=67992
2022-03-07 15:37:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:37:23 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 11.203 | ppl 2357.53 | wps 38846.7 | wpb 510.9 | bsz 1 | num_updates 22931 | best_loss 8.723
2022-03-07 15:37:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22931 updates
2022-03-07 15:37:23 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-07 15:37:23 | INFO | train | epoch 471 | loss 1.607 | ppl 3.05 | wps 21999.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22931 | lr 0.000208828 | gnorm 0.366 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 68085
2022-03-07 15:37:23 | INFO | fairseq.trainer | begin training epoch 472
2022-03-07 15:37:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:39:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:39:48 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 11.247 | ppl 2430.93 | wps 38795.1 | wpb 510.9 | bsz 1 | num_updates 22980 | best_loss 8.723
2022-03-07 15:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22980 updates
2022-03-07 15:39:48 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-07 15:39:48 | INFO | train | epoch 472 | loss 1.607 | ppl 3.05 | wps 21992 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22980 | lr 0.000208605 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 68230
2022-03-07 15:39:48 | INFO | fairseq.trainer | begin training epoch 473
2022-03-07 15:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:40:45 | INFO | train_inner | epoch 473:     20 / 49 loss=1.607, ppl=3.05, wps=22013.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.364, loss_scale=32, train_wall=261, gb_free=21.5, wall=68287
2022-03-07 15:42:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:42:13 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 11.268 | ppl 2465.41 | wps 38684.4 | wpb 510.9 | bsz 1 | num_updates 23029 | best_loss 8.723
2022-03-07 15:42:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23029 updates
2022-03-07 15:42:13 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-07 15:42:13 | INFO | train | epoch 473 | loss 1.606 | ppl 3.04 | wps 21977.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23029 | lr 0.000208383 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 68374
2022-03-07 15:42:13 | INFO | fairseq.trainer | begin training epoch 474
2022-03-07 15:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:44:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:44:37 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 11.225 | ppl 2393.72 | wps 38654.5 | wpb 510.9 | bsz 1 | num_updates 23078 | best_loss 8.723
2022-03-07 15:44:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23078 updates
2022-03-07 15:44:37 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-07 15:44:37 | INFO | train | epoch 474 | loss 1.606 | ppl 3.04 | wps 21998.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23078 | lr 0.000208162 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 68519
2022-03-07 15:44:37 | INFO | fairseq.trainer | begin training epoch 475
2022-03-07 15:44:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:45:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:45:43 | INFO | train_inner | epoch 475:     23 / 49 loss=1.606, ppl=3.04, wps=21797.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.366, loss_scale=32, train_wall=263, gb_free=21.5, wall=68585
2022-03-07 15:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:47:01 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 11.239 | ppl 2417.18 | wps 38838 | wpb 510.9 | bsz 1 | num_updates 23126 | best_loss 8.723
2022-03-07 15:47:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23126 updates
2022-03-07 15:47:01 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-07 15:47:01 | INFO | train | epoch 475 | loss 1.605 | ppl 3.04 | wps 21553 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23126 | lr 0.000207946 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 68663
2022-03-07 15:47:01 | INFO | fairseq.trainer | begin training epoch 476
2022-03-07 15:47:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:49:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:49:26 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 11.254 | ppl 2441.51 | wps 38800.6 | wpb 510.9 | bsz 1 | num_updates 23175 | best_loss 8.723
2022-03-07 15:49:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23175 updates
2022-03-07 15:49:26 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-07 15:49:26 | INFO | train | epoch 476 | loss 1.604 | ppl 3.04 | wps 22008.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23175 | lr 0.000207726 | gnorm 0.363 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 68808
2022-03-07 15:49:26 | INFO | fairseq.trainer | begin training epoch 477
2022-03-07 15:49:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:50:37 | INFO | train_inner | epoch 477:     25 / 49 loss=1.604, ppl=3.04, wps=22026.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.364, loss_scale=32, train_wall=260, gb_free=21.5, wall=68879
2022-03-07 15:51:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:51:50 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 11.24 | ppl 2418.36 | wps 38709.5 | wpb 510.9 | bsz 1 | num_updates 23224 | best_loss 8.723
2022-03-07 15:51:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23224 updates
2022-03-07 15:51:50 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-07 15:51:50 | INFO | train | epoch 477 | loss 1.605 | ppl 3.04 | wps 22011.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23224 | lr 0.000207506 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 68952
2022-03-07 15:51:50 | INFO | fairseq.trainer | begin training epoch 478
2022-03-07 15:51:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:51:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:54:15 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 11.198 | ppl 2348.74 | wps 38997.2 | wpb 510.9 | bsz 1 | num_updates 23272 | best_loss 8.723
2022-03-07 15:54:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23272 updates
2022-03-07 15:54:15 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-07 15:54:15 | INFO | train | epoch 478 | loss 1.604 | ppl 3.04 | wps 21550.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23272 | lr 0.000207292 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 69096
2022-03-07 15:54:15 | INFO | fairseq.trainer | begin training epoch 479
2022-03-07 15:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:54:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:55:38 | INFO | train_inner | epoch 479:     29 / 49 loss=1.604, ppl=3.04, wps=21608.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.365, loss_scale=16, train_wall=266, gb_free=21.5, wall=69179
2022-03-07 15:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:56:39 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 11.194 | ppl 2343.14 | wps 38945.7 | wpb 510.9 | bsz 1 | num_updates 23320 | best_loss 8.723
2022-03-07 15:56:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23320 updates
2022-03-07 15:56:39 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-07 15:56:39 | INFO | train | epoch 479 | loss 1.604 | ppl 3.04 | wps 21549 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23320 | lr 0.000207079 | gnorm 0.363 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 69241
2022-03-07 15:56:39 | INFO | fairseq.trainer | begin training epoch 480
2022-03-07 15:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:58:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:59:03 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 11.198 | ppl 2348.53 | wps 39053.1 | wpb 510.9 | bsz 1 | num_updates 23369 | best_loss 8.723
2022-03-07 15:59:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23369 updates
2022-03-07 15:59:03 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-07 15:59:03 | INFO | train | epoch 480 | loss 1.603 | ppl 3.04 | wps 22017.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23369 | lr 0.000206862 | gnorm 0.362 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 69385
2022-03-07 15:59:03 | INFO | fairseq.trainer | begin training epoch 481
2022-03-07 15:59:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:00:32 | INFO | train_inner | epoch 481:     31 / 49 loss=1.603, ppl=3.04, wps=22027.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.363, loss_scale=16, train_wall=261, gb_free=21.5, wall=69474
2022-03-07 16:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:01:28 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 11.222 | ppl 2388.37 | wps 39080.2 | wpb 510.9 | bsz 1 | num_updates 23418 | best_loss 8.723
2022-03-07 16:01:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23418 updates
2022-03-07 16:01:28 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-07 16:01:28 | INFO | train | epoch 481 | loss 1.603 | ppl 3.04 | wps 22019.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23418 | lr 0.000206645 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 69530
2022-03-07 16:01:28 | INFO | fairseq.trainer | begin training epoch 482
2022-03-07 16:01:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:03:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:03:52 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 11.195 | ppl 2343.6 | wps 39190.4 | wpb 510.9 | bsz 1 | num_updates 23467 | best_loss 8.723
2022-03-07 16:03:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23467 updates
2022-03-07 16:03:52 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-07 16:03:52 | INFO | train | epoch 482 | loss 1.602 | ppl 3.04 | wps 22011.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23467 | lr 0.000206429 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 69674
2022-03-07 16:03:52 | INFO | fairseq.trainer | begin training epoch 483
2022-03-07 16:03:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:05:27 | INFO | train_inner | epoch 483:     33 / 49 loss=1.602, ppl=3.04, wps=22029.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.362, loss_scale=32, train_wall=261, gb_free=21.5, wall=69768
2022-03-07 16:05:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:06:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:06:17 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 11.22 | ppl 2385.06 | wps 38859.1 | wpb 510.9 | bsz 1 | num_updates 23515 | best_loss 8.723
2022-03-07 16:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23515 updates
2022-03-07 16:06:17 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-07 16:06:17 | INFO | train | epoch 483 | loss 1.602 | ppl 3.04 | wps 21549.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23515 | lr 0.000206218 | gnorm 0.359 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 69818
2022-03-07 16:06:17 | INFO | fairseq.trainer | begin training epoch 484
2022-03-07 16:06:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:08:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:08:41 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 11.219 | ppl 2382.91 | wps 38804.7 | wpb 510.9 | bsz 1 | num_updates 23564 | best_loss 8.723
2022-03-07 16:08:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23564 updates
2022-03-07 16:08:41 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-07 16:08:41 | INFO | train | epoch 484 | loss 1.601 | ppl 3.03 | wps 22008.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23564 | lr 0.000206004 | gnorm 0.359 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 69963
2022-03-07 16:08:41 | INFO | fairseq.trainer | begin training epoch 485
2022-03-07 16:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:10:24 | INFO | train_inner | epoch 485:     36 / 49 loss=1.602, ppl=3.04, wps=21810.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23600, lr=0.000205847, gnorm=0.361, loss_scale=16, train_wall=263, gb_free=21.5, wall=70066
2022-03-07 16:11:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:11:05 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 11.188 | ppl 2332.37 | wps 38740.3 | wpb 510.9 | bsz 1 | num_updates 23613 | best_loss 8.723
2022-03-07 16:11:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23613 updates
2022-03-07 16:11:05 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-07 16:11:05 | INFO | train | epoch 485 | loss 1.602 | ppl 3.03 | wps 21994.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23613 | lr 0.00020579 | gnorm 0.363 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 70107
2022-03-07 16:11:05 | INFO | fairseq.trainer | begin training epoch 486
2022-03-07 16:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:13:30 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 11.236 | ppl 2411.54 | wps 38839.3 | wpb 510.9 | bsz 1 | num_updates 23662 | best_loss 8.723
2022-03-07 16:13:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23662 updates
2022-03-07 16:13:30 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-07 16:13:30 | INFO | train | epoch 486 | loss 1.601 | ppl 3.03 | wps 22014.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23662 | lr 0.000205577 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 70252
2022-03-07 16:13:30 | INFO | fairseq.trainer | begin training epoch 487
2022-03-07 16:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:15:19 | INFO | train_inner | epoch 487:     38 / 49 loss=1.601, ppl=3.03, wps=22021.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.364, loss_scale=32, train_wall=260, gb_free=21.5, wall=70360
2022-03-07 16:15:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:15:54 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 11.236 | ppl 2411.24 | wps 38906.4 | wpb 510.9 | bsz 1 | num_updates 23711 | best_loss 8.723
2022-03-07 16:15:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23711 updates
2022-03-07 16:15:54 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-07 16:15:54 | INFO | train | epoch 487 | loss 1.6 | ppl 3.03 | wps 21997.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23711 | lr 0.000205364 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 70396
2022-03-07 16:15:54 | INFO | fairseq.trainer | begin training epoch 488
2022-03-07 16:15:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:15:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:18:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:18:19 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 11.173 | ppl 2308.67 | wps 38826.1 | wpb 510.9 | bsz 1 | num_updates 23759 | best_loss 8.723
2022-03-07 16:18:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23759 updates
2022-03-07 16:18:19 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-07 16:18:19 | INFO | train | epoch 488 | loss 1.6 | ppl 3.03 | wps 21536.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23759 | lr 0.000205157 | gnorm 0.359 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 70541
2022-03-07 16:18:19 | INFO | fairseq.trainer | begin training epoch 489
2022-03-07 16:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:20:16 | INFO | train_inner | epoch 489:     41 / 49 loss=1.6, ppl=3.03, wps=21811.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.359, loss_scale=16, train_wall=263, gb_free=21.5, wall=70658
2022-03-07 16:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:20:43 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 11.205 | ppl 2360.98 | wps 39179.3 | wpb 510.9 | bsz 1 | num_updates 23808 | best_loss 8.723
2022-03-07 16:20:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23808 updates
2022-03-07 16:20:43 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-07 16:20:43 | INFO | train | epoch 489 | loss 1.6 | ppl 3.03 | wps 22030.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23808 | lr 0.000204946 | gnorm 0.358 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 70685
2022-03-07 16:20:43 | INFO | fairseq.trainer | begin training epoch 490
2022-03-07 16:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:23:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:23:07 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 11.236 | ppl 2412.29 | wps 38991.8 | wpb 510.9 | bsz 1 | num_updates 23857 | best_loss 8.723
2022-03-07 16:23:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23857 updates
2022-03-07 16:23:07 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-07 16:23:07 | INFO | train | epoch 490 | loss 1.6 | ppl 3.03 | wps 22014.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23857 | lr 0.000204735 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 70829
2022-03-07 16:23:07 | INFO | fairseq.trainer | begin training epoch 491
2022-03-07 16:23:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:25:11 | INFO | train_inner | epoch 491:     43 / 49 loss=1.599, ppl=3.03, wps=22022.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.359, loss_scale=32, train_wall=260, gb_free=21.5, wall=70952
2022-03-07 16:25:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:25:32 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 11.21 | ppl 2369.46 | wps 38839.1 | wpb 510.9 | bsz 1 | num_updates 23906 | best_loss 8.723
2022-03-07 16:25:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23906 updates
2022-03-07 16:25:32 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-07 16:25:32 | INFO | train | epoch 491 | loss 1.598 | ppl 3.03 | wps 21988.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23906 | lr 0.000204525 | gnorm 0.355 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 70974
2022-03-07 16:25:32 | INFO | fairseq.trainer | begin training epoch 492
2022-03-07 16:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:27:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:27:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:27:56 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 11.196 | ppl 2346.1 | wps 38864.1 | wpb 510.9 | bsz 1 | num_updates 23954 | best_loss 8.723
2022-03-07 16:27:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23954 updates
2022-03-07 16:27:56 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-07 16:27:56 | INFO | train | epoch 492 | loss 1.599 | ppl 3.03 | wps 21539.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23954 | lr 0.00020432 | gnorm 0.36 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 71118
2022-03-07 16:27:57 | INFO | fairseq.trainer | begin training epoch 493
2022-03-07 16:27:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:30:08 | INFO | train_inner | epoch 493:     46 / 49 loss=1.599, ppl=3.03, wps=21806.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.359, loss_scale=16, train_wall=263, gb_free=21.5, wall=71250
2022-03-07 16:30:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:30:21 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 11.212 | ppl 2371.46 | wps 39001.4 | wpb 510.9 | bsz 1 | num_updates 24003 | best_loss 8.723
2022-03-07 16:30:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 24003 updates
2022-03-07 16:30:21 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-07 16:30:21 | INFO | train | epoch 493 | loss 1.598 | ppl 3.03 | wps 22009.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24003 | lr 0.000204111 | gnorm 0.357 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 71263
2022-03-07 16:30:21 | INFO | fairseq.trainer | begin training epoch 494
2022-03-07 16:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:32:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:32:45 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 11.205 | ppl 2360.48 | wps 38803.5 | wpb 510.9 | bsz 1 | num_updates 24052 | best_loss 8.723
2022-03-07 16:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24052 updates
2022-03-07 16:32:45 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-07 16:32:45 | INFO | train | epoch 494 | loss 1.598 | ppl 3.03 | wps 22003.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24052 | lr 0.000203903 | gnorm 0.359 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 71407
2022-03-07 16:32:45 | INFO | fairseq.trainer | begin training epoch 495
2022-03-07 16:32:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:35:03 | INFO | train_inner | epoch 495:     48 / 49 loss=1.598, ppl=3.03, wps=22021.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.359, loss_scale=32, train_wall=260, gb_free=21.5, wall=71544
2022-03-07 16:35:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:35:10 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 11.179 | ppl 2318.68 | wps 38856.8 | wpb 510.9 | bsz 1 | num_updates 24101 | best_loss 8.723
2022-03-07 16:35:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24101 updates
2022-03-07 16:35:10 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-07 16:35:10 | INFO | train | epoch 495 | loss 1.598 | ppl 3.03 | wps 22000.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24101 | lr 0.000203696 | gnorm 0.359 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 71552
2022-03-07 16:35:10 | INFO | fairseq.trainer | begin training epoch 496
2022-03-07 16:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:35:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:37:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:37:34 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 11.18 | ppl 2319.72 | wps 38992.2 | wpb 510.9 | bsz 1 | num_updates 24149 | best_loss 8.723
2022-03-07 16:37:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24149 updates
2022-03-07 16:37:34 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-07 16:37:34 | INFO | train | epoch 496 | loss 1.597 | ppl 3.03 | wps 21555.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24149 | lr 0.000203493 | gnorm 0.363 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 71696
2022-03-07 16:37:34 | INFO | fairseq.trainer | begin training epoch 497
2022-03-07 16:37:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:39:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:39:59 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 11.149 | ppl 2270.68 | wps 38869.7 | wpb 510.9 | bsz 1 | num_updates 24198 | best_loss 8.723
2022-03-07 16:39:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24198 updates
2022-03-07 16:39:59 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-07 16:39:59 | INFO | train | epoch 497 | loss 1.596 | ppl 3.02 | wps 22015.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24198 | lr 0.000203287 | gnorm 0.354 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 71840
2022-03-07 16:39:59 | INFO | fairseq.trainer | begin training epoch 498
2022-03-07 16:39:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:40:04 | INFO | train_inner | epoch 498:      2 / 49 loss=1.597, ppl=3.02, wps=21395.8, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=24200, lr=0.000203279, gnorm=0.359, loss_scale=16, train_wall=262, gb_free=21.5, wall=71846
2022-03-07 16:42:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:42:23 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 11.176 | ppl 2313.75 | wps 38978.2 | wpb 510.9 | bsz 1 | num_updates 24247 | best_loss 8.723
2022-03-07 16:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24247 updates
2022-03-07 16:42:23 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-07 16:42:23 | INFO | train | epoch 498 | loss 1.597 | ppl 3.02 | wps 22006.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24247 | lr 0.000203082 | gnorm 0.359 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 71985
2022-03-07 16:42:23 | INFO | fairseq.trainer | begin training epoch 499
2022-03-07 16:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:44:49 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 11.205 | ppl 2360.62 | wps 38048.7 | wpb 510.9 | bsz 1 | num_updates 24296 | best_loss 8.723
2022-03-07 16:44:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24296 updates
2022-03-07 16:44:49 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-07 16:44:49 | INFO | train | epoch 499 | loss 1.596 | ppl 3.02 | wps 21763.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24296 | lr 0.000202877 | gnorm 0.353 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 72131
2022-03-07 16:44:49 | INFO | fairseq.trainer | begin training epoch 500
2022-03-07 16:44:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:45:01 | INFO | train_inner | epoch 500:      4 / 49 loss=1.596, ppl=3.02, wps=21897.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.356, loss_scale=32, train_wall=262, gb_free=21.5, wall=72142
2022-03-07 16:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:47:15 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 11.23 | ppl 2401.61 | wps 37856.5 | wpb 510.9 | bsz 1 | num_updates 24345 | best_loss 8.723
2022-03-07 16:47:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24345 updates
2022-03-07 16:47:15 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-07 16:47:15 | INFO | train | epoch 500 | loss 1.595 | ppl 3.02 | wps 21774.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24345 | lr 0.000202673 | gnorm 0.352 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 72277
2022-03-07 16:47:15 | INFO | fairseq.trainer | begin training epoch 501
2022-03-07 16:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:48:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:49:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:49:41 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 11.22 | ppl 2385.79 | wps 37617 | wpb 510.9 | bsz 1 | num_updates 24393 | best_loss 8.723
2022-03-07 16:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24393 updates
2022-03-07 16:49:41 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-07 16:49:41 | INFO | train | epoch 501 | loss 1.595 | ppl 3.02 | wps 21297.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24393 | lr 0.000202473 | gnorm 0.357 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 72423
2022-03-07 16:49:41 | INFO | fairseq.trainer | begin training epoch 502
2022-03-07 16:49:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:50:01 | INFO | train_inner | epoch 502:      7 / 49 loss=1.595, ppl=3.02, wps=21564.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.355, loss_scale=32, train_wall=265, gb_free=21.5, wall=72443
2022-03-07 16:52:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:52:07 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 11.207 | ppl 2364.45 | wps 38007.6 | wpb 510.9 | bsz 1 | num_updates 24442 | best_loss 8.723
2022-03-07 16:52:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24442 updates
2022-03-07 16:52:07 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-07 16:52:07 | INFO | train | epoch 502 | loss 1.595 | ppl 3.02 | wps 21757 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24442 | lr 0.00020227 | gnorm 0.354 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 72569
2022-03-07 16:52:07 | INFO | fairseq.trainer | begin training epoch 503
2022-03-07 16:52:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:54:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:54:33 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 11.178 | ppl 2316.18 | wps 37603.9 | wpb 510.9 | bsz 1 | num_updates 24490 | best_loss 8.723
2022-03-07 16:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24490 updates
2022-03-07 16:54:33 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-07 16:54:33 | INFO | train | epoch 503 | loss 1.594 | ppl 3.02 | wps 21297 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24490 | lr 0.000202072 | gnorm 0.353 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 72715
2022-03-07 16:54:33 | INFO | fairseq.trainer | begin training epoch 504
2022-03-07 16:54:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:55:02 | INFO | train_inner | epoch 504:     10 / 49 loss=1.594, ppl=3.02, wps=21563.9, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.352, loss_scale=32, train_wall=265, gb_free=21.5, wall=72744
2022-03-07 16:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:56:59 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 11.166 | ppl 2298.37 | wps 37688.6 | wpb 510.9 | bsz 1 | num_updates 24539 | best_loss 8.723
2022-03-07 16:56:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24539 updates
2022-03-07 16:56:59 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-07 16:56:59 | INFO | train | epoch 504 | loss 1.594 | ppl 3.02 | wps 21749.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24539 | lr 0.00020187 | gnorm 0.356 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 72861
2022-03-07 16:56:59 | INFO | fairseq.trainer | begin training epoch 505
2022-03-07 16:56:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:59:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:59:25 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 11.175 | ppl 2311.61 | wps 37901.8 | wpb 510.9 | bsz 1 | num_updates 24588 | best_loss 8.723
2022-03-07 16:59:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24588 updates
2022-03-07 16:59:25 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-07 16:59:25 | INFO | train | epoch 505 | loss 1.594 | ppl 3.02 | wps 21760 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24588 | lr 0.000201669 | gnorm 0.355 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 73007
2022-03-07 16:59:25 | INFO | fairseq.trainer | begin training epoch 506
2022-03-07 16:59:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:00:00 | INFO | train_inner | epoch 506:     12 / 49 loss=1.594, ppl=3.02, wps=21766.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.357, loss_scale=32, train_wall=263, gb_free=21.5, wall=73042
2022-03-07 17:00:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:01:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:01:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:01:52 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 11.176 | ppl 2313.86 | wps 37811.3 | wpb 510.9 | bsz 1 | num_updates 24635 | best_loss 8.723
2022-03-07 17:01:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24635 updates
2022-03-07 17:01:52 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-07 17:01:52 | INFO | train | epoch 506 | loss 1.594 | ppl 3.02 | wps 20854.5 | ups 0.32 | wpb 64829.4 | bsz 126.6 | num_updates 24635 | lr 0.000201476 | gnorm 0.363 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 73153
2022-03-07 17:01:52 | INFO | fairseq.trainer | begin training epoch 507
2022-03-07 17:01:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:04:18 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 11.189 | ppl 2334.9 | wps 37668.6 | wpb 510.9 | bsz 1 | num_updates 24684 | best_loss 8.723
2022-03-07 17:04:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24684 updates
2022-03-07 17:04:18 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-07 17:04:18 | INFO | train | epoch 507 | loss 1.593 | ppl 3.02 | wps 21729.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24684 | lr 0.000201276 | gnorm 0.355 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 73300
2022-03-07 17:04:18 | INFO | fairseq.trainer | begin training epoch 508
2022-03-07 17:04:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:05:04 | INFO | train_inner | epoch 508:     16 / 49 loss=1.593, ppl=3.02, wps=21353, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.358, loss_scale=16, train_wall=268, gb_free=21.5, wall=73346
2022-03-07 17:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:06:44 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 11.215 | ppl 2376.47 | wps 38053.9 | wpb 510.9 | bsz 1 | num_updates 24733 | best_loss 8.723
2022-03-07 17:06:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24733 updates
2022-03-07 17:06:44 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-07 17:06:44 | INFO | train | epoch 508 | loss 1.593 | ppl 3.02 | wps 21769.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24733 | lr 0.000201077 | gnorm 0.355 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 73446
2022-03-07 17:06:44 | INFO | fairseq.trainer | begin training epoch 509
2022-03-07 17:06:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:09:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:09:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:09:10 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 11.173 | ppl 2308.93 | wps 37827.3 | wpb 510.9 | bsz 1 | num_updates 24781 | best_loss 8.723
2022-03-07 17:09:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24781 updates
2022-03-07 17:09:10 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-07 17:09:10 | INFO | train | epoch 509 | loss 1.592 | ppl 3.02 | wps 21321.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24781 | lr 0.000200882 | gnorm 0.357 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 73592
2022-03-07 17:09:10 | INFO | fairseq.trainer | begin training epoch 510
2022-03-07 17:09:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:10:05 | INFO | train_inner | epoch 510:     19 / 49 loss=1.593, ppl=3.02, wps=21577.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.357, loss_scale=16, train_wall=265, gb_free=21.5, wall=73646
2022-03-07 17:11:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:11:36 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 11.141 | ppl 2257.67 | wps 37755.9 | wpb 510.9 | bsz 1 | num_updates 24830 | best_loss 8.723
2022-03-07 17:11:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24830 updates
2022-03-07 17:11:36 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-07 17:11:36 | INFO | train | epoch 510 | loss 1.592 | ppl 3.02 | wps 21755.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24830 | lr 0.000200683 | gnorm 0.357 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 73738
2022-03-07 17:11:36 | INFO | fairseq.trainer | begin training epoch 511
2022-03-07 17:11:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:13:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:14:02 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 11.209 | ppl 2367.93 | wps 37934.5 | wpb 510.9 | bsz 1 | num_updates 24879 | best_loss 8.723
2022-03-07 17:14:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24879 updates
2022-03-07 17:14:02 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-07 17:14:02 | INFO | train | epoch 511 | loss 1.592 | ppl 3.01 | wps 21773.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24879 | lr 0.000200486 | gnorm 0.356 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 73884
2022-03-07 17:14:02 | INFO | fairseq.trainer | begin training epoch 512
2022-03-07 17:14:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:15:03 | INFO | train_inner | epoch 512:     21 / 49 loss=1.592, ppl=3.01, wps=21775.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.356, loss_scale=16, train_wall=263, gb_free=21.5, wall=73944
2022-03-07 17:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:16:28 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 11.199 | ppl 2351.51 | wps 37817.4 | wpb 510.9 | bsz 1 | num_updates 24928 | best_loss 8.723
2022-03-07 17:16:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24928 updates
2022-03-07 17:16:28 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-07 17:16:28 | INFO | train | epoch 512 | loss 1.592 | ppl 3.01 | wps 21748.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24928 | lr 0.000200289 | gnorm 0.355 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 74030
2022-03-07 17:16:28 | INFO | fairseq.trainer | begin training epoch 513
2022-03-07 17:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:17:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:18:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:18:54 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 11.165 | ppl 2295.68 | wps 38129.7 | wpb 510.9 | bsz 1 | num_updates 24976 | best_loss 8.723
2022-03-07 17:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24976 updates
2022-03-07 17:18:54 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-07 17:18:54 | INFO | train | epoch 513 | loss 1.591 | ppl 3.01 | wps 21300.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24976 | lr 0.000200096 | gnorm 0.352 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 74176
2022-03-07 17:18:54 | INFO | fairseq.trainer | begin training epoch 514
2022-03-07 17:18:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:20:04 | INFO | train_inner | epoch 514:     24 / 49 loss=1.591, ppl=3.01, wps=21560.5, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.354, loss_scale=16, train_wall=266, gb_free=21.5, wall=74245
2022-03-07 17:21:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:21:20 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 11.204 | ppl 2359.47 | wps 37771.1 | wpb 510.9 | bsz 1 | num_updates 25025 | best_loss 8.723
2022-03-07 17:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25025 updates
2022-03-07 17:21:20 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-07 17:21:20 | INFO | train | epoch 514 | loss 1.591 | ppl 3.01 | wps 21755 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25025 | lr 0.0001999 | gnorm 0.359 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 74322
2022-03-07 17:21:20 | INFO | fairseq.trainer | begin training epoch 515
2022-03-07 17:21:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:23:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:23:46 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 11.179 | ppl 2317.97 | wps 37908.4 | wpb 510.9 | bsz 1 | num_updates 25074 | best_loss 8.723
2022-03-07 17:23:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25074 updates
2022-03-07 17:23:46 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-07 17:23:46 | INFO | train | epoch 515 | loss 1.59 | ppl 3.01 | wps 21738.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25074 | lr 0.000199705 | gnorm 0.354 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 74468
2022-03-07 17:23:46 | INFO | fairseq.trainer | begin training epoch 516
2022-03-07 17:23:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:25:02 | INFO | train_inner | epoch 516:     26 / 49 loss=1.59, ppl=3.01, wps=21764.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.354, loss_scale=32, train_wall=263, gb_free=21.5, wall=74543
2022-03-07 17:26:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:26:13 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 11.184 | ppl 2327.03 | wps 38013.2 | wpb 510.9 | bsz 1 | num_updates 25123 | best_loss 8.723
2022-03-07 17:26:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25123 updates
2022-03-07 17:26:13 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-07 17:26:13 | INFO | train | epoch 516 | loss 1.59 | ppl 3.01 | wps 21744.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25123 | lr 0.00019951 | gnorm 0.35 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 74614
2022-03-07 17:26:13 | INFO | fairseq.trainer | begin training epoch 517
2022-03-07 17:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:26:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:28:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:28:39 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 11.189 | ppl 2335.16 | wps 37966 | wpb 510.9 | bsz 1 | num_updates 25171 | best_loss 8.723
2022-03-07 17:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25171 updates
2022-03-07 17:28:39 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-07 17:28:39 | INFO | train | epoch 517 | loss 1.589 | ppl 3.01 | wps 21317.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25171 | lr 0.000199319 | gnorm 0.355 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 74760
2022-03-07 17:28:39 | INFO | fairseq.trainer | begin training epoch 518
2022-03-07 17:28:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:30:02 | INFO | train_inner | epoch 518:     29 / 49 loss=1.589, ppl=3.01, wps=21559.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.353, loss_scale=16, train_wall=266, gb_free=21.5, wall=74844
2022-03-07 17:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:31:05 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 11.164 | ppl 2294.76 | wps 37772.6 | wpb 510.9 | bsz 1 | num_updates 25220 | best_loss 8.723
2022-03-07 17:31:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25220 updates
2022-03-07 17:31:05 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-07 17:31:05 | INFO | train | epoch 518 | loss 1.59 | ppl 3.01 | wps 21747.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25220 | lr 0.000199126 | gnorm 0.353 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 74906
2022-03-07 17:31:05 | INFO | fairseq.trainer | begin training epoch 519
2022-03-07 17:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:33:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:33:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:33:31 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 11.169 | ppl 2302.83 | wps 37839 | wpb 510.9 | bsz 1 | num_updates 25268 | best_loss 8.723
2022-03-07 17:33:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25268 updates
2022-03-07 17:33:31 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-07 17:33:31 | INFO | train | epoch 519 | loss 1.589 | ppl 3.01 | wps 21305.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25268 | lr 0.000198937 | gnorm 0.348 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 75053
2022-03-07 17:33:31 | INFO | fairseq.trainer | begin training epoch 520
2022-03-07 17:33:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:35:03 | INFO | train_inner | epoch 520:     32 / 49 loss=1.589, ppl=3.01, wps=21566.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.351, loss_scale=16, train_wall=265, gb_free=21.5, wall=75145
2022-03-07 17:35:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:35:57 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 11.182 | ppl 2324.04 | wps 37923.9 | wpb 510.9 | bsz 1 | num_updates 25317 | best_loss 8.723
2022-03-07 17:35:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25317 updates
2022-03-07 17:35:57 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-07 17:35:57 | INFO | train | epoch 520 | loss 1.588 | ppl 3.01 | wps 21769.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25317 | lr 0.000198744 | gnorm 0.354 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 75198
2022-03-07 17:35:57 | INFO | fairseq.trainer | begin training epoch 521
2022-03-07 17:35:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:38:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:38:23 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 11.158 | ppl 2285.7 | wps 37873.6 | wpb 510.9 | bsz 1 | num_updates 25366 | best_loss 8.723
2022-03-07 17:38:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25366 updates
2022-03-07 17:38:23 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-07 17:38:23 | INFO | train | epoch 521 | loss 1.588 | ppl 3.01 | wps 21734.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25366 | lr 0.000198552 | gnorm 0.349 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 75345
2022-03-07 17:38:23 | INFO | fairseq.trainer | begin training epoch 522
2022-03-07 17:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:40:01 | INFO | train_inner | epoch 522:     34 / 49 loss=1.588, ppl=3.01, wps=21772.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=25400, lr=0.000198419, gnorm=0.351, loss_scale=32, train_wall=263, gb_free=21.5, wall=75443
2022-03-07 17:40:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:40:49 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 11.177 | ppl 2315.51 | wps 37798.7 | wpb 510.9 | bsz 1 | num_updates 25414 | best_loss 8.723
2022-03-07 17:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25414 updates
2022-03-07 17:40:49 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-07 17:40:49 | INFO | train | epoch 522 | loss 1.588 | ppl 3.01 | wps 21325.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25414 | lr 0.000198364 | gnorm 0.351 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 75491
2022-03-07 17:40:49 | INFO | fairseq.trainer | begin training epoch 523
2022-03-07 17:40:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:43:15 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 11.185 | ppl 2328.71 | wps 37631.1 | wpb 510.9 | bsz 1 | num_updates 25463 | best_loss 8.723
2022-03-07 17:43:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25463 updates
2022-03-07 17:43:15 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-07 17:43:15 | INFO | train | epoch 523 | loss 1.588 | ppl 3.01 | wps 21722.2 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 25463 | lr 0.000198173 | gnorm 0.351 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 75637
2022-03-07 17:43:15 | INFO | fairseq.trainer | begin training epoch 524
2022-03-07 17:43:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:45:02 | INFO | train_inner | epoch 524:     37 / 49 loss=1.588, ppl=3.01, wps=21557.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.35, loss_scale=16, train_wall=266, gb_free=21.5, wall=75744
2022-03-07 17:45:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:45:41 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 11.166 | ppl 2298.13 | wps 37804.5 | wpb 510.9 | bsz 1 | num_updates 25512 | best_loss 8.723
2022-03-07 17:45:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25512 updates
2022-03-07 17:45:41 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-07 17:45:41 | INFO | train | epoch 524 | loss 1.587 | ppl 3.01 | wps 21760.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25512 | lr 0.000197983 | gnorm 0.346 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 75783
2022-03-07 17:45:41 | INFO | fairseq.trainer | begin training epoch 525
2022-03-07 17:45:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:48:07 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 11.192 | ppl 2339.62 | wps 37738.3 | wpb 510.9 | bsz 1 | num_updates 25561 | best_loss 8.723
2022-03-07 17:48:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25561 updates
2022-03-07 17:48:07 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-07 17:48:07 | INFO | train | epoch 525 | loss 1.587 | ppl 3 | wps 21734.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25561 | lr 0.000197793 | gnorm 0.354 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 75929
2022-03-07 17:48:07 | INFO | fairseq.trainer | begin training epoch 526
2022-03-07 17:48:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:50:00 | INFO | train_inner | epoch 526:     39 / 49 loss=1.587, ppl=3, wps=21757, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.35, loss_scale=32, train_wall=263, gb_free=21.5, wall=76042
2022-03-07 17:50:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:50:34 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 11.239 | ppl 2417.08 | wps 37692.3 | wpb 510.9 | bsz 1 | num_updates 25610 | best_loss 8.723
2022-03-07 17:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25610 updates
2022-03-07 17:50:34 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-07 17:50:34 | INFO | train | epoch 526 | loss 1.587 | ppl 3 | wps 21735 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25610 | lr 0.000197604 | gnorm 0.348 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 76075
2022-03-07 17:50:34 | INFO | fairseq.trainer | begin training epoch 527
2022-03-07 17:50:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:51:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:52:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:53:00 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 11.159 | ppl 2286.47 | wps 37865 | wpb 510.9 | bsz 1 | num_updates 25658 | best_loss 8.723
2022-03-07 17:53:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25658 updates
2022-03-07 17:53:00 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-07 17:53:00 | INFO | train | epoch 527 | loss 1.586 | ppl 3 | wps 21305.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25658 | lr 0.000197419 | gnorm 0.348 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 76222
2022-03-07 17:53:00 | INFO | fairseq.trainer | begin training epoch 528
2022-03-07 17:53:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:55:01 | INFO | train_inner | epoch 528:     42 / 49 loss=1.586, ppl=3, wps=21557.7, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.347, loss_scale=16, train_wall=266, gb_free=21.5, wall=76343
2022-03-07 17:55:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:55:26 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 11.213 | ppl 2373.06 | wps 37649.1 | wpb 510.9 | bsz 1 | num_updates 25707 | best_loss 8.723
2022-03-07 17:55:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25707 updates
2022-03-07 17:55:26 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-07 17:55:26 | INFO | train | epoch 528 | loss 1.586 | ppl 3 | wps 21757.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25707 | lr 0.000197231 | gnorm 0.347 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 76368
2022-03-07 17:55:26 | INFO | fairseq.trainer | begin training epoch 529
2022-03-07 17:55:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:57:52 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 11.178 | ppl 2316.27 | wps 37707.4 | wpb 510.9 | bsz 1 | num_updates 25756 | best_loss 8.723
2022-03-07 17:57:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25756 updates
2022-03-07 17:57:52 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-07 17:57:52 | INFO | train | epoch 529 | loss 1.586 | ppl 3 | wps 21754 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25756 | lr 0.000197043 | gnorm 0.357 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 76514
2022-03-07 17:57:52 | INFO | fairseq.trainer | begin training epoch 530
2022-03-07 17:57:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:59:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:00:02 | INFO | train_inner | epoch 530:     45 / 49 loss=1.586, ppl=3, wps=21556.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.353, loss_scale=16, train_wall=265, gb_free=21.5, wall=76644
2022-03-07 18:00:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:00:18 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 11.136 | ppl 2251.01 | wps 37834.6 | wpb 510.9 | bsz 1 | num_updates 25804 | best_loss 8.723
2022-03-07 18:00:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25804 updates
2022-03-07 18:00:18 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-07 18:00:18 | INFO | train | epoch 530 | loss 1.586 | ppl 3 | wps 21289.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25804 | lr 0.00019686 | gnorm 0.349 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 76660
2022-03-07 18:00:18 | INFO | fairseq.trainer | begin training epoch 531
2022-03-07 18:00:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:02:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:02:44 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 11.172 | ppl 2307.18 | wps 37829.4 | wpb 510.9 | bsz 1 | num_updates 25853 | best_loss 8.723
2022-03-07 18:02:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25853 updates
2022-03-07 18:02:44 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-07 18:02:44 | INFO | train | epoch 531 | loss 1.585 | ppl 3 | wps 21760.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25853 | lr 0.000196673 | gnorm 0.349 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 76806
2022-03-07 18:02:44 | INFO | fairseq.trainer | begin training epoch 532
2022-03-07 18:02:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:05:00 | INFO | train_inner | epoch 532:     47 / 49 loss=1.585, ppl=3, wps=21768.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.348, loss_scale=16, train_wall=263, gb_free=21.5, wall=76942
2022-03-07 18:05:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:05:10 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 11.163 | ppl 2293.46 | wps 37982.4 | wpb 510.9 | bsz 1 | num_updates 25902 | best_loss 8.723
2022-03-07 18:05:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25902 updates
2022-03-07 18:05:10 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-07 18:05:10 | INFO | train | epoch 532 | loss 1.585 | ppl 3 | wps 21746.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25902 | lr 0.000196487 | gnorm 0.349 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 76952
2022-03-07 18:05:10 | INFO | fairseq.trainer | begin training epoch 533
2022-03-07 18:05:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:07:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:07:36 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 11.134 | ppl 2248.02 | wps 37482.3 | wpb 510.9 | bsz 1 | num_updates 25951 | best_loss 8.723
2022-03-07 18:07:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25951 updates
2022-03-07 18:07:36 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-07 18:07:36 | INFO | train | epoch 533 | loss 1.585 | ppl 3 | wps 21745.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25951 | lr 0.000196301 | gnorm 0.349 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 77098
2022-03-07 18:07:36 | INFO | fairseq.trainer | begin training epoch 534
2022-03-07 18:07:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:09:57 | INFO | train_inner | epoch 534:     49 / 49 loss=1.585, ppl=3, wps=21771.4, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=26000, lr=0.000196116, gnorm=0.352, loss_scale=32, train_wall=261, gb_free=21.5, wall=77238
2022-03-07 18:09:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:10:03 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 11.124 | ppl 2232.26 | wps 37495.5 | wpb 510.9 | bsz 1 | num_updates 26000 | best_loss 8.723
2022-03-07 18:10:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 26000 updates
2022-03-07 18:10:03 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-07 18:10:03 | INFO | train | epoch 534 | loss 1.584 | ppl 3 | wps 21763 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26000 | lr 0.000196116 | gnorm 0.352 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 77244
2022-03-07 18:10:03 | INFO | fairseq.trainer | begin training epoch 535
2022-03-07 18:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:12:29 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 11.155 | ppl 2280.95 | wps 37867.6 | wpb 510.9 | bsz 1 | num_updates 26048 | best_loss 8.723
2022-03-07 18:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26048 updates
2022-03-07 18:12:29 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-07 18:12:29 | INFO | train | epoch 535 | loss 1.584 | ppl 3 | wps 21296.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26048 | lr 0.000195935 | gnorm 0.352 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 77390
2022-03-07 18:12:29 | INFO | fairseq.trainer | begin training epoch 536
2022-03-07 18:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:14:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:14:55 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 11.157 | ppl 2282.83 | wps 37667 | wpb 510.9 | bsz 1 | num_updates 26097 | best_loss 8.723
2022-03-07 18:14:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26097 updates
2022-03-07 18:14:55 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-07 18:14:55 | INFO | train | epoch 536 | loss 1.584 | ppl 3 | wps 21738.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26097 | lr 0.000195751 | gnorm 0.35 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 77537
2022-03-07 18:14:55 | INFO | fairseq.trainer | begin training epoch 537
2022-03-07 18:14:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:15:04 | INFO | train_inner | epoch 537:      3 / 49 loss=1.584, ppl=3, wps=21133.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.351, loss_scale=16, train_wall=265, gb_free=21.5, wall=77545
2022-03-07 18:17:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:17:21 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 11.176 | ppl 2313.18 | wps 37816.6 | wpb 510.9 | bsz 1 | num_updates 26146 | best_loss 8.723
2022-03-07 18:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26146 updates
2022-03-07 18:17:21 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-07 18:17:21 | INFO | train | epoch 537 | loss 1.583 | ppl 3 | wps 21754.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26146 | lr 0.000195568 | gnorm 0.347 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 77683
2022-03-07 18:17:21 | INFO | fairseq.trainer | begin training epoch 538
2022-03-07 18:17:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:19:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:19:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:19:47 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 11.171 | ppl 2306.26 | wps 37996.3 | wpb 510.9 | bsz 1 | num_updates 26194 | best_loss 8.723
2022-03-07 18:19:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26194 updates
2022-03-07 18:19:47 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-07 18:19:47 | INFO | train | epoch 538 | loss 1.583 | ppl 3 | wps 21297.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26194 | lr 0.000195389 | gnorm 0.351 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 77829
2022-03-07 18:19:47 | INFO | fairseq.trainer | begin training epoch 539
2022-03-07 18:19:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:20:04 | INFO | train_inner | epoch 539:      6 / 49 loss=1.583, ppl=3, wps=21559.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.35, loss_scale=16, train_wall=266, gb_free=21.5, wall=77846
2022-03-07 18:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:22:13 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 11.181 | ppl 2321.16 | wps 37774.6 | wpb 510.9 | bsz 1 | num_updates 26243 | best_loss 8.723
2022-03-07 18:22:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26243 updates
2022-03-07 18:22:13 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-07 18:22:13 | INFO | train | epoch 539 | loss 1.583 | ppl 3 | wps 21763.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26243 | lr 0.000195206 | gnorm 0.35 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 77975
2022-03-07 18:22:13 | INFO | fairseq.trainer | begin training epoch 540
2022-03-07 18:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:24:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:24:39 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 11.158 | ppl 2285.32 | wps 37749 | wpb 510.9 | bsz 1 | num_updates 26292 | best_loss 8.723
2022-03-07 18:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26292 updates
2022-03-07 18:24:39 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-07 18:24:39 | INFO | train | epoch 540 | loss 1.583 | ppl 3 | wps 21741.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26292 | lr 0.000195024 | gnorm 0.35 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 78121
2022-03-07 18:24:39 | INFO | fairseq.trainer | begin training epoch 541
2022-03-07 18:24:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:25:03 | INFO | train_inner | epoch 541:      8 / 49 loss=1.582, ppl=2.99, wps=21768.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.35, loss_scale=16, train_wall=263, gb_free=21.5, wall=78144
2022-03-07 18:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:27:06 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 11.147 | ppl 2267.76 | wps 37636.6 | wpb 510.9 | bsz 1 | num_updates 26341 | best_loss 8.723
2022-03-07 18:27:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26341 updates
2022-03-07 18:27:06 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-07 18:27:06 | INFO | train | epoch 541 | loss 1.582 | ppl 2.99 | wps 21722.6 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 26341 | lr 0.000194843 | gnorm 0.347 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 78267
2022-03-07 18:27:06 | INFO | fairseq.trainer | begin training epoch 542
2022-03-07 18:27:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:29:32 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 11.174 | ppl 2309.9 | wps 37817.1 | wpb 510.9 | bsz 1 | num_updates 26390 | best_loss 8.723
2022-03-07 18:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26390 updates
2022-03-07 18:29:32 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-07 18:29:32 | INFO | train | epoch 542 | loss 1.582 | ppl 2.99 | wps 21757.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26390 | lr 0.000194662 | gnorm 0.347 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 78413
2022-03-07 18:29:32 | INFO | fairseq.trainer | begin training epoch 543
2022-03-07 18:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:30:01 | INFO | train_inner | epoch 543:     10 / 49 loss=1.582, ppl=2.99, wps=21747.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.347, loss_scale=32, train_wall=263, gb_free=21.5, wall=78443
2022-03-07 18:30:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:31:58 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 11.103 | ppl 2199.41 | wps 37799.4 | wpb 510.9 | bsz 1 | num_updates 26438 | best_loss 8.723
2022-03-07 18:31:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26438 updates
2022-03-07 18:31:58 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-07 18:31:58 | INFO | train | epoch 543 | loss 1.582 | ppl 2.99 | wps 21273.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26438 | lr 0.000194485 | gnorm 0.349 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 78560
2022-03-07 18:31:58 | INFO | fairseq.trainer | begin training epoch 544
2022-03-07 18:31:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:34:24 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 11.162 | ppl 2291.98 | wps 37756.7 | wpb 510.9 | bsz 1 | num_updates 26487 | best_loss 8.723
2022-03-07 18:34:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26487 updates
2022-03-07 18:34:24 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-07 18:34:24 | INFO | train | epoch 544 | loss 1.581 | ppl 2.99 | wps 21745 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26487 | lr 0.000194305 | gnorm 0.343 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 78706
2022-03-07 18:34:24 | INFO | fairseq.trainer | begin training epoch 545
2022-03-07 18:34:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:35:02 | INFO | train_inner | epoch 545:     13 / 49 loss=1.581, ppl=2.99, wps=21553.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.345, loss_scale=16, train_wall=266, gb_free=21.5, wall=78744
2022-03-07 18:36:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:36:50 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 11.162 | ppl 2291.8 | wps 37690.3 | wpb 510.9 | bsz 1 | num_updates 26536 | best_loss 8.723
2022-03-07 18:36:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26536 updates
2022-03-07 18:36:50 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-07 18:36:50 | INFO | train | epoch 545 | loss 1.581 | ppl 2.99 | wps 21746.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26536 | lr 0.000194125 | gnorm 0.348 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 78852
2022-03-07 18:36:50 | INFO | fairseq.trainer | begin training epoch 546
2022-03-07 18:36:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:39:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:39:17 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 11.141 | ppl 2257.82 | wps 37819.2 | wpb 510.9 | bsz 1 | num_updates 26585 | best_loss 8.723
2022-03-07 18:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26585 updates
2022-03-07 18:39:17 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-07 18:39:17 | INFO | train | epoch 546 | loss 1.581 | ppl 2.99 | wps 21732 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26585 | lr 0.000193946 | gnorm 0.349 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 78998
2022-03-07 18:39:17 | INFO | fairseq.trainer | begin training epoch 547
2022-03-07 18:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:40:00 | INFO | train_inner | epoch 547:     15 / 49 loss=1.581, ppl=2.99, wps=21760.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.349, loss_scale=32, train_wall=263, gb_free=21.5, wall=79042
2022-03-07 18:41:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:41:43 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 11.144 | ppl 2263.47 | wps 37867.5 | wpb 510.9 | bsz 1 | num_updates 26634 | best_loss 8.723
2022-03-07 18:41:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26634 updates
2022-03-07 18:41:43 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-07 18:41:43 | INFO | train | epoch 547 | loss 1.58 | ppl 2.99 | wps 21764.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26634 | lr 0.000193768 | gnorm 0.344 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 79144
2022-03-07 18:41:43 | INFO | fairseq.trainer | begin training epoch 548
2022-03-07 18:41:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:42:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:43:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:44:09 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 11.147 | ppl 2268.11 | wps 37773.7 | wpb 510.9 | bsz 1 | num_updates 26681 | best_loss 8.723
2022-03-07 18:44:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26681 updates
2022-03-07 18:44:09 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-07 18:44:09 | INFO | train | epoch 548 | loss 1.58 | ppl 2.99 | wps 20859.4 | ups 0.32 | wpb 64829.4 | bsz 126.6 | num_updates 26681 | lr 0.000193597 | gnorm 0.35 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 79290
2022-03-07 18:44:09 | INFO | fairseq.trainer | begin training epoch 549
2022-03-07 18:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:45:03 | INFO | train_inner | epoch 549:     19 / 49 loss=1.58, ppl=2.99, wps=21366.2, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.346, loss_scale=16, train_wall=268, gb_free=21.5, wall=79345
2022-03-07 18:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:46:34 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 11.182 | ppl 2324.14 | wps 38234.7 | wpb 510.9 | bsz 1 | num_updates 26730 | best_loss 8.723
2022-03-07 18:46:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26730 updates
2022-03-07 18:46:34 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-07 18:46:34 | INFO | train | epoch 549 | loss 1.579 | ppl 2.99 | wps 21807.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26730 | lr 0.00019342 | gnorm 0.344 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 79436
2022-03-07 18:46:34 | INFO | fairseq.trainer | begin training epoch 550
2022-03-07 18:46:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:49:00 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 11.171 | ppl 2305.25 | wps 37969.7 | wpb 510.9 | bsz 1 | num_updates 26779 | best_loss 8.723
2022-03-07 18:49:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26779 updates
2022-03-07 18:49:00 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-07 18:49:00 | INFO | train | epoch 550 | loss 1.58 | ppl 2.99 | wps 21825.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26779 | lr 0.000193243 | gnorm 0.349 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 79582
2022-03-07 18:49:00 | INFO | fairseq.trainer | begin training epoch 551
2022-03-07 18:49:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:50:01 | INFO | train_inner | epoch 551:     21 / 49 loss=1.579, ppl=2.99, wps=21837.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.347, loss_scale=32, train_wall=262, gb_free=21.5, wall=79642
2022-03-07 18:50:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:51:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:51:26 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 11.149 | ppl 2270.8 | wps 37679.1 | wpb 510.9 | bsz 1 | num_updates 26827 | best_loss 8.723
2022-03-07 18:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26827 updates
2022-03-07 18:51:26 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-07 18:51:26 | INFO | train | epoch 551 | loss 1.579 | ppl 2.99 | wps 21355 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26827 | lr 0.00019307 | gnorm 0.348 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 79727
2022-03-07 18:51:26 | INFO | fairseq.trainer | begin training epoch 552
2022-03-07 18:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:53:52 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 11.17 | ppl 2304.62 | wps 37739.2 | wpb 510.9 | bsz 1 | num_updates 26876 | best_loss 8.723
2022-03-07 18:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26876 updates
2022-03-07 18:53:52 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-07 18:53:52 | INFO | train | epoch 552 | loss 1.578 | ppl 2.99 | wps 21744.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26876 | lr 0.000192894 | gnorm 0.343 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 79874
2022-03-07 18:53:52 | INFO | fairseq.trainer | begin training epoch 553
2022-03-07 18:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:55:01 | INFO | train_inner | epoch 553:     24 / 49 loss=1.578, ppl=2.99, wps=21572.2, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.345, loss_scale=16, train_wall=265, gb_free=21.5, wall=79943
2022-03-07 18:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:56:18 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 11.151 | ppl 2274.2 | wps 37677.7 | wpb 510.9 | bsz 1 | num_updates 26925 | best_loss 8.723
2022-03-07 18:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26925 updates
2022-03-07 18:56:18 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-07 18:56:18 | INFO | train | epoch 553 | loss 1.578 | ppl 2.99 | wps 21755.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26925 | lr 0.000192718 | gnorm 0.345 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 80020
2022-03-07 18:56:18 | INFO | fairseq.trainer | begin training epoch 554
2022-03-07 18:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:58:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:58:44 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 11.115 | ppl 2217.88 | wps 37746.2 | wpb 510.9 | bsz 1 | num_updates 26974 | best_loss 8.723
2022-03-07 18:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26974 updates
2022-03-07 18:58:44 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-07 18:58:44 | INFO | train | epoch 554 | loss 1.578 | ppl 2.99 | wps 21742.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26974 | lr 0.000192543 | gnorm 0.349 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 80166
2022-03-07 18:58:44 | INFO | fairseq.trainer | begin training epoch 555
2022-03-07 18:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:59:59 | INFO | train_inner | epoch 555:     26 / 49 loss=1.578, ppl=2.99, wps=21770.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.348, loss_scale=32, train_wall=263, gb_free=21.5, wall=80241
2022-03-07 19:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:01:10 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 11.144 | ppl 2262.51 | wps 37851.7 | wpb 510.9 | bsz 1 | num_updates 27023 | best_loss 8.723
2022-03-07 19:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27023 updates
2022-03-07 19:01:10 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-07 19:01:10 | INFO | train | epoch 555 | loss 1.578 | ppl 2.99 | wps 21745.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27023 | lr 0.000192368 | gnorm 0.347 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 80312
2022-03-07 19:01:10 | INFO | fairseq.trainer | begin training epoch 556
2022-03-07 19:01:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:03:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:03:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:03:36 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 11.163 | ppl 2292.72 | wps 37912.8 | wpb 510.9 | bsz 1 | num_updates 27070 | best_loss 8.723
2022-03-07 19:03:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27070 updates
2022-03-07 19:03:36 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-07 19:03:36 | INFO | train | epoch 556 | loss 1.578 | ppl 2.99 | wps 20868.2 | ups 0.32 | wpb 64829.4 | bsz 126.6 | num_updates 27070 | lr 0.000192201 | gnorm 0.349 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 80458
2022-03-07 19:03:36 | INFO | fairseq.trainer | begin training epoch 557
2022-03-07 19:03:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:05:03 | INFO | train_inner | epoch 557:     30 / 49 loss=1.578, ppl=2.99, wps=21347.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.347, loss_scale=16, train_wall=268, gb_free=21.5, wall=80545
2022-03-07 19:05:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:06:02 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 11.172 | ppl 2307.08 | wps 37728.7 | wpb 510.9 | bsz 1 | num_updates 27119 | best_loss 8.723
2022-03-07 19:06:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27119 updates
2022-03-07 19:06:03 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-07 19:06:03 | INFO | train | epoch 557 | loss 1.577 | ppl 2.98 | wps 21731.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27119 | lr 0.000192027 | gnorm 0.344 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 80604
2022-03-07 19:06:03 | INFO | fairseq.trainer | begin training epoch 558
2022-03-07 19:06:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:08:29 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 11.167 | ppl 2299.91 | wps 37685.3 | wpb 510.9 | bsz 1 | num_updates 27168 | best_loss 8.723
2022-03-07 19:08:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27168 updates
2022-03-07 19:08:29 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-07 19:08:29 | INFO | train | epoch 558 | loss 1.577 | ppl 2.98 | wps 21751.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27168 | lr 0.000191854 | gnorm 0.344 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 80750
2022-03-07 19:08:29 | INFO | fairseq.trainer | begin training epoch 559
2022-03-07 19:08:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:10:01 | INFO | train_inner | epoch 559:     32 / 49 loss=1.577, ppl=2.98, wps=21764.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.343, loss_scale=32, train_wall=263, gb_free=21.5, wall=80843
2022-03-07 19:10:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:10:55 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 11.144 | ppl 2263.43 | wps 37918.9 | wpb 510.9 | bsz 1 | num_updates 27217 | best_loss 8.723
2022-03-07 19:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27217 updates
2022-03-07 19:10:55 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-07 19:10:55 | INFO | train | epoch 559 | loss 1.577 | ppl 2.98 | wps 21741 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27217 | lr 0.000191681 | gnorm 0.345 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 80897
2022-03-07 19:10:55 | INFO | fairseq.trainer | begin training epoch 560
2022-03-07 19:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:11:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:13:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:13:21 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 11.126 | ppl 2235.48 | wps 37733.8 | wpb 510.9 | bsz 1 | num_updates 27265 | best_loss 8.723
2022-03-07 19:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27265 updates
2022-03-07 19:13:21 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-07 19:13:21 | INFO | train | epoch 560 | loss 1.576 | ppl 2.98 | wps 21286.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27265 | lr 0.000191513 | gnorm 0.345 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 81043
2022-03-07 19:13:21 | INFO | fairseq.trainer | begin training epoch 561
2022-03-07 19:13:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:15:02 | INFO | train_inner | epoch 561:     35 / 49 loss=1.576, ppl=2.98, wps=21550.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.344, loss_scale=16, train_wall=266, gb_free=21.5, wall=81144
2022-03-07 19:15:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:15:47 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 11.156 | ppl 2282.18 | wps 37911 | wpb 510.9 | bsz 1 | num_updates 27314 | best_loss 8.723
2022-03-07 19:15:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27314 updates
2022-03-07 19:15:47 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-07 19:15:47 | INFO | train | epoch 561 | loss 1.576 | ppl 2.98 | wps 21759 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27314 | lr 0.000191341 | gnorm 0.344 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 81189
2022-03-07 19:15:47 | INFO | fairseq.trainer | begin training epoch 562
2022-03-07 19:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:18:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:18:13 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 11.115 | ppl 2218.48 | wps 37849.1 | wpb 510.9 | bsz 1 | num_updates 27363 | best_loss 8.723
2022-03-07 19:18:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27363 updates
2022-03-07 19:18:13 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-07 19:18:13 | INFO | train | epoch 562 | loss 1.577 | ppl 2.98 | wps 21733.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27363 | lr 0.000191169 | gnorm 0.346 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 81335
2022-03-07 19:18:13 | INFO | fairseq.trainer | begin training epoch 563
2022-03-07 19:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:18:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:20:03 | INFO | train_inner | epoch 563:     38 / 49 loss=1.577, ppl=2.98, wps=21561.4, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.346, loss_scale=16, train_wall=266, gb_free=21.5, wall=81445
2022-03-07 19:20:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:20:39 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 11.117 | ppl 2221.38 | wps 37767.3 | wpb 510.9 | bsz 1 | num_updates 27411 | best_loss 8.723
2022-03-07 19:20:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27411 updates
2022-03-07 19:20:39 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-07 19:20:39 | INFO | train | epoch 563 | loss 1.576 | ppl 2.98 | wps 21318.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27411 | lr 0.000191002 | gnorm 0.344 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 81481
2022-03-07 19:20:39 | INFO | fairseq.trainer | begin training epoch 564
2022-03-07 19:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:23:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:23:05 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 11.093 | ppl 2184.43 | wps 37893.5 | wpb 510.9 | bsz 1 | num_updates 27460 | best_loss 8.723
2022-03-07 19:23:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27460 updates
2022-03-07 19:23:05 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-07 19:23:05 | INFO | train | epoch 564 | loss 1.576 | ppl 2.98 | wps 21755.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27460 | lr 0.000190831 | gnorm 0.342 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 81627
2022-03-07 19:23:05 | INFO | fairseq.trainer | begin training epoch 565
2022-03-07 19:23:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:25:01 | INFO | train_inner | epoch 565:     40 / 49 loss=1.575, ppl=2.98, wps=21766.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.342, loss_scale=32, train_wall=263, gb_free=21.5, wall=81743
2022-03-07 19:25:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:25:32 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 11.17 | ppl 2303.69 | wps 37967.1 | wpb 510.9 | bsz 1 | num_updates 27509 | best_loss 8.723
2022-03-07 19:25:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27509 updates
2022-03-07 19:25:32 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-07 19:25:32 | INFO | train | epoch 565 | loss 1.575 | ppl 2.98 | wps 21741.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27509 | lr 0.000190661 | gnorm 0.341 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 81773
2022-03-07 19:25:32 | INFO | fairseq.trainer | begin training epoch 566
2022-03-07 19:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:26:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:27:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:27:58 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 11.162 | ppl 2291.46 | wps 37839.9 | wpb 510.9 | bsz 1 | num_updates 27557 | best_loss 8.723
2022-03-07 19:27:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27557 updates
2022-03-07 19:27:58 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-07 19:27:58 | INFO | train | epoch 566 | loss 1.574 | ppl 2.98 | wps 21308.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27557 | lr 0.000190495 | gnorm 0.34 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 81919
2022-03-07 19:27:58 | INFO | fairseq.trainer | begin training epoch 567
2022-03-07 19:27:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:30:02 | INFO | train_inner | epoch 567:     43 / 49 loss=1.574, ppl=2.98, wps=21563.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.339, loss_scale=16, train_wall=265, gb_free=21.5, wall=82044
2022-03-07 19:30:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:30:24 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 11.138 | ppl 2252.88 | wps 37889 | wpb 510.9 | bsz 1 | num_updates 27606 | best_loss 8.723
2022-03-07 19:30:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27606 updates
2022-03-07 19:30:24 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-07 19:30:24 | INFO | train | epoch 567 | loss 1.574 | ppl 2.98 | wps 21754.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27606 | lr 0.000190326 | gnorm 0.34 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 82065
2022-03-07 19:30:24 | INFO | fairseq.trainer | begin training epoch 568
2022-03-07 19:30:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:32:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:32:50 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 11.147 | ppl 2268.36 | wps 37762.1 | wpb 510.9 | bsz 1 | num_updates 27655 | best_loss 8.723
2022-03-07 19:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27655 updates
2022-03-07 19:32:50 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-07 19:32:50 | INFO | train | epoch 568 | loss 1.575 | ppl 2.98 | wps 21753.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27655 | lr 0.000190157 | gnorm 0.344 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 82212
2022-03-07 19:32:50 | INFO | fairseq.trainer | begin training epoch 569
2022-03-07 19:32:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:35:00 | INFO | train_inner | epoch 569:     45 / 49 loss=1.574, ppl=2.98, wps=21773.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.343, loss_scale=32, train_wall=263, gb_free=21.5, wall=82342
2022-03-07 19:35:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:35:16 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 11.142 | ppl 2260.24 | wps 37829.2 | wpb 510.9 | bsz 1 | num_updates 27704 | best_loss 8.723
2022-03-07 19:35:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27704 updates
2022-03-07 19:35:16 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-07 19:35:16 | INFO | train | epoch 569 | loss 1.574 | ppl 2.98 | wps 21756.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27704 | lr 0.000189989 | gnorm 0.342 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 82358
2022-03-07 19:35:16 | INFO | fairseq.trainer | begin training epoch 570
2022-03-07 19:35:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:35:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:37:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:37:42 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 11.148 | ppl 2269.62 | wps 37598 | wpb 510.9 | bsz 1 | num_updates 27752 | best_loss 8.723
2022-03-07 19:37:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27752 updates
2022-03-07 19:37:42 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-07 19:37:42 | INFO | train | epoch 570 | loss 1.574 | ppl 2.98 | wps 21277.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27752 | lr 0.000189825 | gnorm 0.34 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 82504
2022-03-07 19:37:42 | INFO | fairseq.trainer | begin training epoch 571
2022-03-07 19:37:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:40:01 | INFO | train_inner | epoch 571:     48 / 49 loss=1.574, ppl=2.98, wps=21538.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.34, loss_scale=16, train_wall=266, gb_free=21.5, wall=82643
2022-03-07 19:40:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:40:08 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 11.118 | ppl 2222.34 | wps 37705.1 | wpb 510.9 | bsz 1 | num_updates 27801 | best_loss 8.723
2022-03-07 19:40:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27801 updates
2022-03-07 19:40:08 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-07 19:40:08 | INFO | train | epoch 571 | loss 1.573 | ppl 2.98 | wps 21727.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27801 | lr 0.000189657 | gnorm 0.34 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 82650
2022-03-07 19:40:08 | INFO | fairseq.trainer | begin training epoch 572
2022-03-07 19:40:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:42:35 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 11.122 | ppl 2229.38 | wps 37859.8 | wpb 510.9 | bsz 1 | num_updates 27850 | best_loss 8.723
2022-03-07 19:42:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27850 updates
2022-03-07 19:42:35 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-07 19:42:35 | INFO | train | epoch 572 | loss 1.573 | ppl 2.97 | wps 21743.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27850 | lr 0.00018949 | gnorm 0.341 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 82796
2022-03-07 19:42:35 | INFO | fairseq.trainer | begin training epoch 573
2022-03-07 19:42:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:45:01 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 11.149 | ppl 2270.78 | wps 37689.7 | wpb 510.9 | bsz 1 | num_updates 27899 | best_loss 8.723
2022-03-07 19:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27899 updates
2022-03-07 19:45:01 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-07 19:45:01 | INFO | train | epoch 573 | loss 1.572 | ppl 2.97 | wps 21751.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27899 | lr 0.000189324 | gnorm 0.34 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 82942
2022-03-07 19:45:01 | INFO | fairseq.trainer | begin training epoch 574
2022-03-07 19:45:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:45:04 | INFO | train_inner | epoch 574:      1 / 49 loss=1.572, ppl=2.97, wps=21333.3, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=27900, lr=0.000189321, gnorm=0.341, loss_scale=32, train_wall=262, gb_free=21.5, wall=82945
2022-03-07 19:47:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:47:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:47:27 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 11.168 | ppl 2301.18 | wps 37771.3 | wpb 510.9 | bsz 1 | num_updates 27947 | best_loss 8.723
2022-03-07 19:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27947 updates
2022-03-07 19:47:27 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-07 19:47:27 | INFO | train | epoch 574 | loss 1.573 | ppl 2.97 | wps 21297.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27947 | lr 0.000189161 | gnorm 0.341 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 83089
2022-03-07 19:47:27 | INFO | fairseq.trainer | begin training epoch 575
2022-03-07 19:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:49:53 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 11.175 | ppl 2311.48 | wps 37674 | wpb 510.9 | bsz 1 | num_updates 27996 | best_loss 8.723
2022-03-07 19:49:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27996 updates
2022-03-07 19:49:53 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-07 19:49:53 | INFO | train | epoch 575 | loss 1.572 | ppl 2.97 | wps 21750.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27996 | lr 0.000188996 | gnorm 0.344 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 83235
2022-03-07 19:49:53 | INFO | fairseq.trainer | begin training epoch 576
2022-03-07 19:49:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:50:05 | INFO | train_inner | epoch 576:      4 / 49 loss=1.572, ppl=2.97, wps=21555.8, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.342, loss_scale=16, train_wall=266, gb_free=21.5, wall=83246
2022-03-07 19:52:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:52:19 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 11.149 | ppl 2270.38 | wps 37799.6 | wpb 510.9 | bsz 1 | num_updates 28045 | best_loss 8.723
2022-03-07 19:52:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28045 updates
2022-03-07 19:52:19 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-07 19:52:19 | INFO | train | epoch 576 | loss 1.572 | ppl 2.97 | wps 21746.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28045 | lr 0.000188831 | gnorm 0.343 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 83381
2022-03-07 19:52:19 | INFO | fairseq.trainer | begin training epoch 577
2022-03-07 19:52:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:54:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:54:45 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 11.173 | ppl 2308.55 | wps 37835.2 | wpb 510.9 | bsz 1 | num_updates 28094 | best_loss 8.723
2022-03-07 19:54:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28094 updates
2022-03-07 19:54:45 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-07 19:54:45 | INFO | train | epoch 577 | loss 1.572 | ppl 2.97 | wps 21732.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28094 | lr 0.000188666 | gnorm 0.345 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 83527
2022-03-07 19:54:45 | INFO | fairseq.trainer | begin training epoch 578
2022-03-07 19:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:55:03 | INFO | train_inner | epoch 578:      6 / 49 loss=1.572, ppl=2.97, wps=21759.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.345, loss_scale=32, train_wall=263, gb_free=21.5, wall=83545
2022-03-07 19:56:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:57:11 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 11.117 | ppl 2221.41 | wps 37699.7 | wpb 510.9 | bsz 1 | num_updates 28142 | best_loss 8.723
2022-03-07 19:57:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28142 updates
2022-03-07 19:57:11 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-07 19:57:11 | INFO | train | epoch 578 | loss 1.572 | ppl 2.97 | wps 21314.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28142 | lr 0.000188505 | gnorm 0.343 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 83673
2022-03-07 19:57:11 | INFO | fairseq.trainer | begin training epoch 579
2022-03-07 19:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:59:38 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 11.125 | ppl 2233.18 | wps 37861.5 | wpb 510.9 | bsz 1 | num_updates 28191 | best_loss 8.723
2022-03-07 19:59:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28191 updates
2022-03-07 19:59:38 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-07 19:59:38 | INFO | train | epoch 579 | loss 1.572 | ppl 2.97 | wps 21745.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28191 | lr 0.000188341 | gnorm 0.343 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 83819
2022-03-07 19:59:38 | INFO | fairseq.trainer | begin training epoch 580
2022-03-07 19:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:00:04 | INFO | train_inner | epoch 580:      9 / 49 loss=1.571, ppl=2.97, wps=21565.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.343, loss_scale=16, train_wall=265, gb_free=21.5, wall=83845
2022-03-07 20:01:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:02:04 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 11.095 | ppl 2187.18 | wps 37749.6 | wpb 510.9 | bsz 1 | num_updates 28240 | best_loss 8.723
2022-03-07 20:02:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28240 updates
2022-03-07 20:02:04 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-07 20:02:04 | INFO | train | epoch 580 | loss 1.571 | ppl 2.97 | wps 21760.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28240 | lr 0.000188177 | gnorm 0.344 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 83965
2022-03-07 20:02:04 | INFO | fairseq.trainer | begin training epoch 581
2022-03-07 20:02:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:04:30 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 11.108 | ppl 2207.79 | wps 37972.9 | wpb 510.9 | bsz 1 | num_updates 28289 | best_loss 8.723
2022-03-07 20:04:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28289 updates
2022-03-07 20:04:30 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-07 20:04:30 | INFO | train | epoch 581 | loss 1.571 | ppl 2.97 | wps 21747.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28289 | lr 0.000188014 | gnorm 0.341 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 84111
2022-03-07 20:04:30 | INFO | fairseq.trainer | begin training epoch 582
2022-03-07 20:04:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:04:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:05:04 | INFO | train_inner | epoch 582:     12 / 49 loss=1.571, ppl=2.97, wps=21560.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.342, loss_scale=16, train_wall=266, gb_free=21.5, wall=84146
2022-03-07 20:06:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:06:56 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 11.136 | ppl 2250.92 | wps 37944.1 | wpb 510.9 | bsz 1 | num_updates 28337 | best_loss 8.723
2022-03-07 20:06:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28337 updates
2022-03-07 20:06:56 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-07 20:06:56 | INFO | train | epoch 582 | loss 1.57 | ppl 2.97 | wps 21283.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28337 | lr 0.000187855 | gnorm 0.34 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 84258
2022-03-07 20:06:56 | INFO | fairseq.trainer | begin training epoch 583
2022-03-07 20:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:09:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:09:22 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 11.122 | ppl 2228.63 | wps 37737.3 | wpb 510.9 | bsz 1 | num_updates 28386 | best_loss 8.723
2022-03-07 20:09:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28386 updates
2022-03-07 20:09:22 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-07 20:09:22 | INFO | train | epoch 583 | loss 1.571 | ppl 2.97 | wps 21746.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28386 | lr 0.000187693 | gnorm 0.345 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 84404
2022-03-07 20:09:22 | INFO | fairseq.trainer | begin training epoch 584
2022-03-07 20:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:10:03 | INFO | train_inner | epoch 584:     14 / 49 loss=1.57, ppl=2.97, wps=21751.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.342, loss_scale=16, train_wall=263, gb_free=21.5, wall=84444
2022-03-07 20:11:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:11:48 | INFO | valid | epoch 584 | valid on 'valid' subset | loss 11.122 | ppl 2228.72 | wps 37857.2 | wpb 510.9 | bsz 1 | num_updates 28435 | best_loss 8.723
2022-03-07 20:11:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 28435 updates
2022-03-07 20:11:48 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2022-03-07 20:11:48 | INFO | train | epoch 584 | loss 1.57 | ppl 2.97 | wps 21727.2 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 28435 | lr 0.000187531 | gnorm 0.339 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 84550
2022-03-07 20:11:48 | INFO | fairseq.trainer | begin training epoch 585
2022-03-07 20:11:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:14:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:14:14 | INFO | valid | epoch 585 | valid on 'valid' subset | loss 11.09 | ppl 2180.39 | wps 37942.7 | wpb 510.9 | bsz 1 | num_updates 28484 | best_loss 8.723
2022-03-07 20:14:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 28484 updates
2022-03-07 20:14:14 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2022-03-07 20:14:14 | INFO | train | epoch 585 | loss 1.57 | ppl 2.97 | wps 21757 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28484 | lr 0.00018737 | gnorm 0.338 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 84696
2022-03-07 20:14:14 | INFO | fairseq.trainer | begin training epoch 586
2022-03-07 20:14:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:15:01 | INFO | train_inner | epoch 586:     16 / 49 loss=1.57, ppl=2.97, wps=21767.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=28500, lr=0.000187317, gnorm=0.34, loss_scale=32, train_wall=263, gb_free=21.5, wall=84742
2022-03-07 20:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:16:40 | INFO | valid | epoch 586 | valid on 'valid' subset | loss 11.142 | ppl 2259.21 | wps 37594.9 | wpb 510.9 | bsz 1 | num_updates 28533 | best_loss 8.723
2022-03-07 20:16:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 28533 updates
2022-03-07 20:16:40 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2022-03-07 20:16:40 | INFO | train | epoch 586 | loss 1.57 | ppl 2.97 | wps 21767.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28533 | lr 0.000187209 | gnorm 0.339 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 84842
2022-03-07 20:16:40 | INFO | fairseq.trainer | begin training epoch 587
2022-03-07 20:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:17:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:19:07 | INFO | valid | epoch 587 | valid on 'valid' subset | loss 11.115 | ppl 2218.42 | wps 37674.5 | wpb 510.9 | bsz 1 | num_updates 28581 | best_loss 8.723
2022-03-07 20:19:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 28581 updates
2022-03-07 20:19:07 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2022-03-07 20:19:07 | INFO | train | epoch 587 | loss 1.569 | ppl 2.97 | wps 21293.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28581 | lr 0.000187052 | gnorm 0.345 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 84988
2022-03-07 20:19:07 | INFO | fairseq.trainer | begin training epoch 588
2022-03-07 20:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:20:02 | INFO | train_inner | epoch 588:     19 / 49 loss=1.569, ppl=2.97, wps=21564.8, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=28600, lr=0.000186989, gnorm=0.34, loss_scale=32, train_wall=265, gb_free=21.5, wall=85043
2022-03-07 20:21:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:21:33 | INFO | valid | epoch 588 | valid on 'valid' subset | loss 11.106 | ppl 2204.75 | wps 37384.5 | wpb 510.9 | bsz 1 | num_updates 28630 | best_loss 8.723
2022-03-07 20:21:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 28630 updates
2022-03-07 20:21:33 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2022-03-07 20:21:33 | INFO | train | epoch 588 | loss 1.569 | ppl 2.97 | wps 21749.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28630 | lr 0.000186891 | gnorm 0.338 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 85134
2022-03-07 20:21:33 | INFO | fairseq.trainer | begin training epoch 589
2022-03-07 20:21:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:22:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:23:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:23:59 | INFO | valid | epoch 589 | valid on 'valid' subset | loss 11.116 | ppl 2220.07 | wps 37672.4 | wpb 510.9 | bsz 1 | num_updates 28678 | best_loss 8.723
2022-03-07 20:23:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 28678 updates
2022-03-07 20:23:59 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2022-03-07 20:23:59 | INFO | train | epoch 589 | loss 1.568 | ppl 2.96 | wps 21332.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28678 | lr 0.000186735 | gnorm 0.337 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 85280
2022-03-07 20:23:59 | INFO | fairseq.trainer | begin training epoch 590
2022-03-07 20:23:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:25:02 | INFO | train_inner | epoch 590:     22 / 49 loss=1.568, ppl=2.96, wps=21567.6, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=28700, lr=0.000186663, gnorm=0.336, loss_scale=16, train_wall=265, gb_free=21.5, wall=85344
2022-03-07 20:26:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:26:25 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 11.095 | ppl 2186.9 | wps 37859.5 | wpb 510.9 | bsz 1 | num_updates 28727 | best_loss 8.723
2022-03-07 20:26:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 28727 updates
2022-03-07 20:26:25 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2022-03-07 20:26:25 | INFO | train | epoch 590 | loss 1.568 | ppl 2.96 | wps 21747.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28727 | lr 0.000186576 | gnorm 0.338 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 85426
2022-03-07 20:26:25 | INFO | fairseq.trainer | begin training epoch 591
2022-03-07 20:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:28:51 | INFO | valid | epoch 591 | valid on 'valid' subset | loss 11.104 | ppl 2201.48 | wps 37991.5 | wpb 510.9 | bsz 1 | num_updates 28776 | best_loss 8.723
2022-03-07 20:28:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 591 @ 28776 updates
2022-03-07 20:28:51 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)
2022-03-07 20:28:51 | INFO | train | epoch 591 | loss 1.568 | ppl 2.97 | wps 21750.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28776 | lr 0.000186417 | gnorm 0.339 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 85573
2022-03-07 20:28:51 | INFO | fairseq.trainer | begin training epoch 592
2022-03-07 20:28:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:30:03 | INFO | train_inner | epoch 592:     25 / 49 loss=1.568, ppl=2.97, wps=21566.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=28800, lr=0.000186339, gnorm=0.34, loss_scale=16, train_wall=265, gb_free=21.5, wall=85645
2022-03-07 20:31:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:31:17 | INFO | valid | epoch 592 | valid on 'valid' subset | loss 11.125 | ppl 2234.04 | wps 37741.6 | wpb 510.9 | bsz 1 | num_updates 28824 | best_loss 8.723
2022-03-07 20:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 592 @ 28824 updates
2022-03-07 20:31:17 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)
2022-03-07 20:31:17 | INFO | train | epoch 592 | loss 1.568 | ppl 2.97 | wps 21306.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28824 | lr 0.000186261 | gnorm 0.34 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 85719
2022-03-07 20:31:17 | INFO | fairseq.trainer | begin training epoch 593
2022-03-07 20:31:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:33:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:33:43 | INFO | valid | epoch 593 | valid on 'valid' subset | loss 11.118 | ppl 2221.99 | wps 37826.9 | wpb 510.9 | bsz 1 | num_updates 28873 | best_loss 8.723
2022-03-07 20:33:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 593 @ 28873 updates
2022-03-07 20:33:43 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)
2022-03-07 20:33:43 | INFO | train | epoch 593 | loss 1.568 | ppl 2.96 | wps 21763.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28873 | lr 0.000186103 | gnorm 0.337 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 85865
2022-03-07 20:33:43 | INFO | fairseq.trainer | begin training epoch 594
2022-03-07 20:33:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:35:01 | INFO | train_inner | epoch 594:     27 / 49 loss=1.567, ppl=2.96, wps=21767.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=28900, lr=0.000186016, gnorm=0.338, loss_scale=16, train_wall=263, gb_free=21.5, wall=85943
2022-03-07 20:36:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:36:09 | INFO | valid | epoch 594 | valid on 'valid' subset | loss 11.096 | ppl 2189.3 | wps 38028.8 | wpb 510.9 | bsz 1 | num_updates 28922 | best_loss 8.723
2022-03-07 20:36:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 594 @ 28922 updates
2022-03-07 20:36:09 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)
2022-03-07 20:36:09 | INFO | train | epoch 594 | loss 1.568 | ppl 2.96 | wps 21747.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28922 | lr 0.000185946 | gnorm 0.338 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 86011
2022-03-07 20:36:09 | INFO | fairseq.trainer | begin training epoch 595
2022-03-07 20:36:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:38:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:38:35 | INFO | valid | epoch 595 | valid on 'valid' subset | loss 11.118 | ppl 2222.95 | wps 37880.3 | wpb 510.9 | bsz 1 | num_updates 28971 | best_loss 8.723
2022-03-07 20:38:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 595 @ 28971 updates
2022-03-07 20:38:35 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)
2022-03-07 20:38:35 | INFO | train | epoch 595 | loss 1.567 | ppl 2.96 | wps 21735.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28971 | lr 0.000185788 | gnorm 0.337 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86157
2022-03-07 20:38:35 | INFO | fairseq.trainer | begin training epoch 596
2022-03-07 20:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:39:59 | INFO | train_inner | epoch 596:     29 / 49 loss=1.567, ppl=2.96, wps=21767.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=29000, lr=0.000185695, gnorm=0.338, loss_scale=32, train_wall=263, gb_free=21.5, wall=86241
2022-03-07 20:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:41:01 | INFO | valid | epoch 596 | valid on 'valid' subset | loss 11.122 | ppl 2228.21 | wps 37894.4 | wpb 510.9 | bsz 1 | num_updates 29020 | best_loss 8.723
2022-03-07 20:41:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 596 @ 29020 updates
2022-03-07 20:41:01 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)
2022-03-07 20:41:01 | INFO | train | epoch 596 | loss 1.567 | ppl 2.96 | wps 21772.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29020 | lr 0.000185631 | gnorm 0.342 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86303
2022-03-07 20:41:01 | INFO | fairseq.trainer | begin training epoch 597
2022-03-07 20:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:42:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:43:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:43:28 | INFO | valid | epoch 597 | valid on 'valid' subset | loss 11.113 | ppl 2215.35 | wps 37727.1 | wpb 510.9 | bsz 1 | num_updates 29068 | best_loss 8.723
2022-03-07 20:43:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 597 @ 29068 updates
2022-03-07 20:43:28 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)
2022-03-07 20:43:28 | INFO | train | epoch 597 | loss 1.566 | ppl 2.96 | wps 21276.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29068 | lr 0.000185478 | gnorm 0.339 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86449
2022-03-07 20:43:28 | INFO | fairseq.trainer | begin training epoch 598
2022-03-07 20:43:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:45:00 | INFO | train_inner | epoch 598:     32 / 49 loss=1.567, ppl=2.96, wps=21557.5, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=29100, lr=0.000185376, gnorm=0.339, loss_scale=32, train_wall=266, gb_free=21.5, wall=86542
2022-03-07 20:45:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:45:54 | INFO | valid | epoch 598 | valid on 'valid' subset | loss 11.14 | ppl 2256.4 | wps 37627.6 | wpb 510.9 | bsz 1 | num_updates 29117 | best_loss 8.723
2022-03-07 20:45:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 598 @ 29117 updates
2022-03-07 20:45:54 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)
2022-03-07 20:45:54 | INFO | train | epoch 598 | loss 1.566 | ppl 2.96 | wps 21746.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29117 | lr 0.000185322 | gnorm 0.336 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86595
2022-03-07 20:45:54 | INFO | fairseq.trainer | begin training epoch 599
2022-03-07 20:45:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:48:20 | INFO | valid | epoch 599 | valid on 'valid' subset | loss 11.159 | ppl 2286 | wps 37693 | wpb 510.9 | bsz 1 | num_updates 29166 | best_loss 8.723
2022-03-07 20:48:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 599 @ 29166 updates
2022-03-07 20:48:20 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)
2022-03-07 20:48:20 | INFO | train | epoch 599 | loss 1.566 | ppl 2.96 | wps 21728.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29166 | lr 0.000185166 | gnorm 0.335 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86742
2022-03-07 20:48:20 | INFO | fairseq.trainer | begin training epoch 600
2022-03-07 20:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:49:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:50:01 | INFO | train_inner | epoch 600:     35 / 49 loss=1.566, ppl=2.96, wps=21538.9, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=29200, lr=0.000185058, gnorm=0.334, loss_scale=32, train_wall=266, gb_free=21.5, wall=86843
2022-03-07 20:50:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:50:46 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 11.172 | ppl 2306.56 | wps 37857.6 | wpb 510.9 | bsz 1 | num_updates 29214 | best_loss 8.723
2022-03-07 20:50:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 29214 updates
2022-03-07 20:50:46 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)
2022-03-07 20:50:46 | INFO | train | epoch 600 | loss 1.566 | ppl 2.96 | wps 21287.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29214 | lr 0.000185014 | gnorm 0.335 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 86888
2022-03-07 20:50:46 | INFO | fairseq.trainer | begin training epoch 601
2022-03-07 20:50:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:52:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:53:12 | INFO | valid | epoch 601 | valid on 'valid' subset | loss 11.158 | ppl 2285.08 | wps 37735.2 | wpb 510.9 | bsz 1 | num_updates 29262 | best_loss 8.723
2022-03-07 20:53:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 601 @ 29262 updates
2022-03-07 20:53:12 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)
2022-03-07 20:53:12 | INFO | train | epoch 601 | loss 1.566 | ppl 2.96 | wps 21300.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29262 | lr 0.000184862 | gnorm 0.34 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 87034
2022-03-07 20:53:12 | INFO | fairseq.trainer | begin training epoch 602
2022-03-07 20:53:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:55:02 | INFO | train_inner | epoch 602:     38 / 49 loss=1.566, ppl=2.96, wps=21555.2, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=29300, lr=0.000184742, gnorm=0.339, loss_scale=16, train_wall=266, gb_free=21.5, wall=87144
2022-03-07 20:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:55:38 | INFO | valid | epoch 602 | valid on 'valid' subset | loss 11.114 | ppl 2215.86 | wps 37796.7 | wpb 510.9 | bsz 1 | num_updates 29311 | best_loss 8.723
2022-03-07 20:55:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 602 @ 29311 updates
2022-03-07 20:55:38 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)
2022-03-07 20:55:38 | INFO | train | epoch 602 | loss 1.565 | ppl 2.96 | wps 21747.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29311 | lr 0.000184708 | gnorm 0.338 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 87180
2022-03-07 20:55:38 | INFO | fairseq.trainer | begin training epoch 603
2022-03-07 20:55:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:58:05 | INFO | valid | epoch 603 | valid on 'valid' subset | loss 11.118 | ppl 2222.48 | wps 37623.9 | wpb 510.9 | bsz 1 | num_updates 29360 | best_loss 8.723
2022-03-07 20:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 603 @ 29360 updates
2022-03-07 20:58:05 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)
2022-03-07 20:58:05 | INFO | train | epoch 603 | loss 1.565 | ppl 2.96 | wps 21738.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29360 | lr 0.000184553 | gnorm 0.338 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 87326
2022-03-07 20:58:05 | INFO | fairseq.trainer | begin training epoch 604
2022-03-07 20:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:00:01 | INFO | train_inner | epoch 604:     40 / 49 loss=1.565, ppl=2.96, wps=21747.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=29400, lr=0.000184428, gnorm=0.337, loss_scale=32, train_wall=263, gb_free=21.5, wall=87442
2022-03-07 21:00:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:00:31 | INFO | valid | epoch 604 | valid on 'valid' subset | loss 11.117 | ppl 2221.33 | wps 38020.3 | wpb 510.9 | bsz 1 | num_updates 29409 | best_loss 8.723
2022-03-07 21:00:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 604 @ 29409 updates
2022-03-07 21:00:31 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)
2022-03-07 21:00:31 | INFO | train | epoch 604 | loss 1.564 | ppl 2.96 | wps 21725.9 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 29409 | lr 0.0001844 | gnorm 0.334 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 87473
2022-03-07 21:00:31 | INFO | fairseq.trainer | begin training epoch 605
2022-03-07 21:00:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:02:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:02:57 | INFO | valid | epoch 605 | valid on 'valid' subset | loss 11.13 | ppl 2240.7 | wps 37807.3 | wpb 510.9 | bsz 1 | num_updates 29457 | best_loss 8.723
2022-03-07 21:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 605 @ 29457 updates
2022-03-07 21:02:57 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)
2022-03-07 21:02:57 | INFO | train | epoch 605 | loss 1.564 | ppl 2.96 | wps 21313.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29457 | lr 0.000184249 | gnorm 0.335 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 87619
2022-03-07 21:02:57 | INFO | fairseq.trainer | begin training epoch 606
2022-03-07 21:02:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:05:01 | INFO | train_inner | epoch 606:     43 / 49 loss=1.564, ppl=2.96, wps=21564.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=29500, lr=0.000184115, gnorm=0.334, loss_scale=16, train_wall=266, gb_free=21.5, wall=87743
2022-03-07 21:05:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:05:23 | INFO | valid | epoch 606 | valid on 'valid' subset | loss 11.126 | ppl 2234.75 | wps 38047.9 | wpb 510.9 | bsz 1 | num_updates 29506 | best_loss 8.723
2022-03-07 21:05:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 606 @ 29506 updates
2022-03-07 21:05:23 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)
2022-03-07 21:05:23 | INFO | train | epoch 606 | loss 1.565 | ppl 2.96 | wps 21746.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29506 | lr 0.000184096 | gnorm 0.335 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 87765
2022-03-07 21:05:23 | INFO | fairseq.trainer | begin training epoch 607
2022-03-07 21:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:07:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:07:49 | INFO | valid | epoch 607 | valid on 'valid' subset | loss 11.163 | ppl 2292.86 | wps 37487 | wpb 510.9 | bsz 1 | num_updates 29555 | best_loss 8.723
2022-03-07 21:07:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 607 @ 29555 updates
2022-03-07 21:07:49 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)
2022-03-07 21:07:49 | INFO | train | epoch 607 | loss 1.564 | ppl 2.96 | wps 21729.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29555 | lr 0.000183944 | gnorm 0.336 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 87911
2022-03-07 21:07:49 | INFO | fairseq.trainer | begin training epoch 608
2022-03-07 21:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:09:59 | INFO | train_inner | epoch 608:     45 / 49 loss=1.564, ppl=2.96, wps=21761.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=29600, lr=0.000183804, gnorm=0.336, loss_scale=32, train_wall=263, gb_free=21.5, wall=88041
2022-03-07 21:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:10:15 | INFO | valid | epoch 608 | valid on 'valid' subset | loss 11.133 | ppl 2245.16 | wps 37885.5 | wpb 510.9 | bsz 1 | num_updates 29604 | best_loss 8.723
2022-03-07 21:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 608 @ 29604 updates
2022-03-07 21:10:15 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)
2022-03-07 21:10:15 | INFO | train | epoch 608 | loss 1.564 | ppl 2.96 | wps 21754.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29604 | lr 0.000183791 | gnorm 0.333 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 88057
2022-03-07 21:10:15 | INFO | fairseq.trainer | begin training epoch 609
2022-03-07 21:10:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:11:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:12:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:12:41 | INFO | valid | epoch 609 | valid on 'valid' subset | loss 11.117 | ppl 2221.74 | wps 37831.1 | wpb 510.9 | bsz 1 | num_updates 29652 | best_loss 8.723
2022-03-07 21:12:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 609 @ 29652 updates
2022-03-07 21:12:42 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)
2022-03-07 21:12:42 | INFO | train | epoch 609 | loss 1.564 | ppl 2.96 | wps 21307.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29652 | lr 0.000183642 | gnorm 0.338 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 88203
2022-03-07 21:12:42 | INFO | fairseq.trainer | begin training epoch 610
2022-03-07 21:12:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:15:00 | INFO | train_inner | epoch 610:     48 / 49 loss=1.564, ppl=2.96, wps=21566.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=29700, lr=0.000183494, gnorm=0.336, loss_scale=16, train_wall=265, gb_free=21.5, wall=88342
2022-03-07 21:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:15:08 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 11.114 | ppl 2216.32 | wps 37680.9 | wpb 510.9 | bsz 1 | num_updates 29701 | best_loss 8.723
2022-03-07 21:15:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 29701 updates
2022-03-07 21:15:08 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)
2022-03-07 21:15:08 | INFO | train | epoch 610 | loss 1.564 | ppl 2.96 | wps 21756.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29701 | lr 0.000183491 | gnorm 0.335 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 88349
2022-03-07 21:15:08 | INFO | fairseq.trainer | begin training epoch 611
2022-03-07 21:15:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:17:34 | INFO | valid | epoch 611 | valid on 'valid' subset | loss 11.077 | ppl 2159.84 | wps 37794 | wpb 510.9 | bsz 1 | num_updates 29750 | best_loss 8.723
2022-03-07 21:17:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 611 @ 29750 updates
2022-03-07 21:17:34 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)
2022-03-07 21:17:34 | INFO | train | epoch 611 | loss 1.563 | ppl 2.95 | wps 21751.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29750 | lr 0.00018334 | gnorm 0.333 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 88495
2022-03-07 21:17:34 | INFO | fairseq.trainer | begin training epoch 612
2022-03-07 21:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:19:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:20:00 | INFO | valid | epoch 612 | valid on 'valid' subset | loss 11.12 | ppl 2226.25 | wps 37825.5 | wpb 510.9 | bsz 1 | num_updates 29799 | best_loss 8.723
2022-03-07 21:20:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 612 @ 29799 updates
2022-03-07 21:20:00 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)
2022-03-07 21:20:00 | INFO | train | epoch 612 | loss 1.562 | ppl 2.95 | wps 21753.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29799 | lr 0.000183189 | gnorm 0.33 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 88642
2022-03-07 21:20:00 | INFO | fairseq.trainer | begin training epoch 613
2022-03-07 21:20:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:20:03 | INFO | train_inner | epoch 613:      1 / 49 loss=1.563, ppl=2.95, wps=21335.9, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=29800, lr=0.000183186, gnorm=0.333, loss_scale=32, train_wall=262, gb_free=21.5, wall=88645
2022-03-07 21:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:22:26 | INFO | valid | epoch 613 | valid on 'valid' subset | loss 11.133 | ppl 2245.47 | wps 37974.7 | wpb 510.9 | bsz 1 | num_updates 29848 | best_loss 8.723
2022-03-07 21:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 613 @ 29848 updates
2022-03-07 21:22:26 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)
2022-03-07 21:22:26 | INFO | train | epoch 613 | loss 1.562 | ppl 2.95 | wps 21742.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29848 | lr 0.000183038 | gnorm 0.339 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 88788
2022-03-07 21:22:26 | INFO | fairseq.trainer | begin training epoch 614
2022-03-07 21:22:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:22:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:24:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:24:52 | INFO | valid | epoch 614 | valid on 'valid' subset | loss 11.119 | ppl 2224.59 | wps 37838.7 | wpb 510.9 | bsz 1 | num_updates 29896 | best_loss 8.723
2022-03-07 21:24:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 614 @ 29896 updates
2022-03-07 21:24:52 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)
2022-03-07 21:24:52 | INFO | train | epoch 614 | loss 1.562 | ppl 2.95 | wps 21292.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29896 | lr 0.000182891 | gnorm 0.336 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 88934
2022-03-07 21:24:52 | INFO | fairseq.trainer | begin training epoch 615
2022-03-07 21:24:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:25:04 | INFO | train_inner | epoch 615:      4 / 49 loss=1.562, ppl=2.95, wps=21552.8, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=29900, lr=0.000182879, gnorm=0.337, loss_scale=16, train_wall=266, gb_free=21.5, wall=88946
2022-03-07 21:27:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:27:18 | INFO | valid | epoch 615 | valid on 'valid' subset | loss 11.15 | ppl 2273.14 | wps 37588.1 | wpb 510.9 | bsz 1 | num_updates 29945 | best_loss 8.723
2022-03-07 21:27:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 615 @ 29945 updates
2022-03-07 21:27:18 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)
2022-03-07 21:27:18 | INFO | train | epoch 615 | loss 1.562 | ppl 2.95 | wps 21754.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29945 | lr 0.000182742 | gnorm 0.334 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 89080
2022-03-07 21:27:18 | INFO | fairseq.trainer | begin training epoch 616
2022-03-07 21:27:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:28:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:29:44 | INFO | valid | epoch 616 | valid on 'valid' subset | loss 11.11 | ppl 2209.95 | wps 37933.2 | wpb 510.9 | bsz 1 | num_updates 29993 | best_loss 8.723
2022-03-07 21:29:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 616 @ 29993 updates
2022-03-07 21:29:44 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)
2022-03-07 21:29:44 | INFO | train | epoch 616 | loss 1.562 | ppl 2.95 | wps 21307.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29993 | lr 0.000182595 | gnorm 0.335 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 89226
2022-03-07 21:29:44 | INFO | fairseq.trainer | begin training epoch 617
2022-03-07 21:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:30:05 | INFO | train_inner | epoch 617:      7 / 49 loss=1.562, ppl=2.95, wps=21563.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30000, lr=0.000182574, gnorm=0.334, loss_scale=16, train_wall=265, gb_free=21.5, wall=89246
2022-03-07 21:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:32:10 | INFO | valid | epoch 617 | valid on 'valid' subset | loss 11.104 | ppl 2200.82 | wps 37775.9 | wpb 510.9 | bsz 1 | num_updates 30042 | best_loss 8.723
2022-03-07 21:32:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 617 @ 30042 updates
2022-03-07 21:32:10 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)
2022-03-07 21:32:10 | INFO | train | epoch 617 | loss 1.562 | ppl 2.95 | wps 21740.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30042 | lr 0.000182447 | gnorm 0.336 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 89372
2022-03-07 21:32:10 | INFO | fairseq.trainer | begin training epoch 618
2022-03-07 21:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:34:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:34:37 | INFO | valid | epoch 618 | valid on 'valid' subset | loss 11.123 | ppl 2230.23 | wps 37781.4 | wpb 510.9 | bsz 1 | num_updates 30091 | best_loss 8.723
2022-03-07 21:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 618 @ 30091 updates
2022-03-07 21:34:37 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)
2022-03-07 21:34:37 | INFO | train | epoch 618 | loss 1.562 | ppl 2.95 | wps 21753.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30091 | lr 0.000182298 | gnorm 0.338 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 89518
2022-03-07 21:34:37 | INFO | fairseq.trainer | begin training epoch 619
2022-03-07 21:34:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:35:03 | INFO | train_inner | epoch 619:      9 / 49 loss=1.562, ppl=2.95, wps=21758.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=30100, lr=0.000182271, gnorm=0.337, loss_scale=16, train_wall=263, gb_free=21.5, wall=89545
2022-03-07 21:36:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:37:03 | INFO | valid | epoch 619 | valid on 'valid' subset | loss 11.107 | ppl 2205.55 | wps 37642.6 | wpb 510.9 | bsz 1 | num_updates 30140 | best_loss 8.723
2022-03-07 21:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 619 @ 30140 updates
2022-03-07 21:37:03 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)
2022-03-07 21:37:03 | INFO | train | epoch 619 | loss 1.561 | ppl 2.95 | wps 21737.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30140 | lr 0.00018215 | gnorm 0.335 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 89665
2022-03-07 21:37:03 | INFO | fairseq.trainer | begin training epoch 620
2022-03-07 21:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:39:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:39:29 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 11.094 | ppl 2185.86 | wps 37811.6 | wpb 510.9 | bsz 1 | num_updates 30189 | best_loss 8.723
2022-03-07 21:39:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 30189 updates
2022-03-07 21:39:29 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)
2022-03-07 21:39:29 | INFO | train | epoch 620 | loss 1.561 | ppl 2.95 | wps 21738.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30189 | lr 0.000182002 | gnorm 0.335 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 89811
2022-03-07 21:39:29 | INFO | fairseq.trainer | begin training epoch 621
2022-03-07 21:39:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:40:01 | INFO | train_inner | epoch 621:     11 / 49 loss=1.561, ppl=2.95, wps=21761.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=30200, lr=0.000181969, gnorm=0.335, loss_scale=32, train_wall=263, gb_free=21.5, wall=89843
2022-03-07 21:41:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:41:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:41:55 | INFO | valid | epoch 621 | valid on 'valid' subset | loss 11.129 | ppl 2239.22 | wps 37392.2 | wpb 510.9 | bsz 1 | num_updates 30237 | best_loss 8.723
2022-03-07 21:41:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 621 @ 30237 updates
2022-03-07 21:41:55 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)
2022-03-07 21:41:55 | INFO | train | epoch 621 | loss 1.56 | ppl 2.95 | wps 21296.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30237 | lr 0.000181857 | gnorm 0.33 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 89957
2022-03-07 21:41:55 | INFO | fairseq.trainer | begin training epoch 622
2022-03-07 21:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:43:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:44:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:44:21 | INFO | valid | epoch 622 | valid on 'valid' subset | loss 11.111 | ppl 2212.13 | wps 37934.1 | wpb 510.9 | bsz 1 | num_updates 30285 | best_loss 8.723
2022-03-07 21:44:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 622 @ 30285 updates
2022-03-07 21:44:21 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)
2022-03-07 21:44:21 | INFO | train | epoch 622 | loss 1.56 | ppl 2.95 | wps 21319.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30285 | lr 0.000181713 | gnorm 0.331 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 90103
2022-03-07 21:44:21 | INFO | fairseq.trainer | begin training epoch 623
2022-03-07 21:44:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:45:05 | INFO | train_inner | epoch 623:     15 / 49 loss=1.56, ppl=2.95, wps=21359.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30300, lr=0.000181668, gnorm=0.33, loss_scale=16, train_wall=268, gb_free=21.5, wall=90146
2022-03-07 21:46:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:46:47 | INFO | valid | epoch 623 | valid on 'valid' subset | loss 11.093 | ppl 2183.63 | wps 37741.6 | wpb 510.9 | bsz 1 | num_updates 30334 | best_loss 8.723
2022-03-07 21:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 623 @ 30334 updates
2022-03-07 21:46:47 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)
2022-03-07 21:46:47 | INFO | train | epoch 623 | loss 1.561 | ppl 2.95 | wps 21760.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30334 | lr 0.000181566 | gnorm 0.332 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 90249
2022-03-07 21:46:47 | INFO | fairseq.trainer | begin training epoch 624
2022-03-07 21:46:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:49:13 | INFO | valid | epoch 624 | valid on 'valid' subset | loss 11.149 | ppl 2270.15 | wps 38050.7 | wpb 510.9 | bsz 1 | num_updates 30383 | best_loss 8.723
2022-03-07 21:49:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 624 @ 30383 updates
2022-03-07 21:49:13 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)
2022-03-07 21:49:13 | INFO | train | epoch 624 | loss 1.56 | ppl 2.95 | wps 21748.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30383 | lr 0.00018142 | gnorm 0.333 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 90395
2022-03-07 21:49:13 | INFO | fairseq.trainer | begin training epoch 625
2022-03-07 21:49:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:50:02 | INFO | train_inner | epoch 625:     17 / 49 loss=1.56, ppl=2.95, wps=21773, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=30400, lr=0.000181369, gnorm=0.333, loss_scale=32, train_wall=263, gb_free=21.5, wall=90444
2022-03-07 21:51:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:51:39 | INFO | valid | epoch 625 | valid on 'valid' subset | loss 11.104 | ppl 2201.59 | wps 37881.2 | wpb 510.9 | bsz 1 | num_updates 30432 | best_loss 8.723
2022-03-07 21:51:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 625 @ 30432 updates
2022-03-07 21:51:39 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)
2022-03-07 21:51:39 | INFO | train | epoch 625 | loss 1.56 | ppl 2.95 | wps 21742.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30432 | lr 0.000181274 | gnorm 0.333 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 90541
2022-03-07 21:51:39 | INFO | fairseq.trainer | begin training epoch 626
2022-03-07 21:51:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:54:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:54:06 | INFO | valid | epoch 626 | valid on 'valid' subset | loss 11.148 | ppl 2269.8 | wps 37809.9 | wpb 510.9 | bsz 1 | num_updates 30481 | best_loss 8.723
2022-03-07 21:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 626 @ 30481 updates
2022-03-07 21:54:06 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)
2022-03-07 21:54:06 | INFO | train | epoch 626 | loss 1.559 | ppl 2.95 | wps 21737.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30481 | lr 0.000181128 | gnorm 0.331 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 90687
2022-03-07 21:54:06 | INFO | fairseq.trainer | begin training epoch 627
2022-03-07 21:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:55:01 | INFO | train_inner | epoch 627:     19 / 49 loss=1.56, ppl=2.95, wps=21756, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=30500, lr=0.000181071, gnorm=0.332, loss_scale=32, train_wall=263, gb_free=21.5, wall=90742
2022-03-07 21:56:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:56:32 | INFO | valid | epoch 627 | valid on 'valid' subset | loss 11.102 | ppl 2198.12 | wps 37825.3 | wpb 510.9 | bsz 1 | num_updates 30530 | best_loss 8.723
2022-03-07 21:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 627 @ 30530 updates
2022-03-07 21:56:32 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)
2022-03-07 21:56:32 | INFO | train | epoch 627 | loss 1.559 | ppl 2.95 | wps 21737.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30530 | lr 0.000180983 | gnorm 0.333 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 90834
2022-03-07 21:56:32 | INFO | fairseq.trainer | begin training epoch 628
2022-03-07 21:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:57:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:58:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:58:58 | INFO | valid | epoch 628 | valid on 'valid' subset | loss 11.123 | ppl 2229.53 | wps 37799.1 | wpb 510.9 | bsz 1 | num_updates 30578 | best_loss 8.723
2022-03-07 21:58:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 628 @ 30578 updates
2022-03-07 21:58:58 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)
2022-03-07 21:58:58 | INFO | train | epoch 628 | loss 1.559 | ppl 2.95 | wps 21293.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30578 | lr 0.00018084 | gnorm 0.329 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 90980
2022-03-07 21:58:58 | INFO | fairseq.trainer | begin training epoch 629
2022-03-07 21:58:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:00:02 | INFO | train_inner | epoch 629:     22 / 49 loss=1.559, ppl=2.95, wps=21541.1, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=30600, lr=0.000180775, gnorm=0.331, loss_scale=32, train_wall=266, gb_free=21.5, wall=91044
2022-03-07 22:01:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:01:24 | INFO | valid | epoch 629 | valid on 'valid' subset | loss 11.094 | ppl 2186.03 | wps 37852.5 | wpb 510.9 | bsz 1 | num_updates 30627 | best_loss 8.723
2022-03-07 22:01:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 629 @ 30627 updates
2022-03-07 22:01:24 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)
2022-03-07 22:01:24 | INFO | train | epoch 629 | loss 1.559 | ppl 2.95 | wps 21727 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 30627 | lr 0.000180696 | gnorm 0.33 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 91126
2022-03-07 22:01:24 | INFO | fairseq.trainer | begin training epoch 630
2022-03-07 22:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:03:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:03:51 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 11.14 | ppl 2256.74 | wps 37680.7 | wpb 510.9 | bsz 1 | num_updates 30676 | best_loss 8.723
2022-03-07 22:03:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 30676 updates
2022-03-07 22:03:51 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)
2022-03-07 22:03:51 | INFO | train | epoch 630 | loss 1.559 | ppl 2.95 | wps 21736.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30676 | lr 0.000180551 | gnorm 0.332 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 91272
2022-03-07 22:03:51 | INFO | fairseq.trainer | begin training epoch 631
2022-03-07 22:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:03:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:04:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:05:06 | INFO | train_inner | epoch 631:     26 / 49 loss=1.559, ppl=2.95, wps=21344, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30700, lr=0.000180481, gnorm=0.331, loss_scale=16, train_wall=268, gb_free=21.5, wall=91348
2022-03-07 22:06:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:06:17 | INFO | valid | epoch 631 | valid on 'valid' subset | loss 11.103 | ppl 2199.32 | wps 37898.7 | wpb 510.9 | bsz 1 | num_updates 30723 | best_loss 8.723
2022-03-07 22:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 631 @ 30723 updates
2022-03-07 22:06:17 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)
2022-03-07 22:06:17 | INFO | train | epoch 631 | loss 1.558 | ppl 2.95 | wps 20857.7 | ups 0.32 | wpb 64829.4 | bsz 126.6 | num_updates 30723 | lr 0.000180413 | gnorm 0.33 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 91418
2022-03-07 22:06:17 | INFO | fairseq.trainer | begin training epoch 632
2022-03-07 22:06:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:08:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:08:42 | INFO | valid | epoch 632 | valid on 'valid' subset | loss 11.099 | ppl 2192.88 | wps 38176.2 | wpb 510.9 | bsz 1 | num_updates 30772 | best_loss 8.723
2022-03-07 22:08:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 632 @ 30772 updates
2022-03-07 22:08:42 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)
2022-03-07 22:08:42 | INFO | train | epoch 632 | loss 1.558 | ppl 2.95 | wps 21784.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30772 | lr 0.000180269 | gnorm 0.332 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 91564
2022-03-07 22:08:42 | INFO | fairseq.trainer | begin training epoch 633
2022-03-07 22:08:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:10:03 | INFO | train_inner | epoch 633:     28 / 49 loss=1.558, ppl=2.95, wps=21790.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=30800, lr=0.000180187, gnorm=0.331, loss_scale=16, train_wall=263, gb_free=21.5, wall=91645
2022-03-07 22:11:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:11:08 | INFO | valid | epoch 633 | valid on 'valid' subset | loss 11.121 | ppl 2226.76 | wps 37868.7 | wpb 510.9 | bsz 1 | num_updates 30821 | best_loss 8.723
2022-03-07 22:11:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 633 @ 30821 updates
2022-03-07 22:11:08 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)
2022-03-07 22:11:08 | INFO | train | epoch 633 | loss 1.559 | ppl 2.95 | wps 21764.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30821 | lr 0.000180126 | gnorm 0.331 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 91710
2022-03-07 22:11:09 | INFO | fairseq.trainer | begin training epoch 634
2022-03-07 22:11:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:13:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:13:35 | INFO | valid | epoch 634 | valid on 'valid' subset | loss 11.102 | ppl 2198.68 | wps 37905.6 | wpb 510.9 | bsz 1 | num_updates 30870 | best_loss 8.723
2022-03-07 22:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 634 @ 30870 updates
2022-03-07 22:13:35 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)
2022-03-07 22:13:35 | INFO | train | epoch 634 | loss 1.558 | ppl 2.94 | wps 21721.8 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 30870 | lr 0.000179983 | gnorm 0.333 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 91857
2022-03-07 22:13:35 | INFO | fairseq.trainer | begin training epoch 635
2022-03-07 22:13:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:15:02 | INFO | train_inner | epoch 635:     30 / 49 loss=1.558, ppl=2.94, wps=21762.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=30900, lr=0.000179896, gnorm=0.333, loss_scale=32, train_wall=263, gb_free=21.5, wall=91943
2022-03-07 22:15:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:16:01 | INFO | valid | epoch 635 | valid on 'valid' subset | loss 11.116 | ppl 2219.05 | wps 37639.5 | wpb 510.9 | bsz 1 | num_updates 30919 | best_loss 8.723
2022-03-07 22:16:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 635 @ 30919 updates
2022-03-07 22:16:01 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)
2022-03-07 22:16:01 | INFO | train | epoch 635 | loss 1.558 | ppl 2.94 | wps 21734.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30919 | lr 0.00017984 | gnorm 0.334 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 92003
2022-03-07 22:16:01 | INFO | fairseq.trainer | begin training epoch 636
2022-03-07 22:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:17:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:18:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:18:27 | INFO | valid | epoch 636 | valid on 'valid' subset | loss 11.061 | ppl 2136.78 | wps 37921.1 | wpb 510.9 | bsz 1 | num_updates 30967 | best_loss 8.723
2022-03-07 22:18:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 636 @ 30967 updates
2022-03-07 22:18:27 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)
2022-03-07 22:18:27 | INFO | train | epoch 636 | loss 1.557 | ppl 2.94 | wps 21318.9 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 30967 | lr 0.000179701 | gnorm 0.329 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 92149
2022-03-07 22:18:27 | INFO | fairseq.trainer | begin training epoch 637
2022-03-07 22:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:20:03 | INFO | train_inner | epoch 637:     33 / 49 loss=1.557, ppl=2.94, wps=21549.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31000, lr=0.000179605, gnorm=0.33, loss_scale=32, train_wall=266, gb_free=21.5, wall=92244
2022-03-07 22:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:20:53 | INFO | valid | epoch 637 | valid on 'valid' subset | loss 11.085 | ppl 2171.76 | wps 37933.7 | wpb 510.9 | bsz 1 | num_updates 31016 | best_loss 8.723
2022-03-07 22:20:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 637 @ 31016 updates
2022-03-07 22:20:53 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)
2022-03-07 22:20:53 | INFO | train | epoch 637 | loss 1.557 | ppl 2.94 | wps 21734.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31016 | lr 0.000179559 | gnorm 0.331 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 92295
2022-03-07 22:20:53 | INFO | fairseq.trainer | begin training epoch 638
2022-03-07 22:20:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:23:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:23:19 | INFO | valid | epoch 638 | valid on 'valid' subset | loss 11.075 | ppl 2156.82 | wps 37900.1 | wpb 510.9 | bsz 1 | num_updates 31065 | best_loss 8.723
2022-03-07 22:23:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 638 @ 31065 updates
2022-03-07 22:23:19 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)
2022-03-07 22:23:19 | INFO | train | epoch 638 | loss 1.557 | ppl 2.94 | wps 21756.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31065 | lr 0.000179417 | gnorm 0.334 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 92441
2022-03-07 22:23:19 | INFO | fairseq.trainer | begin training epoch 639
2022-03-07 22:23:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:24:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:25:03 | INFO | train_inner | epoch 639:     36 / 49 loss=1.557, ppl=2.94, wps=21561.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31100, lr=0.000179316, gnorm=0.334, loss_scale=32, train_wall=265, gb_free=21.5, wall=92545
2022-03-07 22:25:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:25:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:25:45 | INFO | valid | epoch 639 | valid on 'valid' subset | loss 11.109 | ppl 2208.48 | wps 37880.2 | wpb 510.9 | bsz 1 | num_updates 31112 | best_loss 8.723
2022-03-07 22:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 639 @ 31112 updates
2022-03-07 22:25:45 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)
2022-03-07 22:25:45 | INFO | train | epoch 639 | loss 1.556 | ppl 2.94 | wps 20855.7 | ups 0.32 | wpb 64829.4 | bsz 126.6 | num_updates 31112 | lr 0.000179282 | gnorm 0.334 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 92587
2022-03-07 22:25:45 | INFO | fairseq.trainer | begin training epoch 640
2022-03-07 22:25:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:28:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:28:12 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 11.123 | ppl 2230.03 | wps 37562 | wpb 510.9 | bsz 1 | num_updates 31161 | best_loss 8.723
2022-03-07 22:28:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 31161 updates
2022-03-07 22:28:12 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)
2022-03-07 22:28:12 | INFO | train | epoch 640 | loss 1.556 | ppl 2.94 | wps 21731.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31161 | lr 0.000179141 | gnorm 0.329 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 92733
2022-03-07 22:28:12 | INFO | fairseq.trainer | begin training epoch 641
2022-03-07 22:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:30:05 | INFO | train_inner | epoch 641:     39 / 49 loss=1.556, ppl=2.94, wps=21543.9, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=31200, lr=0.000179029, gnorm=0.333, loss_scale=16, train_wall=266, gb_free=21.5, wall=92846
2022-03-07 22:30:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:30:38 | INFO | valid | epoch 641 | valid on 'valid' subset | loss 11.105 | ppl 2203.19 | wps 37685 | wpb 510.9 | bsz 1 | num_updates 31210 | best_loss 8.723
2022-03-07 22:30:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 641 @ 31210 updates
2022-03-07 22:30:38 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)
2022-03-07 22:30:38 | INFO | train | epoch 641 | loss 1.556 | ppl 2.94 | wps 21725.7 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 31210 | lr 0.000179 | gnorm 0.337 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 92880
2022-03-07 22:30:38 | INFO | fairseq.trainer | begin training epoch 642
2022-03-07 22:30:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:32:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:33:04 | INFO | valid | epoch 642 | valid on 'valid' subset | loss 11.138 | ppl 2254.02 | wps 37977.6 | wpb 510.9 | bsz 1 | num_updates 31259 | best_loss 8.723
2022-03-07 22:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 642 @ 31259 updates
2022-03-07 22:33:04 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)
2022-03-07 22:33:04 | INFO | train | epoch 642 | loss 1.556 | ppl 2.94 | wps 21762.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31259 | lr 0.00017886 | gnorm 0.328 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 93026
2022-03-07 22:33:04 | INFO | fairseq.trainer | begin training epoch 643
2022-03-07 22:33:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:35:03 | INFO | train_inner | epoch 643:     41 / 49 loss=1.556, ppl=2.94, wps=21766.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=31300, lr=0.000178743, gnorm=0.332, loss_scale=32, train_wall=263, gb_free=21.5, wall=93144
2022-03-07 22:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:35:30 | INFO | valid | epoch 643 | valid on 'valid' subset | loss 11.104 | ppl 2201.02 | wps 37684.6 | wpb 510.9 | bsz 1 | num_updates 31308 | best_loss 8.723
2022-03-07 22:35:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 643 @ 31308 updates
2022-03-07 22:35:30 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)
2022-03-07 22:35:30 | INFO | train | epoch 643 | loss 1.556 | ppl 2.94 | wps 21737.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31308 | lr 0.00017872 | gnorm 0.336 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 93172
2022-03-07 22:35:30 | INFO | fairseq.trainer | begin training epoch 644
2022-03-07 22:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:37:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:37:56 | INFO | valid | epoch 644 | valid on 'valid' subset | loss 11.105 | ppl 2203.31 | wps 37713.8 | wpb 510.9 | bsz 1 | num_updates 31357 | best_loss 8.723
2022-03-07 22:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 644 @ 31357 updates
2022-03-07 22:37:56 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)
2022-03-07 22:37:56 | INFO | train | epoch 644 | loss 1.555 | ppl 2.94 | wps 21760.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31357 | lr 0.00017858 | gnorm 0.331 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 93318
2022-03-07 22:37:56 | INFO | fairseq.trainer | begin training epoch 645
2022-03-07 22:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:38:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:40:04 | INFO | train_inner | epoch 645:     44 / 49 loss=1.555, ppl=2.94, wps=21552.8, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31400, lr=0.000178458, gnorm=0.332, loss_scale=32, train_wall=266, gb_free=21.5, wall=93445
2022-03-07 22:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:40:22 | INFO | valid | epoch 645 | valid on 'valid' subset | loss 11.096 | ppl 2189.58 | wps 37833.2 | wpb 510.9 | bsz 1 | num_updates 31405 | best_loss 8.723
2022-03-07 22:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 645 @ 31405 updates
2022-03-07 22:40:22 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)
2022-03-07 22:40:22 | INFO | train | epoch 645 | loss 1.555 | ppl 2.94 | wps 21283.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31405 | lr 0.000178443 | gnorm 0.333 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 93464
2022-03-07 22:40:22 | INFO | fairseq.trainer | begin training epoch 646
2022-03-07 22:40:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:42:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:42:49 | INFO | valid | epoch 646 | valid on 'valid' subset | loss 11.116 | ppl 2218.83 | wps 37797.1 | wpb 510.9 | bsz 1 | num_updates 31454 | best_loss 8.723
2022-03-07 22:42:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 646 @ 31454 updates
2022-03-07 22:42:49 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)
2022-03-07 22:42:49 | INFO | train | epoch 646 | loss 1.555 | ppl 2.94 | wps 21739.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31454 | lr 0.000178304 | gnorm 0.329 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 93610
2022-03-07 22:42:49 | INFO | fairseq.trainer | begin training epoch 647
2022-03-07 22:42:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:45:02 | INFO | train_inner | epoch 647:     46 / 49 loss=1.555, ppl=2.94, wps=21760.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=31500, lr=0.000178174, gnorm=0.329, loss_scale=64, train_wall=263, gb_free=21.5, wall=93744
2022-03-07 22:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:45:15 | INFO | valid | epoch 647 | valid on 'valid' subset | loss 11.092 | ppl 2182.36 | wps 37835.7 | wpb 510.9 | bsz 1 | num_updates 31503 | best_loss 8.723
2022-03-07 22:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 647 @ 31503 updates
2022-03-07 22:45:15 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)
2022-03-07 22:45:15 | INFO | train | epoch 647 | loss 1.555 | ppl 2.94 | wps 21749.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31503 | lr 0.000178166 | gnorm 0.327 | loss_scale 64 | train_wall 129 | gb_free 21.5 | wall 93757
2022-03-07 22:45:15 | INFO | fairseq.trainer | begin training epoch 648
2022-03-07 22:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:45:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:47:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:47:41 | INFO | valid | epoch 648 | valid on 'valid' subset | loss 11.091 | ppl 2181.14 | wps 37981.6 | wpb 510.9 | bsz 1 | num_updates 31551 | best_loss 8.723
2022-03-07 22:47:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 648 @ 31551 updates
2022-03-07 22:47:41 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)
2022-03-07 22:47:41 | INFO | train | epoch 648 | loss 1.555 | ppl 2.94 | wps 21309.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31551 | lr 0.00017803 | gnorm 0.331 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 93903
2022-03-07 22:47:41 | INFO | fairseq.trainer | begin training epoch 649
2022-03-07 22:47:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:50:01 | INFO | train_inner | epoch 649:     49 / 49 loss=1.555, ppl=2.94, wps=21556.4, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=31600, lr=0.000177892, gnorm=0.332, loss_scale=32, train_wall=264, gb_free=21.5, wall=94043
2022-03-07 22:50:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:50:07 | INFO | valid | epoch 649 | valid on 'valid' subset | loss 11.106 | ppl 2204.82 | wps 37875 | wpb 510.9 | bsz 1 | num_updates 31600 | best_loss 8.723
2022-03-07 22:50:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 649 @ 31600 updates
2022-03-07 22:50:07 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)
2022-03-07 22:50:07 | INFO | train | epoch 649 | loss 1.555 | ppl 2.94 | wps 21748.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31600 | lr 0.000177892 | gnorm 0.331 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 94049
2022-03-07 22:50:07 | INFO | fairseq.trainer | begin training epoch 650
2022-03-07 22:50:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:51:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:52:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:52:33 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 11.107 | ppl 2205.24 | wps 37687.2 | wpb 510.9 | bsz 1 | num_updates 31648 | best_loss 8.723
2022-03-07 22:52:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 31648 updates
2022-03-07 22:52:33 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)
2022-03-07 22:52:33 | INFO | train | epoch 650 | loss 1.554 | ppl 2.94 | wps 21300.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31648 | lr 0.000177757 | gnorm 0.329 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 94195
2022-03-07 22:52:33 | INFO | fairseq.trainer | begin training epoch 651
2022-03-07 22:52:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:54:59 | INFO | valid | epoch 651 | valid on 'valid' subset | loss 11.104 | ppl 2201.4 | wps 37641.1 | wpb 510.9 | bsz 1 | num_updates 31697 | best_loss 8.723
2022-03-07 22:54:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 651 @ 31697 updates
2022-03-07 22:54:59 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)
2022-03-07 22:54:59 | INFO | train | epoch 651 | loss 1.554 | ppl 2.94 | wps 21731.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31697 | lr 0.00017762 | gnorm 0.328 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 94341
2022-03-07 22:54:59 | INFO | fairseq.trainer | begin training epoch 652
2022-03-07 22:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:55:08 | INFO | train_inner | epoch 652:      3 / 49 loss=1.554, ppl=2.94, wps=21135.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31700, lr=0.000177611, gnorm=0.329, loss_scale=16, train_wall=266, gb_free=21.5, wall=94350
2022-03-07 22:57:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:57:26 | INFO | valid | epoch 652 | valid on 'valid' subset | loss 11.118 | ppl 2222.23 | wps 37652.9 | wpb 510.9 | bsz 1 | num_updates 31746 | best_loss 8.723
2022-03-07 22:57:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 652 @ 31746 updates
2022-03-07 22:57:26 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)
2022-03-07 22:57:26 | INFO | train | epoch 652 | loss 1.554 | ppl 2.94 | wps 21735.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31746 | lr 0.000177482 | gnorm 0.331 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 94487
2022-03-07 22:57:26 | INFO | fairseq.trainer | begin training epoch 653
2022-03-07 22:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:59:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:59:52 | INFO | valid | epoch 653 | valid on 'valid' subset | loss 11.105 | ppl 2202.28 | wps 37853.3 | wpb 510.9 | bsz 1 | num_updates 31795 | best_loss 8.723
2022-03-07 22:59:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 653 @ 31795 updates
2022-03-07 22:59:52 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)
2022-03-07 22:59:52 | INFO | train | epoch 653 | loss 1.553 | ppl 2.93 | wps 21755.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31795 | lr 0.000177346 | gnorm 0.327 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 94633
2022-03-07 22:59:52 | INFO | fairseq.trainer | begin training epoch 654
2022-03-07 22:59:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:00:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:00:09 | INFO | train_inner | epoch 654:      6 / 49 loss=1.553, ppl=2.93, wps=21554.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31800, lr=0.000177332, gnorm=0.328, loss_scale=16, train_wall=266, gb_free=21.5, wall=94651
2022-03-07 23:02:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:02:18 | INFO | valid | epoch 654 | valid on 'valid' subset | loss 11.068 | ppl 2147.12 | wps 37853.3 | wpb 510.9 | bsz 1 | num_updates 31843 | best_loss 8.723
2022-03-07 23:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 654 @ 31843 updates
2022-03-07 23:02:18 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)
2022-03-07 23:02:18 | INFO | train | epoch 654 | loss 1.553 | ppl 2.93 | wps 21279 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31843 | lr 0.000177212 | gnorm 0.329 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 94780
2022-03-07 23:02:18 | INFO | fairseq.trainer | begin training epoch 655
2022-03-07 23:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:04:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:04:44 | INFO | valid | epoch 655 | valid on 'valid' subset | loss 11.117 | ppl 2220.73 | wps 37700 | wpb 510.9 | bsz 1 | num_updates 31892 | best_loss 8.723
2022-03-07 23:04:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 655 @ 31892 updates
2022-03-07 23:04:44 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)
2022-03-07 23:04:44 | INFO | train | epoch 655 | loss 1.553 | ppl 2.93 | wps 21741.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31892 | lr 0.000177076 | gnorm 0.329 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 94926
2022-03-07 23:04:44 | INFO | fairseq.trainer | begin training epoch 656
2022-03-07 23:04:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:05:07 | INFO | train_inner | epoch 656:      8 / 49 loss=1.553, ppl=2.94, wps=21751.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=31900, lr=0.000177054, gnorm=0.33, loss_scale=16, train_wall=263, gb_free=21.5, wall=94949
2022-03-07 23:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:07:10 | INFO | valid | epoch 656 | valid on 'valid' subset | loss 11.091 | ppl 2181.03 | wps 37948.6 | wpb 510.9 | bsz 1 | num_updates 31941 | best_loss 8.723
2022-03-07 23:07:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 656 @ 31941 updates
2022-03-07 23:07:10 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)
2022-03-07 23:07:10 | INFO | train | epoch 656 | loss 1.553 | ppl 2.93 | wps 21763.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31941 | lr 0.00017694 | gnorm 0.33 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95072
2022-03-07 23:07:10 | INFO | fairseq.trainer | begin training epoch 657
2022-03-07 23:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:09:36 | INFO | valid | epoch 657 | valid on 'valid' subset | loss 11.11 | ppl 2209.55 | wps 37865.7 | wpb 510.9 | bsz 1 | num_updates 31990 | best_loss 8.723
2022-03-07 23:09:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 657 @ 31990 updates
2022-03-07 23:09:36 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)
2022-03-07 23:09:36 | INFO | train | epoch 657 | loss 1.553 | ppl 2.93 | wps 21740.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31990 | lr 0.000176804 | gnorm 0.33 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95218
2022-03-07 23:09:36 | INFO | fairseq.trainer | begin training epoch 658
2022-03-07 23:09:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:10:05 | INFO | train_inner | epoch 658:     10 / 49 loss=1.553, ppl=2.93, wps=21775.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=32000, lr=0.000176777, gnorm=0.33, loss_scale=32, train_wall=263, gb_free=21.5, wall=95247
2022-03-07 23:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:12:02 | INFO | valid | epoch 658 | valid on 'valid' subset | loss 11.065 | ppl 2142.47 | wps 37558.5 | wpb 510.9 | bsz 1 | num_updates 32039 | best_loss 8.723
2022-03-07 23:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 658 @ 32039 updates
2022-03-07 23:12:02 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)
2022-03-07 23:12:02 | INFO | train | epoch 658 | loss 1.553 | ppl 2.93 | wps 21737.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32039 | lr 0.000176669 | gnorm 0.332 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95364
2022-03-07 23:12:03 | INFO | fairseq.trainer | begin training epoch 659
2022-03-07 23:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:13:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:14:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:14:29 | INFO | valid | epoch 659 | valid on 'valid' subset | loss 11.09 | ppl 2180.41 | wps 37800.1 | wpb 510.9 | bsz 1 | num_updates 32087 | best_loss 8.723
2022-03-07 23:14:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 659 @ 32087 updates
2022-03-07 23:14:29 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)
2022-03-07 23:14:29 | INFO | train | epoch 659 | loss 1.552 | ppl 2.93 | wps 21281.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32087 | lr 0.000176537 | gnorm 0.329 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95511
2022-03-07 23:14:29 | INFO | fairseq.trainer | begin training epoch 660
2022-03-07 23:14:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:15:06 | INFO | train_inner | epoch 660:     13 / 49 loss=1.552, ppl=2.93, wps=21538, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=32100, lr=0.000176501, gnorm=0.329, loss_scale=32, train_wall=266, gb_free=21.5, wall=95548
2022-03-07 23:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:16:55 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 11.083 | ppl 2169.53 | wps 37799.1 | wpb 510.9 | bsz 1 | num_updates 32136 | best_loss 8.723
2022-03-07 23:16:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 32136 updates
2022-03-07 23:16:55 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)
2022-03-07 23:16:55 | INFO | train | epoch 660 | loss 1.552 | ppl 2.93 | wps 21753.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32136 | lr 0.000176402 | gnorm 0.327 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95657
2022-03-07 23:16:55 | INFO | fairseq.trainer | begin training epoch 661
2022-03-07 23:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:19:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:19:21 | INFO | valid | epoch 661 | valid on 'valid' subset | loss 11.112 | ppl 2212.97 | wps 37753.7 | wpb 510.9 | bsz 1 | num_updates 32185 | best_loss 8.723
2022-03-07 23:19:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 661 @ 32185 updates
2022-03-07 23:19:21 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)
2022-03-07 23:19:21 | INFO | train | epoch 661 | loss 1.551 | ppl 2.93 | wps 21763.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32185 | lr 0.000176268 | gnorm 0.327 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95803
2022-03-07 23:19:21 | INFO | fairseq.trainer | begin training epoch 662
2022-03-07 23:19:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:20:04 | INFO | train_inner | epoch 662:     15 / 49 loss=1.552, ppl=2.93, wps=21773.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=32200, lr=0.000176227, gnorm=0.327, loss_scale=64, train_wall=263, gb_free=21.5, wall=95846
2022-03-07 23:20:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:21:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:21:47 | INFO | valid | epoch 662 | valid on 'valid' subset | loss 11.095 | ppl 2186.84 | wps 37809 | wpb 510.9 | bsz 1 | num_updates 32233 | best_loss 8.723
2022-03-07 23:21:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 662 @ 32233 updates
2022-03-07 23:21:47 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)
2022-03-07 23:21:47 | INFO | train | epoch 662 | loss 1.551 | ppl 2.93 | wps 21282.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32233 | lr 0.000176137 | gnorm 0.325 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 95949
2022-03-07 23:21:47 | INFO | fairseq.trainer | begin training epoch 663
2022-03-07 23:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:24:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:24:13 | INFO | valid | epoch 663 | valid on 'valid' subset | loss 11.111 | ppl 2211.05 | wps 37814.4 | wpb 510.9 | bsz 1 | num_updates 32282 | best_loss 8.723
2022-03-07 23:24:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 663 @ 32282 updates
2022-03-07 23:24:13 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)
2022-03-07 23:24:13 | INFO | train | epoch 663 | loss 1.552 | ppl 2.93 | wps 21731.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32282 | lr 0.000176003 | gnorm 0.327 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 96095
2022-03-07 23:24:13 | INFO | fairseq.trainer | begin training epoch 664
2022-03-07 23:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:25:05 | INFO | train_inner | epoch 664:     18 / 49 loss=1.552, ppl=2.93, wps=21543.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32300, lr=0.000175954, gnorm=0.326, loss_scale=32, train_wall=266, gb_free=21.5, wall=96147
2022-03-07 23:26:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:26:39 | INFO | valid | epoch 664 | valid on 'valid' subset | loss 11.094 | ppl 2186.19 | wps 37777 | wpb 510.9 | bsz 1 | num_updates 32331 | best_loss 8.723
2022-03-07 23:26:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 664 @ 32331 updates
2022-03-07 23:26:39 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)
2022-03-07 23:26:39 | INFO | train | epoch 664 | loss 1.551 | ppl 2.93 | wps 21754.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32331 | lr 0.000175869 | gnorm 0.325 | loss_scale 32 | train_wall 129 | gb_free 21.5 | wall 96241
2022-03-07 23:26:39 | INFO | fairseq.trainer | begin training epoch 665
2022-03-07 23:26:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:27:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:27:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:29:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:29:06 | INFO | valid | epoch 665 | valid on 'valid' subset | loss 11.112 | ppl 2212.76 | wps 37853.2 | wpb 510.9 | bsz 1 | num_updates 32378 | best_loss 8.723
2022-03-07 23:29:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 665 @ 32378 updates
2022-03-07 23:29:06 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)
2022-03-07 23:29:06 | INFO | train | epoch 665 | loss 1.551 | ppl 2.93 | wps 20848.5 | ups 0.32 | wpb 64829.4 | bsz 126.6 | num_updates 32378 | lr 0.000175742 | gnorm 0.331 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 96387
2022-03-07 23:29:06 | INFO | fairseq.trainer | begin training epoch 666
2022-03-07 23:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:30:09 | INFO | train_inner | epoch 666:     22 / 49 loss=1.551, ppl=2.93, wps=21354.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32400, lr=0.000175682, gnorm=0.328, loss_scale=16, train_wall=268, gb_free=21.5, wall=96451
2022-03-07 23:31:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:31:32 | INFO | valid | epoch 666 | valid on 'valid' subset | loss 11.09 | ppl 2179.9 | wps 37955.5 | wpb 510.9 | bsz 1 | num_updates 32427 | best_loss 8.723
2022-03-07 23:31:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 666 @ 32427 updates
2022-03-07 23:31:32 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)
2022-03-07 23:31:32 | INFO | train | epoch 666 | loss 1.551 | ppl 2.93 | wps 21741.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32427 | lr 0.000175609 | gnorm 0.327 | loss_scale 16 | train_wall 129 | gb_free 21.5 | wall 96534
2022-03-07 23:31:32 | INFO | fairseq.trainer | begin training epoch 667
2022-03-07 23:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:33:56 | INFO | valid | epoch 667 | valid on 'valid' subset | loss 11.067 | ppl 2145.84 | wps 38849.7 | wpb 510.9 | bsz 1 | num_updates 32476 | best_loss 8.723
2022-03-07 23:33:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 667 @ 32476 updates
2022-03-07 23:33:56 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)
2022-03-07 23:33:56 | INFO | train | epoch 667 | loss 1.55 | ppl 2.93 | wps 21964.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32476 | lr 0.000175476 | gnorm 0.325 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 96678
2022-03-07 23:33:56 | INFO | fairseq.trainer | begin training epoch 668
2022-03-07 23:33:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:35:05 | INFO | train_inner | epoch 668:     24 / 49 loss=1.55, ppl=2.93, wps=21914.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=32500, lr=0.000175412, gnorm=0.325, loss_scale=32, train_wall=261, gb_free=21.5, wall=96747
2022-03-07 23:36:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:36:21 | INFO | valid | epoch 668 | valid on 'valid' subset | loss 11.081 | ppl 2166.65 | wps 38833.2 | wpb 510.9 | bsz 1 | num_updates 32525 | best_loss 8.723
2022-03-07 23:36:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 668 @ 32525 updates
2022-03-07 23:36:21 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)
2022-03-07 23:36:21 | INFO | train | epoch 668 | loss 1.55 | ppl 2.93 | wps 21989.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32525 | lr 0.000175344 | gnorm 0.327 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 96823
2022-03-07 23:36:21 | INFO | fairseq.trainer | begin training epoch 669
2022-03-07 23:36:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:38:46 | INFO | valid | epoch 669 | valid on 'valid' subset | loss 11.094 | ppl 2185.98 | wps 38846.9 | wpb 510.9 | bsz 1 | num_updates 32574 | best_loss 8.723
2022-03-07 23:38:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 669 @ 32574 updates
2022-03-07 23:38:46 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)
2022-03-07 23:38:46 | INFO | train | epoch 669 | loss 1.55 | ppl 2.93 | wps 21983.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32574 | lr 0.000175212 | gnorm 0.328 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 96967
2022-03-07 23:38:46 | INFO | fairseq.trainer | begin training epoch 670
2022-03-07 23:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:40:00 | INFO | train_inner | epoch 670:     26 / 49 loss=1.55, ppl=2.93, wps=22012.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=32600, lr=0.000175142, gnorm=0.327, loss_scale=64, train_wall=261, gb_free=21.5, wall=97042
2022-03-07 23:40:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:41:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:41:10 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 11.084 | ppl 2170.37 | wps 38812.2 | wpb 510.9 | bsz 1 | num_updates 32622 | best_loss 8.723
2022-03-07 23:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 32622 updates
2022-03-07 23:41:10 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)
2022-03-07 23:41:10 | INFO | train | epoch 670 | loss 1.55 | ppl 2.93 | wps 21548.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32622 | lr 0.000175083 | gnorm 0.328 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 97112
2022-03-07 23:41:10 | INFO | fairseq.trainer | begin training epoch 671
2022-03-07 23:41:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:42:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:43:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:43:34 | INFO | valid | epoch 671 | valid on 'valid' subset | loss 11.086 | ppl 2173.06 | wps 38832.3 | wpb 510.9 | bsz 1 | num_updates 32670 | best_loss 8.723
2022-03-07 23:43:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 671 @ 32670 updates
2022-03-07 23:43:34 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)
2022-03-07 23:43:34 | INFO | train | epoch 671 | loss 1.55 | ppl 2.93 | wps 21538.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32670 | lr 0.000174955 | gnorm 0.328 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 97256
2022-03-07 23:43:35 | INFO | fairseq.trainer | begin training epoch 672
2022-03-07 23:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:45:00 | INFO | train_inner | epoch 672:     30 / 49 loss=1.55, ppl=2.93, wps=21598.8, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=32700, lr=0.000174874, gnorm=0.328, loss_scale=16, train_wall=266, gb_free=21.5, wall=97342
2022-03-07 23:45:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:45:59 | INFO | valid | epoch 672 | valid on 'valid' subset | loss 11.112 | ppl 2213.78 | wps 38950.9 | wpb 510.9 | bsz 1 | num_updates 32719 | best_loss 8.723
2022-03-07 23:45:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 672 @ 32719 updates
2022-03-07 23:45:59 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)
2022-03-07 23:45:59 | INFO | train | epoch 672 | loss 1.549 | ppl 2.93 | wps 22008.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32719 | lr 0.000174824 | gnorm 0.326 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 97401
2022-03-07 23:45:59 | INFO | fairseq.trainer | begin training epoch 673
2022-03-07 23:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:48:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:48:23 | INFO | valid | epoch 673 | valid on 'valid' subset | loss 11.113 | ppl 2215.31 | wps 38972.1 | wpb 510.9 | bsz 1 | num_updates 32768 | best_loss 8.723
2022-03-07 23:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 673 @ 32768 updates
2022-03-07 23:48:23 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)
2022-03-07 23:48:23 | INFO | train | epoch 673 | loss 1.549 | ppl 2.93 | wps 21989.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32768 | lr 0.000174693 | gnorm 0.323 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 97545
2022-03-07 23:48:23 | INFO | fairseq.trainer | begin training epoch 674
2022-03-07 23:48:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:49:55 | INFO | train_inner | epoch 674:     32 / 49 loss=1.549, ppl=2.93, wps=22007.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=32800, lr=0.000174608, gnorm=0.324, loss_scale=32, train_wall=261, gb_free=21.5, wall=97637
2022-03-07 23:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:50:48 | INFO | valid | epoch 674 | valid on 'valid' subset | loss 11.096 | ppl 2188.29 | wps 38887.8 | wpb 510.9 | bsz 1 | num_updates 32817 | best_loss 8.723
2022-03-07 23:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 674 @ 32817 updates
2022-03-07 23:50:48 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)
2022-03-07 23:50:48 | INFO | train | epoch 674 | loss 1.549 | ppl 2.93 | wps 21983.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32817 | lr 0.000174562 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 97690
2022-03-07 23:50:48 | INFO | fairseq.trainer | begin training epoch 675
2022-03-07 23:50:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:52:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:53:12 | INFO | valid | epoch 675 | valid on 'valid' subset | loss 11.072 | ppl 2153.47 | wps 39113.7 | wpb 510.9 | bsz 1 | num_updates 32865 | best_loss 8.723
2022-03-07 23:53:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 675 @ 32865 updates
2022-03-07 23:53:12 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)
2022-03-07 23:53:12 | INFO | train | epoch 675 | loss 1.549 | ppl 2.93 | wps 21548.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32865 | lr 0.000174435 | gnorm 0.329 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 97834
2022-03-07 23:53:12 | INFO | fairseq.trainer | begin training epoch 676
2022-03-07 23:53:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:54:53 | INFO | train_inner | epoch 676:     35 / 49 loss=1.549, ppl=2.93, wps=21797.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=32900, lr=0.000174342, gnorm=0.325, loss_scale=16, train_wall=263, gb_free=21.5, wall=97934
2022-03-07 23:55:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:55:37 | INFO | valid | epoch 676 | valid on 'valid' subset | loss 11.117 | ppl 2221.27 | wps 38840.6 | wpb 510.9 | bsz 1 | num_updates 32914 | best_loss 8.723
2022-03-07 23:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 676 @ 32914 updates
2022-03-07 23:55:37 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)
2022-03-07 23:55:37 | INFO | train | epoch 676 | loss 1.549 | ppl 2.93 | wps 21986.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32914 | lr 0.000174305 | gnorm 0.324 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 97979
2022-03-07 23:55:37 | INFO | fairseq.trainer | begin training epoch 677
2022-03-07 23:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:57:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:58:01 | INFO | valid | epoch 677 | valid on 'valid' subset | loss 11.065 | ppl 2143.05 | wps 39040 | wpb 510.9 | bsz 1 | num_updates 32963 | best_loss 8.723
2022-03-07 23:58:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 677 @ 32963 updates
2022-03-07 23:58:01 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)
2022-03-07 23:58:01 | INFO | train | epoch 677 | loss 1.549 | ppl 2.93 | wps 21997.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32963 | lr 0.000174175 | gnorm 0.325 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 98123
2022-03-07 23:58:01 | INFO | fairseq.trainer | begin training epoch 678
2022-03-07 23:58:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:59:47 | INFO | train_inner | epoch 678:     37 / 49 loss=1.548, ppl=2.92, wps=22017.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33000, lr=0.000174078, gnorm=0.325, loss_scale=32, train_wall=261, gb_free=21.5, wall=98229
2022-03-08 00:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:00:26 | INFO | valid | epoch 678 | valid on 'valid' subset | loss 11.092 | ppl 2182.92 | wps 39253.9 | wpb 510.9 | bsz 1 | num_updates 33012 | best_loss 8.723
2022-03-08 00:00:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 678 @ 33012 updates
2022-03-08 00:00:26 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)
2022-03-08 00:00:26 | INFO | train | epoch 678 | loss 1.548 | ppl 2.92 | wps 22013.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33012 | lr 0.000174046 | gnorm 0.325 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 98268
2022-03-08 00:00:26 | INFO | fairseq.trainer | begin training epoch 679
2022-03-08 00:00:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:02:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:02:50 | INFO | valid | epoch 679 | valid on 'valid' subset | loss 11.09 | ppl 2179.51 | wps 38990.8 | wpb 510.9 | bsz 1 | num_updates 33061 | best_loss 8.723
2022-03-08 00:02:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 679 @ 33061 updates
2022-03-08 00:02:50 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)
2022-03-08 00:02:50 | INFO | train | epoch 679 | loss 1.548 | ppl 2.92 | wps 21988.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33061 | lr 0.000173917 | gnorm 0.328 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 98412
2022-03-08 00:02:50 | INFO | fairseq.trainer | begin training epoch 680
2022-03-08 00:02:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:04:42 | INFO | train_inner | epoch 680:     39 / 49 loss=1.548, ppl=2.92, wps=22020, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33100, lr=0.000173814, gnorm=0.328, loss_scale=32, train_wall=260, gb_free=21.5, wall=98524
2022-03-08 00:05:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:05:15 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 11.112 | ppl 2213.1 | wps 38956.4 | wpb 510.9 | bsz 1 | num_updates 33110 | best_loss 8.723
2022-03-08 00:05:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 33110 updates
2022-03-08 00:05:15 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)
2022-03-08 00:05:15 | INFO | train | epoch 680 | loss 1.548 | ppl 2.92 | wps 22001.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33110 | lr 0.000173788 | gnorm 0.328 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 98557
2022-03-08 00:05:15 | INFO | fairseq.trainer | begin training epoch 681
2022-03-08 00:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:05:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:07:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:07:39 | INFO | valid | epoch 681 | valid on 'valid' subset | loss 11.072 | ppl 2152.46 | wps 38952.4 | wpb 510.9 | bsz 1 | num_updates 33158 | best_loss 8.723
2022-03-08 00:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 681 @ 33158 updates
2022-03-08 00:07:39 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)
2022-03-08 00:07:39 | INFO | train | epoch 681 | loss 1.548 | ppl 2.92 | wps 21551 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33158 | lr 0.000173662 | gnorm 0.328 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 98701
2022-03-08 00:07:39 | INFO | fairseq.trainer | begin training epoch 682
2022-03-08 00:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:08:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:09:42 | INFO | train_inner | epoch 682:     43 / 49 loss=1.548, ppl=2.92, wps=21606.6, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=33200, lr=0.000173553, gnorm=0.328, loss_scale=16, train_wall=266, gb_free=21.5, wall=98824
2022-03-08 00:09:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:10:04 | INFO | valid | epoch 682 | valid on 'valid' subset | loss 11.038 | ppl 2102.56 | wps 38990.2 | wpb 510.9 | bsz 1 | num_updates 33206 | best_loss 8.723
2022-03-08 00:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 682 @ 33206 updates
2022-03-08 00:10:04 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)
2022-03-08 00:10:04 | INFO | train | epoch 682 | loss 1.548 | ppl 2.92 | wps 21556.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33206 | lr 0.000173537 | gnorm 0.327 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 98845
2022-03-08 00:10:04 | INFO | fairseq.trainer | begin training epoch 683
2022-03-08 00:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:12:28 | INFO | valid | epoch 683 | valid on 'valid' subset | loss 11.073 | ppl 2154.84 | wps 38416.1 | wpb 510.9 | bsz 1 | num_updates 33255 | best_loss 8.723
2022-03-08 00:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 683 @ 33255 updates
2022-03-08 00:12:28 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)
2022-03-08 00:12:28 | INFO | train | epoch 683 | loss 1.547 | ppl 2.92 | wps 22002.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33255 | lr 0.000173409 | gnorm 0.323 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 98990
2022-03-08 00:12:28 | INFO | fairseq.trainer | begin training epoch 684
2022-03-08 00:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:14:37 | INFO | train_inner | epoch 684:     45 / 49 loss=1.547, ppl=2.92, wps=22023.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=33300, lr=0.000173292, gnorm=0.325, loss_scale=16, train_wall=260, gb_free=21.5, wall=99119
2022-03-08 00:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:14:52 | INFO | valid | epoch 684 | valid on 'valid' subset | loss 11.089 | ppl 2178.23 | wps 38805.4 | wpb 510.9 | bsz 1 | num_updates 33304 | best_loss 8.723
2022-03-08 00:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 684 @ 33304 updates
2022-03-08 00:14:52 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)
2022-03-08 00:14:52 | INFO | train | epoch 684 | loss 1.547 | ppl 2.92 | wps 22011.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33304 | lr 0.000173281 | gnorm 0.327 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 99134
2022-03-08 00:14:52 | INFO | fairseq.trainer | begin training epoch 685
2022-03-08 00:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:17:17 | INFO | valid | epoch 685 | valid on 'valid' subset | loss 11.115 | ppl 2218.32 | wps 38905.8 | wpb 510.9 | bsz 1 | num_updates 33353 | best_loss 8.723
2022-03-08 00:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 685 @ 33353 updates
2022-03-08 00:17:17 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)
2022-03-08 00:17:17 | INFO | train | epoch 685 | loss 1.547 | ppl 2.92 | wps 22001.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33353 | lr 0.000173154 | gnorm 0.322 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 99279
2022-03-08 00:17:17 | INFO | fairseq.trainer | begin training epoch 686
2022-03-08 00:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:18:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:19:34 | INFO | train_inner | epoch 686:     48 / 49 loss=1.547, ppl=2.92, wps=21806.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33400, lr=0.000173032, gnorm=0.325, loss_scale=16, train_wall=263, gb_free=21.5, wall=99416
2022-03-08 00:19:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:19:41 | INFO | valid | epoch 686 | valid on 'valid' subset | loss 11.082 | ppl 2168.02 | wps 38974 | wpb 510.9 | bsz 1 | num_updates 33401 | best_loss 8.723
2022-03-08 00:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 686 @ 33401 updates
2022-03-08 00:19:41 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)
2022-03-08 00:19:41 | INFO | train | epoch 686 | loss 1.547 | ppl 2.92 | wps 21546.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33401 | lr 0.00017303 | gnorm 0.328 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 99423
2022-03-08 00:19:41 | INFO | fairseq.trainer | begin training epoch 687
2022-03-08 00:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:22:06 | INFO | valid | epoch 687 | valid on 'valid' subset | loss 11.105 | ppl 2203.28 | wps 38893.6 | wpb 510.9 | bsz 1 | num_updates 33450 | best_loss 8.723
2022-03-08 00:22:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 687 @ 33450 updates
2022-03-08 00:22:06 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)
2022-03-08 00:22:06 | INFO | train | epoch 687 | loss 1.547 | ppl 2.92 | wps 22023.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33450 | lr 0.000172903 | gnorm 0.321 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 99567
2022-03-08 00:22:06 | INFO | fairseq.trainer | begin training epoch 688
2022-03-08 00:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:24:30 | INFO | valid | epoch 688 | valid on 'valid' subset | loss 11.089 | ppl 2178.35 | wps 38980.4 | wpb 510.9 | bsz 1 | num_updates 33499 | best_loss 8.723
2022-03-08 00:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 688 @ 33499 updates
2022-03-08 00:24:30 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)
2022-03-08 00:24:30 | INFO | train | epoch 688 | loss 1.547 | ppl 2.92 | wps 21999.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33499 | lr 0.000172776 | gnorm 0.328 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 99712
2022-03-08 00:24:30 | INFO | fairseq.trainer | begin training epoch 689
2022-03-08 00:24:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:24:33 | INFO | train_inner | epoch 689:      1 / 49 loss=1.547, ppl=2.92, wps=21600.8, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=33500, lr=0.000172774, gnorm=0.326, loss_scale=32, train_wall=259, gb_free=21.5, wall=99715
2022-03-08 00:26:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:26:55 | INFO | valid | epoch 689 | valid on 'valid' subset | loss 11.071 | ppl 2151.84 | wps 38950.6 | wpb 510.9 | bsz 1 | num_updates 33548 | best_loss 8.723
2022-03-08 00:26:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 689 @ 33548 updates
2022-03-08 00:26:55 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)
2022-03-08 00:26:55 | INFO | train | epoch 689 | loss 1.546 | ppl 2.92 | wps 21999.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33548 | lr 0.00017265 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 99856
2022-03-08 00:26:55 | INFO | fairseq.trainer | begin training epoch 690
2022-03-08 00:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:29:19 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 11.107 | ppl 2205 | wps 38867.2 | wpb 510.9 | bsz 1 | num_updates 33597 | best_loss 8.723
2022-03-08 00:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 33597 updates
2022-03-08 00:29:19 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)
2022-03-08 00:29:19 | INFO | train | epoch 690 | loss 1.546 | ppl 2.92 | wps 22009.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33597 | lr 0.000172524 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 100001
2022-03-08 00:29:19 | INFO | fairseq.trainer | begin training epoch 691
2022-03-08 00:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:29:28 | INFO | train_inner | epoch 691:      3 / 49 loss=1.546, ppl=2.92, wps=22021.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33600, lr=0.000172516, gnorm=0.324, loss_scale=32, train_wall=261, gb_free=21.5, wall=100009
2022-03-08 00:30:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:31:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:31:43 | INFO | valid | epoch 691 | valid on 'valid' subset | loss 11.064 | ppl 2141.25 | wps 38900.8 | wpb 510.9 | bsz 1 | num_updates 33645 | best_loss 8.723
2022-03-08 00:31:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 691 @ 33645 updates
2022-03-08 00:31:43 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)
2022-03-08 00:31:43 | INFO | train | epoch 691 | loss 1.546 | ppl 2.92 | wps 21539.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33645 | lr 0.000172401 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 100145
2022-03-08 00:31:43 | INFO | fairseq.trainer | begin training epoch 692
2022-03-08 00:31:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:34:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:34:08 | INFO | valid | epoch 692 | valid on 'valid' subset | loss 11.101 | ppl 2197.13 | wps 38928 | wpb 510.9 | bsz 1 | num_updates 33694 | best_loss 8.723
2022-03-08 00:34:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 692 @ 33694 updates
2022-03-08 00:34:08 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)
2022-03-08 00:34:08 | INFO | train | epoch 692 | loss 1.546 | ppl 2.92 | wps 22020.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33694 | lr 0.000172276 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 100290
2022-03-08 00:34:08 | INFO | fairseq.trainer | begin training epoch 693
2022-03-08 00:34:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:34:25 | INFO | train_inner | epoch 693:      6 / 49 loss=1.546, ppl=2.92, wps=21810.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33700, lr=0.00017226, gnorm=0.323, loss_scale=32, train_wall=263, gb_free=21.5, wall=100307
2022-03-08 00:34:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:36:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:36:32 | INFO | valid | epoch 693 | valid on 'valid' subset | loss 11.068 | ppl 2146.11 | wps 38775.8 | wpb 510.9 | bsz 1 | num_updates 33742 | best_loss 8.723
2022-03-08 00:36:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 693 @ 33742 updates
2022-03-08 00:36:32 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)
2022-03-08 00:36:32 | INFO | train | epoch 693 | loss 1.545 | ppl 2.92 | wps 21558.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33742 | lr 0.000172153 | gnorm 0.323 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 100434
2022-03-08 00:36:32 | INFO | fairseq.trainer | begin training epoch 694
2022-03-08 00:36:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:38:57 | INFO | valid | epoch 694 | valid on 'valid' subset | loss 11.083 | ppl 2168.94 | wps 38915 | wpb 510.9 | bsz 1 | num_updates 33791 | best_loss 8.723
2022-03-08 00:38:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 694 @ 33791 updates
2022-03-08 00:38:57 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)
2022-03-08 00:38:57 | INFO | train | epoch 694 | loss 1.545 | ppl 2.92 | wps 22006.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33791 | lr 0.000172028 | gnorm 0.322 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 100578
2022-03-08 00:38:57 | INFO | fairseq.trainer | begin training epoch 695
2022-03-08 00:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:39:22 | INFO | train_inner | epoch 695:      9 / 49 loss=1.545, ppl=2.92, wps=21818.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33800, lr=0.000172005, gnorm=0.323, loss_scale=16, train_wall=263, gb_free=21.5, wall=100604
2022-03-08 00:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:41:21 | INFO | valid | epoch 695 | valid on 'valid' subset | loss 11.044 | ppl 2112.1 | wps 39106.3 | wpb 510.9 | bsz 1 | num_updates 33840 | best_loss 8.723
2022-03-08 00:41:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 695 @ 33840 updates
2022-03-08 00:41:21 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)
2022-03-08 00:41:21 | INFO | train | epoch 695 | loss 1.545 | ppl 2.92 | wps 22004.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33840 | lr 0.000171904 | gnorm 0.325 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 100723
2022-03-08 00:41:21 | INFO | fairseq.trainer | begin training epoch 696
2022-03-08 00:41:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:43:45 | INFO | valid | epoch 696 | valid on 'valid' subset | loss 11.078 | ppl 2162.52 | wps 39087.2 | wpb 510.9 | bsz 1 | num_updates 33889 | best_loss 8.723
2022-03-08 00:43:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 696 @ 33889 updates
2022-03-08 00:43:45 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)
2022-03-08 00:43:45 | INFO | train | epoch 696 | loss 1.545 | ppl 2.92 | wps 22028.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33889 | lr 0.000171779 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 100867
2022-03-08 00:43:45 | INFO | fairseq.trainer | begin training epoch 697
2022-03-08 00:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:44:17 | INFO | train_inner | epoch 697:     11 / 49 loss=1.545, ppl=2.92, wps=22035.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33900, lr=0.000171751, gnorm=0.324, loss_scale=32, train_wall=260, gb_free=21.5, wall=100899
2022-03-08 00:45:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:46:10 | INFO | valid | epoch 697 | valid on 'valid' subset | loss 11.099 | ppl 2194.11 | wps 39014.7 | wpb 510.9 | bsz 1 | num_updates 33937 | best_loss 8.723
2022-03-08 00:46:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 697 @ 33937 updates
2022-03-08 00:46:10 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)
2022-03-08 00:46:10 | INFO | train | epoch 697 | loss 1.544 | ppl 2.92 | wps 21559.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33937 | lr 0.000171658 | gnorm 0.325 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 101011
2022-03-08 00:46:10 | INFO | fairseq.trainer | begin training epoch 698
2022-03-08 00:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:48:34 | INFO | valid | epoch 698 | valid on 'valid' subset | loss 11.072 | ppl 2153.28 | wps 38919.6 | wpb 510.9 | bsz 1 | num_updates 33986 | best_loss 8.723
2022-03-08 00:48:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 698 @ 33986 updates
2022-03-08 00:48:34 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)
2022-03-08 00:48:34 | INFO | train | epoch 698 | loss 1.545 | ppl 2.92 | wps 22012.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33986 | lr 0.000171534 | gnorm 0.328 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 101156
2022-03-08 00:48:34 | INFO | fairseq.trainer | begin training epoch 699
2022-03-08 00:48:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:49:14 | INFO | train_inner | epoch 699:     14 / 49 loss=1.545, ppl=2.92, wps=21812.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34000, lr=0.000171499, gnorm=0.327, loss_scale=16, train_wall=263, gb_free=21.5, wall=101196
2022-03-08 00:50:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:50:58 | INFO | valid | epoch 699 | valid on 'valid' subset | loss 11.034 | ppl 2096.73 | wps 38863.6 | wpb 510.9 | bsz 1 | num_updates 34035 | best_loss 8.723
2022-03-08 00:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 699 @ 34035 updates
2022-03-08 00:50:58 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)
2022-03-08 00:50:58 | INFO | train | epoch 699 | loss 1.544 | ppl 2.92 | wps 22007.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34035 | lr 0.00017141 | gnorm 0.322 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 101300
2022-03-08 00:50:58 | INFO | fairseq.trainer | begin training epoch 700
2022-03-08 00:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:53:23 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 11.091 | ppl 2181.05 | wps 39077.7 | wpb 510.9 | bsz 1 | num_updates 34084 | best_loss 8.723
2022-03-08 00:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 34084 updates
2022-03-08 00:53:23 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)
2022-03-08 00:53:23 | INFO | train | epoch 700 | loss 1.544 | ppl 2.92 | wps 22004.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34084 | lr 0.000171287 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 101445
2022-03-08 00:53:23 | INFO | fairseq.trainer | begin training epoch 701
2022-03-08 00:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:54:09 | INFO | train_inner | epoch 701:     16 / 49 loss=1.544, ppl=2.92, wps=22027.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34100, lr=0.000171247, gnorm=0.321, loss_scale=32, train_wall=260, gb_free=21.5, wall=101490
2022-03-08 00:55:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:55:47 | INFO | valid | epoch 701 | valid on 'valid' subset | loss 11.08 | ppl 2165.3 | wps 39012.7 | wpb 510.9 | bsz 1 | num_updates 34133 | best_loss 8.723
2022-03-08 00:55:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 701 @ 34133 updates
2022-03-08 00:55:47 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)
2022-03-08 00:55:47 | INFO | train | epoch 701 | loss 1.544 | ppl 2.92 | wps 22012.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34133 | lr 0.000171164 | gnorm 0.326 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 101589
2022-03-08 00:55:47 | INFO | fairseq.trainer | begin training epoch 702
2022-03-08 00:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:57:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:58:12 | INFO | valid | epoch 702 | valid on 'valid' subset | loss 11.093 | ppl 2184.23 | wps 38935.6 | wpb 510.9 | bsz 1 | num_updates 34181 | best_loss 8.723
2022-03-08 00:58:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 702 @ 34181 updates
2022-03-08 00:58:12 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)
2022-03-08 00:58:12 | INFO | train | epoch 702 | loss 1.544 | ppl 2.92 | wps 21551.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34181 | lr 0.000171044 | gnorm 0.322 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 101733
2022-03-08 00:58:12 | INFO | fairseq.trainer | begin training epoch 703
2022-03-08 00:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:59:06 | INFO | train_inner | epoch 703:     19 / 49 loss=1.544, ppl=2.92, wps=21818.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=34200, lr=0.000170996, gnorm=0.323, loss_scale=16, train_wall=263, gb_free=21.5, wall=101788
2022-03-08 01:00:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:00:36 | INFO | valid | epoch 703 | valid on 'valid' subset | loss 11.106 | ppl 2203.43 | wps 38748.5 | wpb 510.9 | bsz 1 | num_updates 34230 | best_loss 8.723
2022-03-08 01:00:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 703 @ 34230 updates
2022-03-08 01:00:36 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)
2022-03-08 01:00:36 | INFO | train | epoch 703 | loss 1.543 | ppl 2.91 | wps 22016.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34230 | lr 0.000170921 | gnorm 0.321 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 101878
2022-03-08 01:00:36 | INFO | fairseq.trainer | begin training epoch 704
2022-03-08 01:00:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:02:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:03:00 | INFO | valid | epoch 704 | valid on 'valid' subset | loss 11.067 | ppl 2145.07 | wps 38640.8 | wpb 510.9 | bsz 1 | num_updates 34279 | best_loss 8.723
2022-03-08 01:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 704 @ 34279 updates
2022-03-08 01:03:00 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)
2022-03-08 01:03:00 | INFO | train | epoch 704 | loss 1.543 | ppl 2.91 | wps 22012.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34279 | lr 0.000170799 | gnorm 0.322 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 102022
2022-03-08 01:03:00 | INFO | fairseq.trainer | begin training epoch 705
2022-03-08 01:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:04:01 | INFO | train_inner | epoch 705:     21 / 49 loss=1.543, ppl=2.91, wps=22021, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34300, lr=0.000170747, gnorm=0.322, loss_scale=32, train_wall=260, gb_free=21.5, wall=102082
2022-03-08 01:05:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:05:25 | INFO | valid | epoch 705 | valid on 'valid' subset | loss 11.091 | ppl 2181.75 | wps 39136.4 | wpb 510.9 | bsz 1 | num_updates 34328 | best_loss 8.723
2022-03-08 01:05:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 705 @ 34328 updates
2022-03-08 01:05:25 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)
2022-03-08 01:05:25 | INFO | train | epoch 705 | loss 1.543 | ppl 2.91 | wps 22000.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34328 | lr 0.000170677 | gnorm 0.323 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 102167
2022-03-08 01:05:25 | INFO | fairseq.trainer | begin training epoch 706
2022-03-08 01:05:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:07:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:07:49 | INFO | valid | epoch 706 | valid on 'valid' subset | loss 11.096 | ppl 2188.78 | wps 39070.6 | wpb 510.9 | bsz 1 | num_updates 34377 | best_loss 8.723
2022-03-08 01:07:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 706 @ 34377 updates
2022-03-08 01:07:49 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)
2022-03-08 01:07:49 | INFO | train | epoch 706 | loss 1.543 | ppl 2.91 | wps 22021.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34377 | lr 0.000170556 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 102311
2022-03-08 01:07:49 | INFO | fairseq.trainer | begin training epoch 707
2022-03-08 01:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:08:55 | INFO | train_inner | epoch 707:     23 / 49 loss=1.543, ppl=2.91, wps=22039.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=34400, lr=0.000170499, gnorm=0.321, loss_scale=32, train_wall=260, gb_free=21.5, wall=102377
2022-03-08 01:10:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:10:13 | INFO | valid | epoch 707 | valid on 'valid' subset | loss 11.042 | ppl 2108.22 | wps 38961.4 | wpb 510.9 | bsz 1 | num_updates 34426 | best_loss 8.723
2022-03-08 01:10:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 707 @ 34426 updates
2022-03-08 01:10:13 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)
2022-03-08 01:10:13 | INFO | train | epoch 707 | loss 1.542 | ppl 2.91 | wps 22015.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34426 | lr 0.000170434 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 102455
2022-03-08 01:10:14 | INFO | fairseq.trainer | begin training epoch 708
2022-03-08 01:10:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:10:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:12:38 | INFO | valid | epoch 708 | valid on 'valid' subset | loss 11.068 | ppl 2146.72 | wps 38848.5 | wpb 510.9 | bsz 1 | num_updates 34474 | best_loss 8.723
2022-03-08 01:12:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 708 @ 34474 updates
2022-03-08 01:12:38 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)
2022-03-08 01:12:38 | INFO | train | epoch 708 | loss 1.542 | ppl 2.91 | wps 21560.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34474 | lr 0.000170315 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 102600
2022-03-08 01:12:38 | INFO | fairseq.trainer | begin training epoch 709
2022-03-08 01:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:13:52 | INFO | train_inner | epoch 709:     26 / 49 loss=1.542, ppl=2.91, wps=21819.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=34500, lr=0.000170251, gnorm=0.323, loss_scale=32, train_wall=263, gb_free=21.5, wall=102674
2022-03-08 01:14:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:15:02 | INFO | valid | epoch 709 | valid on 'valid' subset | loss 11.061 | ppl 2136.86 | wps 38964.8 | wpb 510.9 | bsz 1 | num_updates 34523 | best_loss 8.723
2022-03-08 01:15:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 709 @ 34523 updates
2022-03-08 01:15:02 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)
2022-03-08 01:15:02 | INFO | train | epoch 709 | loss 1.542 | ppl 2.91 | wps 22013.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34523 | lr 0.000170195 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 102744
2022-03-08 01:15:02 | INFO | fairseq.trainer | begin training epoch 710
2022-03-08 01:15:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:16:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:17:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:17:27 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 11.095 | ppl 2187.97 | wps 38951.9 | wpb 510.9 | bsz 1 | num_updates 34571 | best_loss 8.723
2022-03-08 01:17:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 34571 updates
2022-03-08 01:17:27 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)
2022-03-08 01:17:27 | INFO | train | epoch 710 | loss 1.542 | ppl 2.91 | wps 21553.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34571 | lr 0.000170076 | gnorm 0.323 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 102888
2022-03-08 01:17:27 | INFO | fairseq.trainer | begin training epoch 711
2022-03-08 01:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:18:50 | INFO | train_inner | epoch 711:     29 / 49 loss=1.542, ppl=2.91, wps=21818.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=34600, lr=0.000170005, gnorm=0.322, loss_scale=32, train_wall=263, gb_free=21.5, wall=102971
2022-03-08 01:19:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:19:51 | INFO | valid | epoch 711 | valid on 'valid' subset | loss 11.075 | ppl 2157.94 | wps 38840.3 | wpb 510.9 | bsz 1 | num_updates 34620 | best_loss 8.723
2022-03-08 01:19:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 711 @ 34620 updates
2022-03-08 01:19:51 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)
2022-03-08 01:19:51 | INFO | train | epoch 711 | loss 1.542 | ppl 2.91 | wps 22012.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34620 | lr 0.000169956 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 103033
2022-03-08 01:19:51 | INFO | fairseq.trainer | begin training epoch 712
2022-03-08 01:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:22:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:22:15 | INFO | valid | epoch 712 | valid on 'valid' subset | loss 11.118 | ppl 2222.73 | wps 38987.4 | wpb 510.9 | bsz 1 | num_updates 34669 | best_loss 8.723
2022-03-08 01:22:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 712 @ 34669 updates
2022-03-08 01:22:15 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)
2022-03-08 01:22:15 | INFO | train | epoch 712 | loss 1.542 | ppl 2.91 | wps 22011.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34669 | lr 0.000169836 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 103177
2022-03-08 01:22:15 | INFO | fairseq.trainer | begin training epoch 713
2022-03-08 01:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:23:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:23:47 | INFO | train_inner | epoch 713:     32 / 49 loss=1.542, ppl=2.91, wps=21811.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=34700, lr=0.00016976, gnorm=0.321, loss_scale=32, train_wall=263, gb_free=21.5, wall=103269
2022-03-08 01:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:24:40 | INFO | valid | epoch 713 | valid on 'valid' subset | loss 11.125 | ppl 2234.05 | wps 38988.9 | wpb 510.9 | bsz 1 | num_updates 34717 | best_loss 8.723
2022-03-08 01:24:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 713 @ 34717 updates
2022-03-08 01:24:40 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)
2022-03-08 01:24:40 | INFO | train | epoch 713 | loss 1.541 | ppl 2.91 | wps 21558.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34717 | lr 0.000169718 | gnorm 0.32 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 103322
2022-03-08 01:24:40 | INFO | fairseq.trainer | begin training epoch 714
2022-03-08 01:24:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:26:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:27:04 | INFO | valid | epoch 714 | valid on 'valid' subset | loss 11.077 | ppl 2160.65 | wps 38913.8 | wpb 510.9 | bsz 1 | num_updates 34766 | best_loss 8.723
2022-03-08 01:27:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 714 @ 34766 updates
2022-03-08 01:27:04 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)
2022-03-08 01:27:04 | INFO | train | epoch 714 | loss 1.542 | ppl 2.91 | wps 22010.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34766 | lr 0.000169599 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 103466
2022-03-08 01:27:04 | INFO | fairseq.trainer | begin training epoch 715
2022-03-08 01:27:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:28:41 | INFO | train_inner | epoch 715:     34 / 49 loss=1.541, ppl=2.91, wps=22034.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=34800, lr=0.000169516, gnorm=0.321, loss_scale=32, train_wall=260, gb_free=21.5, wall=103563
2022-03-08 01:29:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:29:29 | INFO | valid | epoch 715 | valid on 'valid' subset | loss 11.084 | ppl 2170.58 | wps 38851.4 | wpb 510.9 | bsz 1 | num_updates 34815 | best_loss 8.723
2022-03-08 01:29:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 715 @ 34815 updates
2022-03-08 01:29:29 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)
2022-03-08 01:29:29 | INFO | train | epoch 715 | loss 1.541 | ppl 2.91 | wps 22013.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34815 | lr 0.000169479 | gnorm 0.318 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 103610
2022-03-08 01:29:29 | INFO | fairseq.trainer | begin training epoch 716
2022-03-08 01:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:29:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:31:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:31:53 | INFO | valid | epoch 716 | valid on 'valid' subset | loss 11.064 | ppl 2141.27 | wps 38881 | wpb 510.9 | bsz 1 | num_updates 34863 | best_loss 8.723
2022-03-08 01:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 716 @ 34863 updates
2022-03-08 01:31:53 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)
2022-03-08 01:31:53 | INFO | train | epoch 716 | loss 1.541 | ppl 2.91 | wps 21528.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34863 | lr 0.000169363 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 103755
2022-03-08 01:31:53 | INFO | fairseq.trainer | begin training epoch 717
2022-03-08 01:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:33:39 | INFO | train_inner | epoch 717:     37 / 49 loss=1.541, ppl=2.91, wps=21806.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34900, lr=0.000169273, gnorm=0.323, loss_scale=32, train_wall=263, gb_free=21.5, wall=103861
2022-03-08 01:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:34:17 | INFO | valid | epoch 717 | valid on 'valid' subset | loss 11.108 | ppl 2207.28 | wps 38695 | wpb 510.9 | bsz 1 | num_updates 34912 | best_loss 8.723
2022-03-08 01:34:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 717 @ 34912 updates
2022-03-08 01:34:17 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)
2022-03-08 01:34:17 | INFO | train | epoch 717 | loss 1.541 | ppl 2.91 | wps 22010.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34912 | lr 0.000169244 | gnorm 0.325 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 103899
2022-03-08 01:34:18 | INFO | fairseq.trainer | begin training epoch 718
2022-03-08 01:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:36:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:36:42 | INFO | valid | epoch 718 | valid on 'valid' subset | loss 11.087 | ppl 2174.9 | wps 38986.1 | wpb 510.9 | bsz 1 | num_updates 34960 | best_loss 8.723
2022-03-08 01:36:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 718 @ 34960 updates
2022-03-08 01:36:42 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)
2022-03-08 01:36:42 | INFO | train | epoch 718 | loss 1.541 | ppl 2.91 | wps 21561.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34960 | lr 0.000169128 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 104044
2022-03-08 01:36:42 | INFO | fairseq.trainer | begin training epoch 719
2022-03-08 01:36:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:38:36 | INFO | train_inner | epoch 719:     40 / 49 loss=1.54, ppl=2.91, wps=21805.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=35000, lr=0.000169031, gnorm=0.321, loss_scale=32, train_wall=263, gb_free=21.5, wall=104158
2022-03-08 01:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:39:06 | INFO | valid | epoch 719 | valid on 'valid' subset | loss 11.076 | ppl 2159.2 | wps 39029.6 | wpb 510.9 | bsz 1 | num_updates 35009 | best_loss 8.723
2022-03-08 01:39:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 719 @ 35009 updates
2022-03-08 01:39:06 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)
2022-03-08 01:39:06 | INFO | train | epoch 719 | loss 1.54 | ppl 2.91 | wps 21990.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35009 | lr 0.000169009 | gnorm 0.316 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 104188
2022-03-08 01:39:06 | INFO | fairseq.trainer | begin training epoch 720
2022-03-08 01:39:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:41:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:41:31 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 11.073 | ppl 2154.94 | wps 39132 | wpb 510.9 | bsz 1 | num_updates 35058 | best_loss 8.723
2022-03-08 01:41:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 35058 updates
2022-03-08 01:41:31 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)
2022-03-08 01:41:31 | INFO | train | epoch 720 | loss 1.541 | ppl 2.91 | wps 22019.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35058 | lr 0.000168891 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 104332
2022-03-08 01:41:31 | INFO | fairseq.trainer | begin training epoch 721
2022-03-08 01:41:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:42:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:42:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:43:37 | INFO | train_inner | epoch 721:     44 / 49 loss=1.54, ppl=2.91, wps=21608.8, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=35100, lr=0.00016879, gnorm=0.319, loss_scale=16, train_wall=266, gb_free=21.5, wall=104458
2022-03-08 01:43:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:43:55 | INFO | valid | epoch 721 | valid on 'valid' subset | loss 11.096 | ppl 2189.05 | wps 39065.7 | wpb 510.9 | bsz 1 | num_updates 35105 | best_loss 8.723
2022-03-08 01:43:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 721 @ 35105 updates
2022-03-08 01:43:55 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)
2022-03-08 01:43:55 | INFO | train | epoch 721 | loss 1.54 | ppl 2.91 | wps 21096.4 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 35105 | lr 0.000168778 | gnorm 0.317 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 104477
2022-03-08 01:43:55 | INFO | fairseq.trainer | begin training epoch 722
2022-03-08 01:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:46:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:46:19 | INFO | valid | epoch 722 | valid on 'valid' subset | loss 11.068 | ppl 2146.94 | wps 39159.9 | wpb 510.9 | bsz 1 | num_updates 35154 | best_loss 8.723
2022-03-08 01:46:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 722 @ 35154 updates
2022-03-08 01:46:19 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)
2022-03-08 01:46:19 | INFO | train | epoch 722 | loss 1.54 | ppl 2.91 | wps 22017.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35154 | lr 0.00016866 | gnorm 0.319 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 104621
2022-03-08 01:46:19 | INFO | fairseq.trainer | begin training epoch 723
2022-03-08 01:46:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:48:31 | INFO | train_inner | epoch 723:     46 / 49 loss=1.54, ppl=2.91, wps=22035.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35200, lr=0.00016855, gnorm=0.32, loss_scale=16, train_wall=260, gb_free=21.5, wall=104753
2022-03-08 01:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:48:44 | INFO | valid | epoch 723 | valid on 'valid' subset | loss 11.064 | ppl 2140.63 | wps 38802 | wpb 510.9 | bsz 1 | num_updates 35203 | best_loss 8.723
2022-03-08 01:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 723 @ 35203 updates
2022-03-08 01:48:44 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)
2022-03-08 01:48:44 | INFO | train | epoch 723 | loss 1.54 | ppl 2.91 | wps 22010.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35203 | lr 0.000168543 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 104766
2022-03-08 01:48:44 | INFO | fairseq.trainer | begin training epoch 724
2022-03-08 01:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:51:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:51:08 | INFO | valid | epoch 724 | valid on 'valid' subset | loss 11.1 | ppl 2194.46 | wps 39066.8 | wpb 510.9 | bsz 1 | num_updates 35252 | best_loss 8.723
2022-03-08 01:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 724 @ 35252 updates
2022-03-08 01:51:08 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)
2022-03-08 01:51:08 | INFO | train | epoch 724 | loss 1.539 | ppl 2.91 | wps 22010 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35252 | lr 0.000168426 | gnorm 0.318 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 104910
2022-03-08 01:51:08 | INFO | fairseq.trainer | begin training epoch 725
2022-03-08 01:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:53:26 | INFO | train_inner | epoch 725:     48 / 49 loss=1.539, ppl=2.91, wps=22019.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35300, lr=0.000168311, gnorm=0.318, loss_scale=32, train_wall=261, gb_free=21.5, wall=105047
2022-03-08 01:53:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:53:33 | INFO | valid | epoch 725 | valid on 'valid' subset | loss 11.064 | ppl 2141.38 | wps 38976.3 | wpb 510.9 | bsz 1 | num_updates 35301 | best_loss 8.723
2022-03-08 01:53:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 725 @ 35301 updates
2022-03-08 01:53:33 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)
2022-03-08 01:53:33 | INFO | train | epoch 725 | loss 1.539 | ppl 2.91 | wps 21997.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35301 | lr 0.000168309 | gnorm 0.317 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 105054
2022-03-08 01:53:33 | INFO | fairseq.trainer | begin training epoch 726
2022-03-08 01:53:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:55:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:55:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:55:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:55:57 | INFO | valid | epoch 726 | valid on 'valid' subset | loss 11.058 | ppl 2132.15 | wps 39057.6 | wpb 510.9 | bsz 1 | num_updates 35348 | best_loss 8.723
2022-03-08 01:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 726 @ 35348 updates
2022-03-08 01:55:57 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)
2022-03-08 01:55:57 | INFO | train | epoch 726 | loss 1.539 | ppl 2.91 | wps 21110.2 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 35348 | lr 0.000168197 | gnorm 0.32 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 105199
2022-03-08 01:55:57 | INFO | fairseq.trainer | begin training epoch 727
2022-03-08 01:55:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:58:21 | INFO | valid | epoch 727 | valid on 'valid' subset | loss 11.074 | ppl 2155.68 | wps 38961 | wpb 510.9 | bsz 1 | num_updates 35397 | best_loss 8.723
2022-03-08 01:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 727 @ 35397 updates
2022-03-08 01:58:21 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)
2022-03-08 01:58:21 | INFO | train | epoch 727 | loss 1.539 | ppl 2.91 | wps 22009.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35397 | lr 0.00016808 | gnorm 0.321 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 105343
2022-03-08 01:58:21 | INFO | fairseq.trainer | begin training epoch 728
2022-03-08 01:58:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:58:30 | INFO | train_inner | epoch 728:      3 / 49 loss=1.539, ppl=2.91, wps=21195.7, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=35400, lr=0.000168073, gnorm=0.321, loss_scale=16, train_wall=264, gb_free=21.5, wall=105352
2022-03-08 02:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:00:46 | INFO | valid | epoch 728 | valid on 'valid' subset | loss 11.047 | ppl 2115.3 | wps 38874.6 | wpb 510.9 | bsz 1 | num_updates 35446 | best_loss 8.723
2022-03-08 02:00:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 728 @ 35446 updates
2022-03-08 02:00:46 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)
2022-03-08 02:00:46 | INFO | train | epoch 728 | loss 1.539 | ppl 2.91 | wps 22027.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35446 | lr 0.000167964 | gnorm 0.319 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 105487
2022-03-08 02:00:46 | INFO | fairseq.trainer | begin training epoch 729
2022-03-08 02:00:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:03:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:03:10 | INFO | valid | epoch 729 | valid on 'valid' subset | loss 11.081 | ppl 2166.48 | wps 38635.3 | wpb 510.9 | bsz 1 | num_updates 35495 | best_loss 8.723
2022-03-08 02:03:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 729 @ 35495 updates
2022-03-08 02:03:10 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)
2022-03-08 02:03:10 | INFO | train | epoch 729 | loss 1.539 | ppl 2.91 | wps 21986.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35495 | lr 0.000167848 | gnorm 0.32 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 105632
2022-03-08 02:03:10 | INFO | fairseq.trainer | begin training epoch 730
2022-03-08 02:03:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:03:25 | INFO | train_inner | epoch 730:      5 / 49 loss=1.539, ppl=2.91, wps=22024.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35500, lr=0.000167836, gnorm=0.32, loss_scale=32, train_wall=260, gb_free=21.5, wall=105646
2022-03-08 02:05:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:05:35 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 11.034 | ppl 2096.81 | wps 38916.1 | wpb 510.9 | bsz 1 | num_updates 35544 | best_loss 8.723
2022-03-08 02:05:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 35544 updates
2022-03-08 02:05:35 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)
2022-03-08 02:05:35 | INFO | train | epoch 730 | loss 1.539 | ppl 2.91 | wps 21994.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35544 | lr 0.000167732 | gnorm 0.324 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 105777
2022-03-08 02:05:35 | INFO | fairseq.trainer | begin training epoch 731
2022-03-08 02:05:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:07:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:07:59 | INFO | valid | epoch 731 | valid on 'valid' subset | loss 11.082 | ppl 2167.4 | wps 38803.1 | wpb 510.9 | bsz 1 | num_updates 35593 | best_loss 8.723
2022-03-08 02:07:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 731 @ 35593 updates
2022-03-08 02:07:59 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)
2022-03-08 02:07:59 | INFO | train | epoch 731 | loss 1.539 | ppl 2.91 | wps 21998.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35593 | lr 0.000167617 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 105921
2022-03-08 02:07:59 | INFO | fairseq.trainer | begin training epoch 732
2022-03-08 02:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:08:19 | INFO | train_inner | epoch 732:      7 / 49 loss=1.539, ppl=2.91, wps=22010.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35600, lr=0.0001676, gnorm=0.322, loss_scale=64, train_wall=261, gb_free=21.5, wall=105941
2022-03-08 02:08:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:10:24 | INFO | valid | epoch 732 | valid on 'valid' subset | loss 11.073 | ppl 2154.33 | wps 38712.1 | wpb 510.9 | bsz 1 | num_updates 35641 | best_loss 8.723
2022-03-08 02:10:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 732 @ 35641 updates
2022-03-08 02:10:24 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)
2022-03-08 02:10:24 | INFO | train | epoch 732 | loss 1.538 | ppl 2.9 | wps 21540.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35641 | lr 0.000167504 | gnorm 0.316 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 106065
2022-03-08 02:10:24 | INFO | fairseq.trainer | begin training epoch 733
2022-03-08 02:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:12:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:12:48 | INFO | valid | epoch 733 | valid on 'valid' subset | loss 11.059 | ppl 2133.12 | wps 38939.1 | wpb 510.9 | bsz 1 | num_updates 35690 | best_loss 8.723
2022-03-08 02:12:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 733 @ 35690 updates
2022-03-08 02:12:48 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)
2022-03-08 02:12:48 | INFO | train | epoch 733 | loss 1.538 | ppl 2.9 | wps 21983.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35690 | lr 0.000167389 | gnorm 0.318 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 106210
2022-03-08 02:12:48 | INFO | fairseq.trainer | begin training epoch 734
2022-03-08 02:12:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:13:17 | INFO | train_inner | epoch 734:     10 / 49 loss=1.538, ppl=2.9, wps=21799.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35700, lr=0.000167365, gnorm=0.317, loss_scale=32, train_wall=263, gb_free=21.5, wall=106239
2022-03-08 02:14:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:15:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:15:13 | INFO | valid | epoch 734 | valid on 'valid' subset | loss 11.026 | ppl 2085.07 | wps 38826.6 | wpb 510.9 | bsz 1 | num_updates 35738 | best_loss 8.723
2022-03-08 02:15:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 734 @ 35738 updates
2022-03-08 02:15:13 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)
2022-03-08 02:15:13 | INFO | train | epoch 734 | loss 1.537 | ppl 2.9 | wps 21555 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35738 | lr 0.000167276 | gnorm 0.315 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 106354
2022-03-08 02:15:13 | INFO | fairseq.trainer | begin training epoch 735
2022-03-08 02:15:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:17:37 | INFO | valid | epoch 735 | valid on 'valid' subset | loss 11.072 | ppl 2152.44 | wps 38856.4 | wpb 510.9 | bsz 1 | num_updates 35787 | best_loss 8.723
2022-03-08 02:17:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 735 @ 35787 updates
2022-03-08 02:17:37 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)
2022-03-08 02:17:37 | INFO | train | epoch 735 | loss 1.538 | ppl 2.9 | wps 22000.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35787 | lr 0.000167162 | gnorm 0.325 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 106499
2022-03-08 02:17:37 | INFO | fairseq.trainer | begin training epoch 736
2022-03-08 02:17:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:18:14 | INFO | train_inner | epoch 736:     13 / 49 loss=1.537, ppl=2.9, wps=21809.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=35800, lr=0.000167132, gnorm=0.321, loss_scale=32, train_wall=263, gb_free=21.5, wall=106536
2022-03-08 02:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:20:02 | INFO | valid | epoch 736 | valid on 'valid' subset | loss 11.062 | ppl 2137.63 | wps 38987.9 | wpb 510.9 | bsz 1 | num_updates 35836 | best_loss 8.723
2022-03-08 02:20:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 736 @ 35836 updates
2022-03-08 02:20:02 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)
2022-03-08 02:20:02 | INFO | train | epoch 736 | loss 1.538 | ppl 2.9 | wps 21995.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35836 | lr 0.000167048 | gnorm 0.319 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 106643
2022-03-08 02:20:02 | INFO | fairseq.trainer | begin training epoch 737
2022-03-08 02:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:21:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:22:26 | INFO | valid | epoch 737 | valid on 'valid' subset | loss 11.085 | ppl 2172.15 | wps 38780 | wpb 510.9 | bsz 1 | num_updates 35884 | best_loss 8.723
2022-03-08 02:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 737 @ 35884 updates
2022-03-08 02:22:26 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)
2022-03-08 02:22:26 | INFO | train | epoch 737 | loss 1.537 | ppl 2.9 | wps 21546.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35884 | lr 0.000166936 | gnorm 0.32 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 106788
2022-03-08 02:22:26 | INFO | fairseq.trainer | begin training epoch 738
2022-03-08 02:22:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:23:12 | INFO | train_inner | epoch 738:     16 / 49 loss=1.537, ppl=2.9, wps=21810, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=35900, lr=0.000166899, gnorm=0.318, loss_scale=32, train_wall=263, gb_free=21.5, wall=106834
2022-03-08 02:24:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:24:51 | INFO | valid | epoch 738 | valid on 'valid' subset | loss 11.07 | ppl 2150.34 | wps 38794 | wpb 510.9 | bsz 1 | num_updates 35933 | best_loss 8.723
2022-03-08 02:24:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 738 @ 35933 updates
2022-03-08 02:24:51 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)
2022-03-08 02:24:51 | INFO | train | epoch 738 | loss 1.537 | ppl 2.9 | wps 22000 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35933 | lr 0.000166822 | gnorm 0.316 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 106932
2022-03-08 02:24:51 | INFO | fairseq.trainer | begin training epoch 739
2022-03-08 02:24:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:27:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:27:15 | INFO | valid | epoch 739 | valid on 'valid' subset | loss 11.065 | ppl 2142 | wps 38912 | wpb 510.9 | bsz 1 | num_updates 35982 | best_loss 8.723
2022-03-08 02:27:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 739 @ 35982 updates
2022-03-08 02:27:15 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)
2022-03-08 02:27:15 | INFO | train | epoch 739 | loss 1.537 | ppl 2.9 | wps 21998.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35982 | lr 0.000166708 | gnorm 0.318 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 107077
2022-03-08 02:27:15 | INFO | fairseq.trainer | begin training epoch 740
2022-03-08 02:27:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:28:07 | INFO | train_inner | epoch 740:     18 / 49 loss=1.537, ppl=2.9, wps=22016.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=36000, lr=0.000166667, gnorm=0.319, loss_scale=64, train_wall=261, gb_free=21.5, wall=107128
2022-03-08 02:28:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:29:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:29:39 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 11.041 | ppl 2107.22 | wps 38887.1 | wpb 510.9 | bsz 1 | num_updates 36030 | best_loss 8.723
2022-03-08 02:29:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 36030 updates
2022-03-08 02:29:39 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)
2022-03-08 02:29:39 | INFO | train | epoch 740 | loss 1.537 | ppl 2.9 | wps 21556.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36030 | lr 0.000166597 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 107221
2022-03-08 02:29:39 | INFO | fairseq.trainer | begin training epoch 741
2022-03-08 02:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:30:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:31:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:32:04 | INFO | valid | epoch 741 | valid on 'valid' subset | loss 11.069 | ppl 2148.62 | wps 38819.8 | wpb 510.9 | bsz 1 | num_updates 36078 | best_loss 8.723
2022-03-08 02:32:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 741 @ 36078 updates
2022-03-08 02:32:04 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)
2022-03-08 02:32:04 | INFO | train | epoch 741 | loss 1.536 | ppl 2.9 | wps 21556 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36078 | lr 0.000166486 | gnorm 0.316 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 107366
2022-03-08 02:32:04 | INFO | fairseq.trainer | begin training epoch 742
2022-03-08 02:32:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:33:07 | INFO | train_inner | epoch 742:     22 / 49 loss=1.536, ppl=2.9, wps=21603.9, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=36100, lr=0.000166436, gnorm=0.317, loss_scale=16, train_wall=266, gb_free=21.5, wall=107429
2022-03-08 02:34:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:34:28 | INFO | valid | epoch 742 | valid on 'valid' subset | loss 11.096 | ppl 2189.03 | wps 38916.9 | wpb 510.9 | bsz 1 | num_updates 36127 | best_loss 8.723
2022-03-08 02:34:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 742 @ 36127 updates
2022-03-08 02:34:28 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)
2022-03-08 02:34:28 | INFO | train | epoch 742 | loss 1.536 | ppl 2.9 | wps 21990 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36127 | lr 0.000166373 | gnorm 0.317 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 107510
2022-03-08 02:34:28 | INFO | fairseq.trainer | begin training epoch 743
2022-03-08 02:34:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:36:53 | INFO | valid | epoch 743 | valid on 'valid' subset | loss 11.046 | ppl 2114.02 | wps 38828 | wpb 510.9 | bsz 1 | num_updates 36176 | best_loss 8.723
2022-03-08 02:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 743 @ 36176 updates
2022-03-08 02:36:53 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)
2022-03-08 02:36:53 | INFO | train | epoch 743 | loss 1.537 | ppl 2.9 | wps 21980 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36176 | lr 0.000166261 | gnorm 0.322 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 107655
2022-03-08 02:36:53 | INFO | fairseq.trainer | begin training epoch 744
2022-03-08 02:36:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:38:02 | INFO | train_inner | epoch 744:     24 / 49 loss=1.536, ppl=2.9, wps=22002.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=36200, lr=0.000166206, gnorm=0.32, loss_scale=32, train_wall=261, gb_free=21.5, wall=107723
2022-03-08 02:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:39:17 | INFO | valid | epoch 744 | valid on 'valid' subset | loss 11.107 | ppl 2206.32 | wps 38961.4 | wpb 510.9 | bsz 1 | num_updates 36225 | best_loss 8.723
2022-03-08 02:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 744 @ 36225 updates
2022-03-08 02:39:17 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)
2022-03-08 02:39:17 | INFO | train | epoch 744 | loss 1.537 | ppl 2.9 | wps 22001.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36225 | lr 0.000166148 | gnorm 0.32 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 107799
2022-03-08 02:39:17 | INFO | fairseq.trainer | begin training epoch 745
2022-03-08 02:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:41:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:41:42 | INFO | valid | epoch 745 | valid on 'valid' subset | loss 11.057 | ppl 2130.57 | wps 38850.9 | wpb 510.9 | bsz 1 | num_updates 36274 | best_loss 8.723
2022-03-08 02:41:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 745 @ 36274 updates
2022-03-08 02:41:42 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)
2022-03-08 02:41:42 | INFO | train | epoch 745 | loss 1.537 | ppl 2.9 | wps 21995.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36274 | lr 0.000166036 | gnorm 0.321 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 107944
2022-03-08 02:41:42 | INFO | fairseq.trainer | begin training epoch 746
2022-03-08 02:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:42:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:42:59 | INFO | train_inner | epoch 746:     27 / 49 loss=1.537, ppl=2.9, wps=21810.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=36300, lr=0.000165977, gnorm=0.319, loss_scale=16, train_wall=263, gb_free=21.5, wall=108021
2022-03-08 02:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:44:06 | INFO | valid | epoch 746 | valid on 'valid' subset | loss 11.075 | ppl 2156.58 | wps 38943.6 | wpb 510.9 | bsz 1 | num_updates 36322 | best_loss 8.723
2022-03-08 02:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 746 @ 36322 updates
2022-03-08 02:44:06 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)
2022-03-08 02:44:06 | INFO | train | epoch 746 | loss 1.536 | ppl 2.9 | wps 21544.6 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 36322 | lr 0.000165926 | gnorm 0.319 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 108088
2022-03-08 02:44:06 | INFO | fairseq.trainer | begin training epoch 747
2022-03-08 02:44:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:46:31 | INFO | valid | epoch 747 | valid on 'valid' subset | loss 11.063 | ppl 2139.64 | wps 38772.2 | wpb 510.9 | bsz 1 | num_updates 36371 | best_loss 8.723
2022-03-08 02:46:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 747 @ 36371 updates
2022-03-08 02:46:31 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)
2022-03-08 02:46:31 | INFO | train | epoch 747 | loss 1.536 | ppl 2.9 | wps 21985.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36371 | lr 0.000165814 | gnorm 0.32 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 108233
2022-03-08 02:46:31 | INFO | fairseq.trainer | begin training epoch 748
2022-03-08 02:46:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:47:54 | INFO | train_inner | epoch 748:     29 / 49 loss=1.536, ppl=2.9, wps=22006.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36400, lr=0.000165748, gnorm=0.318, loss_scale=16, train_wall=261, gb_free=21.5, wall=108316
2022-03-08 02:48:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:48:55 | INFO | valid | epoch 748 | valid on 'valid' subset | loss 11.086 | ppl 2173.91 | wps 38965.2 | wpb 510.9 | bsz 1 | num_updates 36420 | best_loss 8.723
2022-03-08 02:48:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 748 @ 36420 updates
2022-03-08 02:48:55 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)
2022-03-08 02:48:55 | INFO | train | epoch 748 | loss 1.535 | ppl 2.9 | wps 22003.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36420 | lr 0.000165703 | gnorm 0.317 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 108377
2022-03-08 02:48:55 | INFO | fairseq.trainer | begin training epoch 749
2022-03-08 02:48:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:51:20 | INFO | valid | epoch 749 | valid on 'valid' subset | loss 11.089 | ppl 2178.68 | wps 38853.2 | wpb 510.9 | bsz 1 | num_updates 36469 | best_loss 8.723
2022-03-08 02:51:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 749 @ 36469 updates
2022-03-08 02:51:20 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)
2022-03-08 02:51:20 | INFO | train | epoch 749 | loss 1.535 | ppl 2.9 | wps 22011.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36469 | lr 0.000165592 | gnorm 0.318 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 108521
2022-03-08 02:51:20 | INFO | fairseq.trainer | begin training epoch 750
2022-03-08 02:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:52:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:52:51 | INFO | train_inner | epoch 750:     32 / 49 loss=1.535, ppl=2.9, wps=21805, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36500, lr=0.000165521, gnorm=0.318, loss_scale=16, train_wall=263, gb_free=21.5, wall=108613
2022-03-08 02:53:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:53:44 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 11.073 | ppl 2153.99 | wps 39113.6 | wpb 510.9 | bsz 1 | num_updates 36517 | best_loss 8.723
2022-03-08 02:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 36517 updates
2022-03-08 02:53:44 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)
2022-03-08 02:53:44 | INFO | train | epoch 750 | loss 1.535 | ppl 2.9 | wps 21535.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36517 | lr 0.000165483 | gnorm 0.319 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 108666
2022-03-08 02:53:44 | INFO | fairseq.trainer | begin training epoch 751
2022-03-08 02:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:56:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:56:09 | INFO | valid | epoch 751 | valid on 'valid' subset | loss 11.108 | ppl 2207.79 | wps 39034.3 | wpb 510.9 | bsz 1 | num_updates 36566 | best_loss 8.723
2022-03-08 02:56:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 751 @ 36566 updates
2022-03-08 02:56:09 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)
2022-03-08 02:56:09 | INFO | train | epoch 751 | loss 1.535 | ppl 2.9 | wps 22012.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36566 | lr 0.000165372 | gnorm 0.317 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 108810
2022-03-08 02:56:09 | INFO | fairseq.trainer | begin training epoch 752
2022-03-08 02:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:57:46 | INFO | train_inner | epoch 752:     34 / 49 loss=1.535, ppl=2.9, wps=22030.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=36600, lr=0.000165295, gnorm=0.318, loss_scale=16, train_wall=260, gb_free=21.5, wall=108908
2022-03-08 02:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:58:33 | INFO | valid | epoch 752 | valid on 'valid' subset | loss 11.049 | ppl 2118.18 | wps 38827.1 | wpb 510.9 | bsz 1 | num_updates 36615 | best_loss 8.723
2022-03-08 02:58:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 752 @ 36615 updates
2022-03-08 02:58:33 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)
2022-03-08 02:58:33 | INFO | train | epoch 752 | loss 1.535 | ppl 2.9 | wps 22011.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36615 | lr 0.000165261 | gnorm 0.319 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 108955
2022-03-08 02:58:33 | INFO | fairseq.trainer | begin training epoch 753
2022-03-08 02:58:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:00:58 | INFO | valid | epoch 753 | valid on 'valid' subset | loss 11.078 | ppl 2161.62 | wps 38869.5 | wpb 510.9 | bsz 1 | num_updates 36664 | best_loss 8.723
2022-03-08 03:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 753 @ 36664 updates
2022-03-08 03:00:58 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)
2022-03-08 03:00:58 | INFO | train | epoch 753 | loss 1.535 | ppl 2.9 | wps 21979.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36664 | lr 0.000165151 | gnorm 0.316 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 109099
2022-03-08 03:00:58 | INFO | fairseq.trainer | begin training epoch 754
2022-03-08 03:00:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:02:41 | INFO | train_inner | epoch 754:     36 / 49 loss=1.535, ppl=2.9, wps=22009.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=36700, lr=0.00016507, gnorm=0.316, loss_scale=32, train_wall=261, gb_free=21.5, wall=109202
2022-03-08 03:03:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:03:22 | INFO | valid | epoch 754 | valid on 'valid' subset | loss 11.083 | ppl 2169.13 | wps 38788.3 | wpb 510.9 | bsz 1 | num_updates 36712 | best_loss 8.723
2022-03-08 03:03:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 754 @ 36712 updates
2022-03-08 03:03:22 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)
2022-03-08 03:03:22 | INFO | train | epoch 754 | loss 1.534 | ppl 2.9 | wps 21549.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36712 | lr 0.000165043 | gnorm 0.317 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 109244
2022-03-08 03:03:22 | INFO | fairseq.trainer | begin training epoch 755
2022-03-08 03:03:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:05:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:05:46 | INFO | valid | epoch 755 | valid on 'valid' subset | loss 11.105 | ppl 2201.88 | wps 38730.4 | wpb 510.9 | bsz 1 | num_updates 36761 | best_loss 8.723
2022-03-08 03:05:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 755 @ 36761 updates
2022-03-08 03:05:46 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)
2022-03-08 03:05:46 | INFO | train | epoch 755 | loss 1.534 | ppl 2.9 | wps 21998.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36761 | lr 0.000164933 | gnorm 0.316 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 109388
2022-03-08 03:05:47 | INFO | fairseq.trainer | begin training epoch 756
2022-03-08 03:05:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:07:38 | INFO | train_inner | epoch 756:     39 / 49 loss=1.534, ppl=2.9, wps=21803.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36800, lr=0.000164845, gnorm=0.316, loss_scale=16, train_wall=263, gb_free=21.5, wall=109500
2022-03-08 03:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:08:11 | INFO | valid | epoch 756 | valid on 'valid' subset | loss 11.065 | ppl 2142.47 | wps 38935.2 | wpb 510.9 | bsz 1 | num_updates 36810 | best_loss 8.723
2022-03-08 03:08:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 756 @ 36810 updates
2022-03-08 03:08:11 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)
2022-03-08 03:08:11 | INFO | train | epoch 756 | loss 1.534 | ppl 2.9 | wps 21996.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36810 | lr 0.000164823 | gnorm 0.317 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 109533
2022-03-08 03:08:11 | INFO | fairseq.trainer | begin training epoch 757
2022-03-08 03:08:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:10:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:10:35 | INFO | valid | epoch 757 | valid on 'valid' subset | loss 11.065 | ppl 2142.61 | wps 38870.5 | wpb 510.9 | bsz 1 | num_updates 36859 | best_loss 8.723
2022-03-08 03:10:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 757 @ 36859 updates
2022-03-08 03:10:35 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)
2022-03-08 03:10:35 | INFO | train | epoch 757 | loss 1.534 | ppl 2.9 | wps 21991.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36859 | lr 0.000164713 | gnorm 0.32 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 109677
2022-03-08 03:10:35 | INFO | fairseq.trainer | begin training epoch 758
2022-03-08 03:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:12:33 | INFO | train_inner | epoch 758:     41 / 49 loss=1.534, ppl=2.9, wps=22015.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=36900, lr=0.000164622, gnorm=0.319, loss_scale=32, train_wall=261, gb_free=21.5, wall=109795
2022-03-08 03:12:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:13:00 | INFO | valid | epoch 758 | valid on 'valid' subset | loss 11.089 | ppl 2177.97 | wps 38833.4 | wpb 510.9 | bsz 1 | num_updates 36908 | best_loss 8.723
2022-03-08 03:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 758 @ 36908 updates
2022-03-08 03:13:00 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)
2022-03-08 03:13:00 | INFO | train | epoch 758 | loss 1.534 | ppl 2.9 | wps 21997.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36908 | lr 0.000164604 | gnorm 0.32 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 109822
2022-03-08 03:13:00 | INFO | fairseq.trainer | begin training epoch 759
2022-03-08 03:13:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:15:24 | INFO | valid | epoch 759 | valid on 'valid' subset | loss 11.065 | ppl 2142.44 | wps 38692.6 | wpb 510.9 | bsz 1 | num_updates 36957 | best_loss 8.723
2022-03-08 03:15:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 759 @ 36957 updates
2022-03-08 03:15:24 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)
2022-03-08 03:15:24 | INFO | train | epoch 759 | loss 1.534 | ppl 2.9 | wps 22014.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36957 | lr 0.000164495 | gnorm 0.317 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 109966
2022-03-08 03:15:24 | INFO | fairseq.trainer | begin training epoch 760
2022-03-08 03:15:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:15:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:16:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:17:33 | INFO | train_inner | epoch 760:     45 / 49 loss=1.534, ppl=2.9, wps=21601.3, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=37000, lr=0.000164399, gnorm=0.318, loss_scale=16, train_wall=266, gb_free=21.5, wall=110095
2022-03-08 03:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:17:49 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 11.08 | ppl 2165.5 | wps 38798.7 | wpb 510.9 | bsz 1 | num_updates 37004 | best_loss 8.723
2022-03-08 03:17:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 37004 updates
2022-03-08 03:17:49 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)
2022-03-08 03:17:49 | INFO | train | epoch 760 | loss 1.534 | ppl 2.9 | wps 21089.3 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 37004 | lr 0.00016439 | gnorm 0.317 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 110111
2022-03-08 03:17:49 | INFO | fairseq.trainer | begin training epoch 761
2022-03-08 03:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:20:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:20:13 | INFO | valid | epoch 761 | valid on 'valid' subset | loss 11.108 | ppl 2207.62 | wps 38340.1 | wpb 510.9 | bsz 1 | num_updates 37053 | best_loss 8.723
2022-03-08 03:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 761 @ 37053 updates
2022-03-08 03:20:13 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)
2022-03-08 03:20:13 | INFO | train | epoch 761 | loss 1.533 | ppl 2.89 | wps 22004.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37053 | lr 0.000164281 | gnorm 0.318 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 110255
2022-03-08 03:20:13 | INFO | fairseq.trainer | begin training epoch 762
2022-03-08 03:20:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:22:28 | INFO | train_inner | epoch 762:     47 / 49 loss=1.533, ppl=2.89, wps=22031.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37100, lr=0.000164177, gnorm=0.316, loss_scale=32, train_wall=260, gb_free=21.5, wall=110389
2022-03-08 03:22:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:22:38 | INFO | valid | epoch 762 | valid on 'valid' subset | loss 11.034 | ppl 2096.56 | wps 38743.7 | wpb 510.9 | bsz 1 | num_updates 37102 | best_loss 8.723
2022-03-08 03:22:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 762 @ 37102 updates
2022-03-08 03:22:38 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)
2022-03-08 03:22:38 | INFO | train | epoch 762 | loss 1.533 | ppl 2.89 | wps 22020.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37102 | lr 0.000164173 | gnorm 0.314 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 110399
2022-03-08 03:22:38 | INFO | fairseq.trainer | begin training epoch 763
2022-03-08 03:22:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:24:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:25:02 | INFO | valid | epoch 763 | valid on 'valid' subset | loss 11.078 | ppl 2161.18 | wps 38730.9 | wpb 510.9 | bsz 1 | num_updates 37151 | best_loss 8.723
2022-03-08 03:25:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 763 @ 37151 updates
2022-03-08 03:25:02 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)
2022-03-08 03:25:02 | INFO | train | epoch 763 | loss 1.533 | ppl 2.89 | wps 21997 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37151 | lr 0.000164065 | gnorm 0.316 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 110544
2022-03-08 03:25:02 | INFO | fairseq.trainer | begin training epoch 764
2022-03-08 03:25:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:27:21 | INFO | train_inner | epoch 764:     49 / 49 loss=1.533, ppl=2.89, wps=22013.6, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=37200, lr=0.000163956, gnorm=0.319, loss_scale=32, train_wall=259, gb_free=21.5, wall=110683
2022-03-08 03:27:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:27:26 | INFO | valid | epoch 764 | valid on 'valid' subset | loss 11.061 | ppl 2136.83 | wps 38867 | wpb 510.9 | bsz 1 | num_updates 37200 | best_loss 8.723
2022-03-08 03:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 764 @ 37200 updates
2022-03-08 03:27:26 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)
2022-03-08 03:27:26 | INFO | train | epoch 764 | loss 1.533 | ppl 2.89 | wps 22009.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37200 | lr 0.000163956 | gnorm 0.32 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 110688
2022-03-08 03:27:26 | INFO | fairseq.trainer | begin training epoch 765
2022-03-08 03:27:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:29:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:29:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:29:51 | INFO | valid | epoch 765 | valid on 'valid' subset | loss 11.087 | ppl 2175.16 | wps 38658.2 | wpb 510.9 | bsz 1 | num_updates 37248 | best_loss 8.723
2022-03-08 03:29:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 765 @ 37248 updates
2022-03-08 03:29:51 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)
2022-03-08 03:29:51 | INFO | train | epoch 765 | loss 1.533 | ppl 2.89 | wps 21551.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37248 | lr 0.000163851 | gnorm 0.317 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 110833
2022-03-08 03:29:51 | INFO | fairseq.trainer | begin training epoch 766
2022-03-08 03:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:32:15 | INFO | valid | epoch 766 | valid on 'valid' subset | loss 11.087 | ppl 2174.92 | wps 38877.5 | wpb 510.9 | bsz 1 | num_updates 37297 | best_loss 8.723
2022-03-08 03:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 766 @ 37297 updates
2022-03-08 03:32:15 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)
2022-03-08 03:32:15 | INFO | train | epoch 766 | loss 1.532 | ppl 2.89 | wps 22002.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37297 | lr 0.000163743 | gnorm 0.319 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 110977
2022-03-08 03:32:15 | INFO | fairseq.trainer | begin training epoch 767
2022-03-08 03:32:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:32:24 | INFO | train_inner | epoch 767:      3 / 49 loss=1.533, ppl=2.89, wps=21396.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=37300, lr=0.000163737, gnorm=0.318, loss_scale=32, train_wall=263, gb_free=21.5, wall=110986
2022-03-08 03:34:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:34:40 | INFO | valid | epoch 767 | valid on 'valid' subset | loss 11.067 | ppl 2145.8 | wps 38813.4 | wpb 510.9 | bsz 1 | num_updates 37346 | best_loss 8.723
2022-03-08 03:34:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 767 @ 37346 updates
2022-03-08 03:34:40 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)
2022-03-08 03:34:40 | INFO | train | epoch 767 | loss 1.532 | ppl 2.89 | wps 21999.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37346 | lr 0.000163636 | gnorm 0.316 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 111122
2022-03-08 03:34:40 | INFO | fairseq.trainer | begin training epoch 768
2022-03-08 03:34:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:35:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:36:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:37:04 | INFO | valid | epoch 768 | valid on 'valid' subset | loss 11.069 | ppl 2148.63 | wps 38819.4 | wpb 510.9 | bsz 1 | num_updates 37394 | best_loss 8.723
2022-03-08 03:37:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 768 @ 37394 updates
2022-03-08 03:37:04 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)
2022-03-08 03:37:04 | INFO | train | epoch 768 | loss 1.531 | ppl 2.89 | wps 21536 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37394 | lr 0.000163531 | gnorm 0.312 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 111266
2022-03-08 03:37:04 | INFO | fairseq.trainer | begin training epoch 769
2022-03-08 03:37:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:37:21 | INFO | train_inner | epoch 769:      6 / 49 loss=1.532, ppl=2.89, wps=21803, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37400, lr=0.000163517, gnorm=0.314, loss_scale=32, train_wall=263, gb_free=21.5, wall=111283
2022-03-08 03:39:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:39:29 | INFO | valid | epoch 769 | valid on 'valid' subset | loss 11.069 | ppl 2147.6 | wps 38735 | wpb 510.9 | bsz 1 | num_updates 37443 | best_loss 8.723
2022-03-08 03:39:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 769 @ 37443 updates
2022-03-08 03:39:29 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)
2022-03-08 03:39:29 | INFO | train | epoch 769 | loss 1.533 | ppl 2.89 | wps 22005.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37443 | lr 0.000163424 | gnorm 0.317 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 111410
2022-03-08 03:39:29 | INFO | fairseq.trainer | begin training epoch 770
2022-03-08 03:39:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:41:53 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 11.095 | ppl 2187.17 | wps 38881 | wpb 510.9 | bsz 1 | num_updates 37492 | best_loss 8.723
2022-03-08 03:41:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 37492 updates
2022-03-08 03:41:53 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)
2022-03-08 03:41:53 | INFO | train | epoch 770 | loss 1.532 | ppl 2.89 | wps 22026.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37492 | lr 0.000163317 | gnorm 0.317 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 111555
2022-03-08 03:41:53 | INFO | fairseq.trainer | begin training epoch 771
2022-03-08 03:41:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:42:16 | INFO | train_inner | epoch 771:      8 / 49 loss=1.533, ppl=2.89, wps=22026.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=37500, lr=0.000163299, gnorm=0.317, loss_scale=64, train_wall=260, gb_free=21.5, wall=111578
2022-03-08 03:42:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:44:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:44:17 | INFO | valid | epoch 771 | valid on 'valid' subset | loss 11.057 | ppl 2130.81 | wps 38836.5 | wpb 510.9 | bsz 1 | num_updates 37540 | best_loss 8.723
2022-03-08 03:44:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 771 @ 37540 updates
2022-03-08 03:44:17 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)
2022-03-08 03:44:17 | INFO | train | epoch 771 | loss 1.533 | ppl 2.89 | wps 21548.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37540 | lr 0.000163212 | gnorm 0.316 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 111699
2022-03-08 03:44:17 | INFO | fairseq.trainer | begin training epoch 772
2022-03-08 03:44:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:46:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:46:42 | INFO | valid | epoch 772 | valid on 'valid' subset | loss 11.051 | ppl 2120.98 | wps 38955.9 | wpb 510.9 | bsz 1 | num_updates 37589 | best_loss 8.723
2022-03-08 03:46:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 772 @ 37589 updates
2022-03-08 03:46:42 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)
2022-03-08 03:46:42 | INFO | train | epoch 772 | loss 1.532 | ppl 2.89 | wps 22024.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37589 | lr 0.000163106 | gnorm 0.316 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 111843
2022-03-08 03:46:42 | INFO | fairseq.trainer | begin training epoch 773
2022-03-08 03:46:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:47:13 | INFO | train_inner | epoch 773:     11 / 49 loss=1.532, ppl=2.89, wps=21822.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=37600, lr=0.000163082, gnorm=0.316, loss_scale=32, train_wall=263, gb_free=21.5, wall=111875
2022-03-08 03:49:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:49:06 | INFO | valid | epoch 773 | valid on 'valid' subset | loss 11.075 | ppl 2156.9 | wps 38780.4 | wpb 510.9 | bsz 1 | num_updates 37638 | best_loss 8.723
2022-03-08 03:49:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 773 @ 37638 updates
2022-03-08 03:49:06 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)
2022-03-08 03:49:06 | INFO | train | epoch 773 | loss 1.531 | ppl 2.89 | wps 22010 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37638 | lr 0.000163 | gnorm 0.314 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 111988
2022-03-08 03:49:06 | INFO | fairseq.trainer | begin training epoch 774
2022-03-08 03:49:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:49:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:51:31 | INFO | valid | epoch 774 | valid on 'valid' subset | loss 11.084 | ppl 2171.06 | wps 38751.9 | wpb 510.9 | bsz 1 | num_updates 37686 | best_loss 8.723
2022-03-08 03:51:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 774 @ 37686 updates
2022-03-08 03:51:31 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)
2022-03-08 03:51:31 | INFO | train | epoch 774 | loss 1.531 | ppl 2.89 | wps 21544.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37686 | lr 0.000162896 | gnorm 0.314 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 112132
2022-03-08 03:51:31 | INFO | fairseq.trainer | begin training epoch 775
2022-03-08 03:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:52:11 | INFO | train_inner | epoch 775:     14 / 49 loss=1.531, ppl=2.89, wps=21812.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37700, lr=0.000162866, gnorm=0.314, loss_scale=32, train_wall=263, gb_free=21.5, wall=112172
2022-03-08 03:53:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:53:55 | INFO | valid | epoch 775 | valid on 'valid' subset | loss 11.086 | ppl 2173.42 | wps 38606.5 | wpb 510.9 | bsz 1 | num_updates 37735 | best_loss 8.723
2022-03-08 03:53:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 775 @ 37735 updates
2022-03-08 03:53:55 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)
2022-03-08 03:53:55 | INFO | train | epoch 775 | loss 1.531 | ppl 2.89 | wps 22009.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37735 | lr 0.00016279 | gnorm 0.318 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 112277
2022-03-08 03:53:55 | INFO | fairseq.trainer | begin training epoch 776
2022-03-08 03:53:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:55:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:56:19 | INFO | valid | epoch 776 | valid on 'valid' subset | loss 11.077 | ppl 2160.65 | wps 38788.5 | wpb 510.9 | bsz 1 | num_updates 37783 | best_loss 8.723
2022-03-08 03:56:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 776 @ 37783 updates
2022-03-08 03:56:19 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)
2022-03-08 03:56:19 | INFO | train | epoch 776 | loss 1.53 | ppl 2.89 | wps 21574.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37783 | lr 0.000162687 | gnorm 0.313 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112421
2022-03-08 03:56:19 | INFO | fairseq.trainer | begin training epoch 777
2022-03-08 03:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:57:08 | INFO | train_inner | epoch 777:     17 / 49 loss=1.531, ppl=2.89, wps=21825.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37800, lr=0.00016265, gnorm=0.315, loss_scale=32, train_wall=263, gb_free=21.5, wall=112470
2022-03-08 03:58:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:58:44 | INFO | valid | epoch 777 | valid on 'valid' subset | loss 11.067 | ppl 2145.45 | wps 38701.9 | wpb 510.9 | bsz 1 | num_updates 37832 | best_loss 8.723
2022-03-08 03:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 777 @ 37832 updates
2022-03-08 03:58:44 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)
2022-03-08 03:58:44 | INFO | train | epoch 777 | loss 1.531 | ppl 2.89 | wps 22005.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37832 | lr 0.000162581 | gnorm 0.315 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 112565
2022-03-08 03:58:44 | INFO | fairseq.trainer | begin training epoch 778
2022-03-08 03:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:01:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:01:08 | INFO | valid | epoch 778 | valid on 'valid' subset | loss 11.078 | ppl 2161.13 | wps 38783 | wpb 510.9 | bsz 1 | num_updates 37881 | best_loss 8.723
2022-03-08 04:01:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 778 @ 37881 updates
2022-03-08 04:01:08 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)
2022-03-08 04:01:08 | INFO | train | epoch 778 | loss 1.531 | ppl 2.89 | wps 21996.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37881 | lr 0.000162476 | gnorm 0.314 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 112710
2022-03-08 04:01:08 | INFO | fairseq.trainer | begin training epoch 779
2022-03-08 04:01:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:02:03 | INFO | train_inner | epoch 779:     19 / 49 loss=1.531, ppl=2.89, wps=22013.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=37900, lr=0.000162435, gnorm=0.314, loss_scale=64, train_wall=261, gb_free=21.5, wall=112764
2022-03-08 04:03:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:03:33 | INFO | valid | epoch 779 | valid on 'valid' subset | loss 11.071 | ppl 2150.74 | wps 38943 | wpb 510.9 | bsz 1 | num_updates 37930 | best_loss 8.723
2022-03-08 04:03:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 779 @ 37930 updates
2022-03-08 04:03:33 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)
2022-03-08 04:03:33 | INFO | train | epoch 779 | loss 1.53 | ppl 2.89 | wps 22002.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37930 | lr 0.000162371 | gnorm 0.31 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 112854
2022-03-08 04:03:33 | INFO | fairseq.trainer | begin training epoch 780
2022-03-08 04:03:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:03:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:05:57 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 11.095 | ppl 2187.39 | wps 39025.2 | wpb 510.9 | bsz 1 | num_updates 37978 | best_loss 8.723
2022-03-08 04:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 37978 updates
2022-03-08 04:05:57 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)
2022-03-08 04:05:57 | INFO | train | epoch 780 | loss 1.53 | ppl 2.89 | wps 21565.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37978 | lr 0.000162268 | gnorm 0.314 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 112999
2022-03-08 04:05:57 | INFO | fairseq.trainer | begin training epoch 781
2022-03-08 04:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:07:00 | INFO | train_inner | epoch 781:     22 / 49 loss=1.53, ppl=2.89, wps=21819.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38000, lr=0.000162221, gnorm=0.313, loss_scale=32, train_wall=263, gb_free=21.5, wall=113062
2022-03-08 04:08:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:08:21 | INFO | valid | epoch 781 | valid on 'valid' subset | loss 11.103 | ppl 2198.85 | wps 38962.4 | wpb 510.9 | bsz 1 | num_updates 38027 | best_loss 8.723
2022-03-08 04:08:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 781 @ 38027 updates
2022-03-08 04:08:21 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)
2022-03-08 04:08:21 | INFO | train | epoch 781 | loss 1.53 | ppl 2.89 | wps 22012.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38027 | lr 0.000162164 | gnorm 0.316 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 113143
2022-03-08 04:08:21 | INFO | fairseq.trainer | begin training epoch 782
2022-03-08 04:08:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:10:46 | INFO | valid | epoch 782 | valid on 'valid' subset | loss 11.048 | ppl 2117.54 | wps 39015.5 | wpb 510.9 | bsz 1 | num_updates 38076 | best_loss 8.723
2022-03-08 04:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 782 @ 38076 updates
2022-03-08 04:10:46 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)
2022-03-08 04:10:46 | INFO | train | epoch 782 | loss 1.53 | ppl 2.89 | wps 22000.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38076 | lr 0.000162059 | gnorm 0.312 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 113288
2022-03-08 04:10:46 | INFO | fairseq.trainer | begin training epoch 783
2022-03-08 04:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:11:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:11:57 | INFO | train_inner | epoch 783:     25 / 49 loss=1.53, ppl=2.89, wps=21819.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=38100, lr=0.000162008, gnorm=0.314, loss_scale=32, train_wall=263, gb_free=21.5, wall=113359
2022-03-08 04:13:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:13:10 | INFO | valid | epoch 783 | valid on 'valid' subset | loss 11.088 | ppl 2177.45 | wps 38991.2 | wpb 510.9 | bsz 1 | num_updates 38124 | best_loss 8.723
2022-03-08 04:13:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 783 @ 38124 updates
2022-03-08 04:13:10 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)
2022-03-08 04:13:10 | INFO | train | epoch 783 | loss 1.53 | ppl 2.89 | wps 21557.4 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 38124 | lr 0.000161957 | gnorm 0.314 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 113432
2022-03-08 04:13:10 | INFO | fairseq.trainer | begin training epoch 784
2022-03-08 04:13:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:15:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:15:35 | INFO | valid | epoch 784 | valid on 'valid' subset | loss 11.098 | ppl 2192.39 | wps 38919.1 | wpb 510.9 | bsz 1 | num_updates 38173 | best_loss 8.723
2022-03-08 04:15:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 784 @ 38173 updates
2022-03-08 04:15:35 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)
2022-03-08 04:15:35 | INFO | train | epoch 784 | loss 1.529 | ppl 2.89 | wps 21990.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38173 | lr 0.000161853 | gnorm 0.315 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 113576
2022-03-08 04:15:35 | INFO | fairseq.trainer | begin training epoch 785
2022-03-08 04:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:16:52 | INFO | train_inner | epoch 785:     27 / 49 loss=1.529, ppl=2.89, wps=22011.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=38200, lr=0.000161796, gnorm=0.313, loss_scale=32, train_wall=261, gb_free=21.5, wall=113654
2022-03-08 04:16:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:17:59 | INFO | valid | epoch 785 | valid on 'valid' subset | loss 11.077 | ppl 2160.24 | wps 38802.3 | wpb 510.9 | bsz 1 | num_updates 38221 | best_loss 8.723
2022-03-08 04:17:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 785 @ 38221 updates
2022-03-08 04:17:59 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)
2022-03-08 04:17:59 | INFO | train | epoch 785 | loss 1.53 | ppl 2.89 | wps 21545 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38221 | lr 0.000161752 | gnorm 0.313 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 113721
2022-03-08 04:17:59 | INFO | fairseq.trainer | begin training epoch 786
2022-03-08 04:17:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:20:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:20:24 | INFO | valid | epoch 786 | valid on 'valid' subset | loss 11.077 | ppl 2160.36 | wps 39018.6 | wpb 510.9 | bsz 1 | num_updates 38270 | best_loss 8.723
2022-03-08 04:20:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 786 @ 38270 updates
2022-03-08 04:20:24 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)
2022-03-08 04:20:24 | INFO | train | epoch 786 | loss 1.529 | ppl 2.89 | wps 22009.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38270 | lr 0.000161648 | gnorm 0.314 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 113865
2022-03-08 04:20:24 | INFO | fairseq.trainer | begin training epoch 787
2022-03-08 04:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:21:49 | INFO | train_inner | epoch 787:     30 / 49 loss=1.529, ppl=2.89, wps=21804.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=38300, lr=0.000161585, gnorm=0.314, loss_scale=16, train_wall=263, gb_free=21.5, wall=113951
2022-03-08 04:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:22:48 | INFO | valid | epoch 787 | valid on 'valid' subset | loss 11.073 | ppl 2153.82 | wps 38912.9 | wpb 510.9 | bsz 1 | num_updates 38319 | best_loss 8.723
2022-03-08 04:22:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 787 @ 38319 updates
2022-03-08 04:22:48 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)
2022-03-08 04:22:48 | INFO | train | epoch 787 | loss 1.529 | ppl 2.89 | wps 21994.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38319 | lr 0.000161545 | gnorm 0.313 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 114010
2022-03-08 04:22:48 | INFO | fairseq.trainer | begin training epoch 788
2022-03-08 04:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:25:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:25:12 | INFO | valid | epoch 788 | valid on 'valid' subset | loss 11.072 | ppl 2153.36 | wps 38927.1 | wpb 510.9 | bsz 1 | num_updates 38368 | best_loss 8.723
2022-03-08 04:25:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 788 @ 38368 updates
2022-03-08 04:25:12 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)
2022-03-08 04:25:12 | INFO | train | epoch 788 | loss 1.53 | ppl 2.89 | wps 22005.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38368 | lr 0.000161442 | gnorm 0.31 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 114154
2022-03-08 04:25:12 | INFO | fairseq.trainer | begin training epoch 789
2022-03-08 04:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:26:44 | INFO | train_inner | epoch 789:     32 / 49 loss=1.529, ppl=2.89, wps=22023.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38400, lr=0.000161374, gnorm=0.314, loss_scale=32, train_wall=261, gb_free=21.5, wall=114246
2022-03-08 04:27:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:27:37 | INFO | valid | epoch 789 | valid on 'valid' subset | loss 11.066 | ppl 2143.36 | wps 38861 | wpb 510.9 | bsz 1 | num_updates 38417 | best_loss 8.723
2022-03-08 04:27:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 789 @ 38417 updates
2022-03-08 04:27:37 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)
2022-03-08 04:27:37 | INFO | train | epoch 789 | loss 1.529 | ppl 2.89 | wps 22003.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38417 | lr 0.000161339 | gnorm 0.318 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 114299
2022-03-08 04:27:37 | INFO | fairseq.trainer | begin training epoch 790
2022-03-08 04:27:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:29:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:30:01 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 11.082 | ppl 2167.64 | wps 38883.8 | wpb 510.9 | bsz 1 | num_updates 38465 | best_loss 8.723
2022-03-08 04:30:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 38465 updates
2022-03-08 04:30:01 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)
2022-03-08 04:30:01 | INFO | train | epoch 790 | loss 1.529 | ppl 2.89 | wps 21556.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38465 | lr 0.000161238 | gnorm 0.31 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 114443
2022-03-08 04:30:01 | INFO | fairseq.trainer | begin training epoch 791
2022-03-08 04:30:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:30:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:31:44 | INFO | train_inner | epoch 791:     36 / 49 loss=1.529, ppl=2.89, wps=21597.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=38500, lr=0.000161165, gnorm=0.311, loss_scale=16, train_wall=266, gb_free=21.5, wall=114546
2022-03-08 04:32:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:32:26 | INFO | valid | epoch 791 | valid on 'valid' subset | loss 11.06 | ppl 2134.58 | wps 39075.4 | wpb 510.9 | bsz 1 | num_updates 38513 | best_loss 8.723
2022-03-08 04:32:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 791 @ 38513 updates
2022-03-08 04:32:26 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)
2022-03-08 04:32:26 | INFO | train | epoch 791 | loss 1.529 | ppl 2.89 | wps 21536.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38513 | lr 0.000161137 | gnorm 0.312 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 114588
2022-03-08 04:32:26 | INFO | fairseq.trainer | begin training epoch 792
2022-03-08 04:32:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:34:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:34:50 | INFO | valid | epoch 792 | valid on 'valid' subset | loss 11.086 | ppl 2173.55 | wps 38432.2 | wpb 510.9 | bsz 1 | num_updates 38562 | best_loss 8.723
2022-03-08 04:34:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 792 @ 38562 updates
2022-03-08 04:34:50 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)
2022-03-08 04:34:50 | INFO | train | epoch 792 | loss 1.529 | ppl 2.89 | wps 22002.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38562 | lr 0.000161035 | gnorm 0.311 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 114732
2022-03-08 04:34:50 | INFO | fairseq.trainer | begin training epoch 793
2022-03-08 04:34:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:36:39 | INFO | train_inner | epoch 793:     38 / 49 loss=1.529, ppl=2.89, wps=22019.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=38600, lr=0.000160956, gnorm=0.312, loss_scale=32, train_wall=260, gb_free=21.5, wall=114841
2022-03-08 04:37:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:37:15 | INFO | valid | epoch 793 | valid on 'valid' subset | loss 11.063 | ppl 2138.98 | wps 38778.7 | wpb 510.9 | bsz 1 | num_updates 38611 | best_loss 8.723
2022-03-08 04:37:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 793 @ 38611 updates
2022-03-08 04:37:15 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)
2022-03-08 04:37:15 | INFO | train | epoch 793 | loss 1.529 | ppl 2.89 | wps 21996.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38611 | lr 0.000160933 | gnorm 0.315 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 114876
2022-03-08 04:37:15 | INFO | fairseq.trainer | begin training epoch 794
2022-03-08 04:37:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:38:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:39:39 | INFO | valid | epoch 794 | valid on 'valid' subset | loss 11.012 | ppl 2065.58 | wps 38891 | wpb 510.9 | bsz 1 | num_updates 38659 | best_loss 8.723
2022-03-08 04:39:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 794 @ 38659 updates
2022-03-08 04:39:39 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)
2022-03-08 04:39:39 | INFO | train | epoch 794 | loss 1.529 | ppl 2.89 | wps 21540.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38659 | lr 0.000160833 | gnorm 0.316 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 115021
2022-03-08 04:39:39 | INFO | fairseq.trainer | begin training epoch 795
2022-03-08 04:39:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:41:37 | INFO | train_inner | epoch 795:     41 / 49 loss=1.528, ppl=2.88, wps=21803.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=38700, lr=0.000160748, gnorm=0.314, loss_scale=16, train_wall=263, gb_free=21.5, wall=115138
2022-03-08 04:41:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:42:04 | INFO | valid | epoch 795 | valid on 'valid' subset | loss 11.056 | ppl 2128.97 | wps 38645.7 | wpb 510.9 | bsz 1 | num_updates 38708 | best_loss 8.723
2022-03-08 04:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 795 @ 38708 updates
2022-03-08 04:42:04 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)
2022-03-08 04:42:04 | INFO | train | epoch 795 | loss 1.528 | ppl 2.88 | wps 21996.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38708 | lr 0.000160731 | gnorm 0.311 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 115165
2022-03-08 04:42:04 | INFO | fairseq.trainer | begin training epoch 796
2022-03-08 04:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:44:28 | INFO | valid | epoch 796 | valid on 'valid' subset | loss 11.057 | ppl 2129.89 | wps 38791.4 | wpb 510.9 | bsz 1 | num_updates 38757 | best_loss 8.723
2022-03-08 04:44:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 796 @ 38757 updates
2022-03-08 04:44:28 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)
2022-03-08 04:44:28 | INFO | train | epoch 796 | loss 1.528 | ppl 2.88 | wps 22007.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38757 | lr 0.000160629 | gnorm 0.317 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 115310
2022-03-08 04:44:28 | INFO | fairseq.trainer | begin training epoch 797
2022-03-08 04:44:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:46:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:46:34 | INFO | train_inner | epoch 797:     44 / 49 loss=1.528, ppl=2.88, wps=21810.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38800, lr=0.00016054, gnorm=0.316, loss_scale=16, train_wall=263, gb_free=21.5, wall=115436
2022-03-08 04:46:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:46:53 | INFO | valid | epoch 797 | valid on 'valid' subset | loss 11.082 | ppl 2168.14 | wps 38775.3 | wpb 510.9 | bsz 1 | num_updates 38805 | best_loss 8.723
2022-03-08 04:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 797 @ 38805 updates
2022-03-08 04:46:53 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)
2022-03-08 04:46:53 | INFO | train | epoch 797 | loss 1.527 | ppl 2.88 | wps 21546 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38805 | lr 0.00016053 | gnorm 0.315 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 115454
2022-03-08 04:46:53 | INFO | fairseq.trainer | begin training epoch 798
2022-03-08 04:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:49:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:49:17 | INFO | valid | epoch 798 | valid on 'valid' subset | loss 11.071 | ppl 2150.71 | wps 38932.8 | wpb 510.9 | bsz 1 | num_updates 38854 | best_loss 8.723
2022-03-08 04:49:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 798 @ 38854 updates
2022-03-08 04:49:17 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)
2022-03-08 04:49:17 | INFO | train | epoch 798 | loss 1.528 | ppl 2.88 | wps 22005.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38854 | lr 0.000160429 | gnorm 0.31 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 115599
2022-03-08 04:49:17 | INFO | fairseq.trainer | begin training epoch 799
2022-03-08 04:49:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:51:28 | INFO | train_inner | epoch 799:     46 / 49 loss=1.528, ppl=2.88, wps=22026.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38900, lr=0.000160334, gnorm=0.312, loss_scale=16, train_wall=260, gb_free=21.5, wall=115730
2022-03-08 04:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:51:41 | INFO | valid | epoch 799 | valid on 'valid' subset | loss 11.065 | ppl 2143.05 | wps 38910.5 | wpb 510.9 | bsz 1 | num_updates 38903 | best_loss 8.723
2022-03-08 04:51:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 799 @ 38903 updates
2022-03-08 04:51:41 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)
2022-03-08 04:51:41 | INFO | train | epoch 799 | loss 1.527 | ppl 2.88 | wps 22022 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38903 | lr 0.000160328 | gnorm 0.313 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 115743
2022-03-08 04:51:41 | INFO | fairseq.trainer | begin training epoch 800
2022-03-08 04:51:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:54:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:54:06 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 11.084 | ppl 2170.04 | wps 38781.3 | wpb 510.9 | bsz 1 | num_updates 38952 | best_loss 8.723
2022-03-08 04:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 38952 updates
2022-03-08 04:54:06 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)
2022-03-08 04:54:06 | INFO | train | epoch 800 | loss 1.527 | ppl 2.88 | wps 22020.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38952 | lr 0.000160227 | gnorm 0.31 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 115887
2022-03-08 04:54:06 | INFO | fairseq.trainer | begin training epoch 801
2022-03-08 04:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:56:23 | INFO | train_inner | epoch 801:     48 / 49 loss=1.527, ppl=2.88, wps=22028.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39000, lr=0.000160128, gnorm=0.311, loss_scale=32, train_wall=260, gb_free=21.5, wall=116025
2022-03-08 04:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:56:30 | INFO | valid | epoch 801 | valid on 'valid' subset | loss 11.055 | ppl 2127.85 | wps 38732.7 | wpb 510.9 | bsz 1 | num_updates 39001 | best_loss 8.723
2022-03-08 04:56:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 801 @ 39001 updates
2022-03-08 04:56:30 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)
2022-03-08 04:56:30 | INFO | train | epoch 801 | loss 1.527 | ppl 2.88 | wps 21995.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39001 | lr 0.000160126 | gnorm 0.311 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 116032
2022-03-08 04:56:30 | INFO | fairseq.trainer | begin training epoch 802
2022-03-08 04:56:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:58:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:58:55 | INFO | valid | epoch 802 | valid on 'valid' subset | loss 11.086 | ppl 2173.2 | wps 38997.5 | wpb 510.9 | bsz 1 | num_updates 39050 | best_loss 8.723
2022-03-08 04:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 802 @ 39050 updates
2022-03-08 04:58:55 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)
2022-03-08 04:58:55 | INFO | train | epoch 802 | loss 1.528 | ppl 2.88 | wps 21996 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39050 | lr 0.000160026 | gnorm 0.316 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 116176
2022-03-08 04:58:55 | INFO | fairseq.trainer | begin training epoch 803
2022-03-08 04:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:59:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:01:19 | INFO | valid | epoch 803 | valid on 'valid' subset | loss 11.059 | ppl 2133.17 | wps 38867 | wpb 510.9 | bsz 1 | num_updates 39098 | best_loss 8.723
2022-03-08 05:01:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 803 @ 39098 updates
2022-03-08 05:01:19 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)
2022-03-08 05:01:19 | INFO | train | epoch 803 | loss 1.527 | ppl 2.88 | wps 21544.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39098 | lr 0.000159927 | gnorm 0.315 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 116321
2022-03-08 05:01:19 | INFO | fairseq.trainer | begin training epoch 804
2022-03-08 05:01:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:01:25 | INFO | train_inner | epoch 804:      2 / 49 loss=1.527, ppl=2.88, wps=21379.5, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=39100, lr=0.000159923, gnorm=0.316, loss_scale=32, train_wall=262, gb_free=21.5, wall=116327
2022-03-08 05:03:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:03:43 | INFO | valid | epoch 804 | valid on 'valid' subset | loss 11.023 | ppl 2080.71 | wps 38875.4 | wpb 510.9 | bsz 1 | num_updates 39147 | best_loss 8.723
2022-03-08 05:03:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 804 @ 39147 updates
2022-03-08 05:03:43 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)
2022-03-08 05:03:43 | INFO | train | epoch 804 | loss 1.527 | ppl 2.88 | wps 22005 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39147 | lr 0.000159827 | gnorm 0.31 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 116465
2022-03-08 05:03:43 | INFO | fairseq.trainer | begin training epoch 805
2022-03-08 05:03:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:05:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:06:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:06:08 | INFO | valid | epoch 805 | valid on 'valid' subset | loss 11.058 | ppl 2132.63 | wps 38817.2 | wpb 510.9 | bsz 1 | num_updates 39195 | best_loss 8.723
2022-03-08 05:06:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 805 @ 39195 updates
2022-03-08 05:06:08 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)
2022-03-08 05:06:08 | INFO | train | epoch 805 | loss 1.526 | ppl 2.88 | wps 21549.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39195 | lr 0.000159729 | gnorm 0.314 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 116610
2022-03-08 05:06:08 | INFO | fairseq.trainer | begin training epoch 806
2022-03-08 05:06:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:06:22 | INFO | train_inner | epoch 806:      5 / 49 loss=1.527, ppl=2.88, wps=21811.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39200, lr=0.000159719, gnorm=0.313, loss_scale=32, train_wall=263, gb_free=21.5, wall=116624
2022-03-08 05:06:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:08:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:08:32 | INFO | valid | epoch 806 | valid on 'valid' subset | loss 11.05 | ppl 2119.51 | wps 39011 | wpb 510.9 | bsz 1 | num_updates 39243 | best_loss 8.723
2022-03-08 05:08:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 806 @ 39243 updates
2022-03-08 05:08:32 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)
2022-03-08 05:08:32 | INFO | train | epoch 806 | loss 1.527 | ppl 2.88 | wps 21570.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39243 | lr 0.000159632 | gnorm 0.315 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 116754
2022-03-08 05:08:32 | INFO | fairseq.trainer | begin training epoch 807
2022-03-08 05:08:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:10:57 | INFO | valid | epoch 807 | valid on 'valid' subset | loss 11.067 | ppl 2144.8 | wps 39518.6 | wpb 510.9 | bsz 1 | num_updates 39292 | best_loss 8.723
2022-03-08 05:10:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 807 @ 39292 updates
2022-03-08 05:10:57 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)
2022-03-08 05:10:57 | INFO | train | epoch 807 | loss 1.527 | ppl 2.88 | wps 22000.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39292 | lr 0.000159532 | gnorm 0.311 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 116898
2022-03-08 05:10:57 | INFO | fairseq.trainer | begin training epoch 808
2022-03-08 05:10:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:11:20 | INFO | train_inner | epoch 808:      8 / 49 loss=1.526, ppl=2.88, wps=21816.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=39300, lr=0.000159516, gnorm=0.312, loss_scale=16, train_wall=263, gb_free=21.5, wall=116921
2022-03-08 05:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:13:21 | INFO | valid | epoch 808 | valid on 'valid' subset | loss 11.047 | ppl 2115.89 | wps 38917 | wpb 510.9 | bsz 1 | num_updates 39341 | best_loss 8.723
2022-03-08 05:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 808 @ 39341 updates
2022-03-08 05:13:21 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)
2022-03-08 05:13:21 | INFO | train | epoch 808 | loss 1.526 | ppl 2.88 | wps 21992.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39341 | lr 0.000159433 | gnorm 0.312 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 117043
2022-03-08 05:13:21 | INFO | fairseq.trainer | begin training epoch 809
2022-03-08 05:13:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:14:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:15:46 | INFO | valid | epoch 809 | valid on 'valid' subset | loss 11.056 | ppl 2129.2 | wps 38808.9 | wpb 510.9 | bsz 1 | num_updates 39389 | best_loss 8.723
2022-03-08 05:15:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 809 @ 39389 updates
2022-03-08 05:15:46 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)
2022-03-08 05:15:46 | INFO | train | epoch 809 | loss 1.526 | ppl 2.88 | wps 21563.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39389 | lr 0.000159335 | gnorm 0.312 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 117187
2022-03-08 05:15:46 | INFO | fairseq.trainer | begin training epoch 810
2022-03-08 05:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:16:17 | INFO | train_inner | epoch 810:     11 / 49 loss=1.526, ppl=2.88, wps=21814.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=39400, lr=0.000159313, gnorm=0.312, loss_scale=16, train_wall=263, gb_free=21.5, wall=117219
2022-03-08 05:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:18:10 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 11.088 | ppl 2176.09 | wps 39026.7 | wpb 510.9 | bsz 1 | num_updates 39438 | best_loss 8.723
2022-03-08 05:18:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 39438 updates
2022-03-08 05:18:10 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)
2022-03-08 05:18:10 | INFO | train | epoch 810 | loss 1.526 | ppl 2.88 | wps 22002.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39438 | lr 0.000159236 | gnorm 0.309 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 117332
2022-03-08 05:18:10 | INFO | fairseq.trainer | begin training epoch 811
2022-03-08 05:18:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:20:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:20:34 | INFO | valid | epoch 811 | valid on 'valid' subset | loss 11.026 | ppl 2084.59 | wps 38953.8 | wpb 510.9 | bsz 1 | num_updates 39487 | best_loss 8.723
2022-03-08 05:20:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 811 @ 39487 updates
2022-03-08 05:20:34 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)
2022-03-08 05:20:34 | INFO | train | epoch 811 | loss 1.526 | ppl 2.88 | wps 22001.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39487 | lr 0.000159138 | gnorm 0.31 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 117476
2022-03-08 05:20:34 | INFO | fairseq.trainer | begin training epoch 812
2022-03-08 05:20:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:21:12 | INFO | train_inner | epoch 812:     13 / 49 loss=1.526, ppl=2.88, wps=22019.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39500, lr=0.000159111, gnorm=0.31, loss_scale=32, train_wall=260, gb_free=21.5, wall=117513
2022-03-08 05:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:22:59 | INFO | valid | epoch 812 | valid on 'valid' subset | loss 11.036 | ppl 2099.29 | wps 39103.6 | wpb 510.9 | bsz 1 | num_updates 39536 | best_loss 8.723
2022-03-08 05:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 812 @ 39536 updates
2022-03-08 05:22:59 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)
2022-03-08 05:22:59 | INFO | train | epoch 812 | loss 1.526 | ppl 2.88 | wps 22006.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39536 | lr 0.000159039 | gnorm 0.309 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 117621
2022-03-08 05:22:59 | INFO | fairseq.trainer | begin training epoch 813
2022-03-08 05:22:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:25:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:25:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:25:23 | INFO | valid | epoch 813 | valid on 'valid' subset | loss 11.055 | ppl 2127.62 | wps 38894.4 | wpb 510.9 | bsz 1 | num_updates 39584 | best_loss 8.723
2022-03-08 05:25:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 813 @ 39584 updates
2022-03-08 05:25:23 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)
2022-03-08 05:25:23 | INFO | train | epoch 813 | loss 1.526 | ppl 2.88 | wps 21543.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39584 | lr 0.000158943 | gnorm 0.312 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 117765
2022-03-08 05:25:23 | INFO | fairseq.trainer | begin training epoch 814
2022-03-08 05:25:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:26:09 | INFO | train_inner | epoch 814:     16 / 49 loss=1.526, ppl=2.88, wps=21804, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39600, lr=0.00015891, gnorm=0.311, loss_scale=16, train_wall=263, gb_free=21.5, wall=117811
2022-03-08 05:27:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:27:48 | INFO | valid | epoch 814 | valid on 'valid' subset | loss 11.049 | ppl 2119.44 | wps 38983.5 | wpb 510.9 | bsz 1 | num_updates 39633 | best_loss 8.723
2022-03-08 05:27:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 814 @ 39633 updates
2022-03-08 05:27:48 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)
2022-03-08 05:27:48 | INFO | train | epoch 814 | loss 1.525 | ppl 2.88 | wps 22003.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39633 | lr 0.000158844 | gnorm 0.309 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 117909
2022-03-08 05:27:48 | INFO | fairseq.trainer | begin training epoch 815
2022-03-08 05:27:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:30:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:30:12 | INFO | valid | epoch 815 | valid on 'valid' subset | loss 11.062 | ppl 2138.48 | wps 38873.8 | wpb 510.9 | bsz 1 | num_updates 39682 | best_loss 8.723
2022-03-08 05:30:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 815 @ 39682 updates
2022-03-08 05:30:12 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)
2022-03-08 05:30:12 | INFO | train | epoch 815 | loss 1.525 | ppl 2.88 | wps 21990.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39682 | lr 0.000158746 | gnorm 0.313 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 118054
2022-03-08 05:30:12 | INFO | fairseq.trainer | begin training epoch 816
2022-03-08 05:30:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:31:04 | INFO | train_inner | epoch 816:     18 / 49 loss=1.525, ppl=2.88, wps=22016.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=39700, lr=0.00015871, gnorm=0.31, loss_scale=16, train_wall=260, gb_free=21.5, wall=118106
2022-03-08 05:32:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:32:37 | INFO | valid | epoch 816 | valid on 'valid' subset | loss 11.061 | ppl 2136.53 | wps 38993.7 | wpb 510.9 | bsz 1 | num_updates 39731 | best_loss 8.723
2022-03-08 05:32:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 816 @ 39731 updates
2022-03-08 05:32:37 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)
2022-03-08 05:32:37 | INFO | train | epoch 816 | loss 1.525 | ppl 2.88 | wps 22010.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39731 | lr 0.000158648 | gnorm 0.311 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 118198
2022-03-08 05:32:37 | INFO | fairseq.trainer | begin training epoch 817
2022-03-08 05:32:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:34:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:35:01 | INFO | valid | epoch 817 | valid on 'valid' subset | loss 11.066 | ppl 2144.45 | wps 38853.6 | wpb 510.9 | bsz 1 | num_updates 39780 | best_loss 8.723
2022-03-08 05:35:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 817 @ 39780 updates
2022-03-08 05:35:01 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)
2022-03-08 05:35:01 | INFO | train | epoch 817 | loss 1.525 | ppl 2.88 | wps 22025 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39780 | lr 0.00015855 | gnorm 0.31 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 118343
2022-03-08 05:35:01 | INFO | fairseq.trainer | begin training epoch 818
2022-03-08 05:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:35:58 | INFO | train_inner | epoch 818:     20 / 49 loss=1.525, ppl=2.88, wps=22036.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39800, lr=0.000158511, gnorm=0.311, loss_scale=32, train_wall=260, gb_free=21.5, wall=118400
2022-03-08 05:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:37:25 | INFO | valid | epoch 818 | valid on 'valid' subset | loss 11.057 | ppl 2130.68 | wps 38706.9 | wpb 510.9 | bsz 1 | num_updates 39829 | best_loss 8.723
2022-03-08 05:37:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 818 @ 39829 updates
2022-03-08 05:37:25 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)
2022-03-08 05:37:25 | INFO | train | epoch 818 | loss 1.525 | ppl 2.88 | wps 22004.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39829 | lr 0.000158453 | gnorm 0.311 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 118487
2022-03-08 05:37:25 | INFO | fairseq.trainer | begin training epoch 819
2022-03-08 05:37:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:37:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:39:50 | INFO | valid | epoch 819 | valid on 'valid' subset | loss 11.036 | ppl 2099.5 | wps 38942.9 | wpb 510.9 | bsz 1 | num_updates 39877 | best_loss 8.723
2022-03-08 05:39:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 819 @ 39877 updates
2022-03-08 05:39:50 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)
2022-03-08 05:39:50 | INFO | train | epoch 819 | loss 1.525 | ppl 2.88 | wps 21562.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39877 | lr 0.000158358 | gnorm 0.311 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 118631
2022-03-08 05:39:50 | INFO | fairseq.trainer | begin training epoch 820
2022-03-08 05:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:40:55 | INFO | train_inner | epoch 820:     23 / 49 loss=1.524, ppl=2.88, wps=21818, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39900, lr=0.000158312, gnorm=0.311, loss_scale=32, train_wall=263, gb_free=21.5, wall=118697
2022-03-08 05:41:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:42:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:42:14 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 11.036 | ppl 2099.24 | wps 38947.1 | wpb 510.9 | bsz 1 | num_updates 39925 | best_loss 8.723
2022-03-08 05:42:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 39925 updates
2022-03-08 05:42:14 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)
2022-03-08 05:42:14 | INFO | train | epoch 820 | loss 1.524 | ppl 2.88 | wps 21563.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39925 | lr 0.000158262 | gnorm 0.313 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 118776
2022-03-08 05:42:14 | INFO | fairseq.trainer | begin training epoch 821
2022-03-08 05:42:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:44:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:44:38 | INFO | valid | epoch 821 | valid on 'valid' subset | loss 11.03 | ppl 2091.09 | wps 38996.9 | wpb 510.9 | bsz 1 | num_updates 39974 | best_loss 8.723
2022-03-08 05:44:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 821 @ 39974 updates
2022-03-08 05:44:38 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)
2022-03-08 05:44:38 | INFO | train | epoch 821 | loss 1.524 | ppl 2.88 | wps 22002.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39974 | lr 0.000158165 | gnorm 0.314 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 118920
2022-03-08 05:44:38 | INFO | fairseq.trainer | begin training epoch 822
2022-03-08 05:44:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:45:53 | INFO | train_inner | epoch 822:     26 / 49 loss=1.524, ppl=2.88, wps=21817.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=40000, lr=0.000158114, gnorm=0.313, loss_scale=16, train_wall=263, gb_free=21.5, wall=118995
2022-03-08 05:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:47:03 | INFO | valid | epoch 822 | valid on 'valid' subset | loss 11.065 | ppl 2141.76 | wps 38894.8 | wpb 510.9 | bsz 1 | num_updates 40023 | best_loss 8.723
2022-03-08 05:47:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 822 @ 40023 updates
2022-03-08 05:47:03 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)
2022-03-08 05:47:03 | INFO | train | epoch 822 | loss 1.525 | ppl 2.88 | wps 22006.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40023 | lr 0.000158068 | gnorm 0.314 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 119065
2022-03-08 05:47:03 | INFO | fairseq.trainer | begin training epoch 823
2022-03-08 05:47:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:49:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:49:27 | INFO | valid | epoch 823 | valid on 'valid' subset | loss 11.015 | ppl 2069.69 | wps 38958.7 | wpb 510.9 | bsz 1 | num_updates 40072 | best_loss 8.723
2022-03-08 05:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 823 @ 40072 updates
2022-03-08 05:49:27 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)
2022-03-08 05:49:27 | INFO | train | epoch 823 | loss 1.524 | ppl 2.88 | wps 21994 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40072 | lr 0.000157972 | gnorm 0.31 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 119209
2022-03-08 05:49:27 | INFO | fairseq.trainer | begin training epoch 824
2022-03-08 05:49:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:50:48 | INFO | train_inner | epoch 824:     28 / 49 loss=1.525, ppl=2.88, wps=22013.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=40100, lr=0.000157917, gnorm=0.312, loss_scale=32, train_wall=260, gb_free=21.5, wall=119289
2022-03-08 05:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:51:52 | INFO | valid | epoch 824 | valid on 'valid' subset | loss 11.05 | ppl 2119.64 | wps 39027.4 | wpb 510.9 | bsz 1 | num_updates 40121 | best_loss 8.723
2022-03-08 05:51:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 824 @ 40121 updates
2022-03-08 05:51:52 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)
2022-03-08 05:51:52 | INFO | train | epoch 824 | loss 1.525 | ppl 2.88 | wps 21996.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40121 | lr 0.000157875 | gnorm 0.313 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 119354
2022-03-08 05:51:52 | INFO | fairseq.trainer | begin training epoch 825
2022-03-08 05:51:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:54:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:54:16 | INFO | valid | epoch 825 | valid on 'valid' subset | loss 11.022 | ppl 2079.87 | wps 38887.4 | wpb 510.9 | bsz 1 | num_updates 40170 | best_loss 8.723
2022-03-08 05:54:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 825 @ 40170 updates
2022-03-08 05:54:16 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)
2022-03-08 05:54:16 | INFO | train | epoch 825 | loss 1.524 | ppl 2.88 | wps 22021.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40170 | lr 0.000157779 | gnorm 0.312 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 119498
2022-03-08 05:54:16 | INFO | fairseq.trainer | begin training epoch 826
2022-03-08 05:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:54:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:55:45 | INFO | train_inner | epoch 826:     31 / 49 loss=1.524, ppl=2.88, wps=21817.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40200, lr=0.00015772, gnorm=0.31, loss_scale=32, train_wall=263, gb_free=21.5, wall=119587
2022-03-08 05:56:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:56:41 | INFO | valid | epoch 826 | valid on 'valid' subset | loss 11.042 | ppl 2107.95 | wps 39020.5 | wpb 510.9 | bsz 1 | num_updates 40218 | best_loss 8.723
2022-03-08 05:56:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 826 @ 40218 updates
2022-03-08 05:56:41 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)
2022-03-08 05:56:41 | INFO | train | epoch 826 | loss 1.523 | ppl 2.87 | wps 21560.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40218 | lr 0.000157685 | gnorm 0.306 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 119642
2022-03-08 05:56:41 | INFO | fairseq.trainer | begin training epoch 827
2022-03-08 05:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:58:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:59:05 | INFO | valid | epoch 827 | valid on 'valid' subset | loss 11.034 | ppl 2096.81 | wps 38925.3 | wpb 510.9 | bsz 1 | num_updates 40267 | best_loss 8.723
2022-03-08 05:59:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 827 @ 40267 updates
2022-03-08 05:59:05 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)
2022-03-08 05:59:05 | INFO | train | epoch 827 | loss 1.524 | ppl 2.87 | wps 22023.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40267 | lr 0.000157589 | gnorm 0.309 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 119787
2022-03-08 05:59:05 | INFO | fairseq.trainer | begin training epoch 828
2022-03-08 05:59:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:00:39 | INFO | train_inner | epoch 828:     33 / 49 loss=1.524, ppl=2.88, wps=22027.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40300, lr=0.000157524, gnorm=0.308, loss_scale=32, train_wall=260, gb_free=21.5, wall=119881
2022-03-08 06:00:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 06:01:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:01:29 | INFO | valid | epoch 828 | valid on 'valid' subset | loss 11.035 | ppl 2098.25 | wps 38974.9 | wpb 510.9 | bsz 1 | num_updates 40315 | best_loss 8.723
2022-03-08 06:01:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 828 @ 40315 updates
2022-03-08 06:01:29 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)
2022-03-08 06:01:29 | INFO | train | epoch 828 | loss 1.524 | ppl 2.88 | wps 21543.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40315 | lr 0.000157495 | gnorm 0.309 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 119931
2022-03-08 06:01:29 | INFO | fairseq.trainer | begin training epoch 829
2022-03-08 06:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:03:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:03:54 | INFO | valid | epoch 829 | valid on 'valid' subset | loss 11.042 | ppl 2108.78 | wps 38856.8 | wpb 510.9 | bsz 1 | num_updates 40364 | best_loss 8.723
2022-03-08 06:03:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 829 @ 40364 updates
2022-03-08 06:03:54 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)
2022-03-08 06:03:54 | INFO | train | epoch 829 | loss 1.523 | ppl 2.87 | wps 22006.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40364 | lr 0.000157399 | gnorm 0.311 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 120076
2022-03-08 06:03:54 | INFO | fairseq.trainer | begin training epoch 830
2022-03-08 06:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:05:37 | INFO | train_inner | epoch 830:     36 / 49 loss=1.523, ppl=2.87, wps=21817.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40400, lr=0.000157329, gnorm=0.31, loss_scale=32, train_wall=263, gb_free=21.5, wall=120178
2022-03-08 06:06:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:06:18 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 11.029 | ppl 2089.13 | wps 38880.2 | wpb 510.9 | bsz 1 | num_updates 40413 | best_loss 8.723
2022-03-08 06:06:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 40413 updates
2022-03-08 06:06:18 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)
2022-03-08 06:06:18 | INFO | train | epoch 830 | loss 1.523 | ppl 2.87 | wps 22010.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40413 | lr 0.000157304 | gnorm 0.309 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 120220
2022-03-08 06:06:18 | INFO | fairseq.trainer | begin training epoch 831
2022-03-08 06:06:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:07:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 06:08:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:08:43 | INFO | valid | epoch 831 | valid on 'valid' subset | loss 11.027 | ppl 2086.51 | wps 39048 | wpb 510.9 | bsz 1 | num_updates 40461 | best_loss 8.723
2022-03-08 06:08:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 831 @ 40461 updates
2022-03-08 06:08:43 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)
2022-03-08 06:08:43 | INFO | train | epoch 831 | loss 1.523 | ppl 2.87 | wps 21556.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40461 | lr 0.000157211 | gnorm 0.312 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 120364
2022-03-08 06:08:43 | INFO | fairseq.trainer | begin training epoch 832
2022-03-08 06:08:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:10:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 06:10:37 | INFO | train_inner | epoch 832:     40 / 49 loss=1.523, ppl=2.87, wps=21614.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=40500, lr=0.000157135, gnorm=0.311, loss_scale=16, train_wall=266, gb_free=21.5, wall=120479
2022-03-08 06:11:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:11:07 | INFO | valid | epoch 832 | valid on 'valid' subset | loss 11.037 | ppl 2100.51 | wps 38970.7 | wpb 510.9 | bsz 1 | num_updates 40509 | best_loss 8.723
2022-03-08 06:11:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 832 @ 40509 updates
2022-03-08 06:11:07 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)
2022-03-08 06:11:07 | INFO | train | epoch 832 | loss 1.523 | ppl 2.87 | wps 21574.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40509 | lr 0.000157117 | gnorm 0.311 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 120509
2022-03-08 06:11:07 | INFO | fairseq.trainer | begin training epoch 833
2022-03-08 06:11:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:13:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:13:31 | INFO | valid | epoch 833 | valid on 'valid' subset | loss 11.03 | ppl 2091.43 | wps 38808.9 | wpb 510.9 | bsz 1 | num_updates 40558 | best_loss 8.723
2022-03-08 06:13:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 833 @ 40558 updates
2022-03-08 06:13:31 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)
2022-03-08 06:13:31 | INFO | train | epoch 833 | loss 1.523 | ppl 2.87 | wps 22010.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40558 | lr 0.000157022 | gnorm 0.312 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 120653
2022-03-08 06:13:31 | INFO | fairseq.trainer | begin training epoch 834
2022-03-08 06:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:15:31 | INFO | train_inner | epoch 834:     42 / 49 loss=1.523, ppl=2.87, wps=22029.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=40600, lr=0.000156941, gnorm=0.312, loss_scale=16, train_wall=260, gb_free=21.5, wall=120773
2022-03-08 06:15:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:15:56 | INFO | valid | epoch 834 | valid on 'valid' subset | loss 11.038 | ppl 2103.15 | wps 38943.7 | wpb 510.9 | bsz 1 | num_updates 40607 | best_loss 8.723
2022-03-08 06:15:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 834 @ 40607 updates
2022-03-08 06:15:56 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)
2022-03-08 06:15:56 | INFO | train | epoch 834 | loss 1.522 | ppl 2.87 | wps 22010.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40607 | lr 0.000156928 | gnorm 0.313 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 120797
2022-03-08 06:15:56 | INFO | fairseq.trainer | begin training epoch 835
2022-03-08 06:15:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:17:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 06:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:18:20 | INFO | valid | epoch 835 | valid on 'valid' subset | loss 11.053 | ppl 2124.53 | wps 38968.8 | wpb 510.9 | bsz 1 | num_updates 40655 | best_loss 8.723
2022-03-08 06:18:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 835 @ 40655 updates
2022-03-08 06:18:20 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)
2022-03-08 06:18:20 | INFO | train | epoch 835 | loss 1.522 | ppl 2.87 | wps 21553.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40655 | lr 0.000156835 | gnorm 0.311 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 120942
2022-03-08 06:18:20 | INFO | fairseq.trainer | begin training epoch 836
2022-03-08 06:18:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:20:29 | INFO | train_inner | epoch 836:     45 / 49 loss=1.522, ppl=2.87, wps=21818.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=40700, lr=0.000156748, gnorm=0.31, loss_scale=16, train_wall=263, gb_free=21.5, wall=121070
2022-03-08 06:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 342, in train
    valid_losses, should_stop = validate_and_save(
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 429, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 499, in validate
    trainer.valid_step(sample)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 1075, in valid_step
    logging_output = self._reduce_and_log_stats(logging_outputs, sample_size)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 1445, in _reduce_and_log_stats
    logging_output = agg.get_smoothed_values()
  File "/cluster/home/andriusb/fq/fairseq/fairseq/logging/meters.py", line 302, in get_smoothed_values
    [
  File "/cluster/home/andriusb/fq/fairseq/fairseq/logging/meters.py", line 303, in <listcomp>
    (key, self.get_smoothed_value(key))
  File "/cluster/home/andriusb/fq/fairseq/fairseq/logging/meters.py", line 297, in get_smoothed_value
    return meter.smoothed_value
  File "/cluster/home/andriusb/fq/fairseq/fairseq/logging/meters.py", line 108, in smoothed_value
    val = safe_round(val, self.round)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/logging/meters.py", line 60, in safe_round
    return safe_round(number.item(), ndigits)
KeyboardInterrupt
