Sender: LSF System <lsfadmin@eu-g2-04>
Subject: Job 202625112: <w2_jelinek_0.1_0.0_0.9_#3> in cluster <euler> Exited

Job <w2_jelinek_0.1_0.0_0.9_#3> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Jan 31 08:50:05 2022
Job was executed on host(s) <eu-g2-04>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Jan 31 08:50:12 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Jan 31 08:50:12 2022
Terminated at Tue Feb  1 04:49:59 2022
Results reported at Tue Feb  1 04:49:59 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.1, 0.0, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72905.00 sec.
    Max Memory :                                 6056 MB
    Average Memory :                             3674.55 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13944.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72004 sec.
    Turnaround time :                            71994 sec.

The output (if any) follows:

2022-01-31 08:50:20 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.1, 0.0, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-31 08:50:20 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-31 08:50:21 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1419/36718 [00:00<00:02, 14174.97it/s]  8%|▊         | 2837/36718 [00:00<00:02, 13517.18it/s] 12%|█▏        | 4386/36718 [00:00<00:02, 14392.97it/s] 16%|█▋        | 6002/36718 [00:00<00:02, 15077.92it/s] 20%|██        | 7513/36718 [00:00<00:02, 14268.62it/s] 24%|██▍       | 8949/36718 [00:00<00:01, 13938.47it/s] 28%|██▊       | 10358/36718 [00:00<00:01, 13982.23it/s] 32%|███▏      | 11761/36718 [00:00<00:01, 13711.82it/s] 36%|███▌      | 13233/36718 [00:00<00:01, 14006.61it/s] 40%|███▉      | 14652/36718 [00:01<00:01, 14056.99it/s] 44%|████▎     | 16061/36718 [00:01<00:01, 13840.68it/s] 48%|████▊     | 17491/36718 [00:01<00:01, 13974.10it/s] 52%|█████▏    | 18927/36718 [00:01<00:01, 14085.09it/s] 55%|█████▌    | 20337/36718 [00:01<00:01, 14058.49it/s] 59%|█████▉    | 21744/36718 [00:01<00:01, 13904.84it/s] 63%|██████▎   | 23215/36718 [00:01<00:00, 14136.88it/s] 68%|██████▊   | 24864/36718 [00:01<00:00, 14836.50it/s] 72%|███████▏  | 26350/36718 [00:01<00:00, 14403.07it/s] 76%|███████▌  | 27794/36718 [00:01<00:00, 13903.53it/s] 80%|███████▉  | 29284/36718 [00:02<00:00, 14189.17it/s] 84%|████████▎ | 30708/36718 [00:02<00:00, 13775.56it/s] 87%|████████▋ | 32091/36718 [00:02<00:00, 13560.95it/s] 91%|█████████ | 33451/36718 [00:02<00:00, 13452.28it/s] 95%|█████████▌| 34917/36718 [00:02<00:00, 13795.64it/s] 99%|█████████▉| 36300/36718 [00:02<00:00, 13737.63it/s]100%|██████████| 36718/36718 [00:02<00:00, 13981.99it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2811/36718 [00:00<00:01, 28108.28it/s] 17%|█▋        | 6095/36718 [00:00<00:00, 30887.61it/s] 25%|██▌       | 9184/36718 [00:00<00:00, 29620.55it/s] 33%|███▎      | 12167/36718 [00:00<00:00, 29695.00it/s] 41%|████▏     | 15218/36718 [00:00<00:00, 29983.56it/s] 50%|████▉     | 18220/36718 [00:00<00:00, 29425.46it/s] 58%|█████▊    | 21260/36718 [00:00<00:00, 29730.95it/s] 66%|██████▋   | 24348/36718 [00:00<00:00, 30090.06it/s] 75%|███████▍  | 27360/36718 [00:00<00:00, 29536.83it/s] 83%|████████▎ | 30318/36718 [00:01<00:00, 29217.19it/s] 91%|█████████ | 33243/36718 [00:01<00:00, 28328.91it/s] 98%|█████████▊| 36135/36718 [00:01<00:00, 28496.88it/s]100%|██████████| 36718/36718 [00:01<00:00, 29209.60it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.11it/s]2022-01-31 08:50:34 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-31 08:50:34 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-31 08:50:34 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-31 08:50:34 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-31 08:50:34 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-31 08:50:34 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-31 08:50:34 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-31 08:50:34 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-31 08:50:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:50:34 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-31 08:50:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:50:34 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-31 08:50:34 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-31 08:50:34 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint_last.pt
2022-01-31 08:50:34 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint_last.pt
2022-01-31 08:50:34 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-31 08:50:34 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-31 08:50:34 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-31 08:50:34 | INFO | fairseq.trainer | begin training epoch 1
2022-01-31 08:50:34 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-31 08:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-31 08:56:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.699 | ppl 26592.6 | wps 7830.5 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-31 08:56:28 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-31 08:56:28 | INFO | train | epoch 001 | loss 16.133 | ppl 71847.7 | wps 5917.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.237 | train_wall 324 | gb_free 6.1 | wall 354
KL Stats: Epoch 1 Divergences: Uniform: 0.517208394610612 Unigram: 3.6856011076604216
2022-01-31 08:56:28 | INFO | fairseq.trainer | begin training epoch 2
2022-01-31 08:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 08:59:35 | INFO | train_inner | epoch 002:     36 / 64 loss=15.593, ppl=49417.3, wps=6060.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.652, train_wall=510, gb_free=6.1, wall=540
2022-01-31 09:01:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:02:26 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.698 | ppl 13288.5 | wps 7843.6 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-31 09:02:26 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-31 09:02:26 | INFO | train | epoch 002 | loss 14.424 | ppl 21986.4 | wps 5835.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.494 | train_wall 329 | gb_free 6.1 | wall 712
KL Stats: Epoch 2 Divergences: Uniform: 0.5345499046738815 Unigram: 2.415997657361054
2022-01-31 09:02:26 | INFO | fairseq.trainer | begin training epoch 3
2022-01-31 09:02:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:07:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:08:23 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.877 | ppl 7520.44 | wps 7847.4 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-31 09:08:23 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-31 09:08:23 | INFO | train | epoch 003 | loss 13.522 | ppl 11762.5 | wps 5860.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.204 | train_wall 328 | gb_free 6.1 | wall 1068
KL Stats: Epoch 3 Divergences: Uniform: 0.5190752576416564 Unigram: 1.733469657351904
2022-01-31 09:08:23 | INFO | fairseq.trainer | begin training epoch 4
2022-01-31 09:08:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:09:03 | INFO | train_inner | epoch 004:      8 / 64 loss=13.655, ppl=12898.2, wps=5731.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.233, train_wall=512, gb_free=6.1, wall=1109
2022-01-31 09:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:14:19 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.032 | ppl 4186.81 | wps 7838.3 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-31 09:14:19 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-31 09:14:19 | INFO | train | epoch 004 | loss 12.574 | ppl 6099.57 | wps 5866.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.959 | train_wall 327 | gb_free 6.1 | wall 1424
KL Stats: Epoch 4 Divergences: Uniform: 0.6028876543785803 Unigram: 1.119898046115955
2022-01-31 09:14:19 | INFO | fairseq.trainer | begin training epoch 5
2022-01-31 09:14:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:18:05 | INFO | train_inner | epoch 005:     44 / 64 loss=12.226, ppl=4790.33, wps=6029.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.843, train_wall=513, gb_free=6.1, wall=1651
2022-01-31 09:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:20:14 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.513 | ppl 2922.68 | wps 8004.8 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-31 09:20:14 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-31 09:20:14 | INFO | train | epoch 005 | loss 11.78 | ppl 3516.08 | wps 5869.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.687 | train_wall 328 | gb_free 6.1 | wall 1780
KL Stats: Epoch 5 Divergences: Uniform: 0.8414502514768483 Unigram: 0.6666348311195255
2022-01-31 09:20:14 | INFO | fairseq.trainer | begin training epoch 6
2022-01-31 09:20:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:25:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:26:11 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.267 | ppl 2463.98 | wps 7862.3 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-31 09:26:11 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-31 09:26:11 | INFO | train | epoch 006 | loss 11.348 | ppl 2607.18 | wps 5861.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.584 | train_wall 328 | gb_free 6.1 | wall 2137
KL Stats: Epoch 6 Divergences: Uniform: 1.1381679960636897 Unigram: 0.466223778536306
2022-01-31 09:26:11 | INFO | fairseq.trainer | begin training epoch 7
2022-01-31 09:26:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:27:33 | INFO | train_inner | epoch 007:     16 / 64 loss=11.371, ppl=2648.07, wps=5747.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.582, train_wall=511, gb_free=6.1, wall=2218
2022-01-31 09:31:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:32:07 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.122 | ppl 2229.25 | wps 7826.2 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-31 09:32:07 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-31 09:32:07 | INFO | train | epoch 007 | loss 11.147 | ppl 2267.92 | wps 5856 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.524 | train_wall 328 | gb_free 6.1 | wall 2493
KL Stats: Epoch 7 Divergences: Uniform: 1.3621972641625302 Unigram: 0.4759570718658166
2022-01-31 09:32:07 | INFO | fairseq.trainer | begin training epoch 8
2022-01-31 09:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:36:36 | INFO | train_inner | epoch 008:     52 / 64 loss=11.086, ppl=2173.19, wps=6012.8, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=514, gb_free=6.1, wall=2762
2022-01-31 09:37:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:38:04 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.017 | ppl 2072.77 | wps 7815 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-31 09:38:04 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-31 09:38:04 | INFO | train | epoch 008 | loss 11.034 | ppl 2096.41 | wps 5850.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 328 | gb_free 6.1 | wall 2850
KL Stats: Epoch 8 Divergences: Uniform: 1.477641246290245 Unigram: 0.55090545782554
2022-01-31 09:38:04 | INFO | fairseq.trainer | begin training epoch 9
2022-01-31 09:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:44:01 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.9 | ppl 1910.42 | wps 7827.3 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-31 09:44:01 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-31 09:44:01 | INFO | train | epoch 009 | loss 10.927 | ppl 1947.19 | wps 5851.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 328 | gb_free 6.1 | wall 3207
KL Stats: Epoch 9 Divergences: Uniform: 1.522980453171203 Unigram: 0.6545921842945029
2022-01-31 09:44:01 | INFO | fairseq.trainer | begin training epoch 10
2022-01-31 09:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:46:05 | INFO | train_inner | epoch 010:     24 / 64 loss=10.918, ppl=1934.73, wps=5731.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.488, train_wall=511, gb_free=6.1, wall=3331
2022-01-31 09:49:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:49:58 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.795 | ppl 1776.39 | wps 7782.2 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-31 09:49:58 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-31 09:49:58 | INFO | train | epoch 010 | loss 10.817 | ppl 1804.08 | wps 5853.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.484 | train_wall 328 | gb_free 6.1 | wall 3564
KL Stats: Epoch 10 Divergences: Uniform: 1.5479367586754715 Unigram: 0.768739755027727
2022-01-31 09:49:58 | INFO | fairseq.trainer | begin training epoch 11
2022-01-31 09:49:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:55:08 | INFO | train_inner | epoch 011:     60 / 64 loss=10.74, ppl=1710.71, wps=6017.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=514, gb_free=6.1, wall=3874
2022-01-31 09:55:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:55:55 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.686 | ppl 1647.97 | wps 7823.6 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-31 09:55:55 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-31 09:55:55 | INFO | train | epoch 011 | loss 10.7 | ppl 1663.77 | wps 5854.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.498 | train_wall 328 | gb_free 6.1 | wall 3921
KL Stats: Epoch 11 Divergences: Uniform: 1.5662919629482603 Unigram: 0.8823497823434991
2022-01-31 09:55:55 | INFO | fairseq.trainer | begin training epoch 12
2022-01-31 09:55:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:01:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:01:51 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.578 | ppl 1528.88 | wps 7847.3 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-31 10:01:51 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-31 10:01:51 | INFO | train | epoch 012 | loss 10.583 | ppl 1533.59 | wps 5876 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.479 | train_wall 327 | gb_free 6.1 | wall 4276
KL Stats: Epoch 12 Divergences: Uniform: 1.5772463506558076 Unigram: 0.9927787941083134
2022-01-31 10:01:51 | INFO | fairseq.trainer | begin training epoch 13
2022-01-31 10:01:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:04:36 | INFO | train_inner | epoch 013:     32 / 64 loss=10.559, ppl=1508.19, wps=5742.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.494, train_wall=510, gb_free=6.1, wall=4441
2022-01-31 10:07:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:07:47 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.488 | ppl 1435.97 | wps 7863.5 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-31 10:07:47 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-31 10:07:47 | INFO | train | epoch 013 | loss 10.468 | ppl 1416.33 | wps 5853.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 328 | gb_free 6.1 | wall 4633
KL Stats: Epoch 13 Divergences: Uniform: 1.6027387457321445 Unigram: 1.089840558810177
2022-01-31 10:07:47 | INFO | fairseq.trainer | begin training epoch 14
2022-01-31 10:07:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:13:44 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.393 | ppl 1344.23 | wps 7848.9 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-31 10:13:44 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-31 10:13:44 | INFO | train | epoch 014 | loss 10.357 | ppl 1311.24 | wps 5858.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.557 | train_wall 328 | gb_free 6.1 | wall 4990
KL Stats: Epoch 14 Divergences: Uniform: 1.6292497132864732 Unigram: 1.1795074918034127
2022-01-31 10:13:44 | INFO | fairseq.trainer | begin training epoch 15
2022-01-31 10:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:14:05 | INFO | train_inner | epoch 015:      4 / 64 loss=10.379, ppl=1332.01, wps=5729.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.537, train_wall=512, gb_free=6.1, wall=5010
2022-01-31 10:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:19:41 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.323 | ppl 1280.73 | wps 7757.2 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-31 10:19:41 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-31 10:19:41 | INFO | train | epoch 015 | loss 10.245 | ppl 1213.45 | wps 5851.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.537 | train_wall 328 | gb_free 6.1 | wall 5347
KL Stats: Epoch 15 Divergences: Uniform: 1.6525316768046014 Unigram: 1.2610839664592142
2022-01-31 10:19:41 | INFO | fairseq.trainer | begin training epoch 16
2022-01-31 10:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:23:07 | INFO | train_inner | epoch 016:     40 / 64 loss=10.204, ppl=1179.28, wps=6024.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.557, train_wall=513, gb_free=6.1, wall=5553
2022-01-31 10:25:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:25:38 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.243 | ppl 1211.72 | wps 7838.5 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-31 10:25:38 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-31 10:25:38 | INFO | train | epoch 016 | loss 10.138 | ppl 1127.16 | wps 5850 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.555 | train_wall 328 | gb_free 6.1 | wall 5704
KL Stats: Epoch 16 Divergences: Uniform: 1.6810889769489374 Unigram: 1.3394041445537825
2022-01-31 10:25:38 | INFO | fairseq.trainer | begin training epoch 17
2022-01-31 10:25:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:31:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:31:35 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.15 | ppl 1136.44 | wps 7844.1 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-31 10:31:35 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-31 10:31:35 | INFO | train | epoch 017 | loss 10.032 | ppl 1046.81 | wps 5855.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.548 | train_wall 328 | gb_free 6.1 | wall 6060
KL Stats: Epoch 17 Divergences: Uniform: 1.7144411620276798 Unigram: 1.40776968261585
2022-01-31 10:31:35 | INFO | fairseq.trainer | begin training epoch 18
2022-01-31 10:31:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:32:37 | INFO | train_inner | epoch 018:     12 / 64 loss=10.046, ppl=1057.12, wps=5723.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.55, train_wall=512, gb_free=6.1, wall=6122
2022-01-31 10:37:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:37:30 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.087 | ppl 1087.63 | wps 8007.6 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-31 10:37:30 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-31 10:37:30 | INFO | train | epoch 018 | loss 9.932 | ppl 976.59 | wps 5876.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.572 | train_wall 327 | gb_free 6.1 | wall 6416
KL Stats: Epoch 18 Divergences: Uniform: 1.7496488849904026 Unigram: 1.4746713423485551
2022-01-31 10:37:30 | INFO | fairseq.trainer | begin training epoch 19
2022-01-31 10:37:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:41:38 | INFO | train_inner | epoch 019:     48 / 64 loss=9.882, ppl=943.63, wps=6042.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.543, train_wall=512, gb_free=6.1, wall=6663
2022-01-31 10:42:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:43:27 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.013 | ppl 1033.27 | wps 7838.5 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-31 10:43:27 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-31 10:43:27 | INFO | train | epoch 019 | loss 9.828 | ppl 909.12 | wps 5857.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 328 | gb_free 6.1 | wall 6772
KL Stats: Epoch 19 Divergences: Uniform: 1.7792725108540752 Unigram: 1.5414256647434226
2022-01-31 10:43:27 | INFO | fairseq.trainer | begin training epoch 20
2022-01-31 10:43:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:49:23 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.928 | ppl 973.96 | wps 7854.7 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-31 10:49:23 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-31 10:49:23 | INFO | train | epoch 020 | loss 9.732 | ppl 850.39 | wps 5854.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.553 | train_wall 328 | gb_free 6.1 | wall 7129
KL Stats: Epoch 20 Divergences: Uniform: 1.810073113896505 Unigram: 1.6018857836352949
2022-01-31 10:49:23 | INFO | fairseq.trainer | begin training epoch 21
2022-01-31 10:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:51:07 | INFO | train_inner | epoch 021:     20 / 64 loss=9.727, ppl=847.46, wps=5723, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.547, train_wall=512, gb_free=6.1, wall=7233
2022-01-31 10:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:55:20 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.886 | ppl 945.96 | wps 7839.1 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-31 10:55:20 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-31 10:55:20 | INFO | train | epoch 021 | loss 9.638 | ppl 796.65 | wps 5854.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.528 | train_wall 328 | gb_free 6.1 | wall 7486
KL Stats: Epoch 21 Divergences: Uniform: 1.8398694904232575 Unigram: 1.6609174339600896
2022-01-31 10:55:20 | INFO | fairseq.trainer | begin training epoch 22
2022-01-31 10:55:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:00:10 | INFO | train_inner | epoch 022:     56 / 64 loss=9.585, ppl=768.17, wps=6025.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.536, train_wall=513, gb_free=6.1, wall=7775
2022-01-31 11:00:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:01:18 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.82 | ppl 903.64 | wps 7747.2 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-31 11:01:18 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-31 11:01:18 | INFO | train | epoch 022 | loss 9.549 | ppl 749.04 | wps 5833.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.547 | train_wall 329 | gb_free 6.1 | wall 7844
KL Stats: Epoch 22 Divergences: Uniform: 1.8648498854105915 Unigram: 1.7173722735310575
2022-01-31 11:01:18 | INFO | fairseq.trainer | begin training epoch 23
2022-01-31 11:01:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:06:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:07:16 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.761 | ppl 867.89 | wps 7827.5 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-31 11:07:16 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-31 11:07:16 | INFO | train | epoch 023 | loss 9.462 | ppl 705.38 | wps 5838.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.517 | train_wall 329 | gb_free 6.1 | wall 8202
KL Stats: Epoch 23 Divergences: Uniform: 1.8927516774288877 Unigram: 1.7692917245152893
2022-01-31 11:07:16 | INFO | fairseq.trainer | begin training epoch 24
2022-01-31 11:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:09:40 | INFO | train_inner | epoch 024:     28 / 64 loss=9.447, ppl=698.06, wps=5712.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.529, train_wall=513, gb_free=6.1, wall=8346
2022-01-31 11:12:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:13:12 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.702 | ppl 832.69 | wps 7824 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-31 11:13:12 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-31 11:13:12 | INFO | train | epoch 024 | loss 9.379 | ppl 665.78 | wps 5868.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.551 | train_wall 327 | gb_free 6.1 | wall 8557
KL Stats: Epoch 24 Divergences: Uniform: 1.9145869638355795 Unigram: 1.815088546175561
2022-01-31 11:13:12 | INFO | fairseq.trainer | begin training epoch 25
2022-01-31 11:13:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:18:40 | INFO | train_inner | epoch 025:     64 / 64 loss=9.325, ppl=641.36, wps=6033.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.531, train_wall=511, gb_free=6.1, wall=8886
2022-01-31 11:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:19:08 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.67 | ppl 814.62 | wps 7871.8 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-31 11:19:08 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-31 11:19:08 | INFO | train | epoch 025 | loss 9.297 | ppl 629.17 | wps 5858.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.52 | train_wall 328 | gb_free 6.1 | wall 8914
KL Stats: Epoch 25 Divergences: Uniform: 1.9436216731098985 Unigram: 1.8632243217175344
2022-01-31 11:19:08 | INFO | fairseq.trainer | begin training epoch 26
2022-01-31 11:19:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:25:06 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.619 | ppl 786.47 | wps 7840.5 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-31 11:25:06 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-31 11:25:06 | INFO | train | epoch 026 | loss 9.217 | ppl 595.05 | wps 5837 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.546 | train_wall 329 | gb_free 6.1 | wall 9272
KL Stats: Epoch 26 Divergences: Uniform: 1.9564830183824116 Unigram: 1.9069174388965078
2022-01-31 11:25:06 | INFO | fairseq.trainer | begin training epoch 27
2022-01-31 11:25:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:28:12 | INFO | train_inner | epoch 027:     36 / 64 loss=9.189, ppl=583.53, wps=5720, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.535, train_wall=514, gb_free=6.1, wall=9458
2022-01-31 11:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:31:02 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.589 | ppl 769.97 | wps 7757.5 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-31 11:31:02 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-31 11:31:02 | INFO | train | epoch 027 | loss 9.136 | ppl 562.48 | wps 5866.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.52 | train_wall 327 | gb_free 6.1 | wall 9628
KL Stats: Epoch 27 Divergences: Uniform: 1.9820231089738016 Unigram: 1.9459831047947016
2022-01-31 11:31:02 | INFO | fairseq.trainer | begin training epoch 28
2022-01-31 11:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:36:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:36:58 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.564 | ppl 756.84 | wps 7847.9 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-31 11:36:58 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-31 11:36:58 | INFO | train | epoch 028 | loss 9.058 | ppl 532.98 | wps 5869.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.525 | train_wall 327 | gb_free 6.1 | wall 9984
KL Stats: Epoch 28 Divergences: Uniform: 2.013568105456356 Unigram: 1.9871563517777484
2022-01-31 11:36:58 | INFO | fairseq.trainer | begin training epoch 29
2022-01-31 11:36:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:37:39 | INFO | train_inner | epoch 029:      8 / 64 loss=9.073, ppl=538.73, wps=5745.2, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.527, train_wall=510, gb_free=6.1, wall=10025
2022-01-31 11:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:42:54 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.532 | ppl 740.08 | wps 7843.3 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-31 11:42:54 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-31 11:42:54 | INFO | train | epoch 029 | loss 8.979 | ppl 504.73 | wps 5861.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.527 | train_wall 328 | gb_free 6.1 | wall 10340
KL Stats: Epoch 29 Divergences: Uniform: 2.0329932599294147 Unigram: 2.024818367922089
2022-01-31 11:42:54 | INFO | fairseq.trainer | begin training epoch 30
2022-01-31 11:42:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:46:41 | INFO | train_inner | epoch 030:     44 / 64 loss=8.946, ppl=493.36, wps=6029.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.519, train_wall=513, gb_free=6.1, wall=10567
2022-01-31 11:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:48:50 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.503 | ppl 725.54 | wps 7976.9 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-31 11:48:50 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-31 11:48:50 | INFO | train | epoch 030 | loss 8.902 | ppl 478.35 | wps 5869 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.522 | train_wall 328 | gb_free 6.1 | wall 10696
KL Stats: Epoch 30 Divergences: Uniform: 2.052228590990245 Unigram: 2.0652157583080077
2022-01-31 11:48:50 | INFO | fairseq.trainer | begin training epoch 31
2022-01-31 11:48:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:54:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:54:48 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.455 | ppl 701.6 | wps 7853 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-31 11:54:48 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-31 11:54:48 | INFO | train | epoch 031 | loss 8.823 | ppl 452.88 | wps 5842.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.495 | train_wall 329 | gb_free 6.1 | wall 11053
KL Stats: Epoch 31 Divergences: Uniform: 2.0699090993621323 Unigram: 2.0991911459540558
2022-01-31 11:54:48 | INFO | fairseq.trainer | begin training epoch 32
2022-01-31 11:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:56:10 | INFO | train_inner | epoch 032:     16 / 64 loss=8.824, ppl=453.24, wps=5731.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.503, train_wall=512, gb_free=6.1, wall=11136
2022-01-31 12:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:00:44 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.419 | ppl 684.59 | wps 7852.3 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-31 12:00:44 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-31 12:00:44 | INFO | train | epoch 032 | loss 8.749 | ppl 430.28 | wps 5858 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.508 | train_wall 328 | gb_free 6.1 | wall 11410
KL Stats: Epoch 32 Divergences: Uniform: 2.0962749504270524 Unigram: 2.136079636775701
2022-01-31 12:00:44 | INFO | fairseq.trainer | begin training epoch 33
2022-01-31 12:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:05:13 | INFO | train_inner | epoch 033:     52 / 64 loss=8.712, ppl=419.42, wps=6018.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.512, train_wall=514, gb_free=6.1, wall=11679
2022-01-31 12:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:06:42 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.404 | ppl 677.58 | wps 7831.7 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-31 12:06:42 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-31 12:06:42 | INFO | train | epoch 033 | loss 8.675 | ppl 408.64 | wps 5843.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.51 | train_wall 329 | gb_free 6.1 | wall 11767
KL Stats: Epoch 33 Divergences: Uniform: 2.121835613589365 Unigram: 2.1758039922540684
2022-01-31 12:06:42 | INFO | fairseq.trainer | begin training epoch 34
2022-01-31 12:06:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:12:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:12:38 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.392 | ppl 672.03 | wps 7848.2 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-31 12:12:38 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-31 12:12:38 | INFO | train | epoch 034 | loss 8.599 | ppl 387.82 | wps 5854.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.512 | train_wall 328 | gb_free 6.1 | wall 12124
KL Stats: Epoch 34 Divergences: Uniform: 2.141329987124237 Unigram: 2.211969545667456
2022-01-31 12:12:38 | INFO | fairseq.trainer | begin training epoch 35
2022-01-31 12:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:14:42 | INFO | train_inner | epoch 035:     24 / 64 loss=8.586, ppl=384.4, wps=5729.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.514, train_wall=512, gb_free=6.1, wall=12248
2022-01-31 12:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:18:36 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.357 | ppl 655.6 | wps 7920.8 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-31 12:18:36 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-31 12:18:36 | INFO | train | epoch 035 | loss 8.527 | ppl 368.88 | wps 5847.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.507 | train_wall 329 | gb_free 6.1 | wall 12481
KL Stats: Epoch 35 Divergences: Uniform: 2.1630275068524356 Unigram: 2.2423064347854256
2022-01-31 12:18:36 | INFO | fairseq.trainer | begin training epoch 36
2022-01-31 12:18:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:23:46 | INFO | train_inner | epoch 036:     60 / 64 loss=8.483, ppl=357.73, wps=6012.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.499, train_wall=515, gb_free=6.1, wall=12791
2022-01-31 12:24:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:24:33 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.331 | ppl 643.93 | wps 7839.8 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-31 12:24:33 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-31 12:24:33 | INFO | train | epoch 036 | loss 8.453 | ppl 350.43 | wps 5845.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.497 | train_wall 328 | gb_free 6.1 | wall 12839
KL Stats: Epoch 36 Divergences: Uniform: 2.1848241602427367 Unigram: 2.2812232144715994
2022-01-31 12:24:33 | INFO | fairseq.trainer | begin training epoch 37
2022-01-31 12:24:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:30:29 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.349 | ppl 652.24 | wps 7831.2 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-31 12:30:29 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-31 12:30:29 | INFO | train | epoch 037 | loss 8.384 | ppl 334.07 | wps 5861 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.509 | train_wall 328 | gb_free 6.1 | wall 13195
KL Stats: Epoch 37 Divergences: Uniform: 2.203489617035752 Unigram: 2.316397890322906
2022-01-31 12:30:29 | INFO | fairseq.trainer | begin training epoch 38
2022-01-31 12:30:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:33:14 | INFO | train_inner | epoch 038:     32 / 64 loss=8.363, ppl=329.14, wps=5735.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.507, train_wall=511, gb_free=6.1, wall=13360
2022-01-31 12:35:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:36:26 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.329 | ppl 643.01 | wps 7827.8 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-31 12:36:26 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-31 12:36:26 | INFO | train | epoch 038 | loss 8.315 | ppl 318.58 | wps 5848.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.507 | train_wall 328 | gb_free 6.1 | wall 13552
KL Stats: Epoch 38 Divergences: Uniform: 2.234366494922494 Unigram: 2.3405972583210315
2022-01-31 12:36:26 | INFO | fairseq.trainer | begin training epoch 39
2022-01-31 12:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:41:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:42:23 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.312 | ppl 635.73 | wps 7827.3 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-31 12:42:23 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-31 12:42:23 | INFO | train | epoch 039 | loss 8.246 | ppl 303.68 | wps 5864 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.498 | train_wall 327 | gb_free 6.1 | wall 13908
KL Stats: Epoch 39 Divergences: Uniform: 2.24170071921029 Unigram: 2.3802682186199515
2022-01-31 12:42:23 | INFO | fairseq.trainer | begin training epoch 40
2022-01-31 12:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:42:43 | INFO | train_inner | epoch 040:      4 / 64 loss=8.268, ppl=308.33, wps=5726.4, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.504, train_wall=512, gb_free=6.1, wall=13929
2022-01-31 12:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:48:20 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.29 | ppl 625.94 | wps 7765.4 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-31 12:48:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-31 12:48:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint40.pt
2022-01-31 12:48:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint40.pt
2022-01-31 12:48:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.29) (writing took 4.873954883776605 seconds)
2022-01-31 12:48:25 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-31 12:48:25 | INFO | train | epoch 040 | loss 8.178 | ppl 289.55 | wps 5765.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.501 | train_wall 328 | gb_free 6.1 | wall 14271
KL Stats: Epoch 40 Divergences: Uniform: 2.267977422467878 Unigram: 2.411234622630235
2022-01-31 12:48:25 | INFO | fairseq.trainer | begin training epoch 41
2022-01-31 12:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:51:50 | INFO | train_inner | epoch 041:     40 / 64 loss=8.154, ppl=284.87, wps=5973.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.499, train_wall=513, gb_free=6.1, wall=14476
2022-01-31 12:53:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:54:20 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.28 | ppl 621.58 | wps 7847.2 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.28
2022-01-31 12:54:20 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-31 12:54:20 | INFO | train | epoch 041 | loss 8.114 | ppl 277.01 | wps 5874.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.502 | train_wall 327 | gb_free 6.1 | wall 14626
KL Stats: Epoch 41 Divergences: Uniform: 2.2836917864710187 Unigram: 2.4385710476876574
2022-01-31 12:54:20 | INFO | fairseq.trainer | begin training epoch 42
2022-01-31 12:54:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:59:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:00:16 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.258 | ppl 612.46 | wps 7842 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.258
2022-01-31 13:00:16 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-31 13:00:16 | INFO | train | epoch 042 | loss 8.05 | ppl 264.98 | wps 5869.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.513 | train_wall 327 | gb_free 6.1 | wall 14982
KL Stats: Epoch 42 Divergences: Uniform: 2.300976599368634 Unigram: 2.474831047345943
2022-01-31 13:00:16 | INFO | fairseq.trainer | begin training epoch 43
2022-01-31 13:00:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:01:18 | INFO | train_inner | epoch 043:     12 / 64 loss=8.056, ppl=266.17, wps=5742, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.512, train_wall=511, gb_free=6.1, wall=15044
2022-01-31 13:05:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:06:12 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.288 | ppl 625.11 | wps 7907.6 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.288
2022-01-31 13:06:12 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-31 13:06:12 | INFO | train | epoch 043 | loss 7.984 | ppl 253.21 | wps 5866.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.497 | train_wall 327 | gb_free 6.1 | wall 15338
KL Stats: Epoch 43 Divergences: Uniform: 2.3226290864516934 Unigram: 2.503865702121564
2022-01-31 13:06:12 | INFO | fairseq.trainer | begin training epoch 44
2022-01-31 13:06:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:10:19 | INFO | train_inner | epoch 044:     48 / 64 loss=7.95, ppl=247.32, wps=6035.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.502, train_wall=513, gb_free=6.1, wall=15585
2022-01-31 13:11:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:12:08 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.295 | ppl 627.97 | wps 7864.3 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.29
2022-01-31 13:12:08 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-31 13:12:08 | INFO | train | epoch 044 | loss 7.925 | ppl 243.09 | wps 5865.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.509 | train_wall 327 | gb_free 6.1 | wall 15694
KL Stats: Epoch 44 Divergences: Uniform: 2.341551777314357 Unigram: 2.5316330457442717
2022-01-31 13:12:08 | INFO | fairseq.trainer | begin training epoch 45
2022-01-31 13:12:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:17:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:18:04 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.265 | ppl 615.16 | wps 7801.4 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.265
2022-01-31 13:18:04 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-31 13:18:04 | INFO | train | epoch 045 | loss 7.861 | ppl 232.52 | wps 5863 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.503 | train_wall 327 | gb_free 6.1 | wall 16050
KL Stats: Epoch 45 Divergences: Uniform: 2.3594785450936633 Unigram: 2.5660223371443935
2022-01-31 13:18:05 | INFO | fairseq.trainer | begin training epoch 46
2022-01-31 13:18:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:19:48 | INFO | train_inner | epoch 046:     20 / 64 loss=7.861, ppl=232.52, wps=5738.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.506, train_wall=511, gb_free=6.1, wall=16153
2022-01-31 13:23:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:24:01 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.274 | ppl 619.17 | wps 7838.1 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.274
2022-01-31 13:24:01 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-31 13:24:01 | INFO | train | epoch 046 | loss 7.803 | ppl 223.28 | wps 5862.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.513 | train_wall 327 | gb_free 6.1 | wall 16406
KL Stats: Epoch 46 Divergences: Uniform: 2.372532614273227 Unigram: 2.5855353878595224
2022-01-31 13:24:01 | INFO | fairseq.trainer | begin training epoch 47
2022-01-31 13:24:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:28:50 | INFO | train_inner | epoch 047:     56 / 64 loss=7.772, ppl=218.56, wps=6024, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.503, train_wall=513, gb_free=6.1, wall=16696
2022-01-31 13:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:29:58 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.261 | ppl 613.7 | wps 7860.1 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.261
2022-01-31 13:29:58 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-31 13:29:58 | INFO | train | epoch 047 | loss 7.744 | ppl 214.38 | wps 5849.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.498 | train_wall 328 | gb_free 6.1 | wall 16764
KL Stats: Epoch 47 Divergences: Uniform: 2.3953707973744356 Unigram: 2.6122049747759957
2022-01-31 13:29:58 | INFO | fairseq.trainer | begin training epoch 48
2022-01-31 13:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:35:55 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.253 | ppl 610.2 | wps 8030.1 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.253
2022-01-31 13:35:55 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-31 13:35:55 | INFO | train | epoch 048 | loss 7.687 | ppl 206.13 | wps 5849.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.511 | train_wall 329 | gb_free 6.1 | wall 17121
KL Stats: Epoch 48 Divergences: Uniform: 2.4143608979421143 Unigram: 2.642530954947643
2022-01-31 13:35:55 | INFO | fairseq.trainer | begin training epoch 49
2022-01-31 13:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:38:20 | INFO | train_inner | epoch 049:     28 / 64 loss=7.67, ppl=203.61, wps=5722.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.507, train_wall=513, gb_free=6.1, wall=17265
2022-01-31 13:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:41:52 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.282 | ppl 622.5 | wps 7832.3 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.282
2022-01-31 13:41:52 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-31 13:41:52 | INFO | train | epoch 049 | loss 7.63 | ppl 198.12 | wps 5849.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.507 | train_wall 328 | gb_free 6.1 | wall 17478
KL Stats: Epoch 49 Divergences: Uniform: 2.4188905508318213 Unigram: 2.6677853228301935
2022-01-31 13:41:52 | INFO | fairseq.trainer | begin training epoch 50
2022-01-31 13:41:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:47:20 | INFO | train_inner | epoch 050:     64 / 64 loss=7.606, ppl=194.86, wps=6032.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.525, train_wall=511, gb_free=6.1, wall=17806
2022-01-31 13:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:47:48 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.295 | ppl 628.08 | wps 7876.2 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.29
2022-01-31 13:47:48 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-31 13:47:48 | INFO | train | epoch 050 | loss 7.58 | ppl 191.31 | wps 5869.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.532 | train_wall 327 | gb_free 6.1 | wall 17834
KL Stats: Epoch 50 Divergences: Uniform: 2.4357930271031853 Unigram: 2.6851564620898873
2022-01-31 13:47:48 | INFO | fairseq.trainer | begin training epoch 51
2022-01-31 13:47:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:53:45 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.306 | ppl 632.87 | wps 7838.8 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.29
2022-01-31 13:53:45 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-31 13:53:45 | INFO | train | epoch 051 | loss 7.523 | ppl 183.98 | wps 5854.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.508 | train_wall 328 | gb_free 6.1 | wall 18190
KL Stats: Epoch 51 Divergences: Uniform: 2.4625107206030523 Unigram: 2.7080783075721224
2022-01-31 13:53:45 | INFO | fairseq.trainer | begin training epoch 52
2022-01-31 13:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:56:50 | INFO | train_inner | epoch 052:     36 / 64 loss=7.5, ppl=180.96, wps=5734.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.509, train_wall=513, gb_free=6.1, wall=18376
2022-01-31 13:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:59:41 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.291 | ppl 626.58 | wps 7834.3 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.29
2022-01-31 13:59:41 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-31 13:59:41 | INFO | train | epoch 052 | loss 7.471 | ppl 177.46 | wps 5859.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.52 | train_wall 328 | gb_free 6.1 | wall 18547
KL Stats: Epoch 52 Divergences: Uniform: 2.473241743594871 Unigram: 2.7419926173095432
2022-01-31 13:59:41 | INFO | fairseq.trainer | begin training epoch 53
2022-01-31 13:59:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:05:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:05:37 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.276 | ppl 620.04 | wps 7921.8 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.276
2022-01-31 14:05:37 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-31 14:05:37 | INFO | train | epoch 053 | loss 7.42 | ppl 171.21 | wps 5867.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.509 | train_wall 327 | gb_free 6.1 | wall 18903
KL Stats: Epoch 53 Divergences: Uniform: 2.4961905188418685 Unigram: 2.7590443627653363
2022-01-31 14:05:37 | INFO | fairseq.trainer | begin training epoch 54
2022-01-31 14:05:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:06:19 | INFO | train_inner | epoch 054:      8 / 64 loss=7.433, ppl=172.79, wps=5727.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.52, train_wall=512, gb_free=6.1, wall=18945
2022-01-31 14:11:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:11:35 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.33 | ppl 643.61 | wps 7847.4 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.29
2022-01-31 14:11:35 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-31 14:11:35 | INFO | train | epoch 054 | loss 7.37 | ppl 165.42 | wps 5832.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.525 | train_wall 329 | gb_free 6.1 | wall 19261
KL Stats: Epoch 54 Divergences: Uniform: 2.497436100146636 Unigram: 2.779324647748518
2022-01-31 14:11:35 | INFO | fairseq.trainer | begin training epoch 55
2022-01-31 14:11:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:15:22 | INFO | train_inner | epoch 055:     44 / 64 loss=7.342, ppl=162.23, wps=6017.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.518, train_wall=514, gb_free=6.1, wall=19488
2022-01-31 14:17:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:17:32 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.327 | ppl 642.36 | wps 7860.7 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.29
2022-01-31 14:17:32 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-31 14:17:32 | INFO | train | epoch 055 | loss 7.322 | ppl 160.05 | wps 5856.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.529 | train_wall 328 | gb_free 6.1 | wall 19617
KL Stats: Epoch 55 Divergences: Uniform: 2.512791394446619 Unigram: 2.808401310438587
2022-01-31 14:17:32 | INFO | fairseq.trainer | begin training epoch 56
2022-01-31 14:17:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:23:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:23:28 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.438 | ppl 693.63 | wps 7844.3 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.29
2022-01-31 14:23:28 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-31 14:23:28 | INFO | train | epoch 056 | loss 7.273 | ppl 154.69 | wps 5861.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.52 | train_wall 328 | gb_free 6.1 | wall 19974
KL Stats: Epoch 56 Divergences: Uniform: 2.51154919936294 Unigram: 2.825248114648947
2022-01-31 14:23:28 | INFO | fairseq.trainer | begin training epoch 57
2022-01-31 14:23:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:24:50 | INFO | train_inner | epoch 057:     16 / 64 loss=7.277, ppl=155.13, wps=5736.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.53, train_wall=511, gb_free=6.1, wall=20056
2022-01-31 14:28:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:29:24 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.416 | ppl 683.01 | wps 7751.3 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.29
2022-01-31 14:29:24 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-31 14:29:24 | INFO | train | epoch 057 | loss 7.226 | ppl 149.71 | wps 5871.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.531 | train_wall 327 | gb_free 6.1 | wall 20329
KL Stats: Epoch 57 Divergences: Uniform: 2.5433143425453415 Unigram: 2.8541784453698913
2022-01-31 14:29:24 | INFO | fairseq.trainer | begin training epoch 58
2022-01-31 14:29:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:33:51 | INFO | train_inner | epoch 058:     52 / 64 loss=7.202, ppl=147.19, wps=6043.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.527, train_wall=511, gb_free=6.1, wall=20597
2022-01-31 14:34:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:35:19 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.422 | ppl 685.83 | wps 7844.4 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.29
2022-01-31 14:35:19 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-31 14:35:19 | INFO | train | epoch 058 | loss 7.181 | ppl 145.13 | wps 5870.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.529 | train_wall 327 | gb_free 6.1 | wall 20685
KL Stats: Epoch 58 Divergences: Uniform: 2.5545396036536654 Unigram: 2.8690830763847734
2022-01-31 14:35:19 | INFO | fairseq.trainer | begin training epoch 59
2022-01-31 14:35:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:40:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:41:17 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.487 | ppl 717.77 | wps 7836.2 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.29
2022-01-31 14:41:17 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-31 14:41:17 | INFO | train | epoch 059 | loss 7.137 | ppl 140.7 | wps 5836.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.536 | train_wall 329 | gb_free 6.1 | wall 21043
KL Stats: Epoch 59 Divergences: Uniform: 2.56783731048286 Unigram: 2.8899126929068535
2022-01-31 14:41:17 | INFO | fairseq.trainer | begin training epoch 60
2022-01-31 14:41:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:43:21 | INFO | train_inner | epoch 060:     24 / 64 loss=7.13, ppl=140.11, wps=5722.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.536, train_wall=513, gb_free=6.1, wall=21167
2022-01-31 14:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:47:13 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.44 | ppl 694.49 | wps 7962.6 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.29
2022-01-31 14:47:13 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-31 14:47:13 | INFO | train | epoch 060 | loss 7.092 | ppl 136.47 | wps 5871 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.542 | train_wall 327 | gb_free 6.1 | wall 21399
KL Stats: Epoch 60 Divergences: Uniform: 2.582392889607815 Unigram: 2.9171904700626756
2022-01-31 14:47:13 | INFO | fairseq.trainer | begin training epoch 61
2022-01-31 14:47:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:52:22 | INFO | train_inner | epoch 061:     60 / 64 loss=7.073, ppl=134.67, wps=6033.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.547, train_wall=513, gb_free=6.1, wall=21708
2022-01-31 14:52:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:53:10 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.498 | ppl 722.85 | wps 7819.5 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.29
2022-01-31 14:53:10 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-31 14:53:10 | INFO | train | epoch 061 | loss 7.05 | ppl 132.51 | wps 5851.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.549 | train_wall 328 | gb_free 6.1 | wall 21756
KL Stats: Epoch 61 Divergences: Uniform: 2.6006211294791353 Unigram: 2.92704817183114
2022-01-31 14:53:10 | INFO | fairseq.trainer | begin training epoch 62
2022-01-31 14:53:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:58:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:59:07 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.468 | ppl 708.08 | wps 7851.8 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.29
2022-01-31 14:59:07 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-31 14:59:07 | INFO | train | epoch 062 | loss 7.008 | ppl 128.75 | wps 5850 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.551 | train_wall 328 | gb_free 6.1 | wall 22113
KL Stats: Epoch 62 Divergences: Uniform: 2.606305320687258 Unigram: 2.9574455860398685
2022-01-31 14:59:07 | INFO | fairseq.trainer | begin training epoch 63
2022-01-31 14:59:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:01:52 | INFO | train_inner | epoch 063:     32 / 64 loss=6.983, ppl=126.47, wps=5722.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.55, train_wall=512, gb_free=6.1, wall=22278
2022-01-31 15:04:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:05:04 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.48 | ppl 713.92 | wps 7841 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.29
2022-01-31 15:05:04 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-31 15:05:04 | INFO | train | epoch 063 | loss 6.965 | ppl 124.9 | wps 5856.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.547 | train_wall 328 | gb_free 6.1 | wall 22469
KL Stats: Epoch 63 Divergences: Uniform: 2.618785416238635 Unigram: 2.9738992967448974
2022-01-31 15:05:04 | INFO | fairseq.trainer | begin training epoch 64
2022-01-31 15:05:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:11:01 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.558 | ppl 753.82 | wps 7841.8 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.29
2022-01-31 15:11:01 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-31 15:11:01 | INFO | train | epoch 064 | loss 6.922 | ppl 121.26 | wps 5851.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.558 | train_wall 328 | gb_free 6.1 | wall 22826
KL Stats: Epoch 64 Divergences: Uniform: 2.628982474525611 Unigram: 2.992738841747211
2022-01-31 15:11:01 | INFO | fairseq.trainer | begin training epoch 65
2022-01-31 15:11:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:11:21 | INFO | train_inner | epoch 065:      4 / 64 loss=6.949, ppl=123.54, wps=5726.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.554, train_wall=512, gb_free=6.1, wall=22847
2022-01-31 15:16:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:16:57 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.565 | ppl 757.63 | wps 7859.4 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.29
2022-01-31 15:16:57 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-31 15:16:57 | INFO | train | epoch 065 | loss 6.879 | ppl 117.73 | wps 5857.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.555 | train_wall 328 | gb_free 6.1 | wall 23183
KL Stats: Epoch 65 Divergences: Uniform: 2.6387180847112095 Unigram: 3.0134925258143763
2022-01-31 15:16:57 | INFO | fairseq.trainer | begin training epoch 66
2022-01-31 15:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:20:23 | INFO | train_inner | epoch 066:     40 / 64 loss=6.855, ppl=115.79, wps=6031.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.561, train_wall=513, gb_free=6.1, wall=23389
2022-01-31 15:22:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:22:54 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.577 | ppl 763.57 | wps 7837.8 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.29
2022-01-31 15:22:54 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-31 15:22:54 | INFO | train | epoch 066 | loss 6.839 | ppl 114.52 | wps 5856.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.555 | train_wall 328 | gb_free 6.1 | wall 23540
KL Stats: Epoch 66 Divergences: Uniform: 2.651188497166606 Unigram: 3.0278592977426446
2022-01-31 15:22:54 | INFO | fairseq.trainer | begin training epoch 67
2022-01-31 15:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:28:49 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.553 | ppl 751.36 | wps 7815.3 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.29
2022-01-31 15:28:49 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-31 15:28:49 | INFO | train | epoch 067 | loss 6.798 | ppl 111.25 | wps 5882.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.554 | train_wall 326 | gb_free 6.1 | wall 23895
KL Stats: Epoch 67 Divergences: Uniform: 2.6699556343512065 Unigram: 3.0547058660614717
2022-01-31 15:28:49 | INFO | fairseq.trainer | begin training epoch 68
2022-01-31 15:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:29:51 | INFO | train_inner | epoch 068:     12 / 64 loss=6.806, ppl=111.93, wps=5744.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.551, train_wall=510, gb_free=6.1, wall=23956
2022-01-31 15:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:34:46 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.626 | ppl 789.97 | wps 7831.5 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.29
2022-01-31 15:34:46 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-31 15:34:46 | INFO | train | epoch 068 | loss 6.762 | ppl 108.5 | wps 5852.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.578 | train_wall 328 | gb_free 6.1 | wall 24252
KL Stats: Epoch 68 Divergences: Uniform: 2.6794011551594132 Unigram: 3.0733487497051186
2022-01-31 15:34:46 | INFO | fairseq.trainer | begin training epoch 69
2022-01-31 15:34:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:38:53 | INFO | train_inner | epoch 069:     48 / 64 loss=6.743, ppl=107.1, wps=6027.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.566, train_wall=513, gb_free=6.1, wall=24499
2022-01-31 15:40:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:40:43 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.635 | ppl 795.11 | wps 7760.3 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.29
2022-01-31 15:40:43 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-31 15:40:43 | INFO | train | epoch 069 | loss 6.722 | ppl 105.55 | wps 5850.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.555 | train_wall 328 | gb_free 6.1 | wall 24609
KL Stats: Epoch 69 Divergences: Uniform: 2.692300496289744 Unigram: 3.089894889250788
2022-01-31 15:40:43 | INFO | fairseq.trainer | begin training epoch 70
2022-01-31 15:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:46:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:46:40 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.703 | ppl 833.37 | wps 7649 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.29
2022-01-31 15:46:40 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-31 15:46:40 | INFO | train | epoch 070 | loss 6.687 | ppl 103.03 | wps 5850.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.559 | train_wall 328 | gb_free 6.1 | wall 24965
KL Stats: Epoch 70 Divergences: Uniform: 2.697833402813989 Unigram: 3.100456947016811
2022-01-31 15:46:40 | INFO | fairseq.trainer | begin training epoch 71
2022-01-31 15:46:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:48:23 | INFO | train_inner | epoch 071:     20 / 64 loss=6.681, ppl=102.63, wps=5715.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.563, train_wall=512, gb_free=6.1, wall=25069
2022-01-31 15:52:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:52:37 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.688 | ppl 824.87 | wps 7749.8 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.29
2022-01-31 15:52:37 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-31 15:52:37 | INFO | train | epoch 071 | loss 6.654 | ppl 100.68 | wps 5846.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.578 | train_wall 328 | gb_free 6.1 | wall 25323
KL Stats: Epoch 71 Divergences: Uniform: 2.708446192201698 Unigram: 3.123140413180172
2022-01-31 15:52:37 | INFO | fairseq.trainer | begin training epoch 72
2022-01-31 15:52:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:57:24 | INFO | train_inner | epoch 072:     56 / 64 loss=6.638, ppl=99.61, wps=6040.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.573, train_wall=511, gb_free=6.1, wall=25610
2022-01-31 15:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:58:33 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.641 | ppl 798.24 | wps 7754.1 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.29
2022-01-31 15:58:33 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-31 15:58:33 | INFO | train | epoch 072 | loss 6.618 | ppl 98.23 | wps 5872.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.57 | train_wall 327 | gb_free 6.1 | wall 25678
KL Stats: Epoch 72 Divergences: Uniform: 2.7257006899600444 Unigram: 3.1415577593031747
2022-01-31 15:58:33 | INFO | fairseq.trainer | begin training epoch 73
2022-01-31 15:58:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:04:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:04:29 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.73 | ppl 849.4 | wps 7778 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.29
2022-01-31 16:04:29 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-31 16:04:29 | INFO | train | epoch 073 | loss 6.586 | ppl 96.04 | wps 5859.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.571 | train_wall 327 | gb_free 6.1 | wall 26035
KL Stats: Epoch 73 Divergences: Uniform: 2.7247781095322745 Unigram: 3.157295048210391
2022-01-31 16:04:29 | INFO | fairseq.trainer | begin training epoch 74
2022-01-31 16:04:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:06:53 | INFO | train_inner | epoch 074:     28 / 64 loss=6.575, ppl=95.31, wps=5735.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.572, train_wall=511, gb_free=6.1, wall=26178
2022-01-31 16:09:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:10:25 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.626 | ppl 790.1 | wps 7749.4 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.29
2022-01-31 16:10:25 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-31 16:10:25 | INFO | train | epoch 074 | loss 6.554 | ppl 93.93 | wps 5871.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.586 | train_wall 327 | gb_free 6.1 | wall 26391
KL Stats: Epoch 74 Divergences: Uniform: 2.7385114359950893 Unigram: 3.184915355719623
2022-01-31 16:10:25 | INFO | fairseq.trainer | begin training epoch 75
2022-01-31 16:10:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:15:53 | INFO | train_inner | epoch 075:     64 / 64 loss=6.544, ppl=93.31, wps=6033.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.584, train_wall=511, gb_free=6.1, wall=26719
2022-01-31 16:15:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:16:22 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.766 | ppl 870.43 | wps 7654.9 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.29
2022-01-31 16:16:22 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-31 16:16:22 | INFO | train | epoch 075 | loss 6.523 | ppl 91.96 | wps 5854.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.578 | train_wall 327 | gb_free 6.1 | wall 26747
KL Stats: Epoch 75 Divergences: Uniform: 2.741120185949408 Unigram: 3.1948940729597544
2022-01-31 16:16:22 | INFO | fairseq.trainer | begin training epoch 76
2022-01-31 16:16:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:22:18 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.725 | ppl 846.13 | wps 7816.6 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.29
2022-01-31 16:22:18 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-31 16:22:18 | INFO | train | epoch 076 | loss 6.494 | ppl 90.12 | wps 5865.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.598 | train_wall 327 | gb_free 6.1 | wall 27103
KL Stats: Epoch 76 Divergences: Uniform: 2.7547274526891528 Unigram: 3.215229785341821
2022-01-31 16:22:18 | INFO | fairseq.trainer | begin training epoch 77
2022-01-31 16:22:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:25:23 | INFO | train_inner | epoch 077:     36 / 64 loss=6.468, ppl=88.54, wps=5732.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.592, train_wall=512, gb_free=6.1, wall=27289
2022-01-31 16:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:28:14 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.766 | ppl 870.59 | wps 7776.1 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.29
2022-01-31 16:28:14 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-31 16:28:14 | INFO | train | epoch 077 | loss 6.464 | ppl 88.27 | wps 5867.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.597 | train_wall 327 | gb_free 6.1 | wall 27459
KL Stats: Epoch 77 Divergences: Uniform: 2.755473268862782 Unigram: 3.2377440815124308
2022-01-31 16:28:14 | INFO | fairseq.trainer | begin training epoch 78
2022-01-31 16:28:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:33:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:34:10 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.73 | ppl 849.26 | wps 7920.8 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.29
2022-01-31 16:34:10 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-31 16:34:10 | INFO | train | epoch 078 | loss 6.437 | ppl 86.62 | wps 5859.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.601 | train_wall 328 | gb_free 6.1 | wall 27816
KL Stats: Epoch 78 Divergences: Uniform: 2.7689016539416627 Unigram: 3.249212446923897
2022-01-31 16:34:10 | INFO | fairseq.trainer | begin training epoch 79
2022-01-31 16:34:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:34:52 | INFO | train_inner | epoch 079:      8 / 64 loss=6.451, ppl=87.5, wps=5734, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.605, train_wall=511, gb_free=6.1, wall=27857
2022-01-31 16:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:40:07 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.827 | ppl 908.13 | wps 7849.1 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.29
2022-01-31 16:40:07 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-31 16:40:07 | INFO | train | epoch 079 | loss 6.405 | ppl 84.75 | wps 5848.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.588 | train_wall 328 | gb_free 6.1 | wall 28173
KL Stats: Epoch 79 Divergences: Uniform: 2.7718663429399095 Unigram: 3.2610553525788384
2022-01-31 16:40:07 | INFO | fairseq.trainer | begin training epoch 80
2022-01-31 16:40:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:43:54 | INFO | train_inner | epoch 080:     44 / 64 loss=6.389, ppl=83.81, wps=6027.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.591, train_wall=513, gb_free=6.1, wall=28400
2022-01-31 16:45:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:46:04 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.742 | ppl 856.06 | wps 7824.3 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.29
2022-01-31 16:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-31 16:46:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint80.pt
2022-01-31 16:46:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint80.pt
2022-01-31 16:46:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.742) (writing took 3.554910463280976 seconds)
2022-01-31 16:46:07 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-31 16:46:07 | INFO | train | epoch 080 | loss 6.381 | ppl 83.32 | wps 5802.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.603 | train_wall 328 | gb_free 6.1 | wall 28533
KL Stats: Epoch 80 Divergences: Uniform: 2.7778181665693977 Unigram: 3.2833505363608273
2022-01-31 16:46:07 | INFO | fairseq.trainer | begin training epoch 81
2022-01-31 16:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:52:04 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.814 | ppl 900.02 | wps 7841.7 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.29
2022-01-31 16:52:04 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-31 16:52:04 | INFO | train | epoch 081 | loss 6.355 | ppl 81.83 | wps 5859.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.615 | train_wall 328 | gb_free 6.1 | wall 28889
KL Stats: Epoch 81 Divergences: Uniform: 2.7978398000934734 Unigram: 3.299518783093557
2022-01-31 16:52:04 | INFO | fairseq.trainer | begin training epoch 82
2022-01-31 16:52:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:53:26 | INFO | train_inner | epoch 082:     16 / 64 loss=6.361, ppl=82.2, wps=5700, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.62, train_wall=511, gb_free=6.1, wall=28971
2022-01-31 16:57:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:57:59 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.772 | ppl 874.33 | wps 7855.4 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.29
2022-01-31 16:57:59 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-31 16:57:59 | INFO | train | epoch 082 | loss 6.328 | ppl 80.34 | wps 5870.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.61 | train_wall 327 | gb_free 6.1 | wall 29245
KL Stats: Epoch 82 Divergences: Uniform: 2.7992774490986303 Unigram: 3.322864494797816
2022-01-31 16:57:59 | INFO | fairseq.trainer | begin training epoch 83
2022-01-31 16:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:02:27 | INFO | train_inner | epoch 083:     52 / 64 loss=6.314, ppl=79.55, wps=6041.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.609, train_wall=512, gb_free=6.1, wall=29512
2022-01-31 17:03:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:03:55 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.693 | ppl 827.92 | wps 7933.2 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.29
2022-01-31 17:03:55 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-31 17:03:55 | INFO | train | epoch 083 | loss 6.304 | ppl 78.99 | wps 5878.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.618 | train_wall 327 | gb_free 6.1 | wall 29600
KL Stats: Epoch 83 Divergences: Uniform: 2.8133406032734958 Unigram: 3.33984726680632
2022-01-31 17:03:55 | INFO | fairseq.trainer | begin training epoch 84
2022-01-31 17:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:09:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:09:52 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.779 | ppl 878.48 | wps 7846.8 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.29
2022-01-31 17:09:52 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-31 17:09:52 | INFO | train | epoch 084 | loss 6.279 | ppl 77.63 | wps 5850.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.615 | train_wall 328 | gb_free 6.1 | wall 29958
KL Stats: Epoch 84 Divergences: Uniform: 2.8156578613819674 Unigram: 3.349408390783385
2022-01-31 17:09:52 | INFO | fairseq.trainer | begin training epoch 85
2022-01-31 17:09:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:11:56 | INFO | train_inner | epoch 085:     24 / 64 loss=6.268, ppl=77.06, wps=5730.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.615, train_wall=512, gb_free=6.1, wall=30081
2022-01-31 17:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:15:49 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.797 | ppl 889.54 | wps 7840.7 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.29
2022-01-31 17:15:49 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-31 17:15:49 | INFO | train | epoch 085 | loss 6.255 | ppl 76.35 | wps 5853 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.623 | train_wall 328 | gb_free 6.1 | wall 30314
KL Stats: Epoch 85 Divergences: Uniform: 2.8300923714889614 Unigram: 3.3609882021183126
2022-01-31 17:15:49 | INFO | fairseq.trainer | begin training epoch 86
2022-01-31 17:15:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:20:58 | INFO | train_inner | epoch 086:     60 / 64 loss=6.252, ppl=76.21, wps=6021, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.629, train_wall=514, gb_free=6.1, wall=30624
2022-01-31 17:21:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:21:46 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.815 | ppl 900.81 | wps 7836.5 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.29
2022-01-31 17:21:46 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-31 17:21:46 | INFO | train | epoch 086 | loss 6.231 | ppl 75.11 | wps 5849.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.632 | train_wall 328 | gb_free 6.1 | wall 30671
KL Stats: Epoch 86 Divergences: Uniform: 2.828308306320265 Unigram: 3.385656513217498
2022-01-31 17:21:46 | INFO | fairseq.trainer | begin training epoch 87
2022-01-31 17:21:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:27:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:27:42 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.851 | ppl 923.6 | wps 7736.1 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.29
2022-01-31 17:27:42 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-31 17:27:42 | INFO | train | epoch 087 | loss 6.209 | ppl 73.97 | wps 5859.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.651 | train_wall 327 | gb_free 6.1 | wall 31028
KL Stats: Epoch 87 Divergences: Uniform: 2.8336558541984913 Unigram: 3.393945844237983
2022-01-31 17:27:42 | INFO | fairseq.trainer | begin training epoch 88
2022-01-31 17:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:30:27 | INFO | train_inner | epoch 088:     32 / 64 loss=6.196, ppl=73.32, wps=5732.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.651, train_wall=511, gb_free=6.1, wall=31193
2022-01-31 17:33:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:33:39 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.815 | ppl 900.84 | wps 7842.7 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.29
2022-01-31 17:33:39 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-31 17:33:39 | INFO | train | epoch 088 | loss 6.186 | ppl 72.83 | wps 5853.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.648 | train_wall 328 | gb_free 6.1 | wall 31385
KL Stats: Epoch 88 Divergences: Uniform: 2.841669920757512 Unigram: 3.409556756483096
2022-01-31 17:33:39 | INFO | fairseq.trainer | begin training epoch 89
2022-01-31 17:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:39:36 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.82 | ppl 904.14 | wps 7824.2 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.29
2022-01-31 17:39:36 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-31 17:39:36 | INFO | train | epoch 089 | loss 6.168 | ppl 71.89 | wps 5851.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.661 | train_wall 328 | gb_free 6.1 | wall 31742
KL Stats: Epoch 89 Divergences: Uniform: 2.852255433916887 Unigram: 3.4218323981026466
2022-01-31 17:39:36 | INFO | fairseq.trainer | begin training epoch 90
2022-01-31 17:39:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:39:56 | INFO | train_inner | epoch 090:      4 / 64 loss=6.178, ppl=72.41, wps=5724.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.657, train_wall=512, gb_free=6.1, wall=31762
2022-01-31 17:45:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:45:32 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.893 | ppl 950.67 | wps 7936.1 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.29
2022-01-31 17:45:32 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-31 17:45:32 | INFO | train | epoch 090 | loss 6.144 | ppl 70.71 | wps 5865 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.637 | train_wall 328 | gb_free 6.1 | wall 32098
KL Stats: Epoch 90 Divergences: Uniform: 2.8513590447171446 Unigram: 3.431394040505197
2022-01-31 17:45:32 | INFO | fairseq.trainer | begin training epoch 91
2022-01-31 17:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:48:59 | INFO | train_inner | epoch 091:     40 / 64 loss=6.125, ppl=69.81, wps=6023.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.635, train_wall=514, gb_free=6.1, wall=32305
2022-01-31 17:51:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:51:29 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.885 | ppl 945.52 | wps 7834.8 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.29
2022-01-31 17:51:29 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-31 17:51:29 | INFO | train | epoch 091 | loss 6.122 | ppl 69.63 | wps 5845 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.645 | train_wall 329 | gb_free 6.1 | wall 32455
KL Stats: Epoch 91 Divergences: Uniform: 2.8609451318496184 Unigram: 3.457986270169708
2022-01-31 17:51:29 | INFO | fairseq.trainer | begin training epoch 92
2022-01-31 17:51:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:56:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:57:26 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.901 | ppl 956 | wps 7850.7 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.29
2022-01-31 17:57:26 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-31 17:57:26 | INFO | train | epoch 092 | loss 6.104 | ppl 68.77 | wps 5862.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.666 | train_wall 328 | gb_free 6.1 | wall 32811
KL Stats: Epoch 92 Divergences: Uniform: 2.865546964509086 Unigram: 3.466909888157885
2022-01-31 17:57:26 | INFO | fairseq.trainer | begin training epoch 93
2022-01-31 17:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:58:27 | INFO | train_inner | epoch 093:     12 / 64 loss=6.113, ppl=69.21, wps=5734.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.662, train_wall=511, gb_free=6.1, wall=32873
2022-01-31 18:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:03:22 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.848 | ppl 921.78 | wps 7864.5 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.29
2022-01-31 18:03:22 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-31 18:03:22 | INFO | train | epoch 093 | loss 6.086 | ppl 67.92 | wps 5867.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.664 | train_wall 327 | gb_free 6.1 | wall 33167
KL Stats: Epoch 93 Divergences: Uniform: 2.8747369600728625 Unigram: 3.4833577734282213
2022-01-31 18:03:22 | INFO | fairseq.trainer | begin training epoch 94
2022-01-31 18:03:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:07:29 | INFO | train_inner | epoch 094:     48 / 64 loss=6.071, ppl=67.24, wps=6029.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.666, train_wall=513, gb_free=6.1, wall=33415
2022-01-31 18:08:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:09:19 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.927 | ppl 973.76 | wps 7830.5 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.29
2022-01-31 18:09:19 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-31 18:09:19 | INFO | train | epoch 094 | loss 6.064 | ppl 66.9 | wps 5851.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.665 | train_wall 328 | gb_free 6.1 | wall 33524
KL Stats: Epoch 94 Divergences: Uniform: 2.877513395115581 Unigram: 3.49938328150797
2022-01-31 18:09:19 | INFO | fairseq.trainer | begin training epoch 95
2022-01-31 18:09:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:15:14 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.937 | ppl 980.42 | wps 8020.3 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.29
2022-01-31 18:15:14 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-31 18:15:14 | INFO | train | epoch 095 | loss 6.045 | ppl 66.01 | wps 5867.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.661 | train_wall 328 | gb_free 6.1 | wall 33880
KL Stats: Epoch 95 Divergences: Uniform: 2.8821069702168756 Unigram: 3.510813961333822
2022-01-31 18:15:14 | INFO | fairseq.trainer | begin training epoch 96
2022-01-31 18:15:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:16:58 | INFO | train_inner | epoch 096:     20 / 64 loss=6.044, ppl=65.97, wps=5738.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.663, train_wall=511, gb_free=6.1, wall=33983
2022-01-31 18:20:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:21:11 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.858 | ppl 927.75 | wps 7844.4 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.29
2022-01-31 18:21:11 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-31 18:21:11 | INFO | train | epoch 096 | loss 6.029 | ppl 65.28 | wps 5863.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.675 | train_wall 327 | gb_free 6.1 | wall 34236
KL Stats: Epoch 96 Divergences: Uniform: 2.89185744150977 Unigram: 3.5185268952801025
2022-01-31 18:21:11 | INFO | fairseq.trainer | begin training epoch 97
2022-01-31 18:21:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:26:00 | INFO | train_inner | epoch 097:     56 / 64 loss=6.023, ppl=65.03, wps=6019.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.686, train_wall=514, gb_free=6.1, wall=34526
2022-01-31 18:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:27:08 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.934 | ppl 977.99 | wps 7816.6 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.29
2022-01-31 18:27:08 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-31 18:27:08 | INFO | train | epoch 097 | loss 6.012 | ppl 64.52 | wps 5838.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.688 | train_wall 329 | gb_free 6.1 | wall 34594
KL Stats: Epoch 97 Divergences: Uniform: 2.9008521560663865 Unigram: 3.5440895684390825
2022-01-31 18:27:08 | INFO | fairseq.trainer | begin training epoch 98
2022-01-31 18:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:32:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:33:05 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.922 | ppl 969.96 | wps 7828.4 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.29
2022-01-31 18:33:05 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-31 18:33:05 | INFO | train | epoch 098 | loss 5.991 | ppl 63.61 | wps 5862.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.694 | train_wall 327 | gb_free 6.1 | wall 34950
KL Stats: Epoch 98 Divergences: Uniform: 2.898821637305587 Unigram: 3.5435061844200546
2022-01-31 18:33:05 | INFO | fairseq.trainer | begin training epoch 99
2022-01-31 18:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:35:29 | INFO | train_inner | epoch 099:     28 / 64 loss=5.982, ppl=63.22, wps=5737.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.693, train_wall=511, gb_free=6.1, wall=35094
2022-01-31 18:38:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:39:01 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.938 | ppl 980.89 | wps 7830.6 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.29
2022-01-31 18:39:01 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-31 18:39:01 | INFO | train | epoch 099 | loss 5.974 | ppl 62.84 | wps 5866.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.695 | train_wall 327 | gb_free 6.1 | wall 35306
KL Stats: Epoch 99 Divergences: Uniform: 2.9051198747705156 Unigram: 3.5648624337201005
2022-01-31 18:39:01 | INFO | fairseq.trainer | begin training epoch 100
2022-01-31 18:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:44:29 | INFO | train_inner | epoch 100:     64 / 64 loss=5.977, ppl=62.99, wps=6031, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.705, train_wall=511, gb_free=6.1, wall=35635
2022-01-31 18:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:44:57 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.881 | ppl 942.76 | wps 7882.1 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.29
2022-01-31 18:44:57 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-31 18:44:57 | INFO | train | epoch 100 | loss 5.96 | ppl 62.25 | wps 5862.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.711 | train_wall 328 | gb_free 6.1 | wall 35663
KL Stats: Epoch 100 Divergences: Uniform: 2.9088823478908683 Unigram: 3.573776732324972
2022-01-31 18:44:57 | INFO | fairseq.trainer | begin training epoch 101
2022-01-31 18:44:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:50:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:50:54 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.939 | ppl 981.4 | wps 7850.2 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.29
2022-01-31 18:50:54 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-31 18:50:54 | INFO | train | epoch 101 | loss 5.939 | ppl 61.35 | wps 5852.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.708 | train_wall 328 | gb_free 6.1 | wall 36019
KL Stats: Epoch 101 Divergences: Uniform: 2.918221504488258 Unigram: 3.5912306227262847
2022-01-31 18:50:54 | INFO | fairseq.trainer | begin training epoch 102
2022-01-31 18:50:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:54:00 | INFO | train_inner | epoch 102:     36 / 64 loss=5.926, ppl=60.78, wps=5728.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.717, train_wall=513, gb_free=6.1, wall=36205
2022-01-31 18:56:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:56:51 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.944 | ppl 985.34 | wps 7836.2 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.29
2022-01-31 18:56:51 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-31 18:56:51 | INFO | train | epoch 102 | loss 5.926 | ppl 60.79 | wps 5853.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.725 | train_wall 328 | gb_free 6.1 | wall 36376
KL Stats: Epoch 102 Divergences: Uniform: 2.9149174840514838 Unigram: 3.5996971195981176
2022-01-31 18:56:51 | INFO | fairseq.trainer | begin training epoch 103
2022-01-31 18:56:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:02:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:02:47 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.942 | ppl 983.48 | wps 7831.2 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.29
2022-01-31 19:02:47 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-31 19:02:47 | INFO | train | epoch 103 | loss 5.908 | ppl 60.05 | wps 5867.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.712 | train_wall 327 | gb_free 6.1 | wall 36732
KL Stats: Epoch 103 Divergences: Uniform: 2.929068771193835 Unigram: 3.6135491361842385
2022-01-31 19:02:47 | INFO | fairseq.trainer | begin training epoch 104
2022-01-31 19:02:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:03:28 | INFO | train_inner | epoch 104:      8 / 64 loss=5.915, ppl=60.35, wps=5740.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.716, train_wall=511, gb_free=6.1, wall=36773
2022-01-31 19:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:08:43 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.97 | ppl 1002.85 | wps 7845.3 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.29
2022-01-31 19:08:43 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-31 19:08:43 | INFO | train | epoch 104 | loss 5.895 | ppl 59.49 | wps 5854.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.723 | train_wall 328 | gb_free 6.1 | wall 37089
KL Stats: Epoch 104 Divergences: Uniform: 2.921846406913788 Unigram: 3.628791090228322
2022-01-31 19:08:43 | INFO | fairseq.trainer | begin training epoch 105
2022-01-31 19:08:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:12:31 | INFO | train_inner | epoch 105:     44 / 64 loss=5.882, ppl=58.97, wps=6014.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.724, train_wall=514, gb_free=6.1, wall=37317
2022-01-31 19:14:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:14:41 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.926 | ppl 972.58 | wps 7752.3 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.29
2022-01-31 19:14:41 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-31 19:14:41 | INFO | train | epoch 105 | loss 5.877 | ppl 58.79 | wps 5840.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.727 | train_wall 329 | gb_free 6.1 | wall 37447
KL Stats: Epoch 105 Divergences: Uniform: 2.927999191902184 Unigram: 3.6371713334382823
2022-01-31 19:14:41 | INFO | fairseq.trainer | begin training epoch 106
2022-01-31 19:14:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:20:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:20:37 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.952 | ppl 990.24 | wps 7837.3 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.29
2022-01-31 19:20:37 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-31 19:20:37 | INFO | train | epoch 106 | loss 5.861 | ppl 58.14 | wps 5860.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.717 | train_wall 328 | gb_free 6.1 | wall 37803
KL Stats: Epoch 106 Divergences: Uniform: 2.933958317510721 Unigram: 3.641976673868673
2022-01-31 19:20:37 | INFO | fairseq.trainer | begin training epoch 107
2022-01-31 19:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:22:00 | INFO | train_inner | epoch 107:     16 / 64 loss=5.865, ppl=58.27, wps=5732.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.721, train_wall=511, gb_free=6.1, wall=37885
2022-01-31 19:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:26:34 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.959 | ppl 995.17 | wps 7815.9 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.29
2022-01-31 19:26:34 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-31 19:26:34 | INFO | train | epoch 107 | loss 5.846 | ppl 57.53 | wps 5859.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.722 | train_wall 328 | gb_free 6.1 | wall 38159
KL Stats: Epoch 107 Divergences: Uniform: 2.944170568341739 Unigram: 3.662934894409383
2022-01-31 19:26:34 | INFO | fairseq.trainer | begin training epoch 108
2022-01-31 19:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:31:01 | INFO | train_inner | epoch 108:     52 / 64 loss=5.842, ppl=57.35, wps=6033, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.726, train_wall=512, gb_free=6.1, wall=38427
2022-01-31 19:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:32:29 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.941 | ppl 983.21 | wps 7919.9 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.29
2022-01-31 19:32:29 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-31 19:32:29 | INFO | train | epoch 108 | loss 5.835 | ppl 57.09 | wps 5870.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.736 | train_wall 327 | gb_free 6.1 | wall 38515
KL Stats: Epoch 108 Divergences: Uniform: 2.9456544628261834 Unigram: 3.6713233821613227
2022-01-31 19:32:29 | INFO | fairseq.trainer | begin training epoch 109
2022-01-31 19:32:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:38:25 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.963 | ppl 998.24 | wps 7856.2 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.29
2022-01-31 19:38:25 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-31 19:38:25 | INFO | train | epoch 109 | loss 5.819 | ppl 56.47 | wps 5866.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.742 | train_wall 327 | gb_free 6.1 | wall 38871
KL Stats: Epoch 109 Divergences: Uniform: 2.9469948557816874 Unigram: 3.686066909625802
2022-01-31 19:38:25 | INFO | fairseq.trainer | begin training epoch 110
2022-01-31 19:38:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:40:29 | INFO | train_inner | epoch 110:     24 / 64 loss=5.813, ppl=56.23, wps=5738.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.747, train_wall=511, gb_free=6.1, wall=38995
2022-01-31 19:43:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:44:23 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.052 | ppl 1061.29 | wps 7814.9 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.29
2022-01-31 19:44:23 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-31 19:44:23 | INFO | train | epoch 110 | loss 5.806 | ppl 55.95 | wps 5847.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.748 | train_wall 328 | gb_free 6.1 | wall 39228
KL Stats: Epoch 110 Divergences: Uniform: 2.9529942547645347 Unigram: 3.688917320143949
2022-01-31 19:44:23 | INFO | fairseq.trainer | begin training epoch 111
2022-01-31 19:44:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:49:31 | INFO | train_inner | epoch 111:     60 / 64 loss=5.805, ppl=55.92, wps=6028.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.758, train_wall=513, gb_free=6.1, wall=39537
2022-01-31 19:49:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:50:19 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.997 | ppl 1021.8 | wps 7836.3 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.29
2022-01-31 19:50:19 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-31 19:50:19 | INFO | train | epoch 111 | loss 5.793 | ppl 55.43 | wps 5869.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.77 | train_wall 327 | gb_free 6.1 | wall 39584
KL Stats: Epoch 111 Divergences: Uniform: 2.958232169144957 Unigram: 3.712586618136471
2022-01-31 19:50:19 | INFO | fairseq.trainer | begin training epoch 112
2022-01-31 19:50:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:55:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:56:15 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.038 | ppl 1051.03 | wps 7849.1 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.29
2022-01-31 19:56:15 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-31 19:56:15 | INFO | train | epoch 112 | loss 5.778 | ppl 54.86 | wps 5858.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.748 | train_wall 328 | gb_free 6.1 | wall 39941
KL Stats: Epoch 112 Divergences: Uniform: 2.956651482749292 Unigram: 3.7232129993938203
2022-01-31 19:56:15 | INFO | fairseq.trainer | begin training epoch 113
2022-01-31 19:56:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:59:00 | INFO | train_inner | epoch 113:     32 / 64 loss=5.766, ppl=54.41, wps=5732.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.75, train_wall=512, gb_free=6.1, wall=40106
2022-01-31 20:01:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:02:11 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.065 | ppl 1071.18 | wps 8031.4 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.29
2022-01-31 20:02:11 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-31 20:02:11 | INFO | train | epoch 113 | loss 5.763 | ppl 54.3 | wps 5862.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.76 | train_wall 328 | gb_free 6.1 | wall 40297
KL Stats: Epoch 113 Divergences: Uniform: 2.970154316013673 Unigram: 3.7323132333785125
2022-01-31 20:02:11 | INFO | fairseq.trainer | begin training epoch 114
2022-01-31 20:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:08:08 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.032 | ppl 1046.72 | wps 7819.2 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.29
2022-01-31 20:08:08 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-31 20:08:08 | INFO | train | epoch 114 | loss 5.75 | ppl 53.83 | wps 5854.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.772 | train_wall 328 | gb_free 6.1 | wall 40654
KL Stats: Epoch 114 Divergences: Uniform: 2.9633227946014338 Unigram: 3.7364174323879875
2022-01-31 20:08:08 | INFO | fairseq.trainer | begin training epoch 115
2022-01-31 20:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:08:29 | INFO | train_inner | epoch 115:      4 / 64 loss=5.763, ppl=54.3, wps=5734.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.772, train_wall=512, gb_free=6.1, wall=40674
2022-01-31 20:13:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:14:04 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.052 | ppl 1061.8 | wps 7821.7 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.29
2022-01-31 20:14:04 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-31 20:14:04 | INFO | train | epoch 115 | loss 5.738 | ppl 53.38 | wps 5862.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.781 | train_wall 327 | gb_free 6.1 | wall 41010
KL Stats: Epoch 115 Divergences: Uniform: 2.9710936173829725 Unigram: 3.7451520825405944
2022-01-31 20:14:04 | INFO | fairseq.trainer | begin training epoch 116
2022-01-31 20:14:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:17:32 | INFO | train_inner | epoch 116:     40 / 64 loss=5.724, ppl=52.87, wps=6018.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.776, train_wall=514, gb_free=6.1, wall=41217
2022-01-31 20:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:20:03 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.013 | ppl 1033.54 | wps 7827.4 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.29
2022-01-31 20:20:03 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-31 20:20:03 | INFO | train | epoch 116 | loss 5.725 | ppl 52.89 | wps 5826.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.774 | train_wall 330 | gb_free 6.1 | wall 41369
KL Stats: Epoch 116 Divergences: Uniform: 2.9725005049944664 Unigram: 3.7522981510763427
2022-01-31 20:20:03 | INFO | fairseq.trainer | begin training epoch 117
2022-01-31 20:20:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:25:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:26:00 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.074 | ppl 1077.9 | wps 7725.2 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.29
2022-01-31 20:26:00 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-31 20:26:00 | INFO | train | epoch 117 | loss 5.715 | ppl 52.53 | wps 5852.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.789 | train_wall 328 | gb_free 6.1 | wall 41725
KL Stats: Epoch 117 Divergences: Uniform: 2.9722236854681903 Unigram: 3.771100226900496
2022-01-31 20:26:00 | INFO | fairseq.trainer | begin training epoch 118
2022-01-31 20:26:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:27:02 | INFO | train_inner | epoch 118:     12 / 64 loss=5.72, ppl=52.71, wps=5719.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.792, train_wall=512, gb_free=6.1, wall=41787
2022-01-31 20:31:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:31:57 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.103 | ppl 1099.98 | wps 7831.7 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.29
2022-01-31 20:31:57 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-31 20:31:57 | INFO | train | epoch 118 | loss 5.702 | ppl 52.07 | wps 5843.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.8 | train_wall 329 | gb_free 6.1 | wall 42083
KL Stats: Epoch 118 Divergences: Uniform: 2.984010811334602 Unigram: 3.7770286188409217
2022-01-31 20:31:57 | INFO | fairseq.trainer | begin training epoch 119
2022-01-31 20:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:36:04 | INFO | train_inner | epoch 119:     48 / 64 loss=5.691, ppl=51.68, wps=6023.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.795, train_wall=513, gb_free=6.1, wall=42330
2022-01-31 20:37:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:37:53 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.057 | ppl 1065.31 | wps 7830.6 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.29
2022-01-31 20:37:53 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-31 20:37:53 | INFO | train | epoch 119 | loss 5.688 | ppl 51.56 | wps 5867.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.802 | train_wall 327 | gb_free 6.1 | wall 42439
KL Stats: Epoch 119 Divergences: Uniform: 2.9861449888426623 Unigram: 3.7924699652105027
2022-01-31 20:37:53 | INFO | fairseq.trainer | begin training epoch 120
2022-01-31 20:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:43:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:43:50 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.094 | ppl 1093.28 | wps 7924.7 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.29
2022-01-31 20:43:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-31 20:43:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint120.pt
2022-01-31 20:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint120.pt
2022-01-31 20:43:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.094) (writing took 3.3954974729567766 seconds)
2022-01-31 20:43:53 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-31 20:43:53 | INFO | train | epoch 120 | loss 5.678 | ppl 51.2 | wps 5801.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.794 | train_wall 328 | gb_free 6.1 | wall 42799
KL Stats: Epoch 120 Divergences: Uniform: 2.989256713001981 Unigram: 3.7992169731096115
2022-01-31 20:43:53 | INFO | fairseq.trainer | begin training epoch 121
2022-01-31 20:43:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:45:36 | INFO | train_inner | epoch 121:     20 / 64 loss=5.679, ppl=51.23, wps=5699.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.8, train_wall=512, gb_free=6.1, wall=42902
2022-01-31 20:49:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:49:50 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.088 | ppl 1088.68 | wps 7824.6 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.29
2022-01-31 20:49:50 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-31 20:49:50 | INFO | train | epoch 121 | loss 5.667 | ppl 50.8 | wps 5849.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.802 | train_wall 328 | gb_free 6.1 | wall 43156
KL Stats: Epoch 121 Divergences: Uniform: 2.9903880911724228 Unigram: 3.807805982421252
2022-01-31 20:49:50 | INFO | fairseq.trainer | begin training epoch 122
2022-01-31 20:49:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:54:39 | INFO | train_inner | epoch 122:     56 / 64 loss=5.665, ppl=50.73, wps=6017.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.812, train_wall=514, gb_free=6.1, wall=43445
2022-01-31 20:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:55:47 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.039 | ppl 1052.15 | wps 7807.2 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.29
2022-01-31 20:55:47 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-31 20:55:47 | INFO | train | epoch 122 | loss 5.657 | ppl 50.44 | wps 5852.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.822 | train_wall 328 | gb_free 6.1 | wall 43513
KL Stats: Epoch 122 Divergences: Uniform: 2.996788647457382 Unigram: 3.8190911733675574
2022-01-31 20:55:47 | INFO | fairseq.trainer | begin training epoch 123
2022-01-31 20:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:01:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:01:44 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.127 | ppl 1118.49 | wps 7816.7 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.29
2022-01-31 21:01:44 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-31 21:01:44 | INFO | train | epoch 123 | loss 5.643 | ppl 49.99 | wps 5849.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.804 | train_wall 328 | gb_free 6.1 | wall 43870
KL Stats: Epoch 123 Divergences: Uniform: 2.996793557737226 Unigram: 3.8350295237419716
2022-01-31 21:01:44 | INFO | fairseq.trainer | begin training epoch 124
2022-01-31 21:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:04:08 | INFO | train_inner | epoch 124:     28 / 64 loss=5.637, ppl=49.76, wps=5728.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.806, train_wall=512, gb_free=6.1, wall=44014
2022-01-31 21:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:07:41 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.057 | ppl 1065.51 | wps 7834.7 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.29
2022-01-31 21:07:41 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-31 21:07:41 | INFO | train | epoch 124 | loss 5.634 | ppl 49.66 | wps 5856.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.828 | train_wall 328 | gb_free 6.1 | wall 44226
KL Stats: Epoch 124 Divergences: Uniform: 2.9909709621629235 Unigram: 3.8277534898841745
2022-01-31 21:07:41 | INFO | fairseq.trainer | begin training epoch 125
2022-01-31 21:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:13:09 | INFO | train_inner | epoch 125:     64 / 64 loss=5.637, ppl=49.76, wps=6028.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.833, train_wall=511, gb_free=6.1, wall=44555
2022-01-31 21:13:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:13:36 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.106 | ppl 1102.37 | wps 7970.6 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.29
2022-01-31 21:13:36 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-31 21:13:36 | INFO | train | epoch 125 | loss 5.622 | ppl 49.26 | wps 5869.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.827 | train_wall 328 | gb_free 6.1 | wall 44582
KL Stats: Epoch 125 Divergences: Uniform: 2.998012022288492 Unigram: 3.8434956307629187
2022-01-31 21:13:37 | INFO | fairseq.trainer | begin training epoch 126
2022-01-31 21:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:19:34 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.118 | ppl 1111.02 | wps 7831.6 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.29
2022-01-31 21:19:34 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-31 21:19:34 | INFO | train | epoch 126 | loss 5.611 | ppl 48.88 | wps 5847.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.814 | train_wall 328 | gb_free 6.1 | wall 44939
KL Stats: Epoch 126 Divergences: Uniform: 3.0052412037737253 Unigram: 3.854848321786839
2022-01-31 21:19:34 | INFO | fairseq.trainer | begin training epoch 127
2022-01-31 21:19:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:22:39 | INFO | train_inner | epoch 127:     36 / 64 loss=5.599, ppl=48.49, wps=5734.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.832, train_wall=513, gb_free=6.1, wall=45125
2022-01-31 21:25:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:25:29 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.102 | ppl 1098.67 | wps 7839.3 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.29
2022-01-31 21:25:29 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-31 21:25:29 | INFO | train | epoch 127 | loss 5.602 | ppl 48.57 | wps 5872.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.842 | train_wall 327 | gb_free 6.1 | wall 45295
KL Stats: Epoch 127 Divergences: Uniform: 3.0059959567815424 Unigram: 3.861290193059103
2022-01-31 21:25:29 | INFO | fairseq.trainer | begin training epoch 128
2022-01-31 21:25:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:31:26 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.125 | ppl 1116.66 | wps 7839.7 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.29
2022-01-31 21:31:26 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-31 21:31:26 | INFO | train | epoch 128 | loss 5.591 | ppl 48.2 | wps 5850.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.844 | train_wall 328 | gb_free 6.1 | wall 45652
KL Stats: Epoch 128 Divergences: Uniform: 3.0055516493145857 Unigram: 3.8689075788285434
2022-01-31 21:31:26 | INFO | fairseq.trainer | begin training epoch 129
2022-01-31 21:31:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:32:08 | INFO | train_inner | epoch 129:      8 / 64 loss=5.598, ppl=48.45, wps=5733.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.838, train_wall=511, gb_free=6.1, wall=45693
2022-01-31 21:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:37:24 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.124 | ppl 1115.58 | wps 7839.3 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.29
2022-01-31 21:37:24 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-31 21:37:24 | INFO | train | epoch 129 | loss 5.584 | ppl 47.98 | wps 5845.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.854 | train_wall 329 | gb_free 6.1 | wall 46009
KL Stats: Epoch 129 Divergences: Uniform: 3.002639358222511 Unigram: 3.877890855219435
2022-01-31 21:37:24 | INFO | fairseq.trainer | begin training epoch 130
2022-01-31 21:37:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:41:11 | INFO | train_inner | epoch 130:     44 / 64 loss=5.571, ppl=47.55, wps=6014.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.845, train_wall=514, gb_free=6.1, wall=46237
2022-01-31 21:42:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:43:20 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.128 | ppl 1118.85 | wps 7786.1 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.29
2022-01-31 21:43:20 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-31 21:43:20 | INFO | train | epoch 130 | loss 5.571 | ppl 47.53 | wps 5858.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.841 | train_wall 328 | gb_free 6.1 | wall 46366
KL Stats: Epoch 130 Divergences: Uniform: 3.008637856865691 Unigram: 3.888506879184281
2022-01-31 21:43:20 | INFO | fairseq.trainer | begin training epoch 131
2022-01-31 21:43:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:49:16 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.099 | ppl 1096.83 | wps 7816.5 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.29
2022-01-31 21:49:16 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-31 21:49:16 | INFO | train | epoch 131 | loss 5.563 | ppl 47.27 | wps 5864 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.86 | train_wall 327 | gb_free 6.1 | wall 46722
KL Stats: Epoch 131 Divergences: Uniform: 3.014075638398138 Unigram: 3.892896715503664
2022-01-31 21:49:16 | INFO | fairseq.trainer | begin training epoch 132
2022-01-31 21:49:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:50:39 | INFO | train_inner | epoch 132:     16 / 64 loss=5.566, ppl=47.37, wps=5740.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.859, train_wall=510, gb_free=6.1, wall=46805
2022-01-31 21:54:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:55:13 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.128 | ppl 1119.28 | wps 7831.2 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.29
2022-01-31 21:55:13 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-31 21:55:13 | INFO | train | epoch 132 | loss 5.553 | ppl 46.96 | wps 5862.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.872 | train_wall 327 | gb_free 6.1 | wall 47078
KL Stats: Epoch 132 Divergences: Uniform: 3.01276792201581 Unigram: 3.9087337620037164
2022-01-31 21:55:13 | INFO | fairseq.trainer | begin training epoch 133
2022-01-31 21:55:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:59:40 | INFO | train_inner | epoch 133:     52 / 64 loss=5.547, ppl=46.77, wps=6033.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.872, train_wall=512, gb_free=6.1, wall=47346
2022-01-31 22:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:01:09 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.095 | ppl 1093.75 | wps 7813.3 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.29
2022-01-31 22:01:09 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-31 22:01:09 | INFO | train | epoch 133 | loss 5.542 | ppl 46.6 | wps 5860.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.871 | train_wall 328 | gb_free 6.1 | wall 47435
KL Stats: Epoch 133 Divergences: Uniform: 3.0247023631560235 Unigram: 3.9125850140334126
2022-01-31 22:01:09 | INFO | fairseq.trainer | begin training epoch 134
2022-01-31 22:01:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:07:05 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.213 | ppl 1187.23 | wps 7823.9 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.29
2022-01-31 22:07:05 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-31 22:07:05 | INFO | train | epoch 134 | loss 5.534 | ppl 46.35 | wps 5858.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.901 | train_wall 328 | gb_free 6.1 | wall 47791
KL Stats: Epoch 134 Divergences: Uniform: 3.015347536859965 Unigram: 3.918390897978585
2022-01-31 22:07:06 | INFO | fairseq.trainer | begin training epoch 135
2022-01-31 22:07:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:09:09 | INFO | train_inner | epoch 135:     24 / 64 loss=5.533, ppl=46.3, wps=5736.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.892, train_wall=511, gb_free=6.1, wall=47914
2022-01-31 22:12:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:13:02 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.154 | ppl 1138.99 | wps 7729.9 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.29
2022-01-31 22:13:02 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-31 22:13:02 | INFO | train | epoch 135 | loss 5.524 | ppl 46.03 | wps 5865.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.879 | train_wall 327 | gb_free 6.1 | wall 48147
KL Stats: Epoch 135 Divergences: Uniform: 3.021054618791427 Unigram: 3.929158523143052
2022-01-31 22:13:02 | INFO | fairseq.trainer | begin training epoch 136
2022-01-31 22:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:18:11 | INFO | train_inner | epoch 136:     60 / 64 loss=5.525, ppl=46.05, wps=6023.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.886, train_wall=513, gb_free=6.1, wall=48457
2022-01-31 22:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:18:58 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.168 | ppl 1150.12 | wps 7830 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.29
2022-01-31 22:18:58 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-31 22:18:58 | INFO | train | epoch 136 | loss 5.516 | ppl 45.75 | wps 5854.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.889 | train_wall 328 | gb_free 6.1 | wall 48504
KL Stats: Epoch 136 Divergences: Uniform: 3.0212329563118856 Unigram: 3.933462528562313
2022-01-31 22:18:58 | INFO | fairseq.trainer | begin training epoch 137
2022-01-31 22:18:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:24:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:24:55 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.222 | ppl 1194.61 | wps 7848.6 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.29
2022-01-31 22:24:55 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-31 22:24:55 | INFO | train | epoch 137 | loss 5.509 | ppl 45.53 | wps 5849 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.921 | train_wall 328 | gb_free 6.1 | wall 48861
KL Stats: Epoch 137 Divergences: Uniform: 3.023289416453281 Unigram: 3.944449442310223
2022-01-31 22:24:55 | INFO | fairseq.trainer | begin training epoch 138
2022-01-31 22:24:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:27:40 | INFO | train_inner | epoch 138:     32 / 64 loss=5.499, ppl=45.23, wps=5730.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.903, train_wall=512, gb_free=6.1, wall=49026
2022-01-31 22:30:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:30:51 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.237 | ppl 1206.99 | wps 8022.4 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.29
2022-01-31 22:30:51 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-31 22:30:51 | INFO | train | epoch 138 | loss 5.497 | ppl 45.16 | wps 5873.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.891 | train_wall 327 | gb_free 6.1 | wall 49217
KL Stats: Epoch 138 Divergences: Uniform: 3.025632021112861 Unigram: 3.946643257903037
2022-01-31 22:30:51 | INFO | fairseq.trainer | begin training epoch 139
2022-01-31 22:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:36:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:36:48 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.211 | ppl 1185.54 | wps 7839.1 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.29
2022-01-31 22:36:48 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-31 22:36:48 | INFO | train | epoch 139 | loss 5.488 | ppl 44.88 | wps 5854.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.923 | train_wall 328 | gb_free 6.1 | wall 49573
KL Stats: Epoch 139 Divergences: Uniform: 3.028012962908518 Unigram: 3.9649852330664555
2022-01-31 22:36:48 | INFO | fairseq.trainer | begin training epoch 140
2022-01-31 22:36:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:37:09 | INFO | train_inner | epoch 140:      4 / 64 loss=5.496, ppl=45.12, wps=5735.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.921, train_wall=512, gb_free=6.1, wall=49594
2022-01-31 22:42:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:42:44 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.195 | ppl 1171.92 | wps 7835.9 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.29
2022-01-31 22:42:44 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-31 22:42:44 | INFO | train | epoch 140 | loss 5.48 | ppl 44.64 | wps 5860.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.922 | train_wall 328 | gb_free 6.1 | wall 49930
KL Stats: Epoch 140 Divergences: Uniform: 3.027051586497375 Unigram: 3.9706657729675863
2022-01-31 22:42:44 | INFO | fairseq.trainer | begin training epoch 141
2022-01-31 22:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:46:10 | INFO | train_inner | epoch 141:     40 / 64 loss=5.472, ppl=44.39, wps=6032.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.924, train_wall=512, gb_free=6.1, wall=50136
2022-01-31 22:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:48:40 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.251 | ppl 1218.6 | wps 7839.7 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.29
2022-01-31 22:48:40 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-31 22:48:40 | INFO | train | epoch 141 | loss 5.472 | ppl 44.39 | wps 5866.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.916 | train_wall 327 | gb_free 6.1 | wall 50286
KL Stats: Epoch 141 Divergences: Uniform: 3.033565383459058 Unigram: 3.9799895220949977
2022-01-31 22:48:40 | INFO | fairseq.trainer | begin training epoch 142
2022-01-31 22:48:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:54:37 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.203 | ppl 1178.51 | wps 7838.1 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.29
2022-01-31 22:54:37 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-31 22:54:37 | INFO | train | epoch 142 | loss 5.464 | ppl 44.14 | wps 5857 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.946 | train_wall 328 | gb_free 6.1 | wall 50642
KL Stats: Epoch 142 Divergences: Uniform: 3.0330811368059276 Unigram: 3.978078231566015
2022-01-31 22:54:37 | INFO | fairseq.trainer | begin training epoch 143
2022-01-31 22:54:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:55:39 | INFO | train_inner | epoch 143:     12 / 64 loss=5.465, ppl=44.17, wps=5731.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.931, train_wall=512, gb_free=6.1, wall=50705
2022-01-31 23:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:00:33 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.191 | ppl 1168.61 | wps 7903.1 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.29
2022-01-31 23:00:33 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-31 23:00:33 | INFO | train | epoch 143 | loss 5.455 | ppl 43.86 | wps 5859.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.918 | train_wall 328 | gb_free 6.1 | wall 50999
KL Stats: Epoch 143 Divergences: Uniform: 3.04291486221581 Unigram: 3.9888203822397097
2022-01-31 23:00:33 | INFO | fairseq.trainer | begin training epoch 144
2022-01-31 23:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:04:41 | INFO | train_inner | epoch 144:     48 / 64 loss=5.452, ppl=43.79, wps=6032.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.915, train_wall=513, gb_free=6.1, wall=51246
2022-01-31 23:06:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:06:30 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.278 | ppl 1241.81 | wps 7850.4 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.29
2022-01-31 23:06:30 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-31 23:06:30 | INFO | train | epoch 144 | loss 5.45 | ppl 43.7 | wps 5854.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.917 | train_wall 328 | gb_free 6.1 | wall 51356
KL Stats: Epoch 144 Divergences: Uniform: 3.0339599184814263 Unigram: 3.990451990949594
2022-01-31 23:06:30 | INFO | fairseq.trainer | begin training epoch 145
2022-01-31 23:06:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:11:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:12:26 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.215 | ppl 1188.73 | wps 7815.6 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.29
2022-01-31 23:12:26 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-31 23:12:26 | INFO | train | epoch 145 | loss 5.442 | ppl 43.48 | wps 5860.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.945 | train_wall 328 | gb_free 6.1 | wall 51712
KL Stats: Epoch 145 Divergences: Uniform: 3.042607400558072 Unigram: 4.001060286258201
2022-01-31 23:12:26 | INFO | fairseq.trainer | begin training epoch 146
2022-01-31 23:12:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:14:10 | INFO | train_inner | epoch 146:     20 / 64 loss=5.438, ppl=43.36, wps=5728.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.947, train_wall=512, gb_free=6.1, wall=51816
2022-01-31 23:17:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:18:23 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.231 | ppl 1201.56 | wps 7838.1 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.29
2022-01-31 23:18:23 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-31 23:18:23 | INFO | train | epoch 146 | loss 5.431 | ppl 43.16 | wps 5856.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.961 | train_wall 328 | gb_free 6.1 | wall 52069
KL Stats: Epoch 146 Divergences: Uniform: 3.03956439491912 Unigram: 4.0042693935602545
2022-01-31 23:18:23 | INFO | fairseq.trainer | begin training epoch 147
2022-01-31 23:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:23:11 | INFO | train_inner | epoch 147:     56 / 64 loss=5.433, ppl=43.21, wps=6034.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.969, train_wall=512, gb_free=6.1, wall=52357
2022-01-31 23:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:24:20 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.183 | ppl 1162.53 | wps 7763.4 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.29
2022-01-31 23:24:20 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-31 23:24:20 | INFO | train | epoch 147 | loss 5.424 | ppl 42.94 | wps 5851 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.98 | train_wall 328 | gb_free 6.1 | wall 52426
KL Stats: Epoch 147 Divergences: Uniform: 3.045200730132041 Unigram: 4.01579120177139
2022-01-31 23:24:20 | INFO | fairseq.trainer | begin training epoch 148
2022-01-31 23:24:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:29:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:30:17 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.208 | ppl 1182.65 | wps 7838 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.29
2022-01-31 23:30:17 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-31 23:30:17 | INFO | train | epoch 148 | loss 5.417 | ppl 42.71 | wps 5851.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.953 | train_wall 328 | gb_free 6.1 | wall 52783
KL Stats: Epoch 148 Divergences: Uniform: 3.0429937698763845 Unigram: 4.0224635293099595
2022-01-31 23:30:17 | INFO | fairseq.trainer | begin training epoch 149
2022-01-31 23:30:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:32:42 | INFO | train_inner | epoch 149:     28 / 64 loss=5.412, ppl=42.59, wps=5711, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.957, train_wall=513, gb_free=6.1, wall=52928
2022-01-31 23:35:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:36:15 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.287 | ppl 1249.06 | wps 7848.3 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.29
2022-01-31 23:36:15 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-31 23:36:15 | INFO | train | epoch 149 | loss 5.411 | ppl 42.55 | wps 5833.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.965 | train_wall 329 | gb_free 6.1 | wall 53141
KL Stats: Epoch 149 Divergences: Uniform: 3.0491225005148572 Unigram: 4.029804365612695
2022-01-31 23:36:15 | INFO | fairseq.trainer | begin training epoch 150
2022-01-31 23:36:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:41:44 | INFO | train_inner | epoch 150:     64 / 64 loss=5.413, ppl=42.61, wps=6013.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.972, train_wall=513, gb_free=6.1, wall=53470
2022-01-31 23:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:42:12 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.286 | ppl 1248.38 | wps 8020.7 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.29
2022-01-31 23:42:12 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-31 23:42:12 | INFO | train | epoch 150 | loss 5.402 | ppl 42.29 | wps 5856.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.97 | train_wall 328 | gb_free 6.1 | wall 53497
KL Stats: Epoch 150 Divergences: Uniform: 3.047466270880227 Unigram: 4.0299796912070125
2022-01-31 23:42:12 | INFO | fairseq.trainer | begin training epoch 151
2022-01-31 23:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:47:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:48:10 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.223 | ppl 1195.37 | wps 7856.3 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.29
2022-01-31 23:48:10 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-31 23:48:10 | INFO | train | epoch 151 | loss 5.394 | ppl 42.06 | wps 5833.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.997 | train_wall 329 | gb_free 6.1 | wall 53855
KL Stats: Epoch 151 Divergences: Uniform: 3.0434594882418198 Unigram: 4.039476807996849
2022-01-31 23:48:10 | INFO | fairseq.trainer | begin training epoch 152
2022-01-31 23:48:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:51:16 | INFO | train_inner | epoch 152:     36 / 64 loss=5.381, ppl=41.69, wps=5720.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.995, train_wall=515, gb_free=6.1, wall=54041
2022-01-31 23:53:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:54:06 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.213 | ppl 1186.53 | wps 7843.1 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.29
2022-01-31 23:54:06 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-31 23:54:06 | INFO | train | epoch 152 | loss 5.388 | ppl 41.86 | wps 5865.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.003 | train_wall 327 | gb_free 6.1 | wall 54211
KL Stats: Epoch 152 Divergences: Uniform: 3.0542965377641687 Unigram: 4.050538004423532
2022-01-31 23:54:06 | INFO | fairseq.trainer | begin training epoch 153
2022-01-31 23:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:59:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:00:03 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.263 | ppl 1228.88 | wps 7862.1 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.29
2022-02-01 00:00:03 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-01 00:00:03 | INFO | train | epoch 153 | loss 5.379 | ppl 41.62 | wps 5853 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.986 | train_wall 328 | gb_free 6.1 | wall 54568
KL Stats: Epoch 153 Divergences: Uniform: 3.0533656572374936 Unigram: 4.056986386332573
2022-02-01 00:00:03 | INFO | fairseq.trainer | begin training epoch 154
2022-02-01 00:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:00:44 | INFO | train_inner | epoch 154:      8 / 64 loss=5.388, ppl=41.86, wps=5738.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.997, train_wall=511, gb_free=6.1, wall=54609
2022-02-01 00:05:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:05:59 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.282 | ppl 1244.96 | wps 7833.2 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.29
2022-02-01 00:05:59 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-01 00:05:59 | INFO | train | epoch 154 | loss 5.373 | ppl 41.44 | wps 5857.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.011 | train_wall 328 | gb_free 6.1 | wall 54925
KL Stats: Epoch 154 Divergences: Uniform: 3.0596152090571267 Unigram: 4.058354967814046
2022-02-01 00:05:59 | INFO | fairseq.trainer | begin training epoch 155
2022-02-01 00:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:09:46 | INFO | train_inner | epoch 155:     44 / 64 loss=5.365, ppl=41.2, wps=6026, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.994, train_wall=513, gb_free=6.1, wall=55152
2022-02-01 00:11:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:11:56 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.261 | ppl 1226.66 | wps 7853.3 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.29
2022-02-01 00:11:56 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-01 00:11:56 | INFO | train | epoch 155 | loss 5.367 | ppl 41.28 | wps 5860.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.002 | train_wall 328 | gb_free 6.1 | wall 55281
KL Stats: Epoch 155 Divergences: Uniform: 3.0548763614837404 Unigram: 4.070180938448104
2022-02-01 00:11:56 | INFO | fairseq.trainer | begin training epoch 156
2022-02-01 00:11:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:17:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:17:51 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.271 | ppl 1235.58 | wps 7825.8 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.29
2022-02-01 00:17:51 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-01 00:17:51 | INFO | train | epoch 156 | loss 5.36 | ppl 41.06 | wps 5873 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.034 | train_wall 327 | gb_free 6.1 | wall 55637
KL Stats: Epoch 156 Divergences: Uniform: 3.056439922483455 Unigram: 4.069101174672444
2022-02-01 00:17:51 | INFO | fairseq.trainer | begin training epoch 157
2022-02-01 00:17:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:19:13 | INFO | train_inner | epoch 157:     16 / 64 loss=5.366, ppl=41.24, wps=5748.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.036, train_wall=510, gb_free=6.1, wall=55719
2022-02-01 00:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:23:47 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.232 | ppl 1202.85 | wps 7835.3 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.29
2022-02-01 00:23:47 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-01 00:23:47 | INFO | train | epoch 157 | loss 5.352 | ppl 40.85 | wps 5877 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.022 | train_wall 327 | gb_free 6.1 | wall 55992
KL Stats: Epoch 157 Divergences: Uniform: 3.0608715626910903 Unigram: 4.079767542947836
2022-02-01 00:23:47 | INFO | fairseq.trainer | begin training epoch 158
2022-02-01 00:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:28:14 | INFO | train_inner | epoch 158:     52 / 64 loss=5.346, ppl=40.67, wps=6041.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.014, train_wall=512, gb_free=6.1, wall=56260
2022-02-01 00:29:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:29:43 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.288 | ppl 1250.01 | wps 7830 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.29
2022-02-01 00:29:43 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-01 00:29:43 | INFO | train | epoch 158 | loss 5.346 | ppl 40.68 | wps 5867.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.016 | train_wall 327 | gb_free 6.1 | wall 56348
KL Stats: Epoch 158 Divergences: Uniform: 3.0558533945773583 Unigram: 4.086374289821213
2022-02-01 00:29:43 | INFO | fairseq.trainer | begin training epoch 159
2022-02-01 00:29:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:35:39 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.326 | ppl 1283.23 | wps 7828.9 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.29
2022-02-01 00:35:39 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-01 00:35:39 | INFO | train | epoch 159 | loss 5.34 | ppl 40.51 | wps 5853.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.054 | train_wall 328 | gb_free 6.1 | wall 56705
KL Stats: Epoch 159 Divergences: Uniform: 3.0549733275791513 Unigram: 4.093062282084784
2022-02-01 00:35:39 | INFO | fairseq.trainer | begin training epoch 160
2022-02-01 00:35:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:37:43 | INFO | train_inner | epoch 160:     24 / 64 loss=5.339, ppl=40.48, wps=5732.4, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.058, train_wall=511, gb_free=6.1, wall=56828
2022-02-01 00:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:41:36 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.269 | ppl 1234.01 | wps 7746.1 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.29
2022-02-01 00:41:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-01 00:41:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint160.pt
2022-02-01 00:41:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint160.pt
2022-02-01 00:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.269) (writing took 3.3701740400865674 seconds)
2022-02-01 00:41:39 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-01 00:41:39 | INFO | train | epoch 160 | loss 5.333 | ppl 40.31 | wps 5805.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.046 | train_wall 327 | gb_free 6.1 | wall 57065
KL Stats: Epoch 160 Divergences: Uniform: 3.0616603969628158 Unigram: 4.100983607626151
2022-02-01 00:41:39 | INFO | fairseq.trainer | begin training epoch 161
2022-02-01 00:41:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:46:50 | INFO | train_inner | epoch 161:     60 / 64 loss=5.334, ppl=40.34, wps=5976.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.04, train_wall=514, gb_free=6.1, wall=57375
2022-02-01 00:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:47:37 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.24 | ppl 1209.22 | wps 7838.6 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.29
2022-02-01 00:47:37 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-01 00:47:37 | INFO | train | epoch 161 | loss 5.327 | ppl 40.14 | wps 5840.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.041 | train_wall 329 | gb_free 6.1 | wall 57422
KL Stats: Epoch 161 Divergences: Uniform: 3.0672003823918232 Unigram: 4.102704337899334
2022-02-01 00:47:37 | INFO | fairseq.trainer | begin training epoch 162
2022-02-01 00:47:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:53:34 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.242 | ppl 1211.15 | wps 7813.6 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.29
2022-02-01 00:53:34 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-01 00:53:34 | INFO | train | epoch 162 | loss 5.319 | ppl 39.92 | wps 5842.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.039 | train_wall 329 | gb_free 6.1 | wall 57780
KL Stats: Epoch 162 Divergences: Uniform: 3.068637760702473 Unigram: 4.110482323820518
2022-02-01 00:53:34 | INFO | fairseq.trainer | begin training epoch 163
2022-02-01 00:53:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:56:20 | INFO | train_inner | epoch 163:     32 / 64 loss=5.306, ppl=39.57, wps=5717.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.044, train_wall=513, gb_free=6.1, wall=57945
2022-02-01 00:59:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:59:31 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.387 | ppl 1338.81 | wps 7959.4 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.29
2022-02-01 00:59:31 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-01 00:59:31 | INFO | train | epoch 163 | loss 5.316 | ppl 39.83 | wps 5860.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.056 | train_wall 328 | gb_free 6.1 | wall 58136
KL Stats: Epoch 163 Divergences: Uniform: 3.0683272439429246 Unigram: 4.117609959309015
2022-02-01 00:59:31 | INFO | fairseq.trainer | begin training epoch 164
2022-02-01 00:59:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:05:28 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.279 | ppl 1242.12 | wps 7851.2 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.29
2022-02-01 01:05:28 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-01 01:05:28 | INFO | train | epoch 164 | loss 5.308 | ppl 39.61 | wps 5845.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.07 | train_wall 329 | gb_free 6.1 | wall 58494
KL Stats: Epoch 164 Divergences: Uniform: 3.0633462307138863 Unigram: 4.121737585562999
2022-02-01 01:05:28 | INFO | fairseq.trainer | begin training epoch 165
2022-02-01 01:05:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:05:48 | INFO | train_inner | epoch 165:      4 / 64 loss=5.323, ppl=40.02, wps=5732.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.065, train_wall=512, gb_free=6.1, wall=58514
2022-02-01 01:10:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:11:24 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.389 | ppl 1340.62 | wps 7843.3 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.29
2022-02-01 01:11:24 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-01 01:11:24 | INFO | train | epoch 165 | loss 5.3 | ppl 39.39 | wps 5868.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.058 | train_wall 327 | gb_free 6.1 | wall 58849
KL Stats: Epoch 165 Divergences: Uniform: 3.0696356733587122 Unigram: 4.132712199113341
2022-02-01 01:11:24 | INFO | fairseq.trainer | begin training epoch 166
2022-02-01 01:11:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:14:50 | INFO | train_inner | epoch 166:     40 / 64 loss=5.293, ppl=39.2, wps=6028.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.057, train_wall=513, gb_free=6.1, wall=59056
2022-02-01 01:16:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:17:21 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.191 | ppl 1168.97 | wps 7853 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.29
2022-02-01 01:17:21 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-01 01:17:21 | INFO | train | epoch 166 | loss 5.295 | ppl 39.27 | wps 5851.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.075 | train_wall 328 | gb_free 6.1 | wall 59206
KL Stats: Epoch 166 Divergences: Uniform: 3.0707235288683488 Unigram: 4.136854159265849
2022-02-01 01:17:21 | INFO | fairseq.trainer | begin training epoch 167
2022-02-01 01:17:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:22:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:23:18 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.205 | ppl 1180.29 | wps 7859.9 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.29
2022-02-01 01:23:18 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-01 01:23:18 | INFO | train | epoch 167 | loss 5.29 | ppl 39.13 | wps 5850 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.092 | train_wall 328 | gb_free 6.1 | wall 59563
KL Stats: Epoch 167 Divergences: Uniform: 3.0688495478310482 Unigram: 4.136527112892242
2022-02-01 01:23:18 | INFO | fairseq.trainer | begin training epoch 168
2022-02-01 01:23:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:24:20 | INFO | train_inner | epoch 168:     12 / 64 loss=5.292, ppl=39.18, wps=5726.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.097, train_wall=512, gb_free=6.1, wall=59625
2022-02-01 01:28:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:29:14 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.294 | ppl 1255.7 | wps 7984.4 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.29
2022-02-01 01:29:14 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-01 01:29:14 | INFO | train | epoch 168 | loss 5.284 | ppl 38.96 | wps 5870.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.11 | train_wall 328 | gb_free 6.1 | wall 59919
KL Stats: Epoch 168 Divergences: Uniform: 3.0764219447659538 Unigram: 4.141364380141867
2022-02-01 01:29:14 | INFO | fairseq.trainer | begin training epoch 169
2022-02-01 01:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:33:21 | INFO | train_inner | epoch 169:     48 / 64 loss=5.283, ppl=38.94, wps=6034.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.106, train_wall=513, gb_free=6.1, wall=60167
2022-02-01 01:34:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:35:11 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.264 | ppl 1229.46 | wps 7838.6 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.29
2022-02-01 01:35:11 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-01 01:35:11 | INFO | train | epoch 169 | loss 5.278 | ppl 38.8 | wps 5850.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.091 | train_wall 328 | gb_free 6.1 | wall 60276
KL Stats: Epoch 169 Divergences: Uniform: 3.0743679720933206 Unigram: 4.148062016241189
2022-02-01 01:35:11 | INFO | fairseq.trainer | begin training epoch 170
2022-02-01 01:35:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:40:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:41:07 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.318 | ppl 1276.73 | wps 7827.3 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.29
2022-02-01 01:41:07 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-01 01:41:07 | INFO | train | epoch 170 | loss 5.272 | ppl 38.64 | wps 5853.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.13 | train_wall 328 | gb_free 6.1 | wall 60633
KL Stats: Epoch 170 Divergences: Uniform: 3.076272813574346 Unigram: 4.152342232925544
2022-02-01 01:41:07 | INFO | fairseq.trainer | begin training epoch 171
2022-02-01 01:41:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:42:50 | INFO | train_inner | epoch 171:     20 / 64 loss=5.267, ppl=38.51, wps=5727.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.133, train_wall=512, gb_free=6.1, wall=60736
2022-02-01 01:46:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:47:04 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.268 | ppl 1233.32 | wps 7826.8 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.29
2022-02-01 01:47:04 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-01 01:47:04 | INFO | train | epoch 171 | loss 5.268 | ppl 38.52 | wps 5863.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.148 | train_wall 327 | gb_free 6.1 | wall 60989
KL Stats: Epoch 171 Divergences: Uniform: 3.07382952283342 Unigram: 4.158352140104088
2022-02-01 01:47:04 | INFO | fairseq.trainer | begin training epoch 172
2022-02-01 01:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:51:52 | INFO | train_inner | epoch 172:     56 / 64 loss=5.269, ppl=38.56, wps=6029.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.117, train_wall=513, gb_free=6.1, wall=61278
2022-02-01 01:52:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:53:00 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.295 | ppl 1256.31 | wps 7828.4 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.29
2022-02-01 01:53:00 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-01 01:53:00 | INFO | train | epoch 172 | loss 5.259 | ppl 38.3 | wps 5852.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.111 | train_wall 328 | gb_free 6.1 | wall 61346
KL Stats: Epoch 172 Divergences: Uniform: 3.0753096500291752 Unigram: 4.166689883747262
2022-02-01 01:53:00 | INFO | fairseq.trainer | begin training epoch 173
2022-02-01 01:53:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:58:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:58:57 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.232 | ppl 1202.99 | wps 7788.9 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.29
2022-02-01 01:58:57 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-01 01:58:57 | INFO | train | epoch 173 | loss 5.256 | ppl 38.22 | wps 5856 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.162 | train_wall 328 | gb_free 6.1 | wall 61703
KL Stats: Epoch 173 Divergences: Uniform: 3.07695695849138 Unigram: 4.16835253364607
2022-02-01 01:58:57 | INFO | fairseq.trainer | begin training epoch 174
2022-02-01 01:58:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:01:22 | INFO | train_inner | epoch 174:     28 / 64 loss=5.25, ppl=38.05, wps=5724.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.147, train_wall=512, gb_free=6.1, wall=61848
2022-02-01 02:04:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:04:54 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.342 | ppl 1297.96 | wps 7823.9 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.29
2022-02-01 02:04:54 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-01 02:04:54 | INFO | train | epoch 174 | loss 5.251 | ppl 38.08 | wps 5857.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.132 | train_wall 328 | gb_free 6.1 | wall 62059
KL Stats: Epoch 174 Divergences: Uniform: 3.0758240920302606 Unigram: 4.178547501511114
2022-02-01 02:04:54 | INFO | fairseq.trainer | begin training epoch 175
2022-02-01 02:04:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:10:22 | INFO | train_inner | epoch 175:     64 / 64 loss=5.254, ppl=38.17, wps=6031.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.139, train_wall=511, gb_free=6.1, wall=62388
2022-02-01 02:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:10:50 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.366 | ppl 1319.3 | wps 7825.4 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.29
2022-02-01 02:10:50 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-01 02:10:50 | INFO | train | epoch 175 | loss 5.244 | ppl 37.89 | wps 5855.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.132 | train_wall 328 | gb_free 6.1 | wall 62416
KL Stats: Epoch 175 Divergences: Uniform: 3.086779721408646 Unigram: 4.180490780977265
2022-02-01 02:10:50 | INFO | fairseq.trainer | begin training epoch 176
2022-02-01 02:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:16:48 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.31 | ppl 1269.41 | wps 7855.3 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.29
2022-02-01 02:16:48 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-01 02:16:48 | INFO | train | epoch 176 | loss 5.239 | ppl 37.77 | wps 5844.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.157 | train_wall 329 | gb_free 6.1 | wall 62773
KL Stats: Epoch 176 Divergences: Uniform: 3.08545310413684 Unigram: 4.189388365730729
2022-02-01 02:16:48 | INFO | fairseq.trainer | begin training epoch 177
2022-02-01 02:16:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:19:53 | INFO | train_inner | epoch 177:     36 / 64 loss=5.226, ppl=37.44, wps=5725.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.158, train_wall=514, gb_free=6.1, wall=62959
2022-02-01 02:22:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:22:43 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.29 | ppl 1252.21 | wps 7838.6 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.29
2022-02-01 02:22:43 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-01 02:22:43 | INFO | train | epoch 177 | loss 5.234 | ppl 37.63 | wps 5872.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.181 | train_wall 327 | gb_free 6.1 | wall 63129
KL Stats: Epoch 177 Divergences: Uniform: 3.0804037656246477 Unigram: 4.191443756110289
2022-02-01 02:22:43 | INFO | fairseq.trainer | begin training epoch 178
2022-02-01 02:22:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:28:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:28:41 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.292 | ppl 1253.46 | wps 7714.5 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.29
2022-02-01 02:28:41 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-01 02:28:41 | INFO | train | epoch 178 | loss 5.23 | ppl 37.53 | wps 5848.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.169 | train_wall 328 | gb_free 6.1 | wall 63486
KL Stats: Epoch 178 Divergences: Uniform: 3.0918264613382243 Unigram: 4.19606172038458
2022-02-01 02:28:41 | INFO | fairseq.trainer | begin training epoch 179
2022-02-01 02:28:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:29:22 | INFO | train_inner | epoch 179:      8 / 64 loss=5.237, ppl=37.72, wps=5730.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.177, train_wall=511, gb_free=6.1, wall=63528
2022-02-01 02:34:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:34:38 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.266 | ppl 1231.27 | wps 7864.8 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.29
2022-02-01 02:34:38 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-01 02:34:38 | INFO | train | epoch 179 | loss 5.223 | ppl 37.35 | wps 5844.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.194 | train_wall 329 | gb_free 6.1 | wall 63844
KL Stats: Epoch 179 Divergences: Uniform: 3.0924607379352893 Unigram: 4.201193349392108
2022-02-01 02:34:38 | INFO | fairseq.trainer | begin training epoch 180
2022-02-01 02:34:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:38:25 | INFO | train_inner | epoch 180:     44 / 64 loss=5.219, ppl=37.24, wps=6022.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.191, train_wall=514, gb_free=6.1, wall=64070
2022-02-01 02:40:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:40:34 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.245 | ppl 1213.84 | wps 7943.4 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.29
2022-02-01 02:40:34 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-01 02:40:34 | INFO | train | epoch 180 | loss 5.22 | ppl 37.26 | wps 5867.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.215 | train_wall 328 | gb_free 6.1 | wall 64200
KL Stats: Epoch 180 Divergences: Uniform: 3.087293082642333 Unigram: 4.205507170926503
2022-02-01 02:40:34 | INFO | fairseq.trainer | begin training epoch 181
2022-02-01 02:40:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:46:31 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.325 | ppl 1283 | wps 7835.4 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.29
2022-02-01 02:46:31 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-01 02:46:31 | INFO | train | epoch 181 | loss 5.213 | ppl 37.1 | wps 5848.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.216 | train_wall 328 | gb_free 6.1 | wall 64557
KL Stats: Epoch 181 Divergences: Uniform: 3.0915367225514907 Unigram: 4.212614743062987
2022-02-01 02:46:31 | INFO | fairseq.trainer | begin training epoch 182
2022-02-01 02:46:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:47:53 | INFO | train_inner | epoch 182:     16 / 64 loss=5.214, ppl=37.12, wps=5732.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.228, train_wall=512, gb_free=6.1, wall=64639
2022-02-01 02:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:52:28 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.265 | ppl 1230.47 | wps 7853.8 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.29
2022-02-01 02:52:28 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-01 02:52:28 | INFO | train | epoch 182 | loss 5.208 | ppl 36.98 | wps 5850.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.209 | train_wall 328 | gb_free 6.1 | wall 64914
KL Stats: Epoch 182 Divergences: Uniform: 3.0913826336714623 Unigram: 4.209573042218123
2022-02-01 02:52:28 | INFO | fairseq.trainer | begin training epoch 183
2022-02-01 02:52:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:56:57 | INFO | train_inner | epoch 183:     52 / 64 loss=5.206, ppl=36.92, wps=6013.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.211, train_wall=514, gb_free=6.1, wall=65183
2022-02-01 02:57:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:58:26 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.33 | ppl 1287.48 | wps 7834.3 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.29
2022-02-01 02:58:26 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-01 02:58:26 | INFO | train | epoch 183 | loss 5.203 | ppl 36.83 | wps 5841 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.213 | train_wall 329 | gb_free 6.1 | wall 65271
KL Stats: Epoch 183 Divergences: Uniform: 3.094593125240463 Unigram: 4.221917499291648
2022-02-01 02:58:26 | INFO | fairseq.trainer | begin training epoch 184
2022-02-01 02:58:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:04:22 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.254 | ppl 1220.84 | wps 7840.3 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.29
2022-02-01 03:04:22 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-01 03:04:22 | INFO | train | epoch 184 | loss 5.2 | ppl 36.75 | wps 5861.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.24 | train_wall 328 | gb_free 6.1 | wall 65628
KL Stats: Epoch 184 Divergences: Uniform: 3.0945662885996907 Unigram: 4.222409460844064
2022-02-01 03:04:22 | INFO | fairseq.trainer | begin training epoch 185
2022-02-01 03:04:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:06:26 | INFO | train_inner | epoch 185:     24 / 64 loss=5.2, ppl=36.75, wps=5727.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.239, train_wall=512, gb_free=6.1, wall=65752
2022-02-01 03:09:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:10:18 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.29 | ppl 1251.86 | wps 7754.9 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.29
2022-02-01 03:10:18 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-01 03:10:18 | INFO | train | epoch 185 | loss 5.195 | ppl 36.63 | wps 5856.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.245 | train_wall 328 | gb_free 6.1 | wall 65984
KL Stats: Epoch 185 Divergences: Uniform: 3.091036509366973 Unigram: 4.227940000643267
2022-02-01 03:10:18 | INFO | fairseq.trainer | begin training epoch 186
2022-02-01 03:10:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:15:28 | INFO | train_inner | epoch 186:     60 / 64 loss=5.195, ppl=36.62, wps=6033.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.227, train_wall=512, gb_free=6.1, wall=66293
2022-02-01 03:15:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:16:15 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.201 | ppl 1176.96 | wps 7822.8 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.29
2022-02-01 03:16:15 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-01 03:16:15 | INFO | train | epoch 186 | loss 5.19 | ppl 36.52 | wps 5856.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.217 | train_wall 328 | gb_free 6.1 | wall 66341
KL Stats: Epoch 186 Divergences: Uniform: 3.0946367632480287 Unigram: 4.230184487538818
2022-02-01 03:16:15 | INFO | fairseq.trainer | begin training epoch 187
2022-02-01 03:16:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:21:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:22:11 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.295 | ppl 1256.65 | wps 7813.3 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.29
2022-02-01 03:22:11 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-01 03:22:11 | INFO | train | epoch 187 | loss 5.184 | ppl 36.36 | wps 5861 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.233 | train_wall 327 | gb_free 6.1 | wall 66697
KL Stats: Epoch 187 Divergences: Uniform: 3.0938049467521087 Unigram: 4.234701700544971
2022-02-01 03:22:11 | INFO | fairseq.trainer | begin training epoch 188
2022-02-01 03:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:24:56 | INFO | train_inner | epoch 188:     32 / 64 loss=5.178, ppl=36.19, wps=5732.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.232, train_wall=511, gb_free=6.1, wall=66862
2022-02-01 03:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:28:08 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.287 | ppl 1249.59 | wps 7882.4 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.29
2022-02-01 03:28:08 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-01 03:28:08 | INFO | train | epoch 188 | loss 5.18 | ppl 36.24 | wps 5858.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.267 | train_wall 328 | gb_free 6.1 | wall 67054
KL Stats: Epoch 188 Divergences: Uniform: 3.092809704743752 Unigram: 4.242493715595257
2022-02-01 03:28:08 | INFO | fairseq.trainer | begin training epoch 189
2022-02-01 03:28:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:33:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:34:05 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.312 | ppl 1271.15 | wps 7817.4 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.29
2022-02-01 03:34:05 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-01 03:34:05 | INFO | train | epoch 189 | loss 5.175 | ppl 36.13 | wps 5850 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.283 | train_wall 328 | gb_free 6.1 | wall 67411
KL Stats: Epoch 189 Divergences: Uniform: 3.0961535629885386 Unigram: 4.2497315273462695
2022-02-01 03:34:05 | INFO | fairseq.trainer | begin training epoch 190
2022-02-01 03:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:34:26 | INFO | train_inner | epoch 190:      4 / 64 loss=5.182, ppl=36.29, wps=5727.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.288, train_wall=512, gb_free=6.1, wall=67431
2022-02-01 03:39:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:40:01 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.287 | ppl 1249.1 | wps 7841 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.29
2022-02-01 03:40:01 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-01 03:40:01 | INFO | train | epoch 190 | loss 5.169 | ppl 35.98 | wps 5864.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.233 | train_wall 327 | gb_free 6.1 | wall 67767
KL Stats: Epoch 190 Divergences: Uniform: 3.0983491784141055 Unigram: 4.251850199498339
2022-02-01 03:40:01 | INFO | fairseq.trainer | begin training epoch 191
2022-02-01 03:40:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:43:28 | INFO | train_inner | epoch 191:     40 / 64 loss=5.159, ppl=35.73, wps=6028.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.268, train_wall=513, gb_free=6.1, wall=67973
2022-02-01 03:45:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:45:58 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.288 | ppl 1250.47 | wps 7842.3 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.29
2022-02-01 03:45:58 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-01 03:45:58 | INFO | train | epoch 191 | loss 5.166 | ppl 35.91 | wps 5850.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.306 | train_wall 328 | gb_free 6.1 | wall 68124
KL Stats: Epoch 191 Divergences: Uniform: 3.0940748690712256 Unigram: 4.253456637005355
2022-02-01 03:45:58 | INFO | fairseq.trainer | begin training epoch 192
2022-02-01 03:45:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:51:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:51:55 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.299 | ppl 1259.75 | wps 7824.4 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.29
2022-02-01 03:51:55 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-01 03:51:55 | INFO | train | epoch 192 | loss 5.162 | ppl 35.81 | wps 5859 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.296 | train_wall 328 | gb_free 6.1 | wall 68480
KL Stats: Epoch 192 Divergences: Uniform: 3.0947993938202227 Unigram: 4.250821258140256
2022-02-01 03:51:55 | INFO | fairseq.trainer | begin training epoch 193
2022-02-01 03:51:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:52:57 | INFO | train_inner | epoch 193:     12 / 64 loss=5.168, ppl=35.96, wps=5729.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.292, train_wall=512, gb_free=6.1, wall=68542
2022-02-01 03:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:57:51 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.301 | ppl 1261.9 | wps 7991.3 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.29
2022-02-01 03:57:51 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-01 03:57:51 | INFO | train | epoch 193 | loss 5.157 | ppl 35.69 | wps 5861.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.273 | train_wall 328 | gb_free 6.1 | wall 68837
KL Stats: Epoch 193 Divergences: Uniform: 3.1003788430797647 Unigram: 4.259927600847051
2022-02-01 03:57:51 | INFO | fairseq.trainer | begin training epoch 194
2022-02-01 03:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:01:59 | INFO | train_inner | epoch 194:     48 / 64 loss=5.153, ppl=35.59, wps=6030.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.291, train_wall=513, gb_free=6.1, wall=69084
2022-02-01 04:03:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:03:48 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.315 | ppl 1273.45 | wps 7844.6 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.29
2022-02-01 04:03:48 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-01 04:03:48 | INFO | train | epoch 194 | loss 5.152 | ppl 35.56 | wps 5846.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.318 | train_wall 328 | gb_free 6.1 | wall 69194
KL Stats: Epoch 194 Divergences: Uniform: 3.0979535202952526 Unigram: 4.2663521347604645
2022-02-01 04:03:48 | INFO | fairseq.trainer | begin training epoch 195
2022-02-01 04:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:09:46 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.299 | ppl 1259.65 | wps 7840.2 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.29
2022-02-01 04:09:46 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-01 04:09:46 | INFO | train | epoch 195 | loss 5.151 | ppl 35.52 | wps 5836.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.344 | train_wall 329 | gb_free 6.1 | wall 69552
KL Stats: Epoch 195 Divergences: Uniform: 3.098361891320267 Unigram: 4.269793585147849
2022-02-01 04:09:46 | INFO | fairseq.trainer | begin training epoch 196
2022-02-01 04:09:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:11:29 | INFO | train_inner | epoch 196:     20 / 64 loss=5.147, ppl=35.44, wps=5714, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.328, train_wall=513, gb_free=6.1, wall=69655
2022-02-01 04:15:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:15:43 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.248 | ppl 1215.66 | wps 7847.2 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.29
2022-02-01 04:15:43 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-01 04:15:43 | INFO | train | epoch 196 | loss 5.145 | ppl 35.38 | wps 5859.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.326 | train_wall 328 | gb_free 6.1 | wall 69908
KL Stats: Epoch 196 Divergences: Uniform: 3.098819283554409 Unigram: 4.271692922154481
2022-02-01 04:15:43 | INFO | fairseq.trainer | begin training epoch 197
2022-02-01 04:15:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:20:31 | INFO | train_inner | epoch 197:     56 / 64 loss=5.146, ppl=35.4, wps=6025, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.348, train_wall=513, gb_free=6.1, wall=70197
2022-02-01 04:21:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:21:39 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.281 | ppl 1244.51 | wps 7835.6 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.29
2022-02-01 04:21:39 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-01 04:21:39 | INFO | train | epoch 197 | loss 5.141 | ppl 35.28 | wps 5856.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.349 | train_wall 328 | gb_free 6.1 | wall 70265
KL Stats: Epoch 197 Divergences: Uniform: 3.098889325705307 Unigram: 4.275688122708269
2022-02-01 04:21:39 | INFO | fairseq.trainer | begin training epoch 198
2022-02-01 04:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:27:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:27:36 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.304 | ppl 1264.34 | wps 7816.5 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.29
2022-02-01 04:27:36 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-01 04:27:36 | INFO | train | epoch 198 | loss 5.134 | ppl 35.11 | wps 5850.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.344 | train_wall 328 | gb_free 6.1 | wall 70622
KL Stats: Epoch 198 Divergences: Uniform: 3.1030448544464586 Unigram: 4.280950893574802
2022-02-01 04:27:36 | INFO | fairseq.trainer | begin training epoch 199
2022-02-01 04:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:30:01 | INFO | train_inner | epoch 199:     28 / 64 loss=5.129, ppl=35, wps=5726, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.349, train_wall=512, gb_free=6.1, wall=70767
2022-02-01 04:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:33:33 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.292 | ppl 1253.39 | wps 7835.5 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.29
2022-02-01 04:33:33 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-01 04:33:33 | INFO | train | epoch 199 | loss 5.132 | ppl 35.07 | wps 5852.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.359 | train_wall 328 | gb_free 6.1 | wall 70979
KL Stats: Epoch 199 Divergences: Uniform: 3.1042581933686537 Unigram: 4.289522006148716
2022-02-01 04:33:33 | INFO | fairseq.trainer | begin training epoch 200
2022-02-01 04:33:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:39:02 | INFO | train_inner | epoch 200:     64 / 64 loss=5.139, ppl=35.25, wps=6022.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.373, train_wall=512, gb_free=6.1, wall=71308
2022-02-01 04:39:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:39:30 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.31 | ppl 1269.58 | wps 7852.6 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.29
2022-02-01 04:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-01 04:39:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint200.pt
2022-02-01 04:39:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint200.pt
2022-02-01 04:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.31) (writing took 3.416966806165874 seconds)
2022-02-01 04:39:33 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-01 04:39:33 | INFO | train | epoch 200 | loss 5.127 | ppl 34.94 | wps 5798 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.379 | train_wall 328 | gb_free 6.1 | wall 71339
KL Stats: Epoch 200 Divergences: Uniform: 3.1040061602738502 Unigram: 4.2921871000324625
2022-02-01 04:39:33 | INFO | fairseq.trainer | begin training epoch 201
2022-02-01 04:39:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:45:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:45:29 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.313 | ppl 1272.44 | wps 7893.7 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.29
2022-02-01 04:45:29 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-01 04:45:29 | INFO | train | epoch 201 | loss 5.124 | ppl 34.86 | wps 5867.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.352 | train_wall 327 | gb_free 6.1 | wall 71695
KL Stats: Epoch 201 Divergences: Uniform: 3.101620626724724 Unigram: 4.288970773716371
2022-02-01 04:45:29 | INFO | fairseq.trainer | begin training epoch 202
2022-02-01 04:45:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:48:36 | INFO | train_inner | epoch 202:     36 / 64 loss=5.11, ppl=34.54, wps=5695.2, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.372, train_wall=513, gb_free=6.1, wall=71882
User defined signal 2
Sender: LSF System <lsfadmin@eu-g3-037>
Subject: Job 202993562: <w2_jelinek_0.1_0.0_0.9_#3> in cluster <euler> Exited

Job <w2_jelinek_0.1_0.0_0.9_#3> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:07:00 2022
Job was executed on host(s) <eu-g3-037>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:07:34 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:07:34 2022
Terminated at Thu Feb  3 02:07:38 2022
Results reported at Thu Feb  3 02:07:38 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.1, 0.0, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 3002 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   71962.00 sec.
    Max Memory :                                 6039 MB
    Average Memory :                             3618.14 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13961.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72004 sec.
    Turnaround time :                            72038 sec.

The output (if any) follows:

2022-02-02 06:07:43 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3002, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 3002, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.1, 0.0, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:07:43 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:07:44 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  3%|▎         | 1108/36718 [00:00<00:03, 11078.87it/s]  6%|▌         | 2216/36718 [00:00<00:03, 10161.81it/s]  9%|▉         | 3441/36718 [00:00<00:03, 11056.63it/s] 13%|█▎        | 4668/36718 [00:00<00:02, 11518.58it/s] 16%|█▋        | 5985/36718 [00:00<00:02, 12094.52it/s] 20%|█▉        | 7200/36718 [00:00<00:02, 11360.72it/s] 23%|██▎       | 8347/36718 [00:00<00:02, 11286.74it/s] 26%|██▌       | 9483/36718 [00:00<00:02, 11130.92it/s] 29%|██▉       | 10601/36718 [00:00<00:02, 11077.08it/s] 32%|███▏      | 11712/36718 [00:01<00:02, 11059.61it/s] 35%|███▌      | 12875/36718 [00:01<00:02, 11221.07it/s] 38%|███▊      | 14048/36718 [00:01<00:01, 11367.45it/s] 42%|████▏     | 15276/36718 [00:01<00:01, 11636.84it/s] 45%|████▍     | 16442/36718 [00:01<00:01, 11149.44it/s] 48%|████▊     | 17562/36718 [00:01<00:01, 11157.26it/s] 51%|█████     | 18687/36718 [00:01<00:01, 11180.24it/s] 54%|█████▍    | 19965/36718 [00:01<00:01, 11645.90it/s] 58%|█████▊    | 21133/36718 [00:01<00:01, 11399.71it/s] 61%|██████    | 22276/36718 [00:01<00:01, 11247.15it/s] 64%|██████▍   | 23460/36718 [00:02<00:01, 11411.92it/s] 68%|██████▊   | 24838/36718 [00:02<00:00, 12103.54it/s] 71%|███████   | 26051/36718 [00:02<00:00, 11932.93it/s] 74%|███████▍  | 27247/36718 [00:02<00:00, 11232.84it/s] 77%|███████▋  | 28389/36718 [00:02<00:00, 11282.06it/s] 80%|████████  | 29524/36718 [00:02<00:00, 11243.25it/s] 83%|████████▎ | 30653/36718 [00:02<00:00, 11093.71it/s] 87%|████████▋ | 31768/36718 [00:02<00:00, 11108.29it/s] 90%|████████▉ | 32882/36718 [00:02<00:00, 10801.73it/s] 93%|█████████▎| 33966/36718 [00:03<00:00, 10790.54it/s] 96%|█████████▌| 35114/36718 [00:03<00:00, 10987.39it/s] 99%|█████████▊| 36250/36718 [00:03<00:00, 11091.67it/s]100%|██████████| 36718/36718 [00:03<00:00, 11254.68it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  5%|▌         | 2007/36718 [00:00<00:01, 20067.05it/s] 12%|█▏        | 4242/36718 [00:00<00:01, 21408.60it/s] 18%|█▊        | 6493/36718 [00:00<00:01, 21908.42it/s] 24%|██▎       | 8684/36718 [00:00<00:01, 21432.36it/s] 29%|██▉       | 10829/36718 [00:00<00:01, 21436.42it/s] 35%|███▌      | 13000/36718 [00:00<00:01, 21520.45it/s] 42%|████▏     | 15257/36718 [00:00<00:00, 21858.74it/s] 48%|████▊     | 17444/36718 [00:00<00:00, 21486.89it/s] 54%|█████▎    | 19704/36718 [00:00<00:00, 21825.18it/s] 60%|█████▉    | 21889/36718 [00:01<00:00, 21427.44it/s] 66%|██████▌   | 24270/36718 [00:01<00:00, 22138.33it/s] 72%|███████▏  | 26491/36718 [00:01<00:00, 22157.20it/s] 78%|███████▊  | 28709/36718 [00:01<00:00, 21993.99it/s] 84%|████████▍ | 30911/36718 [00:01<00:00, 21436.86it/s] 90%|█████████ | 33059/36718 [00:01<00:00, 20987.41it/s] 96%|█████████▌| 35245/36718 [00:01<00:00, 21237.04it/s]100%|██████████| 36718/36718 [00:01<00:00, 21516.03it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 81.62it/s]2022-02-02 06:07:58 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:07:58 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:07:58 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:07:58 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:07:58 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:07:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:07:58 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:07:58 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:07:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:07:58 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-02-02 06:07:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:07:58 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:07:58 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:07:58 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint_last.pt
2022-02-02 06:07:58 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint_last.pt
2022-02-02 06:07:58 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:07:58 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:07:58 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:07:58 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:07:58 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:13:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:13:47 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.744 | ppl 27437.8 | wps 8136.7 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:13:47 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:13:47 | INFO | train | epoch 001 | loss 16.006 | ppl 65808.1 | wps 6034 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.06 | train_wall 318 | gb_free 6.1 | wall 349
KL Stats: Epoch 1 Divergences: Uniform: 0.5245263495553191 Unigram: 3.608613703973654
2022-02-02 06:13:47 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:13:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:16:48 | INFO | train_inner | epoch 002:     36 / 64 loss=15.517, ppl=46895.8, wps=6211.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.539, train_wall=497, gb_free=6.1, wall=529
2022-02-02 06:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:19:33 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.685 | ppl 13174.6 | wps 8135 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:19:33 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:19:33 | INFO | train | epoch 002 | loss 14.428 | ppl 22038.3 | wps 6041.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.515 | train_wall 317 | gb_free 6.1 | wall 695
KL Stats: Epoch 2 Divergences: Uniform: 0.528092305712101 Unigram: 2.421741595386771
2022-02-02 06:19:33 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:25:19 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.854 | ppl 7405.41 | wps 8100.5 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:25:19 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:25:19 | INFO | train | epoch 003 | loss 13.515 | ppl 11710 | wps 6045.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.247 | train_wall 317 | gb_free 6.1 | wall 1040
KL Stats: Epoch 3 Divergences: Uniform: 0.5108746792071139 Unigram: 1.7309427995762188
2022-02-02 06:25:19 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:25:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:25:59 | INFO | train_inner | epoch 004:      8 / 64 loss=13.648, ppl=12834.1, wps=5916.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.278, train_wall=495, gb_free=6.1, wall=1080
2022-02-02 06:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:31:05 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.024 | ppl 4164.2 | wps 8135.9 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:31:05 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:31:05 | INFO | train | epoch 004 | loss 12.57 | ppl 6081.54 | wps 6028.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.98 | train_wall 318 | gb_free 6.1 | wall 1387
KL Stats: Epoch 4 Divergences: Uniform: 0.5976557933749805 Unigram: 1.108332700481745
2022-02-02 06:31:05 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:34:45 | INFO | train_inner | epoch 005:     44 / 64 loss=12.231, ppl=4808.49, wps=6211.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.867, train_wall=497, gb_free=6.1, wall=1606
2022-02-02 06:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:36:50 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.5 | ppl 2896.79 | wps 8112.8 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:36:50 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:36:50 | INFO | train | epoch 005 | loss 11.791 | ppl 3542.54 | wps 6047 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.713 | train_wall 317 | gb_free 6.1 | wall 1732
KL Stats: Epoch 5 Divergences: Uniform: 0.8315662807535712 Unigram: 0.6388235109094721
2022-02-02 06:36:50 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:36:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:42:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:42:36 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.273 | ppl 2475.04 | wps 8148.4 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:42:36 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:42:36 | INFO | train | epoch 006 | loss 11.361 | ppl 2630.44 | wps 6045.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.566 | train_wall 317 | gb_free 6.1 | wall 2078
KL Stats: Epoch 6 Divergences: Uniform: 1.1382912474106113 Unigram: 0.43299561029955697
2022-02-02 06:42:36 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:42:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:43:56 | INFO | train_inner | epoch 007:     16 / 64 loss=11.381, ppl=2666.47, wps=5913.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.578, train_wall=495, gb_free=6.1, wall=2158
2022-02-02 06:47:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:48:22 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.14 | ppl 2256.13 | wps 8120.7 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:48:22 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:48:22 | INFO | train | epoch 007 | loss 11.157 | ppl 2283.01 | wps 6040.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.529 | train_wall 317 | gb_free 6.1 | wall 2423
KL Stats: Epoch 7 Divergences: Uniform: 1.3648120022539663 Unigram: 0.4566967377544137
2022-02-02 06:48:22 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:48:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:52:41 | INFO | train_inner | epoch 008:     52 / 64 loss=11.091, ppl=2181.72, wps=6222.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.519, train_wall=496, gb_free=6.1, wall=2683
2022-02-02 06:53:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:54:07 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.027 | ppl 2086.81 | wps 8151.6 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:54:07 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:54:07 | INFO | train | epoch 008 | loss 11.041 | ppl 2107.59 | wps 6055.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.516 | train_wall 316 | gb_free 6.1 | wall 2768
KL Stats: Epoch 8 Divergences: Uniform: 1.476058450847851 Unigram: 0.5381901059423718
2022-02-02 06:54:07 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:54:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:59:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:59:52 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.924 | ppl 1943.16 | wps 8154.2 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 06:59:52 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 06:59:52 | INFO | train | epoch 009 | loss 10.936 | ppl 1959.26 | wps 6043.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 317 | gb_free 6.1 | wall 3114
KL Stats: Epoch 9 Divergences: Uniform: 1.522859473626348 Unigram: 0.6390563320489232
2022-02-02 06:59:52 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 06:59:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:01:52 | INFO | train_inner | epoch 010:     24 / 64 loss=10.929, ppl=1949.88, wps=5916.7, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.496, train_wall=495, gb_free=6.1, wall=3234
2022-02-02 07:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:05:38 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.811 | ppl 1796.29 | wps 8125.2 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:05:38 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:05:38 | INFO | train | epoch 010 | loss 10.825 | ppl 1814.47 | wps 6047.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.497 | train_wall 317 | gb_free 6.1 | wall 3459
KL Stats: Epoch 10 Divergences: Uniform: 1.545014182091606 Unigram: 0.7580717746490804
2022-02-02 07:05:38 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:05:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:10:38 | INFO | train_inner | epoch 011:     60 / 64 loss=10.748, ppl=1720.14, wps=6215.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.484, train_wall=496, gb_free=6.1, wall=3760
2022-02-02 07:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:11:24 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.693 | ppl 1655.85 | wps 8104.5 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:11:24 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:11:24 | INFO | train | epoch 011 | loss 10.706 | ppl 1670.83 | wps 6035.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.482 | train_wall 317 | gb_free 6.1 | wall 3805
KL Stats: Epoch 11 Divergences: Uniform: 1.5615182081646672 Unigram: 0.8773569301981107
2022-02-02 07:11:24 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:11:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:16:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:17:10 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.609 | ppl 1561.67 | wps 8137.6 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:17:10 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:17:10 | INFO | train | epoch 012 | loss 10.589 | ppl 1540.7 | wps 6031.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.481 | train_wall 318 | gb_free 6.1 | wall 4152
KL Stats: Epoch 12 Divergences: Uniform: 1.5837511795656023 Unigram: 0.9885537404247882
2022-02-02 07:17:10 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:19:50 | INFO | train_inner | epoch 013:     32 / 64 loss=10.558, ppl=1507.11, wps=5909, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.493, train_wall=495, gb_free=6.1, wall=4311
2022-02-02 07:22:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:22:55 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.514 | ppl 1462.06 | wps 8144.7 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:22:55 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:22:55 | INFO | train | epoch 013 | loss 10.474 | ppl 1422.45 | wps 6055.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 316 | gb_free 6.1 | wall 4497
KL Stats: Epoch 13 Divergences: Uniform: 1.6031897775448538 Unigram: 1.0896834750414635
2022-02-02 07:22:55 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:22:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:28:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:28:40 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.416 | ppl 1366.07 | wps 8133.4 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:28:40 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:28:40 | INFO | train | epoch 014 | loss 10.36 | ppl 1314.65 | wps 6050.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.516 | train_wall 317 | gb_free 6.1 | wall 4842
KL Stats: Epoch 14 Divergences: Uniform: 1.6304812296411486 Unigram: 1.1719815592420826
2022-02-02 07:28:40 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:29:00 | INFO | train_inner | epoch 015:      4 / 64 loss=10.389, ppl=1340.95, wps=5921.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.517, train_wall=494, gb_free=6.1, wall=4862
2022-02-02 07:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:34:26 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.315 | ppl 1273.56 | wps 8139.9 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:34:26 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:34:26 | INFO | train | epoch 015 | loss 10.25 | ppl 1218.15 | wps 6034 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.552 | train_wall 318 | gb_free 6.1 | wall 5188
KL Stats: Epoch 15 Divergences: Uniform: 1.6552691090863596 Unigram: 1.2515309249566389
2022-02-02 07:34:26 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:37:47 | INFO | train_inner | epoch 016:     40 / 64 loss=10.211, ppl=1184.96, wps=6206.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.563, train_wall=497, gb_free=6.1, wall=5388
2022-02-02 07:39:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:40:12 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.233 | ppl 1203.75 | wps 8130.4 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:40:12 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:40:12 | INFO | train | epoch 016 | loss 10.141 | ppl 1129.35 | wps 6034.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.564 | train_wall 318 | gb_free 6.1 | wall 5534
KL Stats: Epoch 16 Divergences: Uniform: 1.6844446930523402 Unigram: 1.3292503949540804
2022-02-02 07:40:12 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:45:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:45:58 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.165 | ppl 1148.17 | wps 8115.3 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:45:58 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:45:58 | INFO | train | epoch 017 | loss 10.031 | ppl 1046.12 | wps 6034.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.521 | train_wall 318 | gb_free 6.1 | wall 5880
KL Stats: Epoch 17 Divergences: Uniform: 1.71350114254543 Unigram: 1.4030489689818075
2022-02-02 07:45:58 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:45:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:46:59 | INFO | train_inner | epoch 018:     12 / 64 loss=10.039, ppl=1052.01, wps=5906.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.535, train_wall=496, gb_free=6.1, wall=5940
2022-02-02 07:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:51:44 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.057 | ppl 1065.2 | wps 8146.7 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 07:51:44 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 07:51:44 | INFO | train | epoch 018 | loss 9.929 | ppl 974.96 | wps 6037.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.594 | train_wall 318 | gb_free 6.1 | wall 6226
KL Stats: Epoch 18 Divergences: Uniform: 1.746024561520952 Unigram: 1.4713813162781215
2022-02-02 07:51:44 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 07:51:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:55:44 | INFO | train_inner | epoch 019:     48 / 64 loss=9.881, ppl=943.1, wps=6214.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.548, train_wall=497, gb_free=6.1, wall=6466
2022-02-02 07:57:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:57:30 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.005 | ppl 1027.54 | wps 8107.1 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 07:57:30 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 07:57:30 | INFO | train | epoch 019 | loss 9.825 | ppl 907.08 | wps 6040.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.497 | train_wall 317 | gb_free 6.1 | wall 6572
KL Stats: Epoch 19 Divergences: Uniform: 1.7753398606790949 Unigram: 1.539314221341082
2022-02-02 07:57:30 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 07:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:03:17 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.943 | ppl 984.37 | wps 8140 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 08:03:17 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 08:03:17 | INFO | train | epoch 020 | loss 9.729 | ppl 848.39 | wps 6018.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.507 | train_wall 319 | gb_free 6.1 | wall 6919
KL Stats: Epoch 20 Divergences: Uniform: 1.8100720850880603 Unigram: 1.6025976557970787
2022-02-02 08:03:17 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 08:03:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:04:57 | INFO | train_inner | epoch 021:     20 / 64 loss=9.727, ppl=847.25, wps=5898.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.508, train_wall=496, gb_free=6.1, wall=7019
2022-02-02 08:08:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:09:02 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.895 | ppl 952.26 | wps 8124.4 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:09:02 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:09:02 | INFO | train | epoch 021 | loss 9.634 | ppl 794.46 | wps 6058.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.514 | train_wall 316 | gb_free 6.1 | wall 7264
KL Stats: Epoch 21 Divergences: Uniform: 1.8370567450669413 Unigram: 1.6634328760044659
2022-02-02 08:09:02 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:09:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:13:42 | INFO | train_inner | epoch 022:     56 / 64 loss=9.582, ppl=766.22, wps=6228.7, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.519, train_wall=495, gb_free=6.1, wall=7543
2022-02-02 08:14:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:14:47 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.843 | ppl 918.63 | wps 8125.2 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:14:47 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:14:47 | INFO | train | epoch 022 | loss 9.545 | ppl 746.88 | wps 6045.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.535 | train_wall 317 | gb_free 6.1 | wall 7609
KL Stats: Epoch 22 Divergences: Uniform: 1.8613008144851055 Unigram: 1.7182903596680799
2022-02-02 08:14:47 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:14:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:20:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:20:33 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.786 | ppl 883.08 | wps 8134.5 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:20:33 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:20:33 | INFO | train | epoch 023 | loss 9.46 | ppl 704.5 | wps 6048.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.56 | train_wall 317 | gb_free 6.1 | wall 7954
KL Stats: Epoch 23 Divergences: Uniform: 1.8843340264179418 Unigram: 1.7693497938841012
2022-02-02 08:20:33 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:20:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:22:53 | INFO | train_inner | epoch 024:     28 / 64 loss=9.445, ppl=697.04, wps=5915.5, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.551, train_wall=495, gb_free=6.1, wall=8094
2022-02-02 08:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:26:19 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.719 | ppl 842.98 | wps 8088.4 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:26:19 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:26:19 | INFO | train | epoch 024 | loss 9.376 | ppl 664.52 | wps 6038.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.532 | train_wall 317 | gb_free 6.1 | wall 8300
KL Stats: Epoch 24 Divergences: Uniform: 1.9106383970246228 Unigram: 1.818719729602575
2022-02-02 08:26:19 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:26:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:31:38 | INFO | train_inner | epoch 025:     64 / 64 loss=9.32, ppl=639.28, wps=6205.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.528, train_wall=496, gb_free=6.1, wall=8620
2022-02-02 08:31:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:32:05 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.674 | ppl 816.78 | wps 8021.1 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:32:05 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:32:05 | INFO | train | epoch 025 | loss 9.293 | ppl 627.35 | wps 6023 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.52 | train_wall 318 | gb_free 6.1 | wall 8647
KL Stats: Epoch 25 Divergences: Uniform: 1.9374249768796836 Unigram: 1.861993589032982
2022-02-02 08:32:05 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:32:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:37:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:37:51 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.641 | ppl 798.42 | wps 8138.4 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:37:51 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:37:51 | INFO | train | epoch 026 | loss 9.213 | ppl 593.37 | wps 6042.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.52 | train_wall 317 | gb_free 6.1 | wall 8993
KL Stats: Epoch 26 Divergences: Uniform: 1.9631228059649308 Unigram: 1.9031005349097863
2022-02-02 08:37:51 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:40:51 | INFO | train_inner | epoch 027:     36 / 64 loss=9.183, ppl=581.29, wps=5910.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.535, train_wall=496, gb_free=6.1, wall=9173
2022-02-02 08:43:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:43:37 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.603 | ppl 777.43 | wps 8124.6 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:43:37 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:43:37 | INFO | train | epoch 027 | loss 9.135 | ppl 562.1 | wps 6044.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.561 | train_wall 317 | gb_free 6.1 | wall 9338
KL Stats: Epoch 27 Divergences: Uniform: 1.9840857198489172 Unigram: 1.9454004026972553
2022-02-02 08:43:37 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:49:22 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.566 | ppl 757.86 | wps 8136 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 08:49:22 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 08:49:22 | INFO | train | epoch 028 | loss 9.055 | ppl 531.76 | wps 6042.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.52 | train_wall 317 | gb_free 6.1 | wall 9684
KL Stats: Epoch 28 Divergences: Uniform: 2.0072750924589156 Unigram: 1.984781832045256
2022-02-02 08:49:22 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 08:49:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:50:02 | INFO | train_inner | epoch 029:      8 / 64 loss=9.07, ppl=537.47, wps=5914.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.531, train_wall=495, gb_free=6.1, wall=9724
2022-02-02 08:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:55:07 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.528 | ppl 738.48 | wps 8136.9 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 08:55:07 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 08:55:07 | INFO | train | epoch 029 | loss 8.978 | ppl 504.31 | wps 6051.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.53 | train_wall 317 | gb_free 6.1 | wall 10029
KL Stats: Epoch 29 Divergences: Uniform: 2.02687211297006 Unigram: 2.0210847993242016
2022-02-02 08:55:07 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 08:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:58:48 | INFO | train_inner | epoch 030:     44 / 64 loss=8.946, ppl=493.11, wps=6218.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.518, train_wall=496, gb_free=6.1, wall=10250
2022-02-02 09:00:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:00:54 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.499 | ppl 723.48 | wps 8140.3 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 09:00:54 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 09:00:54 | INFO | train | epoch 030 | loss 8.901 | ppl 477.95 | wps 6032 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.503 | train_wall 318 | gb_free 6.1 | wall 10375
KL Stats: Epoch 30 Divergences: Uniform: 2.050411180872098 Unigram: 2.0605589179425468
2022-02-02 09:00:54 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 09:00:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:06:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:06:39 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.464 | ppl 706.39 | wps 8118 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 09:06:39 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 09:06:39 | INFO | train | epoch 031 | loss 8.826 | ppl 453.8 | wps 6042.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.524 | train_wall 317 | gb_free 6.1 | wall 10721
KL Stats: Epoch 31 Divergences: Uniform: 2.069653211992368 Unigram: 2.103317038831952
2022-02-02 09:06:39 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 09:06:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:07:59 | INFO | train_inner | epoch 032:     16 / 64 loss=8.829, ppl=454.62, wps=5909.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.519, train_wall=495, gb_free=6.1, wall=10801
2022-02-02 09:11:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:12:25 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.465 | ppl 706.7 | wps 8124.6 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:12:25 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:12:25 | INFO | train | epoch 032 | loss 8.75 | ppl 430.46 | wps 6039.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.506 | train_wall 317 | gb_free 6.1 | wall 11067
KL Stats: Epoch 32 Divergences: Uniform: 2.088345266795931 Unigram: 2.1395285222671108
2022-02-02 09:12:25 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:12:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:16:45 | INFO | train_inner | epoch 033:     52 / 64 loss=8.711, ppl=419.05, wps=6223.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.499, train_wall=496, gb_free=6.1, wall=11326
2022-02-02 09:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:18:10 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.429 | ppl 689.28 | wps 8129.9 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:18:10 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:18:10 | INFO | train | epoch 033 | loss 8.675 | ppl 408.79 | wps 6054.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.497 | train_wall 316 | gb_free 6.1 | wall 11412
KL Stats: Epoch 33 Divergences: Uniform: 2.116030224471213 Unigram: 2.1807692364169076
2022-02-02 09:18:10 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:18:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:23:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:23:56 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.421 | ppl 685.71 | wps 8136.7 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:23:56 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:23:56 | INFO | train | epoch 034 | loss 8.601 | ppl 388.21 | wps 6043.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.498 | train_wall 317 | gb_free 6.1 | wall 11757
KL Stats: Epoch 34 Divergences: Uniform: 2.1339964590440896 Unigram: 2.217035032196993
2022-02-02 09:23:56 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:23:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:25:56 | INFO | train_inner | epoch 035:     24 / 64 loss=8.59, ppl=385.46, wps=5913.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.497, train_wall=495, gb_free=6.1, wall=11877
2022-02-02 09:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:29:41 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.38 | ppl 666.23 | wps 8126.7 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:29:41 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:29:41 | INFO | train | epoch 035 | loss 8.531 | ppl 369.91 | wps 6046.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.515 | train_wall 317 | gb_free 6.1 | wall 12103
KL Stats: Epoch 35 Divergences: Uniform: 2.156500441521155 Unigram: 2.2484137597107328
2022-02-02 09:29:41 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:29:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:34:41 | INFO | train_inner | epoch 036:     60 / 64 loss=8.49, ppl=359.66, wps=6218.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.516, train_wall=496, gb_free=6.1, wall=12403
2022-02-02 09:35:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:35:27 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.341 | ppl 648.62 | wps 8137.4 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:35:27 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:35:27 | INFO | train | epoch 036 | loss 8.46 | ppl 352.09 | wps 6041.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.505 | train_wall 317 | gb_free 6.1 | wall 12449
KL Stats: Epoch 36 Divergences: Uniform: 2.1768014591850284 Unigram: 2.2815711444290914
2022-02-02 09:35:27 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:40:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:41:13 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.346 | ppl 650.99 | wps 8145.2 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:41:13 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:41:13 | INFO | train | epoch 037 | loss 8.388 | ppl 335.03 | wps 6030.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.499 | train_wall 318 | gb_free 6.1 | wall 12795
KL Stats: Epoch 37 Divergences: Uniform: 2.19942472830805 Unigram: 2.316181417576112
2022-02-02 09:41:13 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:41:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:43:53 | INFO | train_inner | epoch 038:     32 / 64 loss=8.367, ppl=330.2, wps=5907.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.498, train_wall=496, gb_free=6.1, wall=12955
2022-02-02 09:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:46:59 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.349 | ppl 651.93 | wps 8121 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 09:46:59 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 09:46:59 | INFO | train | epoch 038 | loss 8.319 | ppl 319.34 | wps 6043.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.497 | train_wall 317 | gb_free 6.1 | wall 13141
KL Stats: Epoch 38 Divergences: Uniform: 2.2181366563002056 Unigram: 2.3516428988084654
2022-02-02 09:46:59 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 09:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:52:45 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.336 | ppl 646.49 | wps 8099.9 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 09:52:45 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 09:52:45 | INFO | train | epoch 039 | loss 8.254 | ppl 305.23 | wps 6028.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.509 | train_wall 318 | gb_free 6.1 | wall 13487
KL Stats: Epoch 39 Divergences: Uniform: 2.2424196096404203 Unigram: 2.3810144952282184
2022-02-02 09:52:45 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 09:52:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:53:05 | INFO | train_inner | epoch 040:      4 / 64 loss=8.27, ppl=308.77, wps=5904.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.504, train_wall=496, gb_free=6.1, wall=13507
2022-02-02 09:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:58:31 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.303 | ppl 631.64 | wps 8119.8 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 09:58:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 09:58:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint40.pt
2022-02-02 09:58:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint40.pt
2022-02-02 09:58:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.303) (writing took 4.557467428967357 seconds)
2022-02-02 09:58:35 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 09:58:35 | INFO | train | epoch 040 | loss 8.187 | ppl 291.5 | wps 5969.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.506 | train_wall 317 | gb_free 6.1 | wall 13837
KL Stats: Epoch 40 Divergences: Uniform: 2.252859978584835 Unigram: 2.4090652167400255
2022-02-02 09:58:35 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 09:58:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:01:55 | INFO | train_inner | epoch 041:     40 / 64 loss=8.156, ppl=285.27, wps=6165.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.498, train_wall=496, gb_free=6.1, wall=14037
2022-02-02 10:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:04:21 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.301 | ppl 630.96 | wps 8135.7 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.301
2022-02-02 10:04:21 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 10:04:21 | INFO | train | epoch 041 | loss 8.12 | ppl 278.22 | wps 6041.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.489 | train_wall 317 | gb_free 6.1 | wall 14183
KL Stats: Epoch 41 Divergences: Uniform: 2.2755372459709617 Unigram: 2.4399994845079203
2022-02-02 10:04:21 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 10:04:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:10:07 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.328 | ppl 642.76 | wps 8082.8 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.303
2022-02-02 10:10:07 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 10:10:07 | INFO | train | epoch 042 | loss 8.059 | ppl 266.61 | wps 6036.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.516 | train_wall 317 | gb_free 6.1 | wall 14529
KL Stats: Epoch 42 Divergences: Uniform: 2.2993510354639315 Unigram: 2.4645705699285716
2022-02-02 10:10:07 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 10:10:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:11:07 | INFO | train_inner | epoch 043:     12 / 64 loss=8.07, ppl=268.71, wps=5910.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.51, train_wall=495, gb_free=6.1, wall=14589
2022-02-02 10:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:15:53 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.274 | ppl 619.19 | wps 8114.5 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.274
2022-02-02 10:15:53 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:15:53 | INFO | train | epoch 043 | loss 7.994 | ppl 254.85 | wps 6036.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.494 | train_wall 317 | gb_free 6.1 | wall 14875
KL Stats: Epoch 43 Divergences: Uniform: 2.3161222827841956 Unigram: 2.49429745225445
2022-02-02 10:15:53 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:15:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:19:53 | INFO | train_inner | epoch 044:     48 / 64 loss=7.964, ppl=249.77, wps=6207.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.487, train_wall=497, gb_free=6.1, wall=15115
2022-02-02 10:21:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:21:39 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.269 | ppl 617.02 | wps 8128.8 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.269
2022-02-02 10:21:39 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:21:39 | INFO | train | epoch 044 | loss 7.933 | ppl 244.32 | wps 6029.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.486 | train_wall 318 | gb_free 6.1 | wall 15221
KL Stats: Epoch 44 Divergences: Uniform: 2.335215241656111 Unigram: 2.526928783997503
2022-02-02 10:21:39 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:26:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:27:25 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.26 | ppl 612.9 | wps 8102 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.26
2022-02-02 10:27:25 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:27:25 | INFO | train | epoch 045 | loss 7.872 | ppl 234.23 | wps 6043.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.493 | train_wall 317 | gb_free 6.1 | wall 15567
KL Stats: Epoch 45 Divergences: Uniform: 2.355059280323548 Unigram: 2.5514589539116033
2022-02-02 10:27:25 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:27:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:29:05 | INFO | train_inner | epoch 046:     20 / 64 loss=7.872, ppl=234.26, wps=5907, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.501, train_wall=495, gb_free=6.1, wall=15667
2022-02-02 10:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:33:11 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.274 | ppl 619.3 | wps 8142 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.274
2022-02-02 10:33:11 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:33:11 | INFO | train | epoch 046 | loss 7.814 | ppl 225.03 | wps 6028 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.516 | train_wall 318 | gb_free 6.1 | wall 15913
KL Stats: Epoch 46 Divergences: Uniform: 2.3762587914718716 Unigram: 2.5776970364282357
2022-02-02 10:33:11 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:33:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:37:52 | INFO | train_inner | epoch 047:     56 / 64 loss=7.777, ppl=219.31, wps=6208.4, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.505, train_wall=497, gb_free=6.1, wall=16193
2022-02-02 10:38:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:38:58 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.248 | ppl 607.85 | wps 8159.2 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.248
2022-02-02 10:38:58 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:38:58 | INFO | train | epoch 047 | loss 7.753 | ppl 215.66 | wps 6032.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.502 | train_wall 318 | gb_free 6.1 | wall 16259
KL Stats: Epoch 47 Divergences: Uniform: 2.3848202428551075 Unigram: 2.6113698149171873
2022-02-02 10:38:58 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:38:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:44:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:44:44 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.307 | ppl 633.55 | wps 8122 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.303
2022-02-02 10:44:44 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 10:44:44 | INFO | train | epoch 048 | loss 7.696 | ppl 207.3 | wps 6037.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.498 | train_wall 317 | gb_free 6.1 | wall 16605
KL Stats: Epoch 48 Divergences: Uniform: 2.3930872573463113 Unigram: 2.6307527797781938
2022-02-02 10:44:44 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 10:44:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:47:04 | INFO | train_inner | epoch 049:     28 / 64 loss=7.68, ppl=205.04, wps=5904.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.498, train_wall=496, gb_free=6.1, wall=16745
2022-02-02 10:50:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:50:30 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.307 | ppl 633.6 | wps 8137 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.303
2022-02-02 10:50:30 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 10:50:30 | INFO | train | epoch 049 | loss 7.642 | ppl 199.72 | wps 6032.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.513 | train_wall 318 | gb_free 6.1 | wall 16951
KL Stats: Epoch 49 Divergences: Uniform: 2.418129533436687 Unigram: 2.6610034429598426
2022-02-02 10:50:30 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 10:50:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:55:51 | INFO | train_inner | epoch 050:     64 / 64 loss=7.614, ppl=195.94, wps=6188.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.516, train_wall=497, gb_free=6.1, wall=17272
2022-02-02 10:55:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:56:18 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.332 | ppl 644.65 | wps 7980.6 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.303
2022-02-02 10:56:18 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 10:56:18 | INFO | train | epoch 050 | loss 7.585 | ppl 192.07 | wps 5998.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.51 | train_wall 319 | gb_free 6.1 | wall 17300
KL Stats: Epoch 50 Divergences: Uniform: 2.4366280339423465 Unigram: 2.6867596742263435
2022-02-02 10:56:18 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 10:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:01:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:02:08 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.329 | ppl 642.95 | wps 8004.6 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.303
2022-02-02 11:02:08 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 11:02:08 | INFO | train | epoch 051 | loss 7.531 | ppl 184.89 | wps 5973.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.498 | train_wall 321 | gb_free 6.1 | wall 17649
KL Stats: Epoch 51 Divergences: Uniform: 2.4510371443752286 Unigram: 2.7147249418843655
2022-02-02 11:02:08 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 11:02:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:05:10 | INFO | train_inner | epoch 052:     36 / 64 loss=7.508, ppl=181.97, wps=5845, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.501, train_wall=502, gb_free=6.1, wall=17831
2022-02-02 11:07:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 11:07:57 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.36 | ppl 657.01 | wps 8000.5 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.303
2022-02-02 11:07:57 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 11:07:57 | INFO | train | epoch 052 | loss 7.48 | ppl 178.48 | wps 5972.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.514 | train_wall 321 | gb_free 6.1 | wall 17999
KL Stats: Epoch 52 Divergences: Uniform: 2.4592739182263545 Unigram: 2.7333353282185167
2022-02-02 11:07:57 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 11:07:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:13:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:13:47 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.381 | ppl 666.68 | wps 7978.1 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.303
2022-02-02 11:13:47 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 11:13:47 | INFO | train | epoch 053 | loss 7.428 | ppl 172.16 | wps 5976 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.504 | train_wall 320 | gb_free 6.1 | wall 18348
KL Stats: Epoch 53 Divergences: Uniform: 2.4739653628188876 Unigram: 2.758492874771132
2022-02-02 11:13:47 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 11:13:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:14:27 | INFO | train_inner | epoch 054:      8 / 64 loss=7.437, ppl=173.31, wps=5845.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.509, train_wall=500, gb_free=6.1, wall=18389
2022-02-02 11:19:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:19:37 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.336 | ppl 646.12 | wps 7998.7 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.303
2022-02-02 11:19:37 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:19:37 | INFO | train | epoch 054 | loss 7.377 | ppl 166.19 | wps 5960.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.504 | train_wall 321 | gb_free 6.1 | wall 18699
KL Stats: Epoch 54 Divergences: Uniform: 2.495861471360702 Unigram: 2.779338036650189
2022-02-02 11:19:37 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:19:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:23:20 | INFO | train_inner | epoch 055:     44 / 64 loss=7.355, ppl=163.7, wps=6132.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.515, train_wall=503, gb_free=6.1, wall=18922
2022-02-02 11:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:25:28 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.408 | ppl 679.26 | wps 8011.1 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.303
2022-02-02 11:25:28 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:25:28 | INFO | train | epoch 055 | loss 7.327 | ppl 160.62 | wps 5958.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.516 | train_wall 322 | gb_free 6.1 | wall 19049
KL Stats: Epoch 55 Divergences: Uniform: 2.505052756691741 Unigram: 2.799903813437044
2022-02-02 11:25:28 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:25:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:30:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:31:17 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.372 | ppl 662.7 | wps 8091 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.303
2022-02-02 11:31:17 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:31:17 | INFO | train | epoch 056 | loss 7.278 | ppl 155.17 | wps 5974.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.519 | train_wall 321 | gb_free 6.1 | wall 19399
KL Stats: Epoch 56 Divergences: Uniform: 2.5234094088309296 Unigram: 2.8262471387611723
2022-02-02 11:31:17 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:31:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:32:38 | INFO | train_inner | epoch 057:     16 / 64 loss=7.276, ppl=155.01, wps=5843.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.513, train_wall=501, gb_free=6.1, wall=19480
2022-02-02 11:36:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:37:05 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.394 | ppl 672.64 | wps 8095.8 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.303
2022-02-02 11:37:05 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:37:05 | INFO | train | epoch 057 | loss 7.231 | ppl 150.26 | wps 6014.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.523 | train_wall 319 | gb_free 6.1 | wall 19746
KL Stats: Epoch 57 Divergences: Uniform: 2.5341100536131402 Unigram: 2.8479982023497343
2022-02-02 11:37:05 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:37:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:41:25 | INFO | train_inner | epoch 058:     52 / 64 loss=7.21, ppl=148.1, wps=6203.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.521, train_wall=497, gb_free=6.1, wall=20007
2022-02-02 11:42:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:42:51 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.455 | ppl 701.78 | wps 8126.9 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.303
2022-02-02 11:42:51 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 11:42:51 | INFO | train | epoch 058 | loss 7.184 | ppl 145.45 | wps 6036.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.52 | train_wall 317 | gb_free 6.1 | wall 20092
KL Stats: Epoch 58 Divergences: Uniform: 2.5493977149221774 Unigram: 2.8722067933266713
2022-02-02 11:42:51 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 11:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:48:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:48:37 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.416 | ppl 682.91 | wps 8071.4 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.303
2022-02-02 11:48:37 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 11:48:37 | INFO | train | epoch 059 | loss 7.139 | ppl 140.99 | wps 6032.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.525 | train_wall 318 | gb_free 6.1 | wall 20438
KL Stats: Epoch 59 Divergences: Uniform: 2.568026379802414 Unigram: 2.8903652007877167
2022-02-02 11:48:37 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 11:48:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:50:37 | INFO | train_inner | epoch 060:     24 / 64 loss=7.124, ppl=139.5, wps=5905.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.526, train_wall=496, gb_free=6.1, wall=20559
2022-02-02 11:53:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:54:23 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.491 | ppl 719.36 | wps 8125.4 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.303
2022-02-02 11:54:23 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 11:54:23 | INFO | train | epoch 060 | loss 7.094 | ppl 136.66 | wps 6037 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.534 | train_wall 317 | gb_free 6.1 | wall 20784
KL Stats: Epoch 60 Divergences: Uniform: 2.572270178763114 Unigram: 2.9175970229476067
2022-02-02 11:54:23 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 11:54:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:59:23 | INFO | train_inner | epoch 061:     60 / 64 loss=7.083, ppl=135.55, wps=6212.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.529, train_wall=497, gb_free=6.1, wall=21085
2022-02-02 11:59:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:00:09 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.453 | ppl 700.63 | wps 8090.4 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.303
2022-02-02 12:00:09 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 12:00:09 | INFO | train | epoch 061 | loss 7.052 | ppl 132.66 | wps 6037.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.526 | train_wall 317 | gb_free 6.1 | wall 21130
KL Stats: Epoch 61 Divergences: Uniform: 2.588375898768412 Unigram: 2.9320288911904964
2022-02-02 12:00:09 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 12:00:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:05:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:05:55 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.581 | ppl 766.06 | wps 8138.6 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.303
2022-02-02 12:05:55 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 12:05:55 | INFO | train | epoch 062 | loss 7.008 | ppl 128.7 | wps 6035.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.533 | train_wall 318 | gb_free 6.1 | wall 21476
KL Stats: Epoch 62 Divergences: Uniform: 2.599653647520571 Unigram: 2.9533255308720996
2022-02-02 12:05:55 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 12:05:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:08:35 | INFO | train_inner | epoch 063:     32 / 64 loss=6.985, ppl=126.69, wps=5907.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.536, train_wall=495, gb_free=6.1, wall=21637
2022-02-02 12:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:11:41 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.527 | ppl 737.53 | wps 8113.4 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.303
2022-02-02 12:11:41 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 12:11:41 | INFO | train | epoch 063 | loss 6.965 | ppl 124.97 | wps 6038.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.537 | train_wall 317 | gb_free 6.1 | wall 21822
KL Stats: Epoch 63 Divergences: Uniform: 2.61705474720179 Unigram: 2.9680666120328536
2022-02-02 12:11:41 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 12:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:17:26 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.515 | ppl 731.82 | wps 8123.8 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.303
2022-02-02 12:17:26 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 12:17:26 | INFO | train | epoch 064 | loss 6.922 | ppl 121.27 | wps 6042.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.54 | train_wall 317 | gb_free 6.1 | wall 22168
KL Stats: Epoch 64 Divergences: Uniform: 2.6387561160196373 Unigram: 2.9903202451603494
2022-02-02 12:17:26 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 12:17:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:17:46 | INFO | train_inner | epoch 065:      4 / 64 loss=6.946, ppl=123.31, wps=5910, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.539, train_wall=495, gb_free=6.1, wall=22188
2022-02-02 12:22:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:23:12 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.583 | ppl 766.89 | wps 8137.4 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.303
2022-02-02 12:23:12 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:23:12 | INFO | train | epoch 065 | loss 6.882 | ppl 117.98 | wps 6039.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.547 | train_wall 317 | gb_free 6.1 | wall 22514
KL Stats: Epoch 65 Divergences: Uniform: 2.6464577241839167 Unigram: 3.0200671567633264
2022-02-02 12:23:12 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:23:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:26:32 | INFO | train_inner | epoch 066:     40 / 64 loss=6.854, ppl=115.66, wps=6215.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.537, train_wall=496, gb_free=6.1, wall=22714
2022-02-02 12:28:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:28:58 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.542 | ppl 745.67 | wps 8130.6 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.303
2022-02-02 12:28:58 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:28:58 | INFO | train | epoch 066 | loss 6.838 | ppl 114.41 | wps 6040 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.533 | train_wall 317 | gb_free 6.1 | wall 22860
KL Stats: Epoch 66 Divergences: Uniform: 2.653026814043813 Unigram: 3.035840485077988
2022-02-02 12:28:58 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:28:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:34:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:34:44 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.525 | ppl 736.79 | wps 8173.9 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.303
2022-02-02 12:34:44 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:34:44 | INFO | train | epoch 067 | loss 6.799 | ppl 111.37 | wps 6041.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.543 | train_wall 317 | gb_free 6.1 | wall 23205
KL Stats: Epoch 67 Divergences: Uniform: 2.6601140450436542 Unigram: 3.0587048708360776
2022-02-02 12:34:44 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:35:44 | INFO | train_inner | epoch 068:     12 / 64 loss=6.808, ppl=112.08, wps=5912, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.544, train_wall=495, gb_free=6.1, wall=23265
2022-02-02 12:40:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:40:29 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.543 | ppl 746.11 | wps 8117.8 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.303
2022-02-02 12:40:29 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 12:40:29 | INFO | train | epoch 068 | loss 6.761 | ppl 108.45 | wps 6045.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.549 | train_wall 317 | gb_free 6.1 | wall 23551
KL Stats: Epoch 68 Divergences: Uniform: 2.681749962934959 Unigram: 3.0757578685978917
2022-02-02 12:40:29 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 12:40:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:44:29 | INFO | train_inner | epoch 069:     48 / 64 loss=6.737, ppl=106.7, wps=6220.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.549, train_wall=496, gb_free=6.1, wall=23791
2022-02-02 12:45:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:46:14 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.583 | ppl 767.04 | wps 8150.7 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.303
2022-02-02 12:46:14 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 12:46:14 | INFO | train | epoch 069 | loss 6.721 | ppl 105.52 | wps 6050.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.551 | train_wall 317 | gb_free 6.1 | wall 23896
KL Stats: Epoch 69 Divergences: Uniform: 2.6960078965173104 Unigram: 3.1003992880284916
2022-02-02 12:46:14 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 12:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:51:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:52:04 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.634 | ppl 794.45 | wps 8024.3 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.303
2022-02-02 12:52:04 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 12:52:04 | INFO | train | epoch 070 | loss 6.687 | ppl 103.06 | wps 5974.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.568 | train_wall 321 | gb_free 6.1 | wall 24246
KL Stats: Epoch 70 Divergences: Uniform: 2.6907785754705396 Unigram: 3.099387016922857
2022-02-02 12:52:04 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 12:52:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:53:45 | INFO | train_inner | epoch 071:     20 / 64 loss=6.687, ppl=103.02, wps=5859.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.565, train_wall=500, gb_free=6.1, wall=24347
2022-02-02 12:57:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:57:54 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.696 | ppl 829.48 | wps 7983.2 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.303
2022-02-02 12:57:54 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 12:57:54 | INFO | train | epoch 071 | loss 6.65 | ppl 100.43 | wps 5967.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.547 | train_wall 321 | gb_free 6.1 | wall 24596
KL Stats: Epoch 71 Divergences: Uniform: 2.7062309577737023 Unigram: 3.1210015808483043
2022-02-02 12:57:54 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 12:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:02:34 | INFO | train_inner | epoch 072:     56 / 64 loss=6.635, ppl=99.38, wps=6178.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.551, train_wall=499, gb_free=6.1, wall=24876
2022-02-02 13:03:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:03:40 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.595 | ppl 773.52 | wps 8163.7 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.303
2022-02-02 13:03:40 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 13:03:40 | INFO | train | epoch 072 | loss 6.617 | ppl 98.15 | wps 6041.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.56 | train_wall 317 | gb_free 6.1 | wall 24941
KL Stats: Epoch 72 Divergences: Uniform: 2.7212334903568043 Unigram: 3.157355108739427
2022-02-02 13:03:40 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 13:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:09:25 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.71 | ppl 837.54 | wps 8124.2 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.303
2022-02-02 13:09:25 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 13:09:25 | INFO | train | epoch 073 | loss 6.582 | ppl 95.79 | wps 6042.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.562 | train_wall 317 | gb_free 6.1 | wall 25287
KL Stats: Epoch 73 Divergences: Uniform: 2.720875585126813 Unigram: 3.1689698930004675
2022-02-02 13:09:25 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 13:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:11:45 | INFO | train_inner | epoch 074:     28 / 64 loss=6.57, ppl=95.02, wps=5914.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.563, train_wall=495, gb_free=6.1, wall=25427
2022-02-02 13:14:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:15:11 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.749 | ppl 860.49 | wps 8114.5 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.303
2022-02-02 13:15:11 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 13:15:11 | INFO | train | epoch 074 | loss 6.553 | ppl 93.89 | wps 6043.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.575 | train_wall 317 | gb_free 6.1 | wall 25633
KL Stats: Epoch 74 Divergences: Uniform: 2.729594180491888 Unigram: 3.1927412634577372
2022-02-02 13:15:11 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 13:15:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:20:30 | INFO | train_inner | epoch 075:     64 / 64 loss=6.544, ppl=93.29, wps=6217.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.572, train_wall=495, gb_free=6.1, wall=25951
2022-02-02 13:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:20:57 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.698 | ppl 830.55 | wps 8095.8 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.303
2022-02-02 13:20:57 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 13:20:57 | INFO | train | epoch 075 | loss 6.519 | ppl 91.74 | wps 6040.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.567 | train_wall 317 | gb_free 6.1 | wall 25978
KL Stats: Epoch 75 Divergences: Uniform: 2.7480623197195744 Unigram: 3.201937106573153
2022-02-02 13:20:57 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 13:20:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:26:42 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.713 | ppl 839.06 | wps 8095.5 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.303
2022-02-02 13:26:42 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:26:42 | INFO | train | epoch 076 | loss 6.49 | ppl 89.91 | wps 6040.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.58 | train_wall 317 | gb_free 6.1 | wall 26324
KL Stats: Epoch 76 Divergences: Uniform: 2.7570905965855004 Unigram: 3.2224627557035768
2022-02-02 13:26:43 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:26:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:29:43 | INFO | train_inner | epoch 077:     36 / 64 loss=6.467, ppl=88.44, wps=5912.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.574, train_wall=496, gb_free=6.1, wall=26504
2022-02-02 13:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:32:28 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.687 | ppl 824.03 | wps 8168.9 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.303
2022-02-02 13:32:28 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:32:28 | INFO | train | epoch 077 | loss 6.459 | ppl 87.97 | wps 6040.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.576 | train_wall 317 | gb_free 6.1 | wall 26670
KL Stats: Epoch 77 Divergences: Uniform: 2.770087462978473 Unigram: 3.239769577292194
2022-02-02 13:32:28 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:32:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:38:13 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.679 | ppl 819.99 | wps 8139.1 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.303
2022-02-02 13:38:13 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 13:38:13 | INFO | train | epoch 078 | loss 6.43 | ppl 86.24 | wps 6054.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.585 | train_wall 317 | gb_free 6.1 | wall 27015
KL Stats: Epoch 78 Divergences: Uniform: 2.7730613305099903 Unigram: 3.263274755998553
2022-02-02 13:38:13 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 13:38:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:38:53 | INFO | train_inner | epoch 079:      8 / 64 loss=6.444, ppl=87.05, wps=5918.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.585, train_wall=495, gb_free=6.1, wall=27055
2022-02-02 13:43:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:43:58 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.736 | ppl 852.58 | wps 8152 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.303
2022-02-02 13:43:58 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 13:43:58 | INFO | train | epoch 079 | loss 6.401 | ppl 84.54 | wps 6050.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.579 | train_wall 317 | gb_free 6.1 | wall 27360
KL Stats: Epoch 79 Divergences: Uniform: 2.7835643729579433 Unigram: 3.274233667997588
2022-02-02 13:43:58 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 13:43:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:47:38 | INFO | train_inner | epoch 080:     44 / 64 loss=6.389, ppl=83.83, wps=6227.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.59, train_wall=495, gb_free=6.1, wall=27580
2022-02-02 13:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:49:44 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.662 | ppl 810.1 | wps 8149.8 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.303
2022-02-02 13:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 13:49:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint80.pt
2022-02-02 13:49:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint80.pt
2022-02-02 13:49:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.662) (writing took 3.1534300060011446 seconds)
2022-02-02 13:49:47 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 13:49:47 | INFO | train | epoch 080 | loss 6.377 | ppl 83.11 | wps 5995 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.596 | train_wall 317 | gb_free 6.1 | wall 27709
KL Stats: Epoch 80 Divergences: Uniform: 2.7944755574305535 Unigram: 3.2954564005652376
2022-02-02 13:49:47 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 13:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:55:32 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.826 | ppl 907.63 | wps 8130.5 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.303
2022-02-02 13:55:32 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 13:55:32 | INFO | train | epoch 081 | loss 6.349 | ppl 81.53 | wps 6052 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.597 | train_wall 317 | gb_free 6.1 | wall 28054
KL Stats: Epoch 81 Divergences: Uniform: 2.7910651098184465 Unigram: 3.3122973829388775
2022-02-02 13:55:32 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 13:55:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:56:52 | INFO | train_inner | epoch 082:     16 / 64 loss=6.347, ppl=81.4, wps=5884.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.595, train_wall=495, gb_free=6.1, wall=28134
2022-02-02 14:00:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:01:18 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.731 | ppl 849.95 | wps 8129 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.303
2022-02-02 14:01:18 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 14:01:18 | INFO | train | epoch 082 | loss 6.324 | ppl 80.1 | wps 6036 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.6 | train_wall 318 | gb_free 6.1 | wall 28400
KL Stats: Epoch 82 Divergences: Uniform: 2.8079353600039356 Unigram: 3.3345803746741134
2022-02-02 14:01:18 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 14:01:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:05:38 | INFO | train_inner | epoch 083:     52 / 64 loss=6.315, ppl=79.64, wps=6217, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.605, train_wall=496, gb_free=6.1, wall=28660
2022-02-02 14:06:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:07:03 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.772 | ppl 874.2 | wps 8154.1 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.303
2022-02-02 14:07:03 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 14:07:03 | INFO | train | epoch 083 | loss 6.3 | ppl 78.82 | wps 6048 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.605 | train_wall 317 | gb_free 6.1 | wall 28745
KL Stats: Epoch 83 Divergences: Uniform: 2.805832729729027 Unigram: 3.3375319103320544
2022-02-02 14:07:03 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 14:07:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:12:49 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.849 | ppl 922.34 | wps 8094.4 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.303
2022-02-02 14:12:49 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 14:12:49 | INFO | train | epoch 084 | loss 6.273 | ppl 77.33 | wps 6049.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.604 | train_wall 317 | gb_free 6.1 | wall 29090
KL Stats: Epoch 84 Divergences: Uniform: 2.8165133063972023 Unigram: 3.361078464450489
2022-02-02 14:12:49 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 14:12:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:14:48 | INFO | train_inner | epoch 085:     24 / 64 loss=6.264, ppl=76.84, wps=5920.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.599, train_wall=494, gb_free=6.1, wall=29210
2022-02-02 14:18:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:18:34 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.858 | ppl 927.86 | wps 8109.8 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.303
2022-02-02 14:18:34 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 14:18:34 | INFO | train | epoch 085 | loss 6.25 | ppl 76.09 | wps 6048.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.606 | train_wall 317 | gb_free 6.1 | wall 29436
KL Stats: Epoch 85 Divergences: Uniform: 2.821245932441471 Unigram: 3.378795733623276
2022-02-02 14:18:34 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 14:18:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:23:34 | INFO | train_inner | epoch 086:     60 / 64 loss=6.246, ppl=75.9, wps=6221.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.616, train_wall=496, gb_free=6.1, wall=29735
2022-02-02 14:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:24:19 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.855 | ppl 926.32 | wps 8155.1 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.303
2022-02-02 14:24:19 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 14:24:19 | INFO | train | epoch 086 | loss 6.227 | ppl 74.88 | wps 6048.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.614 | train_wall 317 | gb_free 6.1 | wall 29781
KL Stats: Epoch 86 Divergences: Uniform: 2.827235299007553 Unigram: 3.3878488342760935
2022-02-02 14:24:19 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 14:24:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:30:05 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.851 | ppl 923.24 | wps 8087.6 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.303
2022-02-02 14:30:05 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:30:05 | INFO | train | epoch 087 | loss 6.204 | ppl 73.71 | wps 6034 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.609 | train_wall 317 | gb_free 6.1 | wall 30127
KL Stats: Epoch 87 Divergences: Uniform: 2.8387999589634747 Unigram: 3.4130019466452635
2022-02-02 14:30:05 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:30:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:32:46 | INFO | train_inner | epoch 088:     32 / 64 loss=6.188, ppl=72.9, wps=5904.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.612, train_wall=496, gb_free=6.1, wall=30288
2022-02-02 14:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:35:52 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.816 | ppl 901.08 | wps 8080.1 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.303
2022-02-02 14:35:52 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 14:35:52 | INFO | train | epoch 088 | loss 6.184 | ppl 72.69 | wps 6023.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.628 | train_wall 318 | gb_free 6.1 | wall 30474
KL Stats: Epoch 88 Divergences: Uniform: 2.846804316288304 Unigram: 3.422570051217788
2022-02-02 14:35:52 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 14:35:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:41:38 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.855 | ppl 925.91 | wps 8140.8 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.303
2022-02-02 14:41:38 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 14:41:38 | INFO | train | epoch 089 | loss 6.162 | ppl 71.62 | wps 6041.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.634 | train_wall 317 | gb_free 6.1 | wall 30819
KL Stats: Epoch 89 Divergences: Uniform: 2.8534486837721484 Unigram: 3.4330400138021946
2022-02-02 14:41:38 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 14:41:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:41:58 | INFO | train_inner | epoch 090:      4 / 64 loss=6.178, ppl=72.39, wps=5905.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.636, train_wall=496, gb_free=6.1, wall=30839
2022-02-02 14:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:47:23 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.807 | ppl 895.68 | wps 8146.9 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.303
2022-02-02 14:47:23 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 14:47:23 | INFO | train | epoch 090 | loss 6.138 | ppl 70.42 | wps 6052.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.625 | train_wall 317 | gb_free 6.1 | wall 31165
KL Stats: Epoch 90 Divergences: Uniform: 2.8529720476771057 Unigram: 3.4476593398963193
2022-02-02 14:47:23 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 14:47:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:50:42 | INFO | train_inner | epoch 091:     40 / 64 loss=6.123, ppl=69.7, wps=6231, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.632, train_wall=495, gb_free=6.1, wall=31364
2022-02-02 14:52:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:53:08 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.814 | ppl 900.06 | wps 8134.7 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.303
2022-02-02 14:53:08 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 14:53:08 | INFO | train | epoch 091 | loss 6.12 | ppl 69.54 | wps 6057.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.636 | train_wall 316 | gb_free 6.1 | wall 31509
KL Stats: Epoch 91 Divergences: Uniform: 2.8630302341789657 Unigram: 3.4659499681847814
2022-02-02 14:53:08 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 14:53:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:58:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:58:53 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.878 | ppl 940.93 | wps 8134.3 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.303
2022-02-02 14:58:53 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 14:58:53 | INFO | train | epoch 092 | loss 6.097 | ppl 68.47 | wps 6050.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.636 | train_wall 317 | gb_free 6.1 | wall 31855
KL Stats: Epoch 92 Divergences: Uniform: 2.8673137829031776 Unigram: 3.4818850234514653
2022-02-02 14:58:53 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 14:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:59:53 | INFO | train_inner | epoch 093:     12 / 64 loss=6.102, ppl=68.7, wps=5921.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.632, train_wall=494, gb_free=6.1, wall=31914
2022-02-02 15:04:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:04:38 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.829 | ppl 909.69 | wps 8140.4 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.303
2022-02-02 15:04:38 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 15:04:38 | INFO | train | epoch 093 | loss 6.081 | ppl 67.7 | wps 6046.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.664 | train_wall 317 | gb_free 6.1 | wall 32200
KL Stats: Epoch 93 Divergences: Uniform: 2.881664733171357 Unigram: 3.4887953388706823
2022-02-02 15:04:38 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 15:04:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:08:38 | INFO | train_inner | epoch 094:     48 / 64 loss=6.069, ppl=67.14, wps=6216.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.652, train_wall=496, gb_free=6.1, wall=32440
2022-02-02 15:09:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:10:24 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.865 | ppl 932.51 | wps 8124.4 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.303
2022-02-02 15:10:24 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 15:10:24 | INFO | train | epoch 094 | loss 6.058 | ppl 66.61 | wps 6038.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.642 | train_wall 317 | gb_free 6.1 | wall 32546
KL Stats: Epoch 94 Divergences: Uniform: 2.8801038331896582 Unigram: 3.507897540192788
2022-02-02 15:10:24 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 15:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:15:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:16:09 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.865 | ppl 932.8 | wps 8160.7 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.303
2022-02-02 15:16:09 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 15:16:09 | INFO | train | epoch 095 | loss 6.04 | ppl 65.79 | wps 6048 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.66 | train_wall 317 | gb_free 6.1 | wall 32891
KL Stats: Epoch 95 Divergences: Uniform: 2.8866506992209713 Unigram: 3.5189164845720167
2022-02-02 15:16:09 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 15:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:17:49 | INFO | train_inner | epoch 096:     20 / 64 loss=6.037, ppl=65.67, wps=5917.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.66, train_wall=495, gb_free=6.1, wall=32991
2022-02-02 15:21:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:21:55 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.91 | ppl 962.3 | wps 8100.7 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.303
2022-02-02 15:21:55 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 15:21:55 | INFO | train | epoch 096 | loss 6.021 | ppl 64.94 | wps 6049.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.655 | train_wall 317 | gb_free 6.1 | wall 33236
KL Stats: Epoch 96 Divergences: Uniform: 2.8884894951576134 Unigram: 3.5320769923557664
2022-02-02 15:21:55 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 15:21:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:26:35 | INFO | train_inner | epoch 097:     56 / 64 loss=6.019, ppl=64.84, wps=6214.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.66, train_wall=496, gb_free=6.1, wall=33517
2022-02-02 15:27:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:27:41 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.838 | ppl 915.28 | wps 8128.6 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.303
2022-02-02 15:27:41 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 15:27:41 | INFO | train | epoch 097 | loss 6.003 | ppl 64.11 | wps 6032.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.662 | train_wall 318 | gb_free 6.1 | wall 33583
KL Stats: Epoch 97 Divergences: Uniform: 2.8957036630450173 Unigram: 3.5441292090993746
2022-02-02 15:27:41 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 15:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:33:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:33:27 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.985 | ppl 1013.53 | wps 8095.5 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.303
2022-02-02 15:33:27 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 15:33:27 | INFO | train | epoch 098 | loss 5.984 | ppl 63.31 | wps 6038.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.664 | train_wall 317 | gb_free 6.1 | wall 33929
KL Stats: Epoch 98 Divergences: Uniform: 2.8936151522718108 Unigram: 3.551782057436635
2022-02-02 15:33:27 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 15:33:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:35:47 | INFO | train_inner | epoch 099:     28 / 64 loss=5.974, ppl=62.84, wps=5907.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.681, train_wall=495, gb_free=6.1, wall=34069
2022-02-02 15:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:39:13 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.925 | ppl 972.26 | wps 8138.5 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.303
2022-02-02 15:39:13 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 15:39:13 | INFO | train | epoch 099 | loss 5.969 | ppl 62.62 | wps 6034 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.696 | train_wall 318 | gb_free 6.1 | wall 34275
KL Stats: Epoch 99 Divergences: Uniform: 2.9026523687233143 Unigram: 3.5764214318432495
2022-02-02 15:39:13 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 15:39:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:44:32 | INFO | train_inner | epoch 100:     64 / 64 loss=5.969, ppl=62.64, wps=6209.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.681, train_wall=496, gb_free=6.1, wall=34594
2022-02-02 15:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:44:59 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.871 | ppl 936.6 | wps 8109.7 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.303
2022-02-02 15:44:59 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 15:44:59 | INFO | train | epoch 100 | loss 5.952 | ppl 61.89 | wps 6034.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.684 | train_wall 318 | gb_free 6.1 | wall 34621
KL Stats: Epoch 100 Divergences: Uniform: 2.91093838865684 Unigram: 3.5886090871655987
2022-02-02 15:44:59 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 15:44:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:50:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:50:45 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.893 | ppl 950.62 | wps 8092.3 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.303
2022-02-02 15:50:45 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 15:50:45 | INFO | train | epoch 101 | loss 5.933 | ppl 61.09 | wps 6036 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.686 | train_wall 317 | gb_free 6.1 | wall 34967
KL Stats: Epoch 101 Divergences: Uniform: 2.914635448417714 Unigram: 3.597451829613975
2022-02-02 15:50:45 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 15:50:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:53:46 | INFO | train_inner | epoch 102:     36 / 64 loss=5.916, ppl=60.39, wps=5906.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.686, train_wall=497, gb_free=6.1, wall=35147
2022-02-02 15:56:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:56:32 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.935 | ppl 978.69 | wps 8092.9 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.303
2022-02-02 15:56:32 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 15:56:32 | INFO | train | epoch 102 | loss 5.918 | ppl 60.45 | wps 6028.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.683 | train_wall 318 | gb_free 6.1 | wall 35313
KL Stats: Epoch 102 Divergences: Uniform: 2.923171222659677 Unigram: 3.6138975166290326
2022-02-02 15:56:32 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 15:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:01:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:02:17 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.877 | ppl 940.54 | wps 8107.1 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.303
2022-02-02 16:02:17 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 16:02:17 | INFO | train | epoch 103 | loss 5.903 | ppl 59.85 | wps 6041 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.705 | train_wall 317 | gb_free 6.1 | wall 35659
KL Stats: Epoch 103 Divergences: Uniform: 2.931135999431517 Unigram: 3.6171010295073827
2022-02-02 16:02:17 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 16:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:02:57 | INFO | train_inner | epoch 104:      8 / 64 loss=5.913, ppl=60.25, wps=5906.4, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.699, train_wall=495, gb_free=6.1, wall=35699
2022-02-02 16:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:08:03 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.85 | ppl 923.05 | wps 8098.1 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.303
2022-02-02 16:08:03 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 16:08:03 | INFO | train | epoch 104 | loss 5.886 | ppl 59.14 | wps 6042 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.702 | train_wall 317 | gb_free 6.1 | wall 36005
KL Stats: Epoch 104 Divergences: Uniform: 2.924675218698135 Unigram: 3.6292091334495766
2022-02-02 16:08:03 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 16:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:11:43 | INFO | train_inner | epoch 105:     44 / 64 loss=5.875, ppl=58.7, wps=6214.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.708, train_wall=496, gb_free=6.1, wall=36225
2022-02-02 16:13:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:13:49 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.93 | ppl 975.58 | wps 8137.9 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.303
2022-02-02 16:13:49 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 16:13:49 | INFO | train | epoch 105 | loss 5.87 | ppl 58.47 | wps 6036.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.712 | train_wall 318 | gb_free 6.1 | wall 36351
KL Stats: Epoch 105 Divergences: Uniform: 2.9359806848535315 Unigram: 3.6511297645010106
2022-02-02 16:13:49 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 16:13:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:19:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:19:34 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.947 | ppl 987.03 | wps 8164.6 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.303
2022-02-02 16:19:34 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 16:19:34 | INFO | train | epoch 106 | loss 5.858 | ppl 58.01 | wps 6050.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.719 | train_wall 317 | gb_free 6.1 | wall 36696
KL Stats: Epoch 106 Divergences: Uniform: 2.936236316343969 Unigram: 3.660547016040516
2022-02-02 16:19:34 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 16:19:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:20:54 | INFO | train_inner | epoch 107:     16 / 64 loss=5.854, ppl=57.83, wps=5917.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.711, train_wall=495, gb_free=6.1, wall=36776
2022-02-02 16:24:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:25:20 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.953 | ppl 991.47 | wps 8079.8 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.303
2022-02-02 16:25:20 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 16:25:20 | INFO | train | epoch 107 | loss 5.84 | ppl 57.29 | wps 6035.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.718 | train_wall 317 | gb_free 6.1 | wall 37042
KL Stats: Epoch 107 Divergences: Uniform: 2.933515840670928 Unigram: 3.6723538581604327
2022-02-02 16:25:20 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 16:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:29:41 | INFO | train_inner | epoch 108:     52 / 64 loss=5.839, ppl=57.25, wps=6207.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.724, train_wall=497, gb_free=6.1, wall=37302
2022-02-02 16:30:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:31:06 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.996 | ppl 1021.46 | wps 8118.8 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.303
2022-02-02 16:31:06 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 16:31:06 | INFO | train | epoch 108 | loss 5.827 | ppl 56.75 | wps 6035.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.723 | train_wall 318 | gb_free 6.1 | wall 37388
KL Stats: Epoch 108 Divergences: Uniform: 2.932494019170999 Unigram: 3.6780601730888494
2022-02-02 16:31:06 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 16:31:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:36:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:36:53 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.007 | ppl 1028.71 | wps 8108.1 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.303
2022-02-02 16:36:53 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 16:36:53 | INFO | train | epoch 109 | loss 5.814 | ppl 56.24 | wps 6028.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.743 | train_wall 318 | gb_free 6.1 | wall 37734
KL Stats: Epoch 109 Divergences: Uniform: 2.9458331369687016 Unigram: 3.6996515858612535
2022-02-02 16:36:53 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 16:36:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:38:53 | INFO | train_inner | epoch 110:     24 / 64 loss=5.803, ppl=55.84, wps=5902.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.737, train_wall=496, gb_free=6.1, wall=37855
2022-02-02 16:42:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:42:39 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.955 | ppl 992.55 | wps 8111.4 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.303
2022-02-02 16:42:39 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 16:42:39 | INFO | train | epoch 110 | loss 5.797 | ppl 55.61 | wps 6040.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.727 | train_wall 317 | gb_free 6.1 | wall 38080
KL Stats: Epoch 110 Divergences: Uniform: 2.952625939436505 Unigram: 3.700920016301033
2022-02-02 16:42:39 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 16:42:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:47:39 | INFO | train_inner | epoch 111:     60 / 64 loss=5.801, ppl=55.77, wps=6211.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.729, train_wall=497, gb_free=6.1, wall=38381
2022-02-02 16:47:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:48:25 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.991 | ppl 1017.32 | wps 8067.1 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.303
2022-02-02 16:48:25 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 16:48:25 | INFO | train | epoch 111 | loss 5.785 | ppl 55.13 | wps 6028.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.737 | train_wall 318 | gb_free 6.1 | wall 38427
KL Stats: Epoch 111 Divergences: Uniform: 2.951412927294857 Unigram: 3.710883818887574
2022-02-02 16:48:25 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 16:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:53:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:54:12 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.951 | ppl 989.82 | wps 8087.4 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.303
2022-02-02 16:54:12 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 16:54:12 | INFO | train | epoch 112 | loss 5.77 | ppl 54.58 | wps 6025.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.733 | train_wall 318 | gb_free 6.1 | wall 38773
KL Stats: Epoch 112 Divergences: Uniform: 2.963892765273743 Unigram: 3.725222471815398
2022-02-02 16:54:12 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 16:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:56:52 | INFO | train_inner | epoch 113:     32 / 64 loss=5.759, ppl=54.16, wps=5892.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.733, train_wall=497, gb_free=6.1, wall=38934
2022-02-02 16:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:59:59 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.025 | ppl 1042.21 | wps 8058.8 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.303
2022-02-02 16:59:59 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 16:59:59 | INFO | train | epoch 113 | loss 5.758 | ppl 54.1 | wps 6015 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.739 | train_wall 318 | gb_free 6.1 | wall 39121
KL Stats: Epoch 113 Divergences: Uniform: 2.96287893688102 Unigram: 3.732750862585509
2022-02-02 16:59:59 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 16:59:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:05:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:05:46 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.983 | ppl 1011.73 | wps 8081.9 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.303
2022-02-02 17:05:46 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 17:05:46 | INFO | train | epoch 114 | loss 5.745 | ppl 53.64 | wps 6021 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.756 | train_wall 318 | gb_free 6.1 | wall 39467
KL Stats: Epoch 114 Divergences: Uniform: 2.9616261127521026 Unigram: 3.740791684830924
2022-02-02 17:05:46 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 17:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:06:06 | INFO | train_inner | epoch 115:      4 / 64 loss=5.755, ppl=53.99, wps=5889, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.754, train_wall=497, gb_free=6.1, wall=39488
2022-02-02 17:11:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:11:36 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.988 | ppl 1015.42 | wps 7978.1 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.303
2022-02-02 17:11:36 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 17:11:36 | INFO | train | epoch 115 | loss 5.732 | ppl 53.16 | wps 5967.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.763 | train_wall 321 | gb_free 6.1 | wall 39817
KL Stats: Epoch 115 Divergences: Uniform: 2.9671014545760683 Unigram: 3.7481422726969376
2022-02-02 17:11:36 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 17:11:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:14:59 | INFO | train_inner | epoch 116:     40 / 64 loss=5.722, ppl=52.78, wps=6135.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.756, train_wall=502, gb_free=6.1, wall=40020
2022-02-02 17:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:17:26 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 9.986 | ppl 1014 | wps 8016.2 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.303
2022-02-02 17:17:26 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 17:17:26 | INFO | train | epoch 116 | loss 5.72 | ppl 52.7 | wps 5961.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.744 | train_wall 321 | gb_free 6.1 | wall 40168
KL Stats: Epoch 116 Divergences: Uniform: 2.9738408506472163 Unigram: 3.7719580144073714
2022-02-02 17:17:26 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 17:17:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:22:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:23:17 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.068 | ppl 1073.66 | wps 7994.7 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.303
2022-02-02 17:23:17 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 17:23:17 | INFO | train | epoch 117 | loss 5.709 | ppl 52.31 | wps 5954.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.774 | train_wall 322 | gb_free 6.1 | wall 40519
KL Stats: Epoch 117 Divergences: Uniform: 2.976351017111733 Unigram: 3.774496745809258
2022-02-02 17:23:17 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 17:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:24:18 | INFO | train_inner | epoch 118:     12 / 64 loss=5.712, ppl=52.41, wps=5829.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.77, train_wall=502, gb_free=6.1, wall=40579
2022-02-02 17:28:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:29:07 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 9.951 | ppl 989.47 | wps 8011 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.303
2022-02-02 17:29:07 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 17:29:07 | INFO | train | epoch 118 | loss 5.695 | ppl 51.79 | wps 5962.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.789 | train_wall 321 | gb_free 6.1 | wall 40869
KL Stats: Epoch 118 Divergences: Uniform: 2.9752638645823986 Unigram: 3.789818998447694
2022-02-02 17:29:07 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 17:29:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:33:11 | INFO | train_inner | epoch 119:     48 / 64 loss=5.688, ppl=51.55, wps=6125.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.774, train_wall=503, gb_free=6.1, wall=41113
2022-02-02 17:34:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 17:34:58 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.973 | ppl 1004.94 | wps 8034.9 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.303
2022-02-02 17:34:58 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 17:34:58 | INFO | train | epoch 119 | loss 5.685 | ppl 51.43 | wps 5947.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.775 | train_wall 322 | gb_free 6.1 | wall 41220
KL Stats: Epoch 119 Divergences: Uniform: 2.9889297666308408 Unigram: 3.7948109321577306
2022-02-02 17:34:58 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 17:34:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:40:47 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.051 | ppl 1060.91 | wps 8016 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.303
2022-02-02 17:40:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 17:40:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint120.pt
2022-02-02 17:40:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint120.pt
2022-02-02 17:40:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.051) (writing took 2.8498690109699965 seconds)
2022-02-02 17:40:50 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 17:40:50 | INFO | train | epoch 120 | loss 5.668 | ppl 50.83 | wps 5939.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.756 | train_wall 320 | gb_free 6.1 | wall 41572
KL Stats: Epoch 120 Divergences: Uniform: 2.981798008606797 Unigram: 3.79940069764125
2022-02-02 17:40:50 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 17:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:42:31 | INFO | train_inner | epoch 121:     20 / 64 loss=5.666, ppl=50.77, wps=5822, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.773, train_wall=500, gb_free=6.1, wall=41673
2022-02-02 17:46:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:46:39 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 9.928 | ppl 973.96 | wps 8000.8 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.303
2022-02-02 17:46:39 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 17:46:39 | INFO | train | epoch 121 | loss 5.664 | ppl 50.69 | wps 5976.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.793 | train_wall 320 | gb_free 6.1 | wall 41921
KL Stats: Epoch 121 Divergences: Uniform: 2.988434487430456 Unigram: 3.8144856682365544
2022-02-02 17:46:39 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 17:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:51:20 | INFO | train_inner | epoch 122:     56 / 64 loss=5.664, ppl=50.7, wps=6182.5, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.788, train_wall=499, gb_free=6.1, wall=42202
2022-02-02 17:51:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:52:25 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.973 | ppl 1004.75 | wps 8110.5 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.303
2022-02-02 17:52:25 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 17:52:25 | INFO | train | epoch 122 | loss 5.649 | ppl 50.19 | wps 6036 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.788 | train_wall 317 | gb_free 6.1 | wall 42267
KL Stats: Epoch 122 Divergences: Uniform: 2.997340239157848 Unigram: 3.822475410068612
2022-02-02 17:52:25 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 17:52:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:58:11 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.02 | ppl 1038.65 | wps 8108.5 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.303
2022-02-02 17:58:11 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 17:58:11 | INFO | train | epoch 123 | loss 5.636 | ppl 49.74 | wps 6042.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.787 | train_wall 317 | gb_free 6.1 | wall 42613
KL Stats: Epoch 123 Divergences: Uniform: 2.991793734308777 Unigram: 3.8416513260131513
2022-02-02 17:58:11 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 17:58:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:00:31 | INFO | train_inner | epoch 124:     28 / 64 loss=5.63, ppl=49.52, wps=5914.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.789, train_wall=495, gb_free=6.1, wall=42753
2022-02-02 18:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:03:57 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 9.988 | ppl 1015.58 | wps 8122.3 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.303
2022-02-02 18:03:57 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 18:03:57 | INFO | train | epoch 124 | loss 5.627 | ppl 49.42 | wps 6045.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.797 | train_wall 317 | gb_free 6.1 | wall 42958
KL Stats: Epoch 124 Divergences: Uniform: 2.9962655144482784 Unigram: 3.843528636444742
2022-02-02 18:03:57 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 18:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:09:15 | INFO | train_inner | epoch 125:     64 / 64 loss=5.629, ppl=49.5, wps=6220.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.803, train_wall=495, gb_free=6.1, wall=43277
2022-02-02 18:09:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:09:42 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 9.949 | ppl 988.27 | wps 8110.7 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.303
2022-02-02 18:09:42 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 18:09:42 | INFO | train | epoch 125 | loss 5.618 | ppl 49.1 | wps 6047.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.798 | train_wall 317 | gb_free 6.1 | wall 43304
KL Stats: Epoch 125 Divergences: Uniform: 2.9989030417261575 Unigram: 3.8600908813612014
2022-02-02 18:09:42 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 18:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:15:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:15:28 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.06 | ppl 1067.79 | wps 8150.2 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.303
2022-02-02 18:15:28 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 18:15:28 | INFO | train | epoch 126 | loss 5.605 | ppl 48.67 | wps 6033.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.805 | train_wall 318 | gb_free 6.1 | wall 43650
KL Stats: Epoch 126 Divergences: Uniform: 2.9929822091256253 Unigram: 3.862719940070412
2022-02-02 18:15:28 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 18:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:18:28 | INFO | train_inner | epoch 127:     36 / 64 loss=5.592, ppl=48.23, wps=5908.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.814, train_wall=497, gb_free=6.1, wall=43830
2022-02-02 18:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:21:14 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.052 | ppl 1061.29 | wps 8132 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.303
2022-02-02 18:21:14 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 18:21:14 | INFO | train | epoch 127 | loss 5.596 | ppl 48.37 | wps 6045 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.839 | train_wall 317 | gb_free 6.1 | wall 43995
KL Stats: Epoch 127 Divergences: Uniform: 3.0020399298924 Unigram: 3.8675877354804324
2022-02-02 18:21:14 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 18:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:26:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:27:00 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.012 | ppl 1032.76 | wps 8117.9 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.303
2022-02-02 18:27:00 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 18:27:00 | INFO | train | epoch 128 | loss 5.584 | ppl 47.97 | wps 6031.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.82 | train_wall 318 | gb_free 6.1 | wall 44342
KL Stats: Epoch 128 Divergences: Uniform: 3.0007796497065597 Unigram: 3.881011698757126
2022-02-02 18:27:00 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 18:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:27:40 | INFO | train_inner | epoch 129:      8 / 64 loss=5.593, ppl=48.26, wps=5907, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.83, train_wall=496, gb_free=6.1, wall=44382
2022-02-02 18:32:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:32:46 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.009 | ppl 1030.36 | wps 8103.2 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.303
2022-02-02 18:32:46 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 18:32:46 | INFO | train | epoch 129 | loss 5.575 | ppl 47.67 | wps 6027.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.842 | train_wall 318 | gb_free 6.1 | wall 44688
KL Stats: Epoch 129 Divergences: Uniform: 3.0061238834289674 Unigram: 3.892458032725707
2022-02-02 18:32:46 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 18:32:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:36:27 | INFO | train_inner | epoch 130:     44 / 64 loss=5.564, ppl=47.31, wps=6201.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.838, train_wall=497, gb_free=6.1, wall=44909
2022-02-02 18:38:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:38:33 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.04 | ppl 1053.04 | wps 8133.6 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.303
2022-02-02 18:38:33 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 18:38:33 | INFO | train | epoch 130 | loss 5.565 | ppl 47.34 | wps 6028.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.848 | train_wall 318 | gb_free 6.1 | wall 45035
KL Stats: Epoch 130 Divergences: Uniform: 3.012454600425175 Unigram: 3.8992100617010435
2022-02-02 18:38:33 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 18:38:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:44:20 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.012 | ppl 1032.43 | wps 8065.5 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.303
2022-02-02 18:44:20 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 18:44:20 | INFO | train | epoch 131 | loss 5.553 | ppl 46.95 | wps 6015.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.831 | train_wall 318 | gb_free 6.1 | wall 45382
KL Stats: Epoch 131 Divergences: Uniform: 3.0157685942296393 Unigram: 3.903836258559348
2022-02-02 18:44:20 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 18:44:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:45:40 | INFO | train_inner | epoch 132:     16 / 64 loss=5.56, ppl=47.16, wps=5891, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.837, train_wall=497, gb_free=6.1, wall=45462
2022-02-02 18:49:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:50:07 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 9.982 | ppl 1011.37 | wps 8149.2 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.303
2022-02-02 18:50:07 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 18:50:07 | INFO | train | epoch 132 | loss 5.545 | ppl 46.69 | wps 6029.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.845 | train_wall 318 | gb_free 6.1 | wall 45728
KL Stats: Epoch 132 Divergences: Uniform: 3.0174164113816397 Unigram: 3.9124842866812077
2022-02-02 18:50:07 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 18:50:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:54:28 | INFO | train_inner | epoch 133:     52 / 64 loss=5.537, ppl=46.45, wps=6198.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.858, train_wall=498, gb_free=6.1, wall=45989
2022-02-02 18:55:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:55:54 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.006 | ppl 1028.61 | wps 8089.8 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.303
2022-02-02 18:55:54 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 18:55:54 | INFO | train | epoch 133 | loss 5.536 | ppl 46.41 | wps 6018.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.858 | train_wall 318 | gb_free 6.1 | wall 46075
KL Stats: Epoch 133 Divergences: Uniform: 3.024338860750939 Unigram: 3.9259420956604436
2022-02-02 18:55:54 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 18:55:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:01:40 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.086 | ppl 1086.89 | wps 8046.6 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.303
2022-02-02 19:01:40 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 19:01:40 | INFO | train | epoch 134 | loss 5.525 | ppl 46.06 | wps 6027.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.858 | train_wall 318 | gb_free 6.1 | wall 46422
KL Stats: Epoch 134 Divergences: Uniform: 3.0188223738909508 Unigram: 3.9301630361737327
2022-02-02 19:01:40 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 19:01:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:03:41 | INFO | train_inner | epoch 135:     24 / 64 loss=5.522, ppl=45.96, wps=5893.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.85, train_wall=496, gb_free=6.1, wall=46542
2022-02-02 19:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:07:27 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.055 | ppl 1064.11 | wps 8067.9 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.303
2022-02-02 19:07:27 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 19:07:27 | INFO | train | epoch 135 | loss 5.517 | ppl 45.78 | wps 6013.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.852 | train_wall 319 | gb_free 6.1 | wall 46769
KL Stats: Epoch 135 Divergences: Uniform: 3.0243472971495025 Unigram: 3.9375269860624473
2022-02-02 19:07:27 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 19:07:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:12:29 | INFO | train_inner | epoch 136:     60 / 64 loss=5.52, ppl=45.89, wps=6182.7, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.869, train_wall=499, gb_free=6.1, wall=47071
2022-02-02 19:12:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:13:16 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.075 | ppl 1078.98 | wps 8019.4 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.303
2022-02-02 19:13:16 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 19:13:16 | INFO | train | epoch 136 | loss 5.51 | ppl 45.56 | wps 5997.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.871 | train_wall 319 | gb_free 6.1 | wall 47117
KL Stats: Epoch 136 Divergences: Uniform: 3.0163946779262103 Unigram: 3.9441195664488364
2022-02-02 19:13:16 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 19:13:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:18:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:19:06 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.004 | ppl 1026.93 | wps 7999.8 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.303
2022-02-02 19:19:06 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 19:19:06 | INFO | train | epoch 137 | loss 5.498 | ppl 45.18 | wps 5959.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.883 | train_wall 321 | gb_free 6.1 | wall 47468
KL Stats: Epoch 137 Divergences: Uniform: 3.0296313027196917 Unigram: 3.9600765102977387
2022-02-02 19:19:06 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 19:19:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:21:48 | INFO | train_inner | epoch 138:     32 / 64 loss=5.488, ppl=44.86, wps=5833.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.881, train_wall=502, gb_free=6.1, wall=47630
2022-02-02 19:24:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:24:56 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.092 | ppl 1091.42 | wps 7994.8 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.303
2022-02-02 19:24:56 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 19:24:56 | INFO | train | epoch 138 | loss 5.491 | ppl 44.97 | wps 5970.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.884 | train_wall 321 | gb_free 6.1 | wall 47818
KL Stats: Epoch 138 Divergences: Uniform: 3.0207442257386337 Unigram: 3.9624067840711623
2022-02-02 19:24:56 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 19:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:30:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:30:46 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.101 | ppl 1098.6 | wps 8005.8 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.303
2022-02-02 19:30:46 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 19:30:46 | INFO | train | epoch 139 | loss 5.479 | ppl 44.61 | wps 5960.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.874 | train_wall 321 | gb_free 6.1 | wall 48168
KL Stats: Epoch 139 Divergences: Uniform: 3.0240253892095152 Unigram: 3.970207640397723
2022-02-02 19:30:46 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 19:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:31:07 | INFO | train_inner | epoch 140:      4 / 64 loss=5.493, ppl=45.02, wps=5836.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.88, train_wall=501, gb_free=6.1, wall=48188
2022-02-02 19:36:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:36:37 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.127 | ppl 1118.48 | wps 7969.6 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.303
2022-02-02 19:36:37 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 19:36:37 | INFO | train | epoch 140 | loss 5.473 | ppl 44.42 | wps 5963.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.902 | train_wall 321 | gb_free 6.1 | wall 48518
KL Stats: Epoch 140 Divergences: Uniform: 3.0272028995417406 Unigram: 3.977595564846034
2022-02-02 19:36:37 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 19:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:39:59 | INFO | train_inner | epoch 141:     40 / 64 loss=5.458, ppl=43.95, wps=6134.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.893, train_wall=503, gb_free=6.1, wall=48721
2022-02-02 19:42:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:42:27 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.085 | ppl 1086.24 | wps 7998.5 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.303
2022-02-02 19:42:27 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 19:42:27 | INFO | train | epoch 141 | loss 5.462 | ppl 44.08 | wps 5957.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.885 | train_wall 322 | gb_free 6.1 | wall 48869
KL Stats: Epoch 141 Divergences: Uniform: 3.0285314148497804 Unigram: 3.9854572525142937
2022-02-02 19:42:27 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 19:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:47:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:48:18 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.016 | ppl 1035.47 | wps 7988.5 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.303
2022-02-02 19:48:18 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 19:48:18 | INFO | train | epoch 142 | loss 5.457 | ppl 43.91 | wps 5961.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.919 | train_wall 321 | gb_free 6.1 | wall 49219
KL Stats: Epoch 142 Divergences: Uniform: 3.0361025056149025 Unigram: 3.9921615620057316
2022-02-02 19:48:18 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 19:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:49:18 | INFO | train_inner | epoch 143:     12 / 64 loss=5.462, ppl=44.07, wps=5831.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.915, train_wall=502, gb_free=6.1, wall=49280
2022-02-02 19:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:54:08 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.095 | ppl 1094.05 | wps 7955 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.303
2022-02-02 19:54:08 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 19:54:08 | INFO | train | epoch 143 | loss 5.449 | ppl 43.69 | wps 5953.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.92 | train_wall 322 | gb_free 6.1 | wall 49570
KL Stats: Epoch 143 Divergences: Uniform: 3.0377683585556783 Unigram: 3.9991780038521227
2022-02-02 19:54:08 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 19:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:58:12 | INFO | train_inner | epoch 144:     48 / 64 loss=5.446, ppl=43.59, wps=6122.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.926, train_wall=504, gb_free=6.1, wall=49814
2022-02-02 19:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:00:00 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.044 | ppl 1055.71 | wps 8000.9 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.303
2022-02-02 20:00:00 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 20:00:00 | INFO | train | epoch 144 | loss 5.44 | ppl 43.42 | wps 5945.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.934 | train_wall 322 | gb_free 6.1 | wall 49921
KL Stats: Epoch 144 Divergences: Uniform: 3.035356650181045 Unigram: 4.001797908684756
2022-02-02 20:00:00 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 20:00:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:05:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:05:51 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.086 | ppl 1087.09 | wps 7976.6 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.303
2022-02-02 20:05:51 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 20:05:51 | INFO | train | epoch 145 | loss 5.433 | ppl 43.19 | wps 5950 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.92 | train_wall 322 | gb_free 6.1 | wall 50272
KL Stats: Epoch 145 Divergences: Uniform: 3.0395980590298817 Unigram: 4.016332868041856
2022-02-02 20:05:51 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 20:05:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:07:32 | INFO | train_inner | epoch 146:     20 / 64 loss=5.427, ppl=43.02, wps=5820.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.923, train_wall=503, gb_free=6.1, wall=50374
2022-02-02 20:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:11:42 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.059 | ppl 1067.11 | wps 7942.9 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.303
2022-02-02 20:11:42 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 20:11:42 | INFO | train | epoch 146 | loss 5.427 | ppl 43.01 | wps 5943 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.94 | train_wall 322 | gb_free 6.1 | wall 50624
KL Stats: Epoch 146 Divergences: Uniform: 3.041434580624712 Unigram: 4.019467817324297
2022-02-02 20:11:42 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 20:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:16:27 | INFO | train_inner | epoch 147:     56 / 64 loss=5.429, ppl=43.09, wps=6112.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.948, train_wall=504, gb_free=6.1, wall=50909
2022-02-02 20:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:17:34 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.073 | ppl 1077.48 | wps 7941.2 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.303
2022-02-02 20:17:34 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 20:17:34 | INFO | train | epoch 147 | loss 5.417 | ppl 42.73 | wps 5940.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.945 | train_wall 322 | gb_free 6.1 | wall 50975
KL Stats: Epoch 147 Divergences: Uniform: 3.044607205651254 Unigram: 4.02463525779714
2022-02-02 20:17:34 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 20:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:23:25 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.166 | ppl 1148.65 | wps 7968.7 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.303
2022-02-02 20:23:25 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 20:23:25 | INFO | train | epoch 148 | loss 5.409 | ppl 42.5 | wps 5949.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.951 | train_wall 322 | gb_free 6.1 | wall 51326
KL Stats: Epoch 148 Divergences: Uniform: 3.047702748247427 Unigram: 4.042052664335601
2022-02-02 20:23:25 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 20:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:25:47 | INFO | train_inner | epoch 149:     28 / 64 loss=5.402, ppl=42.28, wps=5824.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.951, train_wall=502, gb_free=6.1, wall=51468
2022-02-02 20:28:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:29:15 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.084 | ppl 1085.06 | wps 7961.1 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.303
2022-02-02 20:29:15 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 20:29:15 | INFO | train | epoch 149 | loss 5.401 | ppl 42.25 | wps 5961.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.945 | train_wall 321 | gb_free 6.1 | wall 51677
KL Stats: Epoch 149 Divergences: Uniform: 3.05131981534742 Unigram: 4.041674756390012
2022-02-02 20:29:15 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 20:29:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:34:38 | INFO | train_inner | epoch 150:     64 / 64 loss=5.406, ppl=42.39, wps=6131.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.946, train_wall=502, gb_free=6.1, wall=52000
2022-02-02 20:34:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:35:06 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.085 | ppl 1086.13 | wps 7976.3 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.303
2022-02-02 20:35:06 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 20:35:06 | INFO | train | epoch 150 | loss 5.393 | ppl 42.01 | wps 5957.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.953 | train_wall 321 | gb_free 6.1 | wall 52027
KL Stats: Epoch 150 Divergences: Uniform: 3.0411430517409146 Unigram: 4.048779107917959
2022-02-02 20:35:06 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 20:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:40:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 20:40:56 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.134 | ppl 1123.87 | wps 8012.6 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.303
2022-02-02 20:40:56 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 20:40:56 | INFO | train | epoch 151 | loss 5.387 | ppl 41.83 | wps 5967.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.965 | train_wall 321 | gb_free 6.1 | wall 52377
KL Stats: Epoch 151 Divergences: Uniform: 3.0440203471549925 Unigram: 4.058445957571572
2022-02-02 20:40:56 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 20:40:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:43:58 | INFO | train_inner | epoch 152:     36 / 64 loss=5.377, ppl=41.57, wps=5838.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.973, train_wall=502, gb_free=6.1, wall=52560
2022-02-02 20:46:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:46:46 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.069 | ppl 1074.01 | wps 8011.5 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.303
2022-02-02 20:46:46 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 20:46:46 | INFO | train | epoch 152 | loss 5.382 | ppl 41.71 | wps 5966.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.981 | train_wall 321 | gb_free 6.1 | wall 52727
KL Stats: Epoch 152 Divergences: Uniform: 3.0486224955894445 Unigram: 4.058094671234998
2022-02-02 20:46:46 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 20:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:52:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:52:36 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.173 | ppl 1154.12 | wps 7988.3 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.303
2022-02-02 20:52:36 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 20:52:36 | INFO | train | epoch 153 | loss 5.373 | ppl 41.43 | wps 5961.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.978 | train_wall 321 | gb_free 6.1 | wall 53078
KL Stats: Epoch 153 Divergences: Uniform: 3.0502923928627794 Unigram: 4.0683476183079
2022-02-02 20:52:36 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 20:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:53:17 | INFO | train_inner | epoch 154:      8 / 64 loss=5.378, ppl=41.58, wps=5836.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.977, train_wall=501, gb_free=6.1, wall=53118
2022-02-02 20:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:58:26 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.164 | ppl 1147.28 | wps 7987.3 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.303
2022-02-02 20:58:26 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 20:58:26 | INFO | train | epoch 154 | loss 5.367 | ppl 41.28 | wps 5968.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 0.974 | train_wall 321 | gb_free 6.1 | wall 53428
KL Stats: Epoch 154 Divergences: Uniform: 3.0501266630607025 Unigram: 4.07178703033813
2022-02-02 20:58:26 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 20:58:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:02:09 | INFO | train_inner | epoch 155:     44 / 64 loss=5.359, ppl=41.04, wps=6140, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.974, train_wall=502, gb_free=6.1, wall=53651
2022-02-02 21:03:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:04:16 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.135 | ppl 1124.52 | wps 7998.4 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.303
2022-02-02 21:04:16 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 21:04:16 | INFO | train | epoch 155 | loss 5.36 | ppl 41.06 | wps 5964.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 0.972 | train_wall 321 | gb_free 6.1 | wall 53778
KL Stats: Epoch 155 Divergences: Uniform: 3.052027149090384 Unigram: 4.075488930112566
2022-02-02 21:04:16 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 21:04:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:09:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:10:06 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.104 | ppl 1100.26 | wps 8010.6 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.303
2022-02-02 21:10:06 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 21:10:06 | INFO | train | epoch 156 | loss 5.351 | ppl 40.81 | wps 5968.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 0.988 | train_wall 321 | gb_free 6.1 | wall 54128
KL Stats: Epoch 156 Divergences: Uniform: 3.052000116254296 Unigram: 4.084422514484133
2022-02-02 21:10:06 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 21:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:11:27 | INFO | train_inner | epoch 157:     16 / 64 loss=5.353, ppl=40.88, wps=5837.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=0.985, train_wall=501, gb_free=6.1, wall=54209
2022-02-02 21:15:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 21:15:56 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.18 | ppl 1160.39 | wps 8004.9 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.303
2022-02-02 21:15:56 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 21:15:56 | INFO | train | epoch 157 | loss 5.345 | ppl 40.66 | wps 5967.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 0.986 | train_wall 321 | gb_free 6.1 | wall 54478
KL Stats: Epoch 157 Divergences: Uniform: 3.0554282199632734 Unigram: 4.092413755824076
2022-02-02 21:15:56 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 21:15:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:20:20 | INFO | train_inner | epoch 158:     52 / 64 loss=5.346, ppl=40.68, wps=6134.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=0.997, train_wall=503, gb_free=6.1, wall=54742
2022-02-02 21:21:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:21:47 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.12 | ppl 1112.53 | wps 7979.2 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.303
2022-02-02 21:21:47 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 21:21:47 | INFO | train | epoch 158 | loss 5.339 | ppl 40.48 | wps 5955.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.011 | train_wall 322 | gb_free 6.1 | wall 54829
KL Stats: Epoch 158 Divergences: Uniform: 3.054971986382049 Unigram: 4.095662514051225
2022-02-02 21:21:47 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 21:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:27:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:27:37 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.182 | ppl 1161.56 | wps 7996.1 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.303
2022-02-02 21:27:37 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 21:27:37 | INFO | train | epoch 159 | loss 5.332 | ppl 40.28 | wps 5971.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.03 | train_wall 321 | gb_free 6.1 | wall 55178
KL Stats: Epoch 159 Divergences: Uniform: 3.0589312004397513 Unigram: 4.0991265440431635
2022-02-02 21:27:37 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 21:27:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:29:38 | INFO | train_inner | epoch 160:     24 / 64 loss=5.325, ppl=40.1, wps=5842.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.024, train_wall=501, gb_free=6.1, wall=55300
2022-02-02 21:32:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:33:27 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.097 | ppl 1095.42 | wps 7967.9 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.303
2022-02-02 21:33:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 21:33:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint160.pt
2022-02-02 21:33:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint160.pt
2022-02-02 21:33:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.097) (writing took 5.749904175288975 seconds)
2022-02-02 21:33:32 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 21:33:32 | INFO | train | epoch 160 | loss 5.328 | ppl 40.16 | wps 5871.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.03 | train_wall 321 | gb_free 6.1 | wall 55534
KL Stats: Epoch 160 Divergences: Uniform: 3.060158437799995 Unigram: 4.100805273280375
2022-02-02 21:33:32 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 21:33:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:38:37 | INFO | train_inner | epoch 161:     60 / 64 loss=5.33, ppl=40.23, wps=6063.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.029, train_wall=503, gb_free=6.1, wall=55839
2022-02-02 21:38:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:39:23 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.11 | ppl 1104.98 | wps 7970.3 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.303
2022-02-02 21:39:23 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 21:39:23 | INFO | train | epoch 161 | loss 5.319 | ppl 39.93 | wps 5950.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.02 | train_wall 322 | gb_free 6.1 | wall 55885
KL Stats: Epoch 161 Divergences: Uniform: 3.0565300677757077 Unigram: 4.115271969578079
2022-02-02 21:39:23 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 21:39:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 21:45:15 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.163 | ppl 1146.42 | wps 7955.5 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.303
2022-02-02 21:45:15 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 21:45:15 | INFO | train | epoch 162 | loss 5.314 | ppl 39.77 | wps 5937.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.032 | train_wall 323 | gb_free 6.1 | wall 56237
KL Stats: Epoch 162 Divergences: Uniform: 3.05523206369643 Unigram: 4.117104919762068
2022-02-02 21:45:15 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 21:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:47:58 | INFO | train_inner | epoch 163:     32 / 64 loss=5.303, ppl=39.47, wps=5812.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.025, train_wall=503, gb_free=6.1, wall=56399
2022-02-02 21:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:51:07 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.11 | ppl 1105.23 | wps 7937.2 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.303
2022-02-02 21:51:07 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 21:51:07 | INFO | train | epoch 163 | loss 5.307 | ppl 39.6 | wps 5937.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.025 | train_wall 322 | gb_free 6.1 | wall 56589
KL Stats: Epoch 163 Divergences: Uniform: 3.0600847977825762 Unigram: 4.1254149573250345
2022-02-02 21:51:07 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 21:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:56:58 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.175 | ppl 1156.37 | wps 8013.4 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.303
2022-02-02 21:56:58 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 21:56:58 | INFO | train | epoch 164 | loss 5.3 | ppl 39.39 | wps 5950.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.041 | train_wall 322 | gb_free 6.1 | wall 56940
KL Stats: Epoch 164 Divergences: Uniform: 3.064698660156751 Unigram: 4.1367653763352425
2022-02-02 21:56:58 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 21:56:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:57:18 | INFO | train_inner | epoch 165:      4 / 64 loss=5.311, ppl=39.71, wps=5815.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.041, train_wall=503, gb_free=6.1, wall=56960
2022-02-02 22:02:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:02:49 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.182 | ppl 1161.79 | wps 7999.7 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.303
2022-02-02 22:02:49 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 22:02:49 | INFO | train | epoch 165 | loss 5.293 | ppl 39.19 | wps 5951.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.051 | train_wall 322 | gb_free 6.1 | wall 57291
KL Stats: Epoch 165 Divergences: Uniform: 3.067583238819256 Unigram: 4.136225142057769
2022-02-02 22:02:49 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 22:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:06:12 | INFO | train_inner | epoch 166:     40 / 64 loss=5.283, ppl=38.95, wps=6124.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.053, train_wall=504, gb_free=6.1, wall=57494
2022-02-02 22:08:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:08:40 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.171 | ppl 1152.58 | wps 8008 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.303
2022-02-02 22:08:40 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 22:08:40 | INFO | train | epoch 166 | loss 5.29 | ppl 39.11 | wps 5950.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.065 | train_wall 322 | gb_free 6.1 | wall 57642
KL Stats: Epoch 166 Divergences: Uniform: 3.066115088109382 Unigram: 4.142714568577075
2022-02-02 22:08:40 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 22:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:14:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 22:14:31 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.229 | ppl 1200.18 | wps 7940.3 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.303
2022-02-02 22:14:31 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 22:14:31 | INFO | train | epoch 167 | loss 5.283 | ppl 38.94 | wps 5945.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.069 | train_wall 322 | gb_free 6.1 | wall 57993
KL Stats: Epoch 167 Divergences: Uniform: 3.0727628224487575 Unigram: 4.151547391098233
2022-02-02 22:14:31 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 22:14:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:15:32 | INFO | train_inner | epoch 168:     12 / 64 loss=5.288, ppl=39.08, wps=5816.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.077, train_wall=503, gb_free=6.1, wall=58054
2022-02-02 22:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 22:20:23 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.203 | ppl 1178.59 | wps 7983.5 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.303
2022-02-02 22:20:23 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 22:20:23 | INFO | train | epoch 168 | loss 5.28 | ppl 38.86 | wps 5938.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.107 | train_wall 323 | gb_free 6.1 | wall 58345
KL Stats: Epoch 168 Divergences: Uniform: 3.065594141820881 Unigram: 4.149745026218907
2022-02-02 22:20:23 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 22:20:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:24:27 | INFO | train_inner | epoch 169:     48 / 64 loss=5.278, ppl=38.79, wps=6116.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.097, train_wall=504, gb_free=6.1, wall=58588
2022-02-02 22:25:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:26:14 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.148 | ppl 1134.5 | wps 7954.8 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.303
2022-02-02 22:26:14 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 22:26:14 | INFO | train | epoch 169 | loss 5.27 | ppl 38.59 | wps 5948.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.081 | train_wall 322 | gb_free 6.1 | wall 58696
KL Stats: Epoch 169 Divergences: Uniform: 3.070753695855816 Unigram: 4.15967773639833
2022-02-02 22:26:14 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 22:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:31:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:32:05 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.19 | ppl 1168.38 | wps 7967.8 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.303
2022-02-02 22:32:05 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 22:32:05 | INFO | train | epoch 170 | loss 5.264 | ppl 38.43 | wps 5944.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.094 | train_wall 322 | gb_free 6.1 | wall 59047
KL Stats: Epoch 170 Divergences: Uniform: 3.070907273188835 Unigram: 4.1652763547021125
2022-02-02 22:32:05 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 22:32:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:33:47 | INFO | train_inner | epoch 171:     20 / 64 loss=5.257, ppl=38.24, wps=5817.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.092, train_wall=503, gb_free=6.1, wall=59149
2022-02-02 22:37:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:37:56 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.183 | ppl 1162.79 | wps 7956.6 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.303
2022-02-02 22:37:56 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 22:37:56 | INFO | train | epoch 171 | loss 5.261 | ppl 38.34 | wps 5951.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.109 | train_wall 322 | gb_free 6.1 | wall 59398
KL Stats: Epoch 171 Divergences: Uniform: 3.075510898061821 Unigram: 4.17242857153766
2022-02-02 22:37:56 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 22:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:42:40 | INFO | train_inner | epoch 172:     56 / 64 loss=5.265, ppl=38.46, wps=6127.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.101, train_wall=503, gb_free=6.1, wall=59682
2022-02-02 22:43:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:43:47 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.206 | ppl 1181 | wps 7963.8 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.303
2022-02-02 22:43:47 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 22:43:47 | INFO | train | epoch 172 | loss 5.255 | ppl 38.18 | wps 5953.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.093 | train_wall 322 | gb_free 6.1 | wall 59749
KL Stats: Epoch 172 Divergences: Uniform: 3.0715480579887555 Unigram: 4.175828781331109
2022-02-02 22:43:47 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 22:43:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:49:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:49:39 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.21 | ppl 1184.81 | wps 7974.2 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.303
2022-02-02 22:49:39 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 22:49:39 | INFO | train | epoch 173 | loss 5.251 | ppl 38.07 | wps 5929.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.135 | train_wall 323 | gb_free 6.1 | wall 60101
KL Stats: Epoch 173 Divergences: Uniform: 3.074281358528391 Unigram: 4.183260760834309
2022-02-02 22:49:39 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 22:49:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:52:02 | INFO | train_inner | epoch 174:     28 / 64 loss=5.242, ppl=37.85, wps=5803.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.117, train_wall=504, gb_free=6.1, wall=60244
2022-02-02 22:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:55:31 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.205 | ppl 1180.37 | wps 7968.7 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.303
2022-02-02 22:55:31 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 22:55:31 | INFO | train | epoch 174 | loss 5.243 | ppl 37.88 | wps 5937.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.107 | train_wall 323 | gb_free 6.1 | wall 60453
KL Stats: Epoch 174 Divergences: Uniform: 3.07333014141545 Unigram: 4.184408192734056
2022-02-02 22:55:31 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 22:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:00:55 | INFO | train_inner | epoch 175:     64 / 64 loss=5.251, ppl=38.08, wps=6119.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.127, train_wall=503, gb_free=6.1, wall=60776
2022-02-02 23:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:01:22 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.186 | ppl 1164.58 | wps 7930.4 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.303
2022-02-02 23:01:22 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 23:01:22 | INFO | train | epoch 175 | loss 5.24 | ppl 37.78 | wps 5948.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.13 | train_wall 322 | gb_free 6.1 | wall 60804
KL Stats: Epoch 175 Divergences: Uniform: 3.0725439283723994 Unigram: 4.186148673124013
2022-02-02 23:01:22 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 23:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:07:14 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.216 | ppl 1189.11 | wps 7907.7 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.303
2022-02-02 23:07:14 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 23:07:14 | INFO | train | epoch 176 | loss 5.233 | ppl 37.6 | wps 5931.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.164 | train_wall 323 | gb_free 6.1 | wall 61156
KL Stats: Epoch 176 Divergences: Uniform: 3.0812072502048187 Unigram: 4.194364583285925
2022-02-02 23:07:14 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 23:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:10:18 | INFO | train_inner | epoch 177:     36 / 64 loss=5.22, ppl=37.27, wps=5804.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.171, train_wall=505, gb_free=6.1, wall=61339
2022-02-02 23:12:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:13:06 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.229 | ppl 1200.18 | wps 7992.3 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.303
2022-02-02 23:13:06 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 23:13:06 | INFO | train | epoch 177 | loss 5.229 | ppl 37.51 | wps 5933.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.175 | train_wall 323 | gb_free 6.1 | wall 61508
KL Stats: Epoch 177 Divergences: Uniform: 3.0807906529451548 Unigram: 4.193291062203927
2022-02-02 23:13:06 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 23:13:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 23:18:58 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.156 | ppl 1140.8 | wps 7927.7 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.303
2022-02-02 23:18:58 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-02 23:18:58 | INFO | train | epoch 178 | loss 5.219 | ppl 37.24 | wps 5940 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.117 | train_wall 322 | gb_free 6.1 | wall 61860
KL Stats: Epoch 178 Divergences: Uniform: 3.0812762639705626 Unigram: 4.2009852098667295
2022-02-02 23:18:58 | INFO | fairseq.trainer | begin training epoch 179
2022-02-02 23:18:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:19:39 | INFO | train_inner | epoch 179:      8 / 64 loss=5.23, ppl=37.52, wps=5810.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.133, train_wall=503, gb_free=6.1, wall=61900
2022-02-02 23:24:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:24:50 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.213 | ppl 1187.03 | wps 7954.3 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.303
2022-02-02 23:24:50 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-02 23:24:50 | INFO | train | epoch 179 | loss 5.218 | ppl 37.21 | wps 5928.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.183 | train_wall 323 | gb_free 6.1 | wall 62212
KL Stats: Epoch 179 Divergences: Uniform: 3.083227354105557 Unigram: 4.210855804651619
2022-02-02 23:24:50 | INFO | fairseq.trainer | begin training epoch 180
2022-02-02 23:24:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:28:34 | INFO | train_inner | epoch 180:     44 / 64 loss=5.209, ppl=36.99, wps=6107.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.176, train_wall=505, gb_free=6.1, wall=62436
2022-02-02 23:30:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:30:42 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.223 | ppl 1195.17 | wps 7994.4 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.303
2022-02-02 23:30:42 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-02 23:30:42 | INFO | train | epoch 180 | loss 5.212 | ppl 37.06 | wps 5942.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.164 | train_wall 322 | gb_free 6.1 | wall 62563
KL Stats: Epoch 180 Divergences: Uniform: 3.083629346983834 Unigram: 4.214716487178472
2022-02-02 23:30:42 | INFO | fairseq.trainer | begin training epoch 181
2022-02-02 23:30:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:36:33 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.273 | ppl 1237.48 | wps 7981.2 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.303
2022-02-02 23:36:33 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-02 23:36:33 | INFO | train | epoch 181 | loss 5.206 | ppl 36.9 | wps 5947.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.178 | train_wall 322 | gb_free 6.1 | wall 62915
KL Stats: Epoch 181 Divergences: Uniform: 3.0750678151753337 Unigram: 4.2214861853726955
2022-02-02 23:36:33 | INFO | fairseq.trainer | begin training epoch 182
2022-02-02 23:36:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:37:54 | INFO | train_inner | epoch 182:     16 / 64 loss=5.207, ppl=36.95, wps=5816, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.187, train_wall=503, gb_free=6.1, wall=62996
2022-02-02 23:41:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:42:25 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.168 | ppl 1150.12 | wps 7943.1 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.303
2022-02-02 23:42:25 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-02 23:42:25 | INFO | train | epoch 182 | loss 5.204 | ppl 36.85 | wps 5939.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.229 | train_wall 322 | gb_free 6.1 | wall 63266
KL Stats: Epoch 182 Divergences: Uniform: 3.0847788554427362 Unigram: 4.220806757185759
2022-02-02 23:42:25 | INFO | fairseq.trainer | begin training epoch 183
2022-02-02 23:42:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:46:49 | INFO | train_inner | epoch 183:     52 / 64 loss=5.203, ppl=36.84, wps=6111.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.195, train_wall=505, gb_free=6.1, wall=63531
2022-02-02 23:47:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:48:16 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.199 | ppl 1175.79 | wps 8005.4 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.303
2022-02-02 23:48:16 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-02 23:48:16 | INFO | train | epoch 183 | loss 5.195 | ppl 36.63 | wps 5942.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.171 | train_wall 322 | gb_free 6.1 | wall 63618
KL Stats: Epoch 183 Divergences: Uniform: 3.088653056927379 Unigram: 4.227419811516299
2022-02-02 23:48:16 | INFO | fairseq.trainer | begin training epoch 184
2022-02-02 23:48:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:54:08 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.232 | ppl 1202.68 | wps 7996.8 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.303
2022-02-02 23:54:08 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-02 23:54:08 | INFO | train | epoch 184 | loss 5.191 | ppl 36.54 | wps 5937.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.219 | train_wall 323 | gb_free 6.1 | wall 63970
KL Stats: Epoch 184 Divergences: Uniform: 3.0874971702159164 Unigram: 4.232978677093533
2022-02-02 23:54:08 | INFO | fairseq.trainer | begin training epoch 185
2022-02-02 23:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:56:10 | INFO | train_inner | epoch 185:     24 / 64 loss=5.188, ppl=36.45, wps=5813.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.211, train_wall=503, gb_free=6.1, wall=64092
2022-02-02 23:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:59:59 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.21 | ppl 1184.13 | wps 7969.3 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.303
2022-02-02 23:59:59 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-02 23:59:59 | INFO | train | epoch 185 | loss 5.188 | ppl 36.45 | wps 5947.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.218 | train_wall 322 | gb_free 6.1 | wall 64321
KL Stats: Epoch 185 Divergences: Uniform: 3.0849027313024164 Unigram: 4.238633689380888
2022-02-02 23:59:59 | INFO | fairseq.trainer | begin training epoch 186
2022-02-02 23:59:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:05:04 | INFO | train_inner | epoch 186:     60 / 64 loss=5.19, ppl=36.51, wps=6118.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.221, train_wall=504, gb_free=6.1, wall=64626
2022-02-03 00:05:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:05:51 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.187 | ppl 1165.39 | wps 7897.5 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.303
2022-02-03 00:05:51 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-03 00:05:51 | INFO | train | epoch 186 | loss 5.183 | ppl 36.33 | wps 5938.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.218 | train_wall 322 | gb_free 6.1 | wall 64672
KL Stats: Epoch 186 Divergences: Uniform: 3.0883889470267603 Unigram: 4.238473065948147
2022-02-03 00:05:51 | INFO | fairseq.trainer | begin training epoch 187
2022-02-03 00:05:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:11:43 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.198 | ppl 1174.58 | wps 7978.5 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.303
2022-02-03 00:11:43 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-03 00:11:43 | INFO | train | epoch 187 | loss 5.178 | ppl 36.2 | wps 5935.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.248 | train_wall 323 | gb_free 6.1 | wall 65024
KL Stats: Epoch 187 Divergences: Uniform: 3.086053780645886 Unigram: 4.248761950627042
2022-02-03 00:11:43 | INFO | fairseq.trainer | begin training epoch 188
2022-02-03 00:11:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:14:25 | INFO | train_inner | epoch 188:     32 / 64 loss=5.167, ppl=35.94, wps=5809.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.245, train_wall=503, gb_free=6.1, wall=65187
2022-02-03 00:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:17:34 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.231 | ppl 1201.62 | wps 7941.2 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.303
2022-02-03 00:17:34 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-03 00:17:34 | INFO | train | epoch 188 | loss 5.173 | ppl 36.06 | wps 5944.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.24 | train_wall 322 | gb_free 6.1 | wall 65376
KL Stats: Epoch 188 Divergences: Uniform: 3.091264019105575 Unigram: 4.249027335797211
2022-02-03 00:17:34 | INFO | fairseq.trainer | begin training epoch 189
2022-02-03 00:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:22:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-03 00:23:26 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.209 | ppl 1183.45 | wps 7946.2 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.303
2022-02-03 00:23:26 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-03 00:23:26 | INFO | train | epoch 189 | loss 5.165 | ppl 35.88 | wps 5937.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.24 | train_wall 323 | gb_free 6.1 | wall 65727
KL Stats: Epoch 189 Divergences: Uniform: 3.092296529863868 Unigram: 4.2587607606379025
2022-02-03 00:23:26 | INFO | fairseq.trainer | begin training epoch 190
2022-02-03 00:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:23:46 | INFO | train_inner | epoch 190:      4 / 64 loss=5.176, ppl=36.16, wps=5811.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.238, train_wall=503, gb_free=6.1, wall=65748
2022-02-03 00:28:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-03 00:29:18 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.315 | ppl 1274.16 | wps 7951.7 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.303
2022-02-03 00:29:18 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-03 00:29:18 | INFO | train | epoch 190 | loss 5.163 | ppl 35.82 | wps 5930.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.239 | train_wall 323 | gb_free 6.1 | wall 66080
KL Stats: Epoch 190 Divergences: Uniform: 3.0856405995551395 Unigram: 4.259630156261784
2022-02-03 00:29:18 | INFO | fairseq.trainer | begin training epoch 191
2022-02-03 00:29:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:32:41 | INFO | train_inner | epoch 191:     40 / 64 loss=5.156, ppl=35.65, wps=6106.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.254, train_wall=505, gb_free=6.1, wall=66283
2022-02-03 00:34:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:35:09 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.265 | ppl 1230.53 | wps 7955 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.303
2022-02-03 00:35:09 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-03 00:35:09 | INFO | train | epoch 191 | loss 5.159 | ppl 35.74 | wps 5944.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.265 | train_wall 322 | gb_free 6.1 | wall 66431
KL Stats: Epoch 191 Divergences: Uniform: 3.0915967032901985 Unigram: 4.262540543814844
2022-02-03 00:35:09 | INFO | fairseq.trainer | begin training epoch 192
2022-02-03 00:35:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:41:01 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.278 | ppl 1241.32 | wps 7954.3 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.303
2022-02-03 00:41:01 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-03 00:41:01 | INFO | train | epoch 192 | loss 5.155 | ppl 35.63 | wps 5943.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.268 | train_wall 322 | gb_free 6.1 | wall 66782
KL Stats: Epoch 192 Divergences: Uniform: 3.0948189459426954 Unigram: 4.267538014592671
2022-02-03 00:41:01 | INFO | fairseq.trainer | begin training epoch 193
2022-02-03 00:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:42:02 | INFO | train_inner | epoch 193:     12 / 64 loss=5.159, ppl=35.72, wps=5816.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.256, train_wall=503, gb_free=6.1, wall=66843
2022-02-03 00:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:46:52 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.259 | ppl 1225.06 | wps 7972.6 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.303
2022-02-03 00:46:52 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-03 00:46:52 | INFO | train | epoch 193 | loss 5.151 | ppl 35.54 | wps 5942.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.262 | train_wall 322 | gb_free 6.1 | wall 67134
KL Stats: Epoch 193 Divergences: Uniform: 3.0912831736521036 Unigram: 4.269227119112248
2022-02-03 00:46:52 | INFO | fairseq.trainer | begin training epoch 194
2022-02-03 00:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:50:57 | INFO | train_inner | epoch 194:     48 / 64 loss=5.148, ppl=35.45, wps=6108.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.302, train_wall=505, gb_free=6.1, wall=67378
2022-02-03 00:52:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:52:44 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.309 | ppl 1268.39 | wps 7972.9 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.303
2022-02-03 00:52:44 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-03 00:52:44 | INFO | train | epoch 194 | loss 5.147 | ppl 35.44 | wps 5935.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.337 | train_wall 323 | gb_free 6.1 | wall 67486
KL Stats: Epoch 194 Divergences: Uniform: 3.0932494213038213 Unigram: 4.273412359697365
2022-02-03 00:52:44 | INFO | fairseq.trainer | begin training epoch 195
2022-02-03 00:52:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:58:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:58:36 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.233 | ppl 1203.67 | wps 7914.2 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.303
2022-02-03 00:58:36 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-03 00:58:36 | INFO | train | epoch 195 | loss 5.142 | ppl 35.31 | wps 5937.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.296 | train_wall 322 | gb_free 6.1 | wall 67838
KL Stats: Epoch 195 Divergences: Uniform: 3.1002154229642866 Unigram: 4.279541318701258
2022-02-03 00:58:36 | INFO | fairseq.trainer | begin training epoch 196
2022-02-03 00:58:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:00:18 | INFO | train_inner | epoch 196:     20 / 64 loss=5.14, ppl=35.25, wps=5810.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.315, train_wall=503, gb_free=6.1, wall=67939
2022-02-03 01:04:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-03 01:04:28 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.296 | ppl 1257.49 | wps 7982.3 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.303
2022-02-03 01:04:28 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 01:04:28 | INFO | train | epoch 196 | loss 5.137 | ppl 35.19 | wps 5930.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.313 | train_wall 323 | gb_free 6.1 | wall 68190
KL Stats: Epoch 196 Divergences: Uniform: 3.098512197884781 Unigram: 4.286762694068025
2022-02-03 01:04:28 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 01:04:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:09:13 | INFO | train_inner | epoch 197:     56 / 64 loss=5.142, ppl=35.32, wps=6105.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.297, train_wall=505, gb_free=6.1, wall=68475
2022-02-03 01:09:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-03 01:10:20 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.303 | ppl 1263.3 | wps 7944.7 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.303
2022-02-03 01:10:20 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 01:10:20 | INFO | train | epoch 197 | loss 5.134 | ppl 35.11 | wps 5933 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.301 | train_wall 323 | gb_free 6.1 | wall 68542
KL Stats: Epoch 197 Divergences: Uniform: 3.0913817828568257 Unigram: 4.286856916074588
2022-02-03 01:10:20 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 01:10:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:15:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:16:12 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.315 | ppl 1273.95 | wps 7961.4 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.303
2022-02-03 01:16:12 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 01:16:12 | INFO | train | epoch 198 | loss 5.13 | ppl 35.01 | wps 5938.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.331 | train_wall 323 | gb_free 6.1 | wall 68893
KL Stats: Epoch 198 Divergences: Uniform: 3.0981465362729996 Unigram: 4.2949935516885684
2022-02-03 01:16:12 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 01:16:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:18:34 | INFO | train_inner | epoch 199:     28 / 64 loss=5.121, ppl=34.8, wps=5808.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.333, train_wall=504, gb_free=6.1, wall=69036
2022-02-03 01:21:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:22:03 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.302 | ppl 1262.2 | wps 7960.7 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.303
2022-02-03 01:22:03 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 01:22:03 | INFO | train | epoch 199 | loss 5.127 | ppl 34.93 | wps 5940.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.358 | train_wall 322 | gb_free 6.1 | wall 69245
KL Stats: Epoch 199 Divergences: Uniform: 3.096715445842311 Unigram: 4.29875748156443
2022-02-03 01:22:03 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 01:22:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:27:27 | INFO | train_inner | epoch 200:     64 / 64 loss=5.133, ppl=35.09, wps=6116.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.355, train_wall=503, gb_free=6.1, wall=69569
2022-02-03 01:27:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:27:55 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.238 | ppl 1207.78 | wps 7955 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.303
2022-02-03 01:27:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-03 01:27:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint200.pt
2022-02-03 01:27:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint200.pt
2022-02-03 01:27:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#3/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.238) (writing took 2.9658484272658825 seconds)
2022-02-03 01:27:58 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-03 01:27:58 | INFO | train | epoch 200 | loss 5.121 | ppl 34.8 | wps 5895.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.344 | train_wall 322 | gb_free 6.1 | wall 69599
KL Stats: Epoch 200 Divergences: Uniform: 3.0972427481606015 Unigram: 4.298859587786624
2022-02-03 01:27:58 | INFO | fairseq.trainer | begin training epoch 201
2022-02-03 01:27:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:33:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-03 01:33:47 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.292 | ppl 1254.05 | wps 8039.6 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.303
2022-02-03 01:33:47 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-03 01:33:47 | INFO | train | epoch 201 | loss 5.117 | ppl 34.71 | wps 5971 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.353 | train_wall 321 | gb_free 6.1 | wall 69949
KL Stats: Epoch 201 Divergences: Uniform: 3.0981343814758424 Unigram: 4.3004880245664205
2022-02-03 01:33:47 | INFO | fairseq.trainer | begin training epoch 202
2022-02-03 01:33:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:36:50 | INFO | train_inner | epoch 202:     36 / 64 loss=5.105, ppl=34.43, wps=5810.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.351, train_wall=502, gb_free=6.1, wall=70131
2022-02-03 01:39:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-03 01:39:38 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.324 | ppl 1282.12 | wps 7975.6 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.303
2022-02-03 01:39:38 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-03 01:39:38 | INFO | train | epoch 202 | loss 5.111 | ppl 34.57 | wps 5964.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.355 | train_wall 321 | gb_free 6.1 | wall 70299
KL Stats: Epoch 202 Divergences: Uniform: 3.1008574578479506 Unigram: 4.311464595413716
2022-02-03 01:39:38 | INFO | fairseq.trainer | begin training epoch 203
2022-02-03 01:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:45:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:45:26 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.274 | ppl 1237.98 | wps 8127.9 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.303
2022-02-03 01:45:26 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-03 01:45:26 | INFO | train | epoch 203 | loss 5.11 | ppl 34.53 | wps 5986.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.372 | train_wall 320 | gb_free 6.1 | wall 70648
KL Stats: Epoch 203 Divergences: Uniform: 3.099565772866335 Unigram: 4.314675912082433
2022-02-03 01:45:26 | INFO | fairseq.trainer | begin training epoch 204
2022-02-03 01:45:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:46:07 | INFO | train_inner | epoch 204:      8 / 64 loss=5.117, ppl=34.69, wps=5851.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.376, train_wall=500, gb_free=6.1, wall=70688
2022-02-03 01:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:51:14 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.297 | ppl 1258.49 | wps 8052.6 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.303
2022-02-03 01:51:14 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-03 01:51:14 | INFO | train | epoch 204 | loss 5.106 | ppl 34.43 | wps 6014.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.394 | train_wall 318 | gb_free 6.1 | wall 70995
KL Stats: Epoch 204 Divergences: Uniform: 3.1024781198328037 Unigram: 4.311181105881651
2022-02-03 01:51:14 | INFO | fairseq.trainer | begin training epoch 205
2022-02-03 01:51:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:54:54 | INFO | train_inner | epoch 205:     44 / 64 loss=5.096, ppl=34.2, wps=6195, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.376, train_wall=498, gb_free=6.1, wall=71216
2022-02-03 01:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:57:00 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.289 | ppl 1251.14 | wps 8102.5 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.303
2022-02-03 01:57:00 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-03 01:57:00 | INFO | train | epoch 205 | loss 5.099 | ppl 34.28 | wps 6027.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.38 | train_wall 318 | gb_free 6.1 | wall 71342
KL Stats: Epoch 205 Divergences: Uniform: 3.1050330451790935 Unigram: 4.324598149410947
2022-02-03 01:57:00 | INFO | fairseq.trainer | begin training epoch 206
2022-02-03 01:57:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:02:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:02:47 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.258 | ppl 1224.46 | wps 8108.6 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.303
2022-02-03 02:02:47 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-03 02:02:47 | INFO | train | epoch 206 | loss 5.099 | ppl 34.26 | wps 6027 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.417 | train_wall 318 | gb_free 6.1 | wall 71688
KL Stats: Epoch 206 Divergences: Uniform: 3.105306256891514 Unigram: 4.31807920491489
2022-02-03 02:02:47 | INFO | fairseq.trainer | begin training epoch 207
2022-02-03 02:02:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:04:07 | INFO | train_inner | epoch 207:     16 / 64 loss=5.101, ppl=34.31, wps=5897, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.416, train_wall=496, gb_free=6.1, wall=71769
User defined signal 2
