Sender: LSF System <lsfadmin@eu-lo-s4-010>
Subject: Job 210317806: <iwslt14_de_en_dropout_0.4_kneser_n2_d0.9_#4> in cluster <euler> Exited

Job <iwslt14_de_en_dropout_0.4_kneser_n2_d0.9_#4> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Mar 21 19:59:49 2022
Job was executed on host(s) <eu-lo-s4-010>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Mar 21 20:06:57 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 21 20:06:57 2022
Terminated at Mon Mar 21 20:10:51 2022
Results reported at Mon Mar 21 20:10:51 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_kneser_n2_d0.9_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.4 --weight-decay 0.0001 --criterion kneser_ney_smoothing --kneser-d 0.9 --kneser-n 2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   241.56 sec.
    Max Memory :                                 5143 MB
    Average Memory :                             4014.10 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14857.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   242 sec.
    Turnaround time :                            662 sec.

The output (if any) follows:

2022-03-21 20:07:27 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_kneser_n2_d0.9_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='kneser_ney_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.4, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, kneser_d=0.9, kneser_n=2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_kneser_n2_d0.9_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'kneser_ney_smoothing', 'kneser_d': 0.9, 'kneser_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-21 20:07:27 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-21 20:07:27 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-21 20:07:30 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-21 20:07:30 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-21 20:07:30 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  0%|          | 743/160239 [00:00<00:21, 7424.78it/s]  1%|          | 1547/160239 [00:00<00:20, 7784.24it/s]  2%|▏         | 2426/160239 [00:00<00:19, 8241.59it/s]  2%|▏         | 3351/160239 [00:00<00:18, 8637.99it/s]  3%|▎         | 4244/160239 [00:00<00:17, 8742.82it/s]  3%|▎         | 5119/160239 [00:00<00:17, 8628.42it/s]  4%|▍         | 6020/160239 [00:00<00:17, 8751.00it/s]  4%|▍         | 7056/160239 [00:00<00:16, 9257.93it/s]  5%|▍         | 7983/160239 [00:00<00:16, 9227.90it/s]  6%|▌         | 8917/160239 [00:01<00:16, 9262.15it/s]  6%|▌         | 9945/160239 [00:01<00:15, 9571.33it/s]  7%|▋         | 10993/160239 [00:01<00:15, 9844.68it/s]  7%|▋         | 11978/160239 [00:01<00:15, 9737.76it/s]  8%|▊         | 12975/160239 [00:01<00:15, 9805.97it/s]  9%|▊         | 13962/160239 [00:01<00:14, 9823.63it/s]  9%|▉         | 14945/160239 [00:01<00:15, 9662.75it/s] 10%|▉         | 15922/160239 [00:01<00:14, 9693.14it/s] 11%|█         | 16892/160239 [00:01<00:14, 9579.18it/s] 11%|█         | 17851/160239 [00:01<00:14, 9561.18it/s] 12%|█▏        | 18812/160239 [00:02<00:14, 9575.51it/s] 12%|█▏        | 19918/160239 [00:02<00:14, 10016.43it/s] 13%|█▎        | 20921/160239 [00:02<00:14, 9927.69it/s]  14%|█▎        | 21915/160239 [00:02<00:14, 9661.70it/s] 14%|█▍        | 22883/160239 [00:02<00:14, 9650.09it/s] 15%|█▍        | 23876/160239 [00:02<00:14, 9727.75it/s] 16%|█▌        | 24874/160239 [00:02<00:13, 9800.43it/s] 16%|█▌        | 25855/160239 [00:02<00:13, 9738.89it/s] 17%|█▋        | 26830/160239 [00:02<00:13, 9629.06it/s] 17%|█▋        | 27824/160239 [00:02<00:13, 9718.80it/s] 18%|█▊        | 28811/160239 [00:03<00:13, 9763.49it/s] 19%|█▊        | 29788/160239 [00:03<00:13, 9742.92it/s] 19%|█▉        | 30763/160239 [00:03<00:13, 9571.59it/s] 20%|█▉        | 31878/160239 [00:03<00:12, 10036.24it/s] 21%|██        | 32883/160239 [00:03<00:12, 9914.49it/s]  21%|██        | 33876/160239 [00:03<00:13, 9671.80it/s] 22%|██▏       | 34845/160239 [00:03<00:13, 9636.43it/s] 22%|██▏       | 35810/160239 [00:03<00:12, 9630.00it/s] 23%|██▎       | 36849/160239 [00:03<00:12, 9850.19it/s] 24%|██▎       | 37835/160239 [00:03<00:12, 9758.62it/s] 24%|██▍       | 38862/160239 [00:04<00:12, 9908.27it/s] 25%|██▍       | 39854/160239 [00:04<00:12, 9768.51it/s] 26%|██▌       | 40910/160239 [00:04<00:11, 9996.95it/s] 26%|██▌       | 41911/160239 [00:04<00:12, 9764.04it/s] 27%|██▋       | 42890/160239 [00:04<00:12, 9626.10it/s] 27%|██▋       | 43854/160239 [00:04<00:12, 9545.82it/s] 28%|██▊       | 44810/160239 [00:04<00:12, 9381.04it/s] 29%|██▊       | 45877/160239 [00:04<00:11, 9753.79it/s] 29%|██▉       | 46855/160239 [00:04<00:11, 9730.91it/s] 30%|██▉       | 47854/160239 [00:04<00:11, 9806.77it/s] 30%|███       | 48836/160239 [00:05<00:11, 9615.93it/s] 31%|███       | 49840/160239 [00:05<00:11, 9738.91it/s] 32%|███▏      | 50831/160239 [00:05<00:11, 9788.56it/s] 32%|███▏      | 51811/160239 [00:05<00:11, 9688.87it/s] 33%|███▎      | 52873/160239 [00:05<00:10, 9955.57it/s] 34%|███▎      | 53870/160239 [00:05<00:10, 9861.12it/s] 34%|███▍      | 54872/160239 [00:05<00:10, 9907.05it/s] 35%|███▍      | 55877/160239 [00:05<00:10, 9947.77it/s] 36%|███▌      | 56930/160239 [00:05<00:10, 10120.14it/s] 36%|███▌      | 57977/160239 [00:06<00:10, 10223.18it/s] 37%|███▋      | 59010/160239 [00:06<00:09, 10253.40it/s] 37%|███▋      | 60036/160239 [00:06<00:09, 10190.71it/s] 38%|███▊      | 61056/160239 [00:06<00:09, 9986.98it/s]  39%|███▊      | 62056/160239 [00:06<00:09, 9895.91it/s] 39%|███▉      | 63134/160239 [00:06<00:09, 10153.75it/s] 40%|████      | 64151/160239 [00:06<00:09, 10073.90it/s] 41%|████      | 65334/160239 [00:06<00:08, 10592.13it/s] 41%|████▏     | 66395/160239 [00:06<00:08, 10529.02it/s] 42%|████▏     | 67449/160239 [00:06<00:09, 9933.38it/s]  43%|████▎     | 68470/160239 [00:07<00:09, 10008.61it/s] 43%|████▎     | 69477/160239 [00:07<00:09, 9692.29it/s]  44%|████▍     | 70519/160239 [00:07<00:09, 9898.68it/s] 45%|████▍     | 71514/160239 [00:07<00:09, 9745.11it/s] 45%|████▌     | 72512/160239 [00:07<00:08, 9811.25it/s] 46%|████▌     | 73496/160239 [00:07<00:08, 9710.84it/s] 46%|████▋     | 74469/160239 [00:07<00:08, 9705.95it/s] 47%|████▋     | 75441/160239 [00:07<00:08, 9664.69it/s] 48%|████▊     | 76409/160239 [00:07<00:08, 9581.34it/s] 48%|████▊     | 77498/160239 [00:07<00:08, 9963.92it/s] 49%|████▉     | 78542/160239 [00:08<00:08, 10102.61it/s] 50%|████▉     | 79554/160239 [00:08<00:08, 10041.10it/s] 50%|█████     | 80642/160239 [00:08<00:07, 10289.39it/s] 51%|█████     | 81672/160239 [00:08<00:07, 10220.02it/s] 52%|█████▏    | 82695/160239 [00:08<00:07, 10181.30it/s] 52%|█████▏    | 83737/160239 [00:08<00:07, 10249.21it/s] 53%|█████▎    | 84763/160239 [00:08<00:07, 10020.60it/s] 54%|█████▎    | 85867/160239 [00:08<00:07, 10317.29it/s] 54%|█████▍    | 86910/160239 [00:08<00:07, 10346.69it/s] 55%|█████▍    | 87946/160239 [00:08<00:07, 10167.96it/s] 56%|█████▌    | 88967/160239 [00:09<00:07, 10179.97it/s] 56%|█████▌    | 89991/160239 [00:09<00:06, 10194.25it/s] 57%|█████▋    | 91012/160239 [00:09<00:06, 9916.75it/s]  57%|█████▋    | 92006/160239 [00:09<00:06, 9886.43it/s] 58%|█████▊    | 93028/160239 [00:09<00:06, 9980.77it/s] 59%|█████▊    | 94028/160239 [00:09<00:06, 9659.66it/s] 59%|█████▉    | 95046/160239 [00:09<00:06, 9806.79it/s] 60%|█████▉    | 96082/160239 [00:09<00:06, 9966.74it/s] 61%|██████    | 97081/160239 [00:09<00:06, 9832.40it/s] 61%|██████    | 98092/160239 [00:10<00:06, 9911.18it/s] 62%|██████▏   | 99127/160239 [00:10<00:06, 10040.65it/s] 63%|██████▎   | 100184/160239 [00:10<00:05, 10194.53it/s] 63%|██████▎   | 101205/160239 [00:10<00:05, 10178.04it/s] 64%|██████▍   | 102224/160239 [00:10<00:05, 10102.12it/s] 64%|██████▍   | 103235/160239 [00:10<00:05, 9791.20it/s]  65%|██████▌   | 104285/160239 [00:10<00:05, 9994.79it/s] 66%|██████▌   | 105319/160239 [00:10<00:05, 10094.98it/s] 66%|██████▋   | 106331/160239 [00:10<00:05, 9997.91it/s]  67%|██████▋   | 107333/160239 [00:10<00:05, 9863.83it/s] 68%|██████▊   | 108321/160239 [00:11<00:05, 9501.82it/s] 68%|██████▊   | 109275/160239 [00:11<00:05, 9494.03it/s] 69%|██████▉   | 110284/160239 [00:11<00:05, 9664.74it/s] 69%|██████▉   | 111270/160239 [00:11<00:05, 9720.41it/s] 70%|███████   | 112303/160239 [00:11<00:04, 9899.69it/s] 71%|███████   | 113295/160239 [00:11<00:04, 9788.69it/s] 71%|███████▏  | 114341/160239 [00:11<00:04, 9982.61it/s] 72%|███████▏  | 115341/160239 [00:11<00:04, 9852.40it/s] 73%|███████▎  | 116357/160239 [00:11<00:04, 9940.17it/s] 73%|███████▎  | 117352/160239 [00:11<00:04, 9774.87it/s] 74%|███████▍  | 118369/160239 [00:12<00:04, 9889.56it/s] 75%|███████▍  | 119418/160239 [00:12<00:04, 10065.52it/s] 75%|███████▌  | 120426/160239 [00:12<00:04, 9882.96it/s]  76%|███████▌  | 121481/160239 [00:12<00:03, 10077.02it/s] 76%|███████▋  | 122558/160239 [00:12<00:03, 10277.26it/s] 77%|███████▋  | 123587/160239 [00:12<00:03, 9961.19it/s]  78%|███████▊  | 124586/160239 [00:12<00:03, 9820.96it/s] 78%|███████▊  | 125571/160239 [00:12<00:03, 9683.80it/s] 79%|███████▉  | 126582/160239 [00:12<00:03, 9806.06it/s] 80%|███████▉  | 127590/160239 [00:13<00:03, 9885.38it/s] 80%|████████  | 128625/160239 [00:13<00:03, 10022.23it/s] 81%|████████  | 129629/160239 [00:13<00:03, 9895.71it/s]  82%|████████▏ | 130620/160239 [00:13<00:03, 9588.50it/s] 82%|████████▏ | 131630/160239 [00:13<00:02, 9735.08it/s] 83%|████████▎ | 132632/160239 [00:13<00:02, 9816.44it/s] 83%|████████▎ | 133616/160239 [00:13<00:02, 9610.14it/s] 84%|████████▍ | 134579/160239 [00:13<00:02, 9579.10it/s] 85%|████████▍ | 135568/160239 [00:13<00:02, 9669.28it/s] 85%|████████▌ | 136573/160239 [00:13<00:02, 9778.76it/s] 86%|████████▌ | 137595/160239 [00:14<00:02, 9908.34it/s] 87%|████████▋ | 138607/160239 [00:14<00:02, 9971.02it/s] 87%|████████▋ | 139628/160239 [00:14<00:02, 10042.05it/s] 88%|████████▊ | 140653/160239 [00:14<00:01, 10103.26it/s] 88%|████████▊ | 141664/160239 [00:14<00:01, 10065.71it/s] 89%|████████▉ | 142671/160239 [00:14<00:01, 9854.48it/s]  90%|████████▉ | 143688/160239 [00:14<00:01, 9947.09it/s] 90%|█████████ | 144684/160239 [00:14<00:01, 9886.06it/s] 91%|█████████ | 145674/160239 [00:14<00:01, 9599.88it/s] 92%|█████████▏| 146636/160239 [00:14<00:01, 9578.32it/s] 92%|█████████▏| 147614/160239 [00:15<00:01, 9634.59it/s] 93%|█████████▎| 148579/160239 [00:15<00:01, 9471.44it/s] 93%|█████████▎| 149551/160239 [00:15<00:01, 9538.57it/s] 94%|█████████▍| 150572/160239 [00:15<00:00, 9732.80it/s] 95%|█████████▍| 151547/160239 [00:15<00:00, 9583.25it/s] 95%|█████████▌| 152507/160239 [00:15<00:00, 9573.63it/s] 96%|█████████▌| 153466/160239 [00:15<00:00, 9577.54it/s] 96%|█████████▋| 154465/160239 [00:15<00:00, 9698.54it/s] 97%|█████████▋| 155513/160239 [00:15<00:00, 9928.24it/s] 98%|█████████▊| 156507/160239 [00:15<00:00, 9882.72it/s] 98%|█████████▊| 157563/160239 [00:16<00:00, 10082.12it/s] 99%|█████████▉| 158572/160239 [00:16<00:00, 9806.21it/s] 100%|█████████▉| 159649/160239 [00:16<00:00, 10085.71it/s]100%|██████████| 160239/160239 [00:16<00:00, 9812.34it/s] 
  0%|          | 0/6629 [00:00<?, ?it/s]  0%|          | 29/6629 [00:00<00:23, 284.11it/s]  1%|          | 58/6629 [00:00<00:23, 285.22it/s]  1%|▏         | 88/6629 [00:00<00:22, 287.77it/s]  2%|▏         | 117/6629 [00:00<00:22, 287.51it/s]  2%|▏         | 147/6629 [00:00<00:22, 288.37it/s]  3%|▎         | 176/6629 [00:00<00:22, 287.89it/s]  3%|▎         | 205/6629 [00:00<00:22, 285.45it/s]  4%|▎         | 234/6629 [00:00<00:22, 285.76it/s]  4%|▍         | 263/6629 [00:00<00:22, 286.95it/s]  4%|▍         | 292/6629 [00:01<00:22, 287.87it/s]  5%|▍         | 322/6629 [00:01<00:21, 288.68it/s]  5%|▌         | 352/6629 [00:01<00:21, 289.72it/s]  6%|▌         | 381/6629 [00:01<00:21, 289.45it/s]  6%|▌         | 410/6629 [00:01<00:21, 288.20it/s]  7%|▋         | 439/6629 [00:01<00:21, 288.35it/s]  7%|▋         | 468/6629 [00:01<00:21, 288.76it/s]  7%|▋         | 497/6629 [00:01<00:21, 288.60it/s]  8%|▊         | 526/6629 [00:01<00:21, 288.81it/s]  8%|▊         | 556/6629 [00:01<00:20, 291.08it/s]  9%|▉         | 586/6629 [00:02<00:20, 292.12it/s]  9%|▉         | 616/6629 [00:02<00:20, 290.87it/s] 10%|▉         | 646/6629 [00:02<00:20, 288.10it/s] 10%|█         | 675/6629 [00:02<00:20, 288.08it/s] 11%|█         | 705/6629 [00:02<00:20, 289.45it/s] 11%|█         | 734/6629 [00:02<00:20, 288.14it/s] 12%|█▏        | 763/6629 [00:02<00:20, 288.58it/s] 12%|█▏        | 792/6629 [00:02<00:20, 286.28it/s] 12%|█▏        | 821/6629 [00:02<00:20, 287.04it/s] 13%|█▎        | 850/6629 [00:02<00:20, 284.56it/s] 13%|█▎        | 880/6629 [00:03<00:20, 287.05it/s] 14%|█▎        | 910/6629 [00:03<00:19, 289.01it/s] 14%|█▍        | 939/6629 [00:03<00:19, 288.78it/s] 15%|█▍        | 968/6629 [00:03<00:19, 289.11it/s] 15%|█▌        | 997/6629 [00:03<00:19, 288.93it/s] 15%|█▌        | 1026/6629 [00:03<00:19, 288.47it/s] 16%|█▌        | 1056/6629 [00:03<00:19, 291.90it/s] 16%|█▋        | 1087/6629 [00:03<00:18, 294.80it/s] 17%|█▋        | 1117/6629 [00:03<00:18, 294.06it/s] 17%|█▋        | 1148/6629 [00:03<00:18, 297.12it/s] 18%|█▊        | 1179/6629 [00:04<00:18, 298.31it/s] 18%|█▊        | 1209/6629 [00:04<00:18, 298.80it/s] 19%|█▊        | 1240/6629 [00:04<00:17, 301.07it/s] 19%|█▉        | 1271/6629 [00:04<00:17, 300.47it/s] 20%|█▉        | 1302/6629 [00:04<00:17, 300.80it/s] 20%|██        | 1333/6629 [00:04<00:17, 299.14it/s] 21%|██        | 1364/6629 [00:04<00:17, 299.86it/s] 21%|██        | 1395/6629 [00:04<00:17, 300.05it/s] 22%|██▏       | 1426/6629 [00:04<00:17, 300.91it/s] 22%|██▏       | 1457/6629 [00:04<00:17, 301.87it/s] 22%|██▏       | 1488/6629 [00:05<00:17, 301.08it/s] 23%|██▎       | 1519/6629 [00:05<00:16, 301.21it/s] 23%|██▎       | 1550/6629 [00:05<00:16, 299.56it/s] 24%|██▍       | 1580/6629 [00:05<00:16, 298.50it/s] 24%|██▍       | 1610/6629 [00:05<00:16, 298.08it/s] 25%|██▍       | 1640/6629 [00:05<00:16, 298.52it/s] 25%|██▌       | 1671/6629 [00:05<00:16, 299.97it/s] 26%|██▌       | 1702/6629 [00:05<00:16, 300.99it/s] 26%|██▌       | 1733/6629 [00:05<00:16, 301.74it/s] 27%|██▋       | 1764/6629 [00:06<00:16, 303.53it/s] 27%|██▋       | 1795/6629 [00:06<00:16, 300.11it/s] 28%|██▊       | 1826/6629 [00:06<00:15, 302.02it/s] 28%|██▊       | 1857/6629 [00:06<00:15, 302.62it/s] 28%|██▊       | 1888/6629 [00:06<00:15, 300.83it/s] 29%|██▉       | 1919/6629 [00:06<00:15, 301.32it/s] 29%|██▉       | 1950/6629 [00:06<00:15, 302.15it/s] 30%|██▉       | 1981/6629 [00:06<00:15, 301.46it/s] 30%|███       | 2012/6629 [00:06<00:15, 301.40it/s] 31%|███       | 2043/6629 [00:06<00:15, 300.05it/s] 31%|███▏      | 2074/6629 [00:07<00:15, 300.54it/s] 32%|███▏      | 2105/6629 [00:07<00:15, 299.23it/s] 32%|███▏      | 2136/6629 [00:07<00:14, 299.79it/s] 33%|███▎      | 2167/6629 [00:07<00:14, 300.63it/s] 33%|███▎      | 2198/6629 [00:07<00:14, 300.51it/s] 34%|███▎      | 2229/6629 [00:07<00:14, 299.26it/s] 34%|███▍      | 2260/6629 [00:07<00:14, 300.20it/s] 35%|███▍      | 2291/6629 [00:07<00:14, 298.62it/s] 35%|███▌      | 2322/6629 [00:07<00:14, 299.73it/s] 35%|███▌      | 2353/6629 [00:07<00:14, 300.26it/s] 36%|███▌      | 2384/6629 [00:08<00:14, 299.41it/s] 36%|███▋      | 2415/6629 [00:08<00:14, 300.53it/s] 37%|███▋      | 2446/6629 [00:08<00:13, 299.75it/s] 37%|███▋      | 2477/6629 [00:08<00:13, 300.02it/s] 38%|███▊      | 2508/6629 [00:08<00:13, 301.97it/s] 38%|███▊      | 2539/6629 [00:08<00:13, 300.81it/s] 39%|███▉      | 2570/6629 [00:08<00:13, 298.59it/s] 39%|███▉      | 2601/6629 [00:08<00:13, 299.12it/s] 40%|███▉      | 2632/6629 [00:08<00:13, 299.43it/s] 40%|████      | 2663/6629 [00:09<00:13, 299.79it/s] 41%|████      | 2694/6629 [00:09<00:13, 300.54it/s] 41%|████      | 2725/6629 [00:09<00:13, 299.26it/s] 42%|████▏     | 2756/6629 [00:09<00:12, 299.59it/s] 42%|████▏     | 2786/6629 [00:09<00:12, 298.07it/s] 42%|████▏     | 2817/6629 [00:09<00:12, 299.14it/s] 43%|████▎     | 2848/6629 [00:09<00:12, 299.77it/s] 43%|████▎     | 2878/6629 [00:09<00:12, 299.13it/s] 44%|████▍     | 2909/6629 [00:09<00:12, 299.64it/s] 44%|████▍     | 2940/6629 [00:09<00:12, 300.48it/s] 45%|████▍     | 2971/6629 [00:10<00:12, 300.29it/s] 45%|████▌     | 3002/6629 [00:10<00:12, 300.32it/s] 46%|████▌     | 3033/6629 [00:10<00:12, 298.97it/s] 46%|████▌     | 3064/6629 [00:10<00:11, 299.50it/s] 47%|████▋     | 3095/6629 [00:10<00:11, 299.91it/s] 47%|████▋     | 3126/6629 [00:10<00:11, 300.63it/s] 48%|████▊     | 3157/6629 [00:10<00:11, 300.09it/s] 48%|████▊     | 3188/6629 [00:10<00:11, 299.63it/s] 49%|████▊     | 3218/6629 [00:10<00:11, 299.44it/s] 49%|████▉     | 3249/6629 [00:10<00:11, 299.90it/s] 49%|████▉     | 3279/6629 [00:11<00:11, 298.33it/s] 50%|████▉     | 3309/6629 [00:11<00:11, 298.06it/s] 50%|█████     | 3340/6629 [00:11<00:10, 299.47it/s] 51%|█████     | 3370/6629 [00:11<00:10, 298.80it/s] 51%|█████▏    | 3401/6629 [00:11<00:10, 300.34it/s] 52%|█████▏    | 3432/6629 [00:11<00:10, 301.62it/s] 52%|█████▏    | 3463/6629 [00:11<00:10, 301.47it/s] 53%|█████▎    | 3494/6629 [00:11<00:10, 302.41it/s] 53%|█████▎    | 3525/6629 [00:11<00:10, 300.83it/s] 54%|█████▎    | 3556/6629 [00:11<00:10, 300.85it/s] 54%|█████▍    | 3587/6629 [00:12<00:10, 301.12it/s] 55%|█████▍    | 3618/6629 [00:12<00:09, 301.47it/s] 55%|█████▌    | 3649/6629 [00:12<00:09, 300.32it/s] 56%|█████▌    | 3680/6629 [00:12<00:09, 300.59it/s] 56%|█████▌    | 3711/6629 [00:12<00:09, 301.77it/s] 56%|█████▋    | 3742/6629 [00:12<00:09, 301.19it/s] 57%|█████▋    | 3773/6629 [00:12<00:09, 300.50it/s] 57%|█████▋    | 3804/6629 [00:12<00:09, 299.37it/s] 58%|█████▊    | 3835/6629 [00:12<00:09, 300.28it/s] 58%|█████▊    | 3866/6629 [00:13<00:09, 301.71it/s] 59%|█████▉    | 3897/6629 [00:13<00:09, 301.12it/s] 59%|█████▉    | 3928/6629 [00:13<00:08, 301.87it/s] 60%|█████▉    | 3959/6629 [00:13<00:08, 300.28it/s] 60%|██████    | 3990/6629 [00:13<00:08, 301.75it/s] 61%|██████    | 4021/6629 [00:13<00:08, 301.23it/s] 61%|██████    | 4052/6629 [00:13<00:08, 300.41it/s] 62%|██████▏   | 4083/6629 [00:13<00:08, 298.69it/s] 62%|██████▏   | 4113/6629 [00:13<00:08, 298.99it/s] 63%|██████▎   | 4144/6629 [00:13<00:08, 300.09it/s] 63%|██████▎   | 4175/6629 [00:14<00:08, 300.11it/s] 63%|██████▎   | 4206/6629 [00:14<00:08, 300.38it/s] 64%|██████▍   | 4237/6629 [00:14<00:07, 299.55it/s] 64%|██████▍   | 4267/6629 [00:14<00:07, 299.46it/s] 65%|██████▍   | 4298/6629 [00:14<00:07, 300.01it/s] 65%|██████▌   | 4329/6629 [00:14<00:07, 300.88it/s] 66%|██████▌   | 4360/6629 [00:14<00:07, 301.18it/s] 66%|██████▌   | 4391/6629 [00:14<00:07, 300.31it/s] 67%|██████▋   | 4422/6629 [00:14<00:07, 300.45it/s] 67%|██████▋   | 4453/6629 [00:14<00:07, 300.13it/s] 68%|██████▊   | 4484/6629 [00:15<00:07, 301.14it/s] 68%|██████▊   | 4515/6629 [00:15<00:07, 301.98it/s] 69%|██████▊   | 4546/6629 [00:15<00:06, 300.70it/s] 69%|██████▉   | 4577/6629 [00:15<00:06, 300.39it/s] 70%|██████▉   | 4608/6629 [00:15<00:06, 301.17it/s] 70%|██████▉   | 4639/6629 [00:15<00:06, 301.56it/s] 70%|███████   | 4670/6629 [00:15<00:06, 299.58it/s] 71%|███████   | 4701/6629 [00:15<00:06, 299.71it/s] 71%|███████▏  | 4732/6629 [00:15<00:06, 300.68it/s] 72%|███████▏  | 4763/6629 [00:16<00:06, 299.26it/s] 72%|███████▏  | 4794/6629 [00:16<00:06, 300.75it/s] 73%|███████▎  | 4825/6629 [00:16<00:06, 298.95it/s] 73%|███████▎  | 4855/6629 [00:16<00:05, 297.83it/s] 74%|███████▎  | 4886/6629 [00:16<00:05, 298.95it/s] 74%|███████▍  | 4917/6629 [00:16<00:05, 299.90it/s] 75%|███████▍  | 4948/6629 [00:16<00:05, 300.28it/s] 75%|███████▌  | 4979/6629 [00:16<00:05, 300.38it/s] 76%|███████▌  | 5010/6629 [00:16<00:05, 298.38it/s] 76%|███████▌  | 5041/6629 [00:16<00:05, 299.27it/s] 76%|███████▋  | 5071/6629 [00:17<00:05, 299.47it/s] 77%|███████▋  | 5101/6629 [00:17<00:05, 299.25it/s] 77%|███████▋  | 5132/6629 [00:17<00:04, 299.87it/s] 78%|███████▊  | 5162/6629 [00:17<00:04, 298.83it/s] 78%|███████▊  | 5192/6629 [00:17<00:04, 298.20it/s] 79%|███████▉  | 5222/6629 [00:17<00:04, 297.66it/s] 79%|███████▉  | 5252/6629 [00:17<00:04, 298.30it/s] 80%|███████▉  | 5282/6629 [00:17<00:04, 297.45it/s] 80%|████████  | 5313/6629 [00:17<00:04, 298.98it/s] 81%|████████  | 5344/6629 [00:17<00:04, 299.60it/s] 81%|████████  | 5375/6629 [00:18<00:04, 300.74it/s] 82%|████████▏ | 5406/6629 [00:18<00:04, 297.93it/s] 82%|████████▏ | 5437/6629 [00:18<00:03, 299.58it/s] 82%|████████▏ | 5467/6629 [00:18<00:03, 296.99it/s] 83%|████████▎ | 5498/6629 [00:18<00:03, 298.97it/s] 83%|████████▎ | 5529/6629 [00:18<00:03, 299.95it/s] 84%|████████▍ | 5560/6629 [00:18<00:03, 300.56it/s] 84%|████████▍ | 5591/6629 [00:18<00:03, 300.53it/s] 85%|████████▍ | 5622/6629 [00:18<00:03, 301.63it/s] 85%|████████▌ | 5653/6629 [00:18<00:03, 301.57it/s] 86%|████████▌ | 5684/6629 [00:19<00:03, 301.71it/s] 86%|████████▌ | 5715/6629 [00:19<00:03, 299.95it/s] 87%|████████▋ | 5745/6629 [00:19<00:02, 299.85it/s] 87%|████████▋ | 5776/6629 [00:19<00:02, 300.47it/s] 88%|████████▊ | 5807/6629 [00:19<00:02, 301.54it/s] 88%|████████▊ | 5838/6629 [00:19<00:02, 300.56it/s] 89%|████████▊ | 5869/6629 [00:19<00:02, 302.04it/s] 89%|████████▉ | 5900/6629 [00:19<00:02, 302.02it/s] 89%|████████▉ | 5931/6629 [00:19<00:02, 302.00it/s] 90%|████████▉ | 5962/6629 [00:20<00:02, 302.14it/s] 90%|█████████ | 5993/6629 [00:20<00:02, 298.77it/s] 91%|█████████ | 6023/6629 [00:20<00:02, 297.08it/s] 91%|█████████▏| 6054/6629 [00:20<00:01, 298.11it/s] 92%|█████████▏| 6084/6629 [00:20<00:01, 297.63it/s] 92%|█████████▏| 6115/6629 [00:20<00:01, 298.44it/s] 93%|█████████▎| 6146/6629 [00:20<00:01, 299.11it/s] 93%|█████████▎| 6176/6629 [00:20<00:01, 296.86it/s] 94%|█████████▎| 6206/6629 [00:20<00:01, 297.00it/s] 94%|█████████▍| 6236/6629 [00:20<00:01, 297.26it/s] 95%|█████████▍| 6267/6629 [00:21<00:01, 298.81it/s] 95%|█████████▍| 6297/6629 [00:21<00:01, 298.08it/s] 95%|█████████▌| 6327/6629 [00:21<00:01, 298.20it/s] 96%|█████████▌| 6357/6629 [00:21<00:00, 297.19it/s] 96%|█████████▋| 6387/6629 [00:21<00:00, 297.46it/s] 97%|█████████▋| 6417/6629 [00:21<00:00, 297.80it/s] 97%|█████████▋| 6447/6629 [00:21<00:00, 297.62it/s] 98%|█████████▊| 6477/6629 [00:21<00:00, 297.85it/s] 98%|█████████▊| 6507/6629 [00:21<00:00, 298.15it/s] 99%|█████████▊| 6538/6629 [00:21<00:00, 298.91it/s] 99%|█████████▉| 6569/6629 [00:22<00:00, 300.85it/s]100%|█████████▉| 6600/6629 [00:22<00:00, 301.43it/s]100%|██████████| 6629/6629 [00:22<00:00, 298.10it/s]AVERAGE DENSITY :0.0
2022-03-21 20:08:32 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-21 20:08:32 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-21 20:08:32 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-21 20:08:32 | INFO | fairseq_cli.train | criterion: KneserNeySmoothingCriterion
2022-03-21 20:08:32 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-21 20:08:32 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-21 20:08:32 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-21 20:08:32 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-21 20:08:32 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-21 20:08:32 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-21 20:08:32 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-21 20:08:32 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 7.929 GB ; name = NVIDIA GeForce GTX 1080                 
2022-03-21 20:08:32 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-21 20:08:32 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-21 20:08:32 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-21 20:08:32 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_kneser_n2_d0.9_#4/checkpoint_last.pt
2022-03-21 20:08:32 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_kneser_n2_d0.9_#4/checkpoint_last.pt
2022-03-21 20:08:32 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-21 20:08:32 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-21 20:08:32 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-21 20:08:32 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-21 20:08:33 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16 or --amp, please switch to FP32 which is likely to be faster
2022-03-21 20:08:33 | INFO | fairseq.trainer | begin training epoch 1
2022-03-21 20:08:33 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-21 20:08:34 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 7.93 GiB total capacity; 6.84 GiB already allocated; 132.44 MiB free; 7.13 GiB reserved in total by PyTorch)
2022-03-21 20:08:34 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7007 MB |    7064 MB |   10021 MB |    3013 MB |
|       from large pool |    6942 MB |    7000 MB |    9950 MB |    3007 MB |
|       from small pool |      64 MB |      64 MB |      70 MB |       6 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7007 MB |    7064 MB |   10021 MB |    3013 MB |
|       from large pool |    6942 MB |    7000 MB |    9950 MB |    3007 MB |
|       from small pool |      64 MB |      64 MB |      70 MB |       6 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7298 MB |    7358 MB |    7358 MB |   61440 KB |
|       from large pool |    7232 MB |    7292 MB |    7292 MB |   61440 KB |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  297596 KB |  302423 KB |     791 MB |  512754 KB |
|       from large pool |  296006 KB |  300598 KB |     740 MB |  462201 KB |
|       from small pool |    1590 KB |    2096 KB |      50 MB |   50553 KB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     574    |    7349    |    6778    |
|       from large pool |     246    |     248    |     359    |     113    |
|       from small pool |     325    |     326    |    6990    |    6665    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     574    |    7349    |    6778    |
|       from large pool |     246    |     248    |     359    |     113    |
|       from small pool |     325    |     326    |    6990    |    6665    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     239    |     241    |     241    |       2    |
|       from large pool |     206    |     208    |     208    |       2    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     172    |     176    |     326    |     154    |
|       from large pool |     168    |     171    |     284    |     116    |
|       from small pool |       4    |       6    |      42    |      38    |
|===========================================================================|

2022-03-21 20:08:34 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:35 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 7.11 GiB already allocated; 120.44 MiB free; 7.14 GiB reserved in total by PyTorch)
2022-03-21 20:08:35 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 3         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7275 MB |    7335 MB |   20079 MB |   12803 MB |
|       from large pool |    7210 MB |    7270 MB |   20000 MB |   12790 MB |
|       from small pool |      65 MB |      65 MB |      78 MB |      13 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7275 MB |    7335 MB |   20079 MB |   12803 MB |
|       from large pool |    7210 MB |    7270 MB |   20000 MB |   12790 MB |
|       from small pool |      65 MB |      65 MB |      78 MB |      13 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7310 MB |    7426 MB |    8750 MB |    1440 MB |
|       from large pool |    7244 MB |    7360 MB |    8684 MB |    1440 MB |
|       from small pool |      66 MB |      66 MB |      66 MB |       0 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   35001 KB |  372452 KB |    1548 MB |    1514 MB |
|       from large pool |   34404 KB |  371098 KB |    1487 MB |    1453 MB |
|       from small pool |     596 KB |    3068 KB |      61 MB |      61 MB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     574    |    7803    |    7232    |
|       from large pool |     245    |     248    |     711    |     466    |
|       from small pool |     326    |     327    |    7092    |    6766    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     574    |    7803    |    7232    |
|       from large pool |     245    |     248    |     711    |     466    |
|       from small pool |     326    |     327    |    7092    |    6766    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     233    |     241    |     269    |      36    |
|       from large pool |     200    |     208    |     236    |      36    |
|       from small pool |      33    |      33    |      33    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      27    |     176    |     429    |     402    |
|       from large pool |      23    |     171    |     349    |     326    |
|       from small pool |       4    |       6    |      80    |      76    |
|===========================================================================|

2022-03-21 20:08:35 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:36 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 7.93 GiB total capacity; 6.99 GiB already allocated; 16.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:08:36 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 5         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7161 MB |    7335 MB |   29955 MB |   22793 MB |
|       from large pool |    7097 MB |    7270 MB |   29869 MB |   22772 MB |
|       from small pool |      64 MB |      65 MB |      86 MB |      21 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7161 MB |    7335 MB |   29955 MB |   22793 MB |
|       from large pool |    7097 MB |    7270 MB |   29869 MB |   22772 MB |
|       from small pool |      64 MB |      65 MB |      86 MB |      21 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7414 MB |    7426 MB |   10566 MB |    3152 MB |
|       from large pool |    7348 MB |    7360 MB |   10498 MB |    3150 MB |
|       from small pool |      66 MB |      66 MB |      68 MB |       2 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  258155 KB |  679838 KB |    4273 MB |    4021 MB |
|       from large pool |  256684 KB |  679051 KB |    4199 MB |    3948 MB |
|       from small pool |    1471 KB |    3078 KB |      73 MB |      72 MB |
|---------------------------------------------------------------------------|
| Allocations           |     566    |     574    |    8246    |    7680    |
|       from large pool |     242    |     248    |    1054    |     812    |
|       from small pool |     324    |     327    |    7192    |    6868    |
|---------------------------------------------------------------------------|
| Active allocs         |     566    |     574    |    8246    |    7680    |
|       from large pool |     242    |     248    |    1054    |     812    |
|       from small pool |     324    |     327    |    7192    |    6868    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     233    |     241    |     327    |      94    |
|       from large pool |     200    |     208    |     293    |      93    |
|       from small pool |      33    |      33    |      34    |       1    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     100    |     176    |     648    |     548    |
|       from large pool |      95    |     171    |     527    |     432    |
|       from small pool |       5    |       6    |     121    |     116    |
|===========================================================================|

2022-03-21 20:08:36 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:36 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.37 GiB already allocated; 34.44 MiB free; 7.22 GiB reserved in total by PyTorch)
2022-03-21 20:08:36 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 7         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6519 MB |    7335 MB |   38948 MB |   32429 MB |
|       from large pool |    6455 MB |    7270 MB |   38856 MB |   32400 MB |
|       from small pool |      63 MB |      65 MB |      92 MB |      28 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6519 MB |    7335 MB |   38948 MB |   32429 MB |
|       from large pool |    6455 MB |    7270 MB |   38856 MB |   32400 MB |
|       from small pool |      63 MB |      65 MB |      92 MB |      28 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7396 MB |    7426 MB |   10894 MB |    3498 MB |
|       from large pool |    7332 MB |    7360 MB |   10826 MB |    3494 MB |
|       from small pool |      64 MB |      66 MB |      68 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     876 MB |    1218 MB |    7895 MB |    7018 MB |
|       from large pool |     876 MB |    1218 MB |    7809 MB |    6933 MB |
|       from small pool |       0 MB |       3 MB |      86 MB |      85 MB |
|---------------------------------------------------------------------------|
| Allocations           |     550    |     574    |    8673    |    8123    |
|       from large pool |     228    |     248    |    1383    |    1155    |
|       from small pool |     322    |     327    |    7290    |    6968    |
|---------------------------------------------------------------------------|
| Active allocs         |     550    |     574    |    8673    |    8123    |
|       from large pool |     228    |     248    |    1383    |    1155    |
|       from small pool |     322    |     327    |    7290    |    6968    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     222    |     241    |     336    |     114    |
|       from large pool |     190    |     208    |     302    |     112    |
|       from small pool |      32    |      33    |      34    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      89    |     176    |     858    |     769    |
|       from large pool |      84    |     171    |     686    |     602    |
|       from small pool |       5    |       7    |     172    |     167    |
|===========================================================================|

2022-03-21 20:08:36 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:37 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 330.00 MiB (GPU 0; 7.93 GiB total capacity; 5.86 GiB already allocated; 178.44 MiB free; 7.08 GiB reserved in total by PyTorch)
2022-03-21 20:08:37 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 5            |        cudaMalloc retries: 8         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    5978 MB |    7335 MB |   47225 MB |   41246 MB |
|       from large pool |    5914 MB |    7270 MB |   47127 MB |   41212 MB |
|       from small pool |      63 MB |      65 MB |      97 MB |      34 MB |
|---------------------------------------------------------------------------|
| Active memory         |    5978 MB |    7335 MB |   47225 MB |   41246 MB |
|       from large pool |    5914 MB |    7270 MB |   47127 MB |   41212 MB |
|       from small pool |      63 MB |      65 MB |      97 MB |      34 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7252 MB |    7426 MB |   10894 MB |    3642 MB |
|       from large pool |    7188 MB |    7360 MB |   10826 MB |    3638 MB |
|       from small pool |      64 MB |      66 MB |      68 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1241 MB |    1546 MB |   12604 MB |   11363 MB |
|       from large pool |    1241 MB |    1545 MB |   12509 MB |   11268 MB |
|       from small pool |       0 MB |       3 MB |      95 MB |      94 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |    9135    |    8562    |
|       from large pool |     246    |     248    |    1742    |    1496    |
|       from small pool |     327    |     327    |    7393    |    7066    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |    9135    |    8562    |
|       from large pool |     246    |     248    |    1742    |    1496    |
|       from small pool |     327    |     327    |    7393    |    7066    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     213    |     241    |     336    |     123    |
|       from large pool |     181    |     208    |     302    |     121    |
|       from small pool |      32    |      33    |      34    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     177    |     179    |    1193    |    1016    |
|       from large pool |     172    |     174    |     980    |     808    |
|       from small pool |       5    |       7    |     213    |     208    |
|===========================================================================|

2022-03-21 20:08:37 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:37 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 7.93 GiB total capacity; 6.29 GiB already allocated; 208.44 MiB free; 7.05 GiB reserved in total by PyTorch)
2022-03-21 20:08:37 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 6            |        cudaMalloc retries: 9         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6444 MB |    7335 MB |   56044 MB |   49600 MB |
|       from large pool |    6380 MB |    7270 MB |   55940 MB |   49560 MB |
|       from small pool |      64 MB |      65 MB |     104 MB |      39 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6444 MB |    7335 MB |   56044 MB |   49600 MB |
|       from large pool |    6380 MB |    7270 MB |   55940 MB |   49560 MB |
|       from small pool |      64 MB |      65 MB |     104 MB |      39 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7222 MB |    7426 MB |   10896 MB |    3674 MB |
|       from large pool |    7156 MB |    7360 MB |   10826 MB |    3670 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     777 MB |    1773 MB |   16327 MB |   15549 MB |
|       from large pool |     775 MB |    1772 MB |   16218 MB |   15442 MB |
|       from small pool |       1 MB |       3 MB |     108 MB |     106 MB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     575    |    9589    |    9018    |
|       from large pool |     246    |     248    |    2095    |    1849    |
|       from small pool |     325    |     327    |    7494    |    7169    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     575    |    9589    |    9018    |
|       from large pool |     246    |     248    |    2095    |    1849    |
|       from small pool |     325    |     327    |    7494    |    7169    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     213    |     241    |     337    |     124    |
|       from large pool |     180    |     208    |     302    |     122    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     153    |     180    |    1515    |    1362    |
|       from large pool |     147    |     175    |    1259    |    1112    |
|       from small pool |       6    |       7    |     256    |     250    |
|===========================================================================|

2022-03-21 20:08:37 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:38 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.56 GiB already allocated; 12.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:08:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 7            |        cudaMalloc retries: 10        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6718 MB |    7335 MB |   65348 MB |   58630 MB |
|       from large pool |    6654 MB |    7270 MB |   65237 MB |   58583 MB |
|       from small pool |      64 MB |      65 MB |     110 MB |      46 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6718 MB |    7335 MB |   65348 MB |   58630 MB |
|       from large pool |    6654 MB |    7270 MB |   65237 MB |   58583 MB |
|       from small pool |      64 MB |      65 MB |     110 MB |      46 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7418 MB |    7426 MB |   11092 MB |    3674 MB |
|       from large pool |    7352 MB |    7360 MB |   11022 MB |    3670 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  716512 KB |    1773 MB |   19818 MB |   19118 MB |
|       from large pool |  714647 KB |    1772 MB |   19699 MB |   19001 MB |
|       from small pool |    1864 KB |       3 MB |     118 MB |     116 MB |
|---------------------------------------------------------------------------|
| Allocations           |     560    |     575    |   10030    |    9470    |
|       from large pool |     237    |     248    |    2437    |    2200    |
|       from small pool |     323    |     327    |    7593    |    7270    |
|---------------------------------------------------------------------------|
| Active allocs         |     560    |     575    |   10030    |    9470    |
|       from large pool |     237    |     248    |    2437    |    2200    |
|       from small pool |     323    |     327    |    7593    |    7270    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     221    |     241    |     345    |     124    |
|       from large pool |     188    |     208    |     310    |     122    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     105    |     180    |    1766    |    1661    |
|       from large pool |      98    |     175    |    1464    |    1366    |
|       from small pool |       7    |       7    |     302    |     295    |
|===========================================================================|

2022-03-21 20:08:38 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:39 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 6.34 GiB already allocated; 602.44 MiB free; 6.67 GiB reserved in total by PyTorch)
2022-03-21 20:08:39 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 8            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6487 MB |    7335 MB |   74285 MB |   67797 MB |
|       from large pool |    6423 MB |    7270 MB |   74168 MB |   67744 MB |
|       from small pool |      64 MB |      65 MB |     117 MB |      52 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6487 MB |    7335 MB |   74285 MB |   67797 MB |
|       from large pool |    6423 MB |    7270 MB |   74168 MB |   67744 MB |
|       from small pool |      64 MB |      65 MB |     117 MB |      52 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6828 MB |    7426 MB |   11092 MB |    4264 MB |
|       from large pool |    6762 MB |    7360 MB |   11022 MB |    4260 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  348188 KB |    1773 MB |   22913 MB |   22573 MB |
|       from large pool |  346307 KB |    1772 MB |   22782 MB |   22444 MB |
|       from small pool |    1881 KB |       3 MB |     130 MB |     128 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   10493    |    9921    |
|       from large pool |     246    |     248    |    2797    |    2551    |
|       from small pool |     326    |     327    |    7696    |    7370    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   10493    |    9921    |
|       from large pool |     246    |     248    |    2797    |    2551    |
|       from small pool |     326    |     327    |    7696    |    7370    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     206    |     241    |     345    |     139    |
|       from large pool |     173    |     208    |     310    |     137    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      56    |     180    |    1937    |    1881    |
|       from large pool |      52    |     175    |    1594    |    1542    |
|       from small pool |       4    |       8    |     343    |     339    |
|===========================================================================|

2022-03-21 20:08:39 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:39 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.65 GiB already allocated; 28.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:08:39 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 9            |        cudaMalloc retries: 12        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6809 MB |    7335 MB |   83719 MB |   76909 MB |
|       from large pool |    6745 MB |    7270 MB |   83595 MB |   76849 MB |
|       from small pool |      64 MB |      65 MB |     123 MB |      59 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6809 MB |    7335 MB |   83719 MB |   76909 MB |
|       from large pool |    6745 MB |    7270 MB |   83595 MB |   76849 MB |
|       from small pool |      64 MB |      65 MB |     123 MB |      59 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7402 MB |    7426 MB |   11666 MB |    4264 MB |
|       from large pool |    7336 MB |    7360 MB |   11596 MB |    4260 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  606260 KB |    1773 MB |   26352 MB |   25760 MB |
|       from large pool |  604509 KB |    1772 MB |   26211 MB |   25621 MB |
|       from small pool |    1750 KB |       3 MB |     140 MB |     139 MB |
|---------------------------------------------------------------------------|
| Allocations           |     568    |     575    |   10945    |   10377    |
|       from large pool |     243    |     248    |    3148    |    2905    |
|       from small pool |     325    |     327    |    7797    |    7472    |
|---------------------------------------------------------------------------|
| Active allocs         |     568    |     575    |   10945    |   10377    |
|       from large pool |     243    |     248    |    3148    |    2905    |
|       from small pool |     325    |     327    |    7797    |    7472    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     224    |     241    |     363    |     139    |
|       from large pool |     191    |     208    |     328    |     137    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     100    |     180    |    2166    |    2066    |
|       from large pool |      95    |     175    |    1784    |    1689    |
|       from small pool |       5    |       8    |     382    |     377    |
|===========================================================================|

2022-03-21 20:08:39 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:40 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.51 GiB already allocated; 28.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:08:40 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 10           |        cudaMalloc retries: 13        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6671 MB |    7335 MB |   92954 MB |   86283 MB |
|       from large pool |    6606 MB |    7270 MB |   92824 MB |   86217 MB |
|       from small pool |      64 MB |      65 MB |     130 MB |      66 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6671 MB |    7335 MB |   92954 MB |   86283 MB |
|       from large pool |    6606 MB |    7270 MB |   92824 MB |   86217 MB |
|       from small pool |      64 MB |      65 MB |     130 MB |      66 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7402 MB |    7426 MB |   11666 MB |    4264 MB |
|       from large pool |    7336 MB |    7360 MB |   11596 MB |    4260 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  748470 KB |    1773 MB |   30033 MB |   29302 MB |
|       from large pool |  746625 KB |    1772 MB |   29881 MB |   29152 MB |
|       from small pool |    1845 KB |       3 MB |     151 MB |     149 MB |
|---------------------------------------------------------------------------|
| Allocations           |     568    |     575    |   11397    |   10829    |
|       from large pool |     243    |     248    |    3499    |    3256    |
|       from small pool |     325    |     327    |    7898    |    7573    |
|---------------------------------------------------------------------------|
| Active allocs         |     568    |     575    |   11397    |   10829    |
|       from large pool |     243    |     248    |    3499    |    3256    |
|       from small pool |     325    |     327    |    7898    |    7573    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     224    |     241    |     363    |     139    |
|       from large pool |     191    |     208    |     328    |     137    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     103    |     180    |    2416    |    2313    |
|       from large pool |      97    |     175    |    1993    |    1896    |
|       from small pool |       6    |       8    |     423    |     417    |
|===========================================================================|

2022-03-21 20:08:40 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:40 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.68 GiB already allocated; 28.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:08:40 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 11           |        cudaMalloc retries: 14        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6805 MB |    7335 MB |  102480 MB |   95674 MB |
|       from large pool |    6740 MB |    7270 MB |  102341 MB |   95601 MB |
|       from small pool |      65 MB |      65 MB |     138 MB |      73 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6805 MB |    7335 MB |  102480 MB |   95674 MB |
|       from large pool |    6740 MB |    7270 MB |  102341 MB |   95601 MB |
|       from small pool |      65 MB |      65 MB |     138 MB |      73 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7402 MB |    7426 MB |   11666 MB |    4264 MB |
|       from large pool |    7336 MB |    7360 MB |   11596 MB |    4260 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  578109 KB |    1773 MB |   32860 MB |   32295 MB |
|       from large pool |  577413 KB |    1772 MB |   32698 MB |   32134 MB |
|       from small pool |     695 KB |       3 MB |     162 MB |     161 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   11850    |   11278    |
|       from large pool |     245    |     248    |    3850    |    3605    |
|       from small pool |     327    |     327    |    8000    |    7673    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   11850    |   11278    |
|       from large pool |     245    |     248    |    3850    |    3605    |
|       from small pool |     327    |     327    |    8000    |    7673    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     224    |     241    |     363    |     139    |
|       from large pool |     191    |     208    |     328    |     137    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      59    |     180    |    2628    |    2569    |
|       from large pool |      54    |     175    |    2166    |    2112    |
|       from small pool |       5    |       8    |     462    |     457    |
|===========================================================================|

2022-03-21 20:08:40 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:41 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 824.00 MiB (GPU 0; 7.93 GiB total capacity; 6.45 GiB already allocated; 60.44 MiB free; 7.20 GiB reserved in total by PyTorch)
2022-03-21 20:08:41 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 12           |        cudaMalloc retries: 15        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6605 MB |    7335 MB |  111588 MB |  104982 MB |
|       from large pool |    6541 MB |    7270 MB |  111443 MB |  104902 MB |
|       from small pool |      64 MB |      65 MB |     144 MB |      80 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6605 MB |    7335 MB |  111588 MB |  104982 MB |
|       from large pool |    6541 MB |    7270 MB |  111443 MB |  104902 MB |
|       from small pool |      64 MB |      65 MB |     144 MB |      80 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7370 MB |    7426 MB |   11666 MB |    4296 MB |
|       from large pool |    7304 MB |    7360 MB |   11596 MB |    4292 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  783121 KB |    1773 MB |   35258 MB |   34494 MB |
|       from large pool |  781311 KB |    1772 MB |   35081 MB |   34318 MB |
|       from small pool |    1810 KB |       3 MB |     176 MB |     175 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   12313    |   11741    |
|       from large pool |     246    |     248    |    4210    |    3964    |
|       from small pool |     326    |     327    |    8103    |    7777    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   12313    |   11741    |
|       from large pool |     246    |     248    |    4210    |    3964    |
|       from small pool |     326    |     327    |    8103    |    7777    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     223    |     241    |     363    |     140    |
|       from large pool |     190    |     208    |     328    |     138    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      80    |     180    |    2853    |    2773    |
|       from large pool |      75    |     175    |    2341    |    2266    |
|       from small pool |       5    |       8    |     512    |     507    |
|===========================================================================|

2022-03-21 20:08:41 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:42 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 7.07 GiB already allocated; 96.44 MiB free; 7.16 GiB reserved in total by PyTorch)
2022-03-21 20:08:42 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 13           |        cudaMalloc retries: 17        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7208 MB |    7335 MB |  121660 MB |  114451 MB |
|       from large pool |    7143 MB |    7270 MB |  121508 MB |  114364 MB |
|       from small pool |      64 MB |      65 MB |     152 MB |      87 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7208 MB |    7335 MB |  121660 MB |  114451 MB |
|       from large pool |    7143 MB |    7270 MB |  121508 MB |  114364 MB |
|       from small pool |      64 MB |      65 MB |     152 MB |      87 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7334 MB |    7426 MB |   12458 MB |    5124 MB |
|       from large pool |    7268 MB |    7360 MB |   12388 MB |    5120 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   95502 KB |    1773 MB |   36983 MB |   36890 MB |
|       from large pool |   94296 KB |    1772 MB |   36796 MB |   36704 MB |
|       from small pool |    1206 KB |       3 MB |     187 MB |     186 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   12766    |   12194    |
|       from large pool |     246    |     248    |    4562    |    4316    |
|       from small pool |     326    |     327    |    8204    |    7878    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   12766    |   12194    |
|       from large pool |     246    |     248    |    4562    |    4316    |
|       from small pool |     326    |     327    |    8204    |    7878    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     232    |     241    |     387    |     155    |
|       from large pool |     199    |     208    |     352    |     153    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      27    |     180    |    2939    |    2912    |
|       from large pool |      23    |     175    |    2387    |    2364    |
|       from small pool |       4    |       8    |     552    |     548    |
|===========================================================================|

2022-03-21 20:08:42 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:42 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.75 GiB already allocated; 128.44 MiB free; 7.13 GiB reserved in total by PyTorch)
2022-03-21 20:08:42 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 14           |        cudaMalloc retries: 18        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6878 MB |    7335 MB |  131266 MB |  124387 MB |
|       from large pool |    6813 MB |    7270 MB |  131106 MB |  124292 MB |
|       from small pool |      64 MB |      65 MB |     159 MB |      95 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6878 MB |    7335 MB |  131266 MB |  124387 MB |
|       from large pool |    6813 MB |    7270 MB |  131106 MB |  124292 MB |
|       from small pool |      64 MB |      65 MB |     159 MB |      95 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7302 MB |    7426 MB |   12458 MB |    5156 MB |
|       from large pool |    7236 MB |    7360 MB |   12388 MB |    5152 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  401140 KB |    1773 MB |   39377 MB |   38986 MB |
|       from large pool |  399725 KB |    1772 MB |   39178 MB |   38788 MB |
|       from small pool |    1415 KB |       3 MB |     198 MB |     197 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   13219    |   12647    |
|       from large pool |     246    |     248    |    4914    |    4668    |
|       from small pool |     326    |     327    |    8305    |    7979    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   13219    |   12647    |
|       from large pool |     246    |     248    |    4914    |    4668    |
|       from small pool |     326    |     327    |    8305    |    7979    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     231    |     241    |     387    |     156    |
|       from large pool |     198    |     208    |     352    |     154    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     114    |     180    |    3149    |    3035    |
|       from large pool |     108    |     175    |    2557    |    2449    |
|       from small pool |       6    |       8    |     592    |     586    |
|===========================================================================|

2022-03-21 20:08:42 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:44 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.61 GiB already allocated; 352.44 MiB free; 6.91 GiB reserved in total by PyTorch)
2022-03-21 20:08:44 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 15           |        cudaMalloc retries: 19        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6734 MB |    7335 MB |  140673 MB |  133938 MB |
|       from large pool |    6670 MB |    7270 MB |  140506 MB |  133836 MB |
|       from small pool |      64 MB |      65 MB |     166 MB |     102 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6734 MB |    7335 MB |  140673 MB |  133938 MB |
|       from large pool |    6670 MB |    7270 MB |  140506 MB |  133836 MB |
|       from small pool |      64 MB |      65 MB |     166 MB |     102 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7078 MB |    7426 MB |   12458 MB |    5380 MB |
|       from large pool |    7012 MB |    7360 MB |   12388 MB |    5376 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  318476 KB |    1773 MB |   41687 MB |   41376 MB |
|       from large pool |  317014 KB |    1772 MB |   41477 MB |   41167 MB |
|       from small pool |    1461 KB |       3 MB |     209 MB |     208 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   13672    |   13100    |
|       from large pool |     246    |     248    |    5266    |    5020    |
|       from small pool |     326    |     327    |    8406    |    8080    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   13672    |   13100    |
|       from large pool |     246    |     248    |    5266    |    5020    |
|       from small pool |     326    |     327    |    8406    |    8080    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     224    |     241    |     387    |     163    |
|       from large pool |     191    |     208    |     352    |     161    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      76    |     180    |    3344    |    3268    |
|       from large pool |      71    |     175    |    2712    |    2641    |
|       from small pool |       5    |       8    |     632    |     627    |
|===========================================================================|

2022-03-21 20:08:44 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:44 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 410.00 MiB (GPU 0; 7.93 GiB total capacity; 6.55 GiB already allocated; 80.44 MiB free; 7.18 GiB reserved in total by PyTorch)
2022-03-21 20:08:44 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 16           |        cudaMalloc retries: 20        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6673 MB |    7335 MB |  150039 MB |  143365 MB |
|       from large pool |    6609 MB |    7270 MB |  149865 MB |  143256 MB |
|       from small pool |      64 MB |      65 MB |     173 MB |     109 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6673 MB |    7335 MB |  150039 MB |  143365 MB |
|       from large pool |    6609 MB |    7270 MB |  149865 MB |  143256 MB |
|       from small pool |      64 MB |      65 MB |     173 MB |     109 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7350 MB |    7426 MB |   12762 MB |    5412 MB |
|       from large pool |    7284 MB |    7360 MB |   12692 MB |    5408 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  659986 KB |    1773 MB |   44850 MB |   44205 MB |
|       from large pool |  658254 KB |    1772 MB |   44629 MB |   43986 MB |
|       from small pool |    1731 KB |       3 MB |     220 MB |     218 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   14134    |   13561    |
|       from large pool |     246    |     248    |    5625    |    5379    |
|       from small pool |     327    |     327    |    8509    |    8182    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   14134    |   13561    |
|       from large pool |     246    |     248    |    5625    |    5379    |
|       from small pool |     327    |     327    |    8509    |    8182    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     231    |     241    |     395    |     164    |
|       from large pool |     198    |     208    |     360    |     162    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     106    |     180    |    3579    |    3473    |
|       from large pool |      99    |     175    |    2905    |    2806    |
|       from small pool |       7    |       8    |     674    |     667    |
|===========================================================================|

2022-03-21 20:08:44 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:45 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 7.93 GiB total capacity; 6.84 GiB already allocated; 112.44 MiB free; 7.15 GiB reserved in total by PyTorch)
2022-03-21 20:08:45 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 17           |        cudaMalloc retries: 21        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6973 MB |    7335 MB |  159759 MB |  152785 MB |
|       from large pool |    6908 MB |    7270 MB |  159578 MB |  152669 MB |
|       from small pool |      64 MB |      65 MB |     181 MB |     116 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6973 MB |    7335 MB |  159759 MB |  152785 MB |
|       from large pool |    6908 MB |    7270 MB |  159578 MB |  152669 MB |
|       from small pool |      64 MB |      65 MB |     181 MB |     116 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7318 MB |    7426 MB |   12762 MB |    5444 MB |
|       from large pool |    7252 MB |    7360 MB |   12692 MB |    5440 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  320232 KB |    1773 MB |   47268 MB |   46955 MB |
|       from large pool |  318874 KB |    1772 MB |   47037 MB |   46725 MB |
|       from small pool |    1358 KB |       3 MB |     231 MB |     230 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   14587    |   14015    |
|       from large pool |     246    |     248    |    5977    |    5731    |
|       from small pool |     326    |     327    |    8610    |    8284    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   14587    |   14015    |
|       from large pool |     246    |     248    |    5977    |    5731    |
|       from small pool |     326    |     327    |    8610    |    8284    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     230    |     241    |     395    |     165    |
|       from large pool |     197    |     208    |     360    |     163    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     103    |     180    |    3797    |    3694    |
|       from large pool |      97    |     175    |    3083    |    2986    |
|       from small pool |       6    |       8    |     714    |     708    |
|===========================================================================|

2022-03-21 20:08:45 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:45 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.51 GiB already allocated; 28.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:08:45 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 18           |        cudaMalloc retries: 22        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6661 MB |    7335 MB |  168985 MB |  162323 MB |
|       from large pool |    6597 MB |    7270 MB |  168797 MB |  162200 MB |
|       from small pool |      64 MB |      65 MB |     187 MB |     123 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6661 MB |    7335 MB |  168985 MB |  162323 MB |
|       from large pool |    6597 MB |    7270 MB |  168797 MB |  162200 MB |
|       from small pool |      64 MB |      65 MB |     187 MB |     123 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7402 MB |    7426 MB |   12878 MB |    5476 MB |
|       from large pool |    7336 MB |    7360 MB |   12808 MB |    5472 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  758475 KB |    1773 MB |   50215 MB |   49474 MB |
|       from large pool |  756587 KB |    1772 MB |   49972 MB |   49233 MB |
|       from small pool |    1888 KB |       3 MB |     242 MB |     240 MB |
|---------------------------------------------------------------------------|
| Allocations           |     550    |     575    |   15015    |   14465    |
|       from large pool |     229    |     248    |    6308    |    6079    |
|       from small pool |     321    |     327    |    8707    |    8386    |
|---------------------------------------------------------------------------|
| Active allocs         |     550    |     575    |   15015    |   14465    |
|       from large pool |     229    |     248    |    6308    |    6079    |
|       from small pool |     321    |     327    |    8707    |    8386    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     233    |     241    |     399    |     166    |
|       from large pool |     200    |     208    |     364    |     164    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     122    |     180    |    4033    |    3911    |
|       from large pool |     116    |     175    |    3280    |    3164    |
|       from small pool |       6    |       8    |     753    |     747    |
|===========================================================================|

2022-03-21 20:08:45 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:46 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 824.00 MiB (GPU 0; 7.93 GiB total capacity; 6.23 GiB already allocated; 552.44 MiB free; 6.72 GiB reserved in total by PyTorch)
2022-03-21 20:08:46 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 19           |        cudaMalloc retries: 24        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6379 MB |    7335 MB |  177771 MB |  171391 MB |
|       from large pool |    6315 MB |    7270 MB |  177577 MB |  171261 MB |
|       from small pool |      64 MB |      65 MB |     194 MB |     130 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6379 MB |    7335 MB |  177771 MB |  171391 MB |
|       from large pool |    6315 MB |    7270 MB |  177577 MB |  171261 MB |
|       from small pool |      64 MB |      65 MB |     194 MB |     130 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6878 MB |    7426 MB |   13290 MB |    6412 MB |
|       from large pool |    6812 MB |    7360 MB |   13220 MB |    6408 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  510000 KB |    1773 MB |   53373 MB |   52875 MB |
|       from large pool |  508072 KB |    1772 MB |   53119 MB |   52623 MB |
|       from small pool |    1928 KB |       3 MB |     254 MB |     252 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   15478    |   14906    |
|       from large pool |     246    |     248    |    6668    |    6422    |
|       from small pool |     326    |     327    |    8810    |    8484    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   15478    |   14906    |
|       from large pool |     246    |     248    |    6668    |    6422    |
|       from small pool |     326    |     327    |    8810    |    8484    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     201    |     241    |     400    |     199    |
|       from large pool |     168    |     208    |     365    |     197    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      65    |     180    |    4191    |    4126    |
|       from large pool |      60    |     175    |    3394    |    3334    |
|       from small pool |       5    |       8    |     797    |     792    |
|===========================================================================|

2022-03-21 20:08:46 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:47 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.90 GiB already allocated; 94.44 MiB free; 7.16 GiB reserved in total by PyTorch)
2022-03-21 20:08:47 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 20           |        cudaMalloc retries: 25        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7035 MB |    7335 MB |  187594 MB |  180559 MB |
|       from large pool |    6970 MB |    7270 MB |  187393 MB |  180422 MB |
|       from small pool |      64 MB |      65 MB |     201 MB |     136 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7035 MB |    7335 MB |  187594 MB |  180559 MB |
|       from large pool |    6970 MB |    7270 MB |  187393 MB |  180422 MB |
|       from small pool |      64 MB |      65 MB |     201 MB |     136 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7336 MB |    7426 MB |   13768 MB |    6432 MB |
|       from large pool |    7270 MB |    7360 MB |   13698 MB |    6428 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  275279 KB |    1773 MB |   56678 MB |   56410 MB |
|       from large pool |  273937 KB |    1772 MB |   56414 MB |   56146 MB |
|       from small pool |    1341 KB |       3 MB |     264 MB |     263 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   15931    |   15359    |
|       from large pool |     246    |     248    |    7020    |    6774    |
|       from small pool |     326    |     327    |    8911    |    8585    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   15931    |   15359    |
|       from large pool |     246    |     248    |    7020    |    6774    |
|       from small pool |     326    |     327    |    8911    |    8585    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     215    |     241    |     415    |     200    |
|       from large pool |     182    |     208    |     380    |     198    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     105    |     180    |    4392    |    4287    |
|       from large pool |      99    |     175    |    3556    |    3457    |
|       from small pool |       6    |       8    |     836    |     830    |
|===========================================================================|

2022-03-21 20:08:47 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:48 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 826.00 MiB (GPU 0; 7.93 GiB total capacity; 6.27 GiB already allocated; 334.44 MiB free; 6.93 GiB reserved in total by PyTorch)
2022-03-21 20:08:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 21           |        cudaMalloc retries: 26        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6424 MB |    7335 MB |  196450 MB |  190025 MB |
|       from large pool |    6360 MB |    7270 MB |  196242 MB |  189881 MB |
|       from small pool |      64 MB |      65 MB |     207 MB |     143 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6424 MB |    7335 MB |  196450 MB |  190025 MB |
|       from large pool |    6360 MB |    7270 MB |  196242 MB |  189881 MB |
|       from small pool |      64 MB |      65 MB |     207 MB |     143 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7096 MB |    7426 MB |   13768 MB |    6672 MB |
|       from large pool |    7030 MB |    7360 MB |   13698 MB |    6668 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  687607 KB |    1773 MB |   60237 MB |   59565 MB |
|       from large pool |  685758 KB |    1772 MB |   59958 MB |   59288 MB |
|       from small pool |    1849 KB |       3 MB |     278 MB |     277 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   16394    |   15822    |
|       from large pool |     246    |     248    |    7380    |    7134    |
|       from small pool |     326    |     327    |    9014    |    8688    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   16394    |   15822    |
|       from large pool |     246    |     248    |    7380    |    7134    |
|       from small pool |     326    |     327    |    9014    |    8688    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     207    |     241    |     415    |     208    |
|       from large pool |     174    |     208    |     380    |     206    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      74    |     180    |    4562    |    4488    |
|       from large pool |      69    |     175    |    3683    |    3614    |
|       from small pool |       5    |       8    |     879    |     874    |
|===========================================================================|

2022-03-21 20:08:48 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:48 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 7.93 GiB total capacity; 7.00 GiB already allocated; 10.44 MiB free; 7.25 GiB reserved in total by PyTorch)
2022-03-21 20:08:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 22           |        cudaMalloc retries: 27        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7168 MB |    7335 MB |  206350 MB |  199181 MB |
|       from large pool |    7104 MB |    7270 MB |  206134 MB |  199030 MB |
|       from small pool |      64 MB |      65 MB |     215 MB |     150 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7168 MB |    7335 MB |  206350 MB |  199181 MB |
|       from large pool |    7104 MB |    7270 MB |  206134 MB |  199030 MB |
|       from small pool |      64 MB |      65 MB |     215 MB |     150 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7420 MB |    7426 MB |   14092 MB |    6672 MB |
|       from large pool |    7354 MB |    7360 MB |   14022 MB |    6668 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  257068 KB |    1773 MB |   63318 MB |   63067 MB |
|       from large pool |  255661 KB |    1772 MB |   63028 MB |   62778 MB |
|       from small pool |    1407 KB |       3 MB |     289 MB |     288 MB |
|---------------------------------------------------------------------------|
| Allocations           |     566    |     575    |   16836    |   16270    |
|       from large pool |     242    |     248    |    7723    |    7481    |
|       from small pool |     324    |     327    |    9113    |    8789    |
|---------------------------------------------------------------------------|
| Active allocs         |     566    |     575    |   16836    |   16270    |
|       from large pool |     242    |     248    |    7723    |    7481    |
|       from small pool |     324    |     327    |    9113    |    8789    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     217    |     241    |     425    |     208    |
|       from large pool |     184    |     208    |     390    |     206    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     114    |     180    |    4781    |    4667    |
|       from large pool |     108    |     175    |    3855    |    3747    |
|       from small pool |       6    |       8    |     926    |     920    |
|===========================================================================|

2022-03-21 20:08:48 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:49 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 7.93 GiB total capacity; 6.66 GiB already allocated; 10.44 MiB free; 7.25 GiB reserved in total by PyTorch)
2022-03-21 20:08:49 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 23           |        cudaMalloc retries: 28        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6815 MB |    7335 MB |  215822 MB |  209006 MB |
|       from large pool |    6751 MB |    7270 MB |  215600 MB |  208848 MB |
|       from small pool |      64 MB |      65 MB |     221 MB |     157 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6815 MB |    7335 MB |  215822 MB |  209006 MB |
|       from large pool |    6751 MB |    7270 MB |  215600 MB |  208848 MB |
|       from small pool |      64 MB |      65 MB |     221 MB |     157 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7420 MB |    7426 MB |   14092 MB |    6672 MB |
|       from large pool |    7354 MB |    7360 MB |   14022 MB |    6668 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  618746 KB |    1773 MB |   67107 MB |   66503 MB |
|       from large pool |  616851 KB |    1772 MB |   66807 MB |   66204 MB |
|       from small pool |    1895 KB |       3 MB |     300 MB |     298 MB |
|---------------------------------------------------------------------------|
| Allocations           |     556    |     575    |   17272    |   16716    |
|       from large pool |     233    |     248    |    8060    |    7827    |
|       from small pool |     323    |     327    |    9212    |    8889    |
|---------------------------------------------------------------------------|
| Active allocs         |     556    |     575    |   17272    |   16716    |
|       from large pool |     233    |     248    |    8060    |    7827    |
|       from small pool |     323    |     327    |    9212    |    8889    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     217    |     241    |     425    |     208    |
|       from large pool |     184    |     208    |     390    |     206    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     103    |     180    |    4984    |    4881    |
|       from large pool |      96    |     175    |    4019    |    3923    |
|       from small pool |       7    |       8    |     965    |     958    |
|===========================================================================|

2022-03-21 20:08:49 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:50 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 7.00 GiB already allocated; 40.44 MiB free; 7.22 GiB reserved in total by PyTorch)
2022-03-21 20:08:50 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 24           |        cudaMalloc retries: 29        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7136 MB |    7335 MB |  225802 MB |  218666 MB |
|       from large pool |    7070 MB |    7270 MB |  225572 MB |  218501 MB |
|       from small pool |      65 MB |      65 MB |     230 MB |     164 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7136 MB |    7335 MB |  225802 MB |  218666 MB |
|       from large pool |    7070 MB |    7270 MB |  225572 MB |  218501 MB |
|       from small pool |      65 MB |      65 MB |     230 MB |     164 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7390 MB |    7426 MB |   14092 MB |    6702 MB |
|       from large pool |    7324 MB |    7360 MB |   14022 MB |    6698 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  226711 KB |    1773 MB |   70222 MB |   70000 MB |
|       from large pool |  226539 KB |    1772 MB |   69910 MB |   69689 MB |
|       from small pool |     172 KB |       3 MB |     311 MB |     311 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   17725    |   17153    |
|       from large pool |     245    |     248    |    8411    |    8166    |
|       from small pool |     327    |     327    |    9314    |    8987    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   17725    |   17153    |
|       from large pool |     245    |     248    |    8411    |    8166    |
|       from small pool |     327    |     327    |    9314    |    8987    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     216    |     241    |     425    |     209    |
|       from large pool |     183    |     208    |     390    |     207    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      23    |     180    |    5069    |    5046    |
|       from large pool |      18    |     175    |    4068    |    4050    |
|       from small pool |       5    |       8    |    1001    |     996    |
|===========================================================================|

2022-03-21 20:08:50 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:50 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 412.00 MiB (GPU 0; 7.93 GiB total capacity; 6.38 GiB already allocated; 72.44 MiB free; 7.19 GiB reserved in total by PyTorch)
2022-03-21 20:08:50 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 25           |        cudaMalloc retries: 30        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6500 MB |    7335 MB |  234924 MB |  228423 MB |
|       from large pool |    6435 MB |    7270 MB |  234686 MB |  228250 MB |
|       from small pool |      64 MB |      65 MB |     237 MB |     172 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6500 MB |    7335 MB |  234924 MB |  228423 MB |
|       from large pool |    6435 MB |    7270 MB |  234686 MB |  228250 MB |
|       from small pool |      64 MB |      65 MB |     237 MB |     172 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7358 MB |    7426 MB |   14092 MB |    6734 MB |
|       from large pool |    7292 MB |    7360 MB |   14022 MB |    6730 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     825 MB |    1773 MB |   74069 MB |   73244 MB |
|       from large pool |     824 MB |    1772 MB |   73746 MB |   72922 MB |
|       from small pool |       1 MB |       3 MB |     323 MB |     321 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   18187    |   17614    |
|       from large pool |     246    |     248    |    8770    |    8524    |
|       from small pool |     327    |     327    |    9417    |    9090    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   18187    |   17614    |
|       from large pool |     246    |     248    |    8770    |    8524    |
|       from small pool |     327    |     327    |    9417    |    9090    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     215    |     241    |     425    |     210    |
|       from large pool |     182    |     208    |     390    |     208    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      82    |     180    |    5294    |    5212    |
|       from large pool |      75    |     175    |    4251    |    4176    |
|       from small pool |       7    |       8    |    1043    |    1036    |
|===========================================================================|

2022-03-21 20:08:50 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:51 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.63 GiB already allocated; 132.44 MiB free; 7.13 GiB reserved in total by PyTorch)
2022-03-21 20:08:51 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 26           |        cudaMalloc retries: 31        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6760 MB |    7335 MB |  244372 MB |  237612 MB |
|       from large pool |    6694 MB |    7270 MB |  244127 MB |  237432 MB |
|       from small pool |      65 MB |      65 MB |     245 MB |     179 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6760 MB |    7335 MB |  244372 MB |  237612 MB |
|       from large pool |    6694 MB |    7270 MB |  244127 MB |  237432 MB |
|       from small pool |      65 MB |      65 MB |     245 MB |     179 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7298 MB |    7426 MB |   14092 MB |    6794 MB |
|       from large pool |    7232 MB |    7360 MB |   14022 MB |    6790 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  518034 KB |    1773 MB |   77259 MB |   76753 MB |
|       from large pool |  517576 KB |    1772 MB |   76925 MB |   76419 MB |
|       from small pool |     458 KB |       3 MB |     333 MB |     333 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   18640    |   18068    |
|       from large pool |     245    |     248    |    9121    |    8876    |
|       from small pool |     327    |     327    |    9519    |    9192    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   18640    |   18068    |
|       from large pool |     245    |     248    |    9121    |    8876    |
|       from small pool |     327    |     327    |    9519    |    9192    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     212    |     241    |     425    |     213    |
|       from large pool |     179    |     208    |     390    |     211    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      78    |     180    |    5538    |    5460    |
|       from large pool |      71    |     175    |    4442    |    4371    |
|       from small pool |       7    |       8    |    1096    |    1089    |
|===========================================================================|

2022-03-21 20:08:51 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:51 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.41 GiB already allocated; 164.44 MiB free; 7.10 GiB reserved in total by PyTorch)
2022-03-21 20:08:51 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 27           |        cudaMalloc retries: 32        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6535 MB |    7335 MB |  253508 MB |  246972 MB |
|       from large pool |    6470 MB |    7270 MB |  253255 MB |  246784 MB |
|       from small pool |      65 MB |      65 MB |     253 MB |     187 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6535 MB |    7335 MB |  253508 MB |  246972 MB |
|       from large pool |    6470 MB |    7270 MB |  253255 MB |  246784 MB |
|       from small pool |      65 MB |      65 MB |     253 MB |     187 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7266 MB |    7426 MB |   14092 MB |    6826 MB |
|       from large pool |    7200 MB |    7360 MB |   14022 MB |    6822 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  715037 KB |    1773 MB |   80355 MB |   79657 MB |
|       from large pool |  714331 KB |    1772 MB |   80009 MB |   79311 MB |
|       from small pool |     706 KB |       3 MB |     345 MB |     345 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   19093    |   18521    |
|       from large pool |     245    |     248    |    9472    |    9227    |
|       from small pool |     327    |     327    |    9621    |    9294    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   19093    |   18521    |
|       from large pool |     245    |     248    |    9472    |    9227    |
|       from small pool |     327    |     327    |    9621    |    9294    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     241    |     425    |     214    |
|       from large pool |     178    |     208    |     390    |     212    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      75    |     180    |    5745    |    5670    |
|       from large pool |      70    |     175    |    4611    |    4541    |
|       from small pool |       5    |       8    |    1134    |    1129    |
|===========================================================================|

2022-03-21 20:08:51 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:52 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.58 GiB already allocated; 20.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:08:52 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 28           |        cudaMalloc retries: 33        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6733 MB |    7335 MB |  262825 MB |  256091 MB |
|       from large pool |    6669 MB |    7270 MB |  262565 MB |  255895 MB |
|       from small pool |      64 MB |      65 MB |     260 MB |     195 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6733 MB |    7335 MB |  262825 MB |  256091 MB |
|       from large pool |    6669 MB |    7270 MB |  262565 MB |  255895 MB |
|       from small pool |      64 MB |      65 MB |     260 MB |     195 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7410 MB |    7426 MB |   14268 MB |    6858 MB |
|       from large pool |    7344 MB |    7360 MB |   14198 MB |    6854 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  692775 KB |    1773 MB |   84355 MB |   83678 MB |
|       from large pool |  691028 KB |    1772 MB |   83998 MB |   83323 MB |
|       from small pool |    1747 KB |       3 MB |     357 MB |     355 MB |
|---------------------------------------------------------------------------|
| Allocations           |     569    |     575    |   19546    |   18977    |
|       from large pool |     244    |     248    |    9824    |    9580    |
|       from small pool |     325    |     327    |    9722    |    9397    |
|---------------------------------------------------------------------------|
| Active allocs         |     569    |     575    |   19546    |   18977    |
|       from large pool |     244    |     248    |    9824    |    9580    |
|       from small pool |     325    |     327    |    9722    |    9397    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     214    |     241    |     429    |     215    |
|       from large pool |     181    |     208    |     394    |     213    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     110    |     180    |    5985    |    5875    |
|       from large pool |     104    |     175    |    4813    |    4709    |
|       from small pool |       6    |       8    |    1172    |    1166    |
|===========================================================================|

2022-03-21 20:08:52 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:53 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 396.00 MiB (GPU 0; 7.93 GiB total capacity; 6.94 GiB already allocated; 20.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:08:53 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 29           |        cudaMalloc retries: 34        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7075 MB |    7335 MB |  272683 MB |  265608 MB |
|       from large pool |    7010 MB |    7270 MB |  272416 MB |  265405 MB |
|       from small pool |      64 MB |      65 MB |     267 MB |     202 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7075 MB |    7335 MB |  272683 MB |  265608 MB |
|       from large pool |    7010 MB |    7270 MB |  272416 MB |  265405 MB |
|       from small pool |      64 MB |      65 MB |     267 MB |     202 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7410 MB |    7426 MB |   14268 MB |    6858 MB |
|       from large pool |    7344 MB |    7360 MB |   14198 MB |    6854 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  310078 KB |    1773 MB |   87778 MB |   87475 MB |
|       from large pool |  308753 KB |    1772 MB |   87410 MB |   87108 MB |
|       from small pool |    1324 KB |       3 MB |     368 MB |     366 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   19999    |   19427    |
|       from large pool |     246    |     248    |   10176    |    9930    |
|       from small pool |     326    |     327    |    9823    |    9497    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   19999    |   19427    |
|       from large pool |     246    |     248    |   10176    |    9930    |
|       from small pool |     326    |     327    |    9823    |    9497    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     214    |     241    |     429    |     215    |
|       from large pool |     181    |     208    |     394    |     213    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      97    |     180    |    6201    |    6104    |
|       from large pool |      91    |     175    |    4989    |    4898    |
|       from small pool |       6    |       8    |    1212    |    1206    |
|===========================================================================|

2022-03-21 20:08:53 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:53 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 7.93 GiB total capacity; 6.57 GiB already allocated; 52.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:08:53 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 30           |        cudaMalloc retries: 35        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6725 MB |    7335 MB |  282029 MB |  275304 MB |
|       from large pool |    6661 MB |    7270 MB |  281755 MB |  275094 MB |
|       from small pool |      64 MB |      65 MB |     274 MB |     210 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6725 MB |    7335 MB |  282029 MB |  275304 MB |
|       from large pool |    6661 MB |    7270 MB |  281755 MB |  275094 MB |
|       from small pool |      64 MB |      65 MB |     274 MB |     210 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7378 MB |    7426 MB |   14268 MB |    6890 MB |
|       from large pool |    7312 MB |    7360 MB |   14198 MB |    6886 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  667941 KB |    1773 MB |   91820 MB |   91168 MB |
|       from large pool |  666237 KB |    1772 MB |   91441 MB |   90791 MB |
|       from small pool |    1703 KB |       3 MB |     379 MB |     377 MB |
|---------------------------------------------------------------------------|
| Allocations           |     567    |     575    |   20450    |   19883    |
|       from large pool |     242    |     248    |   10526    |   10284    |
|       from small pool |     325    |     327    |    9924    |    9599    |
|---------------------------------------------------------------------------|
| Active allocs         |     567    |     575    |   20450    |   19883    |
|       from large pool |     242    |     248    |   10526    |   10284    |
|       from small pool |     325    |     327    |    9924    |    9599    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     213    |     241    |     429    |     216    |
|       from large pool |     180    |     208    |     394    |     214    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     118    |     180    |    6431    |    6313    |
|       from large pool |     112    |     175    |    5180    |    5068    |
|       from small pool |       6    |       8    |    1251    |    1245    |
|===========================================================================|

2022-03-21 20:08:53 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:55 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 6.13 GiB already allocated; 612.44 MiB free; 6.66 GiB reserved in total by PyTorch)
2022-03-21 20:08:55 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 31           |        cudaMalloc retries: 36        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6273 MB |    7335 MB |  290662 MB |  284389 MB |
|       from large pool |    6208 MB |    7270 MB |  290381 MB |  284172 MB |
|       from small pool |      64 MB |      65 MB |     281 MB |     216 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6273 MB |    7335 MB |  290662 MB |  284389 MB |
|       from large pool |    6208 MB |    7270 MB |  290381 MB |  284172 MB |
|       from small pool |      64 MB |      65 MB |     281 MB |     216 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6818 MB |    7426 MB |   14268 MB |    7450 MB |
|       from large pool |    6752 MB |    7360 MB |   14198 MB |    7446 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  557529 KB |    1773 MB |   95086 MB |   94542 MB |
|       from large pool |  556445 KB |    1772 MB |   94695 MB |   94152 MB |
|       from small pool |    1084 KB |       3 MB |     391 MB |     389 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   20913    |   20341    |
|       from large pool |     245    |     248    |   10885    |   10640    |
|       from small pool |     327    |     328    |   10028    |    9701    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   20913    |   20341    |
|       from large pool |     245    |     248    |   10885    |   10640    |
|       from small pool |     327    |     328    |   10028    |    9701    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     206    |     241    |     429    |     223    |
|       from large pool |     173    |     208    |     394    |     221    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      64    |     180    |    6590    |    6526    |
|       from large pool |      59    |     175    |    5299    |    5240    |
|       from small pool |       5    |       8    |    1291    |    1286    |
|===========================================================================|

2022-03-21 20:08:55 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:55 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 826.00 MiB (GPU 0; 7.93 GiB total capacity; 6.31 GiB already allocated; 612.44 MiB free; 6.66 GiB reserved in total by PyTorch)
2022-03-21 20:08:55 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 32           |        cudaMalloc retries: 37        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6465 MB |    7335 MB |  299574 MB |  293109 MB |
|       from large pool |    6400 MB |    7270 MB |  299286 MB |  292885 MB |
|       from small pool |      64 MB |      65 MB |     287 MB |     223 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6465 MB |    7335 MB |  299574 MB |  293109 MB |
|       from large pool |    6400 MB |    7270 MB |  299286 MB |  292885 MB |
|       from small pool |      64 MB |      65 MB |     287 MB |     223 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6818 MB |    7426 MB |   14268 MB |    7450 MB |
|       from large pool |    6752 MB |    7360 MB |   14198 MB |    7446 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  361400 KB |    1773 MB |   97846 MB |   97493 MB |
|       from large pool |  359549 KB |    1772 MB |   97440 MB |   97089 MB |
|       from small pool |    1850 KB |       3 MB |     405 MB |     403 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   21376    |   20804    |
|       from large pool |     246    |     248    |   11245    |   10999    |
|       from small pool |     326    |     328    |   10131    |    9805    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   21376    |   20804    |
|       from large pool |     246    |     248    |   11245    |   10999    |
|       from small pool |     326    |     328    |   10131    |    9805    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     206    |     241    |     429    |     223    |
|       from large pool |     173    |     208    |     394    |     221    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      63    |     180    |    6758    |    6695    |
|       from large pool |      58    |     175    |    5425    |    5367    |
|       from small pool |       5    |       8    |    1333    |    1328    |
|===========================================================================|

2022-03-21 20:08:55 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:55 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 412.00 MiB (GPU 0; 7.93 GiB total capacity; 6.75 GiB already allocated; 152.44 MiB free; 7.11 GiB reserved in total by PyTorch)
2022-03-21 20:08:55 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 33           |        cudaMalloc retries: 38        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6875 MB |    7335 MB |  309163 MB |  302287 MB |
|       from large pool |    6811 MB |    7270 MB |  308868 MB |  302057 MB |
|       from small pool |      64 MB |      65 MB |     295 MB |     230 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6875 MB |    7335 MB |  309163 MB |  302287 MB |
|       from large pool |    6811 MB |    7270 MB |  308868 MB |  302057 MB |
|       from small pool |      64 MB |      65 MB |     295 MB |     230 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7278 MB |    7426 MB |   14728 MB |    7450 MB |
|       from large pool |    7212 MB |    7360 MB |   14658 MB |    7446 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  379166 KB |    1773 MB |  100682 MB |  100312 MB |
|       from large pool |  377689 KB |    1772 MB |  100266 MB |   99897 MB |
|       from small pool |    1477 KB |       3 MB |     415 MB |     414 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   21829    |   21257    |
|       from large pool |     246    |     248    |   11597    |   11351    |
|       from small pool |     326    |     328    |   10232    |    9906    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   21829    |   21257    |
|       from large pool |     246    |     248    |   11597    |   11351    |
|       from small pool |     326    |     328    |   10232    |    9906    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     221    |     241    |     444    |     223    |
|       from large pool |     188    |     208    |     409    |     221    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     101    |     180    |    6987    |    6886    |
|       from large pool |      95    |     175    |    5602    |    5507    |
|       from small pool |       6    |       8    |    1385    |    1379    |
|===========================================================================|

2022-03-21 20:08:55 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:56 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 7.13 GiB already allocated; 24.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:08:56 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 34           |        cudaMalloc retries: 39        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7302 MB |    7335 MB |  319222 MB |  311919 MB |
|       from large pool |    7238 MB |    7270 MB |  318920 MB |  311681 MB |
|       from small pool |      64 MB |      65 MB |     302 MB |     237 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7302 MB |    7335 MB |  319222 MB |  311919 MB |
|       from large pool |    7238 MB |    7270 MB |  318920 MB |  311681 MB |
|       from small pool |      64 MB |      65 MB |     302 MB |     237 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7406 MB |    7426 MB |   14888 MB |    7482 MB |
|       from large pool |    7340 MB |    7360 MB |   14818 MB |    7478 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  105645 KB |    1773 MB |  103189 MB |  103086 MB |
|       from large pool |  104303 KB |    1772 MB |  102762 MB |  102660 MB |
|       from small pool |    1342 KB |       3 MB |     427 MB |     425 MB |
|---------------------------------------------------------------------------|
| Allocations           |     568    |     575    |   22273    |   21705    |
|       from large pool |     244    |     248    |   11942    |   11698    |
|       from small pool |     324    |     328    |   10331    |   10007    |
|---------------------------------------------------------------------------|
| Active allocs         |     568    |     575    |   22273    |   21705    |
|       from large pool |     244    |     248    |   11942    |   11698    |
|       from small pool |     324    |     328    |   10331    |   10007    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     223    |     241    |     447    |     224    |
|       from large pool |     190    |     208    |     412    |     222    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      25    |     180    |    7086    |    7061    |
|       from large pool |      20    |     175    |    5661    |    5641    |
|       from small pool |       5    |       8    |    1425    |    1420    |
|===========================================================================|

2022-03-21 20:08:56 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:57 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 7.03 GiB already allocated; 24.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:08:57 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 35           |        cudaMalloc retries: 40        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7198 MB |    7335 MB |  329139 MB |  321940 MB |
|       from large pool |    7133 MB |    7270 MB |  328829 MB |  321695 MB |
|       from small pool |      64 MB |      65 MB |     309 MB |     245 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7198 MB |    7335 MB |  329139 MB |  321940 MB |
|       from large pool |    7133 MB |    7270 MB |  328829 MB |  321695 MB |
|       from small pool |      64 MB |      65 MB |     309 MB |     245 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7406 MB |    7426 MB |   14888 MB |    7482 MB |
|       from large pool |    7340 MB |    7360 MB |   14818 MB |    7478 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  212796 KB |    1773 MB |  105916 MB |  105708 MB |
|       from large pool |  211286 KB |    1772 MB |  105478 MB |  105271 MB |
|       from small pool |    1509 KB |       3 MB |     438 MB |     436 MB |
|---------------------------------------------------------------------------|
| Allocations           |     561    |     575    |   22708    |   22147    |
|       from large pool |     239    |     248    |   12280    |   12041    |
|       from small pool |     322    |     328    |   10428    |   10106    |
|---------------------------------------------------------------------------|
| Active allocs         |     561    |     575    |   22708    |   22147    |
|       from large pool |     239    |     248    |   12280    |   12041    |
|       from small pool |     322    |     328    |   10428    |   10106    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     223    |     241    |     447    |     224    |
|       from large pool |     190    |     208    |     412    |     222    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      43    |     180    |    7202    |    7159    |
|       from large pool |      37    |     175    |    5736    |    5699    |
|       from small pool |       6    |       8    |    1466    |    1460    |
|===========================================================================|

2022-03-21 20:08:57 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:58 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 6.33 GiB already allocated; 300.44 MiB free; 6.96 GiB reserved in total by PyTorch)
2022-03-21 20:08:58 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 36           |        cudaMalloc retries: 41        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6482 MB |    7335 MB |  338073 MB |  331590 MB |
|       from large pool |    6417 MB |    7270 MB |  337755 MB |  331338 MB |
|       from small pool |      65 MB |      65 MB |     317 MB |     252 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6482 MB |    7335 MB |  338073 MB |  331590 MB |
|       from large pool |    6417 MB |    7270 MB |  337755 MB |  331338 MB |
|       from small pool |      65 MB |      65 MB |     317 MB |     252 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7130 MB |    7426 MB |   14888 MB |    7758 MB |
|       from large pool |    7064 MB |    7360 MB |   14818 MB |    7754 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  663185 KB |    1773 MB |  108745 MB |  108097 MB |
|       from large pool |  662346 KB |    1772 MB |  108290 MB |  107643 MB |
|       from small pool |     839 KB |       3 MB |     454 MB |     453 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   23171    |   22599    |
|       from large pool |     245    |     248    |   12639    |   12394    |
|       from small pool |     327    |     328    |   10532    |   10205    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   23171    |   22599    |
|       from large pool |     245    |     248    |   12639    |   12394    |
|       from small pool |     327    |     328    |   10532    |   10205    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     213    |     241    |     447    |     234    |
|       from large pool |     180    |     208    |     412    |     232    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      60    |     180    |    7365    |    7305    |
|       from large pool |      57    |     175    |    5856    |    5799    |
|       from small pool |       3    |       8    |    1509    |    1506    |
|===========================================================================|

2022-03-21 20:08:58 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:59 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 412.00 MiB (GPU 0; 7.93 GiB total capacity; 6.85 GiB already allocated; 44.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:08:59 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 37           |        cudaMalloc retries: 42        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6977 MB |    7335 MB |  347798 MB |  340820 MB |
|       from large pool |    6913 MB |    7270 MB |  347473 MB |  340560 MB |
|       from small pool |      64 MB |      65 MB |     324 MB |     259 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6977 MB |    7335 MB |  347798 MB |  340820 MB |
|       from large pool |    6913 MB |    7270 MB |  347473 MB |  340560 MB |
|       from small pool |      64 MB |      65 MB |     324 MB |     259 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7386 MB |    7426 MB |   15164 MB |    7778 MB |
|       from large pool |    7320 MB |    7360 MB |   15094 MB |    7774 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  385103 KB |    1773 MB |  111510 MB |  111134 MB |
|       from large pool |  383632 KB |    1772 MB |  111044 MB |  110670 MB |
|       from small pool |    1470 KB |       3 MB |     465 MB |     464 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   23624    |   23052    |
|       from large pool |     246    |     248    |   12991    |   12745    |
|       from small pool |     326    |     328    |   10633    |   10307    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   23624    |   23052    |
|       from large pool |     246    |     248    |   12991    |   12745    |
|       from small pool |     326    |     328    |   10633    |   10307    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     220    |     241    |     455    |     235    |
|       from large pool |     187    |     208    |     420    |     233    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     100    |     180    |    7591    |    7491    |
|       from large pool |      94    |     175    |    6040    |    5946    |
|       from small pool |       6    |       8    |    1551    |    1545    |
|===========================================================================|

2022-03-21 20:08:59 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:08:59 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.94 GiB already allocated; 136.44 MiB free; 7.12 GiB reserved in total by PyTorch)
2022-03-21 20:08:59 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 38           |        cudaMalloc retries: 43        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7075 MB |    7335 MB |  357700 MB |  350625 MB |
|       from large pool |    7009 MB |    7270 MB |  357368 MB |  350358 MB |
|       from small pool |      65 MB |      65 MB |     332 MB |     267 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7075 MB |    7335 MB |  357700 MB |  350625 MB |
|       from large pool |    7009 MB |    7270 MB |  357368 MB |  350358 MB |
|       from small pool |      65 MB |      65 MB |     332 MB |     267 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7294 MB |    7426 MB |   15164 MB |    7870 MB |
|       from large pool |    7228 MB |    7360 MB |   15094 MB |    7866 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  191216 KB |    1773 MB |  114212 MB |  114026 MB |
|       from large pool |  190742 KB |    1772 MB |  113735 MB |  113549 MB |
|       from small pool |     473 KB |       3 MB |     477 MB |     476 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   24077    |   23505    |
|       from large pool |     245    |     248    |   13342    |   13097    |
|       from small pool |     327    |     328    |   10735    |   10408    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   24077    |   23505    |
|       from large pool |     245    |     248    |   13342    |   13097    |
|       from small pool |     327    |     328    |   10735    |   10408    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     217    |     241    |     455    |     238    |
|       from large pool |     184    |     208    |     420    |     236    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      27    |     180    |    7706    |    7679    |
|       from large pool |      22    |     175    |    6113    |    6091    |
|       from small pool |       5    |       8    |    1593    |    1588    |
|===========================================================================|

2022-03-21 20:08:59 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:00 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.74 GiB already allocated; 24.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:09:00 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 39           |        cudaMalloc retries: 44        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6874 MB |    7335 MB |  367279 MB |  360405 MB |
|       from large pool |    6809 MB |    7270 MB |  366939 MB |  360129 MB |
|       from small pool |      64 MB |      65 MB |     339 MB |     275 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6874 MB |    7335 MB |  367279 MB |  360405 MB |
|       from large pool |    6809 MB |    7270 MB |  366939 MB |  360129 MB |
|       from small pool |      64 MB |      65 MB |     339 MB |     275 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7406 MB |    7426 MB |   15328 MB |    7922 MB |
|       from large pool |    7340 MB |    7360 MB |   15258 MB |    7918 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  511749 KB |    1773 MB |  117514 MB |  117014 MB |
|       from large pool |  510214 KB |    1772 MB |  117025 MB |  116527 MB |
|       from small pool |    1535 KB |       3 MB |     488 MB |     487 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   24530    |   23958    |
|       from large pool |     246    |     248    |   13694    |   13448    |
|       from small pool |     326    |     328    |   10836    |   10510    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   24530    |   23958    |
|       from large pool |     246    |     248    |   13694    |   13448    |
|       from small pool |     326    |     328    |   10836    |   10510    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     220    |     241    |     460    |     240    |
|       from large pool |     187    |     208    |     425    |     238    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     112    |     180    |    7941    |    7829    |
|       from large pool |     106    |     175    |    6306    |    6200    |
|       from small pool |       6    |       8    |    1635    |    1629    |
|===========================================================================|

2022-03-21 20:09:00 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:00 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 7.93 GiB total capacity; 6.63 GiB already allocated; 24.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:09:00 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 40           |        cudaMalloc retries: 45        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6788 MB |    7335 MB |  376703 MB |  369914 MB |
|       from large pool |    6724 MB |    7270 MB |  376356 MB |  369632 MB |
|       from small pool |      64 MB |      65 MB |     346 MB |     282 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6788 MB |    7335 MB |  376703 MB |  369914 MB |
|       from large pool |    6724 MB |    7270 MB |  376356 MB |  369632 MB |
|       from small pool |      64 MB |      65 MB |     346 MB |     282 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7406 MB |    7426 MB |   15360 MB |    7954 MB |
|       from large pool |    7340 MB |    7360 MB |   15290 MB |    7950 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  632552 KB |    1773 MB |  121011 MB |  120393 MB |
|       from large pool |  630725 KB |    1772 MB |  120511 MB |  119895 MB |
|       from small pool |    1826 KB |       3 MB |     499 MB |     497 MB |
|---------------------------------------------------------------------------|
| Allocations           |     556    |     575    |   24966    |   24410    |
|       from large pool |     233    |     248    |   14031    |   13798    |
|       from small pool |     323    |     328    |   10935    |   10612    |
|---------------------------------------------------------------------------|
| Active allocs         |     556    |     575    |   24966    |   24410    |
|       from large pool |     233    |     248    |   14031    |   13798    |
|       from small pool |     323    |     328    |   10935    |   10612    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     220    |     241    |     461    |     241    |
|       from large pool |     187    |     208    |     426    |     239    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     102    |     180    |    8172    |    8070    |
|       from large pool |      95    |     175    |    6491    |    6396    |
|       from small pool |       7    |       8    |    1681    |    1674    |
|===========================================================================|

2022-03-21 20:09:00 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:01 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 410.00 MiB (GPU 0; 7.93 GiB total capacity; 6.55 GiB already allocated; 24.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:09:01 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 41           |        cudaMalloc retries: 46        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6675 MB |    7335 MB |  386067 MB |  379391 MB |
|       from large pool |    6611 MB |    7270 MB |  385713 MB |  379102 MB |
|       from small pool |      64 MB |      65 MB |     353 MB |     289 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6675 MB |    7335 MB |  386067 MB |  379391 MB |
|       from large pool |    6611 MB |    7270 MB |  385713 MB |  379102 MB |
|       from small pool |      64 MB |      65 MB |     353 MB |     289 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7406 MB |    7426 MB |   15360 MB |    7954 MB |
|       from large pool |    7340 MB |    7360 MB |   15290 MB |    7950 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  714920 KB |    1773 MB |  124946 MB |  124248 MB |
|       from large pool |  713172 KB |    1772 MB |  124436 MB |  123739 MB |
|       from small pool |    1747 KB |       3 MB |     510 MB |     508 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   25428    |   24855    |
|       from large pool |     246    |     248    |   14390    |   14144    |
|       from small pool |     327    |     328    |   11038    |   10711    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   25428    |   24855    |
|       from large pool |     246    |     248    |   14390    |   14144    |
|       from small pool |     327    |     328    |   11038    |   10711    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     220    |     241    |     461    |     241    |
|       from large pool |     187    |     208    |     426    |     239    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      92    |     180    |    8407    |    8315    |
|       from large pool |      86    |     175    |    6688    |    6602    |
|       from small pool |       6    |       8    |    1719    |    1713    |
|===========================================================================|

2022-03-21 20:09:01 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:02 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 826.00 MiB (GPU 0; 7.93 GiB total capacity; 6.08 GiB already allocated; 656.44 MiB free; 6.62 GiB reserved in total by PyTorch)
2022-03-21 20:09:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 42           |        cudaMalloc retries: 47        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6221 MB |    7335 MB |  394630 MB |  388408 MB |
|       from large pool |    6156 MB |    7270 MB |  394270 MB |  388113 MB |
|       from small pool |      64 MB |      65 MB |     360 MB |     295 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6221 MB |    7335 MB |  394630 MB |  388408 MB |
|       from large pool |    6156 MB |    7270 MB |  394270 MB |  388113 MB |
|       from small pool |      64 MB |      65 MB |     360 MB |     295 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6774 MB |    7426 MB |   15360 MB |    8586 MB |
|       from large pool |    6708 MB |    7360 MB |   15290 MB |    8582 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  565685 KB |    1773 MB |  127791 MB |  127239 MB |
|       from large pool |  564397 KB |    1772 MB |  127269 MB |  126718 MB |
|       from small pool |    1288 KB |       3 MB |     521 MB |     520 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   25891    |   25319    |
|       from large pool |     245    |     248    |   14749    |   14504    |
|       from small pool |     327    |     328    |   11142    |   10815    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   25891    |   25319    |
|       from large pool |     245    |     248    |   14749    |   14504    |
|       from small pool |     327    |     328    |   11142    |   10815    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     241    |     461    |     250    |
|       from large pool |     178    |     208    |     426    |     248    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      61    |     180    |    8601    |    8540    |
|       from large pool |      55    |     175    |    6828    |    6773    |
|       from small pool |       6    |       8    |    1773    |    1767    |
|===========================================================================|

2022-03-21 20:09:02 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:03 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 5.90 GiB already allocated; 672.44 MiB free; 6.60 GiB reserved in total by PyTorch)
2022-03-21 20:09:03 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 43           |        cudaMalloc retries: 48        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6040 MB |    7335 MB |  402928 MB |  396888 MB |
|       from large pool |    5976 MB |    7270 MB |  402561 MB |  396585 MB |
|       from small pool |      64 MB |      65 MB |     366 MB |     302 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6040 MB |    7335 MB |  402928 MB |  396888 MB |
|       from large pool |    5976 MB |    7270 MB |  402561 MB |  396585 MB |
|       from small pool |      64 MB |      65 MB |     366 MB |     302 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6758 MB |    7426 MB |   15360 MB |    8602 MB |
|       from large pool |    6692 MB |    7360 MB |   15290 MB |    8598 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  734670 KB |    1773 MB |  130050 MB |  129333 MB |
|       from large pool |  733173 KB |    1772 MB |  129516 MB |  128800 MB |
|       from small pool |    1496 KB |       3 MB |     534 MB |     532 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   26354    |   25782    |
|       from large pool |     245    |     248    |   15108    |   14863    |
|       from small pool |     327    |     328    |   11246    |   10919    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   26354    |   25782    |
|       from large pool |     245    |     248    |   15108    |   14863    |
|       from small pool |     327    |     328    |   11246    |   10919    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     210    |     241    |     461    |     251    |
|       from large pool |     177    |     208    |     426    |     249    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      60    |     180    |    8770    |    8710    |
|       from large pool |      55    |     175    |    6953    |    6898    |
|       from small pool |       5    |       8    |    1817    |    1812    |
|===========================================================================|

2022-03-21 20:09:03 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:03 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 790.00 MiB (GPU 0; 7.93 GiB total capacity; 6.44 GiB already allocated; 360.44 MiB free; 6.90 GiB reserved in total by PyTorch)
2022-03-21 20:09:03 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 44           |        cudaMalloc retries: 49        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6596 MB |    7335 MB |  411993 MB |  405396 MB |
|       from large pool |    6532 MB |    7270 MB |  411618 MB |  405086 MB |
|       from small pool |      64 MB |      65 MB |     374 MB |     309 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6596 MB |    7335 MB |  411993 MB |  405396 MB |
|       from large pool |    6532 MB |    7270 MB |  411618 MB |  405086 MB |
|       from small pool |      64 MB |      65 MB |     374 MB |     309 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7070 MB |    7426 MB |   15756 MB |    8686 MB |
|       from large pool |    7004 MB |    7360 MB |   15686 MB |    8682 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  484426 KB |    1773 MB |  132229 MB |  131756 MB |
|       from large pool |  483249 KB |    1772 MB |  131684 MB |  131212 MB |
|       from small pool |    1177 KB |       3 MB |     544 MB |     543 MB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     575    |   26808    |   26237    |
|       from large pool |     245    |     248    |   15460    |   15215    |
|       from small pool |     326    |     328    |   11348    |   11022    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     575    |   26808    |   26237    |
|       from large pool |     245    |     248    |   15460    |   15215    |
|       from small pool |     326    |     328    |   11348    |   11022    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     208    |     241    |     462    |     254    |
|       from large pool |     175    |     208    |     427    |     252    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     133    |     180    |    9086    |    8953    |
|       from large pool |     128    |     175    |    7230    |    7102    |
|       from small pool |       5    |       8    |    1856    |    1851    |
|===========================================================================|

2022-03-21 20:09:03 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:04 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 412.00 MiB (GPU 0; 7.93 GiB total capacity; 6.18 GiB already allocated; 360.44 MiB free; 6.90 GiB reserved in total by PyTorch)
2022-03-21 20:09:04 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 45           |        cudaMalloc retries: 50        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6298 MB |    7335 MB |  420829 MB |  414531 MB |
|       from large pool |    6234 MB |    7270 MB |  420448 MB |  414214 MB |
|       from small pool |      64 MB |      65 MB |     380 MB |     316 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6298 MB |    7335 MB |  420829 MB |  414531 MB |
|       from large pool |    6234 MB |    7270 MB |  420448 MB |  414214 MB |
|       from small pool |      64 MB |      65 MB |     380 MB |     316 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7070 MB |    7426 MB |   15756 MB |    8686 MB |
|       from large pool |    7004 MB |    7360 MB |   15686 MB |    8682 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  757251 KB |    1773 MB |  135573 MB |  134834 MB |
|       from large pool |  755489 KB |    1772 MB |  135018 MB |  134280 MB |
|       from small pool |    1762 KB |       3 MB |     555 MB |     554 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   27270    |   26697    |
|       from large pool |     246    |     248    |   15819    |   15573    |
|       from small pool |     327    |     328    |   11451    |   11124    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   27270    |   26697    |
|       from large pool |     246    |     248    |   15819    |   15573    |
|       from small pool |     327    |     328    |   11451    |   11124    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     208    |     241    |     462    |     254    |
|       from large pool |     175    |     208    |     427    |     252    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      76    |     180    |    9322    |    9246    |
|       from large pool |      70    |     175    |    7419    |    7349    |
|       from small pool |       6    |       8    |    1903    |    1897    |
|===========================================================================|

2022-03-21 20:09:04 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:04 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 412.00 MiB (GPU 0; 7.93 GiB total capacity; 6.40 GiB already allocated; 232.44 MiB free; 7.03 GiB reserved in total by PyTorch)
2022-03-21 20:09:04 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 46           |        cudaMalloc retries: 51        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6520 MB |    7335 MB |  429976 MB |  423456 MB |
|       from large pool |    6456 MB |    7270 MB |  429589 MB |  423132 MB |
|       from small pool |      64 MB |      65 MB |     387 MB |     323 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6520 MB |    7335 MB |  429976 MB |  423456 MB |
|       from large pool |    6456 MB |    7270 MB |  429589 MB |  423132 MB |
|       from small pool |      64 MB |      65 MB |     387 MB |     323 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7198 MB |    7426 MB |   15916 MB |    8718 MB |
|       from large pool |    7132 MB |    7360 MB |   15846 MB |    8714 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  661020 KB |    1773 MB |  139529 MB |  138883 MB |
|       from large pool |  659310 KB |    1772 MB |  138963 MB |  138319 MB |
|       from small pool |    1709 KB |       3 MB |     566 MB |     564 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   27732    |   27159    |
|       from large pool |     246    |     248    |   16178    |   15932    |
|       from small pool |     327    |     328    |   11554    |   11227    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   27732    |   27159    |
|       from large pool |     246    |     248    |   16178    |   15932    |
|       from small pool |     327    |     328    |   11554    |   11227    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     210    |     241    |     465    |     255    |
|       from large pool |     177    |     208    |     430    |     253    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     102    |     180    |    9561    |    9459    |
|       from large pool |      96    |     175    |    7618    |    7522    |
|       from small pool |       6    |       8    |    1943    |    1937    |
|===========================================================================|

2022-03-21 20:09:04 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:05 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 7.93 GiB total capacity; 6.01 GiB already allocated; 264.44 MiB free; 7.00 GiB reserved in total by PyTorch)
2022-03-21 20:09:05 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 47           |        cudaMalloc retries: 52        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6151 MB |    7335 MB |  438388 MB |  432236 MB |
|       from large pool |    6087 MB |    7270 MB |  437993 MB |  431906 MB |
|       from small pool |      64 MB |      65 MB |     394 MB |     329 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6151 MB |    7335 MB |  438388 MB |  432236 MB |
|       from large pool |    6087 MB |    7270 MB |  437993 MB |  431906 MB |
|       from small pool |      64 MB |      65 MB |     394 MB |     329 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7166 MB |    7426 MB |   15916 MB |    8750 MB |
|       from large pool |    7100 MB |    7360 MB |   15846 MB |    8746 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1014 MB |    1773 MB |  143206 MB |  142192 MB |
|       from large pool |    1012 MB |    1772 MB |  142628 MB |  141615 MB |
|       from small pool |       1 MB |       3 MB |     578 MB |     576 MB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     575    |   28186    |   27615    |
|       from large pool |     245    |     248    |   16530    |   16285    |
|       from small pool |     326    |     328    |   11656    |   11330    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     575    |   28186    |   27615    |
|       from large pool |     245    |     248    |   16530    |   16285    |
|       from small pool |     326    |     328    |   11656    |   11330    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     209    |     241    |     465    |     256    |
|       from large pool |     176    |     208    |     430    |     254    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     141    |     180    |    9878    |    9737    |
|       from large pool |     135    |     175    |    7893    |    7758    |
|       from small pool |       6    |       8    |    1985    |    1979    |
|===========================================================================|

2022-03-21 20:09:05 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:06 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.73 GiB already allocated; 24.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:09:06 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 48           |        cudaMalloc retries: 53        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6892 MB |    7335 MB |  447938 MB |  441046 MB |
|       from large pool |    6828 MB |    7270 MB |  447537 MB |  440709 MB |
|       from small pool |      64 MB |      65 MB |     401 MB |     336 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6892 MB |    7335 MB |  447938 MB |  441046 MB |
|       from large pool |    6828 MB |    7270 MB |  447537 MB |  440709 MB |
|       from small pool |      64 MB |      65 MB |     401 MB |     336 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7406 MB |    7426 MB |   16156 MB |    8750 MB |
|       from large pool |    7340 MB |    7360 MB |   16086 MB |    8746 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  525801 KB |    1773 MB |  146591 MB |  146077 MB |
|       from large pool |  524075 KB |    1772 MB |  146002 MB |  145490 MB |
|       from small pool |    1726 KB |       3 MB |     589 MB |     587 MB |
|---------------------------------------------------------------------------|
| Allocations           |     568    |     575    |   28638    |   28070    |
|       from large pool |     243    |     248    |   16881    |   16638    |
|       from small pool |     325    |     328    |   11757    |   11432    |
|---------------------------------------------------------------------------|
| Active allocs         |     568    |     575    |   28638    |   28070    |
|       from large pool |     243    |     248    |   16881    |   16638    |
|       from small pool |     325    |     328    |   11757    |   11432    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     215    |     241    |     471    |     256    |
|       from large pool |     182    |     208    |     436    |     254    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     102    |     180    |   10116    |   10014    |
|       from large pool |      95    |     175    |    8091    |    7996    |
|       from small pool |       7    |       8    |    2025    |    2018    |
|===========================================================================|

2022-03-21 20:09:06 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:07 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 806.00 MiB (GPU 0; 7.93 GiB total capacity; 6.48 GiB already allocated; 50.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:09:07 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 49           |        cudaMalloc retries: 54        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6640 MB |    7335 MB |  457074 MB |  450434 MB |
|       from large pool |    6576 MB |    7270 MB |  456667 MB |  450090 MB |
|       from small pool |      64 MB |      65 MB |     407 MB |     343 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6640 MB |    7335 MB |  457074 MB |  450434 MB |
|       from large pool |    6576 MB |    7270 MB |  456667 MB |  450090 MB |
|       from small pool |      64 MB |      65 MB |     407 MB |     343 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7380 MB |    7426 MB |   16156 MB |    8776 MB |
|       from large pool |    7314 MB |    7360 MB |   16086 MB |    8772 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  757421 KB |    1773 MB |  150452 MB |  149712 MB |
|       from large pool |  755592 KB |    1772 MB |  149852 MB |  149114 MB |
|       from small pool |    1829 KB |       3 MB |     599 MB |     597 MB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     575    |   29092    |   28521    |
|       from large pool |     246    |     248    |   17234    |   16988    |
|       from small pool |     325    |     328    |   11858    |   11533    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     575    |   29092    |   28521    |
|       from large pool |     246    |     248    |   17234    |   16988    |
|       from small pool |     325    |     328    |   11858    |   11533    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     214    |     241    |     471    |     257    |
|       from large pool |     181    |     208    |     436    |     255    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     102    |     180    |   10347    |   10245    |
|       from large pool |      97    |     175    |    8283    |    8186    |
|       from small pool |       5    |       8    |    2064    |    2059    |
|===========================================================================|

2022-03-21 20:09:07 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:07 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 390.00 MiB (GPU 0; 7.93 GiB total capacity; 6.79 GiB already allocated; 50.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:09:07 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 50           |        cudaMalloc retries: 55        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6921 MB |    7335 MB |  466722 MB |  459800 MB |
|       from large pool |    6855 MB |    7270 MB |  466306 MB |  459450 MB |
|       from small pool |      65 MB |      65 MB |     416 MB |     350 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6921 MB |    7335 MB |  466722 MB |  459800 MB |
|       from large pool |    6855 MB |    7270 MB |  466306 MB |  459450 MB |
|       from small pool |      65 MB |      65 MB |     416 MB |     350 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7380 MB |    7426 MB |   16156 MB |    8776 MB |
|       from large pool |    7314 MB |    7360 MB |   16086 MB |    8772 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  438817 KB |    1773 MB |  153091 MB |  152663 MB |
|       from large pool |  438460 KB |    1772 MB |  152481 MB |  152053 MB |
|       from small pool |     357 KB |       3 MB |     610 MB |     609 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   29545    |   28973    |
|       from large pool |     245    |     248    |   17585    |   17340    |
|       from small pool |     327    |     328    |   11960    |   11633    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   29545    |   28973    |
|       from large pool |     245    |     248    |   17585    |   17340    |
|       from small pool |     327    |     328    |   11960    |   11633    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     214    |     241    |     471    |     257    |
|       from large pool |     181    |     208    |     436    |     255    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      77    |     180    |   10557    |   10480    |
|       from large pool |      71    |     175    |    8446    |    8375    |
|       from small pool |       6    |       8    |    2111    |    2105    |
|===========================================================================|

2022-03-21 20:09:07 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:08 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 410.00 MiB (GPU 0; 7.93 GiB total capacity; 6.36 GiB already allocated; 80.44 MiB free; 7.18 GiB reserved in total by PyTorch)
2022-03-21 20:09:08 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 51           |        cudaMalloc retries: 56        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6480 MB |    7335 MB |  475811 MB |  469330 MB |
|       from large pool |    6416 MB |    7270 MB |  475388 MB |  468972 MB |
|       from small pool |      64 MB |      65 MB |     422 MB |     358 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6480 MB |    7335 MB |  475811 MB |  469330 MB |
|       from large pool |    6416 MB |    7270 MB |  475388 MB |  468972 MB |
|       from small pool |      64 MB |      65 MB |     422 MB |     358 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7350 MB |    7426 MB |   16156 MB |    8806 MB |
|       from large pool |    7284 MB |    7360 MB |   16086 MB |    8802 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     837 MB |    1773 MB |  156851 MB |  156013 MB |
|       from large pool |     835 MB |    1772 MB |  156229 MB |  155393 MB |
|       from small pool |       1 MB |       3 MB |     622 MB |     620 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   30007    |   29434    |
|       from large pool |     246    |     248    |   17944    |   17698    |
|       from small pool |     327    |     328    |   12063    |   11736    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   30007    |   29434    |
|       from large pool |     246    |     248    |   17944    |   17698    |
|       from small pool |     327    |     328    |   12063    |   11736    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     213    |     241    |     471    |     258    |
|       from large pool |     180    |     208    |     436    |     256    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      90    |     180    |   10799    |   10709    |
|       from large pool |      84    |     175    |    8646    |    8562    |
|       from small pool |       6    |       8    |    2153    |    2147    |
|===========================================================================|

2022-03-21 20:09:08 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:08 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 408.00 MiB (GPU 0; 7.93 GiB total capacity; 6.65 GiB already allocated; 112.44 MiB free; 7.15 GiB reserved in total by PyTorch)
2022-03-21 20:09:08 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 52           |        cudaMalloc retries: 57        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6775 MB |    7335 MB |  485261 MB |  478486 MB |
|       from large pool |    6711 MB |    7270 MB |  484832 MB |  478120 MB |
|       from small pool |      64 MB |      65 MB |     429 MB |     365 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6775 MB |    7335 MB |  485261 MB |  478486 MB |
|       from large pool |    6711 MB |    7270 MB |  484832 MB |  478120 MB |
|       from small pool |      64 MB |      65 MB |     429 MB |     365 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7318 MB |    7426 MB |   16156 MB |    8838 MB |
|       from large pool |    7252 MB |    7360 MB |   16086 MB |    8834 MB |
|       from small pool |      66 MB |      66 MB |      70 MB |       4 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  522438 KB |    1773 MB |  160395 MB |  159885 MB |
|       from large pool |  520861 KB |    1772 MB |  159763 MB |  159254 MB |
|       from small pool |    1576 KB |       3 MB |     632 MB |     631 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   30460    |   29888    |
|       from large pool |     246    |     248    |   18296    |   18050    |
|       from small pool |     326    |     328    |   12164    |   11838    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   30460    |   29888    |
|       from large pool |     246    |     248    |   18296    |   18050    |
|       from small pool |     326    |     328    |   12164    |   11838    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     212    |     241    |     471    |     259    |
|       from large pool |     179    |     208    |     436    |     257    |
|       from small pool |      33    |      33    |      35    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     118    |     180    |   11047    |   10929    |
|       from large pool |     112    |     175    |    8852    |    8740    |
|       from small pool |       6    |       8    |    2195    |    2189    |
|===========================================================================|

2022-03-21 20:09:08 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:09 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.50 GiB already allocated; 34.44 MiB free; 7.22 GiB reserved in total by PyTorch)
2022-03-21 20:09:09 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 53           |        cudaMalloc retries: 59        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6657 MB |    7335 MB |  494438 MB |  487780 MB |
|       from large pool |    6594 MB |    7270 MB |  494002 MB |  487408 MB |
|       from small pool |      63 MB |      65 MB |     436 MB |     372 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6657 MB |    7335 MB |  494438 MB |  487780 MB |
|       from large pool |    6594 MB |    7270 MB |  494002 MB |  487408 MB |
|       from small pool |      63 MB |      65 MB |     436 MB |     372 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7396 MB |    7426 MB |   16316 MB |    8920 MB |
|       from large pool |    7332 MB |    7360 MB |   16246 MB |    8914 MB |
|       from small pool |      64 MB |      66 MB |      70 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  755720 KB |    1773 MB |  164259 MB |  163521 MB |
|       from large pool |  755640 KB |    1772 MB |  163617 MB |  162879 MB |
|       from small pool |      80 KB |       3 MB |     641 MB |     641 MB |
|---------------------------------------------------------------------------|
| Allocations           |     538    |     575    |   30870    |   30332    |
|       from large pool |     219    |     248    |   18612    |   18393    |
|       from small pool |     319    |     328    |   12258    |   11939    |
|---------------------------------------------------------------------------|
| Active allocs         |     538    |     575    |   30870    |   30332    |
|       from large pool |     219    |     248    |   18612    |   18393    |
|       from small pool |     319    |     328    |   12258    |   11939    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     210    |     241    |     474    |     264    |
|       from large pool |     178    |     208    |     439    |     261    |
|       from small pool |      32    |      33    |      35    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     118    |     180    |   11283    |   11165    |
|       from large pool |     112    |     175    |    9049    |    8937    |
|       from small pool |       6    |       8    |    2234    |    2228    |
|===========================================================================|

2022-03-21 20:09:09 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:10 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.79 GiB already allocated; 32.44 MiB free; 7.22 GiB reserved in total by PyTorch)
2022-03-21 20:09:10 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 54           |        cudaMalloc retries: 60        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6949 MB |    7335 MB |  503986 MB |  497036 MB |
|       from large pool |    6884 MB |    7270 MB |  503542 MB |  496657 MB |
|       from small pool |      64 MB |      65 MB |     443 MB |     378 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6949 MB |    7335 MB |  503986 MB |  497036 MB |
|       from large pool |    6884 MB |    7270 MB |  503542 MB |  496657 MB |
|       from small pool |      64 MB |      65 MB |     443 MB |     378 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7398 MB |    7426 MB |   16318 MB |    8920 MB |
|       from large pool |    7332 MB |    7360 MB |   16246 MB |    8914 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  459428 KB |    1773 MB |  167782 MB |  167334 MB |
|       from large pool |  457791 KB |    1772 MB |  167130 MB |  166683 MB |
|       from small pool |    1636 KB |       3 MB |     651 MB |     650 MB |
|---------------------------------------------------------------------------|
| Allocations           |     560    |     575    |   31303    |   30743    |
|       from large pool |     238    |     248    |   18948    |   18710    |
|       from small pool |     322    |     328    |   12355    |   12033    |
|---------------------------------------------------------------------------|
| Active allocs         |     560    |     575    |   31303    |   30743    |
|       from large pool |     238    |     248    |   18948    |   18710    |
|       from small pool |     322    |     328    |   12355    |   12033    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     241    |     475    |     264    |
|       from large pool |     178    |     208    |     439    |     261    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     117    |     180    |   11496    |   11379    |
|       from large pool |     111    |     175    |    9228    |    9117    |
|       from small pool |       6    |       8    |    2268    |    2262    |
|===========================================================================|

2022-03-21 20:09:10 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:10 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 7.93 GiB total capacity; 6.72 GiB already allocated; 32.44 MiB free; 7.22 GiB reserved in total by PyTorch)
2022-03-21 20:09:10 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 55           |        cudaMalloc retries: 61        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6878 MB |    7335 MB |  513495 MB |  506617 MB |
|       from large pool |    6813 MB |    7270 MB |  513045 MB |  506231 MB |
|       from small pool |      64 MB |      65 MB |     450 MB |     385 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6878 MB |    7335 MB |  513495 MB |  506617 MB |
|       from large pool |    6813 MB |    7270 MB |  513045 MB |  506231 MB |
|       from small pool |      64 MB |      65 MB |     450 MB |     385 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7398 MB |    7426 MB |   16318 MB |    8920 MB |
|       from large pool |    7332 MB |    7360 MB |   16246 MB |    8914 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  532348 KB |    1773 MB |  171822 MB |  171302 MB |
|       from large pool |  530767 KB |    1772 MB |  171159 MB |  170641 MB |
|       from small pool |    1580 KB |       3 MB |     662 MB |     661 MB |
|---------------------------------------------------------------------------|
| Allocations           |     565    |     575    |   31744    |   31179    |
|       from large pool |     241    |     248    |   19290    |   19049    |
|       from small pool |     324    |     328    |   12454    |   12130    |
|---------------------------------------------------------------------------|
| Active allocs         |     565    |     575    |   31744    |   31179    |
|       from large pool |     241    |     248    |   19290    |   19049    |
|       from small pool |     324    |     328    |   12454    |   12130    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     241    |     475    |     264    |
|       from large pool |     178    |     208    |     439    |     261    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     114    |     180    |   11736    |   11622    |
|       from large pool |     108    |     175    |    9430    |    9322    |
|       from small pool |       6    |       8    |    2306    |    2300    |
|===========================================================================|

2022-03-21 20:09:10 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:11 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 7.93 GiB total capacity; 6.57 GiB already allocated; 6.44 MiB free; 7.25 GiB reserved in total by PyTorch)
2022-03-21 20:09:11 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 56           |        cudaMalloc retries: 62        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6722 MB |    7335 MB |  522826 MB |  516103 MB |
|       from large pool |    6658 MB |    7270 MB |  522369 MB |  515710 MB |
|       from small pool |      64 MB |      65 MB |     456 MB |     392 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6722 MB |    7335 MB |  522826 MB |  516103 MB |
|       from large pool |    6658 MB |    7270 MB |  522369 MB |  515710 MB |
|       from small pool |      64 MB |      65 MB |     456 MB |     392 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7424 MB |    7426 MB |   16344 MB |    8920 MB |
|       from large pool |    7358 MB |    7360 MB |   16272 MB |    8914 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  717987 KB |    1773 MB |  176033 MB |  175332 MB |
|       from large pool |  716061 KB |    1772 MB |  175359 MB |  174660 MB |
|       from small pool |    1925 KB |       3 MB |     673 MB |     671 MB |
|---------------------------------------------------------------------------|
| Allocations           |     556    |     575    |   32180    |   31624    |
|       from large pool |     233    |     248    |   19627    |   19394    |
|       from small pool |     323    |     328    |   12553    |   12230    |
|---------------------------------------------------------------------------|
| Active allocs         |     556    |     575    |   32180    |   31624    |
|       from large pool |     233    |     248    |   19627    |   19394    |
|       from small pool |     323    |     328    |   12553    |   12230    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     212    |     241    |     476    |     264    |
|       from large pool |     179    |     208    |     440    |     261    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     124    |     180    |   11995    |   11871    |
|       from large pool |     117    |     175    |    9649    |    9532    |
|       from small pool |       7    |       8    |    2346    |    2339    |
|===========================================================================|

2022-03-21 20:09:11 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:12 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 7.93 GiB total capacity; 6.48 GiB already allocated; 6.44 MiB free; 7.25 GiB reserved in total by PyTorch)
2022-03-21 20:09:12 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 57           |        cudaMalloc retries: 63        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6630 MB |    7335 MB |  532021 MB |  525390 MB |
|       from large pool |    6566 MB |    7270 MB |  531558 MB |  524991 MB |
|       from small pool |      64 MB |      65 MB |     463 MB |     399 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6630 MB |    7335 MB |  532021 MB |  525390 MB |
|       from large pool |    6566 MB |    7270 MB |  531558 MB |  524991 MB |
|       from small pool |      64 MB |      65 MB |     463 MB |     399 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7424 MB |    7426 MB |   16344 MB |    8920 MB |
|       from large pool |    7358 MB |    7360 MB |   16272 MB |    8914 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     793 MB |    1773 MB |  180291 MB |  179498 MB |
|       from large pool |     791 MB |    1772 MB |  179608 MB |  178816 MB |
|       from small pool |       1 MB |       3 MB |     683 MB |     681 MB |
|---------------------------------------------------------------------------|
| Allocations           |     556    |     575    |   32616    |   32060    |
|       from large pool |     233    |     248    |   19964    |   19731    |
|       from small pool |     323    |     328    |   12652    |   12329    |
|---------------------------------------------------------------------------|
| Active allocs         |     556    |     575    |   32616    |   32060    |
|       from large pool |     233    |     248    |   19964    |   19731    |
|       from small pool |     323    |     328    |   12652    |   12329    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     212    |     241    |     476    |     264    |
|       from large pool |     179    |     208    |     440    |     261    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     120    |     180    |   12245    |   12125    |
|       from large pool |     113    |     175    |    9855    |    9742    |
|       from small pool |       7    |       8    |    2390    |    2383    |
|===========================================================================|

2022-03-21 20:09:12 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:12 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.58 GiB already allocated; 6.44 MiB free; 7.25 GiB reserved in total by PyTorch)
2022-03-21 20:09:12 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 58           |        cudaMalloc retries: 64        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6742 MB |    7335 MB |  541366 MB |  534624 MB |
|       from large pool |    6677 MB |    7270 MB |  540896 MB |  534218 MB |
|       from small pool |      64 MB |      65 MB |     470 MB |     405 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6742 MB |    7335 MB |  541366 MB |  534624 MB |
|       from large pool |    6677 MB |    7270 MB |  540896 MB |  534218 MB |
|       from small pool |      64 MB |      65 MB |     470 MB |     405 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7424 MB |    7426 MB |   16344 MB |    8920 MB |
|       from large pool |    7358 MB |    7360 MB |   16272 MB |    8914 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  698257 KB |    1773 MB |  184607 MB |  183925 MB |
|       from large pool |  696403 KB |    1772 MB |  183913 MB |  183233 MB |
|       from small pool |    1853 KB |       3 MB |     694 MB |     692 MB |
|---------------------------------------------------------------------------|
| Allocations           |     562    |     575    |   33060    |   32498    |
|       from large pool |     239    |     248    |   20309    |   20070    |
|       from small pool |     323    |     328    |   12751    |   12428    |
|---------------------------------------------------------------------------|
| Active allocs         |     562    |     575    |   33060    |   32498    |
|       from large pool |     239    |     248    |   20309    |   20070    |
|       from small pool |     323    |     328    |   12751    |   12428    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     212    |     241    |     476    |     264    |
|       from large pool |     179    |     208    |     440    |     261    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     119    |     180    |   12483    |   12364    |
|       from large pool |     112    |     175    |   10054    |    9942    |
|       from small pool |       7    |       8    |    2429    |    2422    |
|===========================================================================|

2022-03-21 20:09:12 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:13 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 828.00 MiB (GPU 0; 7.93 GiB total capacity; 6.16 GiB already allocated; 594.44 MiB free; 6.68 GiB reserved in total by PyTorch)
2022-03-21 20:09:13 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 59           |        cudaMalloc retries: 65        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6309 MB |    7335 MB |  550055 MB |  543745 MB |
|       from large pool |    6244 MB |    7270 MB |  549577 MB |  543333 MB |
|       from small pool |      64 MB |      65 MB |     477 MB |     412 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6309 MB |    7335 MB |  550055 MB |  543745 MB |
|       from large pool |    6244 MB |    7270 MB |  549577 MB |  543333 MB |
|       from small pool |      64 MB |      65 MB |     477 MB |     412 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6836 MB |    7426 MB |   16344 MB |    9508 MB |
|       from large pool |    6770 MB |    7360 MB |   16272 MB |    9502 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  538996 KB |    1773 MB |  187744 MB |  187217 MB |
|       from large pool |  537831 KB |    1772 MB |  187036 MB |  186511 MB |
|       from small pool |    1165 KB |       3 MB |     707 MB |     706 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   33523    |   32951    |
|       from large pool |     245    |     248    |   20668    |   20423    |
|       from small pool |     327    |     328    |   12855    |   12528    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   33523    |   32951    |
|       from large pool |     245    |     248    |   20668    |   20423    |
|       from small pool |     327    |     328    |   12855    |   12528    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     208    |     241    |     476    |     268    |
|       from large pool |     175    |     208    |     440    |     265    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      61    |     180    |   12657    |   12596    |
|       from large pool |      55    |     175    |   10188    |   10133    |
|       from small pool |       6    |       8    |    2469    |    2463    |
|===========================================================================|

2022-03-21 20:09:13 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:14 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.44 GiB already allocated; 28.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:09:14 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 60           |        cudaMalloc retries: 66        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6590 MB |    7335 MB |  559179 MB |  552588 MB |
|       from large pool |    6526 MB |    7270 MB |  558695 MB |  552168 MB |
|       from small pool |      64 MB |      65 MB |     483 MB |     419 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6590 MB |    7335 MB |  559179 MB |  552588 MB |
|       from large pool |    6526 MB |    7270 MB |  558695 MB |  552168 MB |
|       from small pool |      64 MB |      65 MB |     483 MB |     419 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7402 MB |    7426 MB |   16910 MB |    9508 MB |
|       from large pool |    7336 MB |    7360 MB |   16838 MB |    9502 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     811 MB |    1773 MB |  190547 MB |  189735 MB |
|       from large pool |     809 MB |    1772 MB |  189828 MB |  189018 MB |
|       from small pool |       1 MB |       3 MB |     718 MB |     716 MB |
|---------------------------------------------------------------------------|
| Allocations           |     549    |     575    |   33948    |   33399    |
|       from large pool |     227    |     248    |   20996    |   20769    |
|       from small pool |     322    |     328    |   12952    |   12630    |
|---------------------------------------------------------------------------|
| Active allocs         |     549    |     575    |   33948    |   33399    |
|       from large pool |     227    |     248    |   20996    |   20769    |
|       from small pool |     322    |     328    |   12952    |   12630    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     241    |     494    |     268    |
|       from large pool |     193    |     208    |     458    |     265    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     133    |     180    |   12911    |   12778    |
|       from large pool |     126    |     175    |   10401    |   10275    |
|       from small pool |       7    |       8    |    2510    |    2503    |
|===========================================================================|

2022-03-21 20:09:14 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:15 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 6.57 GiB already allocated; 312.44 MiB free; 6.95 GiB reserved in total by PyTorch)
2022-03-21 20:09:15 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 61           |        cudaMalloc retries: 67        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6727 MB |    7335 MB |  568440 MB |  561712 MB |
|       from large pool |    6662 MB |    7270 MB |  567948 MB |  561286 MB |
|       from small pool |      65 MB |      65 MB |     491 MB |     426 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6727 MB |    7335 MB |  568440 MB |  561712 MB |
|       from large pool |    6662 MB |    7270 MB |  567948 MB |  561286 MB |
|       from small pool |      65 MB |      65 MB |     491 MB |     426 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7118 MB |    7426 MB |   16910 MB |    9792 MB |
|       from large pool |    7052 MB |    7360 MB |   16838 MB |    9786 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  399975 KB |    1773 MB |  192487 MB |  192096 MB |
|       from large pool |  399083 KB |    1772 MB |  191758 MB |  191368 MB |
|       from small pool |     892 KB |       3 MB |     729 MB |     728 MB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     575    |   34402    |   33831    |
|       from large pool |     245    |     248    |   21348    |   21103    |
|       from small pool |     326    |     328    |   13054    |   12728    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     575    |   34402    |   33831    |
|       from large pool |     245    |     248    |   21348    |   21103    |
|       from small pool |     326    |     328    |   13054    |   12728    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     219    |     241    |     494    |     275    |
|       from large pool |     186    |     208    |     458    |     272    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      73    |     180    |   13110    |   13037    |
|       from large pool |      68    |     175    |   10564    |   10496    |
|       from small pool |       5    |       8    |    2546    |    2541    |
|===========================================================================|

2022-03-21 20:09:15 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:15 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.60 GiB already allocated; 14.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:15 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 62           |        cudaMalloc retries: 68        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6759 MB |    7335 MB |  577804 MB |  571044 MB |
|       from large pool |    6695 MB |    7270 MB |  577305 MB |  570610 MB |
|       from small pool |      64 MB |      65 MB |     498 MB |     433 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6759 MB |    7335 MB |  577804 MB |  571044 MB |
|       from large pool |    6695 MB |    7270 MB |  577305 MB |  570610 MB |
|       from small pool |      64 MB |      65 MB |     498 MB |     433 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7416 MB |    7426 MB |   17208 MB |    9792 MB |
|       from large pool |    7350 MB |    7360 MB |   17136 MB |    9786 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  672255 KB |    1773 MB |  195216 MB |  194560 MB |
|       from large pool |  670490 KB |    1772 MB |  194476 MB |  193821 MB |
|       from small pool |    1765 KB |       3 MB |     740 MB |     738 MB |
|---------------------------------------------------------------------------|
| Allocations           |     568    |     575    |   34854    |   34286    |
|       from large pool |     243    |     248    |   21699    |   21456    |
|       from small pool |     325    |     328    |   13155    |   12830    |
|---------------------------------------------------------------------------|
| Active allocs         |     568    |     575    |   34854    |   34286    |
|       from large pool |     243    |     248    |   21699    |   21456    |
|       from small pool |     325    |     328    |   13155    |   12830    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     227    |     241    |     502    |     275    |
|       from large pool |     194    |     208    |     466    |     272    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     114    |     180    |   13354    |   13240    |
|       from large pool |     107    |     175    |   10768    |   10661    |
|       from small pool |       7    |       8    |    2586    |    2579    |
|===========================================================================|

2022-03-21 20:09:15 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:16 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 6.44 GiB already allocated; 576.44 MiB free; 6.69 GiB reserved in total by PyTorch)
2022-03-21 20:09:16 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 63           |        cudaMalloc retries: 69        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6592 MB |    7335 MB |  586892 MB |  580299 MB |
|       from large pool |    6528 MB |    7270 MB |  586387 MB |  579859 MB |
|       from small pool |      64 MB |      65 MB |     504 MB |     440 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6592 MB |    7335 MB |  586892 MB |  580299 MB |
|       from large pool |    6528 MB |    7270 MB |  586387 MB |  579859 MB |
|       from small pool |      64 MB |      65 MB |     504 MB |     440 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6854 MB |    7426 MB |   17208 MB |   10354 MB |
|       from large pool |    6788 MB |    7360 MB |   17136 MB |   10348 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  267516 KB |    1773 MB |  197750 MB |  197489 MB |
|       from large pool |  265662 KB |    1772 MB |  196996 MB |  196737 MB |
|       from small pool |    1853 KB |       3 MB |     754 MB |     752 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   35317    |   34745    |
|       from large pool |     246    |     248    |   22059    |   21813    |
|       from small pool |     326    |     328    |   13258    |   12932    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   35317    |   34745    |
|       from large pool |     246    |     248    |   22059    |   21813    |
|       from small pool |     326    |     328    |   13258    |   12932    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     213    |     241    |     502    |     289    |
|       from large pool |     180    |     208    |     466    |     286    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      65    |     180    |   13530    |   13465    |
|       from large pool |      61    |     175    |   10902    |   10841    |
|       from small pool |       4    |       8    |    2628    |    2624    |
|===========================================================================|

2022-03-21 20:09:16 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:17 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 7.06 GiB already allocated; 16.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:17 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 64           |        cudaMalloc retries: 70        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7232 MB |    7335 MB |  596836 MB |  589603 MB |
|       from large pool |    7167 MB |    7270 MB |  596324 MB |  589156 MB |
|       from small pool |      64 MB |      65 MB |     511 MB |     447 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7232 MB |    7335 MB |  596836 MB |  589603 MB |
|       from large pool |    7167 MB |    7270 MB |  596324 MB |  589156 MB |
|       from small pool |      64 MB |      65 MB |     511 MB |     447 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7414 MB |    7426 MB |   17768 MB |   10354 MB |
|       from large pool |    7348 MB |    7360 MB |   17696 MB |   10348 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  186018 KB |    1773 MB |  199817 MB |  199636 MB |
|       from large pool |  184493 KB |    1772 MB |  199052 MB |  198872 MB |
|       from small pool |    1524 KB |       3 MB |     764 MB |     763 MB |
|---------------------------------------------------------------------------|
| Allocations           |     560    |     575    |   35750    |   35190    |
|       from large pool |     238    |     248    |   22395    |   22157    |
|       from small pool |     322    |     328    |   13355    |   13033    |
|---------------------------------------------------------------------------|
| Active allocs         |     560    |     575    |   35750    |   35190    |
|       from large pool |     238    |     248    |   22395    |   22157    |
|       from small pool |     322    |     328    |   13355    |   13033    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     232    |     241    |     521    |     289    |
|       from large pool |     199    |     208    |     485    |     286    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      53    |     180    |   13659    |   13606    |
|       from large pool |      46    |     175    |   10984    |   10938    |
|       from small pool |       7    |       8    |    2675    |    2668    |
|===========================================================================|

2022-03-21 20:09:17 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:17 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.46 GiB already allocated; 16.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:17 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 65           |        cudaMalloc retries: 71        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6613 MB |    7335 MB |  606000 MB |  599387 MB |
|       from large pool |    6549 MB |    7270 MB |  605482 MB |  598932 MB |
|       from small pool |      64 MB |      65 MB |     518 MB |     454 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6613 MB |    7335 MB |  606000 MB |  599387 MB |
|       from large pool |    6549 MB |    7270 MB |  605482 MB |  598932 MB |
|       from small pool |      64 MB |      65 MB |     518 MB |     454 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7414 MB |    7426 MB |   17768 MB |   10354 MB |
|       from large pool |    7348 MB |    7360 MB |   17696 MB |   10348 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     800 MB |    1773 MB |  202854 MB |  202053 MB |
|       from large pool |     798 MB |    1772 MB |  202078 MB |  201279 MB |
|       from small pool |       1 MB |       3 MB |     775 MB |     773 MB |
|---------------------------------------------------------------------------|
| Allocations           |     562    |     575    |   36194    |   35632    |
|       from large pool |     239    |     248    |   22740    |   22501    |
|       from small pool |     323    |     328    |   13454    |   13131    |
|---------------------------------------------------------------------------|
| Active allocs         |     562    |     575    |   36194    |   35632    |
|       from large pool |     239    |     248    |   22740    |   22501    |
|       from small pool |     323    |     328    |   13454    |   13131    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     232    |     241    |     521    |     289    |
|       from large pool |     199    |     208    |     485    |     286    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     128    |     180    |   13895    |   13767    |
|       from large pool |     121    |     175    |   11181    |   11060    |
|       from small pool |       7    |       8    |    2714    |    2707    |
|===========================================================================|

2022-03-21 20:09:17 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:18 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 7.93 GiB total capacity; 7.06 GiB already allocated; 16.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:18 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 66           |        cudaMalloc retries: 72        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7234 MB |    7335 MB |  616014 MB |  608779 MB |
|       from large pool |    7169 MB |    7270 MB |  615488 MB |  608318 MB |
|       from small pool |      64 MB |      65 MB |     525 MB |     461 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7234 MB |    7335 MB |  616014 MB |  608779 MB |
|       from large pool |    7169 MB |    7270 MB |  615488 MB |  608318 MB |
|       from small pool |      64 MB |      65 MB |     525 MB |     461 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7414 MB |    7426 MB |   17768 MB |   10354 MB |
|       from large pool |    7348 MB |    7360 MB |   17696 MB |   10348 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  183770 KB |    1773 MB |  204940 MB |  204761 MB |
|       from large pool |  182383 KB |    1772 MB |  204154 MB |  203976 MB |
|       from small pool |    1387 KB |       3 MB |     786 MB |     784 MB |
|---------------------------------------------------------------------------|
| Allocations           |     565    |     575    |   36635    |   36070    |
|       from large pool |     241    |     248    |   23082    |   22841    |
|       from small pool |     324    |     328    |   13553    |   13229    |
|---------------------------------------------------------------------------|
| Active allocs         |     565    |     575    |   36635    |   36070    |
|       from large pool |     241    |     248    |   23082    |   22841    |
|       from small pool |     324    |     328    |   13553    |   13229    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     232    |     241    |     521    |     289    |
|       from large pool |     199    |     208    |     485    |     286    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      39    |     180    |   13996    |   13957    |
|       from large pool |      32    |     175    |   11244    |   11212    |
|       from small pool |       7    |       8    |    2752    |    2745    |
|===========================================================================|

2022-03-21 20:09:18 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:18 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.79 GiB already allocated; 16.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:18 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 67           |        cudaMalloc retries: 73        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6923 MB |    7335 MB |  625673 MB |  618750 MB |
|       from large pool |    6858 MB |    7270 MB |  625140 MB |  618282 MB |
|       from small pool |      64 MB |      65 MB |     533 MB |     468 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6923 MB |    7335 MB |  625673 MB |  618750 MB |
|       from large pool |    6858 MB |    7270 MB |  625140 MB |  618282 MB |
|       from small pool |      64 MB |      65 MB |     533 MB |     468 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7414 MB |    7426 MB |   17768 MB |   10354 MB |
|       from large pool |    7348 MB |    7360 MB |   17696 MB |   10348 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  469961 KB |    1773 MB |  207175 MB |  206716 MB |
|       from large pool |  468530 KB |    1772 MB |  206377 MB |  205920 MB |
|       from small pool |    1430 KB |       3 MB |     797 MB |     795 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   37088    |   36516    |
|       from large pool |     246    |     248    |   23434    |   23188    |
|       from small pool |     326    |     328    |   13654    |   13328    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   37088    |   36516    |
|       from large pool |     246    |     248    |   23434    |   23188    |
|       from small pool |     326    |     328    |   13654    |   13328    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     232    |     241    |     521    |     289    |
|       from large pool |     199    |     208    |     485    |     286    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     110    |     180    |   14215    |   14105    |
|       from large pool |     105    |     175    |   11425    |   11320    |
|       from small pool |       5    |       8    |    2790    |    2785    |
|===========================================================================|

2022-03-21 20:09:18 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:19 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.41 GiB already allocated; 8.44 MiB free; 7.25 GiB reserved in total by PyTorch)
2022-03-21 20:09:19 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 68           |        cudaMalloc retries: 75        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6564 MB |    7335 MB |  634734 MB |  628170 MB |
|       from large pool |    6500 MB |    7270 MB |  634194 MB |  627694 MB |
|       from small pool |      64 MB |      65 MB |     539 MB |     475 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6564 MB |    7335 MB |  634734 MB |  628170 MB |
|       from large pool |    6500 MB |    7270 MB |  634194 MB |  627694 MB |
|       from small pool |      64 MB |      65 MB |     539 MB |     475 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7422 MB |    7426 MB |   17832 MB |   10410 MB |
|       from large pool |    7356 MB |    7360 MB |   17760 MB |   10404 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     857 MB |    1773 MB |  209781 MB |  208923 MB |
|       from large pool |     855 MB |    1772 MB |  208973 MB |  208117 MB |
|       from small pool |       1 MB |       3 MB |     808 MB |     806 MB |
|---------------------------------------------------------------------------|
| Allocations           |     546    |     575    |   37508    |   36962    |
|       from large pool |     224    |     248    |   23757    |   23533    |
|       from small pool |     322    |     328    |   13751    |   13429    |
|---------------------------------------------------------------------------|
| Active allocs         |     546    |     575    |   37508    |   36962    |
|       from large pool |     224    |     248    |   23757    |   23533    |
|       from small pool |     322    |     328    |   13751    |   13429    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     231    |     241    |     523    |     292    |
|       from large pool |     198    |     208    |     487    |     289    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     125    |     180    |   14464    |   14339    |
|       from large pool |     120    |     175    |   11628    |   11508    |
|       from small pool |       5    |       8    |    2836    |    2831    |
|===========================================================================|

2022-03-21 20:09:19 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:20 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 826.00 MiB (GPU 0; 7.93 GiB total capacity; 6.80 GiB already allocated; 64.44 MiB free; 7.19 GiB reserved in total by PyTorch)
2022-03-21 20:09:20 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 69           |        cudaMalloc retries: 76        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6959 MB |    7335 MB |  644327 MB |  637368 MB |
|       from large pool |    6893 MB |    7270 MB |  643779 MB |  636885 MB |
|       from small pool |      65 MB |      65 MB |     547 MB |     482 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6959 MB |    7335 MB |  644327 MB |  637368 MB |
|       from large pool |    6893 MB |    7270 MB |  643779 MB |  636885 MB |
|       from small pool |      65 MB |      65 MB |     547 MB |     482 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7366 MB |    7426 MB |   17832 MB |   10466 MB |
|       from large pool |    7300 MB |    7360 MB |   17760 MB |   10460 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  416716 KB |    1773 MB |  211286 MB |  210879 MB |
|       from large pool |  416073 KB |    1772 MB |  210467 MB |  210061 MB |
|       from small pool |     643 KB |       3 MB |     818 MB |     818 MB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     575    |   37962    |   37391    |
|       from large pool |     245    |     248    |   24109    |   23864    |
|       from small pool |     326    |     328    |   13853    |   13527    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     575    |   37962    |   37391    |
|       from large pool |     245    |     248    |   24109    |   23864    |
|       from small pool |     326    |     328    |   13853    |   13527    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     229    |     241    |     523    |     294    |
|       from large pool |     196    |     208    |     487    |     291    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      82    |     180    |   14670    |   14588    |
|       from large pool |      76    |     175    |   11785    |   11709    |
|       from small pool |       6    |       8    |    2885    |    2879    |
|===========================================================================|

2022-03-21 20:09:20 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:21 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.54 GiB already allocated; 64.44 MiB free; 7.19 GiB reserved in total by PyTorch)
2022-03-21 20:09:21 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 70           |        cudaMalloc retries: 77        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6665 MB |    7335 MB |  653680 MB |  647014 MB |
|       from large pool |    6600 MB |    7270 MB |  653125 MB |  646524 MB |
|       from small pool |      64 MB |      65 MB |     554 MB |     490 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6665 MB |    7335 MB |  653680 MB |  647014 MB |
|       from large pool |    6600 MB |    7270 MB |  653125 MB |  646524 MB |
|       from small pool |      64 MB |      65 MB |     554 MB |     490 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7366 MB |    7426 MB |   17832 MB |   10466 MB |
|       from large pool |    7300 MB |    7360 MB |   17760 MB |   10460 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  684831 KB |    1773 MB |  213877 MB |  213208 MB |
|       from large pool |  683166 KB |    1772 MB |  213047 MB |  212379 MB |
|       from small pool |    1665 KB |       3 MB |     830 MB |     828 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   38424    |   37851    |
|       from large pool |     246    |     248    |   24468    |   24222    |
|       from small pool |     327    |     328    |   13956    |   13629    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   38424    |   37851    |
|       from large pool |     246    |     248    |   24468    |   24222    |
|       from small pool |     327    |     328    |   13956    |   13629    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     229    |     241    |     523    |     294    |
|       from large pool |     196    |     208    |     487    |     291    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     108    |     180    |   14908    |   14800    |
|       from large pool |     102    |     175    |   11984    |   11882    |
|       from small pool |       6    |       8    |    2924    |    2918    |
|===========================================================================|

2022-03-21 20:09:21 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:22 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 826.00 MiB (GPU 0; 7.93 GiB total capacity; 6.66 GiB already allocated; 260.44 MiB free; 7.00 GiB reserved in total by PyTorch)
2022-03-21 20:09:22 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 71           |        cudaMalloc retries: 78        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6819 MB |    7335 MB |  663081 MB |  656261 MB |
|       from large pool |    6754 MB |    7270 MB |  662519 MB |  655764 MB |
|       from small pool |      64 MB |      65 MB |     561 MB |     496 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6819 MB |    7335 MB |  663081 MB |  656261 MB |
|       from large pool |    6754 MB |    7270 MB |  662519 MB |  655764 MB |
|       from small pool |      64 MB |      65 MB |     561 MB |     496 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7170 MB |    7426 MB |   17832 MB |   10662 MB |
|       from large pool |    7104 MB |    7360 MB |   17760 MB |   10656 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  359153 KB |    1773 MB |  215605 MB |  215254 MB |
|       from large pool |  358106 KB |    1772 MB |  214764 MB |  214414 MB |
|       from small pool |    1047 KB |       3 MB |     840 MB |     839 MB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     575    |   38878    |   38307    |
|       from large pool |     245    |     248    |   24820    |   24575    |
|       from small pool |     326    |     328    |   14058    |   13732    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     575    |   38878    |   38307    |
|       from large pool |     245    |     248    |   24820    |   24575    |
|       from small pool |     326    |     328    |   14058    |   13732    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     223    |     241    |     523    |     300    |
|       from large pool |     190    |     208    |     487    |     297    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      60    |     180    |   15096    |   15036    |
|       from large pool |      54    |     175    |   12134    |   12080    |
|       from small pool |       6    |       8    |    2962    |    2956    |
|===========================================================================|

2022-03-21 20:09:22 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:22 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 7.93 GiB total capacity; 7.00 GiB already allocated; 88.44 MiB free; 7.17 GiB reserved in total by PyTorch)
2022-03-21 20:09:22 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 72           |        cudaMalloc retries: 79        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7138 MB |    7335 MB |  673027 MB |  665888 MB |
|       from large pool |    7074 MB |    7270 MB |  672457 MB |  665383 MB |
|       from small pool |      64 MB |      65 MB |     569 MB |     504 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7138 MB |    7335 MB |  673027 MB |  665888 MB |
|       from large pool |    7074 MB |    7270 MB |  672457 MB |  665383 MB |
|       from small pool |      64 MB |      65 MB |     569 MB |     504 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7342 MB |    7426 MB |   18004 MB |   10662 MB |
|       from large pool |    7276 MB |    7360 MB |   17932 MB |   10656 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  175172 KB |    1773 MB |  217242 MB |  217071 MB |
|       from large pool |  173867 KB |    1772 MB |  216390 MB |  216220 MB |
|       from small pool |    1304 KB |       3 MB |     852 MB |     851 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   39331    |   38759    |
|       from large pool |     246    |     248    |   25172    |   24926    |
|       from small pool |     326    |     328    |   14159    |   13833    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   39331    |   38759    |
|       from large pool |     246    |     248    |   25172    |   24926    |
|       from small pool |     326    |     328    |   14159    |   13833    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     227    |     241    |     527    |     300    |
|       from large pool |     194    |     208    |     491    |     297    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     107    |     180    |   15323    |   15216    |
|       from large pool |     101    |     175    |   12322    |   12221    |
|       from small pool |       6    |       8    |    3001    |    2995    |
|===========================================================================|

2022-03-21 20:09:22 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:23 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 826.00 MiB (GPU 0; 7.93 GiB total capacity; 6.54 GiB already allocated; 146.44 MiB free; 7.11 GiB reserved in total by PyTorch)
2022-03-21 20:09:23 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 73           |        cudaMalloc retries: 80        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6695 MB |    7335 MB |  682268 MB |  675573 MB |
|       from large pool |    6631 MB |    7270 MB |  681692 MB |  675061 MB |
|       from small pool |      64 MB |      65 MB |     575 MB |     511 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6695 MB |    7335 MB |  682268 MB |  675573 MB |
|       from large pool |    6631 MB |    7270 MB |  681692 MB |  675061 MB |
|       from small pool |      64 MB |      65 MB |     575 MB |     511 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7284 MB |    7426 MB |   18004 MB |   10720 MB |
|       from large pool |    7218 MB |    7360 MB |   17932 MB |   10714 MB |
|       from small pool |      66 MB |      66 MB |      72 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  602496 KB |    1773 MB |  219673 MB |  219084 MB |
|       from large pool |  600729 KB |    1772 MB |  218809 MB |  218223 MB |
|       from small pool |    1767 KB |       3 MB |     863 MB |     861 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   39794    |   39222    |
|       from large pool |     246    |     248    |   25532    |   25286    |
|       from small pool |     326    |     328    |   14262    |   13936    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   39794    |   39222    |
|       from large pool |     246    |     248    |   25532    |   25286    |
|       from small pool |     326    |     328    |   14262    |   13936    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     241    |     527    |     302    |
|       from large pool |     192    |     208    |     491    |     299    |
|       from small pool |      33    |      33    |      36    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      77    |     180    |   15533    |   15456    |
|       from large pool |      71    |     175    |   12492    |   12421    |
|       from small pool |       6    |       8    |    3041    |    3035    |
|===========================================================================|

2022-03-21 20:09:23 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:24 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 6.26 GiB already allocated; 550.44 MiB free; 6.72 GiB reserved in total by PyTorch)
2022-03-21 20:09:24 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 74           |        cudaMalloc retries: 81        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6406 MB |    7335 MB |  691102 MB |  684696 MB |
|       from large pool |    6329 MB |    7270 MB |  690501 MB |  684171 MB |
|       from small pool |      76 MB |      76 MB |     601 MB |     524 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6406 MB |    7335 MB |  691102 MB |  684696 MB |
|       from large pool |    6329 MB |    7270 MB |  690501 MB |  684171 MB |
|       from small pool |      76 MB |      76 MB |     601 MB |     524 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6880 MB |    7426 MB |   18016 MB |   11136 MB |
|       from large pool |    6802 MB |    7360 MB |   17932 MB |   11130 MB |
|       from small pool |      78 MB |      78 MB |      84 MB |       6 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  485026 KB |    1773 MB |  221653 MB |  221180 MB |
|       from large pool |  483675 KB |    1772 MB |  220768 MB |  220295 MB |
|       from small pool |    1351 KB |       3 MB |     885 MB |     884 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   40257    |   39685    |
|       from large pool |     233    |     248    |   25873    |   25640    |
|       from small pool |     339    |     340    |   14384    |   14045    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   40257    |   39685    |
|       from large pool |     233    |     248    |   25873    |   25640    |
|       from small pool |     339    |     340    |   14384    |   14045    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     219    |     241    |     533    |     314    |
|       from large pool |     180    |     208    |     491    |     311    |
|       from small pool |      39    |      39    |      42    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      50    |     180    |   15740    |   15690    |
|       from large pool |      45    |     175    |   12641    |   12596    |
|       from small pool |       5    |       8    |    3099    |    3094    |
|===========================================================================|

2022-03-21 20:09:24 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:25 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 402.00 MiB (GPU 0; 7.93 GiB total capacity; 6.71 GiB already allocated; 262.44 MiB free; 7.00 GiB reserved in total by PyTorch)
2022-03-21 20:09:25 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 75           |        cudaMalloc retries: 82        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6843 MB |    7335 MB |  700647 MB |  693804 MB |
|       from large pool |    6778 MB |    7270 MB |  700039 MB |  693260 MB |
|       from small pool |      64 MB |      76 MB |     608 MB |     543 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6843 MB |    7335 MB |  700647 MB |  693804 MB |
|       from large pool |    6778 MB |    7270 MB |  700039 MB |  693260 MB |
|       from small pool |      64 MB |      76 MB |     608 MB |     543 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7168 MB |    7426 MB |   18316 MB |   11148 MB |
|       from large pool |    7102 MB |    7360 MB |   18232 MB |   11130 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  299548 KB |    1773 MB |  223544 MB |  223252 MB |
|       from large pool |  298121 KB |    1772 MB |  222641 MB |  222350 MB |
|       from small pool |    1426 KB |       3 MB |     902 MB |     901 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   40710    |   40138    |
|       from large pool |     246    |     248    |   26225    |   25979    |
|       from small pool |     326    |     340    |   14485    |   14159    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   40710    |   40138    |
|       from large pool |     246    |     248    |   26225    |   25979    |
|       from small pool |     326    |     340    |   14485    |   14159    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     221    |     241    |     541    |     320    |
|       from large pool |     188    |     208    |     499    |     311    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     170    |     180    |   16087    |   15917    |
|       from large pool |     164    |     175    |   12941    |   12777    |
|       from small pool |       6    |       8    |    3146    |    3140    |
|===========================================================================|

2022-03-21 20:09:25 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:25 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 6.31 GiB already allocated; 646.44 MiB free; 6.62 GiB reserved in total by PyTorch)
2022-03-21 20:09:25 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 76           |        cudaMalloc retries: 83        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6464 MB |    7335 MB |  709557 MB |  703092 MB |
|       from large pool |    6400 MB |    7270 MB |  708942 MB |  702542 MB |
|       from small pool |      64 MB |      76 MB |     614 MB |     550 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6464 MB |    7335 MB |  709557 MB |  703092 MB |
|       from large pool |    6400 MB |    7270 MB |  708942 MB |  702542 MB |
|       from small pool |      64 MB |      76 MB |     614 MB |     550 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6784 MB |    7426 MB |   18316 MB |   11532 MB |
|       from large pool |    6718 MB |    7360 MB |   18232 MB |   11514 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  326728 KB |    1773 MB |  225880 MB |  225561 MB |
|       from large pool |  324864 KB |    1772 MB |  224963 MB |  224646 MB |
|       from small pool |    1864 KB |       3 MB |     916 MB |     915 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   41173    |   40601    |
|       from large pool |     246    |     248    |   26585    |   26339    |
|       from small pool |     326    |     340    |   14588    |   14262    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   41173    |   40601    |
|       from large pool |     246    |     248    |   26585    |   26339    |
|       from small pool |     326    |     340    |   14588    |   14262    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     210    |     241    |     541    |     331    |
|       from large pool |     177    |     208    |     499    |     322    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      61    |     180    |   16261    |   16200    |
|       from large pool |      57    |     175    |   13073    |   13016    |
|       from small pool |       4    |       8    |    3188    |    3184    |
|===========================================================================|

2022-03-21 20:09:25 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:26 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 7.93 GiB total capacity; 6.99 GiB already allocated; 48.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:09:26 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 77           |        cudaMalloc retries: 84        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7162 MB |    7335 MB |  719482 MB |  712320 MB |
|       from large pool |    7098 MB |    7270 MB |  718860 MB |  711762 MB |
|       from small pool |      64 MB |      76 MB |     622 MB |     557 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7162 MB |    7335 MB |  719482 MB |  712320 MB |
|       from large pool |    7098 MB |    7270 MB |  718860 MB |  711762 MB |
|       from small pool |      64 MB |      76 MB |     622 MB |     557 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7382 MB |    7426 MB |   18914 MB |   11532 MB |
|       from large pool |    7316 MB |    7360 MB |   18830 MB |   11514 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  224510 KB |    1773 MB |  227864 MB |  227645 MB |
|       from large pool |  223166 KB |    1772 MB |  226937 MB |  226719 MB |
|       from small pool |    1344 KB |       3 MB |     927 MB |     926 MB |
|---------------------------------------------------------------------------|
| Allocations           |     565    |     575    |   41614    |   41049    |
|       from large pool |     241    |     248    |   26927    |   26686    |
|       from small pool |     324    |     340    |   14687    |   14363    |
|---------------------------------------------------------------------------|
| Active allocs         |     565    |     575    |   41614    |   41049    |
|       from large pool |     241    |     248    |   26927    |   26686    |
|       from small pool |     324    |     340    |   14687    |   14363    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     229    |     241    |     560    |     331    |
|       from large pool |     196    |     208    |     518    |     322    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      39    |     180    |   16367    |   16328    |
|       from large pool |      34    |     175    |   13139    |   13105    |
|       from small pool |       5    |       8    |    3228    |    3223    |
|===========================================================================|

2022-03-21 20:09:26 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:26 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.42 GiB already allocated; 16.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:26 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 78           |        cudaMalloc retries: 85        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6571 MB |    7335 MB |  728571 MB |  721999 MB |
|       from large pool |    6507 MB |    7270 MB |  727942 MB |  721435 MB |
|       from small pool |      64 MB |      76 MB |     628 MB |     564 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6571 MB |    7335 MB |  728571 MB |  721999 MB |
|       from large pool |    6507 MB |    7270 MB |  727942 MB |  721435 MB |
|       from small pool |      64 MB |      76 MB |     628 MB |     564 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7414 MB |    7426 MB |   18946 MB |   11532 MB |
|       from large pool |    7348 MB |    7360 MB |   18862 MB |   11514 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     842 MB |    1773 MB |  231027 MB |  230185 MB |
|       from large pool |     840 MB |    1772 MB |  230089 MB |  229249 MB |
|       from small pool |       1 MB |       3 MB |     938 MB |     936 MB |
|---------------------------------------------------------------------------|
| Allocations           |     561    |     575    |   42056    |   41495    |
|       from large pool |     238    |     248    |   27270    |   27032    |
|       from small pool |     323    |     340    |   14786    |   14463    |
|---------------------------------------------------------------------------|
| Active allocs         |     561    |     575    |   42056    |   41495    |
|       from large pool |     238    |     248    |   27270    |   27032    |
|       from small pool |     323    |     340    |   14786    |   14463    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     230    |     241    |     561    |     331    |
|       from large pool |     197    |     208    |     519    |     322    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     140    |     180    |   16611    |   16471    |
|       from large pool |     133    |     175    |   13342    |   13209    |
|       from small pool |       7    |       8    |    3269    |    3262    |
|===========================================================================|

2022-03-21 20:09:26 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:27 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 410.00 MiB (GPU 0; 7.93 GiB total capacity; 6.96 GiB already allocated; 16.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:27 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 79           |        cudaMalloc retries: 86        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7092 MB |    7335 MB |  738496 MB |  731404 MB |
|       from large pool |    7027 MB |    7270 MB |  737859 MB |  730832 MB |
|       from small pool |      65 MB |      76 MB |     637 MB |     571 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7092 MB |    7335 MB |  738496 MB |  731404 MB |
|       from large pool |    7027 MB |    7270 MB |  737859 MB |  730832 MB |
|       from small pool |      65 MB |      76 MB |     637 MB |     571 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7414 MB |    7426 MB |   18946 MB |   11532 MB |
|       from large pool |    7348 MB |    7360 MB |   18862 MB |   11514 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  296246 KB |    1773 MB |  232692 MB |  232403 MB |
|       from large pool |  295842 KB |    1772 MB |  231743 MB |  231454 MB |
|       from small pool |     404 KB |       3 MB |     949 MB |     948 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   42509    |   41937    |
|       from large pool |     245    |     248    |   27621    |   27376    |
|       from small pool |     327    |     340    |   14888    |   14561    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   42509    |   41937    |
|       from large pool |     245    |     248    |   27621    |   27376    |
|       from small pool |     327    |     340    |   14888    |   14561    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     230    |     241    |     561    |     331    |
|       from large pool |     197    |     208    |     519    |     322    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      25    |     180    |   16696    |   16671    |
|       from large pool |      19    |     175    |   13382    |   13363    |
|       from small pool |       6    |       8    |    3314    |    3308    |
|===========================================================================|

2022-03-21 20:09:27 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:28 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 412.00 MiB (GPU 0; 7.93 GiB total capacity; 6.47 GiB already allocated; 48.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:09:28 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 80           |        cudaMalloc retries: 87        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6596 MB |    7335 MB |  747749 MB |  741153 MB |
|       from large pool |    6532 MB |    7270 MB |  747105 MB |  740573 MB |
|       from small pool |      64 MB |      76 MB |     643 MB |     579 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6596 MB |    7335 MB |  747749 MB |  741153 MB |
|       from large pool |    6532 MB |    7270 MB |  747105 MB |  740573 MB |
|       from small pool |      64 MB |      76 MB |     643 MB |     579 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7382 MB |    7426 MB |   18946 MB |   11564 MB |
|       from large pool |    7316 MB |    7360 MB |   18862 MB |   11546 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  771590 KB |    1773 MB |  235343 MB |  234589 MB |
|       from large pool |  769877 KB |    1772 MB |  234382 MB |  233630 MB |
|       from small pool |    1713 KB |       3 MB |     960 MB |     959 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   42971    |   42398    |
|       from large pool |     246    |     248    |   27980    |   27734    |
|       from small pool |     327    |     340    |   14991    |   14664    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   42971    |   42398    |
|       from large pool |     246    |     248    |   27980    |   27734    |
|       from small pool |     327    |     340    |   14991    |   14664    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     229    |     241    |     561    |     332    |
|       from large pool |     196    |     208    |     519    |     323    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     106    |     180    |   16910    |   16804    |
|       from large pool |     100    |     175    |   13553    |   13453    |
|       from small pool |       6    |       8    |    3357    |    3351    |
|===========================================================================|

2022-03-21 20:09:28 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:28 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.99 GiB already allocated; 80.44 MiB free; 7.18 GiB reserved in total by PyTorch)
2022-03-21 20:09:28 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 81           |        cudaMalloc retries: 88        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7125 MB |    7335 MB |  757716 MB |  750591 MB |
|       from large pool |    7059 MB |    7270 MB |  757064 MB |  750004 MB |
|       from small pool |      65 MB |      76 MB |     652 MB |     586 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7125 MB |    7335 MB |  757716 MB |  750591 MB |
|       from large pool |    7059 MB |    7270 MB |  757064 MB |  750004 MB |
|       from small pool |      65 MB |      76 MB |     652 MB |     586 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7350 MB |    7426 MB |   18946 MB |   11596 MB |
|       from large pool |    7284 MB |    7360 MB |   18862 MB |   11578 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  197204 KB |    1773 MB |  237049 MB |  236857 MB |
|       from large pool |  196972 KB |    1772 MB |  236077 MB |  235885 MB |
|       from small pool |     232 KB |       3 MB |     971 MB |     971 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   43424    |   42852    |
|       from large pool |     245    |     248    |   28331    |   28086    |
|       from small pool |     327    |     340    |   15093    |   14766    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   43424    |   42852    |
|       from large pool |     245    |     248    |   28331    |   28086    |
|       from small pool |     327    |     340    |   15093    |   14766    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     228    |     241    |     561    |     333    |
|       from large pool |     195    |     208    |     519    |     324    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      23    |     180    |   17001    |   16978    |
|       from large pool |      18    |     175    |   13602    |   13584    |
|       from small pool |       5    |       8    |    3399    |    3394    |
|===========================================================================|

2022-03-21 20:09:28 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:29 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.98 GiB already allocated; 112.44 MiB free; 7.15 GiB reserved in total by PyTorch)
2022-03-21 20:09:29 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 82           |        cudaMalloc retries: 89        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7112 MB |    7335 MB |  767666 MB |  760554 MB |
|       from large pool |    7046 MB |    7270 MB |  767006 MB |  759959 MB |
|       from small pool |      65 MB |      76 MB |     660 MB |     595 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7112 MB |    7335 MB |  767666 MB |  760554 MB |
|       from large pool |    7046 MB |    7270 MB |  767006 MB |  759959 MB |
|       from small pool |      65 MB |      76 MB |     660 MB |     595 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7318 MB |    7426 MB |   18946 MB |   11628 MB |
|       from large pool |    7252 MB |    7360 MB |   18862 MB |   11610 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  178110 KB |    1773 MB |  238451 MB |  238277 MB |
|       from large pool |  177814 KB |    1772 MB |  237466 MB |  237293 MB |
|       from small pool |     296 KB |       3 MB |     984 MB |     983 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   43877    |   43305    |
|       from large pool |     245    |     248    |   28682    |   28437    |
|       from small pool |     327    |     340    |   15195    |   14868    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   43877    |   43305    |
|       from large pool |     245    |     248    |   28682    |   28437    |
|       from small pool |     327    |     340    |   15195    |   14868    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     227    |     241    |     561    |     334    |
|       from large pool |     194    |     208    |     519    |     325    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      18    |     180    |   17092    |   17074    |
|       from large pool |      13    |     175    |   13653    |   13640    |
|       from small pool |       5    |       8    |    3439    |    3434    |
|===========================================================================|

2022-03-21 20:09:29 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:30 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.31 GiB already allocated; 144.44 MiB free; 7.12 GiB reserved in total by PyTorch)
2022-03-21 20:09:30 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 83           |        cudaMalloc retries: 90        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6426 MB |    7335 MB |  776682 MB |  770255 MB |
|       from large pool |    6362 MB |    7270 MB |  776014 MB |  769652 MB |
|       from small pool |      64 MB |      76 MB |     667 MB |     603 MB |
|---------------------------------------------------------------------------|
| Active memory         |    6426 MB |    7335 MB |  776682 MB |  770255 MB |
|       from large pool |    6362 MB |    7270 MB |  776014 MB |  769652 MB |
|       from small pool |      64 MB |      76 MB |     667 MB |     603 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7286 MB |    7426 MB |   18946 MB |   11660 MB |
|       from large pool |    7220 MB |    7360 MB |   18862 MB |   11642 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     827 MB |    1773 MB |  241118 MB |  240291 MB |
|       from large pool |     825 MB |    1772 MB |  240122 MB |  239297 MB |
|       from small pool |       1 MB |       3 MB |     995 MB |     994 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   44339    |   43766    |
|       from large pool |     246    |     248    |   29041    |   28795    |
|       from small pool |     327    |     340    |   15298    |   14971    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   44339    |   43766    |
|       from large pool |     246    |     248    |   29041    |   28795    |
|       from small pool |     327    |     340    |   15298    |   14971    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     241    |     561    |     335    |
|       from large pool |     193    |     208    |     519    |     326    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      98    |     180    |   17309    |   17211    |
|       from large pool |      92    |     175    |   13828    |   13736    |
|       from small pool |       6    |       8    |    3481    |    3475    |
|===========================================================================|

2022-03-21 20:09:30 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:31 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 7.04 GiB already allocated; 112.44 MiB free; 7.15 GiB reserved in total by PyTorch)
2022-03-21 20:09:31 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 84           |        cudaMalloc retries: 91        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7181 MB |    7335 MB |     768 GB |  779538 MB |
|       from large pool |    7116 MB |    7270 MB |     767 GB |  778927 MB |
|       from small pool |      64 MB |      76 MB |       0 GB |     610 MB |
|---------------------------------------------------------------------------|
| Active memory         |    7181 MB |    7335 MB |     768 GB |  779538 MB |
|       from large pool |    7116 MB |    7270 MB |     767 GB |  778927 MB |
|       from small pool |      64 MB |      76 MB |       0 GB |     610 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7318 MB |    7426 MB |   19010 MB |   11692 MB |
|       from large pool |    7252 MB |    7360 MB |   18926 MB |   11674 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  107490 KB |    1773 MB |  242773 MB |  242668 MB |
|       from large pool |  106283 KB |    1772 MB |  241766 MB |  241662 MB |
|       from small pool |    1206 KB |       3 MB |    1006 MB |    1005 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   44792    |   44220    |
|       from large pool |     246    |     248    |   29393    |   29147    |
|       from small pool |     326    |     340    |   15399    |   15073    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   44792    |   44220    |
|       from large pool |     246    |     248    |   29393    |   29147    |
|       from small pool |     326    |     340    |   15399    |   15073    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     227    |     241    |     563    |     336    |
|       from large pool |     194    |     208    |     521    |     327    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      30    |     180    |   17398    |   17368    |
|       from large pool |      24    |     175    |   13877    |   13853    |
|       from small pool |       6    |       8    |    3521    |    3515    |
|===========================================================================|

2022-03-21 20:09:31 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:32 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 794.00 MiB (GPU 0; 7.93 GiB total capacity; 6.20 GiB already allocated; 630.44 MiB free; 6.64 GiB reserved in total by PyTorch)
2022-03-21 20:09:32 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 85           |        cudaMalloc retries: 92        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6346 MB |    7335 MB |     776 GB |     770 GB |
|       from large pool |    6282 MB |    7270 MB |     776 GB |     769 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6346 MB |    7335 MB |     776 GB |     770 GB |
|       from large pool |    6282 MB |    7270 MB |     776 GB |     769 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6800 MB |    7426 MB |   19010 MB |   12210 MB |
|       from large pool |    6734 MB |    7360 MB |   18926 MB |   12192 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  464756 KB |    1773 MB |  245251 MB |  244797 MB |
|       from large pool |  462751 KB |    1772 MB |  244232 MB |  243780 MB |
|       from small pool |    2005 KB |       3 MB |    1019 MB |    1017 MB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     575    |   45246    |   44675    |
|       from large pool |     246    |     248    |   29746    |   29500    |
|       from small pool |     325    |     340    |   15500    |   15175    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     575    |   45246    |   44675    |
|       from large pool |     246    |     248    |   29746    |   29500    |
|       from small pool |     325    |     340    |   15500    |   15175    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     241    |     563    |     352    |
|       from large pool |     178    |     208    |     521    |     343    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     146    |     180    |   17702    |   17556    |
|       from large pool |     140    |     175    |   14139    |   13999    |
|       from small pool |       6    |       8    |    3563    |    3557    |
|===========================================================================|

2022-03-21 20:09:32 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:32 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 826.00 MiB (GPU 0; 7.93 GiB total capacity; 6.29 GiB already allocated; 630.44 MiB free; 6.64 GiB reserved in total by PyTorch)
2022-03-21 20:09:32 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 86           |        cudaMalloc retries: 93        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6445 MB |    7335 MB |     785 GB |     779 GB |
|       from large pool |    6379 MB |    7270 MB |     784 GB |     778 GB |
|       from small pool |      65 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6445 MB |    7335 MB |     785 GB |     779 GB |
|       from large pool |    6379 MB |    7270 MB |     784 GB |     778 GB |
|       from small pool |      65 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6800 MB |    7426 MB |   19010 MB |   12210 MB |
|       from large pool |    6734 MB |    7360 MB |   18926 MB |   12192 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  363366 KB |    1773 MB |  247481 MB |  247126 MB |
|       from large pool |  362553 KB |    1772 MB |  246448 MB |  246094 MB |
|       from small pool |     813 KB |       3 MB |    1032 MB |    1032 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   45709    |   45137    |
|       from large pool |     245    |     248    |   30105    |   29860    |
|       from small pool |     327    |     340    |   15604    |   15277    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   45709    |   45137    |
|       from large pool |     245    |     248    |   30105    |   29860    |
|       from small pool |     327    |     340    |   15604    |   15277    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     241    |     563    |     352    |
|       from large pool |     178    |     208    |     521    |     343    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      64    |     180    |   17872    |   17808    |
|       from large pool |      59    |     175    |   14267    |   14208    |
|       from small pool |       5    |       8    |    3605    |    3600    |
|===========================================================================|

2022-03-21 20:09:32 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:33 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.80 GiB already allocated; 138.44 MiB free; 7.12 GiB reserved in total by PyTorch)
2022-03-21 20:09:33 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 87           |        cudaMalloc retries: 94        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6934 MB |    7335 MB |     794 GB |     788 GB |
|       from large pool |    6869 MB |    7270 MB |     794 GB |     787 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6934 MB |    7335 MB |     794 GB |     788 GB |
|       from large pool |    6869 MB |    7270 MB |     794 GB |     787 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7292 MB |    7426 MB |   19502 MB |   12210 MB |
|       from large pool |    7226 MB |    7360 MB |   19418 MB |   12192 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  333671 KB |    1773 MB |  250077 MB |  249751 MB |
|       from large pool |  332237 KB |    1772 MB |  249033 MB |  248708 MB |
|       from small pool |    1433 KB |       3 MB |    1044 MB |    1042 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   46162    |   45590    |
|       from large pool |     246    |     248    |   30457    |   30211    |
|       from small pool |     326    |     340    |   15705    |   15379    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   46162    |   45590    |
|       from large pool |     246    |     248    |   30457    |   30211    |
|       from small pool |     326    |     340    |   15705    |   15379    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     241    |     578    |     352    |
|       from large pool |     193    |     208    |     536    |     343    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     105    |     180    |   18105    |   18000    |
|       from large pool |      99    |     175    |   14448    |   14349    |
|       from small pool |       6    |       8    |    3657    |    3651    |
|===========================================================================|

2022-03-21 20:09:33 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:33 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 410.00 MiB (GPU 0; 7.93 GiB total capacity; 6.43 GiB already allocated; 170.44 MiB free; 7.09 GiB reserved in total by PyTorch)
2022-03-21 20:09:33 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 88           |        cudaMalloc retries: 95        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6557 MB |    7335 MB |     803 GB |     797 GB |
|       from large pool |    6492 MB |    7270 MB |     803 GB |     796 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6557 MB |    7335 MB |     803 GB |     797 GB |
|       from large pool |    6492 MB |    7270 MB |     803 GB |     796 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7260 MB |    7426 MB |   19502 MB |   12242 MB |
|       from large pool |    7194 MB |    7360 MB |   19418 MB |   12224 MB |
|       from small pool |      66 MB |      78 MB |      84 MB |      18 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  686813 KB |    1773 MB |  253274 MB |  252604 MB |
|       from large pool |  685083 KB |    1772 MB |  252219 MB |  251550 MB |
|       from small pool |    1730 KB |       3 MB |    1055 MB |    1053 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   46624    |   46051    |
|       from large pool |     246    |     248    |   30816    |   30570    |
|       from small pool |     327    |     340    |   15808    |   15481    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   46624    |   46051    |
|       from large pool |     246    |     248    |   30816    |   30570    |
|       from small pool |     327    |     340    |   15808    |   15481    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     241    |     578    |     353    |
|       from large pool |     192    |     208    |     536    |     344    |
|       from small pool |      33    |      39    |      42    |       9    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     110    |     180    |   18340    |   18230    |
|       from large pool |     103    |     175    |   14635    |   14532    |
|       from small pool |       7    |       8    |    3705    |    3698    |
|===========================================================================|

2022-03-21 20:09:33 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:34 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.42 GiB already allocated; 12.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:34 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 89           |        cudaMalloc retries: 96        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6571 MB |    7335 MB |     812 GB |     806 GB |
|       from large pool |    6507 MB |    7270 MB |     812 GB |     805 GB |
|       from small pool |      63 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6571 MB |    7335 MB |     812 GB |     806 GB |
|       from large pool |    6507 MB |    7270 MB |     812 GB |     805 GB |
|       from small pool |      63 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7418 MB |    7426 MB |   19694 MB |   12276 MB |
|       from large pool |    7354 MB |    7360 MB |   19610 MB |   12256 MB |
|       from small pool |      64 MB |      78 MB |      84 MB |      20 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     846 MB |    1773 MB |  256376 MB |  255529 MB |
|       from large pool |     846 MB |    1772 MB |  255312 MB |  254465 MB |
|       from small pool |       0 MB |       3 MB |    1063 MB |    1063 MB |
|---------------------------------------------------------------------------|
| Allocations           |     550    |     575    |   47052    |   46502    |
|       from large pool |     229    |     248    |   31147    |   30918    |
|       from small pool |     321    |     340    |   15905    |   15584    |
|---------------------------------------------------------------------------|
| Active allocs         |     550    |     575    |   47052    |   46502    |
|       from large pool |     229    |     248    |   31147    |   30918    |
|       from small pool |     321    |     340    |   15905    |   15584    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     229    |     241    |     584    |     355    |
|       from large pool |     197    |     208    |     542    |     345    |
|       from small pool |      32    |      39    |      42    |      10    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     129    |     180    |   18585    |   18456    |
|       from large pool |     124    |     175    |   14833    |   14709    |
|       from small pool |       5    |       8    |    3752    |    3747    |
|===========================================================================|

2022-03-21 20:09:34 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:35 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.76 GiB already allocated; 10.44 MiB free; 7.25 GiB reserved in total by PyTorch)
2022-03-21 20:09:35 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 90           |        cudaMalloc retries: 97        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6920 MB |    7335 MB |     822 GB |     815 GB |
|       from large pool |    6855 MB |    7270 MB |     821 GB |     814 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6920 MB |    7335 MB |     822 GB |     815 GB |
|       from large pool |    6855 MB |    7270 MB |     821 GB |     814 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7420 MB |    7426 MB |   19696 MB |   12276 MB |
|       from large pool |    7354 MB |    7360 MB |   19610 MB |   12256 MB |
|       from small pool |      66 MB |      78 MB |      86 MB |      20 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  511873 KB |    1773 MB |  258884 MB |  258384 MB |
|       from large pool |  510190 KB |    1772 MB |  257809 MB |  257311 MB |
|       from small pool |    1683 KB |       3 MB |    1074 MB |    1072 MB |
|---------------------------------------------------------------------------|
| Allocations           |     560    |     575    |   47485    |   46925    |
|       from large pool |     238    |     248    |   31483    |   31245    |
|       from small pool |     322    |     340    |   16002    |   15680    |
|---------------------------------------------------------------------------|
| Active allocs         |     560    |     575    |   47485    |   46925    |
|       from large pool |     238    |     248    |   31483    |   31245    |
|       from small pool |     322    |     340    |   16002    |   15680    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     230    |     241    |     585    |     355    |
|       from large pool |     197    |     208    |     542    |     345    |
|       from small pool |      33    |      39    |      43    |      10    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     127    |     180    |   18807    |   18680    |
|       from large pool |     121    |     175    |   15016    |   14895    |
|       from small pool |       6    |       8    |    3791    |    3785    |
|===========================================================================|

2022-03-21 20:09:35 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:35 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.78 GiB already allocated; 10.44 MiB free; 7.25 GiB reserved in total by PyTorch)
2022-03-21 20:09:35 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 91           |        cudaMalloc retries: 98        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6943 MB |    7335 MB |     831 GB |     824 GB |
|       from large pool |    6878 MB |    7270 MB |     830 GB |     823 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6943 MB |    7335 MB |     831 GB |     824 GB |
|       from large pool |    6878 MB |    7270 MB |     830 GB |     823 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7420 MB |    7426 MB |   19696 MB |   12276 MB |
|       from large pool |    7354 MB |    7360 MB |   19610 MB |   12256 MB |
|       from small pool |      66 MB |      78 MB |      86 MB |      20 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  488427 KB |    1773 MB |  261350 MB |  260873 MB |
|       from large pool |  486792 KB |    1772 MB |  260265 MB |  259790 MB |
|       from small pool |    1634 KB |       3 MB |    1084 MB |    1083 MB |
|---------------------------------------------------------------------------|
| Allocations           |     560    |     575    |   47918    |   47358    |
|       from large pool |     238    |     248    |   31819    |   31581    |
|       from small pool |     322    |     340    |   16099    |   15777    |
|---------------------------------------------------------------------------|
| Active allocs         |     560    |     575    |   47918    |   47358    |
|       from large pool |     238    |     248    |   31819    |   31581    |
|       from small pool |     322    |     340    |   16099    |   15777    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     230    |     241    |     585    |     355    |
|       from large pool |     197    |     208    |     542    |     345    |
|       from small pool |      33    |      39    |      43    |      10    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     122    |     180    |   19022    |   18900    |
|       from large pool |     116    |     175    |   15193    |   15077    |
|       from small pool |       6    |       8    |    3829    |    3823    |
|===========================================================================|

2022-03-21 20:09:35 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:36 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 412.00 MiB (GPU 0; 7.93 GiB total capacity; 6.50 GiB already allocated; 10.44 MiB free; 7.25 GiB reserved in total by PyTorch)
2022-03-21 20:09:36 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 92           |        cudaMalloc retries: 99        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6626 MB |    7335 MB |     840 GB |     833 GB |
|       from large pool |    6562 MB |    7270 MB |     839 GB |     833 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6626 MB |    7335 MB |     840 GB |     833 GB |
|       from large pool |    6562 MB |    7270 MB |     839 GB |     833 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7420 MB |    7426 MB |   19696 MB |   12276 MB |
|       from large pool |    7354 MB |    7360 MB |   19610 MB |   12256 MB |
|       from small pool |      66 MB |      78 MB |      86 MB |      20 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  779707 KB |    1773 MB |  264401 MB |  263640 MB |
|       from large pool |  778027 KB |    1772 MB |  263306 MB |  262546 MB |
|       from small pool |    1680 KB |       3 MB |    1095 MB |    1093 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   48380    |   47807    |
|       from large pool |     246    |     248    |   32178    |   31932    |
|       from small pool |     327    |     340    |   16202    |   15875    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   48380    |   47807    |
|       from large pool |     246    |     248    |   32178    |   31932    |
|       from small pool |     327    |     340    |   16202    |   15875    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     230    |     241    |     585    |     355    |
|       from large pool |     197    |     208    |     542    |     345    |
|       from small pool |      33    |      39    |      43    |      10    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     115    |     180    |   19240    |   19125    |
|       from large pool |     109    |     175    |   15371    |   15262    |
|       from small pool |       6    |       8    |    3869    |    3863    |
|===========================================================================|

2022-03-21 20:09:36 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:37 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.47 GiB already allocated; 42.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:09:37 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 93           |        cudaMalloc retries: 100       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6597 MB |    7335 MB |     849 GB |     843 GB |
|       from large pool |    6533 MB |    7270 MB |     848 GB |     842 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6597 MB |    7335 MB |     849 GB |     843 GB |
|       from large pool |    6533 MB |    7270 MB |     848 GB |     842 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7388 MB |    7426 MB |   19696 MB |   12308 MB |
|       from large pool |    7322 MB |    7360 MB |   19610 MB |   12288 MB |
|       from small pool |      66 MB |      78 MB |      86 MB |      20 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  776254 KB |    1773 MB |  267660 MB |  266902 MB |
|       from large pool |  774531 KB |    1772 MB |  266554 MB |  265797 MB |
|       from small pool |    1722 KB |       3 MB |    1105 MB |    1104 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   48842    |   48269    |
|       from large pool |     246    |     248    |   32537    |   32291    |
|       from small pool |     327    |     340    |   16305    |   15978    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   48842    |   48269    |
|       from large pool |     246    |     248    |   32537    |   32291    |
|       from small pool |     327    |     340    |   16305    |   15978    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     229    |     241    |     585    |     356    |
|       from large pool |     196    |     208    |     542    |     346    |
|       from small pool |      33    |      39    |      43    |      10    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     105    |     180    |   19455    |   19350    |
|       from large pool |      99    |     175    |   15545    |   15446    |
|       from small pool |       6    |       8    |    3910    |    3904    |
|===========================================================================|

2022-03-21 20:09:37 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:38 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 6.19 GiB already allocated; 634.44 MiB free; 6.64 GiB reserved in total by PyTorch)
2022-03-21 20:09:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 94           |        cudaMalloc retries: 101       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6338 MB |    7335 MB |     857 GB |     851 GB |
|       from large pool |    6273 MB |    7270 MB |     857 GB |     851 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6338 MB |    7335 MB |     857 GB |     851 GB |
|       from large pool |    6273 MB |    7270 MB |     857 GB |     851 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6796 MB |    7426 MB |   19696 MB |   12900 MB |
|       from large pool |    6730 MB |    7360 MB |   19610 MB |   12880 MB |
|       from small pool |      66 MB |      78 MB |      86 MB |      20 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  468691 KB |    1773 MB |  270051 MB |  269593 MB |
|       from large pool |  467334 KB |    1772 MB |  268929 MB |  268472 MB |
|       from small pool |    1356 KB |       3 MB |    1121 MB |    1120 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   49305    |   48733    |
|       from large pool |     245    |     248    |   32896    |   32651    |
|       from small pool |     327    |     340    |   16409    |   16082    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   49305    |   48733    |
|       from large pool |     245    |     248    |   32896    |   32651    |
|       from small pool |     327    |     340    |   16409    |   16082    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     241    |     585    |     374    |
|       from large pool |     178    |     208    |     542    |     364    |
|       from small pool |      33    |      39    |      43    |      10    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      48    |     180    |   19638    |   19590    |
|       from large pool |      43    |     175    |   15683    |   15640    |
|       from small pool |       5    |       8    |    3955    |    3950    |
|===========================================================================|

2022-03-21 20:09:38 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:38 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.88 GiB already allocated; 166.44 MiB free; 7.09 GiB reserved in total by PyTorch)
2022-03-21 20:09:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 95           |        cudaMalloc retries: 102       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7016 MB |    7335 MB |     867 GB |     860 GB |
|       from large pool |    6951 MB |    7270 MB |     866 GB |     860 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7016 MB |    7335 MB |     867 GB |     860 GB |
|       from large pool |    6951 MB |    7270 MB |     866 GB |     860 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7264 MB |    7426 MB |   20164 MB |   12900 MB |
|       from large pool |    7198 MB |    7360 MB |   20078 MB |   12880 MB |
|       from small pool |      66 MB |      78 MB |      86 MB |      20 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  220625 KB |    1773 MB |  271934 MB |  271718 MB |
|       from large pool |  219332 KB |    1772 MB |  270801 MB |  270586 MB |
|       from small pool |    1292 KB |       3 MB |    1133 MB |    1131 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   49758    |   49186    |
|       from large pool |     246    |     248    |   33248    |   33002    |
|       from small pool |     326    |     340    |   16510    |   16184    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   49758    |   49186    |
|       from large pool |     246    |     248    |   33248    |   33002    |
|       from small pool |     326    |     340    |   16510    |   16184    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     241    |     599    |     374    |
|       from large pool |     192    |     208    |     556    |     364    |
|       from small pool |      33    |      39    |      43    |      10    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     104    |     180    |   19861    |   19757    |
|       from large pool |      97    |     175    |   15866    |   15769    |
|       from small pool |       7    |       8    |    3995    |    3988    |
|===========================================================================|

2022-03-21 20:09:38 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:39 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 830.00 MiB (GPU 0; 7.93 GiB total capacity; 6.28 GiB already allocated; 634.44 MiB free; 6.64 GiB reserved in total by PyTorch)
2022-03-21 20:09:39 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 96           |        cudaMalloc retries: 103       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6427 MB |    7335 MB |     876 GB |     869 GB |
|       from large pool |    6362 MB |    7270 MB |     875 GB |     869 GB |
|       from small pool |      65 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6427 MB |    7335 MB |     876 GB |     869 GB |
|       from large pool |    6362 MB |    7270 MB |     875 GB |     869 GB |
|       from small pool |      65 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6796 MB |    7426 MB |   20164 MB |   13368 MB |
|       from large pool |    6730 MB |    7360 MB |   20078 MB |   13348 MB |
|       from small pool |      66 MB |      78 MB |      86 MB |      20 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  377552 KB |    1773 MB |  274208 MB |  273839 MB |
|       from large pool |  376620 KB |    1772 MB |  273060 MB |  272693 MB |
|       from small pool |     932 KB |       3 MB |    1147 MB |    1146 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   50221    |   49649    |
|       from large pool |     245    |     248    |   33607    |   33362    |
|       from small pool |     327    |     340    |   16614    |   16287    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   50221    |   49649    |
|       from large pool |     245    |     248    |   33607    |   33362    |
|       from small pool |     327    |     340    |   16614    |   16287    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     241    |     599    |     388    |
|       from large pool |     178    |     208    |     556    |     378    |
|       from small pool |      33    |      39    |      43    |      10    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      57    |     180    |   20036    |   19979    |
|       from large pool |      52    |     175    |   15997    |   15945    |
|       from small pool |       5    |       8    |    4039    |    4034    |
|===========================================================================|

2022-03-21 20:09:39 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:40 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.47 GiB already allocated; 22.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:09:40 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 97           |        cudaMalloc retries: 105       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6627 MB |    7335 MB |     885 GB |     878 GB |
|       from large pool |    6563 MB |    7270 MB |     884 GB |     877 GB |
|       from small pool |      63 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6627 MB |    7335 MB |     885 GB |     878 GB |
|       from large pool |    6563 MB |    7270 MB |     884 GB |     877 GB |
|       from small pool |      63 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7408 MB |    7426 MB |   20874 MB |   13466 MB |
|       from large pool |    7344 MB |    7360 MB |   20788 MB |   13444 MB |
|       from small pool |      64 MB |      78 MB |      86 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     780 MB |    1773 MB |  276523 MB |  275743 MB |
|       from large pool |     780 MB |    1772 MB |  275367 MB |  274587 MB |
|       from small pool |       0 MB |       3 MB |    1156 MB |    1156 MB |
|---------------------------------------------------------------------------|
| Allocations           |     530    |     575    |   50621    |   50091    |
|       from large pool |     213    |     248    |   33914    |   33701    |
|       from small pool |     317    |     340    |   16707    |   16390    |
|---------------------------------------------------------------------------|
| Active allocs         |     530    |     575    |   50621    |   50091    |
|       from large pool |     213    |     248    |   33914    |   33701    |
|       from small pool |     317    |     340    |   16707    |   16390    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     224    |     241    |     618    |     394    |
|       from large pool |     192    |     208    |     575    |     383    |
|       from small pool |      32    |      39    |      43    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     114    |     180    |   20268    |   20154    |
|       from large pool |     108    |     175    |   16188    |   16080    |
|       from small pool |       6    |       8    |    4080    |    4074    |
|===========================================================================|

2022-03-21 20:09:40 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:40 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 7.93 GiB total capacity; 6.54 GiB already allocated; 20.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:40 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 98           |        cudaMalloc retries: 106       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6698 MB |    7335 MB |     894 GB |     887 GB |
|       from large pool |    6634 MB |    7270 MB |     893 GB |     886 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6698 MB |    7335 MB |     894 GB |     887 GB |
|       from large pool |    6634 MB |    7270 MB |     893 GB |     886 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7410 MB |    7426 MB |   20876 MB |   13466 MB |
|       from large pool |    7344 MB |    7360 MB |   20788 MB |   13444 MB |
|       from small pool |      66 MB |      78 MB |      88 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  728411 KB |    1773 MB |  279434 MB |  278722 MB |
|       from large pool |  726675 KB |    1772 MB |  278269 MB |  277559 MB |
|       from small pool |    1735 KB |       3 MB |    1164 MB |    1163 MB |
|---------------------------------------------------------------------------|
| Allocations           |     567    |     575    |   51072    |   50505    |
|       from large pool |     242    |     248    |   34264    |   34022    |
|       from small pool |     325    |     340    |   16808    |   16483    |
|---------------------------------------------------------------------------|
| Active allocs         |     567    |     575    |   51072    |   50505    |
|       from large pool |     242    |     248    |   34264    |   34022    |
|       from small pool |     325    |     340    |   16808    |   16483    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     241    |     619    |     394    |
|       from large pool |     192    |     208    |     575    |     383    |
|       from small pool |      33    |      39    |      44    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     115    |     180    |   20477    |   20362    |
|       from large pool |     109    |     175    |   16367    |   16258    |
|       from small pool |       6    |       8    |    4110    |    4104    |
|===========================================================================|

2022-03-21 20:09:40 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:41 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 398.00 MiB (GPU 0; 7.93 GiB total capacity; 6.93 GiB already allocated; 20.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:41 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 99           |        cudaMalloc retries: 107       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7061 MB |    7335 MB |     903 GB |     896 GB |
|       from large pool |    6996 MB |    7270 MB |     903 GB |     896 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7061 MB |    7335 MB |     903 GB |     896 GB |
|       from large pool |    6996 MB |    7270 MB |     903 GB |     896 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7410 MB |    7426 MB |   20876 MB |   13466 MB |
|       from large pool |    7344 MB |    7360 MB |   20788 MB |   13444 MB |
|       from small pool |      66 MB |      78 MB |      88 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  357223 KB |    1773 MB |  281812 MB |  281463 MB |
|       from large pool |  355914 KB |    1772 MB |  280638 MB |  280290 MB |
|       from small pool |    1308 KB |       3 MB |    1173 MB |    1172 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   51525    |   50953    |
|       from large pool |     246    |     248    |   34616    |   34370    |
|       from small pool |     326    |     340    |   16909    |   16583    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   51525    |   50953    |
|       from large pool |     246    |     248    |   34616    |   34370    |
|       from small pool |     326    |     340    |   16909    |   16583    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     241    |     619    |     394    |
|       from large pool |     192    |     208    |     575    |     383    |
|       from small pool |      33    |      39    |      44    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     101    |     180    |   20690    |   20589    |
|       from large pool |      95    |     175    |   16543    |   16448    |
|       from small pool |       6    |       8    |    4147    |    4141    |
|===========================================================================|

2022-03-21 20:09:41 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:41 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.31 GiB already allocated; 20.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:41 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 100          |        cudaMalloc retries: 108       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6431 MB |    7335 MB |     912 GB |     906 GB |
|       from large pool |    6367 MB |    7270 MB |     911 GB |     905 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6431 MB |    7335 MB |     912 GB |     906 GB |
|       from large pool |    6367 MB |    7270 MB |     911 GB |     905 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7410 MB |    7426 MB |   20876 MB |   13466 MB |
|       from large pool |    7344 MB |    7360 MB |   20788 MB |   13444 MB |
|       from small pool |      66 MB |      78 MB |      88 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     946 MB |    1773 MB |  285076 MB |  284129 MB |
|       from large pool |     944 MB |    1772 MB |  283893 MB |  282948 MB |
|       from small pool |       1 MB |       3 MB |    1182 MB |    1181 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   51987    |   51414    |
|       from large pool |     246    |     248    |   34975    |   34729    |
|       from small pool |     327    |     340    |   17012    |   16685    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   51987    |   51414    |
|       from large pool |     246    |     248    |   34975    |   34729    |
|       from small pool |     327    |     340    |   17012    |   16685    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     241    |     619    |     394    |
|       from large pool |     192    |     208    |     575    |     383    |
|       from small pool |      33    |      39    |      44    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     101    |     180    |   20901    |   20800    |
|       from large pool |      95    |     175    |   16717    |   16622    |
|       from small pool |       6    |       8    |    4184    |    4178    |
|===========================================================================|

2022-03-21 20:09:41 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:42 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.87 GiB already allocated; 52.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:09:42 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 101          |        cudaMalloc retries: 109       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7006 MB |    7335 MB |     922 GB |     915 GB |
|       from large pool |    6941 MB |    7270 MB |     921 GB |     914 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7006 MB |    7335 MB |     922 GB |     915 GB |
|       from large pool |    6941 MB |    7270 MB |     921 GB |     914 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7378 MB |    7426 MB |   20876 MB |   13498 MB |
|       from large pool |    7312 MB |    7360 MB |   20788 MB |   13476 MB |
|       from small pool |      66 MB |      78 MB |      88 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  347649 KB |    1773 MB |  287294 MB |  286954 MB |
|       from large pool |  346304 KB |    1772 MB |  286102 MB |  285764 MB |
|       from small pool |    1345 KB |       3 MB |    1191 MB |    1190 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   52440    |   51868    |
|       from large pool |     246    |     248    |   35327    |   35081    |
|       from small pool |     326    |     340    |   17113    |   16787    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   52440    |   51868    |
|       from large pool |     246    |     248    |   35327    |   35081    |
|       from small pool |     326    |     340    |   17113    |   16787    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     224    |     241    |     619    |     395    |
|       from large pool |     191    |     208    |     575    |     384    |
|       from small pool |      33    |      39    |      44    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     111    |     180    |   21102    |   20991    |
|       from large pool |     104    |     175    |   16883    |   16779    |
|       from small pool |       7    |       8    |    4219    |    4212    |
|===========================================================================|

2022-03-21 20:09:42 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:43 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.34 GiB already allocated; 84.44 MiB free; 7.17 GiB reserved in total by PyTorch)
2022-03-21 20:09:43 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 102          |        cudaMalloc retries: 110       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6459 MB |    7335 MB |     931 GB |     924 GB |
|       from large pool |    6395 MB |    7270 MB |     930 GB |     924 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6459 MB |    7335 MB |     931 GB |     924 GB |
|       from large pool |    6395 MB |    7270 MB |     930 GB |     924 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7346 MB |    7426 MB |   20876 MB |   13530 MB |
|       from large pool |    7280 MB |    7360 MB |   20788 MB |   13508 MB |
|       from small pool |      66 MB |      78 MB |      88 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     854 MB |    1773 MB |  290272 MB |  289417 MB |
|       from large pool |     852 MB |    1772 MB |  289071 MB |  288218 MB |
|       from small pool |       1 MB |       3 MB |    1200 MB |    1199 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   52902    |   52329    |
|       from large pool |     246    |     248    |   35686    |   35440    |
|       from small pool |     327    |     340    |   17216    |   16889    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   52902    |   52329    |
|       from large pool |     246    |     248    |   35686    |   35440    |
|       from small pool |     327    |     340    |   17216    |   16889    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     223    |     241    |     619    |     396    |
|       from large pool |     190    |     208    |     575    |     385    |
|       from small pool |      33    |      39    |      44    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     101    |     180    |   21316    |   21215    |
|       from large pool |      94    |     175    |   17061    |   16967    |
|       from small pool |       7    |       8    |    4255    |    4248    |
|===========================================================================|

2022-03-21 20:09:43 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:44 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.50 GiB already allocated; 12.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:44 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 103          |        cudaMalloc retries: 111       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6660 MB |    7335 MB |     940 GB |     933 GB |
|       from large pool |    6596 MB |    7270 MB |     939 GB |     932 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6660 MB |    7335 MB |     940 GB |     933 GB |
|       from large pool |    6596 MB |    7270 MB |     939 GB |     932 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7418 MB |    7426 MB |   20980 MB |   13562 MB |
|       from large pool |    7352 MB |    7360 MB |   20892 MB |   13540 MB |
|       from small pool |      66 MB |      78 MB |      88 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  775290 KB |    1773 MB |  293379 MB |  292622 MB |
|       from large pool |  773437 KB |    1772 MB |  292170 MB |  291415 MB |
|       from small pool |    1853 KB |       3 MB |    1209 MB |    1207 MB |
|---------------------------------------------------------------------------|
| Allocations           |     561    |     575    |   53344    |   52783    |
|       from large pool |     238    |     248    |   36029    |   35791    |
|       from small pool |     323    |     340    |   17315    |   16992    |
|---------------------------------------------------------------------------|
| Active allocs         |     561    |     575    |   53344    |   52783    |
|       from large pool |     238    |     248    |   36029    |   35791    |
|       from small pool |     323    |     340    |   17315    |   16992    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     241    |     623    |     397    |
|       from large pool |     193    |     208    |     579    |     386    |
|       from small pool |      33    |      39    |      44    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     121    |     180    |   21546    |   21425    |
|       from large pool |     115    |     175    |   17257    |   17142    |
|       from small pool |       6    |       8    |    4289    |    4283    |
|===========================================================================|

2022-03-21 20:09:44 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:44 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 7.03 GiB already allocated; 12.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:44 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 104          |        cudaMalloc retries: 112       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7163 MB |    7335 MB |     949 GB |     942 GB |
|       from large pool |    7098 MB |    7270 MB |     949 GB |     942 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7163 MB |    7335 MB |     949 GB |     942 GB |
|       from large pool |    7098 MB |    7270 MB |     949 GB |     942 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7418 MB |    7426 MB |   20980 MB |   13562 MB |
|       from large pool |    7352 MB |    7360 MB |   20892 MB |   13540 MB |
|       from small pool |      66 MB |      78 MB |      88 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  228162 KB |    1773 MB |  295268 MB |  295045 MB |
|       from large pool |  226972 KB |    1772 MB |  294049 MB |  293828 MB |
|       from small pool |    1189 KB |       3 MB |    1218 MB |    1217 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     575    |   53797    |   53225    |
|       from large pool |     246    |     248    |   36381    |   36135    |
|       from small pool |     326    |     340    |   17416    |   17090    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     575    |   53797    |   53225    |
|       from large pool |     246    |     248    |   36381    |   36135    |
|       from small pool |     326    |     340    |   17416    |   17090    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     241    |     623    |     397    |
|       from large pool |     193    |     208    |     579    |     386    |
|       from small pool |      33    |      39    |      44    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      22    |     180    |   21640    |   21618    |
|       from large pool |      17    |     175    |   17317    |   17300    |
|       from small pool |       5    |       8    |    4323    |    4318    |
|===========================================================================|

2022-03-21 20:09:44 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:45 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 410.00 MiB (GPU 0; 7.93 GiB total capacity; 6.38 GiB already allocated; 44.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:09:45 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 105          |        cudaMalloc retries: 113       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6500 MB |    7335 MB |     958 GB |     952 GB |
|       from large pool |    6436 MB |    7270 MB |     957 GB |     951 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6500 MB |    7335 MB |     958 GB |     952 GB |
|       from large pool |    6436 MB |    7270 MB |     957 GB |     951 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7386 MB |    7426 MB |   20980 MB |   13594 MB |
|       from large pool |    7320 MB |    7360 MB |   20892 MB |   13572 MB |
|       from small pool |      66 MB |      78 MB |      88 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     853 MB |    1773 MB |  298674 MB |  297821 MB |
|       from large pool |     851 MB |    1772 MB |  297447 MB |  296595 MB |
|       from small pool |       1 MB |       3 MB |    1227 MB |    1225 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     575    |   54259    |   53686    |
|       from large pool |     246    |     248    |   36740    |   36494    |
|       from small pool |     327    |     340    |   17519    |   17192    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     575    |   54259    |   53686    |
|       from large pool |     246    |     248    |   36740    |   36494    |
|       from small pool |     327    |     340    |   17519    |   17192    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     241    |     623    |     398    |
|       from large pool |     192    |     208    |     579    |     387    |
|       from small pool |      33    |      39    |      44    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     103    |     180    |   21871    |   21768    |
|       from large pool |      96    |     175    |   17509    |   17413    |
|       from small pool |       7    |       8    |    4362    |    4355    |
|===========================================================================|

2022-03-21 20:09:45 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:46 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 7.93 GiB total capacity; 6.39 GiB already allocated; 20.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:46 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 106          |        cudaMalloc retries: 114       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6538 MB |    7335 MB |     967 GB |     961 GB |
|       from large pool |    6474 MB |    7270 MB |     966 GB |     960 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6538 MB |    7335 MB |     967 GB |     961 GB |
|       from large pool |    6474 MB |    7270 MB |     966 GB |     960 GB |
|       from small pool |      64 MB |      76 MB |       0 GB |       0 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7410 MB |    7426 MB |   21036 MB |   13626 MB |
|       from large pool |    7344 MB |    7360 MB |   20948 MB |   13604 MB |
|       from small pool |      66 MB |      78 MB |      88 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     871 MB |    1773 MB |  301948 MB |  301076 MB |
|       from large pool |     869 MB |    1772 MB |  300712 MB |  299843 MB |
|       from small pool |       1 MB |       3 MB |    1235 MB |    1233 MB |
|---------------------------------------------------------------------------|
| Allocations           |     557    |     575    |   54696    |   54139    |
|       from large pool |     234    |     248    |   37078    |   36844    |
|       from small pool |     323    |     340    |   17618    |   17295    |
|---------------------------------------------------------------------------|
| Active allocs         |     557    |     575    |   54696    |   54139    |
|       from large pool |     234    |     248    |   37078    |   36844    |
|       from small pool |     323    |     340    |   17618    |   17295    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     241    |     625    |     399    |
|       from large pool |     193    |     208    |     581    |     388    |
|       from small pool |      33    |      39    |      44    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     133    |     180    |   22119    |   21986    |
|       from large pool |     126    |     175    |   17722    |   17596    |
|       from small pool |       7    |       8    |    4397    |    4390    |
|===========================================================================|

2022-03-21 20:09:46 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-21 20:09:49 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.99 GiB already allocated; 196.44 MiB free; 7.06 GiB reserved in total by PyTorch)
2022-03-21 20:09:49 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 107          |        cudaMalloc retries: 116       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7159 MB |    7335 MB |     987 GB |     980 GB |
|       from large pool |    7094 MB |    7270 MB |     986 GB |     979 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7159 MB |    7335 MB |     987 GB |     980 GB |
|       from large pool |    7094 MB |    7270 MB |     986 GB |     979 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7226 MB |    7426 MB |   28314 MB |   21088 MB |
|       from large pool |    7160 MB |    7360 MB |   28168 MB |   21008 MB |
|       from small pool |      66 MB |     122 MB |     146 MB |      80 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   68449 KB |    1773 MB |  313474 MB |  313408 MB |
|       from large pool |   67354 KB |    1772 MB |  311720 MB |  311654 MB |
|       from small pool |    1095 KB |       3 MB |    1754 MB |    1753 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     580    |   70602    |   70029    |
|       from large pool |     246    |     250    |   38333    |   38087    |
|       from small pool |     327    |     500    |   32269    |   31942    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     580    |   70602    |   70029    |
|       from large pool |     246    |     250    |   38333    |   38087    |
|       from small pool |     327    |     500    |   32269    |   31942    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     235    |     264    |     854    |     619    |
|       from large pool |     202    |     208    |     781    |     579    |
|       from small pool |      33    |      61    |      73    |      40    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      29    |     180    |   23110    |   23081    |
|       from large pool |      24    |     175    |   18409    |   18385    |
|       from small pool |       5    |      12    |    4701    |    4696    |
|===========================================================================|

/cluster/home/andriusb/fq/fairseq/fairseq/criterions/kneser_ney_smoothing.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  vals = torch.tensor(kl_stuff[hash("val")], device=torch.device("cuda"), dtype=torch.float16)
2022-03-21 20:09:49 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:49 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 7.93 GiB total capacity; 6.53 GiB already allocated; 8.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:49 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 108          |        cudaMalloc retries: 118       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6658 MB |    7335 MB |     996 GB |     990 GB |
|       from large pool |    6594 MB |    7270 MB |     995 GB |     988 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6658 MB |    7335 MB |     996 GB |     990 GB |
|       from large pool |    6594 MB |    7270 MB |     995 GB |     988 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7414 MB |    7426 MB |   29324 MB |   21910 MB |
|       from large pool |    7348 MB |    7360 MB |   29176 MB |   21828 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  741036 KB |    1773 MB |  316348 MB |  315624 MB |
|       from large pool |  739186 KB |    1772 MB |  314583 MB |  313861 MB |
|       from small pool |    1849 KB |       3 MB |    1765 MB |    1763 MB |
|---------------------------------------------------------------------------|
| Allocations           |     549    |     580    |   71022    |   70473    |
|       from large pool |     229    |     250    |   38658    |   38429    |
|       from small pool |     320    |     500    |   32364    |   32044    |
|---------------------------------------------------------------------------|
| Active allocs         |     549    |     580    |   71022    |   70473    |
|       from large pool |     229    |     250    |   38658    |   38429    |
|       from small pool |     320    |     500    |   32364    |   32044    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     264    |     886    |     661    |
|       from large pool |     192    |     208    |     812    |     620    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     146    |     180    |   23371    |   23225    |
|       from large pool |     140    |     175    |   18627    |   18487    |
|       from small pool |       6    |      12    |    4744    |    4738    |
|===========================================================================|

2022-03-21 20:09:49 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:50 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.82 GiB already allocated; 84.44 MiB free; 7.17 GiB reserved in total by PyTorch)
2022-03-21 20:09:50 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 109          |        cudaMalloc retries: 120       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6954 MB |    7335 MB |    1006 GB |     999 GB |
|       from large pool |    6889 MB |    7270 MB |    1004 GB |     998 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6954 MB |    7335 MB |    1006 GB |     999 GB |
|       from large pool |    6889 MB |    7270 MB |    1004 GB |     998 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7338 MB |    7426 MB |   29644 MB |   22306 MB |
|       from large pool |    7272 MB |    7360 MB |   29496 MB |   22224 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  360065 KB |    1773 MB |  319912 MB |  319561 MB |
|       from large pool |  358750 KB |    1772 MB |  318137 MB |  317786 MB |
|       from small pool |    1315 KB |       3 MB |    1775 MB |    1774 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   71475    |   70903    |
|       from large pool |     246    |     250    |   39010    |   38764    |
|       from small pool |     326    |     500    |   32465    |   32139    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   71475    |   70903    |
|       from large pool |     246    |     250    |   39010    |   38764    |
|       from small pool |     326    |     500    |   32465    |   32139    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     216    |     264    |     895    |     679    |
|       from large pool |     183    |     208    |     821    |     638    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     120    |     180    |   23602    |   23482    |
|       from large pool |     113    |     175    |   18823    |   18710    |
|       from small pool |       7    |      12    |    4779    |    4772    |
|===========================================================================|

2022-03-21 20:09:50 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:50 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 7.07 GiB already allocated; 20.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:09:50 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 110          |        cudaMalloc retries: 121       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7243 MB |    7335 MB |    1015 GB |    1008 GB |
|       from large pool |    7178 MB |    7270 MB |    1014 GB |    1007 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7243 MB |    7335 MB |    1015 GB |    1008 GB |
|       from large pool |    7178 MB |    7270 MB |    1014 GB |    1007 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7402 MB |    7426 MB |   29740 MB |   22338 MB |
|       from large pool |    7336 MB |    7360 MB |   29592 MB |   22256 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  162654 KB |    1773 MB |  323278 MB |  323119 MB |
|       from large pool |  161351 KB |    1772 MB |  321491 MB |  321333 MB |
|       from small pool |    1302 KB |       3 MB |    1787 MB |    1785 MB |
|---------------------------------------------------------------------------|
| Allocations           |     568    |     580    |   71919    |   71351    |
|       from large pool |     244    |     250    |   39355    |   39111    |
|       from small pool |     324    |     500    |   32564    |   32240    |
|---------------------------------------------------------------------------|
| Active allocs         |     568    |     580    |   71919    |   71351    |
|       from large pool |     244    |     250    |   39355    |   39111    |
|       from small pool |     324    |     500    |   32564    |   32240    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     217    |     264    |     897    |     680    |
|       from large pool |     184    |     208    |     823    |     639    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      48    |     180    |   23734    |   23686    |
|       from large pool |      42    |     175    |   18918    |   18876    |
|       from small pool |       6    |      12    |    4816    |    4810    |
|===========================================================================|

2022-03-21 20:09:50 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:52 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 826.00 MiB (GPU 0; 7.93 GiB total capacity; 6.30 GiB already allocated; 76.44 MiB free; 7.17 GiB reserved in total by PyTorch)
2022-03-21 20:09:52 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 111          |        cudaMalloc retries: 122       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6455 MB |    7335 MB |    1024 GB |    1018 GB |
|       from large pool |    6391 MB |    7270 MB |    1023 GB |    1016 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6455 MB |    7335 MB |    1024 GB |    1018 GB |
|       from large pool |    6391 MB |    7270 MB |    1023 GB |    1016 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7346 MB |    7426 MB |   29740 MB |   22394 MB |
|       from large pool |    7280 MB |    7360 MB |   29592 MB |   22312 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     890 MB |    1773 MB |  326990 MB |  326099 MB |
|       from large pool |     888 MB |    1772 MB |  325186 MB |  324297 MB |
|       from small pool |       1 MB |       3 MB |    1803 MB |    1801 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   72382    |   71810    |
|       from large pool |     246    |     250    |   39715    |   39469    |
|       from small pool |     326    |     500    |   32667    |   32341    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   72382    |   71810    |
|       from large pool |     246    |     250    |   39715    |   39469    |
|       from small pool |     326    |     500    |   32667    |   32341    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     214    |     264    |     897    |     683    |
|       from large pool |     181    |     208    |     823    |     642    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      53    |     180    |   23898    |   23845    |
|       from large pool |      47    |     175    |   19042    |   18995    |
|       from small pool |       6    |      12    |    4856    |    4850    |
|===========================================================================|

2022-03-21 20:09:52 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:52 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.29 GiB already allocated; 76.44 MiB free; 7.17 GiB reserved in total by PyTorch)
2022-03-21 20:09:52 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 112          |        cudaMalloc retries: 123       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6406 MB |    7335 MB |    1033 GB |    1027 GB |
|       from large pool |    6341 MB |    7270 MB |    1031 GB |    1025 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6406 MB |    7335 MB |    1033 GB |    1027 GB |
|       from large pool |    6341 MB |    7270 MB |    1031 GB |    1025 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7346 MB |    7426 MB |   29740 MB |   22394 MB |
|       from large pool |    7280 MB |    7360 MB |   29592 MB |   22312 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     907 MB |    1773 MB |  331077 MB |  330169 MB |
|       from large pool |     906 MB |    1772 MB |  329263 MB |  328357 MB |
|       from small pool |       1 MB |       3 MB |    1813 MB |    1812 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     580    |   72844    |   72271    |
|       from large pool |     246    |     250    |   40074    |   39828    |
|       from small pool |     327    |     500    |   32770    |   32443    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     580    |   72844    |   72271    |
|       from large pool |     246    |     250    |   40074    |   39828    |
|       from small pool |     327    |     500    |   32770    |   32443    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     214    |     264    |     897    |     683    |
|       from large pool |     181    |     208    |     823    |     642    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     126    |     180    |   24142    |   24016    |
|       from large pool |     120    |     175    |   19248    |   19128    |
|       from small pool |       6    |      12    |    4894    |    4888    |
|===========================================================================|

2022-03-21 20:09:52 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:53 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.76 GiB already allocated; 6.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:53 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 113          |        cudaMalloc retries: 124       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6917 MB |    7335 MB |    1042 GB |    1035 GB |
|       from large pool |    6853 MB |    7270 MB |    1041 GB |    1034 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6917 MB |    7335 MB |    1042 GB |    1035 GB |
|       from large pool |    6853 MB |    7270 MB |    1041 GB |    1034 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7416 MB |    7426 MB |   29842 MB |   22426 MB |
|       from large pool |    7350 MB |    7360 MB |   29694 MB |   22344 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  510301 KB |    1988 MB |  335023 MB |  334525 MB |
|       from large pool |  508734 KB |    1988 MB |  333199 MB |  332702 MB |
|       from small pool |    1566 KB |       3 MB |    1824 MB |    1822 MB |
|---------------------------------------------------------------------------|
| Allocations           |     560    |     580    |   73277    |   72717    |
|       from large pool |     238    |     250    |   40410    |   40172    |
|       from small pool |     322    |     500    |   32867    |   32545    |
|---------------------------------------------------------------------------|
| Active allocs         |     560    |     580    |   73277    |   72717    |
|       from large pool |     238    |     250    |   40410    |   40172    |
|       from small pool |     322    |     500    |   32867    |   32545    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     217    |     264    |     901    |     684    |
|       from large pool |     184    |     208    |     827    |     643    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     132    |     180    |   24390    |   24258    |
|       from large pool |     126    |     175    |   19460    |   19334    |
|       from small pool |       6    |      12    |    4930    |    4924    |
|===========================================================================|

2022-03-21 20:09:53 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:53 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 7.93 GiB total capacity; 6.56 GiB already allocated; 6.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:09:53 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 114          |        cudaMalloc retries: 125       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6713 MB |    7335 MB |    1051 GB |    1045 GB |
|       from large pool |    6649 MB |    7270 MB |    1050 GB |    1043 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6713 MB |    7335 MB |    1051 GB |    1045 GB |
|       from large pool |    6649 MB |    7270 MB |    1050 GB |    1043 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7416 MB |    7426 MB |   29842 MB |   22426 MB |
|       from large pool |    7350 MB |    7360 MB |   29694 MB |   22344 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  718888 KB |    1988 MB |  339050 MB |  338348 MB |
|       from large pool |  717187 KB |    1988 MB |  337215 MB |  336515 MB |
|       from small pool |    1700 KB |       3 MB |    1835 MB |    1833 MB |
|---------------------------------------------------------------------------|
| Allocations           |     555    |     580    |   73704    |   73149    |
|       from large pool |     233    |     250    |   40740    |   40507    |
|       from small pool |     322    |     500    |   32964    |   32642    |
|---------------------------------------------------------------------------|
| Active allocs         |     555    |     580    |   73704    |   73149    |
|       from large pool |     233    |     250    |   40740    |   40507    |
|       from small pool |     322    |     500    |   32964    |   32642    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     217    |     264    |     901    |     684    |
|       from large pool |     184    |     208    |     827    |     643    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     146    |     180    |   24668    |   24522    |
|       from large pool |     141    |     175    |   19690    |   19549    |
|       from small pool |       5    |      12    |    4978    |    4973    |
|===========================================================================|

2022-03-21 20:09:53 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:54 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 396.00 MiB (GPU 0; 7.93 GiB total capacity; 5.90 GiB already allocated; 266.44 MiB free; 6.99 GiB reserved in total by PyTorch)
2022-03-21 20:09:54 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 115          |        cudaMalloc retries: 126       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6014 MB |    7335 MB |    1059 GB |    1053 GB |
|       from large pool |    5949 MB |    7270 MB |    1058 GB |    1052 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6014 MB |    7335 MB |    1059 GB |    1053 GB |
|       from large pool |    5949 MB |    7270 MB |    1058 GB |    1052 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7156 MB |    7426 MB |   29842 MB |   22686 MB |
|       from large pool |    7090 MB |    7360 MB |   29694 MB |   22604 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1109 MB |    1988 MB |  343650 MB |  342540 MB |
|       from large pool |    1108 MB |    1988 MB |  341805 MB |  340696 MB |
|       from small pool |       1 MB |       3 MB |    1845 MB |    1843 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   74157    |   73585    |
|       from large pool |     246    |     250    |   41092    |   40846    |
|       from small pool |     326    |     500    |   33065    |   32739    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   74157    |   73585    |
|       from large pool |     246    |     250    |   41092    |   40846    |
|       from small pool |     326    |     500    |   33065    |   32739    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     204    |     264    |     901    |     697    |
|       from large pool |     171    |     208    |     827    |     656    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     150    |     180    |   24982    |   24832    |
|       from large pool |     144    |     175    |   19963    |   19819    |
|       from small pool |       6    |      12    |    5019    |    5013    |
|===========================================================================|

2022-03-21 20:09:54 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:55 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 7.93 GiB total capacity; 7.03 GiB already allocated; 46.44 MiB free; 7.20 GiB reserved in total by PyTorch)
2022-03-21 20:09:55 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 116          |        cudaMalloc retries: 127       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7166 MB |    7335 MB |    1069 GB |    1062 GB |
|       from large pool |    7101 MB |    7270 MB |    1068 GB |    1061 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7166 MB |    7335 MB |    1069 GB |    1062 GB |
|       from large pool |    7101 MB |    7270 MB |    1068 GB |    1061 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7376 MB |    7426 MB |   30094 MB |   22718 MB |
|       from large pool |    7310 MB |    7360 MB |   29946 MB |   22636 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  181719 KB |    2032 MB |  348309 MB |  348132 MB |
|       from large pool |  180452 KB |    2031 MB |  346453 MB |  346277 MB |
|       from small pool |    1267 KB |       3 MB |    1856 MB |    1854 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   74610    |   74038    |
|       from large pool |     246    |     250    |   41444    |   41198    |
|       from small pool |     326    |     500    |   33166    |   32840    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   74610    |   74038    |
|       from large pool |     246    |     250    |   41444    |   41198    |
|       from small pool |     326    |     500    |   33166    |   32840    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     210    |     264    |     908    |     698    |
|       from large pool |     177    |     208    |     834    |     657    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      87    |     180    |   25191    |   25104    |
|       from large pool |      81    |     175    |   20135    |   20054    |
|       from small pool |       6    |      12    |    5056    |    5050    |
|===========================================================================|

2022-03-21 20:09:55 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:55 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.93 GiB already allocated; 14.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:09:55 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 117          |        cudaMalloc retries: 128       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7100 MB |    7335 MB |    1079 GB |    1072 GB |
|       from large pool |    7035 MB |    7270 MB |    1077 GB |    1070 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7100 MB |    7335 MB |    1079 GB |    1072 GB |
|       from large pool |    7035 MB |    7270 MB |    1077 GB |    1070 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7408 MB |    7426 MB |   30158 MB |   22750 MB |
|       from large pool |    7342 MB |    7360 MB |   30010 MB |   22668 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  315237 KB |    2032 MB |  352057 MB |  351750 MB |
|       from large pool |  313761 KB |    2031 MB |  350190 MB |  349884 MB |
|       from small pool |    1476 KB |       3 MB |    1867 MB |    1866 MB |
|---------------------------------------------------------------------------|
| Allocations           |     561    |     580    |   75045    |   74484    |
|       from large pool |     239    |     250    |   41782    |   41543    |
|       from small pool |     322    |     500    |   33263    |   32941    |
|---------------------------------------------------------------------------|
| Active allocs         |     561    |     580    |   75045    |   74484    |
|       from large pool |     239    |     250    |   41782    |   41543    |
|       from small pool |     322    |     500    |   33263    |   32941    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     264    |     910    |     699    |
|       from large pool |     178    |     208    |     836    |     658    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      60    |     180    |   25338    |   25278    |
|       from large pool |      54    |     175    |   20245    |   20191    |
|       from small pool |       6    |      12    |    5093    |    5087    |
|===========================================================================|

2022-03-21 20:09:55 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:56 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 412.00 MiB (GPU 0; 7.93 GiB total capacity; 6.29 GiB already allocated; 14.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:09:56 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 118          |        cudaMalloc retries: 129       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6404 MB |    7335 MB |    1087 GB |    1081 GB |
|       from large pool |    6340 MB |    7270 MB |    1086 GB |    1080 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6404 MB |    7335 MB |    1087 GB |    1081 GB |
|       from large pool |    6340 MB |    7270 MB |    1086 GB |    1080 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7408 MB |    7426 MB |   30158 MB |   22750 MB |
|       from large pool |    7342 MB |    7360 MB |   30010 MB |   22668 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     971 MB |    2032 MB |  356741 MB |  355769 MB |
|       from large pool |     969 MB |    2031 MB |  354863 MB |  353893 MB |
|       from small pool |       1 MB |       3 MB |    1878 MB |    1876 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     580    |   75507    |   74934    |
|       from large pool |     246    |     250    |   42141    |   41895    |
|       from small pool |     327    |     500    |   33366    |   33039    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     580    |   75507    |   74934    |
|       from large pool |     246    |     250    |   42141    |   41895    |
|       from small pool |     327    |     500    |   33366    |   33039    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     264    |     910    |     699    |
|       from large pool |     178    |     208    |     836    |     658    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     120    |     180    |   25579    |   25459    |
|       from large pool |     114    |     175    |   20442    |   20328    |
|       from small pool |       6    |      12    |    5137    |    5131    |
|===========================================================================|

2022-03-21 20:09:56 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:57 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.67 GiB already allocated; 46.44 MiB free; 7.20 GiB reserved in total by PyTorch)
2022-03-21 20:09:57 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 119          |        cudaMalloc retries: 130       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6794 MB |    7335 MB |    1097 GB |    1090 GB |
|       from large pool |    6730 MB |    7270 MB |    1095 GB |    1089 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6794 MB |    7335 MB |    1097 GB |    1090 GB |
|       from large pool |    6730 MB |    7270 MB |    1095 GB |    1089 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7376 MB |    7426 MB |   30158 MB |   22782 MB |
|       from large pool |    7310 MB |    7360 MB |   30010 MB |   22700 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  562496 KB |    2032 MB |  360706 MB |  360156 MB |
|       from large pool |  561035 KB |    2031 MB |  358817 MB |  358269 MB |
|       from small pool |    1460 KB |       3 MB |    1888 MB |    1887 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   75960    |   75388    |
|       from large pool |     246    |     250    |   42493    |   42247    |
|       from small pool |     326    |     500    |   33467    |   33141    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   75960    |   75388    |
|       from large pool |     246    |     250    |   42493    |   42247    |
|       from small pool |     326    |     500    |   33467    |   33141    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     210    |     264    |     910    |     700    |
|       from large pool |     177    |     208    |     836    |     659    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     112    |     180    |   25807    |   25695    |
|       from large pool |     106    |     175    |   20634    |   20528    |
|       from small pool |       6    |      12    |    5173    |    5167    |
|===========================================================================|

2022-03-21 20:09:57 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:58 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.56 GiB already allocated; 30.44 MiB free; 7.22 GiB reserved in total by PyTorch)
2022-03-21 20:09:58 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 120          |        cudaMalloc retries: 131       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6682 MB |    7335 MB |    1106 GB |    1099 GB |
|       from large pool |    6618 MB |    7270 MB |    1104 GB |    1098 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6682 MB |    7335 MB |    1106 GB |    1099 GB |
|       from large pool |    6618 MB |    7270 MB |    1104 GB |    1098 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7392 MB |    7426 MB |   30220 MB |   22828 MB |
|       from large pool |    7326 MB |    7360 MB |   30072 MB |   22746 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  693590 KB |    2032 MB |  365282 MB |  364604 MB |
|       from large pool |  691935 KB |    2031 MB |  363382 MB |  362707 MB |
|       from small pool |    1654 KB |       3 MB |    1899 MB |    1897 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     580    |   76422    |   75849    |
|       from large pool |     246    |     250    |   42852    |   42606    |
|       from small pool |     327    |     500    |   33570    |   33243    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     580    |   76422    |   75849    |
|       from large pool |     246    |     250    |   42852    |   42606    |
|       from small pool |     327    |     500    |   33570    |   33243    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     264    |     913    |     702    |
|       from large pool |     178    |     208    |     839    |     661    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     109    |     180    |   26061    |   25952    |
|       from large pool |     102    |     175    |   20843    |   20741    |
|       from small pool |       7    |      12    |    5218    |    5211    |
|===========================================================================|

2022-03-21 20:09:58 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:58 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 7.09 GiB already allocated; 30.44 MiB free; 7.22 GiB reserved in total by PyTorch)
2022-03-21 20:09:58 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 121          |        cudaMalloc retries: 132       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7226 MB |    7335 MB |    1116 GB |    1109 GB |
|       from large pool |    7161 MB |    7270 MB |    1114 GB |    1107 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7226 MB |    7335 MB |    1116 GB |    1109 GB |
|       from large pool |    7161 MB |    7270 MB |    1114 GB |    1107 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7392 MB |    7426 MB |   30252 MB |   22860 MB |
|       from large pool |    7326 MB |    7360 MB |   30104 MB |   22778 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  137206 KB |    2032 MB |  369688 MB |  369554 MB |
|       from large pool |  136035 KB |    2031 MB |  367778 MB |  367645 MB |
|       from small pool |    1171 KB |       3 MB |    1910 MB |    1909 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   76875    |   76303    |
|       from large pool |     246    |     250    |   43204    |   42958    |
|       from small pool |     326    |     500    |   33671    |   33345    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   76875    |   76303    |
|       from large pool |     246    |     250    |   43204    |   42958    |
|       from small pool |     326    |     500    |   33671    |   33345    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     264    |     914    |     703    |
|       from large pool |     178    |     208    |     840    |     662    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      38    |     180    |   26186    |   26148    |
|       from large pool |      32    |     175    |   20930    |   20898    |
|       from small pool |       6    |      12    |    5256    |    5250    |
|===========================================================================|

2022-03-21 20:09:58 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:59 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 7.93 GiB total capacity; 7.02 GiB already allocated; 46.44 MiB free; 7.20 GiB reserved in total by PyTorch)
2022-03-21 20:09:59 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 122          |        cudaMalloc retries: 133       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7158 MB |    7335 MB |    1125 GB |    1118 GB |
|       from large pool |    7093 MB |    7270 MB |    1124 GB |    1117 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7158 MB |    7335 MB |    1125 GB |    1118 GB |
|       from large pool |    7093 MB |    7270 MB |    1124 GB |    1117 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7376 MB |    7426 MB |   30268 MB |   22892 MB |
|       from large pool |    7310 MB |    7360 MB |   30120 MB |   22810 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  190153 KB |    2032 MB |  373387 MB |  373202 MB |
|       from large pool |  188889 KB |    2031 MB |  371466 MB |  371281 MB |
|       from small pool |    1264 KB |       3 MB |    1921 MB |    1920 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   77328    |   76756    |
|       from large pool |     246    |     250    |   43556    |   43310    |
|       from small pool |     326    |     500    |   33772    |   33446    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   77328    |   76756    |
|       from large pool |     246    |     250    |   43556    |   43310    |
|       from small pool |     326    |     500    |   33772    |   33446    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     264    |     915    |     704    |
|       from large pool |     178    |     208    |     841    |     663    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      87    |     180    |   26393    |   26306    |
|       from large pool |      81    |     175    |   21101    |   21020    |
|       from small pool |       6    |      12    |    5292    |    5286    |
|===========================================================================|

2022-03-21 20:09:59 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:09:59 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 7.93 GiB total capacity; 6.36 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:09:59 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 123          |        cudaMalloc retries: 134       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6512 MB |    7335 MB |    1134 GB |    1128 GB |
|       from large pool |    6448 MB |    7270 MB |    1133 GB |    1126 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6512 MB |    7335 MB |    1134 GB |    1128 GB |
|       from large pool |    6448 MB |    7270 MB |    1133 GB |    1126 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   30328 MB |   22924 MB |
|       from large pool |    7338 MB |    7360 MB |   30180 MB |   22842 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     891 MB |    2032 MB |  378107 MB |  377215 MB |
|       from large pool |     889 MB |    2031 MB |  376174 MB |  375285 MB |
|       from small pool |       1 MB |       3 MB |    1932 MB |    1930 MB |
|---------------------------------------------------------------------------|
| Allocations           |     566    |     580    |   77770    |   77204    |
|       from large pool |     242    |     250    |   43899    |   43657    |
|       from small pool |     324    |     500    |   33871    |   33547    |
|---------------------------------------------------------------------------|
| Active allocs         |     566    |     580    |   77770    |   77204    |
|       from large pool |     242    |     250    |   43899    |   43657    |
|       from small pool |     324    |     500    |   33871    |   33547    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     264    |     916    |     705    |
|       from large pool |     178    |     208    |     842    |     664    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     172    |     180    |   26728    |   26556    |
|       from large pool |     167    |     175    |   21399    |   21232    |
|       from small pool |       5    |      12    |    5329    |    5324    |
|===========================================================================|

2022-03-21 20:09:59 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:00 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.55 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:00 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 124          |        cudaMalloc retries: 135       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6711 MB |    7335 MB |    1143 GB |    1137 GB |
|       from large pool |    6647 MB |    7270 MB |    1142 GB |    1135 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6711 MB |    7335 MB |    1143 GB |    1137 GB |
|       from large pool |    6647 MB |    7270 MB |    1142 GB |    1135 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   30328 MB |   22924 MB |
|       from large pool |    7338 MB |    7360 MB |   30180 MB |   22842 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  709368 KB |    2032 MB |  382511 MB |  381818 MB |
|       from large pool |  707521 KB |    2031 MB |  380568 MB |  379877 MB |
|       from small pool |    1846 KB |       3 MB |    1942 MB |    1941 MB |
|---------------------------------------------------------------------------|
| Allocations           |     561    |     580    |   78212    |   77651    |
|       from large pool |     238    |     250    |   44242    |   44004    |
|       from small pool |     323    |     500    |   33970    |   33647    |
|---------------------------------------------------------------------------|
| Active allocs         |     561    |     580    |   78212    |   77651    |
|       from large pool |     238    |     250    |   44242    |   44004    |
|       from small pool |     323    |     500    |   33970    |   33647    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     264    |     916    |     705    |
|       from large pool |     178    |     208    |     842    |     664    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     121    |     180    |   26971    |   26850    |
|       from large pool |     114    |     175    |   21603    |   21489    |
|       from small pool |       7    |      12    |    5368    |    5361    |
|===========================================================================|

2022-03-21 20:10:00 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:01 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 7.93 GiB total capacity; 6.41 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:01 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 125          |        cudaMalloc retries: 136       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6561 MB |    7335 MB |    1152 GB |    1146 GB |
|       from large pool |    6497 MB |    7270 MB |    1151 GB |    1144 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6561 MB |    7335 MB |    1152 GB |    1146 GB |
|       from large pool |    6497 MB |    7270 MB |    1151 GB |    1144 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   30328 MB |   22924 MB |
|       from large pool |    7338 MB |    7360 MB |   30180 MB |   22842 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     842 MB |    2032 MB |  387286 MB |  386444 MB |
|       from large pool |     840 MB |    2031 MB |  385333 MB |  384492 MB |
|       from small pool |       1 MB |       3 MB |    1953 MB |    1951 MB |
|---------------------------------------------------------------------------|
| Allocations           |     566    |     580    |   78662    |   78096    |
|       from large pool |     241    |     250    |   44591    |   44350    |
|       from small pool |     325    |     500    |   34071    |   33746    |
|---------------------------------------------------------------------------|
| Active allocs         |     566    |     580    |   78662    |   78096    |
|       from large pool |     241    |     250    |   44591    |   44350    |
|       from small pool |     325    |     500    |   34071    |   33746    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     264    |     916    |     705    |
|       from large pool |     178    |     208    |     842    |     664    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     119    |     180    |   27222    |   27103    |
|       from large pool |     114    |     175    |   21817    |   21703    |
|       from small pool |       5    |      12    |    5405    |    5400    |
|===========================================================================|

2022-03-21 20:10:01 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:02 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.49 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 126          |        cudaMalloc retries: 138       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6648 MB |    7335 MB |    1161 GB |    1155 GB |
|       from large pool |    6584 MB |    7270 MB |    1160 GB |    1153 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6648 MB |    7335 MB |    1161 GB |    1155 GB |
|       from large pool |    6584 MB |    7270 MB |    1160 GB |    1153 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   30392 MB |   22988 MB |
|       from large pool |    7338 MB |    7360 MB |   30244 MB |   22906 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  773244 KB |    2032 MB |  391690 MB |  390935 MB |
|       from large pool |  771381 KB |    2031 MB |  389726 MB |  388973 MB |
|       from small pool |    1862 KB |       3 MB |    1963 MB |    1962 MB |
|---------------------------------------------------------------------------|
| Allocations           |     544    |     580    |   79080    |   78536    |
|       from large pool |     222    |     250    |   44912    |   44690    |
|       from small pool |     322    |     500    |   34168    |   33846    |
|---------------------------------------------------------------------------|
| Active allocs         |     544    |     580    |   79080    |   78536    |
|       from large pool |     222    |     250    |   44912    |   44690    |
|       from small pool |     322    |     500    |   34168    |   33846    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     209    |     264    |     918    |     709    |
|       from large pool |     176    |     208    |     844    |     668    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     122    |     180    |   27478    |   27356    |
|       from large pool |     117    |     175    |   22029    |   21912    |
|       from small pool |       5    |      12    |    5449    |    5444    |
|===========================================================================|

2022-03-21 20:10:02 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:02 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 7.93 GiB total capacity; 6.97 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:02 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 127          |        cudaMalloc retries: 139       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7135 MB |    7335 MB |    1171 GB |    1164 GB |
|       from large pool |    7071 MB |    7270 MB |    1169 GB |    1162 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7135 MB |    7335 MB |    1171 GB |    1164 GB |
|       from large pool |    7071 MB |    7270 MB |    1169 GB |    1162 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   30392 MB |   22988 MB |
|       from large pool |    7338 MB |    7360 MB |   30244 MB |   22906 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  274794 KB |    2032 MB |  395442 MB |  395174 MB |
|       from large pool |  273402 KB |    2031 MB |  393468 MB |  393201 MB |
|       from small pool |    1392 KB |       3 MB |    1974 MB |    1973 MB |
|---------------------------------------------------------------------------|
| Allocations           |     566    |     580    |   79522    |   78956    |
|       from large pool |     242    |     250    |   45255    |   45013    |
|       from small pool |     324    |     500    |   34267    |   33943    |
|---------------------------------------------------------------------------|
| Active allocs         |     566    |     580    |   79522    |   78956    |
|       from large pool |     242    |     250    |   45255    |   45013    |
|       from small pool |     324    |     500    |   34267    |   33943    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     209    |     264    |     918    |     709    |
|       from large pool |     176    |     208    |     844    |     668    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      88    |     180    |   27674    |   27586    |
|       from large pool |      82    |     175    |   22191    |   22109    |
|       from small pool |       6    |      12    |    5483    |    5477    |
|===========================================================================|

2022-03-21 20:10:02 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:03 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 7.93 GiB total capacity; 6.90 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:03 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 128          |        cudaMalloc retries: 140       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7029 MB |    7335 MB |    1180 GB |    1173 GB |
|       from large pool |    6964 MB |    7270 MB |    1179 GB |    1172 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7029 MB |    7335 MB |    1180 GB |    1173 GB |
|       from large pool |    6964 MB |    7270 MB |    1179 GB |    1172 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   30392 MB |   22988 MB |
|       from large pool |    7338 MB |    7360 MB |   30244 MB |   22906 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  383875 KB |    2032 MB |  399419 MB |  399044 MB |
|       from large pool |  382382 KB |    2031 MB |  397433 MB |  397060 MB |
|       from small pool |    1493 KB |       3 MB |    1985 MB |    1984 MB |
|---------------------------------------------------------------------------|
| Allocations           |     561    |     580    |   79958    |   79397    |
|       from large pool |     239    |     250    |   45594    |   45355    |
|       from small pool |     322    |     500    |   34364    |   34042    |
|---------------------------------------------------------------------------|
| Active allocs         |     561    |     580    |   79958    |   79397    |
|       from large pool |     239    |     250    |   45594    |   45355    |
|       from small pool |     322    |     500    |   34364    |   34042    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     209    |     264    |     918    |     709    |
|       from large pool |     176    |     208    |     844    |     668    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     116    |     180    |   27917    |   27801    |
|       from large pool |     110    |     175    |   22399    |   22289    |
|       from small pool |       6    |      12    |    5518    |    5512    |
|===========================================================================|

2022-03-21 20:10:03 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:03 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 826.00 MiB (GPU 0; 7.93 GiB total capacity; 6.52 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:03 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 129          |        cudaMalloc retries: 141       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6677 MB |    7335 MB |    1189 GB |    1183 GB |
|       from large pool |    6612 MB |    7270 MB |    1188 GB |    1181 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6677 MB |    7335 MB |    1189 GB |    1183 GB |
|       from large pool |    6612 MB |    7270 MB |    1188 GB |    1181 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   30392 MB |   22988 MB |
|       from large pool |    7338 MB |    7360 MB |   30244 MB |   22906 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  744349 KB |    2032 MB |  403958 MB |  403231 MB |
|       from large pool |  742561 KB |    2031 MB |  401962 MB |  401237 MB |
|       from small pool |    1788 KB |       3 MB |    1996 MB |    1994 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   80421    |   79849    |
|       from large pool |     246    |     250    |   45954    |   45708    |
|       from small pool |     326    |     500    |   34467    |   34141    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   80421    |   79849    |
|       from large pool |     246    |     250    |   45954    |   45708    |
|       from small pool |     326    |     500    |   34467    |   34141    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     209    |     264    |     918    |     709    |
|       from large pool |     176    |     208    |     844    |     668    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      94    |     180    |   28130    |   28036    |
|       from large pool |      88    |     175    |   22568    |   22480    |
|       from small pool |       6    |      12    |    5562    |    5556    |
|===========================================================================|

2022-03-21 20:10:03 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:04 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.53 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:04 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 130          |        cudaMalloc retries: 142       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6651 MB |    7335 MB |    1198 GB |    1192 GB |
|       from large pool |    6585 MB |    7270 MB |    1197 GB |    1190 GB |
|       from small pool |      65 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6651 MB |    7335 MB |    1198 GB |    1192 GB |
|       from large pool |    6585 MB |    7270 MB |    1197 GB |    1190 GB |
|       from small pool |      65 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   30392 MB |   22988 MB |
|       from large pool |    7338 MB |    7360 MB |   30244 MB |   22906 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  737804 KB |    2032 MB |  407633 MB |  406913 MB |
|       from large pool |  737377 KB |    2031 MB |  405626 MB |  404906 MB |
|       from small pool |     427 KB |       3 MB |    2006 MB |    2006 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   80874    |   80302    |
|       from large pool |     245    |     250    |   46305    |   46060    |
|       from small pool |     327    |     500    |   34569    |   34242    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   80874    |   80302    |
|       from large pool |     245    |     250    |   46305    |   46060    |
|       from small pool |     327    |     500    |   34569    |   34242    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     209    |     264    |     918    |     709    |
|       from large pool |     176    |     208    |     844    |     668    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      92    |     180    |   28361    |   28269    |
|       from large pool |      85    |     175    |   22759    |   22674    |
|       from small pool |       7    |      12    |    5602    |    5595    |
|===========================================================================|

2022-03-21 20:10:04 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:05 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 7.93 GiB total capacity; 6.73 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:05 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 131          |        cudaMalloc retries: 143       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6886 MB |    7335 MB |    1208 GB |    1201 GB |
|       from large pool |    6822 MB |    7270 MB |    1206 GB |    1199 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6886 MB |    7335 MB |    1208 GB |    1201 GB |
|       from large pool |    6822 MB |    7270 MB |    1206 GB |    1199 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   30424 MB |   23020 MB |
|       from large pool |    7338 MB |    7360 MB |   30276 MB |   22938 MB |
|       from small pool |      66 MB |     122 MB |     148 MB |      82 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  529729 KB |    2032 MB |  411493 MB |  410976 MB |
|       from large pool |  528087 KB |    2031 MB |  409475 MB |  408959 MB |
|       from small pool |    1642 KB |       3 MB |    2018 MB |    2017 MB |
|---------------------------------------------------------------------------|
| Allocations           |     555    |     580    |   81301    |   80746    |
|       from large pool |     233    |     250    |   46635    |   46402    |
|       from small pool |     322    |     500    |   34666    |   34344    |
|---------------------------------------------------------------------------|
| Active allocs         |     555    |     580    |   81301    |   80746    |
|       from large pool |     233    |     250    |   46635    |   46402    |
|       from small pool |     322    |     500    |   34666    |   34344    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     209    |     264    |     919    |     710    |
|       from large pool |     176    |     208    |     845    |     669    |
|       from small pool |      33    |      61    |      74    |      41    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     142    |     180    |   28631    |   28489    |
|       from large pool |     136    |     175    |   22994    |   22858    |
|       from small pool |       6    |      12    |    5637    |    5631    |
|===========================================================================|

2022-03-21 20:10:05 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:06 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.58 GiB already allocated; 4.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:10:06 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 132          |        cudaMalloc retries: 145       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6742 MB |    7335 MB |    1217 GB |    1210 GB |
|       from large pool |    6678 MB |    7270 MB |    1215 GB |    1209 GB |
|       from small pool |      63 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6742 MB |    7335 MB |    1217 GB |    1210 GB |
|       from large pool |    6678 MB |    7270 MB |    1215 GB |    1209 GB |
|       from small pool |      63 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7418 MB |    7426 MB |   30520 MB |   23102 MB |
|       from large pool |    7354 MB |    7360 MB |   30372 MB |   23018 MB |
|       from small pool |      64 MB |     122 MB |     148 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  691729 KB |    2032 MB |  415339 MB |  414663 MB |
|       from large pool |  691579 KB |    2031 MB |  413311 MB |  412636 MB |
|       from small pool |     149 KB |       3 MB |    2027 MB |    2027 MB |
|---------------------------------------------------------------------------|
| Allocations           |     517    |     580    |   81680    |   81163    |
|       from large pool |     201    |     250    |   46924    |   46723    |
|       from small pool |     316    |     500    |   34756    |   34440    |
|---------------------------------------------------------------------------|
| Active allocs         |     517    |     580    |   81680    |   81163    |
|       from large pool |     201    |     250    |   46924    |   46723    |
|       from small pool |     316    |     500    |   34756    |   34440    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     207    |     264    |     922    |     715    |
|       from large pool |     175    |     208    |     848    |     673    |
|       from small pool |      32    |      61    |      74    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     167    |     180    |   28936    |   28769    |
|       from large pool |     161    |     175    |   23264    |   23103    |
|       from small pool |       6    |      12    |    5672    |    5666    |
|===========================================================================|

2022-03-21 20:10:06 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:06 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 410.00 MiB (GPU 0; 7.93 GiB total capacity; 6.41 GiB already allocated; 298.44 MiB free; 6.96 GiB reserved in total by PyTorch)
2022-03-21 20:10:06 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 133          |        cudaMalloc retries: 147       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6530 MB |    7335 MB |    1225 GB |    1219 GB |
|       from large pool |    6466 MB |    7270 MB |    1224 GB |    1218 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6530 MB |    7335 MB |    1225 GB |    1219 GB |
|       from large pool |    6466 MB |    7270 MB |    1224 GB |    1218 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7124 MB |    7426 MB |   31052 MB |   23928 MB |
|       from large pool |    7058 MB |    7360 MB |   30902 MB |   23844 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  574640 KB |    2032 MB |  418477 MB |  417916 MB |
|       from large pool |  572949 KB |    2031 MB |  416440 MB |  415880 MB |
|       from small pool |    1691 KB |       3 MB |    2037 MB |    2035 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   82133    |   81561    |
|       from large pool |     246    |     250    |   47276    |   47030    |
|       from small pool |     326    |     500    |   34857    |   34531    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   82133    |   81561    |
|       from large pool |     246    |     250    |   47276    |   47030    |
|       from small pool |     326    |     500    |   34857    |   34531    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     224    |     264    |     940    |     716    |
|       from large pool |     191    |     208    |     865    |     674    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      99    |     180    |   29149    |   29050    |
|       from large pool |      92    |     175    |   23439    |   23347    |
|       from small pool |       7    |      12    |    5710    |    5703    |
|===========================================================================|

2022-03-21 20:10:06 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:07 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 818.00 MiB (GPU 0; 7.93 GiB total capacity; 6.61 GiB already allocated; 110.44 MiB free; 7.14 GiB reserved in total by PyTorch)
2022-03-21 20:10:07 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 134          |        cudaMalloc retries: 149       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6768 MB |    7335 MB |    1235 GB |    1228 GB |
|       from large pool |    6703 MB |    7270 MB |    1233 GB |    1227 GB |
|       from small pool |      65 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6768 MB |    7335 MB |    1235 GB |    1228 GB |
|       from large pool |    6703 MB |    7270 MB |    1233 GB |    1227 GB |
|       from small pool |      65 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7312 MB |    7426 MB |   31462 MB |   24150 MB |
|       from large pool |    7246 MB |    7360 MB |   31312 MB |   24066 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  556255 KB |    2032 MB |  421500 MB |  420956 MB |
|       from large pool |  555331 KB |    2031 MB |  419452 MB |  418909 MB |
|       from small pool |     924 KB |       3 MB |    2047 MB |    2047 MB |
|---------------------------------------------------------------------------|
| Allocations           |     571    |     580    |   82587    |   82016    |
|       from large pool |     245    |     250    |   47628    |   47383    |
|       from small pool |     326    |     500    |   34959    |   34633    |
|---------------------------------------------------------------------------|
| Active allocs         |     571    |     580    |   82587    |   82016    |
|       from large pool |     245    |     250    |   47628    |   47383    |
|       from small pool |     326    |     500    |   34959    |   34633    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     214    |     264    |     941    |     727    |
|       from large pool |     181    |     208    |     866    |     685    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      88    |     180    |   29357    |   29269    |
|       from large pool |      82    |     175    |   23610    |   23528    |
|       from small pool |       6    |      12    |    5747    |    5741    |
|===========================================================================|

2022-03-21 20:10:07 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:08 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 824.00 MiB (GPU 0; 7.93 GiB total capacity; 6.27 GiB already allocated; 154.44 MiB free; 7.10 GiB reserved in total by PyTorch)
2022-03-21 20:10:08 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 135          |        cudaMalloc retries: 150       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6420 MB |    7335 MB |    1243 GB |    1237 GB |
|       from large pool |    6356 MB |    7270 MB |    1242 GB |    1235 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6420 MB |    7335 MB |    1243 GB |    1237 GB |
|       from large pool |    6356 MB |    7270 MB |    1242 GB |    1235 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7268 MB |    7426 MB |   31462 MB |   24194 MB |
|       from large pool |    7202 MB |    7360 MB |   31312 MB |   24110 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     847 MB |    2032 MB |  425224 MB |  424376 MB |
|       from large pool |     845 MB |    2031 MB |  423161 MB |  422316 MB |
|       from small pool |       1 MB |       3 MB |    2062 MB |    2060 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   83050    |   82478    |
|       from large pool |     246    |     250    |   47988    |   47742    |
|       from small pool |     326    |     500    |   35062    |   34736    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   83050    |   82478    |
|       from large pool |     246    |     250    |   47988    |   47742    |
|       from small pool |     326    |     500    |   35062    |   34736    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     264    |     941    |     730    |
|       from large pool |     178    |     208    |     866    |     688    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      85    |     180    |   29564    |   29479    |
|       from large pool |      80    |     175    |   23777    |   23697    |
|       from small pool |       5    |      12    |    5787    |    5782    |
|===========================================================================|

2022-03-21 20:10:08 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:08 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.43 GiB already allocated; 34.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:10:08 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 136          |        cudaMalloc retries: 151       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6585 MB |    7335 MB |    1252 GB |    1246 GB |
|       from large pool |    6521 MB |    7270 MB |    1251 GB |    1244 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6585 MB |    7335 MB |    1252 GB |    1246 GB |
|       from large pool |    6521 MB |    7270 MB |    1251 GB |    1244 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7388 MB |    7426 MB |   31582 MB |   24194 MB |
|       from large pool |    7322 MB |    7360 MB |   31432 MB |   24110 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     802 MB |    2032 MB |  428748 MB |  427945 MB |
|       from large pool |     800 MB |    2031 MB |  426675 MB |  425874 MB |
|       from small pool |       1 MB |       3 MB |    2072 MB |    2071 MB |
|---------------------------------------------------------------------------|
| Allocations           |     549    |     580    |   83475    |   82926    |
|       from large pool |     227    |     250    |   48316    |   48089    |
|       from small pool |     322    |     500    |   35159    |   34837    |
|---------------------------------------------------------------------------|
| Active allocs         |     549    |     580    |   83475    |   82926    |
|       from large pool |     227    |     250    |   48316    |   48089    |
|       from small pool |     322    |     500    |   35159    |   34837    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     215    |     264    |     945    |     730    |
|       from large pool |     182    |     208    |     870    |     688    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     126    |     180    |   29811    |   29685    |
|       from large pool |     119    |     175    |   23984    |   23865    |
|       from small pool |       7    |      12    |    5827    |    5820    |
|===========================================================================|

2022-03-21 20:10:08 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:09 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 828.00 MiB (GPU 0; 7.93 GiB total capacity; 6.23 GiB already allocated; 194.44 MiB free; 7.06 GiB reserved in total by PyTorch)
2022-03-21 20:10:09 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 137          |        cudaMalloc retries: 152       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6375 MB |    7335 MB |    1261 GB |    1254 GB |
|       from large pool |    6310 MB |    7270 MB |    1259 GB |    1253 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6375 MB |    7335 MB |    1261 GB |    1254 GB |
|       from large pool |    6310 MB |    7270 MB |    1259 GB |    1253 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7228 MB |    7426 MB |   31582 MB |   24354 MB |
|       from large pool |    7162 MB |    7360 MB |   31432 MB |   24270 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     852 MB |    2032 MB |  431782 MB |  430929 MB |
|       from large pool |     851 MB |    2031 MB |  429699 MB |  428847 MB |
|       from small pool |       1 MB |       3 MB |    2083 MB |    2081 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   83938    |   83366    |
|       from large pool |     245    |     250    |   48675    |   48430    |
|       from small pool |     327    |     500    |   35263    |   34936    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   83938    |   83366    |
|       from large pool |     245    |     250    |   48675    |   48430    |
|       from small pool |     327    |     500    |   35263    |   34936    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     211    |     264    |     945    |     734    |
|       from large pool |     178    |     208    |     870    |     692    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      70    |     180    |   29984    |   29914    |
|       from large pool |      64    |     175    |   24122    |   24058    |
|       from small pool |       6    |      12    |    5862    |    5856    |
|===========================================================================|

2022-03-21 20:10:09 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:10 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 7.93 GiB total capacity; 6.55 GiB already allocated; 34.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:10:10 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 138          |        cudaMalloc retries: 153       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6705 MB |    7335 MB |    1270 GB |    1263 GB |
|       from large pool |    6640 MB |    7270 MB |    1268 GB |    1262 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6705 MB |    7335 MB |    1270 GB |    1263 GB |
|       from large pool |    6640 MB |    7270 MB |    1268 GB |    1262 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7388 MB |    7426 MB |   31742 MB |   24354 MB |
|       from large pool |    7322 MB |    7360 MB |   31592 MB |   24270 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  699235 KB |    2032 MB |  435233 MB |  434550 MB |
|       from large pool |  697499 KB |    2031 MB |  433139 MB |  432458 MB |
|       from small pool |    1736 KB |       3 MB |    2094 MB |    2092 MB |
|---------------------------------------------------------------------------|
| Allocations           |     566    |     580    |   84380    |   83814    |
|       from large pool |     242    |     250    |   49018    |   48776    |
|       from small pool |     324    |     500    |   35362    |   35038    |
|---------------------------------------------------------------------------|
| Active allocs         |     566    |     580    |   84380    |   83814    |
|       from large pool |     242    |     250    |   49018    |   48776    |
|       from small pool |     324    |     500    |   35362    |   35038    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     215    |     264    |     949    |     734    |
|       from large pool |     182    |     208    |     874    |     692    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     128    |     180    |   30232    |   30104    |
|       from large pool |     122    |     175    |   24330    |   24208    |
|       from small pool |       6    |      12    |    5902    |    5896    |
|===========================================================================|

2022-03-21 20:10:10 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:11 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 828.00 MiB (GPU 0; 7.93 GiB total capacity; 6.27 GiB already allocated; 572.44 MiB free; 6.69 GiB reserved in total by PyTorch)
2022-03-21 20:10:11 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 139          |        cudaMalloc retries: 154       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6424 MB |    7335 MB |    1278 GB |    1272 GB |
|       from large pool |    6360 MB |    7270 MB |    1277 GB |    1271 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6424 MB |    7335 MB |    1278 GB |    1272 GB |
|       from large pool |    6360 MB |    7270 MB |    1277 GB |    1271 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6850 MB |    7426 MB |   31742 MB |   24892 MB |
|       from large pool |    6784 MB |    7360 MB |   31592 MB |   24808 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  435473 KB |    2032 MB |  438245 MB |  437820 MB |
|       from large pool |  433650 KB |    2031 MB |  436141 MB |  435717 MB |
|       from small pool |    1822 KB |       3 MB |    2104 MB |    2102 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   84843    |   84271    |
|       from large pool |     246    |     250    |   49378    |   49132    |
|       from small pool |     326    |     500    |   35465    |   35139    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   84843    |   84271    |
|       from large pool |     246    |     250    |   49378    |   49132    |
|       from small pool |     326    |     500    |   35465    |   35139    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     212    |     264    |     949    |     737    |
|       from large pool |     179    |     208    |     874    |     695    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      60    |     180    |   30421    |   30361    |
|       from large pool |      54    |     175    |   24474    |   24420    |
|       from small pool |       6    |      12    |    5947    |    5941    |
|===========================================================================|

2022-03-21 20:10:11 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:11 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.34 GiB already allocated; 26.44 MiB free; 7.22 GiB reserved in total by PyTorch)
2022-03-21 20:10:11 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 140          |        cudaMalloc retries: 156       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6495 MB |    7335 MB |    1287 GB |    1281 GB |
|       from large pool |    6431 MB |    7270 MB |    1286 GB |    1279 GB |
|       from small pool |      63 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6495 MB |    7335 MB |    1287 GB |    1281 GB |
|       from large pool |    6431 MB |    7270 MB |    1286 GB |    1279 GB |
|       from small pool |      63 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7396 MB |    7426 MB |   32336 MB |   24940 MB |
|       from large pool |    7330 MB |    7360 MB |   32186 MB |   24856 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     900 MB |    2032 MB |  441071 MB |  440170 MB |
|       from large pool |     898 MB |    2031 MB |  438956 MB |  438057 MB |
|       from small pool |       2 MB |       3 MB |    2114 MB |    2112 MB |
|---------------------------------------------------------------------------|
| Allocations           |     538    |     580    |   85253    |   84715    |
|       from large pool |     219    |     250    |   49694    |   49475    |
|       from small pool |     319    |     500    |   35559    |   35240    |
|---------------------------------------------------------------------------|
| Active allocs         |     538    |     580    |   85253    |   84715    |
|       from large pool |     219    |     250    |   49694    |   49475    |
|       from small pool |     319    |     500    |   35559    |   35240    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     264    |     966    |     740    |
|       from large pool |     193    |     208    |     891    |     698    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     123    |     180    |   30659    |   30536    |
|       from large pool |     116    |     175    |   24673    |   24557    |
|       from small pool |       7    |      12    |    5986    |    5979    |
|===========================================================================|

2022-03-21 20:10:11 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:12 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 398.00 MiB (GPU 0; 7.93 GiB total capacity; 6.96 GiB already allocated; 10.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:10:12 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 141          |        cudaMalloc retries: 157       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7100 MB |    7335 MB |    1297 GB |    1290 GB |
|       from large pool |    7035 MB |    7270 MB |    1295 GB |    1288 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7100 MB |    7335 MB |    1297 GB |    1290 GB |
|       from large pool |    7035 MB |    7270 MB |    1295 GB |    1288 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7412 MB |    7426 MB |   32352 MB |   24940 MB |
|       from large pool |    7346 MB |    7360 MB |   32202 MB |   24856 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  286632 KB |    2032 MB |  443407 MB |  443127 MB |
|       from large pool |  285349 KB |    2031 MB |  441281 MB |  441003 MB |
|       from small pool |    1283 KB |       3 MB |    2125 MB |    2124 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   85706    |   85134    |
|       from large pool |     246    |     250    |   50046    |   49800    |
|       from small pool |     326    |     500    |   35660    |   35334    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   85706    |   85134    |
|       from large pool |     246    |     250    |   50046    |   49800    |
|       from small pool |     326    |     500    |   35660    |   35334    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     227    |     264    |     967    |     740    |
|       from large pool |     194    |     208    |     892    |     698    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     107    |     180    |   30851    |   30744    |
|       from large pool |     101    |     175    |   24833    |   24732    |
|       from small pool |       6    |      12    |    6018    |    6012    |
|===========================================================================|

2022-03-21 20:10:12 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:12 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 394.00 MiB (GPU 0; 7.93 GiB total capacity; 6.28 GiB already allocated; 42.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:10:12 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 142          |        cudaMalloc retries: 158       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6396 MB |    7335 MB |    1305 GB |    1299 GB |
|       from large pool |    6332 MB |    7270 MB |    1304 GB |    1298 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6396 MB |    7335 MB |    1305 GB |    1299 GB |
|       from large pool |    6332 MB |    7270 MB |    1304 GB |    1298 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7380 MB |    7426 MB |   32352 MB |   24972 MB |
|       from large pool |    7314 MB |    7360 MB |   32202 MB |   24888 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     951 MB |    2032 MB |  446557 MB |  445606 MB |
|       from large pool |     949 MB |    2031 MB |  444421 MB |  443471 MB |
|       from small pool |       1 MB |       3 MB |    2136 MB |    2134 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   86159    |   85587    |
|       from large pool |     246    |     250    |   50398    |   50152    |
|       from small pool |     326    |     500    |   35761    |   35435    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   86159    |   85587    |
|       from large pool |     246    |     250    |   50398    |   50152    |
|       from small pool |     326    |     500    |   35761    |   35435    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     264    |     967    |     741    |
|       from large pool |     193    |     208    |     892    |     699    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     189    |     192    |   31192    |   31003    |
|       from large pool |     182    |     185    |   25130    |   24948    |
|       from small pool |       7    |      12    |    6062    |    6055    |
|===========================================================================|

2022-03-21 20:10:12 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:13 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.40 GiB already allocated; 12.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:10:13 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 143          |        cudaMalloc retries: 159       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6554 MB |    7335 MB |    1314 GB |    1308 GB |
|       from large pool |    6490 MB |    7270 MB |    1313 GB |    1306 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6554 MB |    7335 MB |    1314 GB |    1308 GB |
|       from large pool |    6490 MB |    7270 MB |    1313 GB |    1306 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7410 MB |    7426 MB |   32414 MB |   25004 MB |
|       from large pool |    7344 MB |    7360 MB |   32264 MB |   24920 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     855 MB |    2032 MB |  450175 MB |  449319 MB |
|       from large pool |     853 MB |    2031 MB |  448028 MB |  447175 MB |
|       from small pool |       1 MB |       3 MB |    2146 MB |    2144 MB |
|---------------------------------------------------------------------------|
| Allocations           |     561    |     580    |   86601    |   86040    |
|       from large pool |     238    |     250    |   50741    |   50503    |
|       from small pool |     323    |     500    |   35860    |   35537    |
|---------------------------------------------------------------------------|
| Active allocs         |     561    |     580    |   86601    |   86040    |
|       from large pool |     238    |     250    |   50741    |   50503    |
|       from small pool |     323    |     500    |   35860    |   35537    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     227    |     264    |     969    |     742    |
|       from large pool |     194    |     208    |     894    |     700    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     127    |     193    |   31429    |   31302    |
|       from large pool |     120    |     185    |   25326    |   25206    |
|       from small pool |       7    |      12    |    6103    |    6096    |
|===========================================================================|

2022-03-21 20:10:13 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:14 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.70 GiB already allocated; 12.44 MiB free; 7.24 GiB reserved in total by PyTorch)
2022-03-21 20:10:14 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 144          |        cudaMalloc retries: 160       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6823 MB |    7335 MB |    1324 GB |    1317 GB |
|       from large pool |    6759 MB |    7270 MB |    1322 GB |    1315 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6823 MB |    7335 MB |    1324 GB |    1317 GB |
|       from large pool |    6759 MB |    7270 MB |    1322 GB |    1315 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7410 MB |    7426 MB |   32414 MB |   25004 MB |
|       from large pool |    7344 MB |    7360 MB |   32264 MB |   24920 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  567402 KB |    2032 MB |  452573 MB |  452018 MB |
|       from large pool |  566016 KB |    2031 MB |  450416 MB |  449863 MB |
|       from small pool |    1386 KB |       3 MB |    2156 MB |    2155 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   87054    |   86482    |
|       from large pool |     246    |     250    |   51093    |   50847    |
|       from small pool |     326    |     500    |   35961    |   35635    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   87054    |   86482    |
|       from large pool |     246    |     250    |   51093    |   50847    |
|       from small pool |     326    |     500    |   35961    |   35635    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     227    |     264    |     969    |     742    |
|       from large pool |     194    |     208    |     894    |     700    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     123    |     193    |   31650    |   31527    |
|       from large pool |     116    |     185    |   25505    |   25389    |
|       from small pool |       7    |      12    |    6145    |    6138    |
|===========================================================================|

2022-03-21 20:10:14 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:14 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 7.93 GiB total capacity; 6.40 GiB already allocated; 44.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:10:14 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 145          |        cudaMalloc retries: 161       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6550 MB |    7335 MB |    1332 GB |    1326 GB |
|       from large pool |    6486 MB |    7270 MB |    1331 GB |    1325 GB |
|       from small pool |      63 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6550 MB |    7335 MB |    1332 GB |    1326 GB |
|       from large pool |    6486 MB |    7270 MB |    1331 GB |    1325 GB |
|       from small pool |      63 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7378 MB |    7426 MB |   32414 MB |   25036 MB |
|       from large pool |    7312 MB |    7360 MB |   32264 MB |   24952 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     827 MB |    2032 MB |  455000 MB |  454172 MB |
|       from large pool |     825 MB |    2031 MB |  452832 MB |  452006 MB |
|       from small pool |       2 MB |       3 MB |    2167 MB |    2165 MB |
|---------------------------------------------------------------------------|
| Allocations           |     536    |     580    |   87462    |   86926    |
|       from large pool |     217    |     250    |   51407    |   51190    |
|       from small pool |     319    |     500    |   36055    |   35736    |
|---------------------------------------------------------------------------|
| Active allocs         |     536    |     580    |   87462    |   86926    |
|       from large pool |     217    |     250    |   51407    |   51190    |
|       from small pool |     319    |     500    |   36055    |   35736    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     264    |     969    |     743    |
|       from large pool |     193    |     208    |     894    |     701    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     127    |     193    |   31877    |   31750    |
|       from large pool |     120    |     185    |   25693    |   25573    |
|       from small pool |       7    |      12    |    6184    |    6177    |
|===========================================================================|

2022-03-21 20:10:14 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:15 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 410.00 MiB (GPU 0; 7.93 GiB total capacity; 6.39 GiB already allocated; 44.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:10:15 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 146          |        cudaMalloc retries: 162       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6507 MB |    7335 MB |    1341 GB |    1335 GB |
|       from large pool |    6442 MB |    7270 MB |    1340 GB |    1333 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6507 MB |    7335 MB |    1341 GB |    1335 GB |
|       from large pool |    6442 MB |    7270 MB |    1340 GB |    1333 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7378 MB |    7426 MB |   32414 MB |   25036 MB |
|       from large pool |    7312 MB |    7360 MB |   32264 MB |   24952 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     838 MB |    2032 MB |  457578 MB |  456739 MB |
|       from large pool |     837 MB |    2031 MB |  455400 MB |  454563 MB |
|       from small pool |       1 MB |       3 MB |    2177 MB |    2176 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     580    |   87924    |   87351    |
|       from large pool |     246    |     250    |   51766    |   51520    |
|       from small pool |     327    |     500    |   36158    |   35831    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     580    |   87924    |   87351    |
|       from large pool |     246    |     250    |   51766    |   51520    |
|       from small pool |     327    |     500    |   36158    |   35831    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     264    |     969    |     743    |
|       from large pool |     193    |     208    |     894    |     701    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      94    |     193    |   32078    |   31984    |
|       from large pool |      87    |     185    |   25859    |   25772    |
|       from small pool |       7    |      12    |    6219    |    6212    |
|===========================================================================|

2022-03-21 20:10:15 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:15 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 7.93 GiB total capacity; 6.25 GiB already allocated; 76.44 MiB free; 7.17 GiB reserved in total by PyTorch)
2022-03-21 20:10:15 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 147          |        cudaMalloc retries: 163       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6363 MB |    7335 MB |    1350 GB |    1344 GB |
|       from large pool |    6298 MB |    7270 MB |    1348 GB |    1342 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6363 MB |    7335 MB |    1350 GB |    1344 GB |
|       from large pool |    6298 MB |    7270 MB |    1348 GB |    1342 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7346 MB |    7426 MB |   32414 MB |   25068 MB |
|       from large pool |    7280 MB |    7360 MB |   32264 MB |   24984 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     950 MB |    2032 MB |  460429 MB |  459479 MB |
|       from large pool |     949 MB |    2031 MB |  458241 MB |  457292 MB |
|       from small pool |       1 MB |       3 MB |    2188 MB |    2186 MB |
|---------------------------------------------------------------------------|
| Allocations           |     573    |     580    |   88386    |   87813    |
|       from large pool |     246    |     250    |   52125    |   51879    |
|       from small pool |     327    |     500    |   36261    |   35934    |
|---------------------------------------------------------------------------|
| Active allocs         |     573    |     580    |   88386    |   87813    |
|       from large pool |     246    |     250    |   52125    |   51879    |
|       from small pool |     327    |     500    |   36261    |   35934    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     264    |     969    |     744    |
|       from large pool |     192    |     208    |     894    |     702    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     113    |     193    |   32301    |   32188    |
|       from large pool |     107    |     185    |   26044    |   25937    |
|       from small pool |       6    |      12    |    6257    |    6251    |
|===========================================================================|

2022-03-21 20:10:15 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:16 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 7.93 GiB total capacity; 7.05 GiB already allocated; 44.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:10:16 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 148          |        cudaMalloc retries: 164       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7215 MB |    7335 MB |    1360 GB |    1353 GB |
|       from large pool |    7150 MB |    7270 MB |    1358 GB |    1351 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7215 MB |    7335 MB |    1360 GB |    1353 GB |
|       from large pool |    7150 MB |    7270 MB |    1358 GB |    1351 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7378 MB |    7426 MB |   32478 MB |   25100 MB |
|       from large pool |    7312 MB |    7360 MB |   32328 MB |   25016 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  166403 KB |    2032 MB |  462228 MB |  462065 MB |
|       from large pool |  165099 KB |    2031 MB |  460028 MB |  459867 MB |
|       from small pool |    1303 KB |       3 MB |    2199 MB |    2197 MB |
|---------------------------------------------------------------------------|
| Allocations           |     566    |     580    |   88828    |   88262    |
|       from large pool |     242    |     250    |   52468    |   52226    |
|       from small pool |     324    |     500    |   36360    |   36036    |
|---------------------------------------------------------------------------|
| Active allocs         |     566    |     580    |   88828    |   88262    |
|       from large pool |     242    |     250    |   52468    |   52226    |
|       from small pool |     324    |     500    |   36360    |   36036    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     264    |     970    |     745    |
|       from large pool |     192    |     208    |     895    |     703    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      17    |     193    |   32399    |   32382    |
|       from large pool |      13    |     185    |   26102    |   26089    |
|       from small pool |       4    |      12    |    6297    |    6293    |
|===========================================================================|

2022-03-21 20:10:16 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:17 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 7.93 GiB total capacity; 6.48 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:17 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 149          |        cudaMalloc retries: 165       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6638 MB |    7335 MB |    1369 GB |    1362 GB |
|       from large pool |    6573 MB |    7270 MB |    1367 GB |    1361 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6638 MB |    7335 MB |    1369 GB |    1362 GB |
|       from large pool |    6573 MB |    7270 MB |    1367 GB |    1361 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   32504 MB |   25100 MB |
|       from large pool |    7338 MB |    7360 MB |   32354 MB |   25016 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  784313 KB |    2032 MB |  465233 MB |  464467 MB |
|       from large pool |  782479 KB |    2031 MB |  463023 MB |  462259 MB |
|       from small pool |    1833 KB |       3 MB |    2210 MB |    2208 MB |
|---------------------------------------------------------------------------|
| Allocations           |     556    |     580    |   89264    |   88708    |
|       from large pool |     233    |     250    |   52805    |   52572    |
|       from small pool |     323    |     500    |   36459    |   36136    |
|---------------------------------------------------------------------------|
| Active allocs         |     556    |     580    |   89264    |   88708    |
|       from large pool |     233    |     250    |   52805    |   52572    |
|       from small pool |     323    |     500    |   36459    |   36136    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     264    |     971    |     745    |
|       from large pool |     193    |     208    |     896    |     703    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     132    |     193    |   32665    |   32533    |
|       from large pool |     125    |     185    |   26329    |   26204    |
|       from small pool |       7    |      12    |    6336    |    6329    |
|===========================================================================|

2022-03-21 20:10:17 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:17 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.93 GiB total capacity; 6.31 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:17 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 150          |        cudaMalloc retries: 166       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6457 MB |    7335 MB |    1378 GB |    1371 GB |
|       from large pool |    6393 MB |    7270 MB |    1376 GB |    1370 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6457 MB |    7335 MB |    1378 GB |    1371 GB |
|       from large pool |    6393 MB |    7270 MB |    1376 GB |    1370 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   32504 MB |   25100 MB |
|       from large pool |    7338 MB |    7360 MB |   32354 MB |   25016 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |     946 MB |    2032 MB |  468358 MB |  467412 MB |
|       from large pool |     944 MB |    2031 MB |  466137 MB |  465193 MB |
|       from small pool |       1 MB |       3 MB |    2220 MB |    2218 MB |
|---------------------------------------------------------------------------|
| Allocations           |     545    |     580    |   89683    |   89138    |
|       from large pool |     223    |     250    |   53127    |   52904    |
|       from small pool |     322    |     500    |   36556    |   36234    |
|---------------------------------------------------------------------------|
| Active allocs         |     545    |     580    |   89683    |   89138    |
|       from large pool |     223    |     250    |   53127    |   52904    |
|       from small pool |     322    |     500    |   36556    |   36234    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     264    |     971    |     745    |
|       from large pool |     193    |     208    |     896    |     703    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     139    |     193    |   32915    |   32776    |
|       from large pool |     133    |     185    |   26543    |   26410    |
|       from small pool |       6    |      12    |    6372    |    6366    |
|===========================================================================|

2022-03-21 20:10:17 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:18 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 6.66 GiB already allocated; 18.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:18 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 151          |        cudaMalloc retries: 167       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6787 MB |    7335 MB |    1387 GB |    1380 GB |
|       from large pool |    6722 MB |    7270 MB |    1385 GB |    1379 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6787 MB |    7335 MB |    1387 GB |    1380 GB |
|       from large pool |    6722 MB |    7270 MB |    1385 GB |    1379 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7404 MB |    7426 MB |   32504 MB |   25100 MB |
|       from large pool |    7338 MB |    7360 MB |   32354 MB |   25016 MB |
|       from small pool |      66 MB |     122 MB |     150 MB |      84 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  599022 KB |    2032 MB |  471031 MB |  470446 MB |
|       from large pool |  597626 KB |    2031 MB |  468800 MB |  468216 MB |
|       from small pool |    1396 KB |       3 MB |    2231 MB |    2229 MB |
|---------------------------------------------------------------------------|
| Allocations           |     572    |     580    |   90136    |   89564    |
|       from large pool |     246    |     250    |   53479    |   53233    |
|       from small pool |     326    |     500    |   36657    |   36331    |
|---------------------------------------------------------------------------|
| Active allocs         |     572    |     580    |   90136    |   89564    |
|       from large pool |     246    |     250    |   53479    |   53233    |
|       from small pool |     326    |     500    |   36657    |   36331    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     226    |     264    |     971    |     745    |
|       from large pool |     193    |     208    |     896    |     703    |
|       from small pool |      33    |      61    |      75    |      42    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     114    |     193    |   33133    |   33019    |
|       from large pool |     107    |     185    |   26727    |   26620    |
|       from small pool |       7    |      12    |    6406    |    6399    |
|===========================================================================|

2022-03-21 20:10:18 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:20 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 416.00 MiB (GPU 0; 7.93 GiB total capacity; 7.07 GiB already allocated; 118.44 MiB free; 7.13 GiB reserved in total by PyTorch)
2022-03-21 20:10:20 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 152          |        cudaMalloc retries: 169       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7207 MB |    7246 MB |    1399 GB |    1392 GB |
|       from large pool |    7143 MB |    7182 MB |    1397 GB |    1391 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7207 MB |    7246 MB |    1399 GB |    1392 GB |
|       from large pool |    7143 MB |    7182 MB |    1397 GB |    1391 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7304 MB |    7368 MB |   39450 MB |   32146 MB |
|       from large pool |    7238 MB |    7238 MB |   39236 MB |   31998 MB |
|       from small pool |      66 MB |     130 MB |     214 MB |     148 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   65869 KB |  136240 KB |  475410 MB |  475346 MB |
|       from large pool |   64491 KB |  135275 KB |  472974 MB |  472911 MB |
|       from small pool |    1377 KB |   10815 KB |    2436 MB |    2434 MB |
|---------------------------------------------------------------------------|
| Allocations           |     582    |     584    |   95048    |   94466    |
|       from large pool |     248    |     250    |   54696    |   54448    |
|       from small pool |     334    |     504    |   40352    |   40018    |
|---------------------------------------------------------------------------|
| Active allocs         |     582    |     584    |   95048    |   94466    |
|       from large pool |     248    |     250    |   54696    |   54448    |
|       from small pool |     334    |     504    |   40352    |   40018    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     245    |     277    |    1210    |     965    |
|       from large pool |     212    |     212    |    1103    |     891    |
|       from small pool |      33    |      65    |     107    |      74    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      27    |      47    |   34672    |   34645    |
|       from large pool |      16    |      18    |   27274    |   27258    |
|       from small pool |      11    |      41    |    7398    |    7387    |
|===========================================================================|

2022-03-21 20:10:20 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:20 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 402.00 MiB (GPU 0; 7.93 GiB total capacity; 6.78 GiB already allocated; 40.44 MiB free; 7.21 GiB reserved in total by PyTorch)
2022-03-21 20:10:20 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 153          |        cudaMalloc retries: 170       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6906 MB |    7246 MB |    1408 GB |    1401 GB |
|       from large pool |    6842 MB |    7182 MB |    1406 GB |    1400 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6906 MB |    7246 MB |    1408 GB |    1401 GB |
|       from large pool |    6842 MB |    7182 MB |    1406 GB |    1400 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7382 MB |    7382 MB |   39560 MB |   32178 MB |
|       from large pool |    7316 MB |    7316 MB |   39346 MB |   32030 MB |
|       from small pool |      66 MB |     130 MB |     214 MB |     148 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  453763 KB |  582907 KB |  477091 MB |  476648 MB |
|       from large pool |  452162 KB |  581058 KB |  474644 MB |  474203 MB |
|       from small pool |    1600 KB |   10815 KB |    2446 MB |    2445 MB |
|---------------------------------------------------------------------------|
| Allocations           |     582    |     584    |   95501    |   94919    |
|       from large pool |     248    |     250    |   55048    |   54800    |
|       from small pool |     334    |     504    |   40453    |   40119    |
|---------------------------------------------------------------------------|
| Active allocs         |     582    |     584    |   95501    |   94919    |
|       from large pool |     248    |     250    |   55048    |   54800    |
|       from small pool |     334    |     504    |   40453    |   40119    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     247    |     277    |    1213    |     966    |
|       from large pool |     214    |     214    |    1106    |     892    |
|       from small pool |      33    |      65    |     107    |      74    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     203    |     205    |   35026    |   34823    |
|       from large pool |     193    |     195    |   27589    |   27396    |
|       from small pool |      10    |      41    |    7437    |    7427    |
|===========================================================================|

2022-03-21 20:10:20 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:21 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 408.00 MiB (GPU 0; 7.93 GiB total capacity; 6.57 GiB already allocated; 350.44 MiB free; 6.91 GiB reserved in total by PyTorch)
2022-03-21 20:10:21 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 154          |        cudaMalloc retries: 171       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    6691 MB |    7246 MB |    1417 GB |    1410 GB |
|       from large pool |    6626 MB |    7182 MB |    1415 GB |    1409 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    6691 MB |    7246 MB |    1417 GB |    1410 GB |
|       from large pool |    6626 MB |    7182 MB |    1415 GB |    1409 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7072 MB |    7382 MB |   39560 MB |   32488 MB |
|       from large pool |    7006 MB |    7316 MB |   39346 MB |   32340 MB |
|       from small pool |      66 MB |     130 MB |     214 MB |     148 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  357060 KB |  614587 KB |  478306 MB |  477957 MB |
|       from large pool |  355416 KB |  612738 KB |  475848 MB |  475501 MB |
|       from small pool |    1644 KB |   10815 KB |    2457 MB |    2455 MB |
|---------------------------------------------------------------------------|
| Allocations           |     582    |     584    |   95954    |   95372    |
|       from large pool |     248    |     250    |   55400    |   55152    |
|       from small pool |     334    |     504    |   40554    |   40220    |
|---------------------------------------------------------------------------|
| Active allocs         |     582    |     584    |   95954    |   95372    |
|       from large pool |     248    |     250    |   55400    |   55152    |
|       from small pool |     334    |     504    |   40554    |   40220    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     242    |     277    |    1213    |     971    |
|       from large pool |     209    |     214    |    1106    |     897    |
|       from small pool |      33    |      65    |     107    |      74    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     116    |     207    |   35237    |   35121    |
|       from large pool |     106    |     196    |   27764    |   27658    |
|       from small pool |      10    |      41    |    7473    |    7463    |
|===========================================================================|

2022-03-21 20:10:21 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:22 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 7.93 GiB total capacity; 6.99 GiB already allocated; 14.44 MiB free; 7.23 GiB reserved in total by PyTorch)
2022-03-21 20:10:22 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 155          |        cudaMalloc retries: 173       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7154 MB |    7246 MB |    1426 GB |    1419 GB |
|       from large pool |    7089 MB |    7182 MB |    1424 GB |    1418 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7154 MB |    7246 MB |    1426 GB |    1419 GB |
|       from large pool |    7089 MB |    7182 MB |    1424 GB |    1418 GB |
|       from small pool |      64 MB |     120 MB |       1 GB |       1 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7408 MB |    7416 MB |   41750 MB |   34342 MB |
|       from large pool |    7342 MB |    7350 MB |   41534 MB |   34192 MB |
|       from small pool |      66 MB |     130 MB |     216 MB |     150 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  259653 KB |  614587 KB |  479446 MB |  479192 MB |
|       from large pool |  258259 KB |  612738 KB |  476975 MB |  476723 MB |
|       from small pool |    1393 KB |   10815 KB |    2471 MB |    2469 MB |
|---------------------------------------------------------------------------|
| Allocations           |     575    |     584    |   96395    |   95820    |
|       from large pool |     243    |     250    |   55742    |   55499    |
|       from small pool |     332    |     504    |   40653    |   40321    |
|---------------------------------------------------------------------------|
| Active allocs         |     575    |     584    |   96395    |   95820    |
|       from large pool |     243    |     250    |   55742    |   55499    |
|       from small pool |     332    |     504    |   40653    |   40321    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     235    |     277    |    1273    |    1038    |
|       from large pool |     202    |     216    |    1165    |     963    |
|       from small pool |      33    |      65    |     108    |      75    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     108    |     207    |   35457    |   35349    |
|       from large pool |      98    |     196    |   27946    |   27848    |
|       from small pool |      10    |      41    |    7511    |    7501    |
|===========================================================================|

2022-03-21 20:10:22 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2022-03-21 20:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-21 20:10:38 | INFO | fairseq.tasks.translation | example hypothesis: floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor floor
2022-03-21 20:10:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-21 20:10:48 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 184.00 MiB (GPU 0; 7.93 GiB total capacity; 4.71 GiB already allocated; 28.44 MiB free; 7.22 GiB reserved in total by PyTorch)
2022-03-21 20:10:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 156          |        cudaMalloc retries: 181       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    4824 MB |    7246 MB |    1663 GB |    1658 GB |
|       from large pool |    4758 MB |    7182 MB |    1658 GB |    1653 GB |
|       from small pool |      65 MB |     120 MB |       5 GB |       5 GB |
|---------------------------------------------------------------------------|
| Active memory         |    4824 MB |    7246 MB |    1663 GB |    1658 GB |
|       from large pool |    4758 MB |    7182 MB |    1658 GB |    1653 GB |
|       from small pool |      65 MB |     120 MB |       5 GB |       5 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7394 MB |    7416 MB |   56374 MB |   48980 MB |
|       from large pool |    7326 MB |    7350 MB |   56144 MB |   48818 MB |
|       from small pool |      68 MB |     130 MB |     230 MB |     162 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    2569 MB |    2861 MB |  692597 MB |  690027 MB |
|       from large pool |    2567 MB |    2859 MB |  686389 MB |  683821 MB |
|       from small pool |       2 MB |      10 MB |    6207 MB |    6205 MB |
|---------------------------------------------------------------------------|
| Allocations           |     345    |     584    |  190939    |  190594    |
|       from large pool |      44    |     250    |   64565    |   64521    |
|       from small pool |     301    |     504    |  126374    |  126073    |
|---------------------------------------------------------------------------|
| Active allocs         |     345    |     584    |  190939    |  190594    |
|       from large pool |      44    |     250    |   64565    |   64521    |
|       from small pool |     301    |     504    |  126374    |  126073    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      61    |     277    |    1352    |    1291    |
|       from large pool |      27    |     216    |    1237    |    1210    |
|       from small pool |      34    |      65    |     115    |      81    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      46    |     207    |   78836    |   78790    |
|       from large pool |      29    |     196    |   32632    |   32603    |
|       from small pool |      17    |      41    |   46204    |   46187    |
|===========================================================================|

2022-03-21 20:10:48 | WARNING | fairseq.trainer | ran out of memory in validation step, retrying batch
2022-03-21 20:10:49 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 7.93 GiB total capacity; 5.12 GiB already allocated; 28.44 MiB free; 7.22 GiB reserved in total by PyTorch)
2022-03-21 20:10:49 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 157          |        cudaMalloc retries: 182       |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    5215 MB |    7246 MB |    1670 GB |    1665 GB |
|       from large pool |    5149 MB |    7182 MB |    1665 GB |    1660 GB |
|       from small pool |      65 MB |     120 MB |       5 GB |       5 GB |
|---------------------------------------------------------------------------|
| Active memory         |    5215 MB |    7246 MB |    1670 GB |    1665 GB |
|       from large pool |    5149 MB |    7182 MB |    1665 GB |    1660 GB |
|       from small pool |      65 MB |     120 MB |       5 GB |       5 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7394 MB |    7416 MB |   56374 MB |   48980 MB |
|       from large pool |    7326 MB |    7350 MB |   56144 MB |   48818 MB |
|       from small pool |      68 MB |     130 MB |     230 MB |     162 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    2178 MB |    2861 MB |  699344 MB |  697166 MB |
|       from large pool |    2176 MB |    2859 MB |  693131 MB |  690954 MB |
|       from small pool |       2 MB |      10 MB |    6213 MB |    6211 MB |
|---------------------------------------------------------------------------|
| Allocations           |     363    |     584    |  191337    |  190974    |
|       from large pool |      60    |     250    |   64865    |   64805    |
|       from small pool |     303    |     504    |  126472    |  126169    |
|---------------------------------------------------------------------------|
| Active allocs         |     363    |     584    |  191337    |  190974    |
|       from large pool |      60    |     250    |   64865    |   64805    |
|       from small pool |     303    |     504    |  126472    |  126169    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      61    |     277    |    1352    |    1291    |
|       from large pool |      27    |     216    |    1237    |    1210    |
|       from small pool |      34    |      65    |     115    |      81    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      47    |     207    |   78951    |   78904    |
|       from large pool |      30    |     196    |   32743    |   32713    |
|       from small pool |      17    |      41    |   46208    |   46191    |
|===========================================================================|

Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 1039, in valid_step
    _loss, sample_size, logging_output = self.task.valid_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/translation.py", line 385, in valid_step
    bleu = self._inference_with_bleu(self.sequence_generator, sample, model)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/translation.py", line 477, in _inference_with_bleu
    gen_out = self.inference_step(generator, [model], sample, prefix_tokens=None)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 517, in inference_step
    return generator.generate(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/sequence_generator.py", line 187, in generate
    return self._generate(sample, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/sequence_generator.py", line 332, in _generate
    lprobs, avg_attn_scores = self.model.forward_decoder(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/sequence_generator.py", line 778, in forward_decoder
    decoder_out = model.decoder.forward(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 340, in extract_features_scriptable
    x, layer_attn, _ = layer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/transformer_layer.py", line 368, in forward
    x, attn = self.self_attn(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/multihead_attention.py", line 281, in forward
    v = torch.cat([prev_value, v], dim=1)
RuntimeError: CUDA out of memory. Tried to allocate 184.00 MiB (GPU 0; 7.93 GiB total capacity; 4.71 GiB already allocated; 28.44 MiB free; 7.22 GiB reserved in total by PyTorch)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 342, in train
    valid_losses, should_stop = validate_and_save(
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 429, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 499, in validate
    trainer.valid_step(sample)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 1054, in valid_step
    return self.valid_step(sample, raise_oom=True)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 1055, in valid_step
    raise e
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 1039, in valid_step
    _loss, sample_size, logging_output = self.task.valid_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/translation.py", line 383, in valid_step
    loss, sample_size, logging_output = super().valid_step(sample, model, criterion)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 502, in valid_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/kneser_ney_smoothing.py", line 158, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_base.py", line 150, in forward
    decoder_out = self.decoder(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 226, in forward
    x = self.output_layer(x)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 376, in output_layer
    return self.output_projection(features)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/linear.py", line 93, in forward
    return F.linear(input, self.weight, self.bias)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 1692, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 7.93 GiB total capacity; 5.12 GiB already allocated; 28.44 MiB free; 7.22 GiB reserved in total by PyTorch)
