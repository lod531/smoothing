Sender: LSF System <lsfadmin@eu-g3-066>
Subject: Job 210580071: <iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:22:01 2022
Job was executed on host(s) <eu-g3-066>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:22:23 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:22:23 2022
Terminated at Wed Mar 23 10:29:02 2022
Results reported at Wed Mar 23 10:29:02 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.05 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3986.71 sec.
    Max Memory :                                 5882 MB
    Average Memory :                             4702.98 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14118.00 MB
    Max Swap :                                   3 MB
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   3998 sec.
    Turnaround time :                            4021 sec.

The output (if any) follows:

2022-03-23 09:22:33 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.05, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.05, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:22:33 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:22:33 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:22:34 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:22:34 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:22:34 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:22:34 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:22:34 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:22:34 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:22:34 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:22:34 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:22:34 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:22:40 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:22:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:22:40 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:22:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:22:40 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:22:40 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:22:40 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 09:22:40 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 09:22:40 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:22:40 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:22:40 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:22:40 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:22:40 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:22:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:22:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:22:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:22:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:22:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:23:14 | INFO | train_inner | epoch 001:    104 / 157 loss=11.936, nll_loss=11.854, ppl=3701.02, wps=80271.7, ups=3.19, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.502, loss_scale=8, train_wall=33, gb_free=14, wall=35
2022-03-23 09:23:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:23:34 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 09:23:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:23:37 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:23:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:23:40 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,....
2022-03-23 09:23:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:23:43 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 09:23:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:23:46 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:23:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:23:51 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:23:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:23:56 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:23:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:24:01 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:24:09 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:24:11 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:24:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.194 | nll_loss 10.009 | ppl 1030.07 | bleu 0.02 | wps 4448.7 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:24:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:24:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:24:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.02) (writing took 1.7855676948092878 seconds)
2022-03-23 09:24:13 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:24:13 | INFO | train | epoch 001 | loss 11.473 | nll_loss 11.365 | ppl 2638.36 | wps 42750.6 | ups 1.7 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.801 | loss_scale 8 | train_wall 49 | gb_free 22.4 | wall 93
2022-03-23 09:24:13 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:24:28 | INFO | train_inner | epoch 002:     47 / 157 loss=10.342, nll_loss=10.17, ppl=1152.23, wps=34550.5, ups=1.36, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.397, loss_scale=8, train_wall=30, gb_free=14.7, wall=108
2022-03-23 09:24:59 | INFO | train_inner | epoch 002:    147 / 157 loss=9.583, nll_loss=9.351, ppl=652.9, wps=80262, ups=3.19, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=1.52, loss_scale=8, train_wall=31, gb_free=14, wall=139
2022-03-23 09:25:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:25:05 | INFO | fairseq.tasks.translation | example hypothesis: we we we we.
2022-03-23 09:25:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:25:09 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:25:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:25:13 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:25:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:25:18 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:25:23 | INFO | fairseq.tasks.translation | example hypothesis: and and we we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:25:29 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:25:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:25:34 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:25:40 | INFO | fairseq.tasks.translation | example hypothesis: and and we we we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:25:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:25:47 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:25:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:25:49 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:25:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.208 | nll_loss 8.925 | ppl 485.96 | bleu 0.01 | wps 3699.6 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 09:25:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:25:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 09:25:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 09:25:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 2 @ 310 updates, score 0.01) (writing took 0.8246967741288245 seconds)
2022-03-23 09:25:50 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:25:50 | INFO | train | epoch 002 | loss 9.716 | nll_loss 9.496 | ppl 721.85 | wps 40436.1 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.447 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 191
2022-03-23 09:25:51 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:25:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:26:19 | INFO | train_inner | epoch 003:     90 / 157 loss=9.236, nll_loss=8.963, ppl=498.9, wps=30890.4, ups=1.26, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=1.406, loss_scale=8, train_wall=30, gb_free=13.7, wall=219
2022-03-23 09:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:26:43 | INFO | fairseq.tasks.translation | example hypothesis: we the the the the the.
2022-03-23 09:26:43 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:26:46 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the.
2022-03-23 09:26:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:26:50 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the of the the of the the the the the of the of the.
2022-03-23 09:26:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:26:54 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, and it's's's's's, it's, and it's's's.
2022-03-23 09:26:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:26:59 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's's's's's's that that it's's's's's's's.
2022-03-23 09:26:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:27:04 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:27:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:27:10 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's's the the the the the the, and it's, it's, and the the the the the the the the the, and the the, and it's, and it's, and it's, and it's's's the the the the the the the the the the the the the the the,
2022-03-23 09:27:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:27:16 | INFO | fairseq.tasks.translation | example hypothesis: and we, we the the the the the the the the the the the the the the the the the the, and the, and the the, and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:27:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:27:24 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:27:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:27:26 | INFO | fairseq.tasks.translation | example hypothesis: and it's a a a a a a a a a a a a, and the a a a a a, and the the, the the the the the the the the the the the the, and the, and the, and the the the a a a a a a a a a a a a, and the, and the the the a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a, and the, and the, and the, and the, and the, and the, and the, and the the the the the the, and the the the the the the the the the the the the, and the the the the, and the, and the, and the the the the the the the the the the the the the the the the the the, and the the
2022-03-23 09:27:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:27:26 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.906 | nll_loss 8.585 | ppl 384.05 | bleu 0.17 | wps 3814.6 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.17
2022-03-23 09:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:27:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:27:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:27:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.17) (writing took 1.9240897400304675 seconds)
2022-03-23 09:27:28 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:27:28 | INFO | train | epoch 003 | loss 9.146 | nll_loss 8.863 | ppl 465.66 | wps 40501 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.5 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 288
2022-03-23 09:27:28 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:27:39 | INFO | train_inner | epoch 004:     33 / 157 loss=8.987, nll_loss=8.689, ppl=412.72, wps=31826.7, ups=1.25, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.529, loss_scale=8, train_wall=31, gb_free=13.9, wall=299
2022-03-23 09:28:10 | INFO | train_inner | epoch 004:    133 / 157 loss=8.75, nll_loss=8.433, ppl=345.64, wps=80209.2, ups=3.17, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.601, loss_scale=8, train_wall=31, gb_free=12.6, wall=330
2022-03-23 09:28:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:28:21 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world.
2022-03-23 09:28:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:28:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the world is the world is the world is the world.
2022-03-23 09:28:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:28:29 | INFO | fairseq.tasks.translation | example hypothesis: so we have to have to have to have to be the world.
2022-03-23 09:28:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:28:34 | INFO | fairseq.tasks.translation | example hypothesis: and there's a world, there's the world, there's a world.
2022-03-23 09:28:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:28:39 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not that we have.
2022-03-23 09:28:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:28:44 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world, and the world, and the world, and the world of the world in the world in the world of the world of the world.
2022-03-23 09:28:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:28:49 | INFO | fairseq.tasks.translation | example hypothesis: but there's the world, but there are are are are the world, but you are are are are are are are the world, but there are are are are are are are are the world, but there are are are are are are the world, but they are are are are are are are are are are are are are are are are are are are
2022-03-23 09:28:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:28:55 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can see the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can see to be be be be be be the world of the world of the world of the world of the world of the world of the world of the world of the world of the world.
2022-03-23 09:28:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:29:03 | INFO | fairseq.tasks.translation | example hypothesis: and the "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:29:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:29:05 | INFO | fairseq.tasks.translation | example hypothesis: so we have to have to have to be the world, which is the world of the world of the world of the world of the world of the world, which is the world of the world of the world of the world, which is the world, which is the world of the world of the world of the world, which is the world of the world of the world, which we have to have to do we have to have to have to have that we have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to be be be be be be to be be be be be be be be be be be be be be be be be be be be be be be be be to be to be be be be be be be be be be be be be be be be be be to be to be be be be be be be be be be be be be be be be be be be be be be be be be
2022-03-23 09:29:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:29:05 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 8.376 | nll_loss 8.014 | ppl 258.46 | bleu 0.89 | wps 3700.5 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.89
2022-03-23 09:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:29:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:29:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.89) (writing took 1.948868494015187 seconds)
2022-03-23 09:29:07 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:29:07 | INFO | train | epoch 004 | loss 8.756 | nll_loss 8.44 | ppl 347.3 | wps 39748.8 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.562 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 387
2022-03-23 09:29:08 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:29:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:29:31 | INFO | train_inner | epoch 005:     76 / 157 loss=8.488, nll_loss=8.151, ppl=284.32, wps=30270.8, ups=1.23, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.82, loss_scale=8, train_wall=30, gb_free=13.4, wall=412
2022-03-23 09:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:30:00 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be the world in the world.
2022-03-23 09:30:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:30:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the world is the world.
2022-03-23 09:30:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:30:07 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be the new new new new new new new new new new new new new new new.
2022-03-23 09:30:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:30:11 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world.
2022-03-23 09:30:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:30:14 | INFO | fairseq.tasks.translation | example hypothesis: and it's what we're going to do that we're going to do it.
2022-03-23 09:30:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:30:18 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world in the world in the world.
2022-03-23 09:30:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:30:21 | INFO | fairseq.tasks.translation | example hypothesis: but it's not not not not to be the world of the world of the world.
2022-03-23 09:30:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:30:25 | INFO | fairseq.tasks.translation | example hypothesis: so we can see that we can see the world of the world and we can see the world of the world of the world.
2022-03-23 09:30:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:30:29 | INFO | fairseq.tasks.translation | example hypothesis: and it's that we can say that we have to say that we can say that is the world of the world, "it's the world," it's the world, "it's the world." "" "
2022-03-23 09:30:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:30:31 | INFO | fairseq.tasks.translation | example hypothesis: so we're that we can be that we have to be the world that we can be the world of the world of the world that we can do that we have to be the world of the world that we have to be the world of the world of the world.
2022-03-23 09:30:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:30:31 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.991 | nll_loss 7.597 | ppl 193.57 | bleu 1.42 | wps 5248.8 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.42
2022-03-23 09:30:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 09:30:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:30:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:30:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.42) (writing took 1.9451239770278335 seconds)
2022-03-23 09:30:33 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:30:33 | INFO | train | epoch 005 | loss 8.297 | nll_loss 7.945 | ppl 246.41 | wps 45768.7 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.732 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 474
2022-03-23 09:30:34 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:30:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:40 | INFO | train_inner | epoch 006:     19 / 157 loss=8.173, nll_loss=7.81, ppl=224.37, wps=37161.8, ups=1.46, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.735, loss_scale=8, train_wall=30, gb_free=14.6, wall=480
2022-03-23 09:31:11 | INFO | train_inner | epoch 006:    119 / 157 loss=7.94, nll_loss=7.556, ppl=188.24, wps=80662.6, ups=3.19, wpb=25320.5, bsz=1021.9, num_updates=900, lr=0.0001125, gnorm=1.495, loss_scale=8, train_wall=31, gb_free=13.7, wall=511
2022-03-23 09:31:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:31:26 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world.
2022-03-23 09:31:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:31:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most most most of the most of the world.
2022-03-23 09:31:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:31:35 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new new new new new new new new new new new new new new new new new.
2022-03-23 09:31:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:31:39 | INFO | fairseq.tasks.translation | example hypothesis: there's a lot of the world, and it's a lot of the world.
2022-03-23 09:31:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:31:44 | INFO | fairseq.tasks.translation | example hypothesis: it's not not that we don't know that we're going to do it's going to do that we're going to do that we're going to do that we're going to do it's going to do it's going to do it
2022-03-23 09:31:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:31:49 | INFO | fairseq.tasks.translation | example hypothesis: and this is the people in the world of people in the world, in the world, in the world, in the world, in the world is the world of the world, in the world of the world, and people is the world, in the world of the world, in the world
2022-03-23 09:31:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:31:55 | INFO | fairseq.tasks.translation | example hypothesis: but if you're not going to be a lot of the world, but they're going to be not not going to be a lot of the world, but they're going to be a lot of the world, but they're going to be a lot of the world, but they're going to be a lot of the world, but they're going to
2022-03-23 09:31:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:32:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see that we're going to make the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, we can see the world, and we can see the world, we can see the world, we can see the world, we can see the world, and we can see the world, we can see the world,
2022-03-23 09:32:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:32:09 | INFO | fairseq.tasks.translation | example hypothesis: if you said, "" "it's no," "" "" it's no, "you know," you know, "you know," you know, "you know," you know, "" "it's no," it's no, "" it's no, "" "" "it's no," it's no, "" "" "" "" "" it's no, "it's no," "" "" "it's the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first" "" "" ""
2022-03-23 09:32:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:32:11 | INFO | fairseq.tasks.translation | example hypothesis: but if we think that we're going to be a lot of the world that we're going to think that we're going to think that we're going to be a lot of the world that we've been been been been going to be a lot of the world that we think that we've been been been been been been been been been been been been been going to be going to have to be going to be going to think that we're going to be a lot of the most of the world that we're going to be a lot of the world, but that we think that we've been been been been been been been been been been been been been going to be going to think that we're going to think that we're going to be a lot of the world, but it's going to be a lot of the world that we're going to be a lot of the world that we're going to be be the world, but it's going to think that we've been been been been been been been been been been been been been been going to be
2022-03-23 09:32:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:32:11 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.613 | nll_loss 7.176 | ppl 144.57 | bleu 1.7 | wps 3663.2 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.7
2022-03-23 09:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 09:32:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:32:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:32:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 6 @ 938 updates, score 1.7) (writing took 1.9573666588403285 seconds)
2022-03-23 09:32:13 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:32:13 | INFO | train | epoch 006 | loss 7.924 | nll_loss 7.539 | ppl 186.02 | wps 39632.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 1.591 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 573
2022-03-23 09:32:13 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:32:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:32:33 | INFO | train_inner | epoch 007:     62 / 157 loss=7.711, nll_loss=7.308, ppl=158.49, wps=30766.4, ups=1.22, wpb=25195.5, bsz=1022.5, num_updates=1000, lr=0.000125, gnorm=1.485, loss_scale=8, train_wall=30, gb_free=13.5, wall=593
2022-03-23 09:33:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:33:06 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 09:33:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:33:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the most idea of the most idea of the most idea.
2022-03-23 09:33:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:33:14 | INFO | fairseq.tasks.translation | example hypothesis: so these are new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 09:33:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:33:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a lot of life, and it's going to be going to be going to be going to be a lot of life.
2022-03-23 09:33:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:33:24 | INFO | fairseq.tasks.translation | example hypothesis: it's not what we're going to do is that we're going to do that we're going to do it's going to do that's going to do that we're going to do it's going to do it's not not not not
2022-03-23 09:33:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:33:30 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the people in the world, the world, and the world is the people in the people in the people, and the people in the world, and the world, for the world, and the world, and the most people in the world, and the world, people
2022-03-23 09:33:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:33:35 | INFO | fairseq.tasks.translation | example hypothesis: so, some of course, you're going to get a lot of the same way, but they're not not not not like it, but it, but they're going to be a lot of the way, but they're going to be able to be a lot of the same way, but it, but it, but they're going to be not
2022-03-23 09:33:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:33:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get a lot of the world, and we're going to get a lot of the world, and we can see that we can see the world, and the brain, and we can see the brain, and the world, and we can see the world, and the brain, and we can see that we can see the world, and the brain, and the brain can see that we can see the world, and then we can see
2022-03-23 09:33:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:49 | INFO | fairseq.tasks.translation | example hypothesis: ok: ":" well, you know, "you know," you know, "you're going to say," well, "you know," well, "you know," you know, "the first first first first first first first first first first first is," and then we're going to say, "well," you know, "you know," you know, "you know," you know, "you know," you know, "" the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first is, "" "" ""
2022-03-23 09:33:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:51 | INFO | fairseq.tasks.translation | example hypothesis: and so, it's a lot of the world that we're going to get the world that we're going to get a lot of the world, which is that we're going to be a lot of the world, which is that we're going to be able to be able to be a lot of the world, which is that we're going to be able to be able to be able to be a lot of the world, which is that we're going to be able to see the world, which is that we're going to be able to be able to be able to be a lot of the world, which is that we're going to be able to be a lot of the world, which is that we're going to be able to be a lot of the world, which is that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get
2022-03-23 09:33:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:51 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.277 | nll_loss 6.809 | ppl 112.14 | bleu 2.22 | wps 3640.8 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2.22
2022-03-23 09:33:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 09:33:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:33:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:33:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.22) (writing took 1.9466041042469442 seconds)
2022-03-23 09:33:53 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:33:53 | INFO | train | epoch 007 | loss 7.594 | nll_loss 7.182 | ppl 145.26 | wps 39515.8 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 1.445 | loss_scale 8 | train_wall 48 | gb_free 14.5 | wall 673
2022-03-23 09:33:53 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:33:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:55 | INFO | train_inner | epoch 008:      5 / 157 loss=7.517, nll_loss=7.099, ppl=137.14, wps=30416.3, ups=1.22, wpb=25002.6, bsz=1042.3, num_updates=1100, lr=0.0001375, gnorm=1.455, loss_scale=8, train_wall=30, gb_free=13.8, wall=675
2022-03-23 09:34:26 | INFO | train_inner | epoch 008:    105 / 157 loss=7.281, nll_loss=6.843, ppl=114.81, wps=80985.5, ups=3.22, wpb=25137.5, bsz=1075.3, num_updates=1200, lr=0.00015, gnorm=1.419, loss_scale=8, train_wall=31, gb_free=14.2, wall=706
2022-03-23 09:34:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:46 | INFO | fairseq.tasks.translation | example hypothesis: we went in this room.
2022-03-23 09:34:46 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:34:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most most most of the most most most most most most most most most most most most of the most most most most most.
2022-03-23 09:34:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:34:56 | INFO | fairseq.tasks.translation | example hypothesis: these are going to get new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new york
2022-03-23 09:34:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:35:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, for example, there's a example, and it's going to be where you're going to see where where you're going to be going to see where where you're going to
2022-03-23 09:35:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:35:06 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not going to do that we're going to do that's going to do that's going to do what's going to do.
2022-03-23 09:35:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:35:11 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, as as as as as as as as people for people for the people in the people for the people in the people, for the people, for the people in the people in the people, for the people, for the people, for the people, for people in the people
2022-03-23 09:35:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:35:16 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of some of some of some of these things, but it's not the same time, but if you're not a lot of the same time, but it's not the same time, but it doesn't have a lot of the same time, but it doesn't have a lot of the same time, but it's not not
2022-03-23 09:35:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:35:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to make the way that we can see that we can see that we can see that we can see the brain, and then we can use the brain, and then we can use the brain, and then we can see the brain.
2022-03-23 09:35:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:35:29 | INFO | fairseq.tasks.translation | example hypothesis: well,: one of the world, it's going to say, "it's going to say," if it's a lot of the world, "you know," it's going to say, "it's the first first thing," it's going to say, "it's going to say," you know, "well," it's going to say, "it's going to say," you know, "it's the first first first first first first first first first first first first first first first first first first first first first first first first first thing," it's the first first first first first first first first first first first first first first first first first first first first first first thing, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "" it's
2022-03-23 09:35:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:35:32 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's going to be a lot of the same time that we're going to get the same time, if we're going to get a little little bit that we're going to make a lot of the world, if we're going to make a little bit that we're going to make a little bit that we're going to get to make a lot of the way that we're going to get to make a little bit of the way that we're going to make the same way that we're going to make the same way that we're going to make a little bit that we're going to make a little bit that we're going to make a little bit that we're going to make a little bit that we're going to make a lot of the same way that we're going to be able to make a little bit that we're going to be able to make a lot of the same way that we're going to be able to be able to get to get to be able to make a lot of the way that we're going to
2022-03-23 09:35:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:35:32 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.988 | nll_loss 6.498 | ppl 90.36 | bleu 3.36 | wps 3608.2 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 3.36
2022-03-23 09:35:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 09:35:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:35:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 8 @ 1252 updates, score 3.36) (writing took 1.9469882338307798 seconds)
2022-03-23 09:35:34 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:35:34 | INFO | train | epoch 008 | loss 7.309 | nll_loss 6.873 | ppl 117.21 | wps 39255.2 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 1.424 | loss_scale 8 | train_wall 48 | gb_free 13.6 | wall 774
2022-03-23 09:35:34 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:49 | INFO | train_inner | epoch 009:     48 / 157 loss=7.203, nll_loss=6.757, ppl=108.19, wps=30898.5, ups=1.2, wpb=25702.9, bsz=1011, num_updates=1300, lr=0.0001625, gnorm=1.36, loss_scale=8, train_wall=31, gb_free=14.5, wall=790
2022-03-23 09:36:20 | INFO | train_inner | epoch 009:    148 / 157 loss=7.065, nll_loss=6.607, ppl=97.44, wps=79706.7, ups=3.22, wpb=24780.2, bsz=958.6, num_updates=1400, lr=0.000175, gnorm=1.382, loss_scale=8, train_wall=31, gb_free=13.8, wall=821
2022-03-23 09:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:36:27 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the middle of the top.
2022-03-23 09:36:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:36:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most of the most most most most most most most most most most most here.
2022-03-23 09:36:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:36:35 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new new new new new york are two two technologies.
2022-03-23 09:36:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:36:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's the ooooooan, where you're going to see where you're going to see where it's going to be going to be going to go.
2022-03-23 09:36:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:36:45 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just just a few few years, and what's going to do is what are all of his life.
2022-03-23 09:36:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:36:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the water, like people like people like people for the people, for the most people, and the most people in the most people in the most people in the most people, and the most people in the most people in the most people in the most people, and it's got a
2022-03-23 09:36:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:36:55 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of some of the water, but if you don't have to see it, but if you don't have to see it, and if you don't see it, it doesn't have the same time, you don't see it's not have the same time.
2022-03-23 09:36:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:37:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can see the data that we can see that we can see that we can see the brain and see that we can see a lot of the brain, and then we can see that we can see the brain can see the brain, and the brain can see the brain, and we can see that we can see that we can see that can see the brain can see that can see the brain can see the brain,
2022-03-23 09:37:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:37:09 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the other people, and it's interesting, and it's going to say, "well," and then we're going to say, "and then you know," well, "well," well, "you know," well, "well," well, "well," well, "well," you know, "well," well, "you know," well, "well," well, "well," you know, "well," well, "you know," well, "well," well, "well," well, "well," well, "well," well, "well," well, "you know," well, "well," well, "well," well, "you know," it is, "you know," you know, "you know," ""
2022-03-23 09:37:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:37:11 | INFO | fairseq.tasks.translation | example hypothesis: so, in fact, it's still still still more than the last year, and if we have a lot of the world, and if we're going to do that we're going to have a lot of the world that we're going to do that we're going to have a lot of the world, we're going to be able to do that we're going to do that we're going to do that we're going to have a lot of the world, which is a lot of the world, which is a lot of the world that we're going to be able to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to have a lot of the world, which is a lot of us that we're going to be able to be able to be able to be able to do that we're going to do that we're going to have a lot of the world, and if we're going to have a lot of the world
2022-03-23 09:37:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:37:11 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.641 | nll_loss 6.116 | ppl 69.36 | bleu 4.81 | wps 3695.2 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 4.81
2022-03-23 09:37:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 09:37:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:37:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:37:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 9 @ 1409 updates, score 4.81) (writing took 1.9580263821408153 seconds)
2022-03-23 09:37:13 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:37:13 | INFO | train | epoch 009 | loss 7.036 | nll_loss 6.576 | ppl 95.44 | wps 39583 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 1.348 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 874
2022-03-23 09:37:14 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:37:43 | INFO | train_inner | epoch 010:     91 / 157 loss=6.775, nll_loss=6.295, ppl=78.51, wps=30580.4, ups=1.22, wpb=25166.5, bsz=1026, num_updates=1500, lr=0.0001875, gnorm=1.223, loss_scale=8, train_wall=31, gb_free=14.5, wall=903
2022-03-23 09:38:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:38:07 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppon the end of the end.
2022-03-23 09:38:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:38:10 | INFO | fairseq.tasks.translation | example hypothesis: that's the right. i know, most of most of you know.
2022-03-23 09:38:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:38:14 | INFO | fairseq.tasks.translation | example hypothesis: new york are going to be two new york.
2022-03-23 09:38:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:38:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an chinese food, where they're going to go and get up.
2022-03-23 09:38:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:38:22 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just a few few years on his head, and what's going to do.
2022-03-23 09:38:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:38:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamao of people who have been used to get the number of people, and the number of the number of the number of people.
2022-03-23 09:38:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:38:30 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of them are going to go through the brain, but if you don't need to get it, but if you need the energy, if you need the energy, you need to get the energy, you need to get the energy, and the energy.
2022-03-23 09:38:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can see this.
2022-03-23 09:38:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:41 | INFO | fairseq.tasks.translation | example hypothesis: rb: one of the reasons that it's interesting for me, and i'm going to show you that there's a little bit of the first time, and then we've got to go to the first time, and then you know, and then you know that you know that you've got to talk about that you know, and then you've got to tell you know, and then you know, you know, and then you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know
2022-03-23 09:38:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:44 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still still still the mother, and the way we've got a little bit of our work, when we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get
2022-03-23 09:38:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:44 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.289 | nll_loss 5.733 | ppl 53.18 | bleu 7.91 | wps 4432.6 | wpb 17862.2 | bsz 728.3 | num_updates 1566 | best_bleu 7.91
2022-03-23 09:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1566 updates
2022-03-23 09:38:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:38:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:38:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 10 @ 1566 updates, score 7.91) (writing took 1.9855607990175486 seconds)
2022-03-23 09:38:46 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:38:46 | INFO | train | epoch 010 | loss 6.702 | nll_loss 6.215 | ppl 74.29 | wps 42845.7 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 1566 | lr 0.00019575 | gnorm 1.277 | loss_scale 8 | train_wall 48 | gb_free 13.8 | wall 966
2022-03-23 09:38:46 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:57 | INFO | train_inner | epoch 011:     34 / 157 loss=6.6, nll_loss=6.105, ppl=68.81, wps=33625.2, ups=1.35, wpb=24827.9, bsz=1010.3, num_updates=1600, lr=0.0002, gnorm=1.351, loss_scale=8, train_wall=30, gb_free=14.9, wall=977
2022-03-23 09:39:28 | INFO | train_inner | epoch 011:    134 / 157 loss=6.388, nll_loss=5.876, ppl=58.72, wps=81678.4, ups=3.2, wpb=25502, bsz=1063, num_updates=1700, lr=0.0002125, gnorm=1.366, loss_scale=8, train_wall=31, gb_free=14.5, wall=1008
2022-03-23 09:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:39 | INFO | fairseq.tasks.translation | example hypothesis: we had this ppppon the top of the top.
2022-03-23 09:39:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:39:43 | INFO | fairseq.tasks.translation | example hypothesis: so this is the mao, most of most of most of most of the most of the most of you know.
2022-03-23 09:39:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:39:47 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be able to be two new new york.
2022-03-23 09:39:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:39:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are the chinese chinese chinese chinese, where they're going to be able to be able to be able.
2022-03-23 09:39:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:39:54 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just a few few different head on his head, and what's going on on your head.
2022-03-23 09:39:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:39:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamace of people for the number of animals, and the number of the number of the number of the number.
2022-03-23 09:39:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:40:02 | INFO | fairseq.tasks.translation | example hypothesis: first of some of these are some of the cans, but if you don't need to use the energy, it doesn't need to have the energy energy, and the energy.
2022-03-23 09:40:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:40:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this structure, we can use a structure that can be able to be able to be able to create a structure of the structure, and the structure of the structure of the structure that is all the structure.
2022-03-23 09:40:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:40:11 | INFO | fairseq.tasks.translation | example hypothesis: 18th: one of the interesting interesting interesting, and it's going to be for me that "oh," you know, "well," you know, "you know," well, "you know," you know, "you're going to say," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "well," well, "well," well, "well," you know, "well," well, "well," well, "well," you know, "well," you know, "you know," you know, "well," well, "well," you know, "well," well, "well," well, "well," a
2022-03-23 09:40:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:40:13 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and a lot of work that we were going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:40:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:40:13 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.039 | nll_loss 5.456 | ppl 43.88 | bleu 10.35 | wps 4825.1 | wpb 17862.2 | bsz 728.3 | num_updates 1723 | best_bleu 10.35
2022-03-23 09:40:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1723 updates
2022-03-23 09:40:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:40:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:40:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 11 @ 1723 updates, score 10.35) (writing took 1.9597133169882 seconds)
2022-03-23 09:40:15 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:40:15 | INFO | train | epoch 011 | loss 6.438 | nll_loss 5.929 | ppl 60.93 | wps 44221 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 1723 | lr 0.000215375 | gnorm 1.362 | loss_scale 8 | train_wall 48 | gb_free 14.1 | wall 1055
2022-03-23 09:40:15 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:40:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:39 | INFO | train_inner | epoch 012:     77 / 157 loss=6.269, nll_loss=5.746, ppl=53.66, wps=34965.1, ups=1.4, wpb=24985.4, bsz=970.8, num_updates=1800, lr=0.000225, gnorm=1.288, loss_scale=8, train_wall=30, gb_free=14, wall=1080
2022-03-23 09:41:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:41:08 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppm in the clinics.
2022-03-23 09:41:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:41:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the monha, ha, most of most of most of most of the most of the most.
2022-03-23 09:41:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:41:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to get new orororing.
2022-03-23 09:41:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:41:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese chinese chinese chinese, where they're going to go with a pop.
2022-03-23 09:41:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:41:24 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just going to understand a few different cell on his head on his head, and all of his mind.
2022-03-23 09:41:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:41:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamace of people, for example, the number of animals, and this is a number of animals that has been created in the coliiiiiiiiiiiiiiiiiiiiiiiii
2022-03-23 09:41:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:41:32 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magic of the color, but if you don't need to use the energy, if you don't need your energy, and you need to need your energy, and you need to need the energy.
2022-03-23 09:41:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this structure, we can start to start with a traditional traditional structure, we can start able to start with a huge structure of the structure, and all the structure of the structure of the structure, and all the structure of the structure.
2022-03-23 09:41:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:40 | INFO | fairseq.tasks.translation | example hypothesis: david: one of the reasons, and it's interesting for me to be able to be working for tedtedson, "yes," well, "if we're going to say," and then we're going to say that the best time is going to tell you, "and then we're going to say that the best time."
2022-03-23 09:41:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:42 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, the fact, the mother is still a lot of design, and we had to use a lot of work on the ground that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:41:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:42 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.677 | nll_loss 5.054 | ppl 33.21 | bleu 11.75 | wps 4724.9 | wpb 17862.2 | bsz 728.3 | num_updates 1880 | best_bleu 11.75
2022-03-23 09:41:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1880 updates
2022-03-23 09:41:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:41:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:41:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 12 @ 1880 updates, score 11.75) (writing took 2.021726535167545 seconds)
2022-03-23 09:41:45 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:41:45 | INFO | train | epoch 012 | loss 6.116 | nll_loss 5.58 | ppl 47.85 | wps 44058.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 1880 | lr 0.000235 | gnorm 1.255 | loss_scale 8 | train_wall 48 | gb_free 14.1 | wall 1145
2022-03-23 09:41:45 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:51 | INFO | train_inner | epoch 013:     20 / 157 loss=5.99, nll_loss=5.444, ppl=43.53, wps=34941, ups=1.39, wpb=25105.5, bsz=1045.6, num_updates=1900, lr=0.0002375, gnorm=1.301, loss_scale=8, train_wall=30, gb_free=14.2, wall=1151
2022-03-23 09:42:23 | INFO | train_inner | epoch 013:    120 / 157 loss=5.86, nll_loss=5.3, ppl=39.4, wps=80467.6, ups=3.18, wpb=25276.1, bsz=1044.4, num_updates=2000, lr=0.00025, gnorm=1.232, loss_scale=8, train_wall=31, gb_free=14.9, wall=1183
2022-03-23 09:42:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:38 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppppon clinics.
2022-03-23 09:42:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:42:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the new line of doha ha ha, most of most of the most.
2022-03-23 09:42:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:42:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new ororores of the new orores.
2022-03-23 09:42:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:42:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food food, where they're going to eat and pppace.
2022-03-23 09:42:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:42:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a couple of electroelectrodes on his head, and what all of his thoughts are on the mind.
2022-03-23 09:42:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:42:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamace of people who grew up to the ability of animals, and this is a number of animals for the most important, and that has become become a conconconconconconviction.
2022-03-23 09:42:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:43:01 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of the color of magnetic lines, but it doesn't be able to move the alalalalalalalalalalalalalalty energy, if you need to move the energy energy energy.
2022-03-23 09:43:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:43:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information information that we can see the reflection of this traditional traditional traditional traditional traditional, we can start to start with a big form of the shape of the structure and the information of the information.
2022-03-23 09:43:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and interesting for me to be here for tedtedtedson... yes, "yes," oh, "if we said," if you're going to say, "and then you're going to tell you," the best time, "if you're going to tell you're going to have a lot of you're going to be working with you're going to be working with you're going to be working with a lot of you're going to be working with a lot of you're going to be working with a lot of you're going to be working on on the future,"
2022-03-23 09:43:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:43:12 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the most important invention of the invention, and a big work on our airplane, we've had to see that if we had to be a unique system, it was able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:43:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:43:12 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 5.42 | nll_loss 4.768 | ppl 27.25 | bleu 13.95 | wps 4826.3 | wpb 17862.2 | bsz 728.3 | num_updates 2037 | best_bleu 13.95
2022-03-23 09:43:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2037 updates
2022-03-23 09:43:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:43:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:43:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 13 @ 2037 updates, score 13.95) (writing took 1.9674259033054113 seconds)
2022-03-23 09:43:14 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:43:14 | INFO | train | epoch 013 | loss 5.842 | nll_loss 5.282 | ppl 38.9 | wps 44296.5 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2037 | lr 0.000254625 | gnorm 1.244 | loss_scale 8 | train_wall 48 | gb_free 13.5 | wall 1234
2022-03-23 09:43:14 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:43:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:34 | INFO | train_inner | epoch 014:     63 / 157 loss=5.699, nll_loss=5.126, ppl=34.93, wps=35048.2, ups=1.4, wpb=24981.2, bsz=975.8, num_updates=2100, lr=0.0002625, gnorm=1.194, loss_scale=8, train_wall=31, gb_free=14.7, wall=1254
2022-03-23 09:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:44:07 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppon clinic in the clinics.
2022-03-23 09:44:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:44:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha ha, most of the most of the most of you know here.
2022-03-23 09:44:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:44:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create two new applications.
2022-03-23 09:44:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:44:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where they're going to eat legs with legs, and they're going to be able to get it.
2022-03-23 09:44:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:44:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head, and understand what all the thoughts are in the way.
2022-03-23 09:44:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:44:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamage of responsibility, the responsibility of responsibility grew grew up to the number of animals, and this has become become a conservation.
2022-03-23 09:44:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:44:30 | INFO | fairseq.tasks.translation | example hypothesis: first first, some of the magnetic magnetic lines in the field, but if you don't need to move the alalalalalalalalable energy, and so the alalalable.
2022-03-23 09:44:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection comes from this reflection, we can start able to start with a traditional form of the structure, and the whole structure of the structure.
2022-03-23 09:44:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me for tedtedwomen, "when you're working with the best revolution, and then we're going to tell you," when we've got to tell you. "
2022-03-23 09:44:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:38 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention, and a big design part of the design, when you're able to see that we had to create a unique system, to be able to be able to be able to be able to be able to be able.
2022-03-23 09:44:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:38 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 5.358 | nll_loss 4.682 | ppl 25.67 | bleu 15.63 | wps 5232.5 | wpb 17862.2 | bsz 728.3 | num_updates 2194 | best_bleu 15.63
2022-03-23 09:44:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2194 updates
2022-03-23 09:44:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:44:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:44:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 14 @ 2194 updates, score 15.63) (writing took 1.9712255960330367 seconds)
2022-03-23 09:44:40 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:44:40 | INFO | train | epoch 014 | loss 5.547 | nll_loss 4.96 | ppl 31.13 | wps 45561.9 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 2194 | lr 0.00027425 | gnorm 1.172 | loss_scale 8 | train_wall 48 | gb_free 13.8 | wall 1321
2022-03-23 09:44:41 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:44:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:43 | INFO | train_inner | epoch 015:      6 / 157 loss=5.434, nll_loss=4.838, ppl=28.6, wps=37029.6, ups=1.45, wpb=25546.6, bsz=1077.7, num_updates=2200, lr=0.000275, gnorm=1.119, loss_scale=8, train_wall=31, gb_free=14.1, wall=1323
2022-03-23 09:45:14 | INFO | train_inner | epoch 015:    106 / 157 loss=5.285, nll_loss=4.675, ppl=25.54, wps=80692.2, ups=3.2, wpb=25207.9, bsz=1066.4, num_updates=2300, lr=0.0002875, gnorm=1.183, loss_scale=8, train_wall=31, gb_free=14.7, wall=1354
2022-03-23 09:45:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:34 | INFO | fairseq.tasks.translation | example hypothesis: we made this ppills in the clinic clinic.
2022-03-23 09:45:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:45:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha ha, probably most of you know here.
2022-03-23 09:45:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:45:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to be able to make two new features.
2022-03-23 09:45:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:45:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese chinese food, where happy legs are and salt.
2022-03-23 09:45:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:45:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand what all its thoughts are on the mind.
2022-03-23 09:45:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:45:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamake, the responsibility of responsibility grew up, grew up the number of animals, and this is a number of conservaiiiiiiiiiiibia.
2022-03-23 09:45:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:45:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloop of magnetic magnetic lines, but it doesn't like the alalalaluminum, if you don't need your energy energy, you need your energy, and you need to move your energy, and you need your energy.
2022-03-23 09:45:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:46:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection comes from this reflection, we can start with a traditional face that can start able to start able to start able to start able to begin with the shape of the shape of the information, and the whole structure of the structure of the structure, and the information that we're going to create a structure.
2022-03-23 09:46:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:46:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and interesting to make me here at tedtedwomen, is that when it was the best thing that the best thing that someone said, "the best thing that we say," when we've been working with you're working with a silent revolution. "
2022-03-23 09:46:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:09 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, unfortunately, the mother is still the invention of the invention, and a lot of design design that we've got to solve the airplane on our airplane, that we had to solve a unique result of the problems that we had to solve a unique source of the ground, or to be able to see that if you were able to use the power of a reducing, it was able to see that if you're able to see that we were able to use, it is to use, it, it's a certain amount of the most specific, or a certain source of the most effective, or a whole network of the power of the power, it was actually be able to see that we're able to use, it, it was able to use, or to see that if you're able to see that it was actually be able to see that we're able to see that it was able to be able to be able to be able to be able to use, it, it's a very specific, it, it's a lot of a lot
2022-03-23 09:46:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:09 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.936 | nll_loss 4.225 | ppl 18.7 | bleu 17.61 | wps 4576.5 | wpb 17862.2 | bsz 728.3 | num_updates 2351 | best_bleu 17.61
2022-03-23 09:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2351 updates
2022-03-23 09:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:46:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 15 @ 2351 updates, score 17.61) (writing took 1.9838893758133054 seconds)
2022-03-23 09:46:11 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:46:11 | INFO | train | epoch 015 | loss 5.314 | nll_loss 4.706 | ppl 26.09 | wps 43370.5 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 2351 | lr 0.000293875 | gnorm 1.164 | loss_scale 8 | train_wall 48 | gb_free 13.8 | wall 1412
2022-03-23 09:46:12 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:28 | INFO | train_inner | epoch 016:     49 / 157 loss=5.3, nll_loss=4.687, ppl=25.77, wps=34635.8, ups=1.36, wpb=25434.7, bsz=926.5, num_updates=2400, lr=0.0003, gnorm=1.143, loss_scale=8, train_wall=31, gb_free=13.1, wall=1428
2022-03-23 09:46:58 | INFO | train_inner | epoch 016:    149 / 157 loss=4.987, nll_loss=4.348, ppl=20.37, wps=80142.1, ups=3.25, wpb=24694, bsz=1031.8, num_updates=2500, lr=0.0003125, gnorm=1.014, loss_scale=8, train_wall=30, gb_free=14.7, wall=1459
2022-03-23 09:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in clinic clinics.
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:47:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 09:47:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:47:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golsticks.
2022-03-23 09:47:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:47:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs and salt.
2022-03-23 09:47:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:47:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electroelectroelectrodes on its head, and understand what all its thoughts are on the head.
2022-03-23 09:47:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:47:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamabia, the responsibility grew up for the wild number of animals. and that's a foundation for conservation for conservation.
2022-03-23 09:47:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:47:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloose of magnetic lines, but the sullant doesn't move if you don't need your energy, if you don't need your energy, and you need your energy.
2022-03-23 09:47:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start with traditional face, we can start able to start able to start able to start with a traditional face of the face of the face, and the shape of the information that gives it all the structure through the structure and the structure.
2022-03-23 09:47:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and measure me here for tedtalk is that women's... "
2022-03-23 09:47:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:37 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of invention, and one part of the design that we're on our plane, which was a result of the plane that we had to solve a unique result that we had to solve it, and if you were all the way to see, it's a very specific system, it's a very specific system that we're able to see, it's actually available to see, and if you're able to see, it's the most effective, it's a very specific, if you're able to see, it's the engine, it's the most effective, it's a very specific system, it's the engine, and if you're going to see that we're going to see, it would be able to see, it would be able to see, it's a very specific, it would be able to see that we're able to see that it's a very specific, it's a very specific, it's available to see, and if you have to see, it would be able to see, it's a
2022-03-23 09:47:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:37 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.819 | nll_loss 4.103 | ppl 17.18 | bleu 15.56 | wps 5033.6 | wpb 17862.2 | bsz 728.3 | num_updates 2508 | best_bleu 17.61
2022-03-23 09:47:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2508 updates
2022-03-23 09:47:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 09:47:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 09:47:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 16 @ 2508 updates, score 15.56) (writing took 0.8828658768907189 seconds)
2022-03-23 09:47:38 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:47:38 | INFO | train | epoch 016 | loss 5.054 | nll_loss 4.421 | ppl 21.42 | wps 45627.9 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 2508 | lr 0.0003135 | gnorm 1.084 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 1498
2022-03-23 09:47:38 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:47:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:48:07 | INFO | train_inner | epoch 017:     92 / 157 loss=4.868, nll_loss=4.219, ppl=18.62, wps=36613.5, ups=1.45, wpb=25239.3, bsz=1052.8, num_updates=2600, lr=0.000325, gnorm=1.048, loss_scale=8, train_wall=31, gb_free=13.8, wall=1528
2022-03-23 09:48:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:31 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic clinic clinic in the clinic clinic.
2022-03-23 09:48:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:48:36 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you know here.
2022-03-23 09:48:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:48:40 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golsticks of the two new scores that are going to get rid of the two new lows.
2022-03-23 09:48:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:48:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food food, where happy legs are going to be salt with salt and fat.
2022-03-23 09:48:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:48:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just take a few electrodes on his head and understand what all its thoughts are on the top.
2022-03-23 09:48:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the max, as people took the responsibility for the wild life, the number of animals, and this is a basis of conservation in namibia.
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:48:56 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloose of magnetic field, but the sualalalalalalaly doesn't move your energy, and so you need some of the way that you need to do.
2022-03-23 09:48:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:49:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start to start with a traditional face of the face, and the shape of the shape, and the information is through the structure, and all the structure of the structure, the structure of the structure, and all the structure, the structure, the structure is coming out of this reflection, and all the structure is coming out of this reflection of this reflection, and the structure,
2022-03-23 09:49:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:49:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and you know, "for me, for tedwomen, is that when you say," you know, "you know, you know, you know, you know, you know, you know, you know, you know, women," and you know, you're working on this table, "and then," you know, you know, you know, you know, you know, you know, it's a matter, "you're going to have a lot of you're going to have a lot of women," and you're going to support, "and you know," -- and you know, "-- and you know, it's a silly," -- and you know, "you're going to have a lot of you know," and you know, "you know, you know," you know,
2022-03-23 09:49:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:49:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the design, and a big part of the design work on our airplane, is that we had to solve the unique problems that we had to solve the problems of the ground, and if you can see that it's all the way we have to be connected to a fluid on the ground, or the engine, it is to see that the engine, or the engine, it's the engine, or the engine, or that if you're all the engine, it's a lot of us can use of the engine, you can use of the engine, you can use of the engine, you can use of the engine, or the engine, or that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that the engine, you're going to see that we're going to see that the engine, or the engine, or a lot of a lot of a lot of the engine, or a lot of the engine
2022-03-23 09:49:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:49:10 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.656 | nll_loss 3.91 | ppl 15.03 | bleu 17.91 | wps 4225.5 | wpb 17862.2 | bsz 728.3 | num_updates 2665 | best_bleu 17.91
2022-03-23 09:49:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2665 updates
2022-03-23 09:49:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:49:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:49:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 17 @ 2665 updates, score 17.91) (writing took 2.021533804014325 seconds)
2022-03-23 09:49:12 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:49:12 | INFO | train | epoch 017 | loss 4.865 | nll_loss 4.214 | ppl 18.55 | wps 41829.6 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 2665 | lr 0.000333125 | gnorm 1.075 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 1593
2022-03-23 09:49:13 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:49:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:24 | INFO | train_inner | epoch 018:     35 / 157 loss=4.813, nll_loss=4.155, ppl=17.81, wps=32953.2, ups=1.31, wpb=25247.6, bsz=1001.6, num_updates=2700, lr=0.0003375, gnorm=1.094, loss_scale=8, train_wall=30, gb_free=13.7, wall=1604
2022-03-23 09:49:55 | INFO | train_inner | epoch 018:    135 / 157 loss=4.646, nll_loss=3.975, ppl=15.72, wps=79705, ups=3.21, wpb=24835.3, bsz=1025.2, num_updates=2800, lr=0.00035, gnorm=0.97, loss_scale=8, train_wall=31, gb_free=13.6, wall=1635
2022-03-23 09:50:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:50:06 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic.
2022-03-23 09:50:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:50:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-23 09:50:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:50:13 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be able to create new goldicks of the two new pigs.
2022-03-23 09:50:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:50:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are being involved with salsalz and fat.
2022-03-23 09:50:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:50:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to put some electrodes on his head and understand exactly what all its thoughts are on the way.
2022-03-23 09:50:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:50:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, like the people who grew up for the wild, grew up the number of wild animals, and this is a foundation of conservation in namibia.
2022-03-23 09:50:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:50:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some blooding of magnetic field, but the superconductor may not be able to move if you don't need energy, your energy, and so that's how the sulength of magnetic field is.
2022-03-23 09:50:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start with the big face of the face and the form of the interfaces, and the shape of the information that's all the structure.
2022-03-23 09:50:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here for tedwomen, is that... "well, when we're working on the best time."
2022-03-23 09:50:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of invention, and a great part of design work that we're going to see in our plane, and it's a result that we had to solve the unique way that we had to solve the unique problems that were connected to the ground, and it's all the way we're able to use a reference to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:50:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:39 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 4.37 | nll_loss 3.59 | ppl 12.05 | bleu 21.99 | wps 4857.2 | wpb 17862.2 | bsz 728.3 | num_updates 2822 | best_bleu 21.99
2022-03-23 09:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2822 updates
2022-03-23 09:50:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:50:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:50:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 18 @ 2822 updates, score 21.99) (writing took 1.9721932779066265 seconds)
2022-03-23 09:50:41 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:50:41 | INFO | train | epoch 018 | loss 4.653 | nll_loss 3.982 | ppl 15.8 | wps 44308.6 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2822 | lr 0.00035275 | gnorm 0.945 | loss_scale 8 | train_wall 48 | gb_free 13.6 | wall 1682
2022-03-23 09:50:42 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:51:07 | INFO | train_inner | epoch 019:     78 / 157 loss=4.557, nll_loss=3.877, ppl=14.69, wps=35702.7, ups=1.4, wpb=25562.4, bsz=986.2, num_updates=2900, lr=0.0003625, gnorm=0.921, loss_scale=8, train_wall=31, gb_free=13.8, wall=1707
2022-03-23 09:51:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:34 | INFO | fairseq.tasks.translation | example hypothesis: we asked these sheep in the clinic.
2022-03-23 09:51:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:51:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most familiar here.
2022-03-23 09:51:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:51:42 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldial dines that will become the two new pigs.
2022-03-23 09:51:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:51:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where frog legs are salt with salz and fat.
2022-03-23 09:51:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:51:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head, and understand exactly what all its thoughts are on the road.
2022-03-23 09:51:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:51:53 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis of how people had responsibility for the wild, grew up the number of animals again, and this is a foundation for conservation in namibia.
2022-03-23 09:51:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:51:57 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bbbull of magnetic field, but the susualal doesn't seem to move when they need energy, and so the superconductor of magnetic fields.
2022-03-23 09:51:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:52:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can begin to start with the big face of the face of the face and the basic basic shape of the information that gives you the entire ports, and the entire ports of this reflection.
2022-03-23 09:52:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:52:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, is that... "well, it was" anxiety "the best," the men who said, "and if you're going to tell you the table," and then we're talking about it, and then we've said, "you know, you know," silent, "anximimimimimperative," well, you know, you know, it's a lot of course, you know, you know, "anximimimimperative," anximperperative, "well," well, "well, you know, you know, you know, you know, you know, you know," anximimimimimimperperperative, "well, you know," well, "
2022-03-23 09:52:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:52:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a great part of the design work that we're going to see in our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything of the soil, and a large part of the internet, and a large part of the design work that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see is that we can use a fluid on the electric electric electric, or a fluid on the tragic, or a fluid, or a fluid on the gas gas gas, or a fluid, or a fluid on the tragic, or a fluid, or a fluid, or a fluid on the tragic, which is that it's either, which is that we will be able to be able to use it
2022-03-23 09:52:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:52:08 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 4.26 | nll_loss 3.474 | ppl 11.11 | bleu 23.24 | wps 4868.1 | wpb 17862.2 | bsz 728.3 | num_updates 2979 | best_bleu 23.24
2022-03-23 09:52:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2979 updates
2022-03-23 09:52:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:52:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:52:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 19 @ 2979 updates, score 23.24) (writing took 2.0096523240208626 seconds)
2022-03-23 09:52:10 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:52:10 | INFO | train | epoch 019 | loss 4.469 | nll_loss 3.782 | ppl 13.75 | wps 44438.5 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2979 | lr 0.000372375 | gnorm 0.91 | loss_scale 8 | train_wall 48 | gb_free 13.8 | wall 1771
2022-03-23 09:52:11 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:52:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:17 | INFO | train_inner | epoch 020:     21 / 157 loss=4.376, nll_loss=3.681, ppl=12.83, wps=35201.8, ups=1.41, wpb=24910, bsz=1037.8, num_updates=3000, lr=0.000375, gnorm=0.875, loss_scale=8, train_wall=30, gb_free=13.5, wall=1778
2022-03-23 09:52:49 | INFO | train_inner | epoch 020:    121 / 157 loss=4.296, nll_loss=3.593, ppl=12.06, wps=81436.3, ups=3.17, wpb=25727.6, bsz=1003.9, num_updates=3100, lr=0.0003875, gnorm=0.786, loss_scale=8, train_wall=31, gb_free=14.7, wall=1809
2022-03-23 09:53:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:53:03 | INFO | fairseq.tasks.translation | example hypothesis: we did this little pink in the clinic.
2022-03-23 09:53:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:53:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most of you here.
2022-03-23 09:53:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:53:11 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldial dinners that create the two new pigmentations.
2022-03-23 09:53:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:53:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salsalz and pupppets are served.
2022-03-23 09:53:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:53:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head, and understand exactly what all its thoughts are on the distance.
2022-03-23 09:53:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:53:24 | INFO | fairseq.tasks.translation | example hypothesis: and this is a foundation of how people had the responsibility for the wild wild animals that grew up again, and this is a foundation for conservation conservation protection in namibia.
2022-03-23 09:53:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:53:28 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bbull of magnetic fields are beginning in the inner lines, but the susuicide may not like if they're moving, because they need their energy movements, and so the superconductors are so superconducting.
2022-03-23 09:53:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection reflection, we can start with a traditional facial face that can start with the big constrains of faces and the basic shape, and the basic shape of the information, and through the information that makes the whole structure of these ports that make all the structure and fold a structure.
2022-03-23 09:53:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me for me here in tedwomen is that... "yes, when you were shrinking, when someone said," when someone said, "the men in a table and measure it interesting, the men in a table, and if the revolution starts to be here for me here at tedtedwomen," we've been supporting the truth is that "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 09:53:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention of invention, and a big part of design work working on our airplane, was a result of it that we had to solve the unique problems that were connected to the ground -- everything from a continuous amount of design system -- and a large part of design work that allows us to be able to be able to be able to be able to be able to be able to be able to see in the trajectory of a refrigergergergergergergerman, or a refrigergergergergergergergergerman, or a refrigergerman, or a refrigergerman, or a refrigergerman that we can be able to refrigergergergerman, or a refrigergergergergergergergergergergerman to see that we can be able to be able to be able to be able to be able to be able to be able to be able to solve in the market market market market,
2022-03-23 09:53:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:41 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.234 | nll_loss 3.439 | ppl 10.85 | bleu 23.11 | wps 4369.2 | wpb 17862.2 | bsz 728.3 | num_updates 3136 | best_bleu 23.24
2022-03-23 09:53:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3136 updates
2022-03-23 09:53:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 09:53:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 09:53:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 20 @ 3136 updates, score 23.11) (writing took 0.8644743701443076 seconds)
2022-03-23 09:53:42 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:53:42 | INFO | train | epoch 020 | loss 4.293 | nll_loss 3.591 | ppl 12.05 | wps 43194.8 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 3136 | lr 0.000392 | gnorm 0.865 | loss_scale 8 | train_wall 48 | gb_free 14.2 | wall 1862
2022-03-23 09:53:42 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:53:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:02 | INFO | train_inner | epoch 021:     64 / 157 loss=4.21, nll_loss=3.501, ppl=11.32, wps=34012.8, ups=1.36, wpb=24958.8, bsz=1113.8, num_updates=3200, lr=0.0004, gnorm=0.947, loss_scale=8, train_wall=30, gb_free=13.9, wall=1883
2022-03-23 09:54:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:35 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:54:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:54:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably know most of you here.
2022-03-23 09:54:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:54:43 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that will make two new pigments.
2022-03-23 09:54:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:54:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 09:54:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:54:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head, and understand exactly what all its thoughts are on the road.
2022-03-23 09:54:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:54:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wildlife, the number of wild animals grew back again, and this is a foundation for conservation in namibia.
2022-03-23 09:54:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:54:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloodle of magnetic fields are caught in the inside, but the sulaleggs don't like it, if you don't like your movements, and so the suitation disorder.
2022-03-23 09:54:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:55:02 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial face that can start with the big constructions of the face and the basic shape, and we'll fold it through the information that's all the structure and fold.
2022-03-23 09:55:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:55:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting, and you know, for me, is that... yes, you know, when you're going to be in the best, when someone said, "take you on your table," and you'll say, "thank you."
2022-03-23 09:55:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:55:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're going to be able to see in our plane, was a result of it that we had to solve the unique problems that were connected to the ground -- everything variable system, and that allows us to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:55:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:55:08 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.036 | nll_loss 3.233 | ppl 9.4 | bleu 25.4 | wps 4885.8 | wpb 17862.2 | bsz 728.3 | num_updates 3293 | best_bleu 25.4
2022-03-23 09:55:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3293 updates
2022-03-23 09:55:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:55:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:55:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 21 @ 3293 updates, score 25.4) (writing took 1.9727827068418264 seconds)
2022-03-23 09:55:10 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:55:10 | INFO | train | epoch 021 | loss 4.187 | nll_loss 3.475 | ppl 11.12 | wps 44561.7 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 3293 | lr 0.000411625 | gnorm 0.847 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 1951
2022-03-23 09:55:11 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:55:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:13 | INFO | train_inner | epoch 022:      7 / 157 loss=4.191, nll_loss=3.478, ppl=11.14, wps=34903.8, ups=1.41, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.812, loss_scale=8, train_wall=30, gb_free=14.7, wall=1954
2022-03-23 09:55:45 | INFO | train_inner | epoch 022:    107 / 157 loss=4.114, nll_loss=3.396, ppl=10.52, wps=77955.6, ups=3.17, wpb=24592, bsz=996, num_updates=3400, lr=0.000425, gnorm=0.862, loss_scale=8, train_wall=31, gb_free=13.3, wall=1985
2022-03-23 09:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:56:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:56:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:56:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:56:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:56:11 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldicks.
2022-03-23 09:56:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:56:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and ppepper.
2022-03-23 09:56:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:56:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 09:56:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example hypothesis: and this is a foundation of how people were taking responsibility for wild animals, and this is a foundation of conservation.
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:56:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are caught in the inner field, but the supralegters don't like if they're moving, there's their movements.
2022-03-23 09:56:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial.
2022-03-23 09:56:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that... "well, we've been working on the winner."
2022-03-23 09:56:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're going to be able to see in our aircraft, or a result of it has to solve the unique problems that we had to solve on the ground.
2022-03-23 09:56:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:34 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.045 | nll_loss 3.241 | ppl 9.45 | bleu 23.48 | wps 5453.2 | wpb 17862.2 | bsz 728.3 | num_updates 3450 | best_bleu 25.4
2022-03-23 09:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3450 updates
2022-03-23 09:56:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 09:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 09:56:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 22 @ 3450 updates, score 23.48) (writing took 0.8955451189540327 seconds)
2022-03-23 09:56:35 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:56:35 | INFO | train | epoch 022 | loss 4.072 | nll_loss 3.35 | ppl 10.2 | wps 46609 | ups 1.85 | wpb 25153.6 | bsz 1020.6 | num_updates 3450 | lr 0.00043125 | gnorm 0.812 | loss_scale 8 | train_wall 49 | gb_free 14.4 | wall 2035
2022-03-23 09:56:35 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:56:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:51 | INFO | train_inner | epoch 023:     50 / 157 loss=4.003, nll_loss=3.276, ppl=9.68, wps=38487.9, ups=1.51, wpb=25549.5, bsz=963.1, num_updates=3500, lr=0.0004375, gnorm=0.696, loss_scale=8, train_wall=31, gb_free=13.7, wall=2052
2022-03-23 09:57:23 | INFO | train_inner | epoch 023:    150 / 157 loss=3.905, nll_loss=3.172, ppl=9.01, wps=81099.8, ups=3.2, wpb=25317.8, bsz=1082.4, num_updates=3600, lr=0.00045, gnorm=0.77, loss_scale=8, train_wall=31, gb_free=13.5, wall=2083
2022-03-23 09:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:29 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:57:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:57:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know here.
2022-03-23 09:57:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldicks that create the two new pigs.
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:57:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where happy legs are served with salt suitcase.
2022-03-23 09:57:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:57:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 09:57:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:57:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals of people like the responsibility for wildlife, the number of wildlife animals grew back again. and this is a foundation for conservation in namibia.
2022-03-23 09:57:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:57:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic fields are caught in the inner, but the superconductor may not like if they're moving, because their movements need their energy movements, and so the suprouououty disorder.
2022-03-23 09:57:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:56 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can use the information that comes from this reflection, we can start with a traditional facial that can start with the great constructions of the face and the fundamental form of the face, and through the basic form of the basic constructions of the fundamental constructions of information that are restored through the whole portion, the whole portion of the whole portion.
2022-03-23 09:57:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:58:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured to me here is that -- tar, the best dinner was put together when someone said, "turn you to your men on your table and say," turn you on a table: "turn you to your men '" stop you on your table. "
2022-03-23 09:58:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:58:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're at our plane at the most stest, was a result that we had to solve the unique problems that were connected to the ground -- it was connected to surgery -- everything that was connected to a refrightening variation that allows us to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do
2022-03-23 09:58:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:58:03 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.977 | nll_loss 3.16 | ppl 8.94 | bleu 25.68 | wps 4763 | wpb 17862.2 | bsz 728.3 | num_updates 3607 | best_bleu 25.68
2022-03-23 09:58:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3607 updates
2022-03-23 09:58:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:58:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:58:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 23 @ 3607 updates, score 25.68) (writing took 2.0113527006469667 seconds)
2022-03-23 09:58:05 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 09:58:05 | INFO | train | epoch 023 | loss 3.931 | nll_loss 3.199 | ppl 9.18 | wps 43951 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3607 | lr 0.000450875 | gnorm 0.74 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 2125
2022-03-23 09:58:05 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 09:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:35 | INFO | train_inner | epoch 024:     93 / 157 loss=3.845, nll_loss=3.106, ppl=8.61, wps=34626.7, ups=1.39, wpb=24933.4, bsz=1048.2, num_updates=3700, lr=0.0004625, gnorm=0.732, loss_scale=8, train_wall=31, gb_free=13.9, wall=2155
2022-03-23 09:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 09:58:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:59:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 09:59:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:59:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are creating new goldilocks that create the two new pigs.
2022-03-23 09:59:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:59:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 09:59:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:59:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 09:59:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:59:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how the people responsibility for wildlife grew up the number of wild animals, and that's a foundation for conservation in namibia.
2022-03-23 09:59:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:59:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs are caught by magnetic field lines in the inside, but the superconductor doesn't like it if they move, because their movements need their movements, and so the superconducting disorders.
2022-03-23 09:59:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection of the face and the basic shape, and restoring it through the information that pulls all the ports.
2022-03-23 09:59:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are doing it high-interesting and measured for me here is that... well, when you were striking dinner at the best, when someone said, "turn you to the men in your desk and said," if we're going to support you. "the truth is that we've already supported you that women have a long time."
2022-03-23 09:59:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:32 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a system that allows us to make a refrightening that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see,
2022-03-23 09:59:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:32 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.796 | nll_loss 2.965 | ppl 7.81 | bleu 27.58 | wps 4888.6 | wpb 17862.2 | bsz 728.3 | num_updates 3764 | best_bleu 27.58
2022-03-23 09:59:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3764 updates
2022-03-23 09:59:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:59:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 09:59:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 24 @ 3764 updates, score 27.58) (writing took 2.0109294331632555 seconds)
2022-03-23 09:59:34 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 09:59:34 | INFO | train | epoch 024 | loss 3.828 | nll_loss 3.087 | ppl 8.5 | wps 44587.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 3764 | lr 0.0004705 | gnorm 0.7 | loss_scale 8 | train_wall 48 | gb_free 14.3 | wall 2214
2022-03-23 09:59:34 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 09:59:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:45 | INFO | train_inner | epoch 025:     36 / 157 loss=3.744, nll_loss=2.997, ppl=7.98, wps=36066.9, ups=1.41, wpb=25565.7, bsz=1063.5, num_updates=3800, lr=0.000475, gnorm=0.661, loss_scale=8, train_wall=31, gb_free=14.3, wall=2226
2022-03-23 10:00:17 | INFO | train_inner | epoch 025:    136 / 157 loss=3.832, nll_loss=3.09, ppl=8.52, wps=80244.5, ups=3.21, wpb=24971.5, bsz=968.1, num_updates=3900, lr=0.0004875, gnorm=0.748, loss_scale=8, train_wall=31, gb_free=14.5, wall=2257
2022-03-23 10:00:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in clinic.
2022-03-23 10:00:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:00:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:00:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:00:34 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that will create two new pigs.
2022-03-23 10:00:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:00:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and parbitcase.
2022-03-23 10:00:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:00:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:00:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:00:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife survival, the number of wildlife animals grew again. and that's a basis for conservation in namibia.
2022-03-23 10:00:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:00:49 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines start inside, but the superconductor doesn't like you move, because your movements need energy, and so the superconducting disorder.
2022-03-23 10:00:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, the big constraints of faces and the basic shape, and restoring it through the one thing that pulls the whole porter structure and fold it through.
2022-03-23 10:00:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it high-interesting and measuring me here is that -- well, when the dinner was best summarized when someone said, "turn you to the men on your desk and say," if the revolution starts supporting you. "
2022-03-23 10:00:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that allows us to be a result that we had to solve the unique problems that we had to operate on the ground to operate on the ground -- all of a continuous variables and a refrigering system that allows us to see in the fly, or if you can see the propellism, if you can either see the propellism, if you can't see the world.
2022-03-23 10:00:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:58 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.857 | nll_loss 3.027 | ppl 8.15 | bleu 25.76 | wps 5314.5 | wpb 17862.2 | bsz 728.3 | num_updates 3921 | best_bleu 27.58
2022-03-23 10:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3921 updates
2022-03-23 10:00:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:00:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:00:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 25 @ 3921 updates, score 25.76) (writing took 0.8717636461369693 seconds)
2022-03-23 10:00:59 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:00:59 | INFO | train | epoch 025 | loss 3.771 | nll_loss 3.025 | ppl 8.14 | wps 46426.4 | ups 1.85 | wpb 25153.6 | bsz 1020.6 | num_updates 3921 | lr 0.000490125 | gnorm 0.72 | loss_scale 8 | train_wall 48 | gb_free 14.6 | wall 2299
2022-03-23 10:00:59 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:24 | INFO | train_inner | epoch 026:     79 / 157 loss=3.682, nll_loss=2.93, ppl=7.62, wps=37751.7, ups=1.48, wpb=25448.4, bsz=1017.2, num_updates=4000, lr=0.0005, gnorm=0.683, loss_scale=8, train_wall=31, gb_free=13.1, wall=2324
2022-03-23 10:01:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:52 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piezers in the clinic.
2022-03-23 10:01:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:02:00 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 10:02:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:02:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and parbitcase.
2022-03-23 10:02:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:02:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife animals grew again. and that's a basis for conservation in namibia.
2022-03-23 10:02:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:02:15 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic fields are caught in the inside, but the superconductor doesn't like it, if they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:02:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, the big constructions of the face and the basic shape, and through the theast of information, which includes all the porting structure and all the functions.
2022-03-23 10:02:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to be here for me here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn you to the men on your desk and say," if the revolution starts to support you. "the truth is that we've been supporting you," women are already supporting you. "
2022-03-23 10:02:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we are at our airplane to be stumble, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable system and a refrigeration system that allows us to refrigerator us to make a refrigerator, that allows us to build a refrigerator device to fly, to become a refugesticky traffic, or to a refugestile, to a refugestile, or to a remotmotmotely see the propellum, to the propellum.
2022-03-23 10:02:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:26 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.641 | nll_loss 2.799 | ppl 6.96 | bleu 29.33 | wps 4802.1 | wpb 17862.2 | bsz 728.3 | num_updates 4078 | best_bleu 29.33
2022-03-23 10:02:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4078 updates
2022-03-23 10:02:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:02:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:02:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 26 @ 4078 updates, score 29.33) (writing took 1.9789983117952943 seconds)
2022-03-23 10:02:28 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:02:28 | INFO | train | epoch 026 | loss 3.675 | nll_loss 2.922 | ppl 7.58 | wps 44288.5 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4078 | lr 0.000495195 | gnorm 0.677 | loss_scale 8 | train_wall 48 | gb_free 14.2 | wall 2388
2022-03-23 10:02:28 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:02:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:35 | INFO | train_inner | epoch 027:     22 / 157 loss=3.612, nll_loss=2.855, ppl=7.23, wps=35009.5, ups=1.4, wpb=25035.3, bsz=1086.6, num_updates=4100, lr=0.000493865, gnorm=0.647, loss_scale=8, train_wall=30, gb_free=13.7, wall=2396
2022-03-23 10:03:07 | INFO | train_inner | epoch 027:    122 / 157 loss=3.597, nll_loss=2.838, ppl=7.15, wps=80077.1, ups=3.21, wpb=24941.2, bsz=964.6, num_updates=4200, lr=0.00048795, gnorm=0.633, loss_scale=8, train_wall=31, gb_free=13.9, wall=2427
2022-03-23 10:03:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepses in the clinic.
2022-03-23 10:03:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:03:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i guess most of you here.
2022-03-23 10:03:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:03:29 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs.
2022-03-23 10:03:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:03:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and parbitcase.
2022-03-23 10:03:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:03:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the maginy of people's responsibility for wildlife, the number of wildwildwildanimals grew again. and this is a foundation for conservation in namibia.
2022-03-23 10:03:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:03:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are inside, but the superconductor doesn't like if they're moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:03:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, the big constructions of the face and the basic shape, and we refold it through the information that performs the whole por-structure and all the folds.
2022-03-23 10:03:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to men in your desk and tell you," when the revolution starts to support you. "
2022-03-23 10:03:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane on the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation, and a refrigering system that allows us to use a refrigeration, or a refrigering machine to a refrigerator, or a refrigerator.
2022-03-23 10:03:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:54 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.619 | nll_loss 2.781 | ppl 6.87 | bleu 29.12 | wps 5037.5 | wpb 17862.2 | bsz 728.3 | num_updates 4235 | best_bleu 29.33
2022-03-23 10:03:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4235 updates
2022-03-23 10:03:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:03:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:03:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 27 @ 4235 updates, score 29.12) (writing took 0.8859487879090011 seconds)
2022-03-23 10:03:55 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:03:55 | INFO | train | epoch 027 | loss 3.572 | nll_loss 2.811 | ppl 7.02 | wps 45350.1 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 4235 | lr 0.00048593 | gnorm 0.622 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 2475
2022-03-23 10:03:55 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:16 | INFO | train_inner | epoch 028:     65 / 157 loss=3.523, nll_loss=2.759, ppl=6.77, wps=36183.1, ups=1.45, wpb=24983.4, bsz=1008.5, num_updates=4300, lr=0.000482243, gnorm=0.625, loss_scale=8, train_wall=30, gb_free=14.5, wall=2496
2022-03-23 10:04:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:48 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppets on the clinic.
2022-03-23 10:04:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:04:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 10:04:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:04:55 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that generate two new pigs.
2022-03-23 10:04:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:04:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food where frog legs are served with salz and psuitcase.
2022-03-23 10:04:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:05:03 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:05:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:05:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:05:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:05:11 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bamongst magnetic field lines are caught inside, but the superconductor doesn't like to move because their movements use energy, and so the superconducting disorder.
2022-03-23 10:05:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection, which is the big constructions of facial and restored the basic shape, and through the dieting information that pulls the whole porter structure and all the fits.
2022-03-23 10:05:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that -- well, when you have been best summarized when someone said, "turn to the men on your table and tell them," if the revolution starts to support you. "the truth is that we've already supported you a long time."
2022-03-23 10:05:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a large part of the design work that we're on our plane are the crust, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable and a cooler system that allows us to use a fluid to the operations to a.
2022-03-23 10:05:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:20 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.558 | nll_loss 2.709 | ppl 6.54 | bleu 30.16 | wps 5089.9 | wpb 17862.2 | bsz 728.3 | num_updates 4392 | best_bleu 30.16
2022-03-23 10:05:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4392 updates
2022-03-23 10:05:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:05:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:05:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 28 @ 4392 updates, score 30.16) (writing took 1.9797755498439074 seconds)
2022-03-23 10:05:22 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:05:22 | INFO | train | epoch 028 | loss 3.503 | nll_loss 2.737 | ppl 6.67 | wps 45272.6 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 4392 | lr 0.000477165 | gnorm 0.619 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 2562
2022-03-23 10:05:22 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:25 | INFO | train_inner | epoch 029:      8 / 157 loss=3.519, nll_loss=2.755, ppl=6.75, wps=36273.4, ups=1.44, wpb=25115.8, bsz=996.1, num_updates=4400, lr=0.000476731, gnorm=0.635, loss_scale=8, train_wall=30, gb_free=14.3, wall=2565
2022-03-23 10:05:56 | INFO | train_inner | epoch 029:    108 / 157 loss=3.438, nll_loss=2.668, ppl=6.36, wps=80285.2, ups=3.2, wpb=25124.7, bsz=1021.9, num_updates=4500, lr=0.000471405, gnorm=0.594, loss_scale=8, train_wall=31, gb_free=13.8, wall=2596
2022-03-23 10:06:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:15 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piesters in the clinic.
2022-03-23 10:06:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:06:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 10:06:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:06:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will become two new pigs.
2022-03-23 10:06:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:06:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and parbitcase.
2022-03-23 10:06:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:06:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:06:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:06:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:06:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:06:38 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like if they're moving, because they're using energy, and so the superconductor disorder.
2022-03-23 10:06:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection that refers the big constructions of facial and the basic shape, and recongects it through the diechief information that draws the whole porter structure and all the folds.
2022-03-23 10:06:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was highly interesting and appropriate to me here at tedwomen is that... tja, when dinner was best summarized when someone said, "turn to men on your table and tell them," if the revolution starts to support you. "
2022-03-23 10:06:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:48 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large part of the design work that we're at our aircraft at the stumest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a cooling system that allows us to use a machine in the gosh aircraft until we can use the aircraft, or if you can either see the propeller, or if you can't see the floors.
2022-03-23 10:06:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:48 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.551 | nll_loss 2.705 | ppl 6.52 | bleu 29.86 | wps 4955.7 | wpb 17862.2 | bsz 728.3 | num_updates 4549 | best_bleu 30.16
2022-03-23 10:06:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4549 updates
2022-03-23 10:06:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:06:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:06:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 29 @ 4549 updates, score 29.86) (writing took 0.8823734149336815 seconds)
2022-03-23 10:06:49 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:06:49 | INFO | train | epoch 029 | loss 3.431 | nll_loss 2.66 | ppl 6.32 | wps 45333 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 4549 | lr 0.000468859 | gnorm 0.601 | loss_scale 8 | train_wall 48 | gb_free 13.3 | wall 2649
2022-03-23 10:06:50 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:06:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:06 | INFO | train_inner | epoch 030:     51 / 157 loss=3.412, nll_loss=2.639, ppl=6.23, wps=36231, ups=1.44, wpb=25166.4, bsz=979.4, num_updates=4600, lr=0.000466252, gnorm=0.611, loss_scale=8, train_wall=31, gb_free=14.2, wall=2666
2022-03-23 10:07:37 | INFO | train_inner | epoch 030:    151 / 157 loss=3.357, nll_loss=2.581, ppl=5.98, wps=81293.5, ups=3.21, wpb=25347.5, bsz=1039.1, num_updates=4700, lr=0.000461266, gnorm=0.531, loss_scale=8, train_wall=31, gb_free=14.2, wall=2697
2022-03-23 10:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:42 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep on the clinic clinic.
2022-03-23 10:07:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:07:47 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:07:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:07:50 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs transcend.
2022-03-23 10:07:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:07:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:07:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:07:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all its thoughts are on the track.
2022-03-23 10:07:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:08:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife animals grew again, and that's become a basis for conservation in namibia.
2022-03-23 10:08:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:08:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are caught in the inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:08:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that repeats the big conscores of the face and the basic shape, and then remixed it through the thief information that refers the whole por-structure and all the folding.
2022-03-23 10:08:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that... well, when they were striking dinner, it was best summarized when someone said, "turn you to the men on your table and say," if the revolution starts to support you. "the truth is we've already supported you for this long time."
2022-03-23 10:08:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a large piece of design work that we're on on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a refrigeration machine that allows us to use in the go-to-specific transport until one of the aircraft, or to a specific basis, if we were able to see the propelled by a mechanism, or if you can see the aircraft.
2022-03-23 10:08:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:16 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.49 | nll_loss 2.635 | ppl 6.21 | bleu 30.82 | wps 4885.1 | wpb 17862.2 | bsz 728.3 | num_updates 4706 | best_bleu 30.82
2022-03-23 10:08:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4706 updates
2022-03-23 10:08:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:08:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:08:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 30 @ 4706 updates, score 30.82) (writing took 1.9983006110414863 seconds)
2022-03-23 10:08:18 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:08:18 | INFO | train | epoch 030 | loss 3.362 | nll_loss 2.587 | ppl 6.01 | wps 44271.8 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4706 | lr 0.000460971 | gnorm 0.567 | loss_scale 8 | train_wall 48 | gb_free 13.4 | wall 2739
2022-03-23 10:08:19 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:08:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:49 | INFO | train_inner | epoch 031:     94 / 157 loss=3.328, nll_loss=2.549, ppl=5.85, wps=35368.5, ups=1.39, wpb=25475, bsz=1043.1, num_updates=4800, lr=0.000456435, gnorm=0.602, loss_scale=8, train_wall=31, gb_free=14.1, wall=2769
2022-03-23 10:09:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:12 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:09:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:09:16 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here.
2022-03-23 10:09:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:09:19 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new sponsors.
2022-03-23 10:09:19 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:09:23 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and psuitcase.
2022-03-23 10:09:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:09:27 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all its thoughts are on the track.
2022-03-23 10:09:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:09:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildwildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:09:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:09:35 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductors don't like moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:09:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face can begin to restore the big constructions of the face and the basic shape, and recover it through the thief information that pulls the whole porter structure and all the fits.
2022-03-23 10:09:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me to be here at tedwomen is that... tja, when dinner was best summarized, when someone said, "turn you to the men on your table and say," if the revolution starts to support you. "the truth is that we've already supported you for that long time."
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a cooling system with a refrigeration machine that allows us to use a go-to-go-to-fly transport or a particular car car car car car car car car vehicle, or a specially, or if we had to be able to do it, or if you had to do it, or if you had to be able to be able to do it, or if you can't be able to do it, or if you can't be able to be able to do it, or if you can't be able to do it, or if you can't be able to do it, or a mechanism, or if you can't be able to be able to do it, or if you can't be able to do it, or if you can't do it,
2022-03-23 10:09:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:46 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.455 | nll_loss 2.596 | ppl 6.05 | bleu 31.24 | wps 4808.3 | wpb 17862.2 | bsz 728.3 | num_updates 4863 | best_bleu 31.24
2022-03-23 10:09:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4863 updates
2022-03-23 10:09:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:09:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:09:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 31 @ 4863 updates, score 31.24) (writing took 2.2491861451417208 seconds)
2022-03-23 10:09:48 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:09:48 | INFO | train | epoch 031 | loss 3.323 | nll_loss 2.544 | ppl 5.83 | wps 43997.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4863 | lr 0.000453469 | gnorm 0.575 | loss_scale 8 | train_wall 48 | gb_free 13.3 | wall 2828
2022-03-23 10:09:48 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:09:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:00 | INFO | train_inner | epoch 032:     37 / 157 loss=3.255, nll_loss=2.471, ppl=5.54, wps=34791.4, ups=1.4, wpb=24862.4, bsz=1037.8, num_updates=4900, lr=0.000451754, gnorm=0.519, loss_scale=8, train_wall=30, gb_free=13.3, wall=2841
2022-03-23 10:10:32 | INFO | train_inner | epoch 032:    137 / 157 loss=3.276, nll_loss=2.494, ppl=5.63, wps=80678, ups=3.18, wpb=25359.2, bsz=1036.4, num_updates=5000, lr=0.000447214, gnorm=0.601, loss_scale=8, train_wall=31, gb_free=13.8, wall=2872
2022-03-23 10:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:41 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:10:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:10:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 10:10:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:10:49 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs.
2022-03-23 10:10:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:10:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are served with salt and pills.
2022-03-23 10:10:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:10:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:10:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:11:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:11:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:11:05 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:11:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:11:08 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information coming from this reflection, we can start with a traditional facial reflection, which restores the big contures of the face and the basic shape, and reconcile it through the dieth of the information that refers the whole porter structure and all the fits.
2022-03-23 10:11:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's going to be highly interesting and appropriate to me here at tedwomen is that... well, when you're striking dinner, it's best summarized when someone said, "turn you to the men on your table and tell you," if the revolution begins, we support you. '"the truth, women is that we've already supported with silly carpboard," and then we've started to downharbor, "
2022-03-23 10:11:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a refrigeration system with a refrigeration system that allows us to use a machine in the go-way, until you can see the floating, or if you can see the fluid, until you can use a mechanism, until you can use a trajectory.
2022-03-23 10:11:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:15 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.411 | nll_loss 2.552 | ppl 5.86 | bleu 31.17 | wps 4880.7 | wpb 17862.2 | bsz 728.3 | num_updates 5020 | best_bleu 31.24
2022-03-23 10:11:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5020 updates
2022-03-23 10:11:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:11:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 32 @ 5020 updates, score 31.17) (writing took 0.8686371850781143 seconds)
2022-03-23 10:11:16 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:11:16 | INFO | train | epoch 032 | loss 3.259 | nll_loss 2.475 | ppl 5.56 | wps 45032.1 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 5020 | lr 0.000446322 | gnorm 0.569 | loss_scale 8 | train_wall 48 | gb_free 14.5 | wall 2916
2022-03-23 10:11:16 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:42 | INFO | train_inner | epoch 033:     80 / 157 loss=3.174, nll_loss=2.385, ppl=5.23, wps=35849, ups=1.43, wpb=24994, bsz=1108.6, num_updates=5100, lr=0.000442807, gnorm=0.537, loss_scale=8, train_wall=30, gb_free=13.6, wall=2942
2022-03-23 10:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:09 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:12:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:12:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most of the people here.
2022-03-23 10:12:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:12:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks signs that will create two new pigs.
2022-03-23 10:12:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:12:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and psuitcase.
2022-03-23 10:12:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:12:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:12:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:12:33 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like moving because their movements use energy, and so the superconducting disorder.
2022-03-23 10:12:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which repeats the big constructures of the face and the basic shape, and reconcile it through the dietrous information that refers the whole porter structure and all the fits.
2022-03-23 10:12:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to do it is to be very interesting and appropriate for me here at tedwomen, is that... well, when strictly dinner was best summarized, when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you. '"'" the truth, women have already supported you for this long time. "
2022-03-23 10:12:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the design work, and a large part of the design work that we're at our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variables and a refrigeration system with liquid that allows us to use a flying machine in the goand to be specific to a trajectory, or if you're going to be able to go to the ground, is either the propelled to a mechanism, all the way to the trajectory.
2022-03-23 10:12:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:43 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.385 | nll_loss 2.527 | ppl 5.76 | bleu 32.36 | wps 4792.9 | wpb 17862.2 | bsz 728.3 | num_updates 5177 | best_bleu 32.36
2022-03-23 10:12:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5177 updates
2022-03-23 10:12:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:12:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 33 @ 5177 updates, score 32.36) (writing took 2.0155804781243205 seconds)
2022-03-23 10:12:45 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:12:45 | INFO | train | epoch 033 | loss 3.205 | nll_loss 2.418 | ppl 5.34 | wps 44139.1 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5177 | lr 0.000439502 | gnorm 0.542 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 3006
2022-03-23 10:12:46 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:12:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:12:53 | INFO | train_inner | epoch 034:     23 / 157 loss=3.231, nll_loss=2.444, ppl=5.44, wps=35068.8, ups=1.39, wpb=25153.7, bsz=930.1, num_updates=5200, lr=0.000438529, gnorm=0.553, loss_scale=8, train_wall=30, gb_free=13.8, wall=3013
2022-03-23 10:13:25 | INFO | train_inner | epoch 034:    123 / 157 loss=3.156, nll_loss=2.364, ppl=5.15, wps=80381.2, ups=3.2, wpb=25137.7, bsz=1040.6, num_updates=5300, lr=0.000434372, gnorm=0.562, loss_scale=8, train_wall=31, gb_free=14.3, wall=3045
2022-03-23 10:13:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:39 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:13:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:13:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i guess most of you here know.
2022-03-23 10:13:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:13:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs.
2022-03-23 10:13:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:13:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:13:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:13:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife animals grew again, and that's become a basis for conservation in namibia.
2022-03-23 10:13:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:14:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it, if you move, because your energy uses, and so the superconducting disorder.
2022-03-23 10:14:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:14:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection reflection, we can start with a traditional facial can, which gives the great contures of the face and restoring it through the thief information that refers the whole porter structure and all the fits.
2022-03-23 10:14:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to the men on your table and tell them," if the revolution begins, then we support you. "the truth is that we've already supported you for a long time."
2022-03-23 10:14:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our plane at the stumest toes, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a cooling system of fluid that allows us to use a machine in the go-way way to go, to be able to go and be able to be able to go and be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to operate on the ground, if we can either be able to go away from the vehicle, or if you can be able to fly, or if you can't be able to go away from the operated, or if you can't be able to be able to go away from the operated,
2022-03-23 10:14:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:13 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.382 | nll_loss 2.523 | ppl 5.75 | bleu 32.54 | wps 4740.6 | wpb 17862.2 | bsz 728.3 | num_updates 5334 | best_bleu 32.54
2022-03-23 10:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5334 updates
2022-03-23 10:14:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:14:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:14:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 34 @ 5334 updates, score 32.54) (writing took 2.069390980992466 seconds)
2022-03-23 10:14:15 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:14:15 | INFO | train | epoch 034 | loss 3.167 | nll_loss 2.376 | ppl 5.19 | wps 43919 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5334 | lr 0.000432986 | gnorm 0.565 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 3095
2022-03-23 10:14:16 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:14:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:36 | INFO | train_inner | epoch 035:     66 / 157 loss=3.17, nll_loss=2.379, ppl=5.2, wps=34991.4, ups=1.39, wpb=25119, bsz=947.5, num_updates=5400, lr=0.000430331, gnorm=0.565, loss_scale=8, train_wall=30, gb_free=14.1, wall=3117
2022-03-23 10:15:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:15:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most people here know.
2022-03-23 10:15:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:15:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks signs that are going to cross two new pigs.
2022-03-23 10:15:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all its thoughts are on the track.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field lines are captured inside, but the superconductors don't like it when they move, because their energy use, and so the superconducting disorder.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can that will repeat the big contures of the face and the basic shape, and restore it through this thief information that pulls all the porting structure and all the fits.
2022-03-23 10:15:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you. '"the truth, women is that we've already supported you for a long time."
2022-03-23 10:15:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a cooling system of fluid that allows us to use an aircraft in the go-to-a special transport or special drive, if you fly around the ground.
2022-03-23 10:15:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:42 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 3.354 | nll_loss 2.488 | ppl 5.61 | bleu 32.33 | wps 4981 | wpb 17862.2 | bsz 728.3 | num_updates 5491 | best_bleu 32.54
2022-03-23 10:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5491 updates
2022-03-23 10:15:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:15:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:15:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 35 @ 5491 updates, score 32.33) (writing took 0.8809417090378702 seconds)
2022-03-23 10:15:43 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:15:43 | INFO | train | epoch 035 | loss 3.111 | nll_loss 2.316 | ppl 4.98 | wps 45210.9 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 5491 | lr 0.000426751 | gnorm 0.519 | loss_scale 8 | train_wall 48 | gb_free 13.3 | wall 3183
2022-03-23 10:15:43 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:15:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:46 | INFO | train_inner | epoch 036:      9 / 157 loss=3.087, nll_loss=2.29, ppl=4.89, wps=35953.9, ups=1.44, wpb=25032.4, bsz=1069.2, num_updates=5500, lr=0.000426401, gnorm=0.494, loss_scale=8, train_wall=31, gb_free=14.2, wall=3186
2022-03-23 10:16:17 | INFO | train_inner | epoch 036:    109 / 157 loss=3.074, nll_loss=2.275, ppl=4.84, wps=80116.7, ups=3.18, wpb=25186, bsz=1026.7, num_updates=5600, lr=0.000422577, gnorm=0.539, loss_scale=8, train_wall=31, gb_free=14.7, wall=3218
2022-03-23 10:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppets on the clinic.
2022-03-23 10:16:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:16:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:16:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:16:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks signs that will be transcend two new pigs.
2022-03-23 10:16:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:16:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:16:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:16:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:16:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:16:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the mashy of how people adopted responsibility for wildlife, the number of wildwildlife grew back again, and that's become a basis for conservation in namibia.
2022-03-23 10:16:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductors don't like it when they move, because they use their energy, and so the superconductor disorder.
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:17:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can, which restores the big contures of the face and the basic shape, and then replaces it through the thief information that refuses the entire por-structure and all the fits.
2022-03-23 10:17:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that... well, in the strictly dinner, it was best summarized when someone said, "turn you to the men on your table and tell you, 'if the revolution starts to support you.' '"' the truth, women, we have already supported you for a long time. "
2022-03-23 10:17:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a huge part of the design work that we're on on our airplane is a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuously variable drive, and a refrigerator of the design system with fluid that allows us to use an aircraft on the top of the godder, to a particular vehicle vehicle, or a particular vehicle that would be used to a proliferated to the ground, or if we would be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to operate on the deflew out of the flock out of the ground at the ground, or to the mold, or to be able to be able to the deflew the
2022-03-23 10:17:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:10 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 3.329 | nll_loss 2.472 | ppl 5.55 | bleu 32.67 | wps 4842.1 | wpb 17862.2 | bsz 728.3 | num_updates 5648 | best_bleu 32.67
2022-03-23 10:17:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5648 updates
2022-03-23 10:17:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:17:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:17:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 36 @ 5648 updates, score 32.67) (writing took 2.0919658560305834 seconds)
2022-03-23 10:17:12 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:17:12 | INFO | train | epoch 036 | loss 3.083 | nll_loss 2.285 | ppl 4.88 | wps 44082.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5648 | lr 0.000420778 | gnorm 0.546 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 3272
2022-03-23 10:17:13 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:17:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:29 | INFO | train_inner | epoch 037:     52 / 157 loss=3.033, nll_loss=2.232, ppl=4.7, wps=35696.7, ups=1.4, wpb=25580.8, bsz=1115.6, num_updates=5700, lr=0.000418854, gnorm=0.547, loss_scale=8, train_wall=30, gb_free=14.1, wall=3289
2022-03-23 10:18:00 | INFO | train_inner | epoch 037:    152 / 157 loss=3.108, nll_loss=2.311, ppl=4.96, wps=79654.8, ups=3.22, wpb=24729.4, bsz=902.1, num_updates=5800, lr=0.000415227, gnorm=0.537, loss_scale=8, train_wall=31, gb_free=13.7, wall=3320
2022-03-23 10:18:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:06 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:18:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:18:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most people here know.
2022-03-23 10:18:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:18:13 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs.
2022-03-23 10:18:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:18:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:18:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:18:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:18:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:18:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife grew again, and that's become a foundation for conservation in namibia.
2022-03-23 10:18:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:18:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are captured inside, but the superconductor doesn't like it, if you move, because your energy uses, and the superconducting disorders.
2022-03-23 10:18:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial reflection, which is the big contures of the face, and restore it through the information that refers the whole porter structure and all the fits.
2022-03-23 10:18:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in the strict dinner, it's been best summarized when someone said, "turn you to the men at your table and say," if the revolution begins, then we support you. '"the truth, women, love you, is that we've already supported you, you know, this topic for a long time, you've already been supported with rael chel carchson's" with silspring, "and then we've already supported with the future's" and then we're already supported by the future of the "and we're already supporting you."
2022-03-23 10:18:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're on on on our airplane is a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable device and a cooling system of fluid, that allows us to use an aircraft at the blown of the blown of the go-go-to-the-go-traffic, to a specific vehicle vehicle that allows us to use, or to be able to use a vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle, to travel, if you can see it, or if you can see it's a mechanism, or if you can see it's all the mechanism, if you can see a mechanism, or if you can see a mechanism, you can see a mechanism, you can see it's all the aircraft in a mechanism, you can see it's a mechanism, and you can see it's a mechanism
2022-03-23 10:18:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:40 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.31 | nll_loss 2.444 | ppl 5.44 | bleu 33.12 | wps 4808.7 | wpb 17862.2 | bsz 728.3 | num_updates 5805 | best_bleu 33.12
2022-03-23 10:18:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5805 updates
2022-03-23 10:18:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:18:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 37 @ 5805 updates, score 33.12) (writing took 2.016929063014686 seconds)
2022-03-23 10:18:42 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:18:42 | INFO | train | epoch 037 | loss 3.056 | nll_loss 2.256 | ppl 4.78 | wps 43974 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5805 | lr 0.000415049 | gnorm 0.532 | loss_scale 8 | train_wall 48 | gb_free 14.2 | wall 3362
2022-03-23 10:18:42 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:19:13 | INFO | train_inner | epoch 038:     95 / 157 loss=3.01, nll_loss=2.207, ppl=4.62, wps=34033.8, ups=1.38, wpb=24664.6, bsz=1009.5, num_updates=5900, lr=0.000411693, gnorm=0.51, loss_scale=8, train_wall=31, gb_free=13.9, wall=3393
2022-03-23 10:19:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietters in the clinic.
2022-03-23 10:19:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:19:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:19:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:19:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be translated two new pigs.
2022-03-23 10:19:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:19:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are served with salt and pepper.
2022-03-23 10:19:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:19:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all your thoughts are on the track.
2022-03-23 10:19:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:19:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife animals grew back, and this has become a foundation for conservation in namibia.
2022-03-23 10:19:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:19:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if you move your movements, and the superconducting disorder.
2022-03-23 10:19:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:20:03 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection, which repeats the big contextures of the face and the basic shape, and restore it through the information that refers the whole porter structure and all the folds.
2022-03-23 10:20:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that -- well, when dinner was best summarized, when someone said, "turn to the men on your table and say, 'when the revolution begins to support you.' the truth is that we've already supported you about this topic for a long time.
2022-03-23 10:20:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that allows us to use aircraft on the stumbling toes, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variability and a refrigeration system of liquid liquid liquid that allows us to use aircraft in our aircraft in the go-to-go-transportation to a particular vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle, to fly, to a mechanism, to a mechanism, to fly, to a mechanism, except for an aircraft.
2022-03-23 10:20:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:09 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.321 | nll_loss 2.456 | ppl 5.49 | bleu 32.31 | wps 4920.9 | wpb 17862.2 | bsz 728.3 | num_updates 5962 | best_bleu 33.12
2022-03-23 10:20:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5962 updates
2022-03-23 10:20:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:20:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:20:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 38 @ 5962 updates, score 32.31) (writing took 0.8817034410312772 seconds)
2022-03-23 10:20:10 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:20:10 | INFO | train | epoch 038 | loss 3.014 | nll_loss 2.211 | ppl 4.63 | wps 44800.3 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5962 | lr 0.000409547 | gnorm 0.525 | loss_scale 8 | train_wall 48 | gb_free 14.9 | wall 3450
2022-03-23 10:20:11 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:23 | INFO | train_inner | epoch 039:     38 / 157 loss=2.952, nll_loss=2.145, ppl=4.42, wps=36897.6, ups=1.41, wpb=26083.6, bsz=1155.6, num_updates=6000, lr=0.000408248, gnorm=0.504, loss_scale=8, train_wall=31, gb_free=14.7, wall=3463
2022-03-23 10:20:54 | INFO | train_inner | epoch 039:    138 / 157 loss=3.027, nll_loss=2.224, ppl=4.67, wps=80355.4, ups=3.23, wpb=24907.7, bsz=936.1, num_updates=6100, lr=0.000404888, gnorm=0.566, loss_scale=8, train_wall=31, gb_free=22.4, wall=3494
2022-03-23 10:21:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:21:04 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepers in the clinic.
2022-03-23 10:21:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:21:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:21:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:21:11 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be transcend two new pigs.
2022-03-23 10:21:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:21:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:21:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:21:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:21:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:21:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife survivors grew back, and this is a basis for conservation in namibia.
2022-03-23 10:21:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:21:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field lines are trapped inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:21:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that will restore the big contures of the face and the basic shape, and then restore it through the information that refers the entire por-structure and all the fine.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, when dinner was best summarized, it's one of the reasons that someone said, "turn you to the men at your table and tell them," when the revolution begins, then we support you. "the truth, women, we've already supported you about this topic for a long time.
2022-03-23 10:21:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a large part of the design work that we're on on our airplane at the stest toolbox, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable and cooling system of liquid, that allows us to use an aircraft in the staggressive traffic, to a specific driver's aircraft, or if you could either be able to escaped in the aircraft, or when you can see the operated, in a state of a state of a state of propellum, or when you can see the aircraft, or when you can see the aircraft, or when you can see the aircraft, or when you can see the tragic of the aircraft, or when you can see the aircraft, or when you can see the aircraft in the aircraft, or when you can see in the aircraft, or when you can see in a specific
2022-03-23 10:21:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:38 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 3.295 | nll_loss 2.425 | ppl 5.37 | bleu 33.49 | wps 4751 | wpb 17862.2 | bsz 728.3 | num_updates 6119 | best_bleu 33.49
2022-03-23 10:21:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6119 updates
2022-03-23 10:21:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:21:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:21:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 39 @ 6119 updates, score 33.49) (writing took 2.030744129791856 seconds)
2022-03-23 10:21:40 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:21:40 | INFO | train | epoch 039 | loss 2.983 | nll_loss 2.178 | ppl 4.53 | wps 43773.8 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 6119 | lr 0.000404259 | gnorm 0.527 | loss_scale 8 | train_wall 48 | gb_free 14.8 | wall 3541
2022-03-23 10:21:41 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:21:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:22:06 | INFO | train_inner | epoch 040:     81 / 157 loss=2.946, nll_loss=2.137, ppl=4.4, wps=34322.7, ups=1.39, wpb=24674.4, bsz=984.6, num_updates=6200, lr=0.00040161, gnorm=0.477, loss_scale=8, train_wall=30, gb_free=14, wall=3566
2022-03-23 10:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:34 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:22:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:22:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:22:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:22:41 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be translated to two new pigs.
2022-03-23 10:22:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:22:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where frog legs are served with salt and pepper.
2022-03-23 10:22:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:22:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife survivors grew back, and that's become a foundation for conservation in namibia.
2022-03-23 10:22:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:22:56 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like moving because their movements are using their energy, and so the superconducting disorders.
2022-03-23 10:22:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:23:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this reflection reflection, we can start with a traditional facial reflection that will restore the large contures of the face and the basic shape, and restore it through the information that refers the entire porter structure and all the fits.
2022-03-23 10:23:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen, is that -- well, when the strictly dinner, it's been summarized best when someone said, "turn to the men at your desk and tell them," if the revolution starts to support you, "the truth is that we've been supporting you at this point for a long time." with rael sandra, "and then we're down to our future."
2022-03-23 10:23:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention, and a large part of the design work that we're on on on our airplane on the proud toes, was a result that we had to solve the unique problems that were connected to doing it on the ground, and a large part of the design work that we're on, and a large part of the design work that we're on on on on our aircraft in the stop-traffic to a particular driver, or if you fly, everything from a continuously variable to the ground.
2022-03-23 10:23:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:06 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 3.306 | nll_loss 2.439 | ppl 5.42 | bleu 33.11 | wps 5052.6 | wpb 17862.2 | bsz 728.3 | num_updates 6276 | best_bleu 33.49
2022-03-23 10:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6276 updates
2022-03-23 10:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:23:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:23:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 40 @ 6276 updates, score 33.11) (writing took 0.8865521759726107 seconds)
2022-03-23 10:23:07 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:23:07 | INFO | train | epoch 040 | loss 2.94 | nll_loss 2.131 | ppl 4.38 | wps 45564.5 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 6276 | lr 0.000399171 | gnorm 0.498 | loss_scale 8 | train_wall 48 | gb_free 14.1 | wall 3627
2022-03-23 10:23:07 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:23:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:15 | INFO | train_inner | epoch 041:     24 / 157 loss=2.961, nll_loss=2.154, ppl=4.45, wps=37029.4, ups=1.45, wpb=25482.3, bsz=1001.4, num_updates=6300, lr=0.00039841, gnorm=0.528, loss_scale=8, train_wall=31, gb_free=14, wall=3635
2022-03-23 10:23:46 | INFO | train_inner | epoch 041:    124 / 157 loss=2.923, nll_loss=2.112, ppl=4.32, wps=79906.9, ups=3.2, wpb=24945.4, bsz=1024.8, num_updates=6400, lr=0.000395285, gnorm=0.535, loss_scale=8, train_wall=31, gb_free=14.5, wall=3666
2022-03-23 10:23:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:24:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:24:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:24:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:24:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:24:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs that will be transcend.
2022-03-23 10:24:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:24:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:24:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:24:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on its head and understanding exactly what all its thoughts are on the track.
2022-03-23 10:24:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:24:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:24:23 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconducting disorder.
2022-03-23 10:24:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:27 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can begin to restore the big contures of the face and the basic shape of it, and restore it through the thief of this information that refers the entire por-structure and all the fine.
2022-03-23 10:24:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate to be here for me at tedwomen is that -- well, when strictly dinner was best summarized, when someone said, "turn to the men on your table and tell them, 'when the revolution starts to support you.' ''" 'the truth, women, we already have supported you about this for a long time. at rachel carchson's "] ["] ["] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] ["] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [
2022-03-23 10:24:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on on on our airplane was a result of the fact that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable drive and a cooling system of liquid that allows us to use a machine in the stop-go-traffic to a particular driver's aircraft, or a passenger passage, or if you go to the ground, you're going to see the propeller, or when you're going to fly, you're going to see the ground, you're going to be propelled, you're going to see a mechanism, or if you're going to see the aircraft, you're going to fly, you're going to the ground, you're going to fly, and you're going to fly, and you're going to the aircraft in a mechanism, or if you're going to see it's going to fly, you're going to
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:34 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 3.254 | nll_loss 2.387 | ppl 5.23 | bleu 33.63 | wps 4849.9 | wpb 17862.2 | bsz 728.3 | num_updates 6433 | best_bleu 33.63
2022-03-23 10:24:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6433 updates
2022-03-23 10:24:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:24:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt
2022-03-23 10:24:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_best.pt (epoch 41 @ 6433 updates, score 33.63) (writing took 1.9822849980555475 seconds)
2022-03-23 10:24:36 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:24:36 | INFO | train | epoch 041 | loss 2.927 | nll_loss 2.117 | ppl 4.34 | wps 44445.4 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6433 | lr 0.00039427 | gnorm 0.527 | loss_scale 8 | train_wall 48 | gb_free 13.6 | wall 3716
2022-03-23 10:24:37 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:24:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:24:58 | INFO | train_inner | epoch 042:     67 / 157 loss=2.888, nll_loss=2.075, ppl=4.21, wps=35400.2, ups=1.39, wpb=25376.6, bsz=1027.4, num_updates=6500, lr=0.000392232, gnorm=0.487, loss_scale=8, train_wall=31, gb_free=13.6, wall=3738
2022-03-23 10:25:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:25:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:25:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:25:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:25:37 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will be transcend two new pigs.
2022-03-23 10:25:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:25:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:25:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:25:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:25:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:25:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife animals grew back again, and this has become a basis for conservation in namibia.
2022-03-23 10:25:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:25:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move because their movements use energy, and so the superconducting disorder.
2022-03-23 10:25:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:25:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that will restore the big contures of the face and the basic shape, and then add it through the information that refers the entire por-structure and all the fits.
2022-03-23 10:25:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to men on your table and tell them, 'when the revolution begins, we support you.' ''" the truth, women love is that we've already supported you in this theme for a long time. at rachel, "and then, you know, when someone said," shut down the future of sand. "
2022-03-23 10:26:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work we're on on on on our airplane on the priest toes was a result that we had to solve the unique problems associated with operating it on the ground -- everything from a continuous variable drive and a cooling system of liquid that allows us to use an aircraft in the toy traffic to a particular driver that is either propelled, or when you fly the ground, or when you fly it down, except for a mechanism, except for a mechanism, to fly.
2022-03-23 10:26:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:02 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 3.29 | nll_loss 2.417 | ppl 5.34 | bleu 32.96 | wps 5110.4 | wpb 17862.2 | bsz 728.3 | num_updates 6590 | best_bleu 33.63
2022-03-23 10:26:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6590 updates
2022-03-23 10:26:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:26:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:26:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 42 @ 6590 updates, score 32.96) (writing took 0.8779277047142386 seconds)
2022-03-23 10:26:02 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:26:02 | INFO | train | epoch 042 | loss 2.882 | nll_loss 2.068 | ppl 4.19 | wps 45588.7 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 6590 | lr 0.000389545 | gnorm 0.491 | loss_scale 8 | train_wall 48 | gb_free 14.6 | wall 3803
2022-03-23 10:26:03 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:26:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:06 | INFO | train_inner | epoch 043:     10 / 157 loss=2.869, nll_loss=2.055, ppl=4.16, wps=36851.8, ups=1.46, wpb=25255.4, bsz=1067.6, num_updates=6600, lr=0.000389249, gnorm=0.49, loss_scale=8, train_wall=31, gb_free=14.6, wall=3807
2022-03-23 10:26:38 | INFO | train_inner | epoch 043:    110 / 157 loss=2.894, nll_loss=2.08, ppl=4.23, wps=80049, ups=3.22, wpb=24888.3, bsz=924.1, num_updates=6700, lr=0.000386334, gnorm=0.523, loss_scale=8, train_wall=31, gb_free=14.9, wall=3838
2022-03-23 10:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:26:56 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:26:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:27:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most people here know.
2022-03-23 10:27:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:27:04 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will become two new pigs transcend.
2022-03-23 10:27:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:27:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:27:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:27:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:27:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:27:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:27:19 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of strands of magnetic field are captured inside, but the superconductor doesn't like it, if you move, because your movements use energy, and the superconducting disorder.
2022-03-23 10:27:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can begin with a traditional facial can that will restore the big constraints of the face and the basic form, and then add it to this information that refers the entire por-structure and all fine.
2022-03-23 10:27:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, in the strict dinner, it's been summarized best when someone said, "turn to the men on your desk and tell them, 'when the revolution starts to support you.'"] the truth, women, we've already supported you on this issue for a long time. at rael chel with silspring's "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 10:27:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a large part of the design work that we're on on on our airplane is a result that we had to solve the unique problems that were linked to operate on the ground -- everything from a continuously variable device and a refrigerator system of fluid that allows us to use aircraft in the stop-go-traffic to a particular driver's drill, or if you can see the propeller in the ground, all the way that's going to be done, all the way that's going to be done, all the way that's going to be done, all the way that's going to be done in the way that's going to be done, and the way that's going to be done is to be automasteri.m.
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:30 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 3.261 | nll_loss 2.384 | ppl 5.22 | bleu 33.5 | wps 4860.3 | wpb 17862.2 | bsz 728.3 | num_updates 6747 | best_bleu 33.63
2022-03-23 10:27:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6747 updates
2022-03-23 10:27:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:27:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:27:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 43 @ 6747 updates, score 33.5) (writing took 0.8843569229356945 seconds)
2022-03-23 10:27:31 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:27:31 | INFO | train | epoch 043 | loss 2.864 | nll_loss 2.048 | ppl 4.14 | wps 44693.9 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6747 | lr 0.000384986 | gnorm 0.503 | loss_scale 8 | train_wall 48 | gb_free 14.3 | wall 3891
2022-03-23 10:27:31 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:27:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:27:48 | INFO | train_inner | epoch 044:     53 / 157 loss=2.824, nll_loss=2.006, ppl=4.02, wps=35396.1, ups=1.42, wpb=24948.6, bsz=1084.2, num_updates=6800, lr=0.000383482, gnorm=0.517, loss_scale=8, train_wall=31, gb_free=13.6, wall=3908
2022-03-23 10:28:19 | INFO | train_inner | epoch 044:    153 / 157 loss=2.844, nll_loss=2.027, ppl=4.08, wps=82411, ups=3.23, wpb=25486.8, bsz=1035.6, num_updates=6900, lr=0.000380693, gnorm=0.485, loss_scale=8, train_wall=31, gb_free=14.1, wall=3939
2022-03-23 10:28:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:25 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 10:28:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:28:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:28:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:28:32 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be transcend two new pigs.
2022-03-23 10:28:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:28:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:28:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:28:40 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:43 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense that people took responsibility for wildlife, the number of wildlife animals grew back, and this has become a basis for conservation in namibia.
2022-03-23 10:28:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:28:47 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, so the superconductor disorder.
2022-03-23 10:28:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:28:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that will restore the big contures of the face and the basic shape, and then add it through the information that refers the whole por-structure and all fits.
2022-03-23 10:28:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:28:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it extremely interesting and appropriate for me here at tedwomen is that -- well, when dinner was best summarized, when someone said, "turn to the men in your desk and tell them," if the revolution begins, we support you. '"the truth, women are we already supporting you with this topic for a long time. at rachel," with syringes, "and then down our future of sand," and then down.
2022-03-23 10:28:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:28:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still invention, and a large part of the design work that we're on on on our plane was a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuously variable drive and a refrigerator system of fluid that allows us to use aircraft in the stop-go-traffic until a particular passage that drives the propeller, or when you fly the ground, or when you can see the propeller, all the way down to a mechanism, all the way down to the ground.
2022-03-23 10:28:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:28:58 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 3.255 | nll_loss 2.387 | ppl 5.23 | bleu 33.55 | wps 4932 | wpb 17862.2 | bsz 728.3 | num_updates 6904 | best_bleu 33.63
2022-03-23 10:28:58 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:28:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6904 updates
2022-03-23 10:28:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:28:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt
2022-03-23 10:28:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#1/checkpoint_last.pt (epoch 44 @ 6904 updates, score 33.55) (writing took 0.8908530999906361 seconds)
2022-03-23 10:28:59 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:28:59 | INFO | train | epoch 044 | loss 2.839 | nll_loss 2.022 | ppl 4.06 | wps 44960.8 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 6904 | lr 0.000380583 | gnorm 0.509 | loss_scale 8 | train_wall 48 | gb_free 13.3 | wall 3979
2022-03-23 10:28:59 | INFO | fairseq_cli.train | done training in 3978.3 seconds
