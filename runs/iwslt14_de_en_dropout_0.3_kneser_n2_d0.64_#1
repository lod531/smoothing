Sender: LSF System <lsfadmin@eu-g3-056>
Subject: Job 210653059: <iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1> was submitted from host <eu-login-27> by user <andriusb> in cluster <euler> at Wed Mar 23 18:55:34 2022
Job was executed on host(s) <eu-g3-056>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 18:56:09 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 18:56:09 2022
Terminated at Thu Mar 24 00:32:03 2022
Results reported at Thu Mar 24 00:32:03 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion kneser_ney_smoothing --kneser-d 0.64 --kneser-n 2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   20127.11 sec.
    Max Memory :                                 5143 MB
    Average Memory :                             4392.66 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14857.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   20154 sec.
    Turnaround time :                            20189 sec.

The output (if any) follows:

2022-03-23 18:56:20 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='kneser_ney_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, kneser_d=0.64, kneser_n=2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'kneser_ney_smoothing', 'kneser_d': 0.64, 'kneser_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 18:56:20 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 18:56:20 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 18:56:21 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:56:21 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:56:21 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1145/160239 [00:00<00:13, 11441.50it/s]  2%|▏         | 2526/160239 [00:00<00:12, 12831.11it/s]  2%|▏         | 3944/160239 [00:00<00:11, 13443.13it/s]  3%|▎         | 5289/160239 [00:00<00:11, 13092.85it/s]  4%|▍         | 6659/160239 [00:00<00:11, 13307.45it/s]  5%|▍         | 7991/160239 [00:00<00:11, 13008.23it/s]  6%|▌         | 9294/160239 [00:00<00:11, 12900.25it/s]  7%|▋         | 10656/160239 [00:00<00:11, 13122.36it/s]  7%|▋         | 11970/160239 [00:00<00:11, 13059.06it/s]  8%|▊         | 13299/160239 [00:01<00:11, 13127.11it/s]  9%|▉         | 14613/160239 [00:01<00:11, 13085.22it/s] 10%|▉         | 15922/160239 [00:01<00:11, 12927.15it/s] 11%|█         | 17216/160239 [00:01<00:11, 12710.00it/s] 12%|█▏        | 18511/160239 [00:01<00:11, 12777.76it/s] 12%|█▏        | 19924/160239 [00:01<00:10, 13177.01it/s] 13%|█▎        | 21243/160239 [00:01<00:10, 13126.27it/s] 14%|█▍        | 22557/160239 [00:01<00:10, 12974.79it/s] 15%|█▍        | 23856/160239 [00:01<00:10, 12864.30it/s] 16%|█▌        | 25144/160239 [00:01<00:10, 12862.57it/s] 16%|█▋        | 26431/160239 [00:02<00:10, 12737.66it/s] 17%|█▋        | 27740/160239 [00:02<00:10, 12838.58it/s] 18%|█▊        | 29053/160239 [00:02<00:10, 12923.82it/s] 19%|█▉        | 30346/160239 [00:02<00:10, 12654.21it/s] 20%|█▉        | 31765/160239 [00:02<00:09, 13102.16it/s] 21%|██        | 33078/160239 [00:02<00:09, 12965.31it/s] 21%|██▏       | 34376/160239 [00:02<00:09, 12734.54it/s] 22%|██▏       | 35652/160239 [00:02<00:09, 12536.89it/s] 23%|██▎       | 36964/160239 [00:02<00:09, 12703.64it/s] 24%|██▍       | 38288/160239 [00:02<00:09, 12858.80it/s] 25%|██▍       | 39576/160239 [00:03<00:09, 12727.27it/s] 26%|██▌       | 40946/160239 [00:03<00:09, 13013.21it/s] 26%|██▋       | 42249/160239 [00:03<00:09, 12720.68it/s] 27%|██▋       | 43524/160239 [00:03<00:09, 12568.50it/s] 28%|██▊       | 44783/160239 [00:03<00:09, 12427.51it/s] 29%|██▉       | 46156/160239 [00:03<00:08, 12807.03it/s] 30%|██▉       | 47474/160239 [00:03<00:08, 12916.63it/s] 30%|███       | 48768/160239 [00:03<00:08, 12736.32it/s] 31%|███▏      | 50079/160239 [00:03<00:08, 12840.44it/s] 32%|███▏      | 51423/160239 [00:03<00:08, 13016.62it/s] 33%|███▎      | 52765/160239 [00:04<00:08, 13135.16it/s] 34%|███▎      | 54080/160239 [00:04<00:08, 12983.70it/s] 35%|███▍      | 55380/160239 [00:04<00:08, 12870.12it/s] 35%|███▌      | 56750/160239 [00:04<00:07, 13114.03it/s] 36%|███▋      | 58132/160239 [00:04<00:07, 13323.00it/s] 37%|███▋      | 59467/160239 [00:04<00:07, 13328.55it/s] 38%|███▊      | 60801/160239 [00:04<00:07, 13248.61it/s] 39%|███▉      | 62127/160239 [00:04<00:07, 13055.65it/s] 40%|███▉      | 63501/160239 [00:04<00:07, 13255.83it/s] 41%|████      | 64992/160239 [00:05<00:06, 13745.95it/s] 41%|████▏     | 66368/160239 [00:05<00:06, 13707.18it/s] 42%|████▏     | 67740/160239 [00:05<00:06, 13221.42it/s] 43%|████▎     | 69067/160239 [00:05<00:07, 12933.21it/s] 44%|████▍     | 70417/160239 [00:05<00:06, 13095.59it/s] 45%|████▍     | 71730/160239 [00:05<00:06, 13032.09it/s] 46%|████▌     | 73036/160239 [00:05<00:06, 12856.36it/s] 46%|████▋     | 74324/160239 [00:05<00:06, 12861.67it/s] 47%|████▋     | 75612/160239 [00:05<00:06, 12805.36it/s] 48%|████▊     | 76975/160239 [00:05<00:06, 13047.85it/s] 49%|████▉     | 78360/160239 [00:06<00:06, 13284.08it/s] 50%|████▉     | 79694/160239 [00:06<00:06, 13296.97it/s] 51%|█████     | 81159/160239 [00:06<00:05, 13699.83it/s] 52%|█████▏    | 82530/160239 [00:06<00:05, 13517.96it/s] 52%|█████▏    | 83883/160239 [00:06<00:05, 13457.35it/s] 53%|█████▎    | 85230/160239 [00:06<00:05, 13258.23it/s] 54%|█████▍    | 86688/160239 [00:06<00:05, 13645.52it/s] 55%|█████▍    | 88054/160239 [00:06<00:05, 13503.75it/s] 56%|█████▌    | 89406/160239 [00:06<00:05, 13466.51it/s] 57%|█████▋    | 90754/160239 [00:06<00:05, 13427.61it/s] 57%|█████▋    | 92098/160239 [00:07<00:05, 13242.59it/s] 58%|█████▊    | 93423/160239 [00:07<00:05, 13186.63it/s] 59%|█████▉    | 94743/160239 [00:07<00:05, 12896.56it/s] 60%|█████▉    | 96096/160239 [00:07<00:04, 13080.78it/s] 61%|██████    | 97406/160239 [00:07<00:04, 13063.93it/s] 62%|██████▏   | 98749/160239 [00:07<00:04, 13169.83it/s] 62%|██████▏   | 100142/160239 [00:07<00:04, 13393.94it/s] 63%|██████▎   | 101483/160239 [00:07<00:04, 13318.14it/s] 64%|██████▍   | 102816/160239 [00:07<00:04, 13172.87it/s] 65%|██████▍   | 104134/160239 [00:07<00:04, 13105.56it/s] 66%|██████▌   | 105501/160239 [00:08<00:04, 13268.88it/s] 67%|██████▋   | 106829/160239 [00:08<00:04, 13201.31it/s] 67%|██████▋   | 108150/160239 [00:08<00:04, 12777.55it/s] 68%|██████▊   | 109431/160239 [00:08<00:04, 12687.49it/s] 69%|██████▉   | 110738/160239 [00:08<00:03, 12791.93it/s] 70%|██████▉   | 112117/160239 [00:08<00:03, 13083.54it/s] 71%|███████   | 113428/160239 [00:08<00:03, 13060.98it/s] 72%|███████▏  | 114747/160239 [00:08<00:03, 13095.85it/s] 72%|███████▏  | 116082/160239 [00:08<00:03, 13170.69it/s] 73%|███████▎  | 117400/160239 [00:08<00:03, 12968.64it/s] 74%|███████▍  | 118725/160239 [00:09<00:03, 13050.90it/s] 75%|███████▍  | 120079/160239 [00:09<00:03, 13192.47it/s] 76%|███████▌  | 121411/160239 [00:09<00:02, 13230.04it/s] 77%|███████▋  | 122802/160239 [00:09<00:02, 13428.61it/s] 77%|███████▋  | 124146/160239 [00:09<00:02, 13257.34it/s] 78%|███████▊  | 125473/160239 [00:09<00:02, 12900.80it/s] 79%|███████▉  | 126802/160239 [00:09<00:02, 13012.79it/s] 80%|███████▉  | 128158/160239 [00:09<00:02, 13169.71it/s] 81%|████████  | 129477/160239 [00:09<00:02, 13107.05it/s] 82%|████████▏ | 130789/160239 [00:10<00:02, 12745.43it/s] 82%|████████▏ | 132070/160239 [00:10<00:02, 12763.52it/s] 83%|████████▎ | 133349/160239 [00:10<00:02, 12686.52it/s] 84%|████████▍ | 134619/160239 [00:10<00:02, 12678.07it/s] 85%|████████▍ | 135942/160239 [00:10<00:01, 12838.59it/s] 86%|████████▌ | 137267/160239 [00:10<00:01, 12957.65it/s] 87%|████████▋ | 138630/160239 [00:10<00:01, 13156.79it/s] 87%|████████▋ | 139988/160239 [00:10<00:01, 13281.87it/s] 88%|████████▊ | 141358/160239 [00:10<00:01, 13405.81it/s] 89%|████████▉ | 142699/160239 [00:10<00:01, 13043.55it/s] 90%|████████▉ | 144006/160239 [00:11<00:01, 13022.45it/s] 91%|█████████ | 145310/160239 [00:11<00:01, 12985.67it/s] 91%|█████████▏| 146610/160239 [00:11<00:01, 12745.81it/s] 92%|█████████▏| 147893/160239 [00:11<00:00, 12768.17it/s] 93%|█████████▎| 149171/160239 [00:11<00:00, 12534.85it/s] 94%|█████████▍| 150495/160239 [00:11<00:00, 12739.85it/s] 95%|█████████▍| 151822/160239 [00:11<00:00, 12895.41it/s] 96%|█████████▌| 153113/160239 [00:11<00:00, 12890.75it/s] 96%|█████████▋| 154441/160239 [00:11<00:00, 13005.30it/s] 97%|█████████▋| 155793/160239 [00:11<00:00, 13155.74it/s] 98%|█████████▊| 157149/160239 [00:12<00:00, 13274.69it/s] 99%|█████████▉| 158477/160239 [00:12<00:00, 12955.58it/s]100%|█████████▉| 159853/160239 [00:12<00:00, 13190.60it/s]100%|██████████| 160239/160239 [00:12<00:00, 13040.84it/s]
  0%|          | 0/6629 [00:00<?, ?it/s]  0%|          | 28/6629 [00:00<00:24, 273.66it/s]  1%|          | 58/6629 [00:00<00:23, 284.47it/s]  1%|▏         | 88/6629 [00:00<00:22, 290.87it/s]  2%|▏         | 119/6629 [00:00<00:22, 295.87it/s]  2%|▏         | 149/6629 [00:00<00:22, 293.09it/s]  3%|▎         | 180/6629 [00:00<00:21, 295.51it/s]  3%|▎         | 210/6629 [00:00<00:21, 294.42it/s]  4%|▎         | 240/6629 [00:00<00:21, 293.54it/s]  4%|▍         | 271/6629 [00:00<00:21, 296.98it/s]  5%|▍         | 301/6629 [00:01<00:21, 294.40it/s]  5%|▍         | 331/6629 [00:01<00:21, 294.31it/s]  5%|▌         | 361/6629 [00:01<00:21, 294.61it/s]  6%|▌         | 391/6629 [00:01<00:21, 295.66it/s]  6%|▋         | 422/6629 [00:01<00:20, 298.54it/s]  7%|▋         | 452/6629 [00:01<00:20, 296.32it/s]  7%|▋         | 482/6629 [00:01<00:20, 295.98it/s]  8%|▊         | 512/6629 [00:01<00:20, 294.94it/s]  8%|▊         | 542/6629 [00:01<00:20, 294.80it/s]  9%|▊         | 572/6629 [00:01<00:20, 294.33it/s]  9%|▉         | 602/6629 [00:02<00:20, 293.95it/s] 10%|▉         | 632/6629 [00:02<00:20, 294.08it/s] 10%|▉         | 662/6629 [00:02<00:20, 294.12it/s] 10%|█         | 692/6629 [00:02<00:20, 294.35it/s] 11%|█         | 722/6629 [00:02<00:19, 295.74it/s] 11%|█▏        | 752/6629 [00:02<00:19, 294.44it/s] 12%|█▏        | 782/6629 [00:02<00:19, 295.01it/s] 12%|█▏        | 812/6629 [00:02<00:19, 295.66it/s] 13%|█▎        | 842/6629 [00:02<00:19, 294.87it/s] 13%|█▎        | 872/6629 [00:02<00:19, 295.91it/s] 14%|█▎        | 902/6629 [00:03<00:19, 295.57it/s] 14%|█▍        | 932/6629 [00:03<00:19, 295.25it/s] 15%|█▍        | 962/6629 [00:03<00:19, 296.29it/s] 15%|█▍        | 992/6629 [00:03<00:18, 297.31it/s] 15%|█▌        | 1022/6629 [00:03<00:18, 296.33it/s] 16%|█▌        | 1054/6629 [00:03<00:18, 303.28it/s] 16%|█▋        | 1086/6629 [00:03<00:18, 306.74it/s] 17%|█▋        | 1119/6629 [00:03<00:17, 311.30it/s] 17%|█▋        | 1151/6629 [00:03<00:17, 313.75it/s] 18%|█▊        | 1184/6629 [00:03<00:17, 318.03it/s] 18%|█▊        | 1217/6629 [00:04<00:16, 320.69it/s] 19%|█▉        | 1250/6629 [00:04<00:16, 322.23it/s] 19%|█▉        | 1283/6629 [00:04<00:16, 320.36it/s] 20%|█▉        | 1316/6629 [00:04<00:16, 318.48it/s] 20%|██        | 1348/6629 [00:04<00:16, 318.88it/s] 21%|██        | 1381/6629 [00:04<00:16, 319.67it/s] 21%|██▏       | 1413/6629 [00:04<00:16, 318.52it/s] 22%|██▏       | 1445/6629 [00:04<00:16, 318.48it/s] 22%|██▏       | 1477/6629 [00:04<00:16, 317.76it/s] 23%|██▎       | 1509/6629 [00:04<00:16, 318.42it/s] 23%|██▎       | 1541/6629 [00:05<00:16, 317.26it/s] 24%|██▎       | 1573/6629 [00:05<00:15, 317.57it/s] 24%|██▍       | 1605/6629 [00:05<00:15, 317.69it/s] 25%|██▍       | 1638/6629 [00:05<00:15, 318.41it/s] 25%|██▌       | 1670/6629 [00:05<00:15, 318.79it/s] 26%|██▌       | 1702/6629 [00:05<00:15, 316.25it/s] 26%|██▌       | 1735/6629 [00:05<00:15, 318.11it/s] 27%|██▋       | 1768/6629 [00:05<00:15, 318.87it/s] 27%|██▋       | 1801/6629 [00:05<00:15, 319.84it/s] 28%|██▊       | 1834/6629 [00:06<00:14, 319.78it/s] 28%|██▊       | 1867/6629 [00:06<00:14, 320.73it/s] 29%|██▊       | 1900/6629 [00:06<00:14, 319.91it/s] 29%|██▉       | 1932/6629 [00:06<00:14, 319.15it/s] 30%|██▉       | 1965/6629 [00:06<00:14, 320.08it/s] 30%|███       | 1998/6629 [00:06<00:14, 318.90it/s] 31%|███       | 2031/6629 [00:06<00:14, 321.03it/s] 31%|███       | 2064/6629 [00:06<00:14, 321.92it/s] 32%|███▏      | 2097/6629 [00:06<00:14, 321.11it/s] 32%|███▏      | 2130/6629 [00:06<00:14, 320.42it/s] 33%|███▎      | 2163/6629 [00:07<00:13, 322.39it/s] 33%|███▎      | 2196/6629 [00:07<00:13, 322.68it/s] 34%|███▎      | 2229/6629 [00:07<00:13, 321.19it/s] 34%|███▍      | 2262/6629 [00:07<00:13, 321.65it/s] 35%|███▍      | 2295/6629 [00:07<00:13, 321.11it/s] 35%|███▌      | 2328/6629 [00:07<00:13, 320.05it/s] 36%|███▌      | 2361/6629 [00:07<00:13, 319.62it/s] 36%|███▌      | 2394/6629 [00:07<00:13, 320.47it/s] 37%|███▋      | 2427/6629 [00:07<00:13, 320.02it/s] 37%|███▋      | 2460/6629 [00:07<00:13, 319.48it/s] 38%|███▊      | 2492/6629 [00:08<00:12, 318.95it/s] 38%|███▊      | 2524/6629 [00:08<00:12, 318.17it/s] 39%|███▊      | 2556/6629 [00:08<00:12, 317.97it/s] 39%|███▉      | 2589/6629 [00:08<00:12, 319.61it/s] 40%|███▉      | 2622/6629 [00:08<00:12, 320.88it/s] 40%|████      | 2655/6629 [00:08<00:12, 320.69it/s] 41%|████      | 2688/6629 [00:08<00:12, 321.37it/s] 41%|████      | 2721/6629 [00:08<00:12, 320.13it/s] 42%|████▏     | 2754/6629 [00:08<00:12, 319.83it/s] 42%|████▏     | 2787/6629 [00:08<00:11, 320.37it/s] 43%|████▎     | 2820/6629 [00:09<00:11, 320.51it/s] 43%|████▎     | 2853/6629 [00:09<00:11, 320.62it/s] 44%|████▎     | 2886/6629 [00:09<00:11, 320.40it/s] 44%|████▍     | 2919/6629 [00:09<00:11, 320.37it/s] 45%|████▍     | 2952/6629 [00:09<00:11, 318.13it/s] 45%|████▌     | 2985/6629 [00:09<00:11, 321.08it/s] 46%|████▌     | 3018/6629 [00:09<00:11, 322.92it/s] 46%|████▌     | 3051/6629 [00:09<00:11, 323.85it/s] 47%|████▋     | 3084/6629 [00:09<00:10, 322.78it/s] 47%|████▋     | 3117/6629 [00:10<00:10, 323.87it/s] 48%|████▊     | 3150/6629 [00:10<00:11, 303.17it/s] 48%|████▊     | 3181/6629 [00:10<00:11, 289.67it/s] 48%|████▊     | 3211/6629 [00:10<00:12, 277.00it/s] 49%|████▉     | 3239/6629 [00:10<00:12, 269.53it/s] 49%|████▉     | 3269/6629 [00:10<00:12, 276.92it/s] 50%|████▉     | 3301/6629 [00:10<00:11, 288.28it/s] 50%|█████     | 3334/6629 [00:10<00:11, 298.10it/s] 51%|█████     | 3367/6629 [00:10<00:10, 304.82it/s] 51%|█████▏    | 3399/6629 [00:10<00:10, 307.72it/s] 52%|█████▏    | 3431/6629 [00:11<00:10, 310.30it/s] 52%|█████▏    | 3463/6629 [00:11<00:10, 312.28it/s] 53%|█████▎    | 3495/6629 [00:11<00:10, 308.66it/s] 53%|█████▎    | 3527/6629 [00:11<00:09, 311.22it/s] 54%|█████▎    | 3559/6629 [00:11<00:09, 312.92it/s] 54%|█████▍    | 3591/6629 [00:11<00:09, 313.50it/s] 55%|█████▍    | 3623/6629 [00:11<00:09, 314.39it/s] 55%|█████▌    | 3655/6629 [00:11<00:09, 314.79it/s] 56%|█████▌    | 3687/6629 [00:11<00:09, 314.46it/s] 56%|█████▌    | 3719/6629 [00:12<00:09, 314.54it/s] 57%|█████▋    | 3751/6629 [00:12<00:09, 314.35it/s] 57%|█████▋    | 3783/6629 [00:12<00:09, 315.28it/s] 58%|█████▊    | 3815/6629 [00:12<00:08, 315.90it/s] 58%|█████▊    | 3847/6629 [00:12<00:08, 316.13it/s] 59%|█████▊    | 3879/6629 [00:12<00:08, 316.61it/s] 59%|█████▉    | 3912/6629 [00:12<00:08, 318.78it/s] 60%|█████▉    | 3945/6629 [00:12<00:08, 319.92it/s] 60%|██████    | 3978/6629 [00:12<00:08, 321.68it/s] 61%|██████    | 4011/6629 [00:12<00:08, 320.78it/s] 61%|██████    | 4044/6629 [00:13<00:08, 319.17it/s] 61%|██████▏   | 4076/6629 [00:13<00:08, 318.73it/s] 62%|██████▏   | 4108/6629 [00:13<00:07, 318.65it/s] 62%|██████▏   | 4141/6629 [00:13<00:07, 319.58it/s] 63%|██████▎   | 4174/6629 [00:13<00:07, 321.97it/s] 63%|██████▎   | 4207/6629 [00:13<00:07, 320.96it/s] 64%|██████▍   | 4240/6629 [00:13<00:07, 317.45it/s] 64%|██████▍   | 4272/6629 [00:13<00:07, 315.54it/s] 65%|██████▍   | 4304/6629 [00:13<00:07, 314.13it/s] 65%|██████▌   | 4336/6629 [00:13<00:07, 313.65it/s] 66%|██████▌   | 4368/6629 [00:14<00:07, 313.45it/s] 66%|██████▋   | 4400/6629 [00:14<00:07, 313.39it/s] 67%|██████▋   | 4432/6629 [00:14<00:07, 312.20it/s] 67%|██████▋   | 4464/6629 [00:14<00:06, 313.20it/s] 68%|██████▊   | 4496/6629 [00:14<00:06, 313.98it/s] 68%|██████▊   | 4528/6629 [00:14<00:06, 314.58it/s] 69%|██████▉   | 4561/6629 [00:14<00:06, 316.89it/s] 69%|██████▉   | 4593/6629 [00:14<00:06, 317.66it/s] 70%|██████▉   | 4625/6629 [00:14<00:06, 316.01it/s] 70%|███████   | 4657/6629 [00:14<00:06, 314.40it/s] 71%|███████   | 4689/6629 [00:15<00:06, 314.13it/s] 71%|███████   | 4721/6629 [00:15<00:06, 314.58it/s] 72%|███████▏  | 4753/6629 [00:15<00:06, 311.98it/s] 72%|███████▏  | 4785/6629 [00:15<00:05, 312.72it/s] 73%|███████▎  | 4817/6629 [00:15<00:05, 312.05it/s] 73%|███████▎  | 4849/6629 [00:15<00:05, 313.00it/s] 74%|███████▎  | 4881/6629 [00:15<00:05, 314.09it/s] 74%|███████▍  | 4913/6629 [00:15<00:05, 314.65it/s] 75%|███████▍  | 4945/6629 [00:15<00:05, 315.09it/s] 75%|███████▌  | 4977/6629 [00:15<00:05, 315.34it/s] 76%|███████▌  | 5009/6629 [00:16<00:05, 315.59it/s] 76%|███████▌  | 5042/6629 [00:16<00:04, 318.23it/s] 77%|███████▋  | 5074/6629 [00:16<00:04, 317.89it/s] 77%|███████▋  | 5106/6629 [00:16<00:04, 314.72it/s] 78%|███████▊  | 5138/6629 [00:16<00:04, 309.27it/s] 78%|███████▊  | 5169/6629 [00:16<00:04, 298.60it/s] 78%|███████▊  | 5199/6629 [00:16<00:04, 287.78it/s] 79%|███████▉  | 5228/6629 [00:16<00:05, 276.45it/s] 79%|███████▉  | 5256/6629 [00:16<00:05, 269.70it/s] 80%|███████▉  | 5284/6629 [00:17<00:05, 268.97it/s] 80%|████████  | 5316/6629 [00:17<00:04, 282.23it/s] 81%|████████  | 5348/6629 [00:17<00:04, 291.58it/s] 81%|████████  | 5380/6629 [00:17<00:04, 297.20it/s] 82%|████████▏ | 5411/6629 [00:17<00:04, 300.56it/s] 82%|████████▏ | 5443/6629 [00:17<00:03, 303.88it/s] 83%|████████▎ | 5475/6629 [00:17<00:03, 306.15it/s] 83%|████████▎ | 5506/6629 [00:17<00:03, 306.78it/s] 84%|████████▎ | 5538/6629 [00:17<00:03, 309.23it/s] 84%|████████▍ | 5571/6629 [00:17<00:03, 313.72it/s] 85%|████████▍ | 5603/6629 [00:18<00:03, 313.23it/s] 85%|████████▌ | 5635/6629 [00:18<00:03, 312.75it/s] 85%|████████▌ | 5667/6629 [00:18<00:03, 313.29it/s] 86%|████████▌ | 5699/6629 [00:18<00:02, 313.26it/s] 86%|████████▋ | 5731/6629 [00:18<00:02, 312.81it/s] 87%|████████▋ | 5763/6629 [00:18<00:02, 312.88it/s] 87%|████████▋ | 5795/6629 [00:18<00:02, 313.52it/s] 88%|████████▊ | 5828/6629 [00:18<00:02, 316.32it/s] 88%|████████▊ | 5860/6629 [00:18<00:02, 313.90it/s] 89%|████████▉ | 5892/6629 [00:19<00:02, 311.72it/s] 89%|████████▉ | 5924/6629 [00:19<00:02, 311.49it/s] 90%|████████▉ | 5956/6629 [00:19<00:02, 311.59it/s] 90%|█████████ | 5988/6629 [00:19<00:02, 311.50it/s] 91%|█████████ | 6020/6629 [00:19<00:01, 311.42it/s] 91%|█████████▏| 6052/6629 [00:19<00:01, 312.08it/s] 92%|█████████▏| 6084/6629 [00:19<00:01, 312.71it/s] 92%|█████████▏| 6116/6629 [00:19<00:01, 313.55it/s] 93%|█████████▎| 6149/6629 [00:19<00:01, 315.78it/s] 93%|█████████▎| 6181/6629 [00:19<00:01, 315.27it/s] 94%|█████████▎| 6213/6629 [00:20<00:01, 314.78it/s] 94%|█████████▍| 6245/6629 [00:20<00:01, 311.36it/s] 95%|█████████▍| 6277/6629 [00:20<00:01, 310.49it/s] 95%|█████████▌| 6309/6629 [00:20<00:01, 309.27it/s] 96%|█████████▌| 6341/6629 [00:20<00:00, 310.73it/s] 96%|█████████▌| 6373/6629 [00:20<00:00, 312.36it/s] 97%|█████████▋| 6405/6629 [00:20<00:00, 314.27it/s] 97%|█████████▋| 6437/6629 [00:20<00:00, 311.92it/s] 98%|█████████▊| 6469/6629 [00:20<00:00, 311.92it/s] 98%|█████████▊| 6501/6629 [00:20<00:00, 313.24it/s] 99%|█████████▊| 6533/6629 [00:21<00:00, 314.63it/s] 99%|█████████▉| 6566/6629 [00:21<00:00, 317.27it/s]100%|█████████▉| 6598/6629 [00:21<00:00, 316.34it/s]100%|██████████| 6629/6629 [00:21<00:00, 310.29it/s]AVERAGE DENSITY :0.0
2022-03-23 18:57:14 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 18:57:14 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 18:57:14 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 18:57:14 | INFO | fairseq_cli.train | criterion: KneserNeySmoothingCriterion
2022-03-23 18:57:14 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 18:57:14 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 18:57:14 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 18:57:14 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 18:57:14 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 18:57:14 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 18:57:14 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:57:14 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 18:57:14 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:57:14 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 18:57:14 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 18:57:14 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_last.pt
2022-03-23 18:57:14 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_last.pt
2022-03-23 18:57:14 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 18:57:14 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:57:14 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:57:14 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 18:57:14 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 18:57:14 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 18:57:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 18:57:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 18:57:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 18:57:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 19:02:12 | INFO | train_inner | epoch 001:    104 / 157 loss=11.411, ppl=2722.5, wps=8791.2, ups=0.35, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.605, loss_scale=8, train_wall=297, gb_free=13.5, wall=298
2022-03-23 19:02:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 19:04:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/criterions/kneser_ney_smoothing.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  vals = torch.tensor(kl_stuff[hash("val")], device=torch.device("cuda"), dtype=torch.float16)
2022-03-23 19:04:45 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 19:04:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:04:50 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,.....
2022-03-23 19:04:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:04:55 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 19:04:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:05:00 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:05:07 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:05:14 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:05:21 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:05:29 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:05:38 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:05:40 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:05:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.669 | ppl 813.86 | bleu 0.01 | wps 2944.7 | wpb 17862.2 | bsz 728.3 | num_updates 152
2022-03-23 19:05:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 152 updates
2022-03-23 19:05:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:05:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:05:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 1 @ 152 updates, score 0.01) (writing took 0.8008974497206509 seconds)
2022-03-23 19:05:41 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 19:05:41 | INFO | train | epoch 001 | loss 10.957 | ppl 1987.89 | wps 7714.9 | ups 0.31 | wpb 25120.6 | bsz 980.6 | num_updates 152 | lr 1.9e-05 | gnorm 2.854 | loss_scale 4 | train_wall 444 | gb_free 22.4 | wall 507
2022-03-23 19:05:41 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 19:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:08:01 | INFO | train_inner | epoch 002:     48 / 157 loss=9.791, ppl=885.88, wps=7303, ups=0.29, wpb=25437.5, bsz=1087.6, num_updates=200, lr=2.5e-05, gnorm=1.42, loss_scale=4, train_wall=286, gb_free=13.7, wall=647
2022-03-23 19:12:41 | INFO | train_inner | epoch 002:    148 / 157 loss=9.078, ppl=540.56, wps=8922.6, ups=0.36, wpb=24962.3, bsz=943, num_updates=300, lr=3.75e-05, gnorm=1.527, loss_scale=4, train_wall=279, gb_free=20, wall=927
2022-03-23 19:13:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:13:09 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we.
2022-03-23 19:13:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:13:14 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:13:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:13:21 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:13:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:13:28 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:13:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:13:35 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:13:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:13:43 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:13:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:13:51 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:13:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:13:58 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:13:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:14:07 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" ""
2022-03-23 19:14:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:14:10 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:14:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:14:10 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.675 | ppl 408.72 | bleu 0.01 | wps 2671.5 | wpb 17862.2 | bsz 728.3 | num_updates 309 | best_bleu 0.01
2022-03-23 19:14:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 309 updates
2022-03-23 19:14:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:14:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:14:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 2 @ 309 updates, score 0.01) (writing took 0.7778114723041654 seconds)
2022-03-23 19:14:11 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 19:14:11 | INFO | train | epoch 002 | loss 9.187 | ppl 582.77 | wps 7749.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 309 | lr 3.8625e-05 | gnorm 1.485 | loss_scale 4 | train_wall 442 | gb_free 13.5 | wall 1017
2022-03-23 19:14:11 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 19:14:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:18:27 | INFO | train_inner | epoch 003:     91 / 157 loss=8.714, ppl=419.85, wps=7169.1, ups=0.29, wpb=24808.2, bsz=976.5, num_updates=400, lr=5e-05, gnorm=1.438, loss_scale=4, train_wall=278, gb_free=12.9, wall=1273
2022-03-23 19:21:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:21:38 | INFO | fairseq.tasks.translation | example hypothesis: we the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:21:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:21:44 | INFO | fairseq.tasks.translation | example hypothesis: is is the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:21:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:21:50 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:21:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:21:56 | INFO | fairseq.tasks.translation | example hypothesis: it's a a, and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and it
2022-03-23 19:21:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:22:03 | INFO | fairseq.tasks.translation | example hypothesis: we we that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that.
2022-03-23 19:22:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:22:11 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:22:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:22:18 | INFO | fairseq.tasks.translation | example hypothesis: 's the the the the the the the, and the the the the the the the, and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the, and and and the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:22:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:22:27 | INFO | fairseq.tasks.translation | example hypothesis: we we we the the the, and the the the the the the the the the the the the the the the the the the the the the, and and and and and and and and and and and and and and and and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:22:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:22:36 | INFO | fairseq.tasks.translation | example hypothesis: 's's, "" "" "" "" "" "" "" ""
2022-03-23 19:22:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:22:38 | INFO | fairseq.tasks.translation | example hypothesis: we we we, we a a a a a a a a a a, and the the the the, and the the the the the the the the the the the the the the, and the the the the the the the the the the the, and the the the the the the the the, and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that,
2022-03-23 19:22:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:22:38 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.451 | ppl 349.92 | bleu 0.05 | wps 2700.3 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.05
2022-03-23 19:22:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 19:22:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:22:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:22:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.05) (writing took 0.7796950810588896 seconds)
2022-03-23 19:22:39 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 19:22:39 | INFO | train | epoch 003 | loss 8.626 | ppl 395.06 | wps 7765.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 466 | lr 5.825e-05 | gnorm 1.575 | loss_scale 4 | train_wall 441 | gb_free 13.2 | wall 1525
2022-03-23 19:22:39 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 19:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:24:17 | INFO | train_inner | epoch 004:     34 / 157 loss=8.466, ppl=353.66, wps=7256.7, ups=0.28, wpb=25464, bsz=1090.9, num_updates=500, lr=6.25e-05, gnorm=1.523, loss_scale=4, train_wall=284, gb_free=13, wall=1624
2022-03-23 19:28:59 | INFO | train_inner | epoch 004:    134 / 157 loss=8.223, ppl=298.86, wps=8946.6, ups=0.35, wpb=25227.2, bsz=1021.3, num_updates=600, lr=7.5e-05, gnorm=1.582, loss_scale=4, train_wall=282, gb_free=13.8, wall=1905
2022-03-23 19:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:30:06 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world.
2022-03-23 19:30:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:30:12 | INFO | fairseq.tasks.translation | example hypothesis: the world is the world is the world.
2022-03-23 19:30:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:30:18 | INFO | fairseq.tasks.translation | example hypothesis: we're're're to have to have to have to have to be the world of the world of the world.
2022-03-23 19:30:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:30:24 | INFO | fairseq.tasks.translation | example hypothesis: , it's a way, and it's a way, and it's a way.
2022-03-23 19:30:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:30:30 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not not not not not that we're not not not not not not not.
2022-03-23 19:30:30 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:30:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world of the world, and the world, and the world is the world, and the world, and the world, and the world, and the world.
2022-03-23 19:30:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:30:44 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not, but you can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can're're're be be be be be be be be be be be be their their their their their their, but but it.
2022-03-23 19:30:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:30:52 | INFO | fairseq.tasks.translation | example hypothesis: we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the the way, and that we're the way, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 19:30:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:31:01 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 19:31:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:31:03 | INFO | fairseq.tasks.translation | example hypothesis: , we can can can can can can can can can can can can can can be be be be be the world, which which is the world, which you can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be be be the world, which which which which which which which it's the world, which you can can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be, which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which which to be be be be be be be be be be be be be be be be be be be be be be
2022-03-23 19:31:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:31:03 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.825 | ppl 226.74 | bleu 0.9 | wps 2881.9 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 0.9
2022-03-23 19:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 19:31:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:31:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:31:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 4 @ 623 updates, score 0.9) (writing took 0.7891200948506594 seconds)
2022-03-23 19:31:04 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 19:31:04 | INFO | train | epoch 004 | loss 8.237 | ppl 301.73 | wps 7821.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.504 | loss_scale 4 | train_wall 441 | gb_free 13.4 | wall 2030
2022-03-23 19:31:04 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 19:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:34:38 | INFO | train_inner | epoch 005:     77 / 157 loss=7.94, ppl=245.64, wps=7217.1, ups=0.3, wpb=24464.6, bsz=968, num_updates=700, lr=8.75e-05, gnorm=1.963, loss_scale=4, train_wall=275, gb_free=14.6, wall=2244
2022-03-23 19:38:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:38:33 | INFO | fairseq.tasks.translation | example hypothesis: we have in the world in the world.
2022-03-23 19:38:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:38:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the first of the first here here here here here here.
2022-03-23 19:38:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:38:45 | INFO | fairseq.tasks.translation | example hypothesis: we have to have a lot of the new new new new year.
2022-03-23 19:38:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:38:51 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the way and it's going to be a lot.
2022-03-23 19:38:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:38:58 | INFO | fairseq.tasks.translation | example hypothesis: what we're not not not that we're not not that we're not not not not going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going
2022-03-23 19:38:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:39:05 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of the world, and that we have a lot of people in the world of the world of the world of the world.
2022-03-23 19:39:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:39:13 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the way, and they're not not not not going to be a lot of the lot of the lot of the way, and they can't have that they're going to be able to be able to be a lot of the lot of the lot of the lot of the lot of the way of the way of the way of the
2022-03-23 19:39:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:39:21 | INFO | fairseq.tasks.translation | example hypothesis: we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that that we can see that we can see that we
2022-03-23 19:39:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:39:30 | INFO | fairseq.tasks.translation | example hypothesis: we said, "it's going to say, and we can say," "it's going to say," it's going to say, "it's going to say," it's going to say, "it's a lot of the way," it's a lot of the way, and we can't say, "it's going to say," it's a lot of it's a lot of it's a lot of the way, "" "" "" "it's going to say," it's a lot of it's going to say, "it's a lot of it's going to say," it's a lot of it's a lot of it's a lot of the way, and we can't say, "it's going to say," it's a lot of the way, "that we can't say," "" ""
2022-03-23 19:39:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:39:32 | INFO | fairseq.tasks.translation | example hypothesis: we have that we have that that we can have that we have that we can have that that we can have that we have a lot of that we have that we have a lot of the lot of the way that we can't have that we can't have that we think that that we have that that we can't have that we can't have that that we have a lot of the way that that we can't have that we have that we can't have that we can't have that we can't have that that we have a lot of the little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little that we have that that we have to be that we have that we have that that we have that we can't have that we can't have that we have that we can't have that that we can have to be that that we can can have to be a lot of the way that that we have to
2022-03-23 19:39:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:39:32 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.398 | ppl 168.61 | bleu 1.36 | wps 2763.5 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.36
2022-03-23 19:39:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 19:39:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:39:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.36) (writing took 0.7957438952289522 seconds)
2022-03-23 19:39:33 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 19:39:33 | INFO | train | epoch 005 | loss 7.758 | ppl 216.45 | wps 7755.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.784 | loss_scale 4 | train_wall 443 | gb_free 13.6 | wall 2539
2022-03-23 19:39:34 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 19:39:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:40:28 | INFO | train_inner | epoch 006:     20 / 157 loss=7.647, ppl=200.5, wps=7267.4, ups=0.29, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=1.73, loss_scale=4, train_wall=284, gb_free=12.2, wall=2594
2022-03-23 19:45:12 | INFO | train_inner | epoch 006:    120 / 157 loss=7.382, ppl=166.8, wps=8922, ups=0.35, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=1.549, loss_scale=4, train_wall=283, gb_free=13.6, wall=2878
2022-03-23 19:46:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:47:01 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 19:47:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:47:07 | INFO | fairseq.tasks.translation | example hypothesis: this is here here here here here here's a lot of the most most of the most of the most of the same thing.
2022-03-23 19:47:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:47:13 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a new new new new new new new new new new new new new new new new new new new new new new new.
2022-03-23 19:47:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:47:19 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it's a lot of the world, and it's going to be a lot of the world.
2022-03-23 19:47:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:47:27 | INFO | fairseq.tasks.translation | example hypothesis: we're not going to do that we're going to do it's not not going to do that we're going to do it's going to do it's going to do it.
2022-03-23 19:47:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:47:34 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of people in the world, and it's a lot of people for people in the world, and it's a lot of people for people for people for people for people in the world and people in the world, and people for people in the world.
2022-03-23 19:47:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:47:42 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to be a lot of the way, but you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be
2022-03-23 19:47:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:47:50 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a lot of the world, and we can see that we can see that we can see a lot of the world, and we can see the world, and we can see the world, and we can see the world, and we can see that we can see the world, and we can see that we can see the world, we can see the world, and we can see the world, we can see the world, we can see
2022-03-23 19:47:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:48:00 | INFO | fairseq.tasks.translation | example hypothesis: i said, "you know," you know, "it's going to say," you know, "it's going to say," you know, "it's going to say," it's going to say, "it's going to say," it's going to say, "you know," it's going to say, "it's going to say," it's going to say, "it's going to say," it's a little little little little little little little little little little little little little little little little little little little little little "" "" "" "" "" "" "you're going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's a "
2022-03-23 19:48:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:48:03 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to be a lot of the world that we have to be a lot of a lot of the world, and we're going to be a lot of the way that we're going to be a lot of the world, and we're going to be a lot of the way that we're going to have to be able to have to be able to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the way that we're going to be a lot of the world that we're going to have to be able to be able to be able to be able to be a lot of the way that we're going to be a lot of the world that we're going to be a lot of the way that we have to be able to be able to be a lot of the world, and we're going to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the way that we
2022-03-23 19:48:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:48:03 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.037 | ppl 131.35 | bleu 1.51 | wps 2639.3 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.51
2022-03-23 19:48:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 19:48:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:48:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:48:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.51) (writing took 0.7805504710413516 seconds)
2022-03-23 19:48:04 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 19:48:04 | INFO | train | epoch 006 | loss 7.37 | ppl 165.4 | wps 7737.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.622 | loss_scale 4 | train_wall 441 | gb_free 14.3 | wall 3050
2022-03-23 19:48:04 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 19:48:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:51:02 | INFO | train_inner | epoch 007:     63 / 157 loss=7.15, ppl=141.98, wps=7189, ups=0.29, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.453, loss_scale=4, train_wall=281, gb_free=14.4, wall=3228
2022-03-23 19:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:55:31 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 19:55:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:55:38 | INFO | fairseq.tasks.translation | example hypothesis: here's the idea of the most of the most most of the most of the most of the most of the most of the world.
2022-03-23 19:55:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:55:45 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be new new new new new new new new new new new new new new new new new new new new new new new.
2022-03-23 19:55:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:55:52 | INFO | fairseq.tasks.translation | example hypothesis: there's a lot of the world, and it's going to be going to be a lot, and then there's going to be a lot of the world.
2022-03-23 19:55:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:56:00 | INFO | fairseq.tasks.translation | example hypothesis: what we're going to do is that we're going to do that we're going to do that we're going to do that we're going to be going to do that we're going to do that we're going to be going to do
2022-03-23 19:56:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:56:08 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of people, and the people who are in the people in the people in the people in the world, and people who are in the people in the people in the people in the people in the people who are in the people in the world, and people in the people who
2022-03-23 19:56:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:56:16 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to see, but they're going to see that they're going to see that they're going to get a lot of these things, but they're going to get a lot of these things, but they're going to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 19:56:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:56:24 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see that, and then we can see that we can see the brain, and then we can see that we can see the world, and then we can see that we can see the world, and then we can see the world, and we can see that we can see the world, and then we can see that we can see that we can see the world, and then we can see that we can see the world, and then we can
2022-03-23 19:56:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:56:33 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, and then you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "and then you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say
2022-03-23 19:56:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:56:35 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to be a lot of the world, and we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 19:56:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:56:35 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.831 | ppl 113.87 | bleu 1.61 | wps 2548.7 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 1.61
2022-03-23 19:56:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 19:56:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:56:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 19:56:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 1.61) (writing took 0.7990325940772891 seconds)
2022-03-23 19:56:36 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 19:56:36 | INFO | train | epoch 007 | loss 7.072 | ppl 134.53 | wps 7702.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.516 | loss_scale 4 | train_wall 441 | gb_free 14 | wall 3562
2022-03-23 19:56:37 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 19:56:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:56:53 | INFO | train_inner | epoch 008:      6 / 157 loss=7.01, ppl=128.89, wps=7134, ups=0.29, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.519, loss_scale=4, train_wall=279, gb_free=13.9, wall=3579
2022-03-23 20:01:34 | INFO | train_inner | epoch 008:    106 / 157 loss=6.781, ppl=109.94, wps=8958.6, ups=0.36, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.511, loss_scale=4, train_wall=281, gb_free=14.2, wall=3860
2022-03-23 20:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:04:03 | INFO | fairseq.tasks.translation | example hypothesis: we've got to put in the middle.
2022-03-23 20:04:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:04:09 | INFO | fairseq.tasks.translation | example hypothesis: the idea is that the most most most most of the most most most most of the most most most most of the most most most most most most of
2022-03-23 20:04:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:04:16 | INFO | fairseq.tasks.translation | example hypothesis: that's new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 20:04:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:04:23 | INFO | fairseq.tasks.translation | example hypothesis: it's an example where it's an example where it's going to be where it's going to be an where you're going to be where you're going to be where you're going to be where it
2022-03-23 20:04:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:04:31 | INFO | fairseq.tasks.translation | example hypothesis: it's not what we're going to do that we're going to do that we're not going to do that we're going to do that's not going to do that we're going to do that we're going to do.
2022-03-23 20:04:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:04:38 | INFO | fairseq.tasks.translation | example hypothesis: in fact, in fact, for the most people who are in the people in the people who are in the people who are in the people in the people in the people who are in the people in the people in the people in the people in the people in the people who are in the people
2022-03-23 20:04:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:04:45 | INFO | fairseq.tasks.translation | example hypothesis: you can see, but it's a lot of the same way, but it's a lot of the same way, but it's not a lot of the same way, but but they're not a lot of the same way.
2022-03-23 20:04:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:04:53 | INFO | fairseq.tasks.translation | example hypothesis: if we can take the brain, and we can see that we can take the brain, and we can see the brain, and we can see the brain, and we can see that we can see the brain, and we can see the brain.
2022-03-23 20:04:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:05:02 | INFO | fairseq.tasks.translation | example hypothesis: in fact, in fact, "it's a lot of fact," "we're going to say," "and then it's going to say," what's a little bit of the world, "why we're going to say," well, "why we're going to say," well, "why is a little bit of the first first first first first first first first first first first first first first first first thing," why is, "why we're going to say," and then we're going to say, "why we're going to say," why is, "and then we're going to say," and then it's going to say, "and then we're going to say," why we're going to say, "why is a little bit of the first first first first first first first first first first first first first first first first first question
2022-03-23 20:05:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:05:04 | INFO | fairseq.tasks.translation | example hypothesis: in fact, if we're going to be a little bit of the brain that we're going to be able to be able to be able to be a little bit of the world that we're going to be able to be able to be able to be able to be able to be able to be a little bit of the brain, which is that we're going to be able to be a little bit of the brain, which is that we're going to be able to be a little bit of the brain that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a little bit of the brain that we're going to be a little little bit of the brain that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 20:05:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:05:04 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.575 | ppl 95.34 | bleu 2.46 | wps 2683.2 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.46
2022-03-23 20:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 20:05:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:05:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:05:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.46) (writing took 0.8128161691129208 seconds)
2022-03-23 20:05:05 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 20:05:05 | INFO | train | epoch 008 | loss 6.848 | ppl 115.17 | wps 7763.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.439 | loss_scale 4 | train_wall 440 | gb_free 13.1 | wall 4071
2022-03-23 20:05:05 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 20:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:07:28 | INFO | train_inner | epoch 009:     49 / 157 loss=6.783, ppl=110.1, wps=7244.7, ups=0.28, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.309, loss_scale=4, train_wall=286, gb_free=14.5, wall=4215
2022-03-23 20:12:05 | INFO | train_inner | epoch 009:    149 / 157 loss=6.608, ppl=97.57, wps=8962, ups=0.36, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.457, loss_scale=4, train_wall=277, gb_free=13.9, wall=4491
2022-03-23 20:12:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:12:33 | INFO | fairseq.tasks.translation | example hypothesis: we did this in this room.
2022-03-23 20:12:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:12:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most of the most most of the most most of the most most most most of the
2022-03-23 20:12:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:12:45 | INFO | fairseq.tasks.translation | example hypothesis: this is new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 20:12:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:12:51 | INFO | fairseq.tasks.translation | example hypothesis: there's an example of example, where there are where it's where where are where are in the middle of where are where are where it's going to go up and where it's going to go.
2022-03-23 20:12:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:12:58 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're not going to do this, and what we're going to do, and what we're going to do is that's going to do.
2022-03-23 20:12:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:13:06 | INFO | fairseq.tasks.translation | example hypothesis: in the people like people like people in the people, for people, and the people who are in the people in the people who are working in the people in the united states, and people in the people who are working in the people in the united states.
2022-03-23 20:13:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:13:13 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of some of the water, but if you're going to look at the water, but it's not, but it's not, but it's the same time, but it's not the same time, but it's not the same time, but it's the same way, but it's the same way, but it's
2022-03-23 20:13:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:13:22 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to look at the way that we can see the world, and we can see the information of the world, and we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 20:13:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:13:31 | INFO | fairseq.tasks.translation | example hypothesis: , one of the one of the one of the one of the world, "and it's going to say," "" "" "" "" "" "" "" "" "" "'" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 20:13:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:13:33 | INFO | fairseq.tasks.translation | example hypothesis: it's still still still more than the time that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to the world
2022-03-23 20:13:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:13:33 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.217 | ppl 74.37 | bleu 3.53 | wps 2696 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 3.53
2022-03-23 20:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 20:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:13:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 3.53) (writing took 0.8025679453276098 seconds)
2022-03-23 20:13:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 20:13:34 | INFO | train | epoch 009 | loss 6.597 | ppl 96.83 | wps 7757.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.385 | loss_scale 4 | train_wall 441 | gb_free 14.2 | wall 4580
2022-03-23 20:13:34 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 20:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:17:56 | INFO | train_inner | epoch 010:     92 / 157 loss=6.357, ppl=81.98, wps=7165.2, ups=0.29, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.263, loss_scale=4, train_wall=282, gb_free=13.8, wall=4842
2022-03-23 20:20:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:21:03 | INFO | fairseq.tasks.translation | example hypothesis: we did this in this room.
2022-03-23 20:21:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:21:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the point of my name, the most of you know, most of you know.
2022-03-23 20:21:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:21:15 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new new new new new new new new new new new new new new are going to be able.
2022-03-23 20:21:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:21:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a chinese chinese, where you're going to go.
2022-03-23 20:21:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:21:27 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just just a few years, and what's going on.
2022-03-23 20:21:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:21:33 | INFO | fairseq.tasks.translation | example hypothesis: in the middle of people like people who have been working for the people for the people, and it's a few people for a few years, and that's a few years.
2022-03-23 20:21:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:21:40 | INFO | fairseq.tasks.translation | example hypothesis: some of some of these are some of the water, but if you don't have to get it, but if you don't have the energy, if you don't have to get it.
2022-03-23 20:21:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:21:47 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use this information, we can use this information, and we can use this information, and then we can be able to be able to be able to be able to use the brain, and the brain, and we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 20:21:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:21:56 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reason, and there's interesting interesting interesting, and it's going to talk about the first time, and then it's going to talk about the first time, and then we're going to do it, and then then you're going to do that, and then you know, if you're going to talk about this, you're going to do with a little bit about the first time, you're going to do it's going to do that, you know, and then, you're going to do it's going to do that, you know, and then you know, and then, you know, you're going to do it's going to do it's going to do it's going to do that, you know, and then you know, and then, you're going to do it's going to do it's going to talk about the first time, you know,
2022-03-23 20:21:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:21:58 | INFO | fairseq.tasks.translation | example hypothesis: then it's always always always always always a lot of the last year, and then we're going to do a little bit of the world, and if we're going to do that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to make a
2022-03-23 20:21:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:21:58 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.861 | ppl 58.1 | bleu 5.83 | wps 2959.2 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 5.83
2022-03-23 20:21:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 20:21:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:21:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 5.83) (writing took 0.7975598727352917 seconds)
2022-03-23 20:21:59 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 20:21:59 | INFO | train | epoch 010 | loss 6.266 | ppl 76.98 | wps 7820.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.345 | loss_scale 4 | train_wall 442 | gb_free 13.3 | wall 5085
2022-03-23 20:21:59 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 20:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:23:36 | INFO | train_inner | epoch 011:     35 / 157 loss=6.179, ppl=72.45, wps=7300, ups=0.29, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.434, loss_scale=4, train_wall=278, gb_free=13, wall=5182
2022-03-23 20:28:21 | INFO | train_inner | epoch 011:    135 / 157 loss=5.927, ppl=60.83, wps=8978.3, ups=0.35, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.379, loss_scale=4, train_wall=284, gb_free=12.9, wall=5467
2022-03-23 20:29:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:29:27 | INFO | fairseq.tasks.translation | example hypothesis: we had this pppppon the computer.
2022-03-23 20:29:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:29:33 | INFO | fairseq.tasks.translation | example hypothesis: this is not the maha, most most most most most most most of you know.
2022-03-23 20:29:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:29:39 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new new new new new new new new new new new new two two are going to be used.
2022-03-23 20:29:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:29:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese, where they're going to go, and it's going to be a poke.
2022-03-23 20:29:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:29:51 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just a few of his head, and what's going to do.
2022-03-23 20:29:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:29:58 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamas of people who have been working for the number of the population, and that's a few years.
2022-03-23 20:29:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:30:04 | INFO | fairseq.tasks.translation | example hypothesis: some of you are some of the water, but if you don't need to use the energy, it doesn't need the energy, if you need to have the energy, you need to do it.
2022-03-23 20:30:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:30:10 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use information information, we can see this information, we can use a structure of information, and the structure of the information that are going to be able to be able to use the information.
2022-03-23 20:30:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:30:16 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that there's interesting interesting interesting, and for me, "for me," well, "for you know," well, "you know," you know, "you know," well, "you know," you know, "well," well, "well," well, "well," you know, "you know," you know, "you know," you know, "well," well, "you know," well, "well," well, "well," well, "well," well, "well," you know, "well," you know, "well," well, "well," you know, "you know," you know, "you know," you know, "you know," well, "you know," you know, "well," well, "
2022-03-23 20:30:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:30:19 | INFO | fairseq.tasks.translation | example hypothesis: then, it's still still still the mother, and we have a lot of work that we had to create a new system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a
2022-03-23 20:30:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:30:19 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.526 | ppl 46.07 | bleu 8.68 | wps 3186.1 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.68
2022-03-23 20:30:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 20:30:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:30:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:30:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.68) (writing took 0.7839840711094439 seconds)
2022-03-23 20:30:19 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 20:30:19 | INFO | train | epoch 011 | loss 5.993 | ppl 63.71 | wps 7893.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.391 | loss_scale 4 | train_wall 442 | gb_free 13.6 | wall 5585
2022-03-23 20:30:20 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 20:30:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:34:00 | INFO | train_inner | epoch 012:     78 / 157 loss=5.818, ppl=56.43, wps=7361.8, ups=0.29, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.422, loss_scale=4, train_wall=281, gb_free=13.5, wall=5806
2022-03-23 20:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:37:48 | INFO | fairseq.tasks.translation | example hypothesis: we did that in the middle of the clinics.
2022-03-23 20:37:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:37:54 | INFO | fairseq.tasks.translation | example hypothesis: that's the bottom of the ha, which is most most most most most most most of you know.
2022-03-23 20:37:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:38:00 | INFO | fairseq.tasks.translation | example hypothesis: will be new york.
2022-03-23 20:38:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:38:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese chinese chinese chinese chinese, where they're going to get it, and they're going to get it.
2022-03-23 20:38:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:38:13 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just a few years on the head of his head, and what's all the idea of your mind.
2022-03-23 20:38:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:38:20 | INFO | fairseq.tasks.translation | example hypothesis: in fact, in the mamamamamamats of the responsibility of people, the number of the number of animals, and that's a few years, and that has been a very important way to have been done in the public.
2022-03-23 20:38:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:38:26 | INFO | fairseq.tasks.translation | example hypothesis: first of you are a little bit of the pattern, but if you're not able to use the energy, it doesn't need your energy, if you need your energy, it doesn't need your energy, and you need to need the energy.
2022-03-23 20:38:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:38:33 | INFO | fairseq.tasks.translation | example hypothesis: if we use information that information, we can see this information, we can create a kind of information that we can take the structure of information, and the information that are all the structure of the structure, and all the information, and all the information is all the information, and all the information.
2022-03-23 20:38:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:38:40 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons it's interesting, and it's interesting for me to be talking about women, "oh," if we said, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," oh, "you know," if we're going to say, "you know," oh, "oh," oh, "you know," you know, "oh," oh, "if we're going to say," you're going to say, "you know," you're going to say, "oh," oh, "oh," you know, "you know," you know, "you know," you know, "you know," you know, "you've got a
2022-03-23 20:38:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:38:42 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still the mother of the mother, and a lot of work that we had to be able to be able to be able to be able to be able to be able to create a whole system that we had to create a huge system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a
2022-03-23 20:38:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:38:42 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.217 | ppl 37.19 | bleu 9.57 | wps 3024.7 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 9.57
2022-03-23 20:38:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 20:38:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:38:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:38:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 9.57) (writing took 0.781150777824223 seconds)
2022-03-23 20:38:43 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 20:38:43 | INFO | train | epoch 012 | loss 5.657 | ppl 50.46 | wps 7838.8 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.381 | loss_scale 4 | train_wall 443 | gb_free 13.7 | wall 6089
2022-03-23 20:38:43 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 20:38:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:39:42 | INFO | train_inner | epoch 013:     21 / 157 loss=5.499, ppl=45.24, wps=7346, ups=0.29, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.398, loss_scale=4, train_wall=281, gb_free=13.4, wall=6148
2022-03-23 20:44:25 | INFO | train_inner | epoch 013:    121 / 157 loss=5.371, ppl=41.4, wps=8942.9, ups=0.35, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.352, loss_scale=4, train_wall=282, gb_free=13.1, wall=6431
2022-03-23 20:46:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:46:11 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppon the clinics.
2022-03-23 20:46:11 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:46:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the car of doha, most of most most most.
2022-03-23 20:46:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:46:22 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to make two new forces.
2022-03-23 20:46:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:46:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese food, where they're working with legs.
2022-03-23 20:46:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:46:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just a couple of electrodes on his head, and what's going on.
2022-03-23 20:46:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:46:40 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamamace of responsibility for the number of animals, and this is a number of animals that has been created in the heart.
2022-03-23 20:46:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:46:46 | INFO | fairseq.tasks.translation | example hypothesis: first of some of the magic, you're looking at the lines, but if you don't need your energy, you don't need your energy energy and the energy.
2022-03-23 20:46:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:46:52 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, the reflection of this reflection, we can look at a traditional form, and you can see the structure of the structure of the structure, and all the structure of the structure.
2022-03-23 20:46:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:46:58 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons it's interesting, and it's interesting for example, "oh, you know," oh, you know, "you know," you know, "you're going to say," you know, "if you're going to say," you're going to say, "you're going to say," you're going to say, "you know," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "well," you're going to say, "you're going to say," you're going to say, "you know," you're going to say, "you're going to say," you're going to say, "you know," you're going to be a long time to say, "you know,"
2022-03-23 20:46:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:46:59 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of mother, and part of our work, we've got to be able to be a new system that we had to be able to be able to be able to use it.
2022-03-23 20:46:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:46:59 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 5.004 | ppl 32.1 | bleu 11.91 | wps 3445.8 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 11.91
2022-03-23 20:46:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 20:46:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:46:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:46:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 11.91) (writing took 0.7905903309583664 seconds)
2022-03-23 20:46:59 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 20:46:59 | INFO | train | epoch 013 | loss 5.346 | ppl 40.67 | wps 7958.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.362 | loss_scale 4 | train_wall 441 | gb_free 13 | wall 6585
2022-03-23 20:47:00 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 20:47:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:50:00 | INFO | train_inner | epoch 014:     64 / 157 loss=5.194, ppl=36.61, wps=7442.5, ups=0.3, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.306, loss_scale=4, train_wall=281, gb_free=13.6, wall=6766
2022-03-23 20:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:54:28 | INFO | fairseq.tasks.translation | example hypothesis: we made this pppine in the clinics.
2022-03-23 20:54:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:54:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, ha, most of the most most of the most.
2022-03-23 20:54:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:54:40 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to create new dindindining the new new new york.
2022-03-23 20:54:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:54:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese food where they're waiting with legs, and they're going to get it.
2022-03-23 20:54:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:54:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just have a few electrodes on his head on his head, and what's going on.
2022-03-23 20:54:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:54:58 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamace of people like the responsibility of responsibility, the number of people grew up to the number of animals, and this has become become a lot of people in the middle.
2022-03-23 20:54:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:55:05 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of the magnetic magnetic magnetic lines in the lines, but it doesn't have to move the energy, if you need your energy, and you need to make your energy.
2022-03-23 20:55:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:55:11 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, the reflection of the reflection of this reflection, we can start with a traditional traditional traditional reflection of the information, and all the structure of the structure.
2022-03-23 20:55:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:55:16 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, the reasons it's interesting, and it's interesting to make me here for tedtedtedtalks about women, "well, when we're talking to you're talking about this story, and then we've got to tell you about this issue."
2022-03-23 20:55:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:55:19 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention of the invention, and a lot of design that we had to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the
2022-03-23 20:55:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:55:19 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.736 | ppl 26.64 | bleu 14.48 | wps 3213.9 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 14.48
2022-03-23 20:55:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 20:55:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:55:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 20:55:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 14.48) (writing took 0.8095839968882501 seconds)
2022-03-23 20:55:20 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 20:55:20 | INFO | train | epoch 014 | loss 5.041 | ppl 32.93 | wps 7894.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.293 | loss_scale 4 | train_wall 442 | gb_free 13.3 | wall 7086
2022-03-23 20:55:20 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 20:55:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:55:43 | INFO | train_inner | epoch 015:      7 / 157 loss=4.922, ppl=30.31, wps=7455.7, ups=0.29, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=1.248, loss_scale=4, train_wall=284, gb_free=13.4, wall=7109
2022-03-23 21:00:23 | INFO | train_inner | epoch 015:    107 / 157 loss=4.759, ppl=27.07, wps=8960.4, ups=0.36, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.323, loss_scale=4, train_wall=280, gb_free=13.5, wall=7390
2022-03-23 21:02:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:02:49 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinics.
2022-03-23 21:02:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:02:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, which most of you know.
2022-03-23 21:02:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:03:01 | INFO | fairseq.tasks.translation | example hypothesis: these are new stars going to create new dindinburgh.
2022-03-23 21:03:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:03:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where the legs are shaped with legs and salt.
2022-03-23 21:03:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:03:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just have a few electrodes on his head and understand what all the thoughts are on his mind.
2022-03-23 21:03:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:03:19 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamace of people like the responsibility, the number of animals, and this is a number of animals that have become a conservation for conservation in namiibia.
2022-03-23 21:03:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:03:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magic lines in the lines, but it doesn't go out, if you don't want to move your energy, if you need your energy, you need your energy, and you need your energy.
2022-03-23 21:03:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:03:32 | INFO | fairseq.tasks.translation | example hypothesis: if we use the information that comes from this reflection of this reflection, we can start with a traditional abstract of the traditional face of the electronic face, and there's a real shape of the information, and the whole structure of the information and all the structure of the information, and the information that are all the information and the information that are all the information and the information that are all the information that can use of the information.
2022-03-23 21:03:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:03:39 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting and interesting to make it interesting for me to be here at tedsters, that women were talking about, "oh," oh, "oh," oh, if we're talking about the best part of the best time, "and then we've told you know," if we've got a long time to help you have a lot of love for you're working with you've got a long time to help you have a lot of love to help you know, "
2022-03-23 21:03:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:03:41 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention, and a big design part of our work on the airplane, we had to see that if we had to use a unique problem, that if we had to use a unique market, or if we were able to use a unique system in the ground, if we had to be able to use the market, it was a unique system, if it's not to see that it was a unique, if we had to see that it was a unique, if we had to use the national national national national national market, if we had to see that it was a lot of the market, if we had to see that it was a lot of the most effective, or a lot of the most effective, if we had to see that it was a lot of the most effective, or even if we had to see that it was a lot of the national national national national market, if we had to see that it was actually, if we had to use, if we had to use the most effective,
2022-03-23 21:03:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:03:41 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.351 | ppl 20.41 | bleu 16.2 | wps 3149.1 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.2
2022-03-23 21:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 21:03:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:03:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:03:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.2) (writing took 0.8262880486436188 seconds)
2022-03-23 21:03:42 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 21:03:42 | INFO | train | epoch 015 | loss 4.794 | ppl 27.74 | wps 7860.8 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.284 | loss_scale 4 | train_wall 441 | gb_free 13.3 | wall 7588
2022-03-23 21:03:42 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 21:03:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:06:10 | INFO | train_inner | epoch 016:     50 / 157 loss=4.795, ppl=27.75, wps=7346.8, ups=0.29, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=1.238, loss_scale=4, train_wall=285, gb_free=13.8, wall=7736
2022-03-23 21:10:46 | INFO | train_inner | epoch 016:    150 / 157 loss=4.434, ppl=21.62, wps=8934.6, ups=0.36, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=1.119, loss_scale=4, train_wall=276, gb_free=14, wall=8012
2022-03-23 21:11:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:11:10 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic.
2022-03-23 21:11:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:11:16 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-23 21:11:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:11:21 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf.
2022-03-23 21:11:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:11:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where happy legs are going to be.
2022-03-23 21:11:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:11:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head and understand what all the thoughts are on its head.
2022-03-23 21:11:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:11:38 | INFO | fairseq.tasks.translation | example hypothesis: in the mamammals of responsibility, the number of animals grew up, and this is a number of animals.
2022-03-23 21:11:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:11:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic lines are moving in the field, but the suck doesn't move when it doesn't move, if you need your energy, it doesn't need your energy, and it doesn't need your energy.
2022-03-23 21:11:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:11:50 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, the reflection of this reflection, we can start with a traditional face, we can start with a traditional face of the face of the face of the face of the face and the face of the face of the face of the face and the shape of the shape.
2022-03-23 21:11:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:11:56 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting for me and measure for tedtalks to be here, "yeah, that's that...
2022-03-23 21:11:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:11:57 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and one part of the design that we're going to use on on the airplane.
2022-03-23 21:11:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:11:57 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.262 | ppl 19.18 | bleu 13.61 | wps 3510.7 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.2
2022-03-23 21:11:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 21:11:57 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 21:11:57 | INFO | train | epoch 016 | loss 4.516 | ppl 22.88 | wps 7975.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.186 | loss_scale 4 | train_wall 442 | gb_free 13.6 | wall 8083
2022-03-23 21:11:57 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 21:11:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:16:23 | INFO | train_inner | epoch 017:     93 / 157 loss=4.332, ppl=20.15, wps=7496.9, ups=0.3, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=1.194, loss_scale=4, train_wall=285, gb_free=14.5, wall=8349
2022-03-23 21:19:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:19:26 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic clinic.
2022-03-23 21:19:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:19:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably the most familiar here.
2022-03-23 21:19:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:19:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollocks of golf dindines that make two new picks.
2022-03-23 21:19:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:19:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food food food, where happy legs are made with salsalz and fat.
2022-03-23 21:19:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:19:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring a few electrodes on his head, and understand what all its thoughts are on the way.
2022-03-23 21:19:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:19:58 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamace, like the responsibility for the wild animals, grew up again, and this has become a foundation for protection in namibia.
2022-03-23 21:19:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:20:04 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of magnetic magnetic magnetic magnetic elements, but the sulalalalalable, and the susulllant, if you don't need your energy, and you know, you know, you know, you know, you know, you need to take a few of magnetic magnetic magnetic magnetic magnetic magnetic magnetic magnetic magnetic field
2022-03-23 21:20:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:20:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection reflection reflection reflection, we can start with a traditional face of the interfaces, and the information that gives you the whole structure of the information, and the whole structure of the structure, and all the structure of the structure, the structure of the structure, and all the structure of the structure of the structure of the structure, and the structure of the structure of the structure of the structure that
2022-03-23 21:20:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:20:18 | INFO | fairseq.tasks.translation | example hypothesis: you know, one of the reasons that it's interesting for me to be here at tedsters, "yes, when the best part of the best thing is that the best thing that the men said," when we've been talking about a table, "and then we've been working with you've been working on a table," then we've been working with you've been talking about, "you've got a long time for you've been talking about," you've been talking about, "and you've been working on the word for you've been talking about," you've been talking about, "you've been talking about," you've been talking about, "and then you've got a long time," you've been talking about, "you've been talking about, you've been talking about," you've been talking about, "you've been working on your god,
2022-03-23 21:20:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:20:20 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the ultimate thing is still the mother of the invention, and a big part of the design that we've had to solve is that we had to solve a unique result of the problems that we had to solve in the ground, and if we have to use all the power of the power, it allows us to use, it to use a specific, it to use, it to use the power of the power of the engine, it to use, to use, it to use, to use, to use, to use a specific, to use, to use, to use, it to use the power of the power of the engine, to use, it is to use, if you're actually use the engine, the power of the engine, it is to use of the engine, to use the engine, the engine, to use of the engine, to use, to use, to use the power of the power of the power of the power of the engine, to use, to use of the engine, to use of the engine,
2022-03-23 21:20:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:20:20 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.034 | ppl 16.38 | bleu 17.94 | wps 3048.6 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 17.94
2022-03-23 21:20:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 21:20:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:20:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:20:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 17.94) (writing took 0.8785447790287435 seconds)
2022-03-23 21:20:21 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 21:20:21 | INFO | train | epoch 017 | loss 4.328 | ppl 20.08 | wps 7836.8 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.219 | loss_scale 4 | train_wall 443 | gb_free 13.2 | wall 8587
2022-03-23 21:20:21 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 21:20:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:22:07 | INFO | train_inner | epoch 018:     36 / 157 loss=4.261, ppl=19.17, wps=7339.3, ups=0.29, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=1.219, loss_scale=4, train_wall=283, gb_free=13.9, wall=8693
2022-03-23 21:26:45 | INFO | train_inner | epoch 018:    136 / 157 loss=4.052, ppl=16.59, wps=8933.9, ups=0.36, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=1.034, loss_scale=4, train_wall=278, gb_free=13.7, wall=8971
2022-03-23 21:27:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:27:51 | INFO | fairseq.tasks.translation | example hypothesis: we made this pill in the clinic.
2022-03-23 21:27:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:27:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, which probably knows most of you here.
2022-03-23 21:27:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:28:02 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollocks that will create the two new pigs.
2022-03-23 21:28:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:28:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food food food, where happy legs are getting salt with salz and fat.
2022-03-23 21:28:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:28:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 21:28:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:28:21 | INFO | fairseq.tasks.translation | example hypothesis: this is how people took responsibility for the wild, grew up the number of wild animals, and that's a foundation for the wild protection in namibia.
2022-03-23 21:28:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:28:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some blooding of magnetic magnetic fields, but the sususulant of superconductor, it doesn't matter if you need your energy movements, it doesn't need your energy, and so you need the superconductor.
2022-03-23 21:28:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:28:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face that can start with traditional facial faces, the big constructions of the face and repeat and reform it through the interfaces, and the information that gives you the whole structure that the whole structure.
2022-03-23 21:28:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:28:40 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting and measured me to be here for tedwomen, and then for me, "oh," oh, when we're working on the best time, "oh, somebody was talking to you," you know, "you know," the word is that the fact that there's a silent revolution, "the fact that we've got to support you're working on the piano," silent, "to be a silent," and then we've got a long time for you're listening to you're talking to you're listening to you're talking to the fact that you're talking to your mother's a piano piano piano piano, "to you know," is that you know, "oh," to you're working on the piano, "is that you know," oh, "oh," is that you know, "oh...
2022-03-23 21:28:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:28:42 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother still is still the invention of the invention, and a big part of the design of the design that we're at the plane, is that we had to solve a result that we had to solve the unique problems that we had to solve it in the plane -- it allows us to solve it all the way that we can use it to be able to be able to use the engine, or that if it's a density, it's a mechanism, it allows us to use the engine, it to use the engine, it to use the engine, it to use, it to be a special, it, it to be an aircraft system that if you can't allow us to use the engine, it to use the engine, it to use the engine, it, it to use the engine, it to be an aircraft, it, it to use the engine, it to use the engine, it to put it into the engine, it to be an aircraft, or that if you can't allow us to be a
2022-03-23 21:28:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:28:42 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.729 | ppl 13.26 | bleu 20.99 | wps 3170.5 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.99
2022-03-23 21:28:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 21:28:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:28:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:28:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.99) (writing took 0.7932915962301195 seconds)
2022-03-23 21:28:43 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 21:28:43 | INFO | train | epoch 018 | loss 4.068 | ppl 16.77 | wps 7864.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.027 | loss_scale 4 | train_wall 442 | gb_free 13.2 | wall 9089
2022-03-23 21:28:43 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 21:28:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:32:32 | INFO | train_inner | epoch 019:     79 / 157 loss=3.942, ppl=15.37, wps=7391.7, ups=0.29, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=1.007, loss_scale=4, train_wall=287, gb_free=13.5, wall=9318
2022-03-23 21:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:36:12 | INFO | fairseq.tasks.translation | example hypothesis: we made this sheep in the clinic.
2022-03-23 21:36:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:36:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most here.
2022-03-23 21:36:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:36:24 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollocks that will become two new pigments.
2022-03-23 21:36:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:36:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where happy legs are served with salz and pupppce.
2022-03-23 21:36:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:36:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just able to bring a few electrodes on his head and understand exactly what all its thoughts are on the road.
2022-03-23 21:36:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:36:41 | INFO | fairseq.tasks.translation | example hypothesis: this is a basis of how people had been committed for life, grew up the number of wild animals again, and that's a foundation for conservation in nambia.
2022-03-23 21:36:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:36:48 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field are starting to start in the inner field, but the sususulalalal, if they don't move their movements, they need their energy.
2022-03-23 21:36:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:36:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, which can start with a traditional face of the face of the face and the fundamental shape of the information that the whole structure, the whole structure of this reflection, the whole reflection of this reflection, the whole reflection of this reflection, and the flow of this reflection of this reflection, we're all the information that the information
2022-03-23 21:36:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:37:00 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting and measured for me to be here at tedwomen is that... "well, when you were playing the best thing," you're going to say, "well, you know, the men begins to support you in a table revolution, and when we're going to support you guys in this table revolution," well, we're going to support you. "
2022-03-23 21:37:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:37:03 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother's invention is still the invention of invention, and a big part of the design work that we're going to use in our airplane, that we had to resolution the unique problems that were connected to the ground -- all the way that we have to do it was a chain of the ground -- and a large part of the power of the plane, and we're going to use the aircraft, and we're going to use the aircraft in the aircraft, the aircraft, the aircraft, that we're going to use of the aircraft, that we're going to use it is that we're going to use the aircraft, and we're going to use the aircraft, the aircraft, that we're going to use the aircraft, if you're going to use it, it, the aircraft, you're going to use the aircraft, you're going to use it, the aircraft, you're going to use a very specific surgergergergergerms, you're going to use
2022-03-23 21:37:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:37:03 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.632 | ppl 12.4 | bleu 21.12 | wps 3242.8 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.12
2022-03-23 21:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 21:37:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:37:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:37:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.12) (writing took 0.8004383151419461 seconds)
2022-03-23 21:37:04 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 21:37:04 | INFO | train | epoch 019 | loss 3.846 | ppl 14.38 | wps 7892.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.998 | loss_scale 4 | train_wall 443 | gb_free 13.4 | wall 9590
2022-03-23 21:37:04 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 21:37:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:38:08 | INFO | train_inner | epoch 020:     22 / 157 loss=3.741, ppl=13.37, wps=7377.5, ups=0.3, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.936, loss_scale=4, train_wall=278, gb_free=14.2, wall=9654
2022-03-23 21:42:57 | INFO | train_inner | epoch 020:    122 / 157 loss=3.67, ppl=12.73, wps=8941.1, ups=0.35, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.911, loss_scale=4, train_wall=289, gb_free=13.2, wall=9943
2022-03-23 21:44:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:44:33 | INFO | fairseq.tasks.translation | example hypothesis: we made these bones in the clinic.
2022-03-23 21:44:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:44:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most of you here.
2022-03-23 21:44:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:44:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golf locks that create two new pigs of the two new pigs.
2022-03-23 21:44:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:44:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where happy legs are going to be served with salz and puppet.
2022-03-23 21:44:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:44:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a couple of electrodes on his head, and understand exactly what all his thoughts is on the track.
2022-03-23 21:44:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:45:04 | INFO | fairseq.tasks.translation | example hypothesis: so in the make-like people's responsibility for wildlife, the number of wildlife grew back again, and that's a foundation of conservation in the natural conservation.
2022-03-23 21:45:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:45:10 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloop of magnetic fields in the inner lines, but the sulalalarm doesn't like you, if you're going to move your energy, and so the susuitous disorders.
2022-03-23 21:45:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:45:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial that can start with a traditional facial of the face, and the basic shape of the face, and through that information that information that creates the whole structure, which is the whole structure of the entire portion, and all the shape of these ports.
2022-03-23 21:45:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:45:24 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting and measured to me here at tedwomen, is that... yes, when the best night was put it together when someone said, "hey," hey, when somebody said to you, "the men who say you're going to give you a table and say," if you're talking about a table revolution that says, "the fact that you know, we've got a piano for you've got a long time to be here at tedstage stage stage for tedtedtedtedwomen who said," ro, "the piano for you've got a long time, we've got a long time, the piano piano for you've got a long time," -- there's a piano for you've got a piano for you've got a piano for you've got a piano for the piano, "rings," -- there's a piano, "
2022-03-23 21:45:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:45:26 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of invention is still the invention of invention, and a big part of the design work that we're going to be able to solve in our plane, the result is that we had to solve the unique problems that were connected to the ground -- all of the things that were connected to the ground -- everything from a continent, and it allows us to use a huge part of the aircraft that is that allows us to use to use a mechanism, or to use it to use a mechanical mechanism, if you can actually use a mechanism, or a mechanism that's a mechanism that's available to use it's a mechanical mechanical mechanism, it's an aircraft, it's a mechanism that is that is that is that is that is that's a result of a result of the electric electric electric device that's available to the aircraft, or the market for a market, it can't allow us to the aircraft, or the market, if you can't be able to use it's available to
2022-03-23 21:45:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:45:26 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.494 | ppl 11.27 | bleu 23.05 | wps 3083.8 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.05
2022-03-23 21:45:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 21:45:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:45:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.05) (writing took 0.8279418009333313 seconds)
2022-03-23 21:45:27 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 21:45:27 | INFO | train | epoch 020 | loss 3.647 | ppl 12.53 | wps 7840.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.931 | loss_scale 4 | train_wall 443 | gb_free 13.7 | wall 10093
2022-03-23 21:45:28 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 21:45:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:48:38 | INFO | train_inner | epoch 021:     65 / 157 loss=3.505, ppl=11.35, wps=7301.1, ups=0.29, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.963, loss_scale=4, train_wall=281, gb_free=13.4, wall=10284
2022-03-23 21:52:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:52:58 | INFO | fairseq.tasks.translation | example hypothesis: we put this sheep in the clinic on the clinic.
2022-03-23 21:52:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:53:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most of you here.
2022-03-23 21:53:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:53:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are going to be transmitted by two new pigments.
2022-03-23 21:53:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:53:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are served with salz and pphalt.
2022-03-23 21:53:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:53:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:53:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:53:29 | INFO | fairseq.tasks.translation | example hypothesis: in the make-like people's responsibility for wildlife, grew up the number of wildlife animals again, and that's a foundation for conservation in nambia.
2022-03-23 21:53:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:53:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some bols of magnetic field are caught in the inner lines, but the superconductor may like it, if you don't want to move your movements, and that's the superconductor of the magnetic field.
2022-03-23 21:53:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:53:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face, which can start with a traditional face that can start with the big constructions of the face and the basic form, and then you can fold it through that information, which is all the ports and fold all the structure.
2022-03-23 21:53:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:53:49 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting and measuring it to me here at tedwomen, is that...
2022-03-23 21:53:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:53:51 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of invention is still the invention of invention, and a big part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous system, and a lot of refrigergergergergergerism system, and it's a refrigergergergergergergerous system that we're going to the market, if you can't see that it's a market, if you're going to be able to be able to be able to be able to make it's a marketplace in the engine, or a market, if you're going to make it's a market, you can't have to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to refrigergergergergergergergergergergergergergergergergergergergergergergergergergergergergergergerman,
2022-03-23 21:53:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:53:51 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.35 | ppl 10.2 | bleu 24.28 | wps 3115.8 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.28
2022-03-23 21:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 21:53:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:53:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 21:53:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.28) (writing took 0.8978681513108313 seconds)
2022-03-23 21:53:52 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 21:53:52 | INFO | train | epoch 021 | loss 3.513 | ppl 11.41 | wps 7824.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.944 | loss_scale 4 | train_wall 445 | gb_free 14.3 | wall 10598
2022-03-23 21:53:52 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 21:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:54:16 | INFO | train_inner | epoch 022:      8 / 157 loss=3.544, ppl=11.66, wps=7311.5, ups=0.3, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.944, loss_scale=4, train_wall=279, gb_free=13.4, wall=10622
2022-03-23 21:58:53 | INFO | train_inner | epoch 022:    108 / 157 loss=3.403, ppl=10.58, wps=8901.1, ups=0.36, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.915, loss_scale=4, train_wall=276, gb_free=13.4, wall=10899
2022-03-23 22:01:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:01:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 22:01:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:01:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most of you here.
2022-03-23 22:01:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:01:34 | INFO | fairseq.tasks.translation | example hypothesis: stars are created new golf locks.
2022-03-23 22:01:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:01:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and perror.
2022-03-23 22:01:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:01:45 | INFO | fairseq.tasks.translation | example hypothesis: it's obvious that we don't just bring some electrodes on your head and understand exactly what all his thoughts are on the track.
2022-03-23 22:01:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:01:51 | INFO | fairseq.tasks.translation | example hypothesis: in the magical way, people have been taking responsibility for wild animals, and that's a foundation for conservation.
2022-03-23 22:01:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:01:57 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bust of magnetic field lines in the inner, but the superconductor doesn't like if you move, you're going to move your movements.
2022-03-23 22:01:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:02:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial, the big constraints of the face and the basic shape of the face, and the basic shape of the face of the face.
2022-03-23 22:02:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:02:08 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's very interesting and measuring for me here at tedwomen, is that... "well, when we've come to the piano."
2022-03-23 22:02:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:02:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're going to be able to use in the aircraft, or if you're in the engine, it's a result of it.
2022-03-23 22:02:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:02:09 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.289 | ppl 9.77 | bleu 22.5 | wps 3457.5 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.28
2022-03-23 22:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 22:02:09 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 22:02:09 | INFO | train | epoch 022 | loss 3.374 | ppl 10.37 | wps 7947.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.877 | loss_scale 4 | train_wall 443 | gb_free 14 | wall 11095
2022-03-23 22:02:09 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 22:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:04:33 | INFO | train_inner | epoch 023:     51 / 157 loss=3.318, ppl=9.97, wps=7501.3, ups=0.29, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.778, loss_scale=4, train_wall=286, gb_free=13.3, wall=11239
2022-03-23 22:09:17 | INFO | train_inner | epoch 023:    151 / 157 loss=3.187, ppl=9.11, wps=8963, ups=0.35, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.89, loss_scale=4, train_wall=283, gb_free=13.3, wall=11523
2022-03-23 22:09:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:09:38 | INFO | fairseq.tasks.translation | example hypothesis: we put this plate in the clinic.
2022-03-23 22:09:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:09:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most of you here.
2022-03-23 22:09:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:09:49 | INFO | fairseq.tasks.translation | example hypothesis: stars are created new goldicks that create two new pigs.
2022-03-23 22:09:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:09:55 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and perror.
2022-03-23 22:09:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:10:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and exactly understanding exactly what all his thoughts are on the track.
2022-03-23 22:10:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:10:08 | INFO | fairseq.tasks.translation | example hypothesis: this is a foundation for conservation, growing the number of wildlife animals again, and this is a foundation for conservation in namibia.
2022-03-23 22:10:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:10:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some blow of magnetic field lines are caught in the inner inner field, but the superconductor doesn't like if they're moving, because their energy uses its energy, and so the superconducting disorder of magnetic field.
2022-03-23 22:10:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:10:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can start with a traditional face that can start with the big constructions of the face and the fundamental shape of the face, and through the fundamental structure that we use, and through the basic information that we can fold it through.
2022-03-23 22:10:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:10:28 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that it's very interesting and measured to me here at tedwomen is that... t: yeah, when you're going to break dinner on the best day, when somebody said, "turn it up to you," turn you on the best, "you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to be a long, you know, you know, you know, you know, you know, you know, you know, you're going to be here at tedwomen, you're going to be a
2022-03-23 22:10:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:10:31 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a large part of the design work that we're in the plane, was a result that we had to resolve the unique problems that we had to do with the unique problems that were connected to the unique problems that we had to operate on the ground -- and a large part of the engine, and a large part of the engine, and a chain of the engine that allows us to use of the engine, all the aircraft, all the engine, and we're going to be able to be able to be able to be able to be able to use when we're going to be able to fly in the aircraft, the engine, the engine, the engine, which is that we're using a chain, the engine, the engine, the engine, which is something that would be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 22:10:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:10:31 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.299 | ppl 9.84 | bleu 24.7 | wps 3110.3 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 24.7
2022-03-23 22:10:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 22:10:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 22:10:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 22:10:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 24.7) (writing took 0.8353354292921722 seconds)
2022-03-23 22:10:31 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 22:10:31 | INFO | train | epoch 023 | loss 3.233 | ppl 9.4 | wps 7856.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.855 | loss_scale 4 | train_wall 443 | gb_free 14.2 | wall 11597
2022-03-23 22:10:32 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 22:10:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:14:57 | INFO | train_inner | epoch 024:     94 / 157 loss=3.158, ppl=8.92, wps=7323.3, ups=0.29, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.825, loss_scale=4, train_wall=281, gb_free=13.3, wall=11863
2022-03-23 22:17:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:18:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepriests in the clinic.
2022-03-23 22:18:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:18:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 22:18:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:18:13 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that will be translated by two new pigs.
2022-03-23 22:18:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:18:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and pitcase.
2022-03-23 22:18:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:18:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 22:18:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:18:31 | INFO | fairseq.tasks.translation | example hypothesis: in the magines like people's responsibility for wildlife, grew up the number of wild animals, and that's a foundation for conservation in namibia.
2022-03-23 22:18:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:18:37 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic fields are caught in the inside, but the superconductor doesn't like it, if you move, because your movements need their energy, and so the superconductor of magnetic fields.
2022-03-23 22:18:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:18:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, the big configurations of the face and the basic shape of the face, and through the theast information that makes the whole porn structure and all the leaves.
2022-03-23 22:18:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:18:50 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it high-interesting and measured to me here at tedwomen, is that... tja, when he was the best summarized when someone said, "wage you to the men in a table and say," if the revolution begins to you, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["]
2022-03-23 22:18:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:18:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our plane, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continually variable system to a refrigerators and cooling the power system that we can use when you're in the power of a fluid system, to the republicans, to the air, to the power of a market, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to refrigergergergergerate, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to refrigergergergergerate, to be able to refrigergerate, to be able to refrigergergergergergergergerate the
2022-03-23 22:18:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:18:52 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.063 | ppl 8.36 | bleu 26.69 | wps 3231.4 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.69
2022-03-23 22:18:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 22:18:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 22:18:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 22:18:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 26.69) (writing took 0.827848413027823 seconds)
2022-03-23 22:18:53 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 22:18:53 | INFO | train | epoch 024 | loss 3.123 | ppl 8.71 | wps 7872.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.786 | loss_scale 4 | train_wall 444 | gb_free 13.9 | wall 12099
2022-03-23 22:18:53 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 22:18:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:20:42 | INFO | train_inner | epoch 025:     37 / 157 loss=3.02, ppl=8.11, wps=7392.7, ups=0.29, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.756, loss_scale=4, train_wall=287, gb_free=13.5, wall=12208
2022-03-23 22:25:22 | INFO | train_inner | epoch 025:    137 / 157 loss=3.054, ppl=8.3, wps=8933.1, ups=0.36, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.803, loss_scale=4, train_wall=280, gb_free=13.4, wall=12488
2022-03-23 22:26:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:26:23 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepter in the clinic.
2022-03-23 22:26:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:26:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably knows.
2022-03-23 22:26:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:26:34 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new goldilocks that are going to be translated.
2022-03-23 22:26:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:26:39 | INFO | fairseq.tasks.translation | example hypothesis: for example there are french chinese food where happy legs are served with salz and pcase.
2022-03-23 22:26:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:26:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 22:26:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:26:51 | INFO | fairseq.tasks.translation | example hypothesis: this is a basis of human protection in namibia. and that's a foundation for conservation protection.
2022-03-23 22:26:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:26:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some bust of magnetic field lines are stuck in inside, but the superconductor doesn't like you move, because your movements need your energy, and the superconductor disorders.
2022-03-23 22:26:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:27:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, that restores the big constructions of face and the basic shape, and through the basic form that the whole porter structure and fold.
2022-03-23 22:27:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:27:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting to me here at tedwomen, is that... tyes, when prayer was first summarized, when someone said, "turn you to men on your desk and say," if the revolution starts supporting you. "
2022-03-23 22:27:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:27:09 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a huge part of the design work that we're on our plane is a result that we had to solve the unique problems that we were connected to the engine, or when we're operating it on the ground -- everything from continuous variables to a refrigeration system that allows us to use a refrigeration system to the aircraft system, or a refrigeration system that allows us to solve the air conditioning the air conditioning the air conditioning the air conditioning the air system to the air conditional, to the engine to the air conditioning the air system to the air conditioning the air system to a specific resolution.
2022-03-23 22:27:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:27:09 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.203 | ppl 9.21 | bleu 22.12 | wps 3539 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 26.69
2022-03-23 22:27:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 22:27:09 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 22:27:09 | INFO | train | epoch 025 | loss 3.021 | ppl 8.12 | wps 7965.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.803 | loss_scale 4 | train_wall 443 | gb_free 14.2 | wall 12595
2022-03-23 22:27:09 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 22:27:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:31:01 | INFO | train_inner | epoch 026:     80 / 157 loss=2.932, ppl=7.63, wps=7502.1, ups=0.29, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.753, loss_scale=4, train_wall=287, gb_free=13.5, wall=12827
2022-03-23 22:34:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:34:41 | INFO | fairseq.tasks.translation | example hypothesis: we made these piebsters in the clinic.
2022-03-23 22:34:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:34:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 22:34:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:34:52 | INFO | fairseq.tasks.translation | example hypothesis: stars are creating new goldilocks that are two new pigs.
2022-03-23 22:34:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:34:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pitcase.
2022-03-23 22:34:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:35:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all its thoughts are on the track.
2022-03-23 22:35:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:35:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildwildlife grew again, and that's a foundation for conservation in namibia.
2022-03-23 22:35:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:35:16 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bust of magnetic fields are caught in the inner, but the superconductor doesn't like it, if you move, because your movements need, and so the superconductor disorders.
2022-03-23 22:35:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:35:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can, who restores the grove constructures of the face and restores the basic shape, and through the themes of the information that the whole portion of porter structure and all the fits.
2022-03-23 22:35:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:35:28 | INFO | fairseq.tasks.translation | example hypothesis: then, one of the reasons that makes it very interesting, and measured to me here at tedwomen, is that -- tall, when someone said, "wax you to the men at your table and tell you," if the revolution begins to support you. "
2022-03-23 22:35:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:35:31 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need to be the mother of invention, and a big part of the design work that we're at the stagent, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous varieties to a refrigeration system and a refrigeration system that allows us to use a refrigerator in the aircraft system that allows us to use, to become a refrigerator of the most specific problems that we have to be connected to a mechanism of a mechanism, if we have to be connected to the interconnectivity to be connected to the interactive, if we're in the interactive to a mechanism of a mechanism that we're in the interconnectivity, if you have to operate in the interior to operate in the interconnectivity, it's in the interconnectivity, it's in the same way that we're in the world -- everything that we're connected to operate in the world -- everything that we're in the
2022-03-23 22:35:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:35:31 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.862 | ppl 7.27 | bleu 28.57 | wps 3254.7 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.57
2022-03-23 22:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 22:35:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 22:35:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 22:35:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.57) (writing took 0.8671797751449049 seconds)
2022-03-23 22:35:32 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 22:35:32 | INFO | train | epoch 026 | loss 2.907 | ppl 7.5 | wps 7852.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.731 | loss_scale 4 | train_wall 445 | gb_free 13.8 | wall 13098
2022-03-23 22:35:32 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 22:35:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:36:40 | INFO | train_inner | epoch 027:     23 / 157 loss=2.833, ppl=7.13, wps=7352.3, ups=0.29, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.727, loss_scale=4, train_wall=282, gb_free=14.3, wall=13167
2022-03-23 22:41:23 | INFO | train_inner | epoch 027:    123 / 157 loss=2.862, ppl=7.27, wps=8866.9, ups=0.35, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.753, loss_scale=4, train_wall=282, gb_free=13.1, wall=13449
2022-03-23 22:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:43:03 | INFO | fairseq.tasks.translation | example hypothesis: we put these piesters in the clinic.
2022-03-23 22:43:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:43:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 22:43:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:43:14 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 22:43:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:43:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and piffer.
2022-03-23 22:43:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:43:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:43:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:43:32 | INFO | fairseq.tasks.translation | example hypothesis: in this case, people like responsibility for wildlife, grew up again, and that's a foundation for conservation in namibia.
2022-03-23 22:43:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:43:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are captured inside the inner, but the superconductor doesn't like it if you move, because your movements require energy, and so the superconductor.
2022-03-23 22:43:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:43:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can begin with a traditional facial can that restores the big constructures of the face and restores the basic form of the face and fold it all the porting structure and fold it into a fold.
2022-03-23 22:43:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:43:50 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it highly interesting and measured to me here at tedwomen, is that... tja, it's best summarized when someone said, "shut you to the men on your table and say," if the revolution starts to support you. "the truth is that we've been supporting you."
2022-03-23 22:43:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:43:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables and a refrigerating system that allows us to use a refrigerators and a refrigerators that allows us to use a specific transportation in the aircraft, or the prophecy of a system that allows us to deal with the propellers to do it.
2022-03-23 22:43:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:43:52 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.831 | ppl 7.12 | bleu 28.01 | wps 3355.9 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 28.57
2022-03-23 22:43:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 22:43:52 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 22:43:52 | INFO | train | epoch 027 | loss 2.816 | ppl 7.04 | wps 7900.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.731 | loss_scale 4 | train_wall 445 | gb_free 13.5 | wall 13598
2022-03-23 22:43:52 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 22:43:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:46:59 | INFO | train_inner | epoch 028:     66 / 157 loss=2.747, ppl=6.71, wps=7401.8, ups=0.3, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.71, loss_scale=4, train_wall=281, gb_free=14.2, wall=13785
2022-03-23 22:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:51:23 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepsters on the clinic.
2022-03-23 22:51:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:51:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 22:51:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:51:35 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will have two new pigs.
2022-03-23 22:51:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:51:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and pffer.
2022-03-23 22:51:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:51:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 22:51:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:51:52 | INFO | fairseq.tasks.translation | example hypothesis: in the case, as people took responsibility for wildlife, the number of wildlife grew back again, and that's become a foundation for conservation in namibia.
2022-03-23 22:51:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:51:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements require your energy, and so the superconducting disorder.
2022-03-23 22:51:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:52:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial, which is the big constructures of the face and restoring it through the themes of information that refers all the por-structure and fold it all.
2022-03-23 22:52:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:52:11 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it high-interesting and appropriate to me here at tedwomen, is that... tja, it's been the best summary when someone said, "turn you to the men in your desk and tell you, if the revolution starts to support you." the truth is that we've already supported you for a long time. "
2022-03-23 22:52:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:52:13 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need is still the mother of invention, and a large part of the design work that we're at our plane most staggering, was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variables and a cooling system that allows us to use in the aircraft, or if you're able to operate in the same direction, or if you can either get a constant conditioning for a constant conditioning, or if you can either have to a constant conditioning device, it's a constant conditioning for a constant conditioning device, or the air conditioning, it allows us to a constant conditioning for a constant conditioning, or if you can't have to a constant conditional conditioning, it would be able space, it would allow us to operate, or if you can either be able, it would be able, it would be able, it would have to operate,
2022-03-23 22:52:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:52:13 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.763 | ppl 6.79 | bleu 29.21 | wps 3277.8 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.21
2022-03-23 22:52:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 22:52:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 22:52:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 22:52:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.21) (writing took 0.8267154949717224 seconds)
2022-03-23 22:52:14 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 22:52:14 | INFO | train | epoch 028 | loss 2.732 | ppl 6.65 | wps 7864 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.731 | loss_scale 4 | train_wall 445 | gb_free 13.3 | wall 14100
2022-03-23 22:52:14 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 22:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:52:41 | INFO | train_inner | epoch 029:      9 / 157 loss=2.76, ppl=6.77, wps=7379.4, ups=0.29, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.771, loss_scale=4, train_wall=284, gb_free=13.2, wall=14127
2022-03-23 22:57:24 | INFO | train_inner | epoch 029:    109 / 157 loss=2.657, ppl=6.31, wps=8882.1, ups=0.35, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.706, loss_scale=4, train_wall=283, gb_free=13.1, wall=14410
2022-03-23 22:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:59:45 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 22:59:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:59:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 22:59:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:59:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will transcribe two new pigs.
2022-03-23 22:59:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:00:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frogs are served with salz and ppeffer.
2022-03-23 23:00:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:00:09 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 23:00:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:00:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of the human responsibility for wildlife, the number of wildwildlife grew again, and that's a basis for conservation in namibia.
2022-03-23 23:00:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:00:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like it if you move because your movements use, and so the superconductor disorder.
2022-03-23 23:00:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:00:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial, which restores the big contextures of the face and the basic form, and through the information that pulls all the por-por-structure and folds.
2022-03-23 23:00:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:00:33 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it highly interesting and appropriate to me here at tedwomen, is that... tja, when dinner became sucked it the best, when someone said, "turn you to men on your desk and tell you, 'when the revolution starts to support you, we've already supported you that topic for a long time."
2022-03-23 23:00:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:00:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane is the most proud toolbox, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a cooling system that allows us to use aircraft, or if you can use a specific, or if you can use a mechanism, or if you can either be able to use a mechanism, or if you can't use a mechanism until you can use a mechanism, or if you can use a mechanism until you can use a mechanism, or if you can either, or if you can use a mechanism.
2022-03-23 23:00:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:00:35 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.714 | ppl 6.56 | bleu 29.1 | wps 3279.7 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 29.21
2022-03-23 23:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 23:00:35 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 23:00:35 | INFO | train | epoch 029 | loss 2.644 | ppl 6.25 | wps 7876.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.704 | loss_scale 4 | train_wall 445 | gb_free 12.9 | wall 14601
2022-03-23 23:00:36 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 23:00:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:03:04 | INFO | train_inner | epoch 030:     52 / 157 loss=2.601, ppl=6.07, wps=7365.5, ups=0.29, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.674, loss_scale=4, train_wall=284, gb_free=13.5, wall=14750
2022-03-23 23:07:49 | INFO | train_inner | epoch 030:    152 / 157 loss=2.532, ppl=5.78, wps=8887.4, ups=0.35, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.643, loss_scale=4, train_wall=285, gb_free=14.3, wall=15035
2022-03-23 23:08:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:08:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these piebsters on the clinic.
2022-03-23 23:08:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:08:14 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that i think most of you here.
2022-03-23 23:08:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:08:20 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 23:08:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:08:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salce and pitcase.
2022-03-23 23:08:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:08:32 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its minds are on the track.
2022-03-23 23:08:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:08:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the case that people have taken responsibility for wildlife, the number of wildlife grew again, and that's become a foundation for conservation in namibia.
2022-03-23 23:08:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:08:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught inside, but the superconductors don't like it if they're moving because their movements use their energy, and so the superconducting disorder.
2022-03-23 23:08:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:08:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face that restores the big constructures of the face and the basic shape, and through the one information that causes the whole porter structure and all the ffits.
2022-03-23 23:08:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:08:55 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that makes it highly interesting and appropriate to me here at tedwomen is that... tja, when dinner was best summarized when someone said, "turn on the men on your table and tell them," the truth is that we've already been supporting you for a long time. "
2022-03-23 23:08:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:08:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our aircraft was a result that we had to solve the unique problems associated with doing it on the ground -- everything from a continuous system that allows us to use a special traffic and a refrigerator to a particular cycle, if you could use a specific operating machine, or if you can use it to a specific traffic.
2022-03-23 23:08:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:08:57 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.675 | ppl 6.38 | bleu 29.58 | wps 3393.7 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 29.58
2022-03-23 23:08:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 23:08:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 23:08:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 23:08:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 29.58) (writing took 0.8360600140877068 seconds)
2022-03-23 23:08:58 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 23:08:58 | INFO | train | epoch 030 | loss 2.547 | ppl 5.84 | wps 7860.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.659 | loss_scale 4 | train_wall 447 | gb_free 12.9 | wall 15104
2022-03-23 23:08:58 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 23:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:13:33 | INFO | train_inner | epoch 031:     95 / 157 loss=2.501, ppl=5.66, wps=7413.2, ups=0.29, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.667, loss_scale=4, train_wall=289, gb_free=13.1, wall=15379
2022-03-23 23:16:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:16:29 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 23:16:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:16:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 23:16:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:16:40 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will cross two new pigs.
2022-03-23 23:16:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:16:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and psuffer.
2022-03-23 23:16:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:16:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-23 23:16:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:16:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people adopted responsibility for wildlife, the number of wildanimals grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 23:16:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:17:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines caught inside, but the superconductor doesn't like it if you move, because your movements use your energy, and so the superconductive disorder.
2022-03-23 23:17:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:17:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, which restores the big constructures of the face and restores it through the one information that pulls the whole porter structure and all the fffat.
2022-03-23 23:17:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:17:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... tja, when striking dinner was best summarized when someone said, "turn you to the men in your table and say," if the revolution begins to support you. '"the truth is that we've been supporting you for a long time."
2022-03-23 23:17:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:17:19 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're on our airplane is staggering, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuously variable engine and a refrigeration system that allows us to use aircraft in the aircraft until we can use it in the air conditioning, or if you put it in the air conditioning, it in the air conditioning system, or the air conditioning system, it's the air conditioning system, it's the air conditioning system, it's available to a specific way to a device.
2022-03-23 23:17:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:17:19 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.625 | ppl 6.17 | bleu 30.24 | wps 3303.5 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.24
2022-03-23 23:17:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 23:17:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 23:17:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 23:17:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 30.24) (writing took 0.845680674072355 seconds)
2022-03-23 23:17:19 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 23:17:19 | INFO | train | epoch 031 | loss 2.49 | ppl 5.62 | wps 7868.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.667 | loss_scale 4 | train_wall 445 | gb_free 12.9 | wall 15606
2022-03-23 23:17:20 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 23:17:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:19:10 | INFO | train_inner | epoch 032:     38 / 157 loss=2.418, ppl=5.34, wps=7394.5, ups=0.3, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.636, loss_scale=4, train_wall=280, gb_free=13.9, wall=15716
2022-03-23 23:23:55 | INFO | train_inner | epoch 032:    138 / 157 loss=2.454, ppl=5.48, wps=8868.1, ups=0.35, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.71, loss_scale=4, train_wall=285, gb_free=13.9, wall=16001
2022-03-23 23:24:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:24:51 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 23:24:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:24:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 23:24:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:25:02 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 23:25:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:25:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frogs are served with salz and pitcase.
2022-03-23 23:25:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:25:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its minds are on the track.
2022-03-23 23:25:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:25:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew again. and that's become a foundation for conservation in namibia.
2022-03-23 23:25:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:25:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductive disorder.
2022-03-23 23:25:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:25:32 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big constructions of the face, and restores it through the basic shape, and refolding all the porter structure and all the folds.
2022-03-23 23:25:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:25:38 | INFO | fairseq.tasks.translation | example hypothesis: it's one of the reasons that makes it very interesting and measured to me here at tedwomen is that... tja, when congestion dinner, it was best summarized when someone said, "turn you to the men in your desk and tell you, 'when the revolution begins, we'll support you.'" the truth is that we've been supporting you for a long time. "
2022-03-23 23:25:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:25:40 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a large part of the design work that we're stumbling at our plane was a result that we had to solve the unique problems that were connected to it -- everything from a continual variables, and a refrigeration system, that allows us to use aircraft in the gogo and use it to a specific device, or to the driver's transport, or to a specific, and to the prophecy, which is, to the ground, which is, to the fabric of a machine.
2022-03-23 23:25:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:25:41 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.591 | ppl 6.03 | bleu 29.8 | wps 3299.6 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 30.24
2022-03-23 23:25:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 23:25:41 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 23:25:41 | INFO | train | epoch 032 | loss 2.428 | ppl 5.38 | wps 7881.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.681 | loss_scale 4 | train_wall 445 | gb_free 14 | wall 16107
2022-03-23 23:25:41 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 23:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:29:34 | INFO | train_inner | epoch 033:     81 / 157 loss=2.321, ppl=5, wps=7413.6, ups=0.3, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.669, loss_scale=4, train_wall=282, gb_free=13.6, wall=16340
2022-03-23 23:33:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:33:13 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 23:33:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:33:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably most of you know here.
2022-03-23 23:33:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:33:24 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of the two new pigs.
2022-03-23 23:33:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:33:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and psuitcase.
2022-03-23 23:33:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:33:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-23 23:33:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:33:42 | INFO | fairseq.tasks.translation | example hypothesis: and in the sauce of people like the human responsibility for wildlife, the number of wildlife wildlife grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 23:33:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:33:49 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it if you move because your movements use your energy, and so the superconducting disorder.
2022-03-23 23:33:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:33:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial sscan that restores the big constructions of the face and restores it through the very one information that draws the whole porter structure and all the ffone fold.
2022-03-23 23:33:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:34:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... tja, when praying dinner, it was best summarized when someone said, "turn you to the men in your desk and tell you, 'if the revolution starts to support you,'" the truth is that we've already supported you for this topic for a long time, and then we've been supporting you, "cake syrwanda cake," and then we've got a long time, "cake cake," and then we've got a long term term term term term term term term term term term term term term "cake," cake, "and then you're sending you're sending you to the" cake, "cake."
2022-03-23 23:34:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:34:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane the staggering, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variables, and a refrigeration system that allows us to use aircraft in the go-to-fly, or to make a specific wheelchair, to the ground, to the propelled, if you had to do it.
2022-03-23 23:34:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:34:03 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.533 | ppl 5.79 | bleu 31.16 | wps 3222.9 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.16
2022-03-23 23:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 23:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 23:34:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 23:34:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.16) (writing took 0.9047728879377246 seconds)
2022-03-23 23:34:04 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 23:34:04 | INFO | train | epoch 033 | loss 2.37 | ppl 5.17 | wps 7839.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.68 | loss_scale 4 | train_wall 445 | gb_free 13.5 | wall 16610
2022-03-23 23:34:05 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 23:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:35:15 | INFO | train_inner | epoch 034:     24 / 157 loss=2.404, ppl=5.29, wps=7359.4, ups=0.29, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.686, loss_scale=4, train_wall=283, gb_free=13.4, wall=16681
2022-03-23 23:39:59 | INFO | train_inner | epoch 034:    124 / 157 loss=2.277, ppl=4.85, wps=8868.9, ups=0.35, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.67, loss_scale=4, train_wall=283, gb_free=13.2, wall=16965
2022-03-23 23:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:41:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 23:41:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:41:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably knows most of us here.
2022-03-23 23:41:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:41:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will cross two new pigs.
2022-03-23 23:41:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:41:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salz and pills.
2022-03-23 23:41:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:41:59 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-23 23:41:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:42:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildanimals grew back again, and that's a foundation for conservation in namibia.
2022-03-23 23:42:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:42:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are captured inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 23:42:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:42:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, which restores the big constraints of the face and restoring it through the very basic form of information that refuse all the porter structure and all the fits.
2022-03-23 23:42:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:42:24 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that makes it very interesting and measured to me here at tedwomen is that... tja, when dinner was best summarized, when someone said, "turn you to the men in your desk and tell you," when the revolution begins, then we support you. "the truth, women are supporting you for you for a long time."
2022-03-23 23:42:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:42:26 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, we still have to operate the mother of invention, and a large part of the design work that we're staggering on our plane was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variables and a refrigeration of liquid, that allows us to use a plane in the go-to-one, or to a specific seizure, if you're going to operate, if you're connected to a seizure, if you're going to the contrast, or to a seizure, if you're going to a seizure, if you're going to the shelter, or to a seizure, if you're going to a seizure, you're going to the shelter, you're going to the shelter, and you're going to the ground.
2022-03-23 23:42:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:42:26 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.513 | ppl 5.71 | bleu 31.07 | wps 3253.1 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 31.16
2022-03-23 23:42:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 23:42:26 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 23:42:26 | INFO | train | epoch 034 | loss 2.301 | ppl 4.93 | wps 7872.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.677 | loss_scale 4 | train_wall 444 | gb_free 13.2 | wall 17112
2022-03-23 23:42:26 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 23:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:45:37 | INFO | train_inner | epoch 035:     67 / 157 loss=2.306, ppl=4.95, wps=7419.9, ups=0.3, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.68, loss_scale=4, train_wall=282, gb_free=14.2, wall=17303
2022-03-23 23:49:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:49:55 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 23:49:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:50:00 | INFO | fairseq.tasks.translation | example hypothesis: this is doha's skyline skyline, which i think most of you know here.
2022-03-23 23:50:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:50:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to transcend two new pigs.
2022-03-23 23:50:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:50:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pffer.
2022-03-23 23:50:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:50:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-23 23:50:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:50:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew up again, and that has become a foundation for conservation in namibia.
2022-03-23 23:50:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:50:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 23:50:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:50:36 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can, which restores the big conversion of the face and the basic form, and through the very one information that pulls the entire por-structure and all folds.
2022-03-23 23:50:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:50:42 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... tja, when dinner was summarized at best, when someone said, "turn you to the men in your table and tell them," if the revolution starts to support you. "the truth, women, love is that we've already supported you with a long time of carson's camon's"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 23:50:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:50:45 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need to be the mother of invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a refrigerating system of refrigeration that allows us to use a aircraft machine in the go-to-special transport, or if you go to a specific propellism, or if you can see that you can use the auto space of a specific propellism, or if you can use, or if you can use it's going to a specific propellability, or if you can use it's going to the ground -- everything, all sorts of devices that allows you can use it's going to a mechanical propelled, or if you can use it's going to the aircraft, if you can use it's going to go into a specific propellability to the aircraft, or if you can use it's going to the ground --
2022-03-23 23:50:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:50:45 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.491 | ppl 5.62 | bleu 31.11 | wps 3269.5 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 31.16
2022-03-23 23:50:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 23:50:45 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 23:50:45 | INFO | train | epoch 035 | loss 2.242 | ppl 4.73 | wps 7917.8 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.654 | loss_scale 4 | train_wall 442 | gb_free 12.9 | wall 17611
2022-03-23 23:50:45 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 23:50:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:51:12 | INFO | train_inner | epoch 036:     10 / 157 loss=2.22, ppl=4.66, wps=7439, ups=0.3, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.65, loss_scale=4, train_wall=279, gb_free=14.2, wall=17638
2022-03-23 23:55:55 | INFO | train_inner | epoch 036:    110 / 157 loss=2.17, ppl=4.5, wps=8955.4, ups=0.35, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.657, loss_scale=4, train_wall=282, gb_free=14.2, wall=17921
2022-03-23 23:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:58:10 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 23:58:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:58:16 | INFO | fairseq.tasks.translation | example hypothesis: that's doha's skyline skyline, which probably most of you know here.
2022-03-23 23:58:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:58:22 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 23:58:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:58:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salt and pills.
2022-03-23 23:58:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:58:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 23:58:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:58:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people taking responsibility for wildlife, the number of wildanimals grew up again, and that's a basis for conservation in namibia.
2022-03-23 23:58:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:58:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconduction disorder.
2022-03-23 23:58:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:58:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, which restores the big constraints of the face, and restores it through the very basic form of information that pulls the entire por-structure, and all the ffils.
2022-03-23 23:58:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:58:58 | INFO | fairseq.tasks.translation | example hypothesis: the th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... tja, when contested dinner, it was best summarized when someone said, "turn to the men in your desk, and they say," if the revolution starts to support you. "the truth is that we've already supported you."
2022-03-23 23:58:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:59:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're stumbling on our airplane is a result of the fact that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuous variables and a refrigeration system of refrigeration, that it allows us to use a aircraft in the gogo, or an aircraft, or something that you're aggressive, or whatever you're aggressive, and you're going to get rid of the propellity, or whatever you're aggressive, and you're aggressive, and you're aggressively varied to the most frigerating, and you're aggressively variables you're aggressively varied to the most frigergergerator, and you're going to the ground, and you're aggressively variables you're going to get rid of it, and you're aggressively varied to get rid of it, and
2022-03-23 23:59:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:59:00 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.467 | ppl 5.53 | bleu 31.3 | wps 3270 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 31.3
2022-03-23 23:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 23:59:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 23:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-23 23:59:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 31.3) (writing took 0.8850711840204895 seconds)
2022-03-23 23:59:01 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 23:59:01 | INFO | train | epoch 036 | loss 2.186 | ppl 4.55 | wps 7953.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.674 | loss_scale 4 | train_wall 439 | gb_free 13.4 | wall 18107
2022-03-23 23:59:02 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 23:59:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-24 00:01:34 | INFO | train_inner | epoch 037:     53 / 157 loss=2.127, ppl=4.37, wps=7528, ups=0.3, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.683, loss_scale=4, train_wall=282, gb_free=14.2, wall=18260
2022-03-24 00:06:09 | INFO | train_inner | epoch 037:    153 / 157 loss=2.222, ppl=4.67, wps=9016.2, ups=0.36, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.698, loss_scale=4, train_wall=275, gb_free=13.1, wall=18535
2022-03-24 00:06:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-24 00:06:25 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-24 00:06:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-24 00:06:31 | INFO | fairseq.tasks.translation | example hypothesis: this is doha's skyline skyline, who probably knows most of you here.
2022-03-24 00:06:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-24 00:06:37 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of edinments that are going to be able to transcend two new pigs.
2022-03-24 00:06:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-24 00:06:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salce and pills.
2022-03-24 00:06:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-24 00:06:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on its head and just understand exactly what all his thoughts are on the track.
2022-03-24 00:06:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-24 00:06:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of human responsibility for wildlife, wildlife was growing again, and that has become a foundation for conservation in namibia.
2022-03-24 00:06:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-24 00:07:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconducting disorders.
2022-03-24 00:07:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-24 00:07:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face that restores the big constraints of the face and the fundamental form of information that draws the entire por-structure and all the fine fold.
2022-03-24 00:07:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-24 00:07:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons why it's been very interesting and measured to be here at tedwomen is that... tja, when controversial dinner was best summarized when someone said, "turn you to men in your desk and tell them, 'if the revolution starts to support you.'" '"the truth, love, women, love is that we've already supported you with this issue for a long time when you've already supported a long term, you've already been supporting carriculum, you've already supported carrochel's" and then you've been supported by carrilling, "button your own," and then you know, "button the future," and then you're going to give you know, "button the" and then you know, "and then you know,"' "
2022-03-24 00:07:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-24 00:07:16 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, necessibility is still the mother of invention, and a large part of the design work that we're most proud of on our plane, was a result that we had to solve the unique problems that were connected to operate it on the ground -- everything, from a continuously variable drivers and a refrigerating system with refrigeration that allows us to use an aircraft machine to use a stop-dust machine in the aircraft in the aircraft, to a special transportation of a specific shield, to a specific shield, to a specific shield, to an engine, to a specific propelled, to a specific propelled, to a certain propelled, if you can see that allows us to a specific propellant table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table table,
2022-03-24 00:07:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-24 00:07:16 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 2.428 | ppl 5.38 | bleu 31.98 | wps 3175.9 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 31.98
2022-03-24 00:07:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-24 00:07:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-24 00:07:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-24 00:07:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 31.98) (writing took 0.8513999958522618 seconds)
2022-03-24 00:07:17 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-24 00:07:17 | INFO | train | epoch 037 | loss 2.152 | ppl 4.44 | wps 7960.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.682 | loss_scale 4 | train_wall 437 | gb_free 13.7 | wall 18603
2022-03-24 00:07:18 | INFO | fairseq.trainer | begin training epoch 38
2022-03-24 00:07:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-24 00:11:42 | INFO | train_inner | epoch 038:     96 / 157 loss=2.119, ppl=4.34, wps=7392.6, ups=0.3, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.71, loss_scale=4, train_wall=274, gb_free=13.9, wall=18868
2022-03-24 00:14:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-24 00:14:42 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-24 00:14:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-24 00:14:47 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-24 00:14:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-24 00:14:53 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-24 00:14:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-24 00:14:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frogs are served with salce and pepper.
2022-03-24 00:14:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-24 00:15:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and just understand exactly what all its thoughts are on the track.
2022-03-24 00:15:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-24 00:15:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of humans being responsible for wildlife survival, wild animals grew up again, and this has become a foundation for conservation in namibia.
2022-03-24 00:15:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-24 00:15:18 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines captured inside, but the superconductor doesn't like it when you move because your movements use energy, and that's how the superconduction behaves.
2022-03-24 00:15:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-24 00:15:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can begin with a traditional facial can that restore the big constructions of the face and the basic form, and through the information that will fold the entire pore structure and all the fffone.
2022-03-24 00:15:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-24 00:15:30 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons why it's very interesting and appropriate for me to be here at tedwomen is that... tja, when he summoned it best when someone said, "turn down to the men in your desk and tell you, 'when the revolution begins to support you.'" the truth is that we've already been supported you with this theme for a long time. "
2022-03-24 00:15:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-24 00:15:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're stumbling on our airplane was a result that we had to solve unique problems that were connected to operating it on the ground -- everything from a continually variable drivers and a refrigeration system of refrigeration that allows us to use an aircraft machine in the go-to-and traffic to become a special propellant, or to a seizure, which is when you're either propelled to a propulsive ground, or if you're going to be able to be able to be able to do it's going to operate on the ground, it's going to be solved, it's going to be solved, it's going to be solved, you can see that it's going to be solved by a mechanism, it's going to be solved, it's always variable to be solved in a stealing the air conditionally varied to be solved in the ground, it's going to be solved
2022-03-24 00:15:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-24 00:15:32 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 2.407 | ppl 5.3 | bleu 31.04 | wps 3233.3 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 31.98
2022-03-24 00:15:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-24 00:15:32 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-24 00:15:32 | INFO | train | epoch 038 | loss 2.109 | ppl 4.32 | wps 7978.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.703 | loss_scale 4 | train_wall 438 | gb_free 14.5 | wall 19098
2022-03-24 00:15:33 | INFO | fairseq.trainer | begin training epoch 39
2022-03-24 00:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-24 00:17:25 | INFO | train_inner | epoch 039:     39 / 157 loss=2.007, ppl=4.02, wps=7588.4, ups=0.29, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.642, loss_scale=4, train_wall=287, gb_free=13.2, wall=19212
2022-03-24 00:22:02 | INFO | train_inner | epoch 039:    139 / 157 loss=2.097, ppl=4.28, wps=8988.9, ups=0.36, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.745, loss_scale=4, train_wall=276, gb_free=14.2, wall=19488
2022-03-24 00:22:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-24 00:22:56 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-24 00:22:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-24 00:23:01 | INFO | fairseq.tasks.translation | example hypothesis: this is doha's skyline skyline, which i think most of you know here.
2022-03-24 00:23:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-24 00:23:07 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to be able to cross two new pigs.
2022-03-24 00:23:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-24 00:23:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salz and pepper.
2022-03-24 00:23:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-24 00:23:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-24 00:23:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-24 00:23:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of humans taking responsibility for wildlife survival, wildlife production grew up again, and this has become a basis for conservation in namibia.
2022-03-24 00:23:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-24 00:23:31 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like it, if you move around, you use your movements, and that's how the superconductor behaves.
2022-03-24 00:23:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-24 00:23:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that comes from this reflective reflection, we can begin with a traditional facial sscan that restores the big contextures of the face and the fundamental form, and by the one that information that refers all the porting structure and all the fine folds.
2022-03-24 00:23:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-24 00:23:43 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... tyes, when controversial dinner, it was best summarized when someone said, "turn you to the men in your desk and tell you, 'when the revolution starts to support you.'" '"' the truth, women, we have been supporting you at this theme for a long time."
2022-03-24 00:23:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-24 00:23:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a lot of the design work that we're stumbling on on our airplane was a result of the fact that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable and cooling system of liquid that allows us to use aircraft in the closest and traffic, to a particular propellant, to a contrast, to a contrast, to the ground, to the wheel, to the contrast, to the contrast.
2022-03-24 00:23:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-24 00:23:45 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 2.367 | ppl 5.16 | bleu 31.98 | wps 3308.1 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 31.98
2022-03-24 00:23:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-24 00:23:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-24 00:23:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt
2022-03-24 00:23:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.64_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 31.98) (writing took 0.8573028678074479 seconds)
2022-03-24 00:23:46 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-24 00:23:46 | INFO | train | epoch 039 | loss 2.045 | ppl 4.13 | wps 7999.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.693 | loss_scale 4 | train_wall 437 | gb_free 14.3 | wall 19592
2022-03-24 00:23:46 | INFO | fairseq.trainer | begin training epoch 40
2022-03-24 00:23:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-24 00:27:34 | INFO | train_inner | epoch 040:     82 / 157 loss=2.002, ppl=4, wps=7459.5, ups=0.3, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.657, loss_scale=4, train_wall=276, gb_free=13.7, wall=19820
2022-03-24 00:31:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-24 00:31:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-24 00:31:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-24 00:31:16 | INFO | fairseq.tasks.translation | example hypothesis: this is doha's skyline, who i think most of you know here.
2022-03-24 00:31:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-24 00:31:22 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to be translated into two new pigs.
2022-03-24 00:31:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-24 00:31:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and pepper.
2022-03-24 00:31:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-24 00:31:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-24 00:31:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-24 00:31:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of humans taking responsibility for wildlife, the wild animals grew up again, and this has become a foundation for conservation in namibia.
2022-03-24 00:31:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-24 00:31:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like to move because their movements use energy, and so the superconduction.
2022-03-24 00:31:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-24 00:31:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, which restores the big constraints of the face and reproduce the basic form, and through the information that all the por-structure and all the ffits.
2022-03-24 00:31:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-24 00:31:58 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... tja, when controversial dinner got summed it best, when someone said, "turn you to the men in your desk, and tell them," if the revolution starts, then we support you. "the truth, women, we've been supporting you at this long time. carrachel silly tubes,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [our] ["] ["] ["] ["] ["] [] ["] [
2022-03-24 00:31:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-24 00:32:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a lot of the design work that we're on our airplane is the result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continual variables, and a cooling system that allows us to use aircraft in the aircraft and go-traffic to a special, which is the propellant, either to the aircraft, to the aircraft, to the aircraft.
2022-03-24 00:32:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-24 00:32:00 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 2.362 | ppl 5.14 | bleu 31.62 | wps 3304.5 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 31.98
2022-03-24 00:32:00 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-24 00:32:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-24 00:32:00 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-24 00:32:00 | INFO | train | epoch 040 | loss 1.992 | ppl 3.98 | wps 7992 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.687 | loss_scale 4 | train_wall 438 | gb_free 13.6 | wall 20086
2022-03-24 00:32:00 | INFO | fairseq_cli.train | done training in 20085.7 seconds
