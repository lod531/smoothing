Sender: LSF System <lsfadmin@eu-g3-072>
Subject: Job 208123611: <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.055_0.02_0.925_#1> in cluster <euler> Exited

Job <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.055_0.02_0.925_#1> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 10:20:17 2022
Job was executed on host(s) <eu-g3-072>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Mon Mar 14 10:20:44 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 10:20:44 2022
Terminated at Mon Mar 14 10:21:02 2022
Results reported at Mon Mar 14 10:21:02 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.055, 0.02, 0.925)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 32 --no-epoch-checkpoints --seed 1321671 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   8.77 sec.
    Max Memory :                                 1199 MB
    Average Memory :                             886.00 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               18801.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                6
    Run time :                                   17 sec.
    Turnaround time :                            45 sec.

The output (if any) follows:

2022-03-14 10:20:57 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1321671, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1321671, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.055, 0.02, 0.925)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 10:20:57 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-14 10:20:58 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
Calculating frequency stats:
  0%|          | 0/112584 [00:00<?, ?it/s]  1%|          | 660/112584 [00:00<00:17, 6579.94it/s]  1%|          | 1318/112584 [00:00<00:19, 5736.77it/s]  2%|▏         | 1899/112584 [00:00<00:19, 5591.48it/s]  2%|▏         | 2462/112584 [00:00<00:20, 5496.93it/s]  3%|▎         | 3184/112584 [00:00<00:18, 6074.39it/s]  3%|▎         | 3796/112584 [00:00<00:18, 5932.47it/s]  4%|▍         | 4498/112584 [00:00<00:17, 6270.11it/s]  5%|▍         | 5191/112584 [00:00<00:16, 6473.26it/s]  5%|▌         | 5861/112584 [00:00<00:16, 6542.04it/s]  6%|▌         | 6518/112584 [00:01<00:17, 5955.63it/s]  6%|▋         | 7125/112584 [00:01<00:18, 5830.00it/s]  7%|▋         | 7763/112584 [00:01<00:17, 5983.54it/s]  7%|▋         | 8368/112584 [00:01<00:17, 5994.28it/s]  8%|▊         | 8972/112584 [00:01<00:17, 5883.82it/s]  8%|▊         | 9564/112584 [00:01<00:17, 5859.29it/s]  9%|▉         | 10240/112584 [00:01<00:16, 6120.28it/s] 10%|▉         | 10855/112584 [00:01<00:17, 5838.65it/s] 10%|█         | 11451/112584 [00:01<00:17, 5870.28it/s] 11%|█         | 12102/112584 [00:02<00:16, 6053.57it/s] 11%|█▏        | 12711/112584 [00:02<00:17, 5867.97it/s] 12%|█▏        | 13333/112584 [00:02<00:16, 5965.12it/s] 12%|█▏        | 13994/112584 [00:02<00:16, 6142.95it/s] 13%|█▎        | 14611/112584 [00:02<00:16, 6042.39it/s] 14%|█▎        | 15284/112584 [00:02<00:15, 6234.71it/s] 14%|█▍        | 15910/112584 [00:02<00:16, 5907.74it/s] 15%|█▍        | 16506/112584 [00:02<00:16, 5784.51it/s] 15%|█▌        | 17114/112584 [00:02<00:16, 5866.85it/s] 16%|█▌        | 17704/112584 [00:02<00:16, 5833.36it/s] 16%|█▌        | 18292/112584 [00:03<00:16, 5845.97it/s] 16%|█▋        | 18391/112584 [00:03<00:15, 5970.65it/s]
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 99, in main
    criterion = task.build_criterion(cfg.criterion)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 668, in build_criterion
    return criterions.build_criterion(args, self)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/__init__.py", line 29, in build_criterion
    return build_criterion_(cfg, task)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/registry.py", line 61, in build_x
    return builder(cfg, *extra_args, **extra_kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/fairseq_criterion.py", line 60, in build_criterion
    return cls(**init_args)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/jelinek_mercer.py", line 55, in __init__
    self.fqs, self.N = crit_utils.get_fqs(self)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/utils.py", line 26, in get_fqs
    fqs[token.item()] += 1
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g3-073>
Subject: Job 208123672: <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.055_0.02_0.925_#1> in cluster <euler> Exited

Job <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.055_0.02_0.925_#1> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 10:21:35 2022
Job was executed on host(s) <eu-g3-073>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Mon Mar 14 10:21:59 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 10:21:59 2022
Terminated at Tue Mar 15 06:20:18 2022
Results reported at Tue Mar 15 06:20:18 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.055, 0.02, 0.925)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 32 --no-epoch-checkpoints --seed 1321671 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   71860.27 sec.
    Max Memory :                                 4822 MB
    Average Memory :                             3222.91 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15178.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   71899 sec.
    Turnaround time :                            71923 sec.

The output (if any) follows:

2022-03-14 10:22:05 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1321671, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1321671, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.055, 0.02, 0.925)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 10:22:06 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-14 10:22:06 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
Calculating frequency stats:
  0%|          | 0/112584 [00:00<?, ?it/s]  1%|          | 654/112584 [00:00<00:17, 6534.71it/s]  1%|          | 1308/112584 [00:00<00:19, 5618.29it/s]  2%|▏         | 1879/112584 [00:00<00:20, 5528.23it/s]  2%|▏         | 2436/112584 [00:00<00:20, 5396.61it/s]  3%|▎         | 3166/112584 [00:00<00:18, 6033.60it/s]  3%|▎         | 3775/112584 [00:00<00:18, 5836.11it/s]  4%|▍         | 4461/112584 [00:00<00:17, 6143.00it/s]  5%|▍         | 5164/112584 [00:00<00:16, 6414.50it/s]  5%|▌         | 5810/112584 [00:00<00:16, 6416.24it/s]  6%|▌         | 6455/112584 [00:01<00:17, 5964.69it/s]  6%|▋         | 7059/112584 [00:01<00:18, 5787.49it/s]  7%|▋         | 7658/112584 [00:01<00:17, 5844.72it/s]  7%|▋         | 8247/112584 [00:01<00:18, 5780.29it/s]  8%|▊         | 8828/112584 [00:01<00:18, 5733.71it/s]  8%|▊         | 9443/112584 [00:01<00:17, 5853.97it/s]  9%|▉         | 10046/112584 [00:01<00:17, 5905.20it/s]  9%|▉         | 10638/112584 [00:01<00:17, 5721.33it/s] 10%|▉         | 11226/112584 [00:01<00:17, 5767.16it/s] 10%|█         | 11805/112584 [00:02<00:17, 5631.00it/s] 11%|█         | 12444/112584 [00:02<00:17, 5850.37it/s] 12%|█▏        | 13031/112584 [00:02<00:17, 5792.98it/s] 12%|█▏        | 13695/112584 [00:02<00:16, 6038.78it/s] 13%|█▎        | 14301/112584 [00:02<00:16, 5993.14it/s] 13%|█▎        | 14902/112584 [00:02<00:16, 5969.55it/s] 14%|█▍        | 15500/112584 [00:02<00:16, 5806.01it/s] 14%|█▍        | 16082/112584 [00:02<00:16, 5696.95it/s] 15%|█▍        | 16653/112584 [00:02<00:17, 5639.42it/s] 15%|█▌        | 17267/112584 [00:02<00:16, 5774.84it/s] 16%|█▌        | 17871/112584 [00:03<00:16, 5846.28it/s] 16%|█▋        | 18457/112584 [00:03<00:16, 5686.59it/s] 17%|█▋        | 19151/112584 [00:03<00:15, 6041.98it/s] 18%|█▊        | 19798/112584 [00:03<00:15, 6163.51it/s] 18%|█▊        | 20416/112584 [00:03<00:15, 5857.86it/s] 19%|█▊        | 21019/112584 [00:03<00:15, 5902.40it/s] 19%|█▉        | 21613/112584 [00:03<00:16, 5648.15it/s] 20%|█▉        | 22214/112584 [00:03<00:15, 5745.60it/s] 20%|██        | 22860/112584 [00:03<00:15, 5949.27it/s] 21%|██        | 23488/112584 [00:03<00:14, 6035.59it/s] 22%|██▏       | 24210/112584 [00:04<00:13, 6381.22it/s] 22%|██▏       | 24884/112584 [00:04<00:13, 6481.97it/s] 23%|██▎       | 25535/112584 [00:04<00:13, 6462.42it/s] 23%|██▎       | 26183/112584 [00:04<00:13, 6184.29it/s] 24%|██▍       | 26805/112584 [00:04<00:14, 5773.30it/s] 24%|██▍       | 27390/112584 [00:04<00:15, 5655.24it/s] 25%|██▍       | 27961/112584 [00:04<00:15, 5613.26it/s] 25%|██▌       | 28698/112584 [00:04<00:13, 6110.11it/s] 26%|██▌       | 29315/112584 [00:04<00:14, 5807.51it/s] 27%|██▋       | 29950/112584 [00:05<00:13, 5955.61it/s] 27%|██▋       | 30551/112584 [00:05<00:14, 5736.90it/s] 28%|██▊       | 31130/112584 [00:05<00:14, 5446.02it/s] 28%|██▊       | 31774/112584 [00:05<00:14, 5717.83it/s] 29%|██▊       | 32352/112584 [00:05<00:14, 5440.48it/s] 29%|██▉       | 32911/112584 [00:05<00:14, 5481.72it/s] 30%|██▉       | 33464/112584 [00:05<00:14, 5460.11it/s] 30%|███       | 34050/112584 [00:05<00:14, 5574.68it/s] 31%|███       | 34694/112584 [00:05<00:13, 5824.00it/s] 31%|███▏      | 35279/112584 [00:06<00:13, 5676.87it/s] 32%|███▏      | 35850/112584 [00:06<00:13, 5634.08it/s] 32%|███▏      | 36451/112584 [00:06<00:13, 5741.28it/s] 33%|███▎      | 37027/112584 [00:06<00:13, 5603.32it/s] 33%|███▎      | 37589/112584 [00:06<00:13, 5371.41it/s] 34%|███▍      | 38188/112584 [00:06<00:13, 5543.80it/s] 34%|███▍      | 38752/112584 [00:06<00:13, 5567.86it/s] 35%|███▍      | 39326/112584 [00:06<00:13, 5615.40it/s] 35%|███▌      | 39933/112584 [00:06<00:12, 5739.50it/s] 36%|███▌      | 40574/112584 [00:06<00:12, 5935.24it/s] 37%|███▋      | 41169/112584 [00:07<00:12, 5876.37it/s] 37%|███▋      | 41758/112584 [00:07<00:12, 5581.25it/s] 38%|███▊      | 42320/112584 [00:07<00:12, 5460.24it/s] 38%|███▊      | 42869/112584 [00:07<00:12, 5451.72it/s] 39%|███▊      | 43416/112584 [00:07<00:12, 5406.27it/s] 39%|███▉      | 44063/112584 [00:07<00:11, 5712.44it/s] 40%|███▉      | 44705/112584 [00:07<00:11, 5919.64it/s] 40%|████      | 45299/112584 [00:07<00:11, 5772.93it/s] 41%|████      | 45937/112584 [00:07<00:11, 5949.24it/s] 41%|████▏     | 46579/112584 [00:08<00:10, 6084.82it/s] 42%|████▏     | 47319/112584 [00:08<00:10, 6471.72it/s] 43%|████▎     | 48133/112584 [00:08<00:09, 6964.45it/s] 43%|████▎     | 48832/112584 [00:08<00:09, 6646.93it/s] 44%|████▍     | 49568/112584 [00:08<00:09, 6848.31it/s] 45%|████▍     | 50257/112584 [00:08<00:09, 6275.05it/s] 45%|████▌     | 50896/112584 [00:08<00:10, 5989.48it/s] 46%|████▌     | 51504/112584 [00:08<00:10, 5936.13it/s] 46%|████▋     | 52305/112584 [00:08<00:09, 6511.58it/s] 47%|████▋     | 52965/112584 [00:08<00:09, 6501.22it/s] 48%|████▊     | 53622/112584 [00:09<00:09, 6117.46it/s] 48%|████▊     | 54242/112584 [00:09<00:09, 5912.19it/s] 49%|████▊     | 54840/112584 [00:09<00:09, 5826.73it/s] 49%|████▉     | 55427/112584 [00:09<00:09, 5826.00it/s] 50%|████▉     | 56130/112584 [00:09<00:09, 6168.32it/s] 50%|█████     | 56751/112584 [00:09<00:09, 5815.72it/s] 51%|█████     | 57339/112584 [00:09<00:10, 5501.77it/s] 51%|█████▏    | 57949/112584 [00:09<00:09, 5662.68it/s] 52%|█████▏    | 58702/112584 [00:09<00:08, 6167.63it/s] 53%|█████▎    | 59326/112584 [00:10<00:09, 5879.04it/s] 53%|█████▎    | 59921/112584 [00:10<00:09, 5757.49it/s] 54%|█████▎    | 60502/112584 [00:10<00:09, 5771.46it/s] 54%|█████▍    | 61279/112584 [00:10<00:08, 6341.56it/s] 55%|█████▍    | 61919/112584 [00:10<00:08, 5930.43it/s] 56%|█████▌    | 62550/112584 [00:10<00:08, 6027.73it/s] 56%|█████▌    | 63160/112584 [00:10<00:08, 5807.52it/s] 57%|█████▋    | 63763/112584 [00:10<00:08, 5861.84it/s] 57%|█████▋    | 64354/112584 [00:10<00:08, 5753.10it/s] 58%|█████▊    | 64963/112584 [00:11<00:08, 5847.28it/s] 58%|█████▊    | 65551/112584 [00:11<00:08, 5680.74it/s] 59%|█████▉    | 66146/112584 [00:11<00:08, 5751.01it/s] 59%|█████▉    | 66881/112584 [00:11<00:07, 6211.93it/s] 60%|█████▉    | 67506/112584 [00:11<00:07, 5754.02it/s] 60%|██████    | 68090/112584 [00:11<00:08, 5553.87it/s] 61%|██████    | 68800/112584 [00:11<00:07, 5981.48it/s] 62%|██████▏   | 69406/112584 [00:11<00:07, 5966.50it/s] 62%|██████▏   | 70064/112584 [00:11<00:06, 6140.21it/s] 63%|██████▎   | 70683/112584 [00:12<00:07, 5910.66it/s] 63%|██████▎   | 71279/112584 [00:12<00:07, 5839.23it/s] 64%|██████▍   | 71879/112584 [00:12<00:06, 5876.70it/s] 64%|██████▍   | 72509/112584 [00:12<00:06, 5996.29it/s] 65%|██████▌   | 73236/112584 [00:12<00:06, 6368.23it/s] 66%|██████▌   | 73973/112584 [00:12<00:05, 6656.19it/s] 66%|██████▋   | 74641/112584 [00:12<00:05, 6655.83it/s] 67%|██████▋   | 75309/112584 [00:12<00:05, 6417.65it/s] 67%|██████▋   | 75954/112584 [00:12<00:05, 6306.62it/s] 68%|██████▊   | 76587/112584 [00:12<00:05, 6288.67it/s] 69%|██████▊   | 77218/112584 [00:13<00:05, 5990.24it/s] 69%|██████▉   | 77883/112584 [00:13<00:05, 6173.36it/s] 70%|██████▉   | 78504/112584 [00:13<00:05, 5849.92it/s] 70%|███████   | 79094/112584 [00:13<00:05, 5590.11it/s] 71%|███████   | 79658/112584 [00:13<00:05, 5510.62it/s] 71%|███████   | 80212/112584 [00:13<00:05, 5489.09it/s] 72%|███████▏  | 80834/112584 [00:13<00:05, 5690.70it/s] 72%|███████▏  | 81469/112584 [00:13<00:05, 5879.10it/s] 73%|███████▎  | 82060/112584 [00:13<00:05, 5771.95it/s] 73%|███████▎  | 82673/112584 [00:14<00:05, 5875.60it/s] 74%|███████▍  | 83330/112584 [00:14<00:04, 6076.85it/s] 75%|███████▍  | 83954/112584 [00:14<00:04, 6117.48it/s] 75%|███████▌  | 84567/112584 [00:14<00:04, 5926.68it/s] 76%|███████▌  | 85162/112584 [00:14<00:04, 5775.52it/s] 76%|███████▌  | 85780/112584 [00:14<00:04, 5888.72it/s] 77%|███████▋  | 86371/112584 [00:14<00:04, 5888.40it/s] 77%|███████▋  | 87055/112584 [00:14<00:04, 6166.96it/s] 78%|███████▊  | 87676/112584 [00:14<00:04, 6179.21it/s] 78%|███████▊  | 88295/112584 [00:14<00:03, 6175.55it/s] 79%|███████▉  | 88914/112584 [00:15<00:04, 5701.78it/s] 79%|███████▉  | 89492/112584 [00:15<00:04, 5655.15it/s] 80%|███████▉  | 90063/112584 [00:15<00:04, 5536.59it/s] 81%|████████  | 90642/112584 [00:15<00:03, 5603.90it/s] 81%|████████  | 91284/112584 [00:15<00:03, 5831.32it/s] 82%|████████▏ | 91870/112584 [00:15<00:03, 5790.62it/s] 82%|████████▏ | 92552/112584 [00:15<00:03, 6091.42it/s] 83%|████████▎ | 93164/112584 [00:15<00:03, 5860.78it/s] 83%|████████▎ | 93761/112584 [00:15<00:03, 5887.93it/s] 84%|████████▍ | 94353/112584 [00:16<00:03, 5779.10it/s] 84%|████████▍ | 95035/112584 [00:16<00:02, 6080.49it/s] 85%|████████▍ | 95646/112584 [00:16<00:02, 5777.47it/s] 86%|████████▌ | 96319/112584 [00:16<00:02, 6045.67it/s] 86%|████████▌ | 97099/112584 [00:16<00:02, 6539.77it/s] 87%|████████▋ | 97758/112584 [00:16<00:02, 6153.07it/s] 87%|████████▋ | 98381/112584 [00:16<00:02, 6125.51it/s] 88%|████████▊ | 98999/112584 [00:16<00:02, 5985.73it/s] 88%|████████▊ | 99602/112584 [00:16<00:02, 5751.14it/s] 89%|████████▉ | 100181/112584 [00:16<00:02, 5635.87it/s] 89%|████████▉ | 100747/112584 [00:17<00:02, 5604.01it/s] 90%|█████████ | 101360/112584 [00:17<00:01, 5753.92it/s] 91%|█████████ | 102010/112584 [00:17<00:01, 5957.60it/s] 91%|█████████ | 102608/112584 [00:17<00:01, 5838.45it/s] 92%|█████████▏| 103194/112584 [00:17<00:01, 5838.25it/s] 92%|█████████▏| 103779/112584 [00:17<00:01, 5689.38it/s] 93%|█████████▎| 104350/112584 [00:17<00:01, 5694.69it/s] 93%|█████████▎| 104951/112584 [00:17<00:01, 5786.07it/s] 94%|█████████▎| 105540/112584 [00:17<00:01, 5815.91it/s] 94%|█████████▍| 106127/112584 [00:17<00:01, 5831.27it/s] 95%|█████████▍| 106711/112584 [00:18<00:01, 5749.02it/s] 95%|█████████▌| 107287/112584 [00:18<00:00, 5614.98it/s] 96%|█████████▌| 107880/112584 [00:18<00:00, 5704.54it/s] 96%|█████████▋| 108463/112584 [00:18<00:00, 5735.29it/s] 97%|█████████▋| 109038/112584 [00:18<00:00, 5451.27it/s] 97%|█████████▋| 109610/112584 [00:18<00:00, 5518.51it/s] 98%|█████████▊| 110199/112584 [00:18<00:00, 5623.16it/s] 98%|█████████▊| 110825/112584 [00:18<00:00, 5800.07it/s] 99%|█████████▉| 111482/112584 [00:18<00:00, 6025.32it/s]100%|█████████▉| 112087/112584 [00:19<00:00, 5899.83it/s]100%|██████████| 112584/112584 [00:19<00:00, 5889.65it/s]

gathering stats for n=1
  0%|          | 0/112584 [00:00<?, ?it/s]  2%|▏         | 1832/112584 [00:00<00:06, 18312.94it/s]  3%|▎         | 3775/112584 [00:00<00:05, 18951.05it/s]  5%|▌         | 5960/112584 [00:00<00:05, 20255.57it/s]  7%|▋         | 7986/112584 [00:00<00:05, 19226.83it/s]  9%|▉         | 9958/112584 [00:00<00:05, 19385.65it/s] 11%|█         | 11902/112584 [00:00<00:05, 19215.12it/s] 12%|█▏        | 13912/112584 [00:00<00:05, 19494.86it/s] 14%|█▍        | 15865/112584 [00:00<00:04, 19401.72it/s] 16%|█▌        | 17808/112584 [00:00<00:04, 19270.58it/s] 18%|█▊        | 19869/112584 [00:01<00:04, 19674.65it/s] 19%|█▉        | 21838/112584 [00:01<00:04, 19372.48it/s] 21%|██▏       | 23968/112584 [00:01<00:04, 19945.76it/s] 23%|██▎       | 26040/112584 [00:01<00:04, 20168.59it/s] 25%|██▍       | 28059/112584 [00:01<00:04, 19470.36it/s] 27%|██▋       | 30091/112584 [00:01<00:04, 19717.59it/s] 28%|██▊       | 32068/112584 [00:01<00:04, 19041.32it/s] 30%|███       | 33980/112584 [00:01<00:04, 18912.71it/s] 32%|███▏      | 35911/112584 [00:01<00:04, 19026.52it/s] 34%|███▎      | 37818/112584 [00:01<00:03, 18840.35it/s] 35%|███▌      | 39715/112584 [00:02<00:03, 18877.01it/s] 37%|███▋      | 41671/112584 [00:02<00:03, 19072.16it/s] 39%|███▊      | 43580/112584 [00:02<00:03, 18776.85it/s] 40%|████      | 45590/112584 [00:02<00:03, 19163.21it/s] 43%|████▎     | 47945/112584 [00:02<00:03, 20458.46it/s] 44%|████▍     | 50054/112584 [00:02<00:03, 20639.53it/s] 46%|████▋     | 52121/112584 [00:02<00:02, 20285.66it/s] 48%|████▊     | 54153/112584 [00:02<00:02, 20279.50it/s] 50%|████▉     | 56183/112584 [00:02<00:02, 20048.03it/s] 52%|█████▏    | 58190/112584 [00:02<00:02, 19497.67it/s] 53%|█████▎    | 60151/112584 [00:03<00:02, 19523.70it/s] 55%|█████▌    | 62218/112584 [00:03<00:02, 19859.55it/s] 57%|█████▋    | 64207/112584 [00:03<00:02, 19613.64it/s] 59%|█████▉    | 66171/112584 [00:03<00:02, 19564.30it/s] 61%|██████    | 68129/112584 [00:03<00:02, 19423.30it/s] 62%|██████▏   | 70247/112584 [00:03<00:02, 19935.84it/s] 64%|██████▍   | 72243/112584 [00:03<00:02, 19749.14it/s] 66%|██████▌   | 74585/112584 [00:03<00:01, 20829.82it/s] 68%|██████▊   | 76671/112584 [00:03<00:01, 20573.71it/s] 70%|██████▉   | 78731/112584 [00:04<00:01, 20055.45it/s] 72%|███████▏  | 80741/112584 [00:04<00:01, 19453.90it/s] 74%|███████▎  | 82775/112584 [00:04<00:01, 19707.89it/s] 75%|███████▌  | 84834/112584 [00:04<00:01, 19953.93it/s] 77%|███████▋  | 86834/112584 [00:04<00:01, 19663.97it/s] 79%|███████▉  | 88804/112584 [00:04<00:01, 19570.25it/s] 81%|████████  | 90764/112584 [00:04<00:01, 19139.10it/s] 82%|████████▏ | 92860/112584 [00:04<00:01, 19668.14it/s] 84%|████████▍ | 94835/112584 [00:04<00:00, 19691.68it/s] 86%|████████▌ | 96986/112584 [00:04<00:00, 20225.82it/s] 88%|████████▊ | 99012/112584 [00:05<00:00, 19837.07it/s] 90%|████████▉ | 100999/112584 [00:05<00:00, 19362.48it/s] 91%|█████████▏| 102968/112584 [00:05<00:00, 19457.19it/s] 93%|█████████▎| 104917/112584 [00:05<00:00, 19269.17it/s] 95%|█████████▍| 106847/112584 [00:05<00:00, 19142.47it/s] 97%|█████████▋| 108763/112584 [00:05<00:00, 18925.44it/s] 98%|█████████▊| 110779/112584 [00:05<00:00, 19282.03it/s]100%|██████████| 112584/112584 [00:05<00:00, 19587.23it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 544.01it/s]2022-03-14 10:22:34 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39136, bias=False)
  )
)
2022-03-14 10:22:34 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-14 10:22:34 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-14 10:22:34 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-14 10:22:34 | INFO | fairseq_cli.train | num. shared model params: 38,951,936 (num. trained: 38,951,936)
2022-03-14 10:22:34 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-14 10:22:34 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/valid
2022-03-14 10:22:34 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-14 10:22:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 10:22:34 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-14 10:22:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 10:22:34 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-14 10:22:34 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-03-14 10:22:34 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 10:22:34 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 10:22:34 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-14 10:22:34 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
2022-03-14 10:22:34 | INFO | fairseq.trainer | begin training epoch 1
2022-03-14 10:22:34 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-14 10:22:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-14 10:22:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 10:22:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 10:22:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 10:25:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:25:25 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.075 | ppl 8627.54 | wps 66017 | wpb 2040.3 | bsz 4 | num_updates 99
2022-03-14 10:25:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 99 updates
2022-03-14 10:25:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:25:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:25:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 1 @ 99 updates, score 13.075) (writing took 1.8523396654054523 seconds)
2022-03-14 10:25:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-14 10:25:27 | INFO | train | epoch 001 | loss 14.361 | ppl 21035.6 | wps 40006.5 | ups 0.61 | wpb 65303.3 | bsz 127.6 | num_updates 99 | lr 1.24725e-05 | gnorm 2.878 | loss_scale 8 | train_wall 163 | gb_free 20.8 | wall 173
KL Stats: Epoch 1 Divergences: Uniform: 0.5642681688103179 Unigram: 2.4857521215665423
2022-03-14 10:25:27 | INFO | fairseq.trainer | begin training epoch 2
2022-03-14 10:25:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:25:29 | INFO | train_inner | epoch 002:      1 / 103 loss=14.348, ppl=20859.3, wps=40002.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=100, lr=1.25975e-05, gnorm=2.862, loss_scale=8, train_wall=164, gb_free=20.8, wall=175
2022-03-14 10:28:07 | INFO | train_inner | epoch 002:    101 / 103 loss=12.543, ppl=5968.61, wps=41386.2, ups=0.63, wpb=65530.9, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=1.073, loss_scale=8, train_wall=153, gb_free=20.8, wall=333
2022-03-14 10:28:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:28:13 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.786 | ppl 3531.17 | wps 66336.7 | wpb 2040.3 | bsz 4 | num_updates 202 | best_loss 11.786
2022-03-14 10:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 202 updates
2022-03-14 10:28:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:28:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:28:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 2 @ 202 updates, score 11.786) (writing took 1.924365658313036 seconds)
2022-03-14 10:28:15 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-14 10:28:15 | INFO | train | epoch 002 | loss 12.538 | ppl 5947.53 | wps 40016.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 202 | lr 2.5345e-05 | gnorm 1.07 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 341
KL Stats: Epoch 2 Divergences: Uniform: 0.5359441950111627 Unigram: 1.1937445529904072
2022-03-14 10:28:15 | INFO | fairseq.trainer | begin training epoch 3
2022-03-14 10:28:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:30:50 | INFO | train_inner | epoch 003:     98 / 103 loss=11.35, ppl=2610.31, wps=39957.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=300, lr=3.75925e-05, gnorm=0.64, loss_scale=8, train_wall=153, gb_free=20.8, wall=497
2022-03-14 10:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:31:01 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.879 | ppl 1883.14 | wps 66431.9 | wpb 2040.3 | bsz 4 | num_updates 305 | best_loss 10.879
2022-03-14 10:31:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 305 updates
2022-03-14 10:31:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:31:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 3 @ 305 updates, score 10.879) (writing took 1.9909585388377309 seconds)
2022-03-14 10:31:03 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-14 10:31:03 | INFO | train | epoch 003 | loss 11.323 | ppl 2561.76 | wps 39986.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 305 | lr 3.82174e-05 | gnorm 0.628 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 509
KL Stats: Epoch 3 Divergences: Uniform: 0.7423183792432734 Unigram: 0.577217418062814
2022-03-14 10:31:03 | INFO | fairseq.trainer | begin training epoch 4
2022-03-14 10:31:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:33:34 | INFO | train_inner | epoch 004:     95 / 103 loss=10.73, ppl=1698.11, wps=39970.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=400, lr=5.009e-05, gnorm=0.41, loss_scale=8, train_wall=153, gb_free=20.8, wall=660
2022-03-14 10:33:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:33:50 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.52 | ppl 1468.59 | wps 66473.9 | wpb 2040.3 | bsz 4 | num_updates 408 | best_loss 10.52
2022-03-14 10:33:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 408 updates
2022-03-14 10:33:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:33:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:33:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 4 @ 408 updates, score 10.52) (writing took 2.013433525338769 seconds)
2022-03-14 10:33:52 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-14 10:33:52 | INFO | train | epoch 004 | loss 10.708 | ppl 1672.39 | wps 40006.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 408 | lr 5.10898e-05 | gnorm 0.409 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 678
KL Stats: Epoch 4 Divergences: Uniform: 1.1444706342815696 Unigram: 0.45329806251357524
2022-03-14 10:33:52 | INFO | fairseq.trainer | begin training epoch 5
2022-03-14 10:33:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:36:17 | INFO | train_inner | epoch 005:     92 / 103 loss=10.423, ppl=1372.73, wps=39924.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=500, lr=6.25875e-05, gnorm=0.458, loss_scale=8, train_wall=153, gb_free=20.8, wall=823
2022-03-14 10:36:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:36:38 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.223 | ppl 1195.58 | wps 66331.8 | wpb 2040.3 | bsz 4 | num_updates 511 | best_loss 10.223
2022-03-14 10:36:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 511 updates
2022-03-14 10:36:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:36:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:36:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 5 @ 511 updates, score 10.223) (writing took 2.009764683432877 seconds)
2022-03-14 10:36:40 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-14 10:36:40 | INFO | train | epoch 005 | loss 10.394 | ppl 1345.62 | wps 39964.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 511 | lr 6.39622e-05 | gnorm 0.463 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 846
KL Stats: Epoch 5 Divergences: Uniform: 1.3633129681415004 Unigram: 0.629108045889464
2022-03-14 10:36:40 | INFO | fairseq.trainer | begin training epoch 6
2022-03-14 10:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:39:01 | INFO | train_inner | epoch 006:     89 / 103 loss=10.141, ppl=1129.21, wps=39926.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=600, lr=7.5085e-05, gnorm=0.549, loss_scale=16, train_wall=153, gb_free=20.8, wall=987
2022-03-14 10:39:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:39:26 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.95 | ppl 988.86 | wps 66483.6 | wpb 2040.3 | bsz 4 | num_updates 614 | best_loss 9.95
2022-03-14 10:39:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 614 updates
2022-03-14 10:39:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:39:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:39:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 6 @ 614 updates, score 9.95) (writing took 2.06788422819227 seconds)
2022-03-14 10:39:28 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-14 10:39:28 | INFO | train | epoch 006 | loss 10.113 | ppl 1107.06 | wps 39953.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 614 | lr 7.68347e-05 | gnorm 0.554 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 1014
KL Stats: Epoch 6 Divergences: Uniform: 1.4651631973297468 Unigram: 0.8369957796218159
2022-03-14 10:39:28 | INFO | fairseq.trainer | begin training epoch 7
2022-03-14 10:39:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:41:45 | INFO | train_inner | epoch 007:     86 / 103 loss=9.884, ppl=945, wps=39919.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=700, lr=8.75825e-05, gnorm=0.607, loss_scale=16, train_wall=153, gb_free=20.8, wall=1151
2022-03-14 10:42:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:42:15 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.704 | ppl 834.2 | wps 66233.2 | wpb 2040.3 | bsz 4 | num_updates 717 | best_loss 9.704
2022-03-14 10:42:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 717 updates
2022-03-14 10:42:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:42:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:42:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 7 @ 717 updates, score 9.704) (writing took 2.0421303883194923 seconds)
2022-03-14 10:42:17 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-14 10:42:17 | INFO | train | epoch 007 | loss 9.846 | ppl 920.38 | wps 39963.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 717 | lr 8.97071e-05 | gnorm 0.649 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 1183
KL Stats: Epoch 7 Divergences: Uniform: 1.5769942445323588 Unigram: 1.0149471086892805
2022-03-14 10:42:17 | INFO | fairseq.trainer | begin training epoch 8
2022-03-14 10:42:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:44:28 | INFO | train_inner | epoch 008:     83 / 103 loss=9.632, ppl=793.56, wps=39920.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=800, lr=0.00010008, gnorm=0.729, loss_scale=16, train_wall=153, gb_free=20.8, wall=1314
2022-03-14 10:44:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:45:03 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.457 | ppl 702.87 | wps 66222.2 | wpb 2040.3 | bsz 4 | num_updates 820 | best_loss 9.457
2022-03-14 10:45:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 820 updates
2022-03-14 10:45:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:45:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:45:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 8 @ 820 updates, score 9.457) (writing took 2.029259883798659 seconds)
2022-03-14 10:45:05 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-14 10:45:05 | INFO | train | epoch 008 | loss 9.59 | ppl 770.47 | wps 39963.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 820 | lr 0.00010258 | gnorm 0.715 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 1351
KL Stats: Epoch 8 Divergences: Uniform: 1.7055982256163653 Unigram: 1.1797654547205565
2022-03-14 10:45:05 | INFO | fairseq.trainer | begin training epoch 9
2022-03-14 10:45:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:47:12 | INFO | train_inner | epoch 009:     80 / 103 loss=9.41, ppl=680.18, wps=39914.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=900, lr=0.000112578, gnorm=0.748, loss_scale=16, train_wall=153, gb_free=20.8, wall=1478
2022-03-14 10:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:47:51 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.26 | ppl 613.21 | wps 66485.3 | wpb 2040.3 | bsz 4 | num_updates 923 | best_loss 9.26
2022-03-14 10:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 923 updates
2022-03-14 10:47:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:47:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 9 @ 923 updates, score 9.26) (writing took 2.0312598273158073 seconds)
2022-03-14 10:47:53 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-14 10:47:53 | INFO | train | epoch 009 | loss 9.364 | ppl 658.87 | wps 39950.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 923 | lr 0.000115452 | gnorm 0.764 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 1519
KL Stats: Epoch 9 Divergences: Uniform: 1.8055392755660646 Unigram: 1.333433396345379
2022-03-14 10:47:53 | INFO | fairseq.trainer | begin training epoch 10
2022-03-14 10:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:49:56 | INFO | train_inner | epoch 010:     77 / 103 loss=9.21, ppl=592.23, wps=39899.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1000, lr=0.000125075, gnorm=0.772, loss_scale=16, train_wall=153, gb_free=20.8, wall=1642
2022-03-14 10:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:50:40 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.091 | ppl 545.32 | wps 66004.4 | wpb 2040.3 | bsz 4 | num_updates 1026 | best_loss 9.091
2022-03-14 10:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1026 updates
2022-03-14 10:50:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:50:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:50:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 10 @ 1026 updates, score 9.091) (writing took 2.018939470872283 seconds)
2022-03-14 10:50:42 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-14 10:50:42 | INFO | train | epoch 010 | loss 9.171 | ppl 576.27 | wps 39937.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1026 | lr 0.000128324 | gnorm 0.778 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 1688
KL Stats: Epoch 10 Divergences: Uniform: 1.8981972531300777 Unigram: 1.467921521901295
2022-03-14 10:50:42 | INFO | fairseq.trainer | begin training epoch 11
2022-03-14 10:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:52:39 | INFO | train_inner | epoch 011:     74 / 103 loss=9.041, ppl=526.88, wps=39910.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1100, lr=0.000137573, gnorm=0.788, loss_scale=32, train_wall=153, gb_free=20.8, wall=1805
2022-03-14 10:53:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:53:28 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.945 | ppl 492.97 | wps 65966.8 | wpb 2040.3 | bsz 4 | num_updates 1129 | best_loss 8.945
2022-03-14 10:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1129 updates
2022-03-14 10:53:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:53:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:53:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 11 @ 1129 updates, score 8.945) (writing took 2.0071030920371413 seconds)
2022-03-14 10:53:30 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-14 10:53:30 | INFO | train | epoch 011 | loss 9.001 | ppl 512.23 | wps 39958 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1129 | lr 0.000141197 | gnorm 0.789 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 1856
KL Stats: Epoch 11 Divergences: Uniform: 1.9861205863882487 Unigram: 1.582945209305354
2022-03-14 10:53:30 | INFO | fairseq.trainer | begin training epoch 12
2022-03-14 10:53:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:55:23 | INFO | train_inner | epoch 012:     71 / 103 loss=8.893, ppl=475.39, wps=39915.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1200, lr=0.00015007, gnorm=0.791, loss_scale=32, train_wall=153, gb_free=20.8, wall=1969
2022-03-14 10:56:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:56:16 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.81 | ppl 448.91 | wps 66470.3 | wpb 2040.3 | bsz 4 | num_updates 1232 | best_loss 8.81
2022-03-14 10:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1232 updates
2022-03-14 10:56:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:56:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:56:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 12 @ 1232 updates, score 8.81) (writing took 2.0262945285066962 seconds)
2022-03-14 10:56:18 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-14 10:56:18 | INFO | train | epoch 012 | loss 8.844 | ppl 459.45 | wps 39961.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1232 | lr 0.000154069 | gnorm 0.793 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2024
KL Stats: Epoch 12 Divergences: Uniform: 2.0722770785618985 Unigram: 1.6795629854542493
2022-03-14 10:56:18 | INFO | fairseq.trainer | begin training epoch 13
2022-03-14 10:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 10:58:06 | INFO | train_inner | epoch 013:     68 / 103 loss=8.738, ppl=427.01, wps=39931.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1300, lr=0.000162568, gnorm=0.796, loss_scale=32, train_wall=153, gb_free=20.8, wall=2132
2022-03-14 10:59:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 10:59:05 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.698 | ppl 415.24 | wps 66264.5 | wpb 2040.3 | bsz 4 | num_updates 1335 | best_loss 8.698
2022-03-14 10:59:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1335 updates
2022-03-14 10:59:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:59:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 10:59:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 13 @ 1335 updates, score 8.698) (writing took 2.0260601257905364 seconds)
2022-03-14 10:59:07 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-14 10:59:07 | INFO | train | epoch 013 | loss 8.695 | ppl 414.42 | wps 39969.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1335 | lr 0.000166942 | gnorm 0.812 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2193
KL Stats: Epoch 13 Divergences: Uniform: 2.1551918930847798 Unigram: 1.7695223119075616
2022-03-14 10:59:07 | INFO | fairseq.trainer | begin training epoch 14
2022-03-14 10:59:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:00:50 | INFO | train_inner | epoch 014:     65 / 103 loss=8.601, ppl=388.28, wps=39922.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1400, lr=0.000175065, gnorm=0.838, loss_scale=32, train_wall=153, gb_free=20.8, wall=2296
2022-03-14 11:01:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:01:53 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.585 | ppl 383.89 | wps 66190.8 | wpb 2040.3 | bsz 4 | num_updates 1438 | best_loss 8.585
2022-03-14 11:01:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1438 updates
2022-03-14 11:01:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:01:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:01:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 14 @ 1438 updates, score 8.585) (writing took 2.002744031138718 seconds)
2022-03-14 11:01:55 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-14 11:01:55 | INFO | train | epoch 014 | loss 8.552 | ppl 375.27 | wps 39970.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1438 | lr 0.000179814 | gnorm 0.856 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2361
KL Stats: Epoch 14 Divergences: Uniform: 2.2330124762444954 Unigram: 1.851510126830112
2022-03-14 11:01:55 | INFO | fairseq.trainer | begin training epoch 15
2022-03-14 11:01:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:03:33 | INFO | train_inner | epoch 015:     62 / 103 loss=8.463, ppl=352.99, wps=39921.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1500, lr=0.000187563, gnorm=0.867, loss_scale=32, train_wall=153, gb_free=20.8, wall=2459
2022-03-14 11:04:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:04:41 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.465 | ppl 353.28 | wps 65971.6 | wpb 2040.3 | bsz 4 | num_updates 1541 | best_loss 8.465
2022-03-14 11:04:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1541 updates
2022-03-14 11:04:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:04:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:04:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 15 @ 1541 updates, score 8.465) (writing took 2.0237821536138654 seconds)
2022-03-14 11:04:43 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-14 11:04:43 | INFO | train | epoch 015 | loss 8.409 | ppl 339.87 | wps 39947.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1541 | lr 0.000192686 | gnorm 0.845 | loss_scale 64 | train_wall 158 | gb_free 20.8 | wall 2529
KL Stats: Epoch 15 Divergences: Uniform: 2.308992967118056 Unigram: 1.9275600668699173
2022-03-14 11:04:43 | INFO | fairseq.trainer | begin training epoch 16
2022-03-14 11:04:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:05:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 11:06:19 | INFO | train_inner | epoch 016:     60 / 103 loss=8.323, ppl=320.3, wps=39522.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1600, lr=0.00020006, gnorm=0.843, loss_scale=32, train_wall=155, gb_free=20.8, wall=2625
2022-03-14 11:07:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:07:30 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.361 | ppl 328.71 | wps 66147.7 | wpb 2040.3 | bsz 4 | num_updates 1643 | best_loss 8.361
2022-03-14 11:07:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1643 updates
2022-03-14 11:07:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:07:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:07:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 16 @ 1643 updates, score 8.361) (writing took 2.0243057180196047 seconds)
2022-03-14 11:07:32 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-14 11:07:32 | INFO | train | epoch 016 | loss 8.265 | ppl 307.65 | wps 39562.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 1643 | lr 0.000205434 | gnorm 0.839 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2698
KL Stats: Epoch 16 Divergences: Uniform: 2.3824368876014925 Unigram: 1.9991030118534696
2022-03-14 11:07:32 | INFO | fairseq.trainer | begin training epoch 17
2022-03-14 11:07:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:09:02 | INFO | train_inner | epoch 017:     57 / 103 loss=8.187, ppl=291.47, wps=39907.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1700, lr=0.000212558, gnorm=0.855, loss_scale=32, train_wall=153, gb_free=20.8, wall=2788
2022-03-14 11:10:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:10:18 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.256 | ppl 305.61 | wps 66530.9 | wpb 2040.3 | bsz 4 | num_updates 1746 | best_loss 8.256
2022-03-14 11:10:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1746 updates
2022-03-14 11:10:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:10:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:10:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 17 @ 1746 updates, score 8.256) (writing took 2.0420001931488514 seconds)
2022-03-14 11:10:20 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-14 11:10:20 | INFO | train | epoch 017 | loss 8.128 | ppl 279.81 | wps 39942.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1746 | lr 0.000218306 | gnorm 0.892 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2866
KL Stats: Epoch 17 Divergences: Uniform: 2.4577363236242467 Unigram: 2.066631584335838
2022-03-14 11:10:20 | INFO | fairseq.trainer | begin training epoch 18
2022-03-14 11:10:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:11:46 | INFO | train_inner | epoch 018:     54 / 103 loss=8.051, ppl=265.16, wps=39910.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1800, lr=0.000225055, gnorm=0.879, loss_scale=32, train_wall=153, gb_free=20.8, wall=2952
2022-03-14 11:13:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:13:07 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.172 | ppl 288.49 | wps 65832.4 | wpb 2040.3 | bsz 4 | num_updates 1849 | best_loss 8.172
2022-03-14 11:13:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1849 updates
2022-03-14 11:13:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:13:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 18 @ 1849 updates, score 8.172) (writing took 2.050496752373874 seconds)
2022-03-14 11:13:09 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-14 11:13:09 | INFO | train | epoch 018 | loss 7.989 | ppl 254.12 | wps 39939.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1849 | lr 0.000231179 | gnorm 0.851 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3035
KL Stats: Epoch 18 Divergences: Uniform: 2.5290720895793166 Unigram: 2.1326957821539105
2022-03-14 11:13:09 | INFO | fairseq.trainer | begin training epoch 19
2022-03-14 11:13:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:14:30 | INFO | train_inner | epoch 019:     51 / 103 loss=7.921, ppl=242.42, wps=39888.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1900, lr=0.000237553, gnorm=0.866, loss_scale=32, train_wall=153, gb_free=20.8, wall=3116
2022-03-14 11:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:15:55 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.082 | ppl 270.89 | wps 66296.3 | wpb 2040.3 | bsz 4 | num_updates 1952 | best_loss 8.082
2022-03-14 11:15:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1952 updates
2022-03-14 11:15:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:15:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:15:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 19 @ 1952 updates, score 8.082) (writing took 2.002323060296476 seconds)
2022-03-14 11:15:57 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-14 11:15:57 | INFO | train | epoch 019 | loss 7.856 | ppl 231.69 | wps 39940.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1952 | lr 0.000244051 | gnorm 0.863 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3203
KL Stats: Epoch 19 Divergences: Uniform: 2.6015099217147237 Unigram: 2.1948700702115866
2022-03-14 11:15:57 | INFO | fairseq.trainer | begin training epoch 20
2022-03-14 11:15:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:17:13 | INFO | train_inner | epoch 020:     48 / 103 loss=7.796, ppl=222.25, wps=39911.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2000, lr=0.00025005, gnorm=0.844, loss_scale=32, train_wall=153, gb_free=20.8, wall=3279
2022-03-14 11:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:18:43 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.003 | ppl 256.57 | wps 66489.7 | wpb 2040.3 | bsz 4 | num_updates 2055 | best_loss 8.003
2022-03-14 11:18:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 2055 updates
2022-03-14 11:18:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:18:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:18:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 20 @ 2055 updates, score 8.003) (writing took 2.009140624664724 seconds)
2022-03-14 11:18:46 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-14 11:18:46 | INFO | train | epoch 020 | loss 7.728 | ppl 211.94 | wps 39954.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2055 | lr 0.000256924 | gnorm 0.843 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3372
KL Stats: Epoch 20 Divergences: Uniform: 2.672179266791784 Unigram: 2.252970301364002
2022-03-14 11:18:46 | INFO | fairseq.trainer | begin training epoch 21
2022-03-14 11:18:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:19:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 11:19:58 | INFO | train_inner | epoch 021:     46 / 103 loss=7.667, ppl=203.29, wps=39539.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2100, lr=0.000262548, gnorm=0.862, loss_scale=32, train_wall=155, gb_free=20.8, wall=3445
2022-03-14 11:21:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:21:32 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.942 | ppl 245.98 | wps 65887.2 | wpb 2040.3 | bsz 4 | num_updates 2157 | best_loss 7.942
2022-03-14 11:21:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2157 updates
2022-03-14 11:21:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:21:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:21:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 21 @ 2157 updates, score 7.942) (writing took 2.0320405550301075 seconds)
2022-03-14 11:21:34 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-14 11:21:34 | INFO | train | epoch 021 | loss 7.609 | ppl 195.21 | wps 39574.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2157 | lr 0.000269671 | gnorm 0.853 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3540
KL Stats: Epoch 21 Divergences: Uniform: 2.7448298865006486 Unigram: 2.3104826664477423
2022-03-14 11:21:34 | INFO | fairseq.trainer | begin training epoch 22
2022-03-14 11:21:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:22:42 | INFO | train_inner | epoch 022:     43 / 103 loss=7.559, ppl=188.59, wps=39915.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2200, lr=0.000275045, gnorm=0.845, loss_scale=32, train_wall=153, gb_free=20.8, wall=3608
2022-03-14 11:24:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:24:20 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.875 | ppl 234.72 | wps 66644.8 | wpb 2040.3 | bsz 4 | num_updates 2260 | best_loss 7.875
2022-03-14 11:24:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2260 updates
2022-03-14 11:24:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:24:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:24:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 22 @ 2260 updates, score 7.875) (writing took 1.9824332538992167 seconds)
2022-03-14 11:24:22 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-14 11:24:22 | INFO | train | epoch 022 | loss 7.497 | ppl 180.66 | wps 39961.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2260 | lr 0.000282544 | gnorm 0.85 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3708
KL Stats: Epoch 22 Divergences: Uniform: 2.809166512203462 Unigram: 2.3617256454967235
2022-03-14 11:24:22 | INFO | fairseq.trainer | begin training epoch 23
2022-03-14 11:24:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:25:26 | INFO | train_inner | epoch 023:     40 / 103 loss=7.451, ppl=174.98, wps=39932.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2300, lr=0.000287543, gnorm=0.852, loss_scale=32, train_wall=153, gb_free=20.8, wall=3772
2022-03-14 11:27:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:27:08 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.813 | ppl 224.89 | wps 66439.7 | wpb 2040.3 | bsz 4 | num_updates 2363 | best_loss 7.813
2022-03-14 11:27:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2363 updates
2022-03-14 11:27:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:27:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:27:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 23 @ 2363 updates, score 7.813) (writing took 2.004694925621152 seconds)
2022-03-14 11:27:10 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-14 11:27:10 | INFO | train | epoch 023 | loss 7.389 | ppl 167.62 | wps 39980.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2363 | lr 0.000295416 | gnorm 0.844 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3876
KL Stats: Epoch 23 Divergences: Uniform: 2.8734564016916684 Unigram: 2.411865498555763
2022-03-14 11:27:10 | INFO | fairseq.trainer | begin training epoch 24
2022-03-14 11:27:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:28:09 | INFO | train_inner | epoch 024:     37 / 103 loss=7.349, ppl=163.07, wps=39926.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2400, lr=0.00030004, gnorm=0.832, loss_scale=32, train_wall=153, gb_free=20.8, wall=3935
2022-03-14 11:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:29:57 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.768 | ppl 217.96 | wps 66232.2 | wpb 2040.3 | bsz 4 | num_updates 2466 | best_loss 7.768
2022-03-14 11:29:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2466 updates
2022-03-14 11:29:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:29:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:29:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 24 @ 2466 updates, score 7.768) (writing took 2.0628700917586684 seconds)
2022-03-14 11:29:59 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-14 11:29:59 | INFO | train | epoch 024 | loss 7.288 | ppl 156.29 | wps 39948 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2466 | lr 0.000308288 | gnorm 0.826 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4045
KL Stats: Epoch 24 Divergences: Uniform: 2.9328809287803232 Unigram: 2.4591156127918463
2022-03-14 11:29:59 | INFO | fairseq.trainer | begin training epoch 25
2022-03-14 11:29:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:30:53 | INFO | train_inner | epoch 025:     34 / 103 loss=7.25, ppl=152.25, wps=39909.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2500, lr=0.000312538, gnorm=0.846, loss_scale=32, train_wall=153, gb_free=20.8, wall=4099
2022-03-14 11:32:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:32:45 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.732 | ppl 212.53 | wps 66271.1 | wpb 2040.3 | bsz 4 | num_updates 2569 | best_loss 7.732
2022-03-14 11:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2569 updates
2022-03-14 11:32:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:32:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 25 @ 2569 updates, score 7.732) (writing took 2.0330574605613947 seconds)
2022-03-14 11:32:47 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-14 11:32:47 | INFO | train | epoch 025 | loss 7.193 | ppl 146.35 | wps 39964.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2569 | lr 0.000321161 | gnorm 0.836 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4213
KL Stats: Epoch 25 Divergences: Uniform: 2.987442482179822 Unigram: 2.504212262938241
2022-03-14 11:32:47 | INFO | fairseq.trainer | begin training epoch 26
2022-03-14 11:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:33:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 11:33:38 | INFO | train_inner | epoch 026:     32 / 103 loss=7.17, ppl=143.99, wps=39555, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2600, lr=0.000325035, gnorm=0.823, loss_scale=32, train_wall=155, gb_free=20.8, wall=4264
2022-03-14 11:35:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:35:33 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.699 | ppl 207.8 | wps 66219.2 | wpb 2040.3 | bsz 4 | num_updates 2671 | best_loss 7.699
2022-03-14 11:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2671 updates
2022-03-14 11:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:35:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 26 @ 2671 updates, score 7.699) (writing took 2.005423992872238 seconds)
2022-03-14 11:35:35 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-14 11:35:35 | INFO | train | epoch 026 | loss 7.101 | ppl 137.28 | wps 39580.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2671 | lr 0.000333908 | gnorm 0.82 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4382
KL Stats: Epoch 26 Divergences: Uniform: 3.044706575674974 Unigram: 2.5459506992734324
2022-03-14 11:35:35 | INFO | fairseq.trainer | begin training epoch 27
2022-03-14 11:35:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:36:21 | INFO | train_inner | epoch 027:     29 / 103 loss=7.074, ppl=134.78, wps=39929.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2700, lr=0.000337533, gnorm=0.829, loss_scale=32, train_wall=153, gb_free=20.8, wall=4428
2022-03-14 11:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:38:22 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.654 | ppl 201.38 | wps 66267.1 | wpb 2040.3 | bsz 4 | num_updates 2774 | best_loss 7.654
2022-03-14 11:38:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2774 updates
2022-03-14 11:38:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:38:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:38:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 27 @ 2774 updates, score 7.654) (writing took 2.0550959408283234 seconds)
2022-03-14 11:38:24 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-14 11:38:24 | INFO | train | epoch 027 | loss 7.016 | ppl 129.41 | wps 39950.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2774 | lr 0.000346781 | gnorm 0.824 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4550
KL Stats: Epoch 27 Divergences: Uniform: 3.090101593020384 Unigram: 2.586947570876542
2022-03-14 11:38:24 | INFO | fairseq.trainer | begin training epoch 28
2022-03-14 11:38:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:39:05 | INFO | train_inner | epoch 028:     26 / 103 loss=6.991, ppl=127.24, wps=39895.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2800, lr=0.00035003, gnorm=0.811, loss_scale=32, train_wall=153, gb_free=20.8, wall=4591
2022-03-14 11:41:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:41:10 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.625 | ppl 197.36 | wps 66396.4 | wpb 2040.3 | bsz 4 | num_updates 2877 | best_loss 7.625
2022-03-14 11:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2877 updates
2022-03-14 11:41:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 28 @ 2877 updates, score 7.625) (writing took 1.9997065337374806 seconds)
2022-03-14 11:41:12 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-14 11:41:12 | INFO | train | epoch 028 | loss 6.933 | ppl 122.15 | wps 39929.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2877 | lr 0.000359653 | gnorm 0.831 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4718
KL Stats: Epoch 28 Divergences: Uniform: 3.1382433374649725 Unigram: 2.6268799736553277
2022-03-14 11:41:12 | INFO | fairseq.trainer | begin training epoch 29
2022-03-14 11:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:41:49 | INFO | train_inner | epoch 029:     23 / 103 loss=6.916, ppl=120.76, wps=39901, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=2900, lr=0.000362528, gnorm=0.812, loss_scale=32, train_wall=153, gb_free=20.8, wall=4755
2022-03-14 11:42:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 11:43:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:43:59 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.607 | ppl 194.91 | wps 66512 | wpb 2040.3 | bsz 4 | num_updates 2979 | best_loss 7.607
2022-03-14 11:43:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2979 updates
2022-03-14 11:43:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:44:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 29 @ 2979 updates, score 7.607) (writing took 2.0043592927977443 seconds)
2022-03-14 11:44:01 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-14 11:44:01 | INFO | train | epoch 029 | loss 6.853 | ppl 115.62 | wps 39566 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2979 | lr 0.000372401 | gnorm 0.814 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 4887
KL Stats: Epoch 29 Divergences: Uniform: 3.1891677454492107 Unigram: 2.668146560489364
2022-03-14 11:44:01 | INFO | fairseq.trainer | begin training epoch 30
2022-03-14 11:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:44:34 | INFO | train_inner | epoch 030:     21 / 103 loss=6.837, ppl=114.36, wps=39530.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3000, lr=0.000375025, gnorm=0.853, loss_scale=16, train_wall=155, gb_free=20.8, wall=4920
2022-03-14 11:46:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:46:47 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.579 | ppl 191.25 | wps 66136.9 | wpb 2040.3 | bsz 4 | num_updates 3082 | best_loss 7.579
2022-03-14 11:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 3082 updates
2022-03-14 11:46:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:46:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:46:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 30 @ 3082 updates, score 7.579) (writing took 1.97684445977211 seconds)
2022-03-14 11:46:49 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-14 11:46:49 | INFO | train | epoch 030 | loss 6.776 | ppl 109.56 | wps 39969.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3082 | lr 0.000385273 | gnorm 0.826 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5055
KL Stats: Epoch 30 Divergences: Uniform: 3.2290031250718325 Unigram: 2.706751056136608
2022-03-14 11:46:49 | INFO | fairseq.trainer | begin training epoch 31
2022-03-14 11:46:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:47:18 | INFO | train_inner | epoch 031:     18 / 103 loss=6.761, ppl=108.43, wps=39923.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=3100, lr=0.000387523, gnorm=0.792, loss_scale=16, train_wall=153, gb_free=20.8, wall=5084
2022-03-14 11:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:49:35 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.563 | ppl 189.05 | wps 66263.7 | wpb 2040.3 | bsz 4 | num_updates 3185 | best_loss 7.563
2022-03-14 11:49:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 3185 updates
2022-03-14 11:49:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:49:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:49:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 31 @ 3185 updates, score 7.563) (writing took 2.002104769460857 seconds)
2022-03-14 11:49:37 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-14 11:49:37 | INFO | train | epoch 031 | loss 6.7 | ppl 103.98 | wps 39968.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3185 | lr 0.000398145 | gnorm 0.824 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5223
KL Stats: Epoch 31 Divergences: Uniform: 3.2762739601710473 Unigram: 2.7424741220982822
2022-03-14 11:49:37 | INFO | fairseq.trainer | begin training epoch 32
2022-03-14 11:49:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:50:01 | INFO | train_inner | epoch 032:     15 / 103 loss=6.689, ppl=103.15, wps=39937.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3200, lr=0.00040002, gnorm=0.822, loss_scale=16, train_wall=153, gb_free=20.8, wall=5247
2022-03-14 11:52:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:52:24 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.558 | ppl 188.42 | wps 66297.7 | wpb 2040.3 | bsz 4 | num_updates 3288 | best_loss 7.558
2022-03-14 11:52:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3288 updates
2022-03-14 11:52:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:52:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:52:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 32 @ 3288 updates, score 7.558) (writing took 2.0186421014368534 seconds)
2022-03-14 11:52:26 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-14 11:52:26 | INFO | train | epoch 032 | loss 6.627 | ppl 98.87 | wps 39983.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3288 | lr 0.000411018 | gnorm 0.816 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5392
KL Stats: Epoch 32 Divergences: Uniform: 3.320417830118935 Unigram: 2.781373885555625
2022-03-14 11:52:26 | INFO | fairseq.trainer | begin training epoch 33
2022-03-14 11:52:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:52:45 | INFO | train_inner | epoch 033:     12 / 103 loss=6.622, ppl=98.49, wps=39945.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3300, lr=0.000412518, gnorm=0.823, loss_scale=16, train_wall=153, gb_free=20.8, wall=5411
2022-03-14 11:55:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:55:12 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.558 | ppl 188.41 | wps 66285.2 | wpb 2040.3 | bsz 4 | num_updates 3391 | best_loss 7.558
2022-03-14 11:55:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3391 updates
2022-03-14 11:55:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:55:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:55:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 33 @ 3391 updates, score 7.558) (writing took 2.0324024306610227 seconds)
2022-03-14 11:55:14 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-14 11:55:14 | INFO | train | epoch 033 | loss 6.559 | ppl 94.3 | wps 39978.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3391 | lr 0.00042389 | gnorm 0.841 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5560
KL Stats: Epoch 33 Divergences: Uniform: 3.3620723416411558 Unigram: 2.8199966264411165
2022-03-14 11:55:14 | INFO | fairseq.trainer | begin training epoch 34
2022-03-14 11:55:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:55:28 | INFO | train_inner | epoch 034:      9 / 103 loss=6.552, ppl=93.85, wps=39929.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3400, lr=0.000425015, gnorm=0.842, loss_scale=16, train_wall=153, gb_free=20.8, wall=5574
2022-03-14 11:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 11:58:00 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.537 | ppl 185.73 | wps 66167.2 | wpb 2040.3 | bsz 4 | num_updates 3494 | best_loss 7.537
2022-03-14 11:58:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3494 updates
2022-03-14 11:58:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:58:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt
2022-03-14 11:58:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_best.pt (epoch 34 @ 3494 updates, score 7.537) (writing took 2.0247666463255882 seconds)
2022-03-14 11:58:02 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-14 11:58:02 | INFO | train | epoch 034 | loss 6.488 | ppl 89.73 | wps 39958.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3494 | lr 0.000436763 | gnorm 0.81 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 5728
KL Stats: Epoch 34 Divergences: Uniform: 3.4023760575676456 Unigram: 2.8577611152982834
2022-03-14 11:58:02 | INFO | fairseq.trainer | begin training epoch 35
2022-03-14 11:58:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 11:58:12 | INFO | train_inner | epoch 035:      6 / 103 loss=6.487, ppl=89.68, wps=39921.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3500, lr=0.000437513, gnorm=0.811, loss_scale=32, train_wall=153, gb_free=20.8, wall=5738
2022-03-14 11:59:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 12:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:00:49 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.553 | ppl 187.78 | wps 66507.7 | wpb 2040.3 | bsz 4 | num_updates 3596 | best_loss 7.537
2022-03-14 12:00:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3596 updates
2022-03-14 12:00:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:00:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:00:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 35 @ 3596 updates, score 7.553) (writing took 0.9234324879944324 seconds)
2022-03-14 12:00:49 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-14 12:00:49 | INFO | train | epoch 035 | loss 6.421 | ppl 85.69 | wps 39826.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 3596 | lr 0.00044951 | gnorm 0.807 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5895
KL Stats: Epoch 35 Divergences: Uniform: 3.43984848336728 Unigram: 2.8956380583162296
2022-03-14 12:00:49 | INFO | fairseq.trainer | begin training epoch 36
2022-03-14 12:00:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:00:56 | INFO | train_inner | epoch 036:      4 / 103 loss=6.418, ppl=85.49, wps=39798.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3600, lr=0.00045001, gnorm=0.818, loss_scale=16, train_wall=155, gb_free=20.8, wall=5902
2022-03-14 12:03:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:03:36 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.544 | ppl 186.61 | wps 66180.9 | wpb 2040.3 | bsz 4 | num_updates 3699 | best_loss 7.537
2022-03-14 12:03:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3699 updates
2022-03-14 12:03:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:03:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:03:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 36 @ 3699 updates, score 7.544) (writing took 0.9618942029774189 seconds)
2022-03-14 12:03:37 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-14 12:03:37 | INFO | train | epoch 036 | loss 6.361 | ppl 82.18 | wps 40217.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3699 | lr 0.000462383 | gnorm 0.847 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6063
KL Stats: Epoch 36 Divergences: Uniform: 3.487046143271196 Unigram: 2.934855221281511
2022-03-14 12:03:37 | INFO | fairseq.trainer | begin training epoch 37
2022-03-14 12:03:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:03:38 | INFO | train_inner | epoch 037:      1 / 103 loss=6.362, ppl=82.27, wps=40181.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3700, lr=0.000462508, gnorm=0.839, loss_scale=16, train_wall=153, gb_free=20.8, wall=6064
2022-03-14 12:06:17 | INFO | train_inner | epoch 037:    101 / 103 loss=6.295, ppl=78.53, wps=41349.4, ups=0.63, wpb=65530.9, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.816, loss_scale=16, train_wall=154, gb_free=20.8, wall=6223
2022-03-14 12:06:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:06:23 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.549 | ppl 187.23 | wps 66615.6 | wpb 2040.3 | bsz 4 | num_updates 3802 | best_loss 7.537
2022-03-14 12:06:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3802 updates
2022-03-14 12:06:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:06:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:06:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 37 @ 3802 updates, score 7.549) (writing took 0.9166119201108813 seconds)
2022-03-14 12:06:24 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-14 12:06:24 | INFO | train | epoch 037 | loss 6.295 | ppl 78.51 | wps 40225.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3802 | lr 0.000475255 | gnorm 0.814 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6230
KL Stats: Epoch 37 Divergences: Uniform: 3.527274911620241 Unigram: 2.971910123344553
2022-03-14 12:06:24 | INFO | fairseq.trainer | begin training epoch 38
2022-03-14 12:06:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:08:59 | INFO | train_inner | epoch 038:     98 / 103 loss=6.234, ppl=75.27, wps=40200.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3900, lr=0.000487503, gnorm=0.835, loss_scale=16, train_wall=153, gb_free=20.8, wall=6385
2022-03-14 12:09:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:09:10 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.557 | ppl 188.36 | wps 66015.5 | wpb 2040.3 | bsz 4 | num_updates 3905 | best_loss 7.537
2022-03-14 12:09:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3905 updates
2022-03-14 12:09:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:09:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:09:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 38 @ 3905 updates, score 7.557) (writing took 0.9394886586815119 seconds)
2022-03-14 12:09:11 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-14 12:09:11 | INFO | train | epoch 038 | loss 6.235 | ppl 75.3 | wps 40229.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3905 | lr 0.000488127 | gnorm 0.832 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6397
KL Stats: Epoch 38 Divergences: Uniform: 3.570060877082715 Unigram: 3.0085739940350087
2022-03-14 12:09:11 | INFO | fairseq.trainer | begin training epoch 39
2022-03-14 12:09:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:11:42 | INFO | train_inner | epoch 039:     95 / 103 loss=6.176, ppl=72.29, wps=40214.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4000, lr=0.0005, gnorm=0.843, loss_scale=16, train_wall=153, gb_free=20.8, wall=6548
2022-03-14 12:11:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:11:57 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.581 | ppl 191.44 | wps 66209.1 | wpb 2040.3 | bsz 4 | num_updates 4008 | best_loss 7.537
2022-03-14 12:11:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 4008 updates
2022-03-14 12:11:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:11:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:11:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 39 @ 4008 updates, score 7.581) (writing took 0.9323449833318591 seconds)
2022-03-14 12:11:58 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-14 12:11:58 | INFO | train | epoch 039 | loss 6.176 | ppl 72.28 | wps 40253.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4008 | lr 0.000499501 | gnorm 0.846 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6564
KL Stats: Epoch 39 Divergences: Uniform: 3.6075836709160365 Unigram: 3.046097465366421
2022-03-14 12:11:58 | INFO | fairseq.trainer | begin training epoch 40
2022-03-14 12:11:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:14:24 | INFO | train_inner | epoch 040:     92 / 103 loss=6.116, ppl=69.37, wps=40206.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=4100, lr=0.000493865, gnorm=0.818, loss_scale=32, train_wall=153, gb_free=20.8, wall=6710
2022-03-14 12:14:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 12:14:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:14:45 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.58 | ppl 191.37 | wps 66482.2 | wpb 2040.3 | bsz 4 | num_updates 4110 | best_loss 7.537
2022-03-14 12:14:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 4110 updates
2022-03-14 12:14:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:14:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 40 @ 4110 updates, score 7.58) (writing took 0.8932027444243431 seconds)
2022-03-14 12:14:46 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-14 12:14:46 | INFO | train | epoch 040 | loss 6.114 | ppl 69.26 | wps 39846.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4110 | lr 0.000493264 | gnorm 0.827 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6732
KL Stats: Epoch 40 Divergences: Uniform: 3.6515276619510293 Unigram: 3.082916427982691
2022-03-14 12:14:46 | INFO | fairseq.trainer | begin training epoch 41
2022-03-14 12:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:17:08 | INFO | train_inner | epoch 041:     90 / 103 loss=6.054, ppl=66.43, wps=39816, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=4200, lr=0.00048795, gnorm=0.817, loss_scale=16, train_wall=155, gb_free=20.8, wall=6874
2022-03-14 12:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:17:32 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.592 | ppl 192.97 | wps 66675.8 | wpb 2040.3 | bsz 4 | num_updates 4213 | best_loss 7.537
2022-03-14 12:17:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 4213 updates
2022-03-14 12:17:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:17:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 41 @ 4213 updates, score 7.592) (writing took 0.9230316076427698 seconds)
2022-03-14 12:17:33 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-14 12:17:33 | INFO | train | epoch 041 | loss 6.049 | ppl 66.21 | wps 40239 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4213 | lr 0.000487197 | gnorm 0.803 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6899
KL Stats: Epoch 41 Divergences: Uniform: 3.6951034806150864 Unigram: 3.1222119274188507
2022-03-14 12:17:33 | INFO | fairseq.trainer | begin training epoch 42
2022-03-14 12:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:19:51 | INFO | train_inner | epoch 042:     87 / 103 loss=5.996, ppl=63.84, wps=40203.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=4300, lr=0.000482243, gnorm=0.812, loss_scale=16, train_wall=153, gb_free=20.8, wall=7037
2022-03-14 12:20:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:20:19 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.598 | ppl 193.77 | wps 66295.1 | wpb 2040.3 | bsz 4 | num_updates 4316 | best_loss 7.537
2022-03-14 12:20:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4316 updates
2022-03-14 12:20:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:20:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:20:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 42 @ 4316 updates, score 7.598) (writing took 0.9183787573128939 seconds)
2022-03-14 12:20:20 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-14 12:20:20 | INFO | train | epoch 042 | loss 5.991 | ppl 63.61 | wps 40230.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4316 | lr 0.000481348 | gnorm 0.819 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7066
KL Stats: Epoch 42 Divergences: Uniform: 3.739215672862315 Unigram: 3.161649471225437
2022-03-14 12:20:20 | INFO | fairseq.trainer | begin training epoch 43
2022-03-14 12:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:22:33 | INFO | train_inner | epoch 043:     84 / 103 loss=5.94, ppl=61.41, wps=40220.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=4400, lr=0.000476731, gnorm=0.805, loss_scale=16, train_wall=153, gb_free=20.8, wall=7199
2022-03-14 12:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:23:06 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.621 | ppl 196.89 | wps 66283.9 | wpb 2040.3 | bsz 4 | num_updates 4419 | best_loss 7.537
2022-03-14 12:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4419 updates
2022-03-14 12:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:23:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:23:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 43 @ 4419 updates, score 7.621) (writing took 0.8764936793595552 seconds)
2022-03-14 12:23:07 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-14 12:23:07 | INFO | train | epoch 043 | loss 5.929 | ppl 60.93 | wps 40264.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4419 | lr 0.000475705 | gnorm 0.791 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7233
KL Stats: Epoch 43 Divergences: Uniform: 3.7828611050514933 Unigram: 3.199890487814002
2022-03-14 12:23:07 | INFO | fairseq.trainer | begin training epoch 44
2022-03-14 12:23:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:25:15 | INFO | train_inner | epoch 044:     81 / 103 loss=5.882, ppl=58.97, wps=40221.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4500, lr=0.000471405, gnorm=0.801, loss_scale=16, train_wall=153, gb_free=20.8, wall=7361
2022-03-14 12:25:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:25:53 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.628 | ppl 197.76 | wps 66268.8 | wpb 2040.3 | bsz 4 | num_updates 4522 | best_loss 7.537
2022-03-14 12:25:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4522 updates
2022-03-14 12:25:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:25:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:25:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 44 @ 4522 updates, score 7.628) (writing took 0.8918300960212946 seconds)
2022-03-14 12:25:54 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-14 12:25:54 | INFO | train | epoch 044 | loss 5.877 | ppl 58.75 | wps 40255.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4522 | lr 0.000470256 | gnorm 0.809 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7400
KL Stats: Epoch 44 Divergences: Uniform: 3.823978154490037 Unigram: 3.238187313325355
2022-03-14 12:25:54 | INFO | fairseq.trainer | begin training epoch 45
2022-03-14 12:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:27:58 | INFO | train_inner | epoch 045:     78 / 103 loss=5.833, ppl=57.01, wps=40224, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4600, lr=0.000466252, gnorm=0.803, loss_scale=16, train_wall=153, gb_free=20.8, wall=7524
2022-03-14 12:28:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 12:28:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:28:40 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.668 | ppl 203.33 | wps 66466 | wpb 2040.3 | bsz 4 | num_updates 4624 | best_loss 7.537
2022-03-14 12:28:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4624 updates
2022-03-14 12:28:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:28:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:28:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 45 @ 4624 updates, score 7.668) (writing took 0.8940428728237748 seconds)
2022-03-14 12:28:41 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-14 12:28:41 | INFO | train | epoch 045 | loss 5.82 | ppl 56.51 | wps 39865.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4624 | lr 0.000465041 | gnorm 0.799 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7567
KL Stats: Epoch 45 Divergences: Uniform: 3.859665337184108 Unigram: 3.2768184588910376
2022-03-14 12:28:41 | INFO | fairseq.trainer | begin training epoch 46
2022-03-14 12:28:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:30:42 | INFO | train_inner | epoch 046:     76 / 103 loss=5.78, ppl=54.93, wps=39829, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4700, lr=0.000461266, gnorm=0.791, loss_scale=16, train_wall=155, gb_free=20.8, wall=7688
2022-03-14 12:31:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:31:27 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.675 | ppl 204.39 | wps 66597 | wpb 2040.3 | bsz 4 | num_updates 4727 | best_loss 7.537
2022-03-14 12:31:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4727 updates
2022-03-14 12:31:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:31:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:31:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 46 @ 4727 updates, score 7.675) (writing took 0.8754214765504003 seconds)
2022-03-14 12:31:28 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-14 12:31:28 | INFO | train | epoch 046 | loss 5.77 | ppl 54.57 | wps 40246.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4727 | lr 0.000459946 | gnorm 0.803 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7734
KL Stats: Epoch 46 Divergences: Uniform: 3.9010651353791865 Unigram: 3.3132160987166546
2022-03-14 12:31:28 | INFO | fairseq.trainer | begin training epoch 47
2022-03-14 12:31:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:33:24 | INFO | train_inner | epoch 047:     73 / 103 loss=5.73, ppl=53.07, wps=40213.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4800, lr=0.000456435, gnorm=0.819, loss_scale=16, train_wall=153, gb_free=20.8, wall=7850
2022-03-14 12:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:34:15 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.701 | ppl 208.13 | wps 66474 | wpb 2040.3 | bsz 4 | num_updates 4830 | best_loss 7.537
2022-03-14 12:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4830 updates
2022-03-14 12:34:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:34:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:34:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 47 @ 4830 updates, score 7.701) (writing took 0.8483705585822463 seconds)
2022-03-14 12:34:15 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-14 12:34:15 | INFO | train | epoch 047 | loss 5.719 | ppl 52.69 | wps 40255.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4830 | lr 0.000455016 | gnorm 0.81 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7901
KL Stats: Epoch 47 Divergences: Uniform: 3.941516601447456 Unigram: 3.35147299750757
2022-03-14 12:34:15 | INFO | fairseq.trainer | begin training epoch 48
2022-03-14 12:34:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:36:06 | INFO | train_inner | epoch 048:     70 / 103 loss=5.685, ppl=51.44, wps=40222.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4900, lr=0.000451754, gnorm=0.787, loss_scale=16, train_wall=153, gb_free=20.8, wall=8012
2022-03-14 12:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:37:02 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.717 | ppl 210.44 | wps 66663 | wpb 2040.3 | bsz 4 | num_updates 4933 | best_loss 7.537
2022-03-14 12:37:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4933 updates
2022-03-14 12:37:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:37:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:37:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 48 @ 4933 updates, score 7.717) (writing took 0.9081719648092985 seconds)
2022-03-14 12:37:03 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-14 12:37:03 | INFO | train | epoch 048 | loss 5.67 | ppl 50.92 | wps 40234.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4933 | lr 0.00045024 | gnorm 0.796 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8069
KL Stats: Epoch 48 Divergences: Uniform: 3.9787286369797936 Unigram: 3.3857610312486757
2022-03-14 12:37:03 | INFO | fairseq.trainer | begin training epoch 49
2022-03-14 12:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:38:49 | INFO | train_inner | epoch 049:     67 / 103 loss=5.639, ppl=49.85, wps=40186.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5000, lr=0.000447214, gnorm=0.81, loss_scale=16, train_wall=153, gb_free=20.8, wall=8175
2022-03-14 12:39:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:39:49 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.751 | ppl 215.48 | wps 66078.6 | wpb 2040.3 | bsz 4 | num_updates 5036 | best_loss 7.537
2022-03-14 12:39:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 5036 updates
2022-03-14 12:39:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:39:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:39:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 49 @ 5036 updates, score 7.751) (writing took 0.8501998893916607 seconds)
2022-03-14 12:39:50 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-14 12:39:50 | INFO | train | epoch 049 | loss 5.626 | ppl 49.38 | wps 40233.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5036 | lr 0.000445612 | gnorm 0.797 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8236
KL Stats: Epoch 49 Divergences: Uniform: 4.016940852323408 Unigram: 3.4207316380732635
2022-03-14 12:39:50 | INFO | fairseq.trainer | begin training epoch 50
2022-03-14 12:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:41:31 | INFO | train_inner | epoch 050:     64 / 103 loss=5.597, ppl=48.41, wps=40226.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5100, lr=0.000442807, gnorm=0.791, loss_scale=16, train_wall=153, gb_free=20.8, wall=8337
2022-03-14 12:42:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:42:36 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.778 | ppl 219.55 | wps 66248.7 | wpb 2040.3 | bsz 4 | num_updates 5139 | best_loss 7.537
2022-03-14 12:42:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 5139 updates
2022-03-14 12:42:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:42:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:42:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 50 @ 5139 updates, score 7.778) (writing took 0.8651464469730854 seconds)
2022-03-14 12:42:37 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-14 12:42:37 | INFO | train | epoch 050 | loss 5.582 | ppl 47.92 | wps 40257.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5139 | lr 0.000441124 | gnorm 0.808 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 8403
KL Stats: Epoch 50 Divergences: Uniform: 4.056289961303846 Unigram: 3.452945427720974
2022-03-14 12:42:37 | INFO | fairseq.trainer | begin training epoch 51
2022-03-14 12:42:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:42:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 12:44:15 | INFO | train_inner | epoch 051:     62 / 103 loss=5.553, ppl=46.96, wps=39821.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=5200, lr=0.000438529, gnorm=0.817, loss_scale=16, train_wall=155, gb_free=20.8, wall=8501
2022-03-14 12:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:45:23 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.802 | ppl 223.2 | wps 66690.9 | wpb 2040.3 | bsz 4 | num_updates 5241 | best_loss 7.537
2022-03-14 12:45:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 5241 updates
2022-03-14 12:45:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:45:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:45:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 51 @ 5241 updates, score 7.802) (writing took 0.9178088596090674 seconds)
2022-03-14 12:45:24 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-14 12:45:24 | INFO | train | epoch 051 | loss 5.539 | ppl 46.48 | wps 39833.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5241 | lr 0.00043681 | gnorm 0.813 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8570
KL Stats: Epoch 51 Divergences: Uniform: 4.094958111818068 Unigram: 3.4875645550176824
2022-03-14 12:45:24 | INFO | fairseq.trainer | begin training epoch 52
2022-03-14 12:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:46:58 | INFO | train_inner | epoch 052:     59 / 103 loss=5.515, ppl=45.72, wps=40179.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5300, lr=0.000434372, gnorm=0.794, loss_scale=16, train_wall=153, gb_free=20.8, wall=8664
2022-03-14 12:48:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:48:11 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.811 | ppl 224.58 | wps 66475.8 | wpb 2040.3 | bsz 4 | num_updates 5344 | best_loss 7.537
2022-03-14 12:48:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5344 updates
2022-03-14 12:48:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:48:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:48:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 52 @ 5344 updates, score 7.811) (writing took 0.8587479088455439 seconds)
2022-03-14 12:48:11 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-14 12:48:11 | INFO | train | epoch 052 | loss 5.499 | ppl 45.24 | wps 40239.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5344 | lr 0.00043258 | gnorm 0.804 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8737
KL Stats: Epoch 52 Divergences: Uniform: 4.129048239093092 Unigram: 3.5194155431749543
2022-03-14 12:48:11 | INFO | fairseq.trainer | begin training epoch 53
2022-03-14 12:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:49:40 | INFO | train_inner | epoch 053:     56 / 103 loss=5.477, ppl=44.53, wps=40216.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5400, lr=0.000430331, gnorm=0.826, loss_scale=16, train_wall=153, gb_free=20.8, wall=8826
2022-03-14 12:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:50:58 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.829 | ppl 227.32 | wps 66199 | wpb 2040.3 | bsz 4 | num_updates 5447 | best_loss 7.537
2022-03-14 12:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5447 updates
2022-03-14 12:50:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:50:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:50:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 53 @ 5447 updates, score 7.829) (writing took 0.8678989056497812 seconds)
2022-03-14 12:50:59 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-14 12:50:59 | INFO | train | epoch 053 | loss 5.46 | ppl 44.03 | wps 40244.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5447 | lr 0.000428471 | gnorm 0.806 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8905
KL Stats: Epoch 53 Divergences: Uniform: 4.161241515728865 Unigram: 3.5484359929911484
2022-03-14 12:50:59 | INFO | fairseq.trainer | begin training epoch 54
2022-03-14 12:50:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:52:23 | INFO | train_inner | epoch 054:     53 / 103 loss=5.439, ppl=43.38, wps=40211, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5500, lr=0.000426401, gnorm=0.806, loss_scale=16, train_wall=153, gb_free=20.8, wall=8989
2022-03-14 12:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:53:45 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7.861 | ppl 232.44 | wps 66443.1 | wpb 2040.3 | bsz 4 | num_updates 5550 | best_loss 7.537
2022-03-14 12:53:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5550 updates
2022-03-14 12:53:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:53:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:53:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 54 @ 5550 updates, score 7.861) (writing took 0.8911605775356293 seconds)
2022-03-14 12:53:46 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-14 12:53:46 | INFO | train | epoch 054 | loss 5.423 | ppl 42.9 | wps 40236 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5550 | lr 0.000424476 | gnorm 0.824 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9072
KL Stats: Epoch 54 Divergences: Uniform: 4.195601408250983 Unigram: 3.5806159128551758
2022-03-14 12:53:46 | INFO | fairseq.trainer | begin training epoch 55
2022-03-14 12:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:54:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 12:55:07 | INFO | train_inner | epoch 055:     51 / 103 loss=5.407, ppl=42.43, wps=39829.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=5600, lr=0.000422577, gnorm=0.819, loss_scale=8, train_wall=155, gb_free=20.8, wall=9153
2022-03-14 12:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:56:32 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 7.88 | ppl 235.51 | wps 66311.7 | wpb 2040.3 | bsz 4 | num_updates 5652 | best_loss 7.537
2022-03-14 12:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5652 updates
2022-03-14 12:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:56:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:56:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 55 @ 5652 updates, score 7.88) (writing took 1.0035334639251232 seconds)
2022-03-14 12:56:33 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-14 12:56:33 | INFO | train | epoch 055 | loss 5.384 | ppl 41.75 | wps 39838.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5652 | lr 0.000420629 | gnorm 0.799 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 9239
KL Stats: Epoch 55 Divergences: Uniform: 4.228546702155913 Unigram: 3.6109763129663275
2022-03-14 12:56:33 | INFO | fairseq.trainer | begin training epoch 56
2022-03-14 12:56:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 12:57:49 | INFO | train_inner | epoch 056:     48 / 103 loss=5.363, ppl=41.16, wps=40192.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=5700, lr=0.000418854, gnorm=0.818, loss_scale=8, train_wall=153, gb_free=20.8, wall=9315
2022-03-14 12:59:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 12:59:19 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 7.891 | ppl 237.39 | wps 65978.5 | wpb 2040.3 | bsz 4 | num_updates 5755 | best_loss 7.537
2022-03-14 12:59:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5755 updates
2022-03-14 12:59:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 12:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 56 @ 5755 updates, score 7.891) (writing took 0.9108432978391647 seconds)
2022-03-14 12:59:20 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-14 12:59:20 | INFO | train | epoch 056 | loss 5.35 | ppl 40.79 | wps 40252.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5755 | lr 0.000416848 | gnorm 0.825 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 9406
KL Stats: Epoch 56 Divergences: Uniform: 4.259509587542192 Unigram: 3.6377946660728218
2022-03-14 12:59:20 | INFO | fairseq.trainer | begin training epoch 57
2022-03-14 12:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:00:31 | INFO | train_inner | epoch 057:     45 / 103 loss=5.334, ppl=40.34, wps=40220.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5800, lr=0.000415227, gnorm=0.803, loss_scale=8, train_wall=153, gb_free=20.8, wall=9477
2022-03-14 13:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:02:06 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 7.927 | ppl 243.36 | wps 66271.6 | wpb 2040.3 | bsz 4 | num_updates 5858 | best_loss 7.537
2022-03-14 13:02:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5858 updates
2022-03-14 13:02:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:02:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:02:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 57 @ 5858 updates, score 7.927) (writing took 0.9817938497290015 seconds)
2022-03-14 13:02:07 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-14 13:02:07 | INFO | train | epoch 057 | loss 5.315 | ppl 39.81 | wps 40224.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5858 | lr 0.000413167 | gnorm 0.814 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 9573
KL Stats: Epoch 57 Divergences: Uniform: 4.293746115855322 Unigram: 3.6665761873274
2022-03-14 13:02:07 | INFO | fairseq.trainer | begin training epoch 58
2022-03-14 13:02:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:03:14 | INFO | train_inner | epoch 058:     42 / 103 loss=5.304, ppl=39.5, wps=40180.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5900, lr=0.000411693, gnorm=0.822, loss_scale=8, train_wall=153, gb_free=20.8, wall=9640
2022-03-14 13:04:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:04:54 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 7.955 | ppl 248.07 | wps 66105.3 | wpb 2040.3 | bsz 4 | num_updates 5961 | best_loss 7.537
2022-03-14 13:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5961 updates
2022-03-14 13:04:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:04:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:04:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 58 @ 5961 updates, score 7.955) (writing took 0.9072713376954198 seconds)
2022-03-14 13:04:54 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-14 13:04:54 | INFO | train | epoch 058 | loss 5.282 | ppl 38.92 | wps 40239.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.822 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 9741
KL Stats: Epoch 58 Divergences: Uniform: 4.323020440158094 Unigram: 3.6957900251084803
2022-03-14 13:04:54 | INFO | fairseq.trainer | begin training epoch 59
2022-03-14 13:04:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:05:56 | INFO | train_inner | epoch 059:     39 / 103 loss=5.269, ppl=38.55, wps=40214.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6000, lr=0.000408248, gnorm=0.824, loss_scale=8, train_wall=153, gb_free=20.8, wall=9802
2022-03-14 13:07:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:07:41 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 7.971 | ppl 250.98 | wps 66152.9 | wpb 2040.3 | bsz 4 | num_updates 6064 | best_loss 7.537
2022-03-14 13:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 6064 updates
2022-03-14 13:07:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:07:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:07:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 59 @ 6064 updates, score 7.971) (writing took 0.8992314049974084 seconds)
2022-03-14 13:07:42 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-14 13:07:42 | INFO | train | epoch 059 | loss 5.251 | ppl 38.07 | wps 40258.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6064 | lr 0.000406088 | gnorm 0.824 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 9908
KL Stats: Epoch 59 Divergences: Uniform: 4.352294988656754 Unigram: 3.7224926354736914
2022-03-14 13:07:42 | INFO | fairseq.trainer | begin training epoch 60
2022-03-14 13:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:08:39 | INFO | train_inner | epoch 060:     36 / 103 loss=5.243, ppl=37.86, wps=40232.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=6100, lr=0.000404888, gnorm=0.824, loss_scale=16, train_wall=153, gb_free=20.8, wall=9965
2022-03-14 13:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:10:28 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 7.991 | ppl 254.33 | wps 66192.4 | wpb 2040.3 | bsz 4 | num_updates 6167 | best_loss 7.537
2022-03-14 13:10:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 6167 updates
2022-03-14 13:10:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:10:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:10:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 60 @ 6167 updates, score 7.991) (writing took 0.9659629231318831 seconds)
2022-03-14 13:10:29 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-14 13:10:29 | INFO | train | epoch 060 | loss 5.22 | ppl 37.27 | wps 40239.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6167 | lr 0.000402683 | gnorm 0.825 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10075
KL Stats: Epoch 60 Divergences: Uniform: 4.379105188145976 Unigram: 3.7462369758883747
2022-03-14 13:10:29 | INFO | fairseq.trainer | begin training epoch 61
2022-03-14 13:10:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:11:21 | INFO | train_inner | epoch 061:     33 / 103 loss=5.21, ppl=37.02, wps=40191.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=6200, lr=0.00040161, gnorm=0.826, loss_scale=16, train_wall=153, gb_free=20.8, wall=10127
2022-03-14 13:13:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:13:15 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 8.03 | ppl 261.33 | wps 66094.4 | wpb 2040.3 | bsz 4 | num_updates 6270 | best_loss 7.537
2022-03-14 13:13:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 6270 updates
2022-03-14 13:13:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:13:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:13:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 61 @ 6270 updates, score 8.03) (writing took 1.0337267788127065 seconds)
2022-03-14 13:13:16 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-14 13:13:16 | INFO | train | epoch 061 | loss 5.191 | ppl 36.52 | wps 40193.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6270 | lr 0.000399362 | gnorm 0.839 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10242
KL Stats: Epoch 61 Divergences: Uniform: 4.408374518478298 Unigram: 3.775366440324408
2022-03-14 13:13:16 | INFO | fairseq.trainer | begin training epoch 62
2022-03-14 13:13:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:14:04 | INFO | train_inner | epoch 062:     30 / 103 loss=5.179, ppl=36.24, wps=40158.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=6300, lr=0.00039841, gnorm=0.841, loss_scale=16, train_wall=153, gb_free=20.8, wall=10290
2022-03-14 13:15:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:16:03 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 8.054 | ppl 265.8 | wps 66392.7 | wpb 2040.3 | bsz 4 | num_updates 6373 | best_loss 7.537
2022-03-14 13:16:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 6373 updates
2022-03-14 13:16:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:16:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:16:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 62 @ 6373 updates, score 8.054) (writing took 0.9355789246037602 seconds)
2022-03-14 13:16:04 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-14 13:16:04 | INFO | train | epoch 062 | loss 5.161 | ppl 35.77 | wps 40142.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6373 | lr 0.000396121 | gnorm 0.829 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10410
KL Stats: Epoch 62 Divergences: Uniform: 4.436701429394423 Unigram: 3.801409667079262
2022-03-14 13:16:04 | INFO | fairseq.trainer | begin training epoch 63
2022-03-14 13:16:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:16:47 | INFO | train_inner | epoch 063:     27 / 103 loss=5.156, ppl=35.65, wps=40089.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=6400, lr=0.000395285, gnorm=0.825, loss_scale=16, train_wall=153, gb_free=20.8, wall=10453
2022-03-14 13:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:18:50 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 8.062 | ppl 267.31 | wps 66014.1 | wpb 2040.3 | bsz 4 | num_updates 6476 | best_loss 7.537
2022-03-14 13:18:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6476 updates
2022-03-14 13:18:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:18:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:18:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 63 @ 6476 updates, score 8.062) (writing took 0.9504753071814775 seconds)
2022-03-14 13:18:51 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-14 13:18:51 | INFO | train | epoch 063 | loss 5.134 | ppl 35.12 | wps 40123 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6476 | lr 0.000392958 | gnorm 0.838 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10577
KL Stats: Epoch 63 Divergences: Uniform: 4.4639833378765506 Unigram: 3.8242368290554998
2022-03-14 13:18:51 | INFO | fairseq.trainer | begin training epoch 64
2022-03-14 13:18:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:19:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 13:19:31 | INFO | train_inner | epoch 064:     25 / 103 loss=5.132, ppl=35.07, wps=39729.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=6500, lr=0.000392232, gnorm=0.846, loss_scale=8, train_wall=155, gb_free=20.8, wall=10617
2022-03-14 13:21:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:21:38 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 8.074 | ppl 269.49 | wps 65777.1 | wpb 2040.3 | bsz 4 | num_updates 6578 | best_loss 7.537
2022-03-14 13:21:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6578 updates
2022-03-14 13:21:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:21:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:21:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 64 @ 6578 updates, score 8.074) (writing took 0.9711234252899885 seconds)
2022-03-14 13:21:39 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-14 13:21:39 | INFO | train | epoch 064 | loss 5.107 | ppl 34.46 | wps 39814.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6578 | lr 0.0003899 | gnorm 0.846 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 10745
KL Stats: Epoch 64 Divergences: Uniform: 4.492134189430341 Unigram: 3.8476294843358736
2022-03-14 13:21:39 | INFO | fairseq.trainer | begin training epoch 65
2022-03-14 13:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:22:14 | INFO | train_inner | epoch 065:     22 / 103 loss=5.101, ppl=34.33, wps=40163.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6600, lr=0.000389249, gnorm=0.84, loss_scale=8, train_wall=153, gb_free=20.8, wall=10780
2022-03-14 13:24:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:24:25 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 8.13 | ppl 280.07 | wps 66268.3 | wpb 2040.3 | bsz 4 | num_updates 6681 | best_loss 7.537
2022-03-14 13:24:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6681 updates
2022-03-14 13:24:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:24:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:24:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 65 @ 6681 updates, score 8.13) (writing took 0.9714247351512313 seconds)
2022-03-14 13:24:26 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-14 13:24:26 | INFO | train | epoch 065 | loss 5.079 | ppl 33.81 | wps 40186.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6681 | lr 0.000386883 | gnorm 0.832 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 10912
KL Stats: Epoch 65 Divergences: Uniform: 4.515530463762694 Unigram: 3.8740636053923607
2022-03-14 13:24:26 | INFO | fairseq.trainer | begin training epoch 66
2022-03-14 13:24:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:24:56 | INFO | train_inner | epoch 066:     19 / 103 loss=5.076, ppl=33.74, wps=40147.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=6700, lr=0.000386334, gnorm=0.836, loss_scale=8, train_wall=153, gb_free=20.8, wall=10942
2022-03-14 13:27:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:27:13 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 8.122 | ppl 278.64 | wps 66062.6 | wpb 2040.3 | bsz 4 | num_updates 6784 | best_loss 7.537
2022-03-14 13:27:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6784 updates
2022-03-14 13:27:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:27:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:27:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 66 @ 6784 updates, score 8.122) (writing took 0.9491703975945711 seconds)
2022-03-14 13:27:14 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-14 13:27:14 | INFO | train | epoch 066 | loss 5.057 | ppl 33.29 | wps 40121.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6784 | lr 0.000383934 | gnorm 0.852 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11080
KL Stats: Epoch 66 Divergences: Uniform: 4.538592711192977 Unigram: 3.8924215342026067
2022-03-14 13:27:14 | INFO | fairseq.trainer | begin training epoch 67
2022-03-14 13:27:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:27:39 | INFO | train_inner | epoch 067:     16 / 103 loss=5.053, ppl=33.21, wps=40080.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6800, lr=0.000383482, gnorm=0.853, loss_scale=8, train_wall=153, gb_free=20.8, wall=11105
2022-03-14 13:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:30:01 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 8.141 | ppl 282.24 | wps 66049.4 | wpb 2040.3 | bsz 4 | num_updates 6887 | best_loss 7.537
2022-03-14 13:30:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6887 updates
2022-03-14 13:30:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:30:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 67 @ 6887 updates, score 8.141) (writing took 0.9337640358135104 seconds)
2022-03-14 13:30:02 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-14 13:30:02 | INFO | train | epoch 067 | loss 5.03 | ppl 32.67 | wps 40082.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6887 | lr 0.000381053 | gnorm 0.844 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11248
KL Stats: Epoch 67 Divergences: Uniform: 4.56390141125504 Unigram: 3.9165324908751433
2022-03-14 13:30:02 | INFO | fairseq.trainer | begin training epoch 68
2022-03-14 13:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:30:22 | INFO | train_inner | epoch 068:     13 / 103 loss=5.032, ppl=32.71, wps=40047.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=6900, lr=0.000380693, gnorm=0.841, loss_scale=8, train_wall=154, gb_free=20.8, wall=11268
2022-03-14 13:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:32:48 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 8.166 | ppl 287.21 | wps 66063.9 | wpb 2040.3 | bsz 4 | num_updates 6990 | best_loss 7.537
2022-03-14 13:32:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6990 updates
2022-03-14 13:32:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:32:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:32:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 68 @ 6990 updates, score 8.166) (writing took 0.9238594826310873 seconds)
2022-03-14 13:32:49 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-14 13:32:49 | INFO | train | epoch 068 | loss 5.007 | ppl 32.16 | wps 40135.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6990 | lr 0.000378235 | gnorm 0.834 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11415
KL Stats: Epoch 68 Divergences: Uniform: 4.586084274160112 Unigram: 3.9373443133517987
2022-03-14 13:32:49 | INFO | fairseq.trainer | begin training epoch 69
2022-03-14 13:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:33:05 | INFO | train_inner | epoch 069:     10 / 103 loss=5.005, ppl=32.1, wps=40113.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=7000, lr=0.000377964, gnorm=0.838, loss_scale=8, train_wall=153, gb_free=20.8, wall=11431
2022-03-14 13:35:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:35:36 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 8.203 | ppl 294.71 | wps 66163 | wpb 2040.3 | bsz 4 | num_updates 7093 | best_loss 7.537
2022-03-14 13:35:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 7093 updates
2022-03-14 13:35:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:35:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:35:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 69 @ 7093 updates, score 8.203) (writing took 0.9398234225809574 seconds)
2022-03-14 13:35:37 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-14 13:35:37 | INFO | train | epoch 069 | loss 4.984 | ppl 31.65 | wps 40168.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7093 | lr 0.000375478 | gnorm 0.846 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 11583
KL Stats: Epoch 69 Divergences: Uniform: 4.609709946904914 Unigram: 3.959908103241382
2022-03-14 13:35:37 | INFO | fairseq.trainer | begin training epoch 70
2022-03-14 13:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:35:48 | INFO | train_inner | epoch 070:      7 / 103 loss=4.985, ppl=31.67, wps=40131.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7100, lr=0.000375293, gnorm=0.847, loss_scale=16, train_wall=153, gb_free=20.8, wall=11594
2022-03-14 13:38:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:38:23 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 8.199 | ppl 293.86 | wps 66471.2 | wpb 2040.3 | bsz 4 | num_updates 7196 | best_loss 7.537
2022-03-14 13:38:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 7196 updates
2022-03-14 13:38:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:38:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:38:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 70 @ 7196 updates, score 8.199) (writing took 0.9452405162155628 seconds)
2022-03-14 13:38:24 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-14 13:38:24 | INFO | train | epoch 070 | loss 4.961 | ppl 31.14 | wps 40133.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7196 | lr 0.000372782 | gnorm 0.86 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 11750
KL Stats: Epoch 70 Divergences: Uniform: 4.632920944239121 Unigram: 3.979608421494041
2022-03-14 13:38:24 | INFO | fairseq.trainer | begin training epoch 71
2022-03-14 13:38:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:38:31 | INFO | train_inner | epoch 071:      4 / 103 loss=4.965, ppl=31.24, wps=40097.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=7200, lr=0.000372678, gnorm=0.858, loss_scale=16, train_wall=153, gb_free=20.8, wall=11757
2022-03-14 13:39:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 13:41:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:41:11 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 8.241 | ppl 302.5 | wps 66140 | wpb 2040.3 | bsz 4 | num_updates 7298 | best_loss 7.537
2022-03-14 13:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 7298 updates
2022-03-14 13:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 71 @ 7298 updates, score 8.241) (writing took 0.9404719024896622 seconds)
2022-03-14 13:41:12 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-14 13:41:12 | INFO | train | epoch 071 | loss 4.939 | ppl 30.68 | wps 39817.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 7298 | lr 0.000370167 | gnorm 0.866 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11918
KL Stats: Epoch 71 Divergences: Uniform: 4.6555174106094235 Unigram: 4.000315899864722
2022-03-14 13:41:12 | INFO | fairseq.trainer | begin training epoch 72
2022-03-14 13:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:41:15 | INFO | train_inner | epoch 072:      2 / 103 loss=4.94, ppl=30.7, wps=39791.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=7300, lr=0.000370117, gnorm=0.865, loss_scale=8, train_wall=155, gb_free=20.8, wall=11921
2022-03-14 13:43:53 | INFO | train_inner | epoch 072:    102 / 103 loss=4.918, ppl=30.23, wps=41324, ups=0.63, wpb=65530.9, bsz=128, num_updates=7400, lr=0.000367607, gnorm=0.865, loss_scale=8, train_wall=154, gb_free=20.8, wall=12079
2022-03-14 13:43:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:43:58 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 8.234 | ppl 301.04 | wps 66085.6 | wpb 2040.3 | bsz 4 | num_updates 7401 | best_loss 7.537
2022-03-14 13:43:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 7401 updates
2022-03-14 13:43:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 72 @ 7401 updates, score 8.234) (writing took 0.9462795257568359 seconds)
2022-03-14 13:43:59 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-14 13:43:59 | INFO | train | epoch 072 | loss 4.917 | ppl 30.21 | wps 40192.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7401 | lr 0.000367582 | gnorm 0.865 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12085
KL Stats: Epoch 72 Divergences: Uniform: 4.675636196452144 Unigram: 4.018678172224802
2022-03-14 13:43:59 | INFO | fairseq.trainer | begin training epoch 73
2022-03-14 13:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:46:36 | INFO | train_inner | epoch 073:     99 / 103 loss=4.893, ppl=29.71, wps=40174, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7500, lr=0.000365148, gnorm=0.866, loss_scale=8, train_wall=153, gb_free=20.8, wall=12242
2022-03-14 13:46:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:46:45 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 8.266 | ppl 307.75 | wps 65997.8 | wpb 2040.3 | bsz 4 | num_updates 7504 | best_loss 7.537
2022-03-14 13:46:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7504 updates
2022-03-14 13:46:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:46:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:46:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 73 @ 7504 updates, score 8.266) (writing took 0.9525132579728961 seconds)
2022-03-14 13:46:46 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-14 13:46:46 | INFO | train | epoch 073 | loss 4.897 | ppl 29.79 | wps 40203.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7504 | lr 0.000365051 | gnorm 0.864 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12252
KL Stats: Epoch 73 Divergences: Uniform: 4.696333235052852 Unigram: 4.0374811937809865
2022-03-14 13:46:46 | INFO | fairseq.trainer | begin training epoch 74
2022-03-14 13:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:49:19 | INFO | train_inner | epoch 074:     96 / 103 loss=4.877, ppl=29.39, wps=40170.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7600, lr=0.000362738, gnorm=0.871, loss_scale=8, train_wall=153, gb_free=20.8, wall=12405
2022-03-14 13:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:49:33 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 8.28 | ppl 310.86 | wps 65788.4 | wpb 2040.3 | bsz 4 | num_updates 7607 | best_loss 7.537
2022-03-14 13:49:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7607 updates
2022-03-14 13:49:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:49:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:49:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 74 @ 7607 updates, score 8.28) (writing took 0.9583226116374135 seconds)
2022-03-14 13:49:34 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-14 13:49:34 | INFO | train | epoch 074 | loss 4.877 | ppl 29.39 | wps 40202.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7607 | lr 0.000362571 | gnorm 0.871 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12420
KL Stats: Epoch 74 Divergences: Uniform: 4.714761367200183 Unigram: 4.05652707890142
2022-03-14 13:49:34 | INFO | fairseq.trainer | begin training epoch 75
2022-03-14 13:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:52:01 | INFO | train_inner | epoch 075:     93 / 103 loss=4.856, ppl=28.95, wps=40118.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7700, lr=0.000360375, gnorm=0.871, loss_scale=8, train_wall=153, gb_free=20.8, wall=12567
2022-03-14 13:52:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:52:20 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 8.287 | ppl 312.27 | wps 66458.2 | wpb 2040.3 | bsz 4 | num_updates 7710 | best_loss 7.537
2022-03-14 13:52:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7710 updates
2022-03-14 13:52:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:52:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:52:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 75 @ 7710 updates, score 8.287) (writing took 0.9305020300671458 seconds)
2022-03-14 13:52:21 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-14 13:52:21 | INFO | train | epoch 075 | loss 4.857 | ppl 28.98 | wps 40156.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7710 | lr 0.000360141 | gnorm 0.87 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12587
KL Stats: Epoch 75 Divergences: Uniform: 4.731854777390486 Unigram: 4.0750655611633775
2022-03-14 13:52:21 | INFO | fairseq.trainer | begin training epoch 76
2022-03-14 13:52:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:54:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 13:54:46 | INFO | train_inner | epoch 076:     91 / 103 loss=4.836, ppl=28.57, wps=39715.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7800, lr=0.000358057, gnorm=0.876, loss_scale=8, train_wall=155, gb_free=20.8, wall=12732
2022-03-14 13:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:55:08 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 8.308 | ppl 316.88 | wps 66256.9 | wpb 2040.3 | bsz 4 | num_updates 7812 | best_loss 7.537
2022-03-14 13:55:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7812 updates
2022-03-14 13:55:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:55:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:55:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 76 @ 7812 updates, score 8.308) (writing took 0.9250373290851712 seconds)
2022-03-14 13:55:09 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-14 13:55:09 | INFO | train | epoch 076 | loss 4.837 | ppl 28.58 | wps 39741.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 7812 | lr 0.000357782 | gnorm 0.88 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12755
KL Stats: Epoch 76 Divergences: Uniform: 4.753166640247655 Unigram: 4.092962034785954
2022-03-14 13:55:09 | INFO | fairseq.trainer | begin training epoch 77
2022-03-14 13:55:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 13:57:29 | INFO | train_inner | epoch 077:     88 / 103 loss=4.82, ppl=28.25, wps=40132.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7900, lr=0.000355784, gnorm=0.869, loss_scale=8, train_wall=153, gb_free=20.8, wall=12895
2022-03-14 13:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 13:57:55 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 8.341 | ppl 324.2 | wps 65998.3 | wpb 2040.3 | bsz 4 | num_updates 7915 | best_loss 7.537
2022-03-14 13:57:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7915 updates
2022-03-14 13:57:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:57:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 13:57:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 77 @ 7915 updates, score 8.341) (writing took 0.9421325763687491 seconds)
2022-03-14 13:57:56 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-14 13:57:56 | INFO | train | epoch 077 | loss 4.819 | ppl 28.22 | wps 40165.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7915 | lr 0.000355447 | gnorm 0.868 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12922
KL Stats: Epoch 77 Divergences: Uniform: 4.771245650922432 Unigram: 4.110497538505911
2022-03-14 13:57:56 | INFO | fairseq.trainer | begin training epoch 78
2022-03-14 13:57:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:00:11 | INFO | train_inner | epoch 078:     85 / 103 loss=4.801, ppl=27.87, wps=40108, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8000, lr=0.000353553, gnorm=0.872, loss_scale=8, train_wall=153, gb_free=20.8, wall=13057
2022-03-14 14:00:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:00:43 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 8.368 | ppl 330.32 | wps 66210.6 | wpb 2040.3 | bsz 4 | num_updates 8018 | best_loss 7.537
2022-03-14 14:00:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 8018 updates
2022-03-14 14:00:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:00:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:00:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 78 @ 8018 updates, score 8.368) (writing took 0.9412763919681311 seconds)
2022-03-14 14:00:44 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-14 14:00:44 | INFO | train | epoch 078 | loss 4.801 | ppl 27.87 | wps 40134 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8018 | lr 0.000353156 | gnorm 0.879 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 13090
KL Stats: Epoch 78 Divergences: Uniform: 4.790012589847835 Unigram: 4.128615689531939
2022-03-14 14:00:44 | INFO | fairseq.trainer | begin training epoch 79
2022-03-14 14:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:02:54 | INFO | train_inner | epoch 079:     82 / 103 loss=4.784, ppl=27.56, wps=40162, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8100, lr=0.000351364, gnorm=0.882, loss_scale=8, train_wall=153, gb_free=20.8, wall=13220
2022-03-14 14:03:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:03:30 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 8.371 | ppl 330.97 | wps 65987.2 | wpb 2040.3 | bsz 4 | num_updates 8121 | best_loss 7.537
2022-03-14 14:03:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 8121 updates
2022-03-14 14:03:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:03:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:03:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 79 @ 8121 updates, score 8.371) (writing took 0.9336061533540487 seconds)
2022-03-14 14:03:31 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-14 14:03:31 | INFO | train | epoch 079 | loss 4.783 | ppl 27.53 | wps 40219.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8121 | lr 0.00035091 | gnorm 0.877 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 13257
KL Stats: Epoch 79 Divergences: Uniform: 4.808116022371641 Unigram: 4.14376713260652
2022-03-14 14:03:31 | INFO | fairseq.trainer | begin training epoch 80
2022-03-14 14:03:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:05:36 | INFO | train_inner | epoch 080:     79 / 103 loss=4.767, ppl=27.23, wps=40175.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8200, lr=0.000349215, gnorm=0.889, loss_scale=8, train_wall=153, gb_free=20.8, wall=13383
2022-03-14 14:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:06:18 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 8.379 | ppl 332.9 | wps 66189.2 | wpb 2040.3 | bsz 4 | num_updates 8224 | best_loss 7.537
2022-03-14 14:06:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 8224 updates
2022-03-14 14:06:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:06:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:06:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 80 @ 8224 updates, score 8.379) (writing took 1.1420097695663571 seconds)
2022-03-14 14:06:19 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-14 14:06:19 | INFO | train | epoch 080 | loss 4.767 | ppl 27.23 | wps 40159.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8224 | lr 0.000348705 | gnorm 0.893 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 13425
KL Stats: Epoch 80 Divergences: Uniform: 4.8219026820192274 Unigram: 4.161137056087649
2022-03-14 14:06:19 | INFO | fairseq.trainer | begin training epoch 81
2022-03-14 14:06:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:08:19 | INFO | train_inner | epoch 081:     76 / 103 loss=4.754, ppl=26.99, wps=40120.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8300, lr=0.000347105, gnorm=0.885, loss_scale=8, train_wall=153, gb_free=20.8, wall=13545
2022-03-14 14:09:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:09:05 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 8.412 | ppl 340.51 | wps 66244.4 | wpb 2040.3 | bsz 4 | num_updates 8327 | best_loss 7.537
2022-03-14 14:09:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 8327 updates
2022-03-14 14:09:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:09:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:09:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 81 @ 8327 updates, score 8.412) (writing took 1.0114488452672958 seconds)
2022-03-14 14:09:06 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-14 14:09:06 | INFO | train | epoch 081 | loss 4.748 | ppl 26.88 | wps 40179.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8327 | lr 0.000346542 | gnorm 0.883 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13592
KL Stats: Epoch 81 Divergences: Uniform: 4.839584191277782 Unigram: 4.17852750247171
2022-03-14 14:09:06 | INFO | fairseq.trainer | begin training epoch 82
2022-03-14 14:09:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:11:02 | INFO | train_inner | epoch 082:     73 / 103 loss=4.734, ppl=26.61, wps=40167.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=8400, lr=0.000345033, gnorm=0.886, loss_scale=16, train_wall=153, gb_free=20.8, wall=13708
2022-03-14 14:11:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:11:52 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 8.432 | ppl 345.47 | wps 66419.8 | wpb 2040.3 | bsz 4 | num_updates 8430 | best_loss 7.537
2022-03-14 14:11:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 8430 updates
2022-03-14 14:11:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:11:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:11:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 82 @ 8430 updates, score 8.432) (writing took 1.0862493989989161 seconds)
2022-03-14 14:11:54 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-14 14:11:54 | INFO | train | epoch 082 | loss 4.731 | ppl 26.56 | wps 40169.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8430 | lr 0.000344418 | gnorm 0.881 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13760
KL Stats: Epoch 82 Divergences: Uniform: 4.8567460397185105 Unigram: 4.195807683270571
2022-03-14 14:11:54 | INFO | fairseq.trainer | begin training epoch 83
2022-03-14 14:11:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:13:45 | INFO | train_inner | epoch 083:     70 / 103 loss=4.718, ppl=26.31, wps=40141.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8500, lr=0.000342997, gnorm=0.894, loss_scale=16, train_wall=153, gb_free=20.8, wall=13871
2022-03-14 14:14:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:14:40 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 8.438 | ppl 346.69 | wps 66262.3 | wpb 2040.3 | bsz 4 | num_updates 8533 | best_loss 7.537
2022-03-14 14:14:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 8533 updates
2022-03-14 14:14:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:14:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:14:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 83 @ 8533 updates, score 8.438) (writing took 1.1062164222821593 seconds)
2022-03-14 14:14:41 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-14 14:14:41 | INFO | train | epoch 083 | loss 4.716 | ppl 26.29 | wps 40188.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8533 | lr 0.000342333 | gnorm 0.898 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13927
KL Stats: Epoch 83 Divergences: Uniform: 4.871651773568504 Unigram: 4.210599415334721
2022-03-14 14:14:41 | INFO | fairseq.trainer | begin training epoch 84
2022-03-14 14:14:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:16:27 | INFO | train_inner | epoch 084:     67 / 103 loss=4.705, ppl=26.08, wps=40149.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8600, lr=0.000340997, gnorm=0.886, loss_scale=16, train_wall=153, gb_free=20.8, wall=14033
2022-03-14 14:17:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:17:27 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 8.459 | ppl 351.83 | wps 66256.4 | wpb 2040.3 | bsz 4 | num_updates 8636 | best_loss 7.537
2022-03-14 14:17:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8636 updates
2022-03-14 14:17:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:17:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:17:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 84 @ 8636 updates, score 8.459) (writing took 1.0079539632424712 seconds)
2022-03-14 14:17:28 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-14 14:17:28 | INFO | train | epoch 084 | loss 4.699 | ppl 25.98 | wps 40213.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8636 | lr 0.000340286 | gnorm 0.881 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14094
KL Stats: Epoch 84 Divergences: Uniform: 4.886603233699371 Unigram: 4.226446952904003
2022-03-14 14:17:28 | INFO | fairseq.trainer | begin training epoch 85
2022-03-14 14:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:17:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 14:19:11 | INFO | train_inner | epoch 085:     65 / 103 loss=4.691, ppl=25.84, wps=39793.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=8700, lr=0.000339032, gnorm=0.892, loss_scale=8, train_wall=155, gb_free=20.8, wall=14197
2022-03-14 14:20:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:20:15 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 8.464 | ppl 353.18 | wps 66829.6 | wpb 2040.3 | bsz 4 | num_updates 8738 | best_loss 7.537
2022-03-14 14:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8738 updates
2022-03-14 14:20:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:20:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:20:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 85 @ 8738 updates, score 8.464) (writing took 1.0479699717834592 seconds)
2022-03-14 14:20:16 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-14 14:20:16 | INFO | train | epoch 085 | loss 4.685 | ppl 25.72 | wps 39811.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 8738 | lr 0.000338294 | gnorm 0.898 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 14262
KL Stats: Epoch 85 Divergences: Uniform: 4.9024035318058266 Unigram: 4.239156910039433
2022-03-14 14:20:16 | INFO | fairseq.trainer | begin training epoch 86
2022-03-14 14:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:21:54 | INFO | train_inner | epoch 086:     62 / 103 loss=4.676, ppl=25.56, wps=40178.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8800, lr=0.0003371, gnorm=0.906, loss_scale=8, train_wall=153, gb_free=20.8, wall=14360
2022-03-14 14:22:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:23:02 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 8.477 | ppl 356.22 | wps 66260.7 | wpb 2040.3 | bsz 4 | num_updates 8841 | best_loss 7.537
2022-03-14 14:23:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8841 updates
2022-03-14 14:23:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:23:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:23:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 86 @ 8841 updates, score 8.477) (writing took 1.0550571754574776 seconds)
2022-03-14 14:23:03 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-14 14:23:03 | INFO | train | epoch 086 | loss 4.67 | ppl 25.46 | wps 40210.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8841 | lr 0.000336317 | gnorm 0.904 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 14429
KL Stats: Epoch 86 Divergences: Uniform: 4.915619664334251 Unigram: 4.254031285646866
2022-03-14 14:23:03 | INFO | fairseq.trainer | begin training epoch 87
2022-03-14 14:23:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:24:36 | INFO | train_inner | epoch 087:     59 / 103 loss=4.658, ppl=25.25, wps=40173.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=8900, lr=0.000335201, gnorm=0.884, loss_scale=8, train_wall=153, gb_free=20.8, wall=14522
2022-03-14 14:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:25:49 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 8.49 | ppl 359.53 | wps 65928.9 | wpb 2040.3 | bsz 4 | num_updates 8944 | best_loss 7.537
2022-03-14 14:25:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8944 updates
2022-03-14 14:25:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:25:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:25:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 87 @ 8944 updates, score 8.49) (writing took 1.017096591182053 seconds)
2022-03-14 14:25:50 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-14 14:25:50 | INFO | train | epoch 087 | loss 4.656 | ppl 25.21 | wps 40219.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8944 | lr 0.000334375 | gnorm 0.887 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 14596
KL Stats: Epoch 87 Divergences: Uniform: 4.9291989926600905 Unigram: 4.267173122842332
2022-03-14 14:25:50 | INFO | fairseq.trainer | begin training epoch 88
2022-03-14 14:25:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:27:19 | INFO | train_inner | epoch 088:     56 / 103 loss=4.646, ppl=25.04, wps=40183.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9000, lr=0.000333333, gnorm=0.89, loss_scale=8, train_wall=153, gb_free=20.8, wall=14685
2022-03-14 14:28:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:28:36 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 8.511 | ppl 364.86 | wps 66587.9 | wpb 2040.3 | bsz 4 | num_updates 9047 | best_loss 7.537
2022-03-14 14:28:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 9047 updates
2022-03-14 14:28:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:28:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:28:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 88 @ 9047 updates, score 8.511) (writing took 1.0705435303971171 seconds)
2022-03-14 14:28:37 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-14 14:28:37 | INFO | train | epoch 088 | loss 4.642 | ppl 24.97 | wps 40204.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9047 | lr 0.000332466 | gnorm 0.902 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 14763
KL Stats: Epoch 88 Divergences: Uniform: 4.9428979367883645 Unigram: 4.281459758473741
2022-03-14 14:28:37 | INFO | fairseq.trainer | begin training epoch 89
2022-03-14 14:28:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:30:01 | INFO | train_inner | epoch 089:     53 / 103 loss=4.637, ppl=24.88, wps=40172.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9100, lr=0.000331497, gnorm=0.91, loss_scale=8, train_wall=153, gb_free=20.8, wall=14848
2022-03-14 14:31:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:31:24 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 8.535 | ppl 370.93 | wps 66145.9 | wpb 2040.3 | bsz 4 | num_updates 9150 | best_loss 7.537
2022-03-14 14:31:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 9150 updates
2022-03-14 14:31:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:31:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:31:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 89 @ 9150 updates, score 8.535) (writing took 1.0255298027768731 seconds)
2022-03-14 14:31:25 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-14 14:31:25 | INFO | train | epoch 089 | loss 4.626 | ppl 24.7 | wps 40223.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9150 | lr 0.00033059 | gnorm 0.898 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 14931
KL Stats: Epoch 89 Divergences: Uniform: 4.95717328258541 Unigram: 4.296575428905536
2022-03-14 14:31:25 | INFO | fairseq.trainer | begin training epoch 90
2022-03-14 14:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:32:44 | INFO | train_inner | epoch 090:     50 / 103 loss=4.62, ppl=24.59, wps=40203.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=9200, lr=0.00032969, gnorm=0.896, loss_scale=16, train_wall=153, gb_free=20.8, wall=15010
2022-03-14 14:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:34:11 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 8.538 | ppl 371.82 | wps 66427.8 | wpb 2040.3 | bsz 4 | num_updates 9253 | best_loss 7.537
2022-03-14 14:34:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 9253 updates
2022-03-14 14:34:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:34:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:34:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 90 @ 9253 updates, score 8.538) (writing took 1.0322452308610082 seconds)
2022-03-14 14:34:12 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-14 14:34:12 | INFO | train | epoch 090 | loss 4.613 | ppl 24.47 | wps 40222.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9253 | lr 0.000328745 | gnorm 0.9 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15098
KL Stats: Epoch 90 Divergences: Uniform: 4.968396723958753 Unigram: 4.30945557471188
2022-03-14 14:34:12 | INFO | fairseq.trainer | begin training epoch 91
2022-03-14 14:34:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:35:26 | INFO | train_inner | epoch 091:     47 / 103 loss=4.606, ppl=24.35, wps=40171, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9300, lr=0.000327913, gnorm=0.9, loss_scale=16, train_wall=153, gb_free=20.8, wall=15173
2022-03-14 14:36:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:36:58 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 8.567 | ppl 379.21 | wps 66076.1 | wpb 2040.3 | bsz 4 | num_updates 9356 | best_loss 7.537
2022-03-14 14:36:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 9356 updates
2022-03-14 14:36:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:36:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:36:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 91 @ 9356 updates, score 8.567) (writing took 1.056080567650497 seconds)
2022-03-14 14:36:59 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-14 14:36:59 | INFO | train | epoch 091 | loss 4.6 | ppl 24.25 | wps 40202.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9356 | lr 0.00032693 | gnorm 0.905 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15265
KL Stats: Epoch 91 Divergences: Uniform: 4.982038690343241 Unigram: 4.32383344397031
2022-03-14 14:36:59 | INFO | fairseq.trainer | begin training epoch 92
2022-03-14 14:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:38:09 | INFO | train_inner | epoch 092:     44 / 103 loss=4.595, ppl=24.16, wps=40175.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=9400, lr=0.000326164, gnorm=0.893, loss_scale=16, train_wall=153, gb_free=20.8, wall=15335
2022-03-14 14:39:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:39:46 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 8.585 | ppl 384.13 | wps 66157.2 | wpb 2040.3 | bsz 4 | num_updates 9459 | best_loss 7.537
2022-03-14 14:39:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 9459 updates
2022-03-14 14:39:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:39:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:39:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 92 @ 9459 updates, score 8.585) (writing took 1.0068309335038066 seconds)
2022-03-14 14:39:47 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-14 14:39:47 | INFO | train | epoch 092 | loss 4.586 | ppl 24.02 | wps 40178.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9459 | lr 0.000325145 | gnorm 0.89 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15433
KL Stats: Epoch 92 Divergences: Uniform: 4.9966746689072865 Unigram: 4.337418207853934
2022-03-14 14:39:47 | INFO | fairseq.trainer | begin training epoch 93
2022-03-14 14:39:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:40:52 | INFO | train_inner | epoch 093:     41 / 103 loss=4.579, ppl=23.91, wps=40096.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=9500, lr=0.000324443, gnorm=0.911, loss_scale=16, train_wall=153, gb_free=20.8, wall=15498
2022-03-14 14:42:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:42:34 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 8.575 | ppl 381.25 | wps 66058.7 | wpb 2040.3 | bsz 4 | num_updates 9562 | best_loss 7.537
2022-03-14 14:42:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 9562 updates
2022-03-14 14:42:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:42:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:42:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 93 @ 9562 updates, score 8.575) (writing took 0.9211212238296866 seconds)
2022-03-14 14:42:35 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-14 14:42:35 | INFO | train | epoch 093 | loss 4.574 | ppl 23.82 | wps 40087 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9562 | lr 0.000323389 | gnorm 0.919 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15601
KL Stats: Epoch 93 Divergences: Uniform: 5.006042388293094 Unigram: 4.34632509862206
2022-03-14 14:42:35 | INFO | fairseq.trainer | begin training epoch 94
2022-03-14 14:42:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:43:35 | INFO | train_inner | epoch 094:     38 / 103 loss=4.567, ppl=23.7, wps=40051.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=9600, lr=0.000322749, gnorm=0.913, loss_scale=16, train_wall=154, gb_free=20.8, wall=15661
2022-03-14 14:45:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:45:21 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 8.592 | ppl 385.77 | wps 65988 | wpb 2040.3 | bsz 4 | num_updates 9665 | best_loss 7.537
2022-03-14 14:45:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9665 updates
2022-03-14 14:45:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:45:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 94 @ 9665 updates, score 8.592) (writing took 0.8907844563946128 seconds)
2022-03-14 14:45:22 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-14 14:45:22 | INFO | train | epoch 094 | loss 4.56 | ppl 23.6 | wps 40127.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9665 | lr 0.000321661 | gnorm 0.914 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15768
KL Stats: Epoch 94 Divergences: Uniform: 5.0177314711301015 Unigram: 4.360473725619497
2022-03-14 14:45:22 | INFO | fairseq.trainer | begin training epoch 95
2022-03-14 14:45:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:46:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 14:46:20 | INFO | train_inner | epoch 095:     36 / 103 loss=4.561, ppl=23.6, wps=39689.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9700, lr=0.000321081, gnorm=0.917, loss_scale=16, train_wall=155, gb_free=20.8, wall=15826
2022-03-14 14:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:48:09 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 8.594 | ppl 386.48 | wps 65579.7 | wpb 2040.3 | bsz 4 | num_updates 9767 | best_loss 7.537
2022-03-14 14:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9767 updates
2022-03-14 14:48:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:48:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 95 @ 9767 updates, score 8.594) (writing took 0.8874640362337232 seconds)
2022-03-14 14:48:10 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-14 14:48:10 | INFO | train | epoch 095 | loss 4.549 | ppl 23.4 | wps 39699.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 9767 | lr 0.000319977 | gnorm 0.917 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15936
KL Stats: Epoch 95 Divergences: Uniform: 5.028924646549428 Unigram: 4.37092797446663
2022-03-14 14:48:10 | INFO | fairseq.trainer | begin training epoch 96
2022-03-14 14:48:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:49:02 | INFO | train_inner | epoch 096:     33 / 103 loss=4.547, ppl=23.37, wps=40089.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9800, lr=0.000319438, gnorm=0.913, loss_scale=16, train_wall=153, gb_free=20.8, wall=15988
2022-03-14 14:50:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:50:57 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 8.607 | ppl 390.01 | wps 65542 | wpb 2040.3 | bsz 4 | num_updates 9870 | best_loss 7.537
2022-03-14 14:50:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9870 updates
2022-03-14 14:50:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:50:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:50:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 96 @ 9870 updates, score 8.607) (writing took 0.931119236163795 seconds)
2022-03-14 14:50:58 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-14 14:50:58 | INFO | train | epoch 096 | loss 4.537 | ppl 23.21 | wps 40125.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9870 | lr 0.000318304 | gnorm 0.905 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16104
KL Stats: Epoch 96 Divergences: Uniform: 5.0407655088109715 Unigram: 4.383140509739743
2022-03-14 14:50:58 | INFO | fairseq.trainer | begin training epoch 97
2022-03-14 14:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:51:45 | INFO | train_inner | epoch 097:     30 / 103 loss=4.535, ppl=23.19, wps=40087.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9900, lr=0.000317821, gnorm=0.915, loss_scale=16, train_wall=153, gb_free=20.8, wall=16151
2022-03-14 14:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:53:44 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 8.619 | ppl 393.1 | wps 66145.5 | wpb 2040.3 | bsz 4 | num_updates 9973 | best_loss 7.537
2022-03-14 14:53:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9973 updates
2022-03-14 14:53:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:53:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:53:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 97 @ 9973 updates, score 8.619) (writing took 0.9412404848262668 seconds)
2022-03-14 14:53:45 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-14 14:53:45 | INFO | train | epoch 097 | loss 4.526 | ppl 23.04 | wps 40085.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9973 | lr 0.000316656 | gnorm 0.917 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16271
KL Stats: Epoch 97 Divergences: Uniform: 5.052699839853986 Unigram: 4.396494012968029
2022-03-14 14:53:45 | INFO | fairseq.trainer | begin training epoch 98
2022-03-14 14:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:54:29 | INFO | train_inner | epoch 098:     27 / 103 loss=4.523, ppl=22.99, wps=40022.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10000, lr=0.000316228, gnorm=0.911, loss_scale=16, train_wall=154, gb_free=20.8, wall=16315
2022-03-14 14:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:56:32 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 8.646 | ppl 400.71 | wps 66242.1 | wpb 2040.3 | bsz 4 | num_updates 10076 | best_loss 7.537
2022-03-14 14:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 10076 updates
2022-03-14 14:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:56:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:56:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 98 @ 10076 updates, score 8.646) (writing took 0.9128525806590915 seconds)
2022-03-14 14:56:33 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-14 14:56:33 | INFO | train | epoch 098 | loss 4.513 | ppl 22.84 | wps 40087.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10076 | lr 0.000315033 | gnorm 0.926 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16439
KL Stats: Epoch 98 Divergences: Uniform: 5.060608134141693 Unigram: 4.405821319711958
2022-03-14 14:56:33 | INFO | fairseq.trainer | begin training epoch 99
2022-03-14 14:56:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:57:11 | INFO | train_inner | epoch 099:     24 / 103 loss=4.512, ppl=22.81, wps=40073.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10100, lr=0.000314658, gnorm=0.927, loss_scale=16, train_wall=153, gb_free=20.8, wall=16477
2022-03-14 14:57:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 14:59:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 14:59:20 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 8.67 | ppl 407.28 | wps 66052.9 | wpb 2040.3 | bsz 4 | num_updates 10178 | best_loss 7.537
2022-03-14 14:59:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 10178 updates
2022-03-14 14:59:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:59:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 14:59:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 99 @ 10178 updates, score 8.67) (writing took 0.9453632077202201 seconds)
2022-03-14 14:59:21 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-14 14:59:21 | INFO | train | epoch 099 | loss 4.5 | ppl 22.63 | wps 39699.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 10178 | lr 0.00031345 | gnorm 0.929 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 16607
KL Stats: Epoch 99 Divergences: Uniform: 5.072523608668932 Unigram: 4.419961834059081
2022-03-14 14:59:21 | INFO | fairseq.trainer | begin training epoch 100
2022-03-14 14:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 14:59:56 | INFO | train_inner | epoch 100:     22 / 103 loss=4.499, ppl=22.62, wps=39694.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10200, lr=0.000313112, gnorm=0.944, loss_scale=8, train_wall=155, gb_free=20.8, wall=16642
2022-03-14 15:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:02:07 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 8.668 | ppl 406.83 | wps 66157.7 | wpb 2040.3 | bsz 4 | num_updates 10281 | best_loss 7.537
2022-03-14 15:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 10281 updates
2022-03-14 15:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:02:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:02:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 100 @ 10281 updates, score 8.668) (writing took 0.9859373653307557 seconds)
2022-03-14 15:02:08 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-14 15:02:08 | INFO | train | epoch 100 | loss 4.49 | ppl 22.47 | wps 40181.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10281 | lr 0.000311876 | gnorm 0.931 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 16774
KL Stats: Epoch 100 Divergences: Uniform: 5.082683630996261 Unigram: 4.42924590691261
2022-03-14 15:02:08 | INFO | fairseq.trainer | begin training epoch 101
2022-03-14 15:02:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:02:39 | INFO | train_inner | epoch 101:     19 / 103 loss=4.489, ppl=22.46, wps=40151.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10300, lr=0.000311588, gnorm=0.921, loss_scale=8, train_wall=153, gb_free=20.8, wall=16805
2022-03-14 15:04:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:04:55 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 8.674 | ppl 408.42 | wps 66619 | wpb 2040.3 | bsz 4 | num_updates 10384 | best_loss 7.537
2022-03-14 15:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 10384 updates
2022-03-14 15:04:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:04:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 101 @ 10384 updates, score 8.674) (writing took 1.2095746519044042 seconds)
2022-03-14 15:04:56 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-14 15:04:56 | INFO | train | epoch 101 | loss 4.478 | ppl 22.29 | wps 40155.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10384 | lr 0.000310326 | gnorm 0.923 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 16942
KL Stats: Epoch 101 Divergences: Uniform: 5.093400428101349 Unigram: 4.440560998737746
2022-03-14 15:04:56 | INFO | fairseq.trainer | begin training epoch 102
2022-03-14 15:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:05:21 | INFO | train_inner | epoch 102:     16 / 103 loss=4.479, ppl=22.3, wps=40119.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10400, lr=0.000310087, gnorm=0.926, loss_scale=8, train_wall=153, gb_free=20.8, wall=16967
2022-03-14 15:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:07:42 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 8.703 | ppl 416.66 | wps 66446.8 | wpb 2040.3 | bsz 4 | num_updates 10487 | best_loss 7.537
2022-03-14 15:07:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 10487 updates
2022-03-14 15:07:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:07:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:07:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 102 @ 10487 updates, score 8.703) (writing took 1.0792165333405137 seconds)
2022-03-14 15:07:43 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-14 15:07:43 | INFO | train | epoch 102 | loss 4.467 | ppl 22.12 | wps 40210.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10487 | lr 0.000308798 | gnorm 0.932 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 17109
KL Stats: Epoch 102 Divergences: Uniform: 5.10552611124783 Unigram: 4.453261829430937
2022-03-14 15:07:43 | INFO | fairseq.trainer | begin training epoch 103
2022-03-14 15:07:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:08:04 | INFO | train_inner | epoch 103:     13 / 103 loss=4.468, ppl=22.14, wps=40178.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10500, lr=0.000308607, gnorm=0.932, loss_scale=8, train_wall=153, gb_free=20.8, wall=17130
2022-03-14 15:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:10:30 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 8.7 | ppl 415.96 | wps 65458.2 | wpb 2040.3 | bsz 4 | num_updates 10590 | best_loss 7.537
2022-03-14 15:10:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 10590 updates
2022-03-14 15:10:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:10:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:10:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 103 @ 10590 updates, score 8.7) (writing took 0.9831159235909581 seconds)
2022-03-14 15:10:31 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-14 15:10:31 | INFO | train | epoch 103 | loss 4.457 | ppl 21.97 | wps 40201.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10590 | lr 0.000307293 | gnorm 0.923 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 17277
KL Stats: Epoch 103 Divergences: Uniform: 5.113653714712072 Unigram: 4.46345437271887
2022-03-14 15:10:31 | INFO | fairseq.trainer | begin training epoch 104
2022-03-14 15:10:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:10:47 | INFO | train_inner | epoch 104:     10 / 103 loss=4.458, ppl=21.98, wps=40167.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10600, lr=0.000307148, gnorm=0.924, loss_scale=8, train_wall=153, gb_free=20.8, wall=17293
2022-03-14 15:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:13:17 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 8.721 | ppl 422 | wps 66063 | wpb 2040.3 | bsz 4 | num_updates 10693 | best_loss 7.537
2022-03-14 15:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10693 updates
2022-03-14 15:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:13:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 104 @ 10693 updates, score 8.721) (writing took 0.9951654057949781 seconds)
2022-03-14 15:13:18 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-14 15:13:18 | INFO | train | epoch 104 | loss 4.447 | ppl 21.81 | wps 40205.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10693 | lr 0.000305809 | gnorm 0.923 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17444
KL Stats: Epoch 104 Divergences: Uniform: 5.123890730720007 Unigram: 4.473791886007317
2022-03-14 15:13:18 | INFO | fairseq.trainer | begin training epoch 105
2022-03-14 15:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:13:29 | INFO | train_inner | epoch 105:      7 / 103 loss=4.447, ppl=21.81, wps=40171.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10700, lr=0.000305709, gnorm=0.92, loss_scale=16, train_wall=153, gb_free=20.8, wall=17455
2022-03-14 15:16:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:16:04 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 8.749 | ppl 430.28 | wps 65964.1 | wpb 2040.3 | bsz 4 | num_updates 10796 | best_loss 7.537
2022-03-14 15:16:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10796 updates
2022-03-14 15:16:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:16:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:16:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 105 @ 10796 updates, score 8.749) (writing took 0.9934406410902739 seconds)
2022-03-14 15:16:05 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-14 15:16:05 | INFO | train | epoch 105 | loss 4.439 | ppl 21.7 | wps 40220.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10796 | lr 0.000304347 | gnorm 0.926 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17611
KL Stats: Epoch 105 Divergences: Uniform: 5.132245236979376 Unigram: 4.482172634479709
2022-03-14 15:16:05 | INFO | fairseq.trainer | begin training epoch 106
2022-03-14 15:16:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:16:12 | INFO | train_inner | epoch 106:      4 / 103 loss=4.442, ppl=21.74, wps=40185.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10800, lr=0.00030429, gnorm=0.927, loss_scale=16, train_wall=153, gb_free=20.8, wall=17618
2022-03-14 15:18:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 15:18:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:18:52 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 8.745 | ppl 429 | wps 66078.8 | wpb 2040.3 | bsz 4 | num_updates 10898 | best_loss 7.537
2022-03-14 15:18:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10898 updates
2022-03-14 15:18:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:18:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:18:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 106 @ 10898 updates, score 8.745) (writing took 0.9637807691469789 seconds)
2022-03-14 15:18:52 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-14 15:18:52 | INFO | train | epoch 106 | loss 4.427 | ppl 21.52 | wps 39827.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 10898 | lr 0.000302919 | gnorm 0.932 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 17778
KL Stats: Epoch 106 Divergences: Uniform: 5.141106563861338 Unigram: 4.492969320450867
2022-03-14 15:18:52 | INFO | fairseq.trainer | begin training epoch 107
2022-03-14 15:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:18:56 | INFO | train_inner | epoch 107:      2 / 103 loss=4.429, ppl=21.54, wps=39798.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10900, lr=0.000302891, gnorm=0.932, loss_scale=8, train_wall=155, gb_free=20.8, wall=17782
2022-03-14 15:21:34 | INFO | train_inner | epoch 107:    102 / 103 loss=4.42, ppl=21.4, wps=41356.2, ups=0.63, wpb=65530.9, bsz=128, num_updates=11000, lr=0.000301511, gnorm=0.936, loss_scale=8, train_wall=154, gb_free=20.8, wall=17940
2022-03-14 15:21:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:21:39 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 8.734 | ppl 425.85 | wps 66466.3 | wpb 2040.3 | bsz 4 | num_updates 11001 | best_loss 7.537
2022-03-14 15:21:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 11001 updates
2022-03-14 15:21:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:21:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:21:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 107 @ 11001 updates, score 8.734) (writing took 0.9631543103605509 seconds)
2022-03-14 15:21:40 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-14 15:21:40 | INFO | train | epoch 107 | loss 4.419 | ppl 21.39 | wps 40220 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11001 | lr 0.000301498 | gnorm 0.938 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 17946
KL Stats: Epoch 107 Divergences: Uniform: 5.147932577887279 Unigram: 4.49918972266514
2022-03-14 15:21:40 | INFO | fairseq.trainer | begin training epoch 108
2022-03-14 15:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:24:17 | INFO | train_inner | epoch 108:     99 / 103 loss=4.406, ppl=21.19, wps=40192.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11100, lr=0.00030015, gnorm=0.952, loss_scale=8, train_wall=153, gb_free=20.8, wall=18103
2022-03-14 15:24:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:24:26 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 8.764 | ppl 434.59 | wps 66401.1 | wpb 2040.3 | bsz 4 | num_updates 11104 | best_loss 7.537
2022-03-14 15:24:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 11104 updates
2022-03-14 15:24:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:24:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:24:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 108 @ 11104 updates, score 8.764) (writing took 0.9917045757174492 seconds)
2022-03-14 15:24:27 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-14 15:24:27 | INFO | train | epoch 108 | loss 4.407 | ppl 21.22 | wps 40214.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11104 | lr 0.000300096 | gnorm 0.95 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 18113
KL Stats: Epoch 108 Divergences: Uniform: 5.1562225522079554 Unigram: 4.511798618873633
2022-03-14 15:24:27 | INFO | fairseq.trainer | begin training epoch 109
2022-03-14 15:24:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:26:59 | INFO | train_inner | epoch 109:     96 / 103 loss=4.395, ppl=21.04, wps=40175.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11200, lr=0.000298807, gnorm=0.929, loss_scale=8, train_wall=153, gb_free=20.8, wall=18265
2022-03-14 15:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:27:13 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 8.768 | ppl 436 | wps 65767 | wpb 2040.3 | bsz 4 | num_updates 11207 | best_loss 7.537
2022-03-14 15:27:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 11207 updates
2022-03-14 15:27:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:27:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:27:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 109 @ 11207 updates, score 8.768) (writing took 0.9724154435098171 seconds)
2022-03-14 15:27:14 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-14 15:27:14 | INFO | train | epoch 109 | loss 4.398 | ppl 21.09 | wps 40213.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11207 | lr 0.000298714 | gnorm 0.933 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 18280
KL Stats: Epoch 109 Divergences: Uniform: 5.165498693605783 Unigram: 4.5212174893653145
2022-03-14 15:27:14 | INFO | fairseq.trainer | begin training epoch 110
2022-03-14 15:27:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:29:42 | INFO | train_inner | epoch 110:     93 / 103 loss=4.387, ppl=20.93, wps=40179.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11300, lr=0.000297482, gnorm=0.946, loss_scale=8, train_wall=153, gb_free=20.8, wall=18428
2022-03-14 15:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:30:01 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 8.766 | ppl 435.22 | wps 66579.3 | wpb 2040.3 | bsz 4 | num_updates 11310 | best_loss 7.537
2022-03-14 15:30:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 11310 updates
2022-03-14 15:30:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:30:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 110 @ 11310 updates, score 8.766) (writing took 0.988688888028264 seconds)
2022-03-14 15:30:02 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-14 15:30:02 | INFO | train | epoch 110 | loss 4.389 | ppl 20.94 | wps 40213.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11310 | lr 0.000297351 | gnorm 0.942 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 18448
KL Stats: Epoch 110 Divergences: Uniform: 5.173518467896473 Unigram: 4.5306662592830005
2022-03-14 15:30:02 | INFO | fairseq.trainer | begin training epoch 111
2022-03-14 15:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:32:24 | INFO | train_inner | epoch 111:     90 / 103 loss=4.378, ppl=20.79, wps=40185.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11400, lr=0.000296174, gnorm=0.94, loss_scale=8, train_wall=153, gb_free=20.8, wall=18590
2022-03-14 15:32:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:32:48 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 8.772 | ppl 437.1 | wps 66298.3 | wpb 2040.3 | bsz 4 | num_updates 11413 | best_loss 7.537
2022-03-14 15:32:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 11413 updates
2022-03-14 15:32:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:32:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:32:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 111 @ 11413 updates, score 8.772) (writing took 0.982960213907063 seconds)
2022-03-14 15:32:49 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-14 15:32:49 | INFO | train | epoch 111 | loss 4.379 | ppl 20.8 | wps 40213.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11413 | lr 0.000296006 | gnorm 0.94 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 18615
KL Stats: Epoch 111 Divergences: Uniform: 5.181041285973254 Unigram: 4.538649953327972
2022-03-14 15:32:49 | INFO | fairseq.trainer | begin training epoch 112
2022-03-14 15:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:35:07 | INFO | train_inner | epoch 112:     87 / 103 loss=4.37, ppl=20.68, wps=40182.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11500, lr=0.000294884, gnorm=0.93, loss_scale=16, train_wall=153, gb_free=20.8, wall=18753
2022-03-14 15:35:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:35:35 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 8.79 | ppl 442.67 | wps 65749.5 | wpb 2040.3 | bsz 4 | num_updates 11516 | best_loss 7.537
2022-03-14 15:35:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 11516 updates
2022-03-14 15:35:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:35:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 112 @ 11516 updates, score 8.79) (writing took 0.954964492470026 seconds)
2022-03-14 15:35:36 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-14 15:35:36 | INFO | train | epoch 112 | loss 4.37 | ppl 20.68 | wps 40226.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11516 | lr 0.000294679 | gnorm 0.932 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 18782
KL Stats: Epoch 112 Divergences: Uniform: 5.187014495524118 Unigram: 4.546983619821821
2022-03-14 15:35:36 | INFO | fairseq.trainer | begin training epoch 113
2022-03-14 15:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:37:49 | INFO | train_inner | epoch 113:     84 / 103 loss=4.361, ppl=20.54, wps=40176.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11600, lr=0.00029361, gnorm=0.948, loss_scale=16, train_wall=153, gb_free=20.8, wall=18915
2022-03-14 15:38:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:38:22 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 8.825 | ppl 453.37 | wps 66336.6 | wpb 2040.3 | bsz 4 | num_updates 11619 | best_loss 7.537
2022-03-14 15:38:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 11619 updates
2022-03-14 15:38:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:38:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:38:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 113 @ 11619 updates, score 8.825) (writing took 0.9716935148462653 seconds)
2022-03-14 15:38:23 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-14 15:38:23 | INFO | train | epoch 113 | loss 4.361 | ppl 20.56 | wps 40203.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11619 | lr 0.00029337 | gnorm 0.945 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 18949
KL Stats: Epoch 113 Divergences: Uniform: 5.199007733966901 Unigram: 4.558527188583436
2022-03-14 15:38:23 | INFO | fairseq.trainer | begin training epoch 114
2022-03-14 15:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:40:32 | INFO | train_inner | epoch 114:     81 / 103 loss=4.352, ppl=20.42, wps=40188.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11700, lr=0.000292353, gnorm=0.939, loss_scale=16, train_wall=153, gb_free=20.8, wall=19078
2022-03-14 15:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:41:10 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 8.82 | ppl 452.08 | wps 66054.1 | wpb 2040.3 | bsz 4 | num_updates 11722 | best_loss 7.537
2022-03-14 15:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 11722 updates
2022-03-14 15:41:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:41:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 114 @ 11722 updates, score 8.82) (writing took 0.9827001411467791 seconds)
2022-03-14 15:41:11 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-14 15:41:11 | INFO | train | epoch 114 | loss 4.352 | ppl 20.43 | wps 40227.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11722 | lr 0.000292078 | gnorm 0.95 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19117
KL Stats: Epoch 114 Divergences: Uniform: 5.206321654507412 Unigram: 4.566926439249502
2022-03-14 15:41:11 | INFO | fairseq.trainer | begin training epoch 115
2022-03-14 15:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:43:14 | INFO | train_inner | epoch 115:     78 / 103 loss=4.344, ppl=20.31, wps=40189.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=11800, lr=0.000291111, gnorm=0.954, loss_scale=16, train_wall=153, gb_free=20.8, wall=19240
2022-03-14 15:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:43:57 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 8.826 | ppl 453.92 | wps 66269.7 | wpb 2040.3 | bsz 4 | num_updates 11825 | best_loss 7.537
2022-03-14 15:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11825 updates
2022-03-14 15:43:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:43:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:43:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 115 @ 11825 updates, score 8.826) (writing took 0.992740080691874 seconds)
2022-03-14 15:43:58 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-14 15:43:58 | INFO | train | epoch 115 | loss 4.343 | ppl 20.3 | wps 40215.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11825 | lr 0.000290803 | gnorm 0.95 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19284
KL Stats: Epoch 115 Divergences: Uniform: 5.209470142955156 Unigram: 4.57434776771941
2022-03-14 15:43:58 | INFO | fairseq.trainer | begin training epoch 116
2022-03-14 15:43:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:45:57 | INFO | train_inner | epoch 116:     75 / 103 loss=4.338, ppl=20.22, wps=40188.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=11900, lr=0.000289886, gnorm=0.946, loss_scale=16, train_wall=153, gb_free=20.8, wall=19403
2022-03-14 15:46:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 15:46:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:46:44 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 8.842 | ppl 458.81 | wps 66697.8 | wpb 2040.3 | bsz 4 | num_updates 11927 | best_loss 7.537
2022-03-14 15:46:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11927 updates
2022-03-14 15:46:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:46:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:46:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 116 @ 11927 updates, score 8.842) (writing took 0.976247570477426 seconds)
2022-03-14 15:46:45 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-14 15:46:45 | INFO | train | epoch 116 | loss 4.336 | ppl 20.19 | wps 39855.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 11927 | lr 0.000289557 | gnorm 0.949 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19451
KL Stats: Epoch 116 Divergences: Uniform: 5.219726255528407 Unigram: 4.585293596919383
2022-03-14 15:46:45 | INFO | fairseq.trainer | begin training epoch 117
2022-03-14 15:46:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:48:41 | INFO | train_inner | epoch 117:     73 / 103 loss=4.327, ppl=20.08, wps=39829, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12000, lr=0.000288675, gnorm=0.96, loss_scale=16, train_wall=154, gb_free=20.8, wall=19567
2022-03-14 15:49:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:49:31 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 8.841 | ppl 458.67 | wps 66461.6 | wpb 2040.3 | bsz 4 | num_updates 12030 | best_loss 7.537
2022-03-14 15:49:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 12030 updates
2022-03-14 15:49:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:49:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:49:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 117 @ 12030 updates, score 8.841) (writing took 0.9503870718181133 seconds)
2022-03-14 15:49:32 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-14 15:49:32 | INFO | train | epoch 117 | loss 4.328 | ppl 20.09 | wps 40250.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12030 | lr 0.000288315 | gnorm 0.962 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19618
KL Stats: Epoch 117 Divergences: Uniform: 5.22545020603967 Unigram: 4.592125200760544
2022-03-14 15:49:32 | INFO | fairseq.trainer | begin training epoch 118
2022-03-14 15:49:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:51:23 | INFO | train_inner | epoch 118:     70 / 103 loss=4.318, ppl=19.95, wps=40210.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=12100, lr=0.00028748, gnorm=0.964, loss_scale=16, train_wall=153, gb_free=20.8, wall=19729
2022-03-14 15:52:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:52:18 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 8.898 | ppl 477 | wps 66254.7 | wpb 2040.3 | bsz 4 | num_updates 12133 | best_loss 7.537
2022-03-14 15:52:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 12133 updates
2022-03-14 15:52:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:52:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:52:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 118 @ 12133 updates, score 8.898) (writing took 1.0034275399520993 seconds)
2022-03-14 15:52:19 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-14 15:52:19 | INFO | train | epoch 118 | loss 4.318 | ppl 19.94 | wps 40218.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12133 | lr 0.000287089 | gnorm 0.955 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19786
KL Stats: Epoch 118 Divergences: Uniform: 5.234577016069329 Unigram: 4.603939277926716
2022-03-14 15:52:19 | INFO | fairseq.trainer | begin training epoch 119
2022-03-14 15:52:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:54:06 | INFO | train_inner | epoch 119:     67 / 103 loss=4.315, ppl=19.91, wps=40170, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=12200, lr=0.000286299, gnorm=0.951, loss_scale=16, train_wall=153, gb_free=20.8, wall=19892
2022-03-14 15:55:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:55:06 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 8.854 | ppl 462.84 | wps 66180.6 | wpb 2040.3 | bsz 4 | num_updates 12236 | best_loss 7.537
2022-03-14 15:55:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 12236 updates
2022-03-14 15:55:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:55:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:55:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 119 @ 12236 updates, score 8.854) (writing took 0.9645473817363381 seconds)
2022-03-14 15:55:07 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-14 15:55:07 | INFO | train | epoch 119 | loss 4.312 | ppl 19.86 | wps 40212.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12236 | lr 0.000285878 | gnorm 0.953 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19953
KL Stats: Epoch 119 Divergences: Uniform: 5.238842806407484 Unigram: 4.608436532001278
2022-03-14 15:55:07 | INFO | fairseq.trainer | begin training epoch 120
2022-03-14 15:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:56:48 | INFO | train_inner | epoch 120:     64 / 103 loss=4.304, ppl=19.75, wps=40199.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12300, lr=0.000285133, gnorm=0.953, loss_scale=16, train_wall=153, gb_free=20.8, wall=20054
2022-03-14 15:57:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 15:57:53 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 8.882 | ppl 471.74 | wps 66254.1 | wpb 2040.3 | bsz 4 | num_updates 12339 | best_loss 7.537
2022-03-14 15:57:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 12339 updates
2022-03-14 15:57:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:57:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 15:57:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 120 @ 12339 updates, score 8.882) (writing took 0.9966683993116021 seconds)
2022-03-14 15:57:54 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-14 15:57:54 | INFO | train | epoch 120 | loss 4.303 | ppl 19.74 | wps 40238.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12339 | lr 0.000284682 | gnorm 0.953 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20120
KL Stats: Epoch 120 Divergences: Uniform: 5.247557425349896 Unigram: 4.617826056822383
2022-03-14 15:57:54 | INFO | fairseq.trainer | begin training epoch 121
2022-03-14 15:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 15:59:31 | INFO | train_inner | epoch 121:     61 / 103 loss=4.299, ppl=19.68, wps=40207.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12400, lr=0.000283981, gnorm=0.95, loss_scale=16, train_wall=153, gb_free=20.8, wall=20217
2022-03-14 16:00:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:00:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:00:40 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 8.881 | ppl 471.6 | wps 65993.4 | wpb 2040.3 | bsz 4 | num_updates 12441 | best_loss 7.537
2022-03-14 16:00:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 12441 updates
2022-03-14 16:00:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:00:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:00:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 121 @ 12441 updates, score 8.881) (writing took 0.9578373711556196 seconds)
2022-03-14 16:00:41 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-14 16:00:41 | INFO | train | epoch 121 | loss 4.294 | ppl 19.62 | wps 39849.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 12441 | lr 0.000283513 | gnorm 0.951 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20287
KL Stats: Epoch 121 Divergences: Uniform: 5.256161864078321 Unigram: 4.62597279725771
2022-03-14 16:00:41 | INFO | fairseq.trainer | begin training epoch 122
2022-03-14 16:00:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:02:15 | INFO | train_inner | epoch 122:     59 / 103 loss=4.291, ppl=19.57, wps=39816.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12500, lr=0.000282843, gnorm=0.953, loss_scale=16, train_wall=154, gb_free=20.8, wall=20381
2022-03-14 16:03:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:03:27 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 8.906 | ppl 479.56 | wps 66494.4 | wpb 2040.3 | bsz 4 | num_updates 12544 | best_loss 7.537
2022-03-14 16:03:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 12544 updates
2022-03-14 16:03:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:03:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:03:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 122 @ 12544 updates, score 8.906) (writing took 0.9527807543054223 seconds)
2022-03-14 16:03:28 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-14 16:03:28 | INFO | train | epoch 122 | loss 4.288 | ppl 19.53 | wps 40226.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12544 | lr 0.000282346 | gnorm 0.966 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20454
KL Stats: Epoch 122 Divergences: Uniform: 5.25927203305726 Unigram: 4.632252444568563
2022-03-14 16:03:28 | INFO | fairseq.trainer | begin training epoch 123
2022-03-14 16:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:04:57 | INFO | train_inner | epoch 123:     56 / 103 loss=4.279, ppl=19.41, wps=40196.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=12600, lr=0.000281718, gnorm=0.971, loss_scale=16, train_wall=153, gb_free=20.8, wall=20543
2022-03-14 16:06:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:06:15 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 8.899 | ppl 477.54 | wps 66125.6 | wpb 2040.3 | bsz 4 | num_updates 12647 | best_loss 7.537
2022-03-14 16:06:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 12647 updates
2022-03-14 16:06:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:06:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:06:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 123 @ 12647 updates, score 8.899) (writing took 0.9599035931751132 seconds)
2022-03-14 16:06:16 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-14 16:06:16 | INFO | train | epoch 123 | loss 4.279 | ppl 19.42 | wps 40241.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12647 | lr 0.000281194 | gnorm 0.963 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20622
KL Stats: Epoch 123 Divergences: Uniform: 5.264898052545276 Unigram: 4.640492571711146
2022-03-14 16:06:16 | INFO | fairseq.trainer | begin training epoch 124
2022-03-14 16:06:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:07:40 | INFO | train_inner | epoch 124:     53 / 103 loss=4.277, ppl=19.38, wps=40216.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=12700, lr=0.000280607, gnorm=0.971, loss_scale=16, train_wall=153, gb_free=20.8, wall=20706
2022-03-14 16:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:09:02 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 8.904 | ppl 479.05 | wps 66443.9 | wpb 2040.3 | bsz 4 | num_updates 12750 | best_loss 7.537
2022-03-14 16:09:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 12750 updates
2022-03-14 16:09:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:09:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:09:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 124 @ 12750 updates, score 8.904) (writing took 0.9536879928782582 seconds)
2022-03-14 16:09:03 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-14 16:09:03 | INFO | train | epoch 124 | loss 4.272 | ppl 19.32 | wps 40254.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12750 | lr 0.000280056 | gnorm 0.968 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20789
KL Stats: Epoch 124 Divergences: Uniform: 5.273181310178779 Unigram: 4.6487341462360146
2022-03-14 16:09:03 | INFO | fairseq.trainer | begin training epoch 125
2022-03-14 16:09:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:10:22 | INFO | train_inner | epoch 125:     50 / 103 loss=4.271, ppl=19.3, wps=40219.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12800, lr=0.000279508, gnorm=0.966, loss_scale=16, train_wall=153, gb_free=20.8, wall=20868
2022-03-14 16:11:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:11:49 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 8.915 | ppl 482.55 | wps 65958.3 | wpb 2040.3 | bsz 4 | num_updates 12853 | best_loss 7.537
2022-03-14 16:11:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12853 updates
2022-03-14 16:11:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:11:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:11:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 125 @ 12853 updates, score 8.915) (writing took 0.9291606489568949 seconds)
2022-03-14 16:11:50 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-14 16:11:50 | INFO | train | epoch 125 | loss 4.265 | ppl 19.23 | wps 40262.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12853 | lr 0.000278932 | gnorm 0.966 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20956
KL Stats: Epoch 125 Divergences: Uniform: 5.280004269290207 Unigram: 4.655963645239181
2022-03-14 16:11:50 | INFO | fairseq.trainer | begin training epoch 126
2022-03-14 16:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:13:04 | INFO | train_inner | epoch 126:     47 / 103 loss=4.261, ppl=19.18, wps=40225.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12900, lr=0.000278423, gnorm=0.965, loss_scale=16, train_wall=153, gb_free=20.8, wall=21030
2022-03-14 16:14:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:14:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:14:36 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 8.957 | ppl 496.93 | wps 66183.7 | wpb 2040.3 | bsz 4 | num_updates 12955 | best_loss 7.537
2022-03-14 16:14:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12955 updates
2022-03-14 16:14:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:14:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:14:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 126 @ 12955 updates, score 8.957) (writing took 0.9800585778430104 seconds)
2022-03-14 16:14:37 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-14 16:14:37 | INFO | train | epoch 126 | loss 4.256 | ppl 19.11 | wps 39832.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 12955 | lr 0.000277831 | gnorm 0.976 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21123
KL Stats: Epoch 126 Divergences: Uniform: 5.285748486590762 Unigram: 4.664695668053916
2022-03-14 16:14:37 | INFO | fairseq.trainer | begin training epoch 127
2022-03-14 16:14:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:15:48 | INFO | train_inner | epoch 127:     45 / 103 loss=4.25, ppl=19.02, wps=39777.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13000, lr=0.00027735, gnorm=0.97, loss_scale=16, train_wall=155, gb_free=20.8, wall=21194
2022-03-14 16:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:17:23 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 8.931 | ppl 488.09 | wps 66238.6 | wpb 2040.3 | bsz 4 | num_updates 13058 | best_loss 7.537
2022-03-14 16:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 13058 updates
2022-03-14 16:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:17:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 127 @ 13058 updates, score 8.931) (writing took 0.9032843923196197 seconds)
2022-03-14 16:17:24 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-14 16:17:24 | INFO | train | epoch 127 | loss 4.25 | ppl 19.03 | wps 40183.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13058 | lr 0.000276733 | gnorm 0.956 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21290
KL Stats: Epoch 127 Divergences: Uniform: 5.289395439734394 Unigram: 4.672034340494036
2022-03-14 16:17:24 | INFO | fairseq.trainer | begin training epoch 128
2022-03-14 16:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:18:31 | INFO | train_inner | epoch 128:     42 / 103 loss=4.251, ppl=19.04, wps=40158.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=13100, lr=0.000276289, gnorm=0.962, loss_scale=16, train_wall=153, gb_free=20.8, wall=21357
2022-03-14 16:20:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:20:11 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 8.941 | ppl 491.57 | wps 66440.6 | wpb 2040.3 | bsz 4 | num_updates 13161 | best_loss 7.537
2022-03-14 16:20:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 13161 updates
2022-03-14 16:20:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:20:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:20:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 128 @ 13161 updates, score 8.941) (writing took 0.915951949544251 seconds)
2022-03-14 16:20:12 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-14 16:20:12 | INFO | train | epoch 128 | loss 4.243 | ppl 18.93 | wps 40219.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13161 | lr 0.000275648 | gnorm 0.962 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21458
KL Stats: Epoch 128 Divergences: Uniform: 5.295450665416767 Unigram: 4.677258597861848
2022-03-14 16:20:12 | INFO | fairseq.trainer | begin training epoch 129
2022-03-14 16:20:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:21:14 | INFO | train_inner | epoch 129:     39 / 103 loss=4.239, ppl=18.88, wps=40182.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=13200, lr=0.000275241, gnorm=0.954, loss_scale=16, train_wall=153, gb_free=20.8, wall=21520
2022-03-14 16:22:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:22:58 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 8.948 | ppl 493.89 | wps 65582.8 | wpb 2040.3 | bsz 4 | num_updates 13264 | best_loss 7.537
2022-03-14 16:22:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 13264 updates
2022-03-14 16:22:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:22:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:22:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 129 @ 13264 updates, score 8.948) (writing took 0.9832293782383204 seconds)
2022-03-14 16:22:59 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-14 16:22:59 | INFO | train | epoch 129 | loss 4.236 | ppl 18.84 | wps 40198.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13264 | lr 0.000274576 | gnorm 0.96 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21625
KL Stats: Epoch 129 Divergences: Uniform: 5.300390095235495 Unigram: 4.684170008635162
2022-03-14 16:22:59 | INFO | fairseq.trainer | begin training epoch 130
2022-03-14 16:22:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:23:56 | INFO | train_inner | epoch 130:     36 / 103 loss=4.232, ppl=18.79, wps=40178.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13300, lr=0.000274204, gnorm=0.963, loss_scale=16, train_wall=153, gb_free=20.8, wall=21682
2022-03-14 16:25:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:25:45 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 8.964 | ppl 499.5 | wps 66275.5 | wpb 2040.3 | bsz 4 | num_updates 13367 | best_loss 7.537
2022-03-14 16:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 13367 updates
2022-03-14 16:25:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:25:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:25:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 130 @ 13367 updates, score 8.964) (writing took 0.8645950742065907 seconds)
2022-03-14 16:25:46 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-14 16:25:46 | INFO | train | epoch 130 | loss 4.229 | ppl 18.76 | wps 40259.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13367 | lr 0.000273516 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21792
KL Stats: Epoch 130 Divergences: Uniform: 5.307805014410717 Unigram: 4.691584605616478
2022-03-14 16:25:46 | INFO | fairseq.trainer | begin training epoch 131
2022-03-14 16:25:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:26:38 | INFO | train_inner | epoch 131:     33 / 103 loss=4.228, ppl=18.74, wps=40221.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13400, lr=0.000273179, gnorm=0.97, loss_scale=16, train_wall=153, gb_free=20.8, wall=21844
2022-03-14 16:28:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:28:33 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 8.98 | ppl 504.99 | wps 65456.8 | wpb 2040.3 | bsz 4 | num_updates 13470 | best_loss 7.537
2022-03-14 16:28:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 13470 updates
2022-03-14 16:28:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:28:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:28:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 131 @ 13470 updates, score 8.98) (writing took 0.8731531370431185 seconds)
2022-03-14 16:28:33 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-14 16:28:33 | INFO | train | epoch 131 | loss 4.221 | ppl 18.65 | wps 40207.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13470 | lr 0.000272468 | gnorm 0.96 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 21959
KL Stats: Epoch 131 Divergences: Uniform: 5.313622481895747 Unigram: 4.700964203736676
2022-03-14 16:28:33 | INFO | fairseq.trainer | begin training epoch 132
2022-03-14 16:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:28:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:29:23 | INFO | train_inner | epoch 132:     31 / 103 loss=4.221, ppl=18.65, wps=39757, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13500, lr=0.000272166, gnorm=0.966, loss_scale=16, train_wall=155, gb_free=20.8, wall=22009
2022-03-14 16:31:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:31:20 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 8.971 | ppl 501.74 | wps 65888.2 | wpb 2040.3 | bsz 4 | num_updates 13572 | best_loss 7.537
2022-03-14 16:31:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 13572 updates
2022-03-14 16:31:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:31:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:31:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 132 @ 13572 updates, score 8.971) (writing took 0.9205638337880373 seconds)
2022-03-14 16:31:21 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-14 16:31:21 | INFO | train | epoch 132 | loss 4.215 | ppl 18.57 | wps 39808.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13572 | lr 0.000271443 | gnorm 0.971 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22127
KL Stats: Epoch 132 Divergences: Uniform: 5.317880262702474 Unigram: 4.70634935623848
2022-03-14 16:31:21 | INFO | fairseq.trainer | begin training epoch 133
2022-03-14 16:31:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:32:05 | INFO | train_inner | epoch 133:     28 / 103 loss=4.215, ppl=18.57, wps=40204.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=13600, lr=0.000271163, gnorm=0.976, loss_scale=16, train_wall=153, gb_free=20.8, wall=22171
2022-03-14 16:34:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:34:07 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 8.979 | ppl 504.71 | wps 65930.6 | wpb 2040.3 | bsz 4 | num_updates 13675 | best_loss 7.537
2022-03-14 16:34:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 13675 updates
2022-03-14 16:34:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:34:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:34:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 133 @ 13675 updates, score 8.979) (writing took 0.9550057640299201 seconds)
2022-03-14 16:34:08 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-14 16:34:08 | INFO | train | epoch 133 | loss 4.209 | ppl 18.5 | wps 40218.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13675 | lr 0.000270418 | gnorm 0.983 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22294
KL Stats: Epoch 133 Divergences: Uniform: 5.323545122514888 Unigram: 4.713452378245301
2022-03-14 16:34:08 | INFO | fairseq.trainer | begin training epoch 134
2022-03-14 16:34:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:34:48 | INFO | train_inner | epoch 134:     25 / 103 loss=4.21, ppl=18.5, wps=40183, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13700, lr=0.000270172, gnorm=0.976, loss_scale=16, train_wall=153, gb_free=20.8, wall=22334
2022-03-14 16:36:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:36:54 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 9 | ppl 511.94 | wps 66167.4 | wpb 2040.3 | bsz 4 | num_updates 13778 | best_loss 7.537
2022-03-14 16:36:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 13778 updates
2022-03-14 16:36:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:36:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 134 @ 13778 updates, score 9.0) (writing took 0.9533854005858302 seconds)
2022-03-14 16:36:55 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-14 16:36:55 | INFO | train | epoch 134 | loss 4.202 | ppl 18.4 | wps 40227.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13778 | lr 0.000269406 | gnorm 0.965 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22461
KL Stats: Epoch 134 Divergences: Uniform: 5.331192023967197 Unigram: 4.721011605355704
2022-03-14 16:36:55 | INFO | fairseq.trainer | begin training epoch 135
2022-03-14 16:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:37:30 | INFO | train_inner | epoch 135:     22 / 103 loss=4.201, ppl=18.4, wps=40198.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13800, lr=0.000269191, gnorm=0.971, loss_scale=16, train_wall=153, gb_free=20.8, wall=22496
2022-03-14 16:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:39:41 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 8.981 | ppl 505.2 | wps 65955.6 | wpb 2040.3 | bsz 4 | num_updates 13881 | best_loss 7.537
2022-03-14 16:39:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13881 updates
2022-03-14 16:39:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:39:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:39:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 135 @ 13881 updates, score 8.981) (writing took 0.9451637640595436 seconds)
2022-03-14 16:39:42 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-14 16:39:42 | INFO | train | epoch 135 | loss 4.196 | ppl 18.33 | wps 40240.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13881 | lr 0.000268404 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22628
KL Stats: Epoch 135 Divergences: Uniform: 5.330957647297653 Unigram: 4.723966961461159
2022-03-14 16:39:42 | INFO | fairseq.trainer | begin training epoch 136
2022-03-14 16:39:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:40:13 | INFO | train_inner | epoch 136:     19 / 103 loss=4.197, ppl=18.34, wps=40212.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13900, lr=0.000268221, gnorm=0.978, loss_scale=16, train_wall=153, gb_free=20.8, wall=22659
2022-03-14 16:42:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:42:29 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 9.01 | ppl 515.42 | wps 65781.7 | wpb 2040.3 | bsz 4 | num_updates 13984 | best_loss 7.537
2022-03-14 16:42:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13984 updates
2022-03-14 16:42:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:42:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:42:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 136 @ 13984 updates, score 9.01) (writing took 0.9890335910022259 seconds)
2022-03-14 16:42:30 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-14 16:42:30 | INFO | train | epoch 136 | loss 4.189 | ppl 18.24 | wps 40222.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13984 | lr 0.000267414 | gnorm 0.965 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 22796
KL Stats: Epoch 136 Divergences: Uniform: 5.338323267648745 Unigram: 4.732424598531102
2022-03-14 16:42:30 | INFO | fairseq.trainer | begin training epoch 137
2022-03-14 16:42:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:42:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:42:57 | INFO | train_inner | epoch 137:     17 / 103 loss=4.191, ppl=18.27, wps=39796.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14000, lr=0.000267261, gnorm=0.972, loss_scale=16, train_wall=155, gb_free=20.8, wall=22823
2022-03-14 16:45:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:45:16 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 9.019 | ppl 518.84 | wps 66155.2 | wpb 2040.3 | bsz 4 | num_updates 14086 | best_loss 7.537
2022-03-14 16:45:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 14086 updates
2022-03-14 16:45:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:45:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:45:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 137 @ 14086 updates, score 9.019) (writing took 1.0692138383165002 seconds)
2022-03-14 16:45:17 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-14 16:45:17 | INFO | train | epoch 137 | loss 4.183 | ppl 18.16 | wps 39814.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 14086 | lr 0.000266444 | gnorm 0.988 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22963
KL Stats: Epoch 137 Divergences: Uniform: 5.342570637376399 Unigram: 4.738410321453469
2022-03-14 16:45:17 | INFO | fairseq.trainer | begin training epoch 138
2022-03-14 16:45:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:45:39 | INFO | train_inner | epoch 138:     14 / 103 loss=4.181, ppl=18.14, wps=40172.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14100, lr=0.000266312, gnorm=0.989, loss_scale=16, train_wall=153, gb_free=20.8, wall=22985
2022-03-14 16:48:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:48:03 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 9.027 | ppl 521.78 | wps 66380.6 | wpb 2040.3 | bsz 4 | num_updates 14189 | best_loss 7.537
2022-03-14 16:48:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 14189 updates
2022-03-14 16:48:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:48:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:48:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 138 @ 14189 updates, score 9.027) (writing took 1.1322577092796564 seconds)
2022-03-14 16:48:04 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-14 16:48:04 | INFO | train | epoch 138 | loss 4.176 | ppl 18.08 | wps 40176.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14189 | lr 0.000265475 | gnorm 0.978 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23130
KL Stats: Epoch 138 Divergences: Uniform: 5.349774263781105 Unigram: 4.745909356737716
2022-03-14 16:48:04 | INFO | fairseq.trainer | begin training epoch 139
2022-03-14 16:48:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:48:22 | INFO | train_inner | epoch 139:     11 / 103 loss=4.179, ppl=18.11, wps=40135.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14200, lr=0.000265372, gnorm=0.976, loss_scale=16, train_wall=153, gb_free=20.8, wall=23148
2022-03-14 16:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:50:51 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 9.04 | ppl 526.37 | wps 66165.3 | wpb 2040.3 | bsz 4 | num_updates 14292 | best_loss 7.537
2022-03-14 16:50:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 14292 updates
2022-03-14 16:50:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:50:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:50:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 139 @ 14292 updates, score 9.04) (writing took 0.9540585447102785 seconds)
2022-03-14 16:50:52 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-14 16:50:52 | INFO | train | epoch 139 | loss 4.172 | ppl 18.02 | wps 40162.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 14292 | lr 0.000264517 | gnorm 0.976 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23298
KL Stats: Epoch 139 Divergences: Uniform: 5.353018484855672 Unigram: 4.7516104123310905
2022-03-14 16:50:52 | INFO | fairseq.trainer | begin training epoch 140
2022-03-14 16:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:51:05 | INFO | train_inner | epoch 140:      8 / 103 loss=4.174, ppl=18.05, wps=40131, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14300, lr=0.000264443, gnorm=0.981, loss_scale=16, train_wall=153, gb_free=20.8, wall=23311
2022-03-14 16:53:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:53:38 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 9.033 | ppl 523.95 | wps 65924.1 | wpb 2040.3 | bsz 4 | num_updates 14395 | best_loss 7.537
2022-03-14 16:53:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 14395 updates
2022-03-14 16:53:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:53:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:53:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 140 @ 14395 updates, score 9.033) (writing took 0.9356314232572913 seconds)
2022-03-14 16:53:39 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-14 16:53:39 | INFO | train | epoch 140 | loss 4.166 | ppl 17.95 | wps 40233.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14395 | lr 0.000263569 | gnorm 0.982 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23465
KL Stats: Epoch 140 Divergences: Uniform: 5.359656265107267 Unigram: 4.757047863364352
2022-03-14 16:53:39 | INFO | fairseq.trainer | begin training epoch 141
2022-03-14 16:53:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:53:47 | INFO | train_inner | epoch 141:      5 / 103 loss=4.165, ppl=17.94, wps=40200.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14400, lr=0.000263523, gnorm=0.979, loss_scale=16, train_wall=153, gb_free=20.8, wall=23473
2022-03-14 16:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:56:26 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 9.017 | ppl 517.97 | wps 66437.5 | wpb 2040.3 | bsz 4 | num_updates 14498 | best_loss 7.537
2022-03-14 16:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 14498 updates
2022-03-14 16:56:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 141 @ 14498 updates, score 9.017) (writing took 0.9640587698668242 seconds)
2022-03-14 16:56:26 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-14 16:56:26 | INFO | train | epoch 141 | loss 4.158 | ppl 17.85 | wps 40193.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14498 | lr 0.000262631 | gnorm 0.97 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 23633
KL Stats: Epoch 141 Divergences: Uniform: 5.362110018125129 Unigram: 4.763650512835611
2022-03-14 16:56:26 | INFO | fairseq.trainer | begin training epoch 142
2022-03-14 16:56:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:56:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:56:31 | INFO | train_inner | epoch 142:      3 / 103 loss=4.161, ppl=17.89, wps=39773.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14500, lr=0.000262613, gnorm=0.971, loss_scale=16, train_wall=155, gb_free=20.8, wall=23637
2022-03-14 16:59:09 | INFO | train_inner | epoch 142:    103 / 103 loss=4.155, ppl=17.81, wps=41361.4, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=14600, lr=0.000261712, gnorm=0.977, loss_scale=16, train_wall=153, gb_free=20.8, wall=23795
2022-03-14 16:59:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:59:13 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 9.054 | ppl 531.64 | wps 66430.5 | wpb 2040.3 | bsz 4 | num_updates 14600 | best_loss 7.537
2022-03-14 16:59:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 14600 updates
2022-03-14 16:59:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:59:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 16:59:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 142 @ 14600 updates, score 9.054) (writing took 0.9348906772211194 seconds)
2022-03-14 16:59:14 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-14 16:59:14 | INFO | train | epoch 142 | loss 4.153 | ppl 17.79 | wps 39839.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 14600 | lr 0.000261712 | gnorm 0.978 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23800
KL Stats: Epoch 142 Divergences: Uniform: 5.365244091604947 Unigram: 4.770199771767462
2022-03-14 16:59:14 | INFO | fairseq.trainer | begin training epoch 143
2022-03-14 16:59:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:01:52 | INFO | train_inner | epoch 143:    100 / 103 loss=4.146, ppl=17.7, wps=40197.4, ups=0.61, wpb=65530.9, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.98, loss_scale=16, train_wall=154, gb_free=20.8, wall=23958
2022-03-14 17:01:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:02:00 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 9.065 | ppl 535.76 | wps 66290 | wpb 2040.3 | bsz 4 | num_updates 14703 | best_loss 7.537
2022-03-14 17:02:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 14703 updates
2022-03-14 17:02:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:02:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:02:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 143 @ 14703 updates, score 9.065) (writing took 0.9218841819092631 seconds)
2022-03-14 17:02:01 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-14 17:02:01 | INFO | train | epoch 143 | loss 4.147 | ppl 17.72 | wps 40229.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14703 | lr 0.000260794 | gnorm 0.982 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23967
KL Stats: Epoch 143 Divergences: Uniform: 5.3696963486666185 Unigram: 4.777229792197516
2022-03-14 17:02:01 | INFO | fairseq.trainer | begin training epoch 144
2022-03-14 17:02:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:04:35 | INFO | train_inner | epoch 144:     97 / 103 loss=4.139, ppl=17.62, wps=40196.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14800, lr=0.000259938, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=24121
2022-03-14 17:04:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:04:47 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 9.057 | ppl 532.55 | wps 66619.3 | wpb 2040.3 | bsz 4 | num_updates 14806 | best_loss 7.537
2022-03-14 17:04:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 14806 updates
2022-03-14 17:04:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:04:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 144 @ 14806 updates, score 9.057) (writing took 0.9146774411201477 seconds)
2022-03-14 17:04:48 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-14 17:04:48 | INFO | train | epoch 144 | loss 4.142 | ppl 17.66 | wps 40233.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14806 | lr 0.000259885 | gnorm 1.007 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24134
KL Stats: Epoch 144 Divergences: Uniform: 5.3749517849764 Unigram: 4.780284817124956
2022-03-14 17:04:48 | INFO | fairseq.trainer | begin training epoch 145
2022-03-14 17:04:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:07:17 | INFO | train_inner | epoch 145:     94 / 103 loss=4.135, ppl=17.57, wps=40213.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14900, lr=0.000259064, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=24283
2022-03-14 17:07:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:07:34 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 9.093 | ppl 546.05 | wps 66116.4 | wpb 2040.3 | bsz 4 | num_updates 14909 | best_loss 7.537
2022-03-14 17:07:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 14909 updates
2022-03-14 17:07:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:07:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:07:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 145 @ 14909 updates, score 9.093) (writing took 0.9336932776495814 seconds)
2022-03-14 17:07:35 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-14 17:07:35 | INFO | train | epoch 145 | loss 4.135 | ppl 17.57 | wps 40244.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14909 | lr 0.000258986 | gnorm 0.99 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24301
KL Stats: Epoch 145 Divergences: Uniform: 5.380972177520224 Unigram: 4.788727810260959
2022-03-14 17:07:35 | INFO | fairseq.trainer | begin training epoch 146
2022-03-14 17:07:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:09:59 | INFO | train_inner | epoch 146:     91 / 103 loss=4.128, ppl=17.49, wps=40219.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15000, lr=0.000258199, gnorm=0.991, loss_scale=16, train_wall=153, gb_free=20.8, wall=24445
2022-03-14 17:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:10:21 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 9.064 | ppl 535.35 | wps 66150.7 | wpb 2040.3 | bsz 4 | num_updates 15012 | best_loss 7.537
2022-03-14 17:10:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 15012 updates
2022-03-14 17:10:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:10:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:10:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 146 @ 15012 updates, score 9.064) (writing took 0.8991468157619238 seconds)
2022-03-14 17:10:22 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-14 17:10:22 | INFO | train | epoch 146 | loss 4.131 | ppl 17.53 | wps 40262.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15012 | lr 0.000258096 | gnorm 0.992 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 24468
KL Stats: Epoch 146 Divergences: Uniform: 5.381299618562823 Unigram: 4.792939917819384
2022-03-14 17:10:22 | INFO | fairseq.trainer | begin training epoch 147
2022-03-14 17:10:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:10:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:12:43 | INFO | train_inner | epoch 147:     89 / 103 loss=4.124, ppl=17.43, wps=39840.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=15100, lr=0.000257343, gnorm=0.989, loss_scale=16, train_wall=155, gb_free=20.8, wall=24609
2022-03-14 17:13:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:13:09 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 9.072 | ppl 538.13 | wps 66149.1 | wpb 2040.3 | bsz 4 | num_updates 15114 | best_loss 7.537
2022-03-14 17:13:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 15114 updates
2022-03-14 17:13:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:13:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:13:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 147 @ 15114 updates, score 9.072) (writing took 0.9501391174271703 seconds)
2022-03-14 17:13:10 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-14 17:13:10 | INFO | train | epoch 147 | loss 4.124 | ppl 17.43 | wps 39847.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15114 | lr 0.000257223 | gnorm 0.992 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24636
KL Stats: Epoch 147 Divergences: Uniform: 5.385414568629937 Unigram: 4.796295795531868
2022-03-14 17:13:10 | INFO | fairseq.trainer | begin training epoch 148
2022-03-14 17:13:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:15:26 | INFO | train_inner | epoch 148:     86 / 103 loss=4.117, ppl=17.35, wps=40206.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15200, lr=0.000256495, gnorm=0.99, loss_scale=16, train_wall=153, gb_free=20.8, wall=24772
2022-03-14 17:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:15:56 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 9.086 | ppl 543.35 | wps 66386.1 | wpb 2040.3 | bsz 4 | num_updates 15217 | best_loss 7.537
2022-03-14 17:15:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 15217 updates
2022-03-14 17:15:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:15:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:15:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 148 @ 15217 updates, score 9.086) (writing took 0.9073301255702972 seconds)
2022-03-14 17:15:57 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-14 17:15:57 | INFO | train | epoch 148 | loss 4.119 | ppl 17.38 | wps 40260.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15217 | lr 0.000256351 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24803
KL Stats: Epoch 148 Divergences: Uniform: 5.392759772704427 Unigram: 4.804854331484784
2022-03-14 17:15:57 | INFO | fairseq.trainer | begin training epoch 149
2022-03-14 17:15:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:18:08 | INFO | train_inner | epoch 149:     83 / 103 loss=4.115, ppl=17.33, wps=40228.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15300, lr=0.000255655, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=24934
2022-03-14 17:18:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:18:43 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 9.11 | ppl 552.44 | wps 66052.6 | wpb 2040.3 | bsz 4 | num_updates 15320 | best_loss 7.537
2022-03-14 17:18:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 15320 updates
2022-03-14 17:18:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:18:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:18:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 149 @ 15320 updates, score 9.11) (writing took 0.9405989274382591 seconds)
2022-03-14 17:18:44 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-14 17:18:44 | INFO | train | epoch 149 | loss 4.114 | ppl 17.32 | wps 40245.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15320 | lr 0.000255488 | gnorm 0.99 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24970
KL Stats: Epoch 149 Divergences: Uniform: 5.395367486286619 Unigram: 4.809410603583933
2022-03-14 17:18:44 | INFO | fairseq.trainer | begin training epoch 150
2022-03-14 17:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:20:51 | INFO | train_inner | epoch 150:     80 / 103 loss=4.106, ppl=17.22, wps=40183.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15400, lr=0.000254824, gnorm=0.988, loss_scale=16, train_wall=153, gb_free=20.8, wall=25097
2022-03-14 17:21:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:21:30 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 9.099 | ppl 548.51 | wps 66620.3 | wpb 2040.3 | bsz 4 | num_updates 15423 | best_loss 7.537
2022-03-14 17:21:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 15423 updates
2022-03-14 17:21:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:21:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:21:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 150 @ 15423 updates, score 9.099) (writing took 0.9604033306241035 seconds)
2022-03-14 17:21:31 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-14 17:21:31 | INFO | train | epoch 150 | loss 4.109 | ppl 17.25 | wps 40217.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15423 | lr 0.000254634 | gnorm 0.985 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25137
KL Stats: Epoch 150 Divergences: Uniform: 5.399217531232985 Unigram: 4.814765720009672
2022-03-14 17:21:31 | INFO | fairseq.trainer | begin training epoch 151
2022-03-14 17:21:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:23:33 | INFO | train_inner | epoch 151:     77 / 103 loss=4.109, ppl=17.25, wps=40198, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15500, lr=0.000254, gnorm=0.989, loss_scale=16, train_wall=153, gb_free=20.8, wall=25259
2022-03-14 17:24:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:24:17 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 9.105 | ppl 550.66 | wps 65940.6 | wpb 2040.3 | bsz 4 | num_updates 15526 | best_loss 7.537
2022-03-14 17:24:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 15526 updates
2022-03-14 17:24:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:24:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:24:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 151 @ 15526 updates, score 9.105) (writing took 0.9108630074188113 seconds)
2022-03-14 17:24:18 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-14 17:24:18 | INFO | train | epoch 151 | loss 4.104 | ppl 17.19 | wps 40239.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15526 | lr 0.000253787 | gnorm 0.993 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 25304
KL Stats: Epoch 151 Divergences: Uniform: 5.4034406062214195 Unigram: 4.820743324038473
2022-03-14 17:24:18 | INFO | fairseq.trainer | begin training epoch 152
2022-03-14 17:24:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:24:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:26:17 | INFO | train_inner | epoch 152:     75 / 103 loss=4.096, ppl=17.1, wps=39833.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=15600, lr=0.000253185, gnorm=0.999, loss_scale=16, train_wall=154, gb_free=20.8, wall=25423
2022-03-14 17:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:27:04 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 9.106 | ppl 551.11 | wps 66285.8 | wpb 2040.3 | bsz 4 | num_updates 15628 | best_loss 7.537
2022-03-14 17:27:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 15628 updates
2022-03-14 17:27:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:27:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:27:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 152 @ 15628 updates, score 9.106) (writing took 0.980022138915956 seconds)
2022-03-14 17:27:05 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-14 17:27:05 | INFO | train | epoch 152 | loss 4.098 | ppl 17.13 | wps 39849.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15628 | lr 0.000252958 | gnorm 0.999 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25471
KL Stats: Epoch 152 Divergences: Uniform: 5.407249790344575 Unigram: 4.826241331321433
2022-03-14 17:27:05 | INFO | fairseq.trainer | begin training epoch 153
2022-03-14 17:27:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:29:00 | INFO | train_inner | epoch 153:     72 / 103 loss=4.094, ppl=17.07, wps=40195.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15700, lr=0.000252377, gnorm=0.988, loss_scale=16, train_wall=153, gb_free=20.8, wall=25586
2022-03-14 17:29:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:29:52 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 9.121 | ppl 556.93 | wps 66319.9 | wpb 2040.3 | bsz 4 | num_updates 15731 | best_loss 7.537
2022-03-14 17:29:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 15731 updates
2022-03-14 17:29:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:29:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:29:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 153 @ 15731 updates, score 9.121) (writing took 0.915453271009028 seconds)
2022-03-14 17:29:53 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-14 17:29:53 | INFO | train | epoch 153 | loss 4.092 | ppl 17.06 | wps 40247.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15731 | lr 0.000252128 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25639
KL Stats: Epoch 153 Divergences: Uniform: 5.412649339154697 Unigram: 4.831877344221962
2022-03-14 17:29:53 | INFO | fairseq.trainer | begin training epoch 154
2022-03-14 17:29:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:31:42 | INFO | train_inner | epoch 154:     69 / 103 loss=4.087, ppl=17, wps=40222.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15800, lr=0.000251577, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=25748
2022-03-14 17:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:32:39 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 9.122 | ppl 557.19 | wps 66471.9 | wpb 2040.3 | bsz 4 | num_updates 15834 | best_loss 7.537
2022-03-14 17:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 15834 updates
2022-03-14 17:32:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:32:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 154 @ 15834 updates, score 9.122) (writing took 0.904352905228734 seconds)
2022-03-14 17:32:40 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-14 17:32:40 | INFO | train | epoch 154 | loss 4.089 | ppl 17.02 | wps 40251.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15834 | lr 0.000251307 | gnorm 1 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25806
KL Stats: Epoch 154 Divergences: Uniform: 5.413950169441585 Unigram: 4.835293240843559
2022-03-14 17:32:40 | INFO | fairseq.trainer | begin training epoch 155
2022-03-14 17:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:34:24 | INFO | train_inner | epoch 155:     66 / 103 loss=4.083, ppl=16.95, wps=40197.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15900, lr=0.000250785, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=25910
2022-03-14 17:35:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:35:26 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 9.137 | ppl 562.92 | wps 65990.3 | wpb 2040.3 | bsz 4 | num_updates 15937 | best_loss 7.537
2022-03-14 17:35:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 15937 updates
2022-03-14 17:35:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:35:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:35:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 155 @ 15937 updates, score 9.137) (writing took 0.8519170992076397 seconds)
2022-03-14 17:35:27 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-14 17:35:27 | INFO | train | epoch 155 | loss 4.083 | ppl 16.94 | wps 40246.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15937 | lr 0.000250494 | gnorm 0.999 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25973
KL Stats: Epoch 155 Divergences: Uniform: 5.418596900723883 Unigram: 4.843656339712028
2022-03-14 17:35:27 | INFO | fairseq.trainer | begin training epoch 156
2022-03-14 17:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:37:07 | INFO | train_inner | epoch 156:     63 / 103 loss=4.08, ppl=16.91, wps=40218.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16000, lr=0.00025, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=26073
2022-03-14 17:38:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:38:13 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 9.156 | ppl 570.65 | wps 66153.6 | wpb 2040.3 | bsz 4 | num_updates 16040 | best_loss 7.537
2022-03-14 17:38:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 16040 updates
2022-03-14 17:38:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:38:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:38:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 156 @ 16040 updates, score 9.156) (writing took 0.9046104531735182 seconds)
2022-03-14 17:38:14 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-14 17:38:14 | INFO | train | epoch 156 | loss 4.077 | ppl 16.88 | wps 40239.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16040 | lr 0.000249688 | gnorm 1.003 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 26140
KL Stats: Epoch 156 Divergences: Uniform: 5.423793057844716 Unigram: 4.84918491515047
2022-03-14 17:38:14 | INFO | fairseq.trainer | begin training epoch 157
2022-03-14 17:38:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:38:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:39:51 | INFO | train_inner | epoch 157:     61 / 103 loss=4.074, ppl=16.84, wps=39826.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=16100, lr=0.000249222, gnorm=0.987, loss_scale=16, train_wall=155, gb_free=20.8, wall=26237
2022-03-14 17:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:41:00 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 9.133 | ppl 561.54 | wps 65771.4 | wpb 2040.3 | bsz 4 | num_updates 16142 | best_loss 7.537
2022-03-14 17:41:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 16142 updates
2022-03-14 17:41:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:41:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:41:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 157 @ 16142 updates, score 9.133) (writing took 0.9021899672225118 seconds)
2022-03-14 17:41:01 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-14 17:41:01 | INFO | train | epoch 157 | loss 4.072 | ppl 16.82 | wps 39843.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16142 | lr 0.000248898 | gnorm 0.99 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26307
KL Stats: Epoch 157 Divergences: Uniform: 5.42545597010476 Unigram: 4.852289464150163
2022-03-14 17:41:01 | INFO | fairseq.trainer | begin training epoch 158
2022-03-14 17:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:42:33 | INFO | train_inner | epoch 158:     58 / 103 loss=4.07, ppl=16.8, wps=40208.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16200, lr=0.000248452, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=26399
2022-03-14 17:43:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:43:47 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 9.129 | ppl 560.03 | wps 66259.8 | wpb 2040.3 | bsz 4 | num_updates 16245 | best_loss 7.537
2022-03-14 17:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 16245 updates
2022-03-14 17:43:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:43:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:43:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 158 @ 16245 updates, score 9.129) (writing took 0.9350300887599587 seconds)
2022-03-14 17:43:48 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-14 17:43:48 | INFO | train | epoch 158 | loss 4.069 | ppl 16.79 | wps 40229.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16245 | lr 0.000248108 | gnorm 1 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26474
KL Stats: Epoch 158 Divergences: Uniform: 5.428870319171441 Unigram: 4.856051280438002
2022-03-14 17:43:48 | INFO | fairseq.trainer | begin training epoch 159
2022-03-14 17:43:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:45:16 | INFO | train_inner | epoch 159:     55 / 103 loss=4.066, ppl=16.74, wps=40191.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16300, lr=0.000247689, gnorm=1.008, loss_scale=16, train_wall=153, gb_free=20.8, wall=26562
2022-03-14 17:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:46:35 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 9.133 | ppl 561.6 | wps 66457.7 | wpb 2040.3 | bsz 4 | num_updates 16348 | best_loss 7.537
2022-03-14 17:46:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 16348 updates
2022-03-14 17:46:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:46:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:46:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 159 @ 16348 updates, score 9.133) (writing took 0.9339909013360739 seconds)
2022-03-14 17:46:36 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-14 17:46:36 | INFO | train | epoch 159 | loss 4.063 | ppl 16.71 | wps 40238.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16348 | lr 0.000247325 | gnorm 1 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26642
KL Stats: Epoch 159 Divergences: Uniform: 5.430839784516268 Unigram: 4.860095649416195
2022-03-14 17:46:36 | INFO | fairseq.trainer | begin training epoch 160
2022-03-14 17:46:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:47:58 | INFO | train_inner | epoch 160:     52 / 103 loss=4.061, ppl=16.69, wps=40205.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16400, lr=0.000246932, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=26724
2022-03-14 17:49:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:49:22 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 9.178 | ppl 579.23 | wps 66112.2 | wpb 2040.3 | bsz 4 | num_updates 16451 | best_loss 7.537
2022-03-14 17:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 16451 updates
2022-03-14 17:49:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 160 @ 16451 updates, score 9.178) (writing took 0.9274027245119214 seconds)
2022-03-14 17:49:23 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-14 17:49:23 | INFO | train | epoch 160 | loss 4.058 | ppl 16.66 | wps 40232.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16451 | lr 0.000246549 | gnorm 1.005 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26809
KL Stats: Epoch 160 Divergences: Uniform: 5.436596791715296 Unigram: 4.868565514842655
2022-03-14 17:49:23 | INFO | fairseq.trainer | begin training epoch 161
2022-03-14 17:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:50:40 | INFO | train_inner | epoch 161:     49 / 103 loss=4.054, ppl=16.61, wps=40212.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16500, lr=0.000246183, gnorm=0.999, loss_scale=16, train_wall=153, gb_free=20.8, wall=26886
2022-03-14 17:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:52:09 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 9.158 | ppl 571.29 | wps 65988.9 | wpb 2040.3 | bsz 4 | num_updates 16554 | best_loss 7.537
2022-03-14 17:52:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 16554 updates
2022-03-14 17:52:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:52:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:52:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 161 @ 16554 updates, score 9.158) (writing took 0.9062010450288653 seconds)
2022-03-14 17:52:10 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-14 17:52:10 | INFO | train | epoch 161 | loss 4.054 | ppl 16.61 | wps 40261.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16554 | lr 0.000245781 | gnorm 0.999 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 26976
KL Stats: Epoch 161 Divergences: Uniform: 5.440091522864972 Unigram: 4.870937816708261
2022-03-14 17:52:10 | INFO | fairseq.trainer | begin training epoch 162
2022-03-14 17:52:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:52:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:53:24 | INFO | train_inner | epoch 162:     47 / 103 loss=4.053, ppl=16.6, wps=39837.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=16600, lr=0.00024544, gnorm=1.002, loss_scale=16, train_wall=154, gb_free=20.8, wall=27050
2022-03-14 17:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:54:56 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 9.16 | ppl 572.24 | wps 66594.6 | wpb 2040.3 | bsz 4 | num_updates 16656 | best_loss 7.537
2022-03-14 17:54:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 16656 updates
2022-03-14 17:54:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:54:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:54:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 162 @ 16656 updates, score 9.16) (writing took 0.9297862173989415 seconds)
2022-03-14 17:54:57 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-14 17:54:57 | INFO | train | epoch 162 | loss 4.048 | ppl 16.54 | wps 39858.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16656 | lr 0.000245027 | gnorm 0.99 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27143
KL Stats: Epoch 162 Divergences: Uniform: 5.444207787101608 Unigram: 4.879196251591763
2022-03-14 17:54:57 | INFO | fairseq.trainer | begin training epoch 163
2022-03-14 17:54:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:56:07 | INFO | train_inner | epoch 163:     44 / 103 loss=4.045, ppl=16.51, wps=40203.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16700, lr=0.000244704, gnorm=0.997, loss_scale=16, train_wall=153, gb_free=20.8, wall=27213
2022-03-14 17:57:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:57:43 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 9.176 | ppl 578.41 | wps 66175 | wpb 2040.3 | bsz 4 | num_updates 16759 | best_loss 7.537
2022-03-14 17:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 16759 updates
2022-03-14 17:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:57:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 17:57:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 163 @ 16759 updates, score 9.176) (writing took 0.9093263261020184 seconds)
2022-03-14 17:57:44 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-14 17:57:44 | INFO | train | epoch 163 | loss 4.045 | ppl 16.51 | wps 40228.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16759 | lr 0.000244273 | gnorm 1.004 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27310
KL Stats: Epoch 163 Divergences: Uniform: 5.446078151760403 Unigram: 4.881979456610783
2022-03-14 17:57:44 | INFO | fairseq.trainer | begin training epoch 164
2022-03-14 17:57:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:58:49 | INFO | train_inner | epoch 164:     41 / 103 loss=4.045, ppl=16.51, wps=40196.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16800, lr=0.000243975, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=27375
2022-03-14 18:00:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:00:31 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 9.173 | ppl 577.04 | wps 65935.7 | wpb 2040.3 | bsz 4 | num_updates 16862 | best_loss 7.537
2022-03-14 18:00:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 16862 updates
2022-03-14 18:00:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:00:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:00:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 164 @ 16862 updates, score 9.173) (writing took 0.9078936781734228 seconds)
2022-03-14 18:00:31 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-14 18:00:31 | INFO | train | epoch 164 | loss 4.041 | ppl 16.46 | wps 40242.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16862 | lr 0.000243526 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27477
KL Stats: Epoch 164 Divergences: Uniform: 5.448071191415229 Unigram: 4.884626772194147
2022-03-14 18:00:31 | INFO | fairseq.trainer | begin training epoch 165
2022-03-14 18:00:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:01:32 | INFO | train_inner | epoch 165:     38 / 103 loss=4.038, ppl=16.43, wps=40215.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16900, lr=0.000243252, gnorm=1.013, loss_scale=16, train_wall=153, gb_free=20.8, wall=27538
2022-03-14 18:03:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:03:18 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 9.191 | ppl 584.31 | wps 66180.7 | wpb 2040.3 | bsz 4 | num_updates 16965 | best_loss 7.537
2022-03-14 18:03:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 16965 updates
2022-03-14 18:03:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:03:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:03:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 165 @ 16965 updates, score 9.191) (writing took 0.8567268997430801 seconds)
2022-03-14 18:03:18 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-14 18:03:18 | INFO | train | epoch 165 | loss 4.035 | ppl 16.4 | wps 40266.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16965 | lr 0.000242786 | gnorm 1.005 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27645
KL Stats: Epoch 165 Divergences: Uniform: 5.4539619048758 Unigram: 4.891285524441942
2022-03-14 18:03:18 | INFO | fairseq.trainer | begin training epoch 166
2022-03-14 18:03:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:04:14 | INFO | train_inner | epoch 166:     35 / 103 loss=4.035, ppl=16.4, wps=40237.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17000, lr=0.000242536, gnorm=1.002, loss_scale=16, train_wall=153, gb_free=20.8, wall=27700
2022-03-14 18:06:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:06:05 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 9.184 | ppl 581.48 | wps 66006.1 | wpb 2040.3 | bsz 4 | num_updates 17068 | best_loss 7.537
2022-03-14 18:06:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 17068 updates
2022-03-14 18:06:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:06:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:06:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 166 @ 17068 updates, score 9.184) (writing took 0.9068512478843331 seconds)
2022-03-14 18:06:06 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-14 18:06:06 | INFO | train | epoch 166 | loss 4.03 | ppl 16.33 | wps 40243.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17068 | lr 0.000242052 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27812
KL Stats: Epoch 166 Divergences: Uniform: 5.45590285539364 Unigram: 4.895332970221107
2022-03-14 18:06:06 | INFO | fairseq.trainer | begin training epoch 167
2022-03-14 18:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:06:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:06:58 | INFO | train_inner | epoch 167:     33 / 103 loss=4.027, ppl=16.31, wps=39829.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=17100, lr=0.000241825, gnorm=0.988, loss_scale=16, train_wall=155, gb_free=20.8, wall=27864
2022-03-14 18:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:08:52 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 9.18 | ppl 580.04 | wps 66381.3 | wpb 2040.3 | bsz 4 | num_updates 17170 | best_loss 7.537
2022-03-14 18:08:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 17170 updates
2022-03-14 18:08:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:08:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:08:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 167 @ 17170 updates, score 9.18) (writing took 0.8866342213004827 seconds)
2022-03-14 18:08:53 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-14 18:08:53 | INFO | train | epoch 167 | loss 4.027 | ppl 16.31 | wps 39865.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17170 | lr 0.000241332 | gnorm 1.002 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27979
KL Stats: Epoch 167 Divergences: Uniform: 5.457057487022004 Unigram: 4.899520414127239
2022-03-14 18:08:53 | INFO | fairseq.trainer | begin training epoch 168
2022-03-14 18:08:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:09:40 | INFO | train_inner | epoch 168:     30 / 103 loss=4.028, ppl=16.31, wps=40215.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17200, lr=0.000241121, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=28026
2022-03-14 18:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:11:39 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 9.21 | ppl 592.2 | wps 66097 | wpb 2040.3 | bsz 4 | num_updates 17273 | best_loss 7.537
2022-03-14 18:11:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 17273 updates
2022-03-14 18:11:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:11:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 168 @ 17273 updates, score 9.21) (writing took 0.8809443609789014 seconds)
2022-03-14 18:11:40 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-14 18:11:40 | INFO | train | epoch 168 | loss 4.023 | ppl 16.25 | wps 40235.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17273 | lr 0.000240611 | gnorm 1.012 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28146
KL Stats: Epoch 168 Divergences: Uniform: 5.462544661701142 Unigram: 4.904712139871814
2022-03-14 18:11:40 | INFO | fairseq.trainer | begin training epoch 169
2022-03-14 18:11:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:12:23 | INFO | train_inner | epoch 169:     27 / 103 loss=4.022, ppl=16.24, wps=40191.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17300, lr=0.000240424, gnorm=1.015, loss_scale=16, train_wall=153, gb_free=20.8, wall=28189
2022-03-14 18:14:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:14:26 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 9.223 | ppl 597.51 | wps 66314.3 | wpb 2040.3 | bsz 4 | num_updates 17376 | best_loss 7.537
2022-03-14 18:14:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 17376 updates
2022-03-14 18:14:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:14:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:14:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 169 @ 17376 updates, score 9.223) (writing took 0.8569520339369774 seconds)
2022-03-14 18:14:27 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-14 18:14:27 | INFO | train | epoch 169 | loss 4.017 | ppl 16.19 | wps 40238.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17376 | lr 0.000239897 | gnorm 1.005 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28313
KL Stats: Epoch 169 Divergences: Uniform: 5.463462054654928 Unigram: 4.91007520269497
2022-03-14 18:14:27 | INFO | fairseq.trainer | begin training epoch 170
2022-03-14 18:14:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:15:05 | INFO | train_inner | epoch 170:     24 / 103 loss=4.018, ppl=16.2, wps=40218.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17400, lr=0.000239732, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=28351
2022-03-14 18:17:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:17:13 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 9.231 | ppl 600.78 | wps 66433.3 | wpb 2040.3 | bsz 4 | num_updates 17479 | best_loss 7.537
2022-03-14 18:17:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 17479 updates
2022-03-14 18:17:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:17:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:17:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 170 @ 17479 updates, score 9.231) (writing took 0.8678464060649276 seconds)
2022-03-14 18:17:14 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-14 18:17:14 | INFO | train | epoch 170 | loss 4.013 | ppl 16.14 | wps 40264.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17479 | lr 0.000239189 | gnorm 1.014 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28480
KL Stats: Epoch 170 Divergences: Uniform: 5.468651331501351 Unigram: 4.9143333675669325
2022-03-14 18:17:14 | INFO | fairseq.trainer | begin training epoch 171
2022-03-14 18:17:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:17:48 | INFO | train_inner | epoch 171:     21 / 103 loss=4.015, ppl=16.17, wps=40230.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17500, lr=0.000239046, gnorm=1.018, loss_scale=16, train_wall=153, gb_free=20.8, wall=28514
2022-03-14 18:19:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:20:01 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 9.232 | ppl 601.3 | wps 66477.5 | wpb 2040.3 | bsz 4 | num_updates 17582 | best_loss 7.537
2022-03-14 18:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 17582 updates
2022-03-14 18:20:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:20:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:20:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 171 @ 17582 updates, score 9.232) (writing took 0.849150407128036 seconds)
2022-03-14 18:20:01 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-14 18:20:01 | INFO | train | epoch 171 | loss 4.01 | ppl 16.11 | wps 40244.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17582 | lr 0.000238488 | gnorm 1.011 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28647
KL Stats: Epoch 171 Divergences: Uniform: 5.471113883015337 Unigram: 4.917849877425176
2022-03-14 18:20:01 | INFO | fairseq.trainer | begin training epoch 172
2022-03-14 18:20:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:20:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:20:32 | INFO | train_inner | epoch 172:     19 / 103 loss=4.008, ppl=16.09, wps=39829.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=17600, lr=0.000238366, gnorm=1.009, loss_scale=16, train_wall=155, gb_free=20.8, wall=28678
2022-03-14 18:22:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:22:48 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 9.235 | ppl 602.49 | wps 65768.1 | wpb 2040.3 | bsz 4 | num_updates 17684 | best_loss 7.537
2022-03-14 18:22:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 17684 updates
2022-03-14 18:22:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:22:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:22:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 172 @ 17684 updates, score 9.235) (writing took 0.8832751689478755 seconds)
2022-03-14 18:22:48 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-14 18:22:48 | INFO | train | epoch 172 | loss 4.005 | ppl 16.05 | wps 39857.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17684 | lr 0.000237799 | gnorm 1.004 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28815
KL Stats: Epoch 172 Divergences: Uniform: 5.473539795968497 Unigram: 4.922576953962297
2022-03-14 18:22:49 | INFO | fairseq.trainer | begin training epoch 173
2022-03-14 18:22:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:23:14 | INFO | train_inner | epoch 173:     16 / 103 loss=4.007, ppl=16.08, wps=40210.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17700, lr=0.000237691, gnorm=1.007, loss_scale=16, train_wall=153, gb_free=20.8, wall=28840
2022-03-14 18:25:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:25:35 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 9.23 | ppl 600.59 | wps 66441.4 | wpb 2040.3 | bsz 4 | num_updates 17787 | best_loss 7.537
2022-03-14 18:25:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 17787 updates
2022-03-14 18:25:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:25:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:25:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 173 @ 17787 updates, score 9.23) (writing took 0.8534553032368422 seconds)
2022-03-14 18:25:36 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-14 18:25:36 | INFO | train | epoch 173 | loss 4.001 | ppl 16.01 | wps 40246.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17787 | lr 0.000237109 | gnorm 1.009 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28982
KL Stats: Epoch 173 Divergences: Uniform: 5.475663266281908 Unigram: 4.92825168239233
2022-03-14 18:25:36 | INFO | fairseq.trainer | begin training epoch 174
2022-03-14 18:25:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:25:56 | INFO | train_inner | epoch 174:     13 / 103 loss=4.001, ppl=16.01, wps=40214.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17800, lr=0.000237023, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=29002
2022-03-14 18:28:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:28:22 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 9.235 | ppl 602.76 | wps 66282.8 | wpb 2040.3 | bsz 4 | num_updates 17890 | best_loss 7.537
2022-03-14 18:28:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 17890 updates
2022-03-14 18:28:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:28:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 174 @ 17890 updates, score 9.235) (writing took 0.9724518097937107 seconds)
2022-03-14 18:28:23 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-14 18:28:23 | INFO | train | epoch 174 | loss 3.998 | ppl 15.98 | wps 40223 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17890 | lr 0.000236426 | gnorm 1.006 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29149
KL Stats: Epoch 174 Divergences: Uniform: 5.4777497061827285 Unigram: 4.9318477908404885
2022-03-14 18:28:23 | INFO | fairseq.trainer | begin training epoch 175
2022-03-14 18:28:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:28:39 | INFO | train_inner | epoch 175:     10 / 103 loss=3.999, ppl=15.99, wps=40188, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17900, lr=0.00023636, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=29165
2022-03-14 18:31:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:31:09 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 9.244 | ppl 606.55 | wps 66377.8 | wpb 2040.3 | bsz 4 | num_updates 17993 | best_loss 7.537
2022-03-14 18:31:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 17993 updates
2022-03-14 18:31:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:31:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:31:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 175 @ 17993 updates, score 9.244) (writing took 0.9051956487819552 seconds)
2022-03-14 18:31:10 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-14 18:31:10 | INFO | train | epoch 175 | loss 3.993 | ppl 15.92 | wps 40250 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17993 | lr 0.000235748 | gnorm 0.998 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29316
KL Stats: Epoch 175 Divergences: Uniform: 5.48155658584432 Unigram: 4.934610504453434
2022-03-14 18:31:10 | INFO | fairseq.trainer | begin training epoch 176
2022-03-14 18:31:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:31:21 | INFO | train_inner | epoch 176:      7 / 103 loss=3.995, ppl=15.95, wps=40221.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18000, lr=0.000235702, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=29327
2022-03-14 18:33:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:33:56 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 9.258 | ppl 612.39 | wps 66182.9 | wpb 2040.3 | bsz 4 | num_updates 18096 | best_loss 7.537
2022-03-14 18:33:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 18096 updates
2022-03-14 18:33:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:33:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 176 @ 18096 updates, score 9.258) (writing took 0.8620871249586344 seconds)
2022-03-14 18:33:57 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-14 18:33:57 | INFO | train | epoch 176 | loss 3.989 | ppl 15.88 | wps 40247.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18096 | lr 0.000235076 | gnorm 1.013 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29483
KL Stats: Epoch 176 Divergences: Uniform: 5.486187351447074 Unigram: 4.9421546941647065
2022-03-14 18:33:57 | INFO | fairseq.trainer | begin training epoch 177
2022-03-14 18:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:34:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:34:05 | INFO | train_inner | epoch 177:      5 / 103 loss=3.991, ppl=15.9, wps=39823.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18100, lr=0.00023505, gnorm=1.013, loss_scale=16, train_wall=155, gb_free=20.8, wall=29491
2022-03-14 18:36:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:36:43 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 9.258 | ppl 612.27 | wps 66367.8 | wpb 2040.3 | bsz 4 | num_updates 18198 | best_loss 7.537
2022-03-14 18:36:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 18198 updates
2022-03-14 18:36:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:36:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:36:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 177 @ 18198 updates, score 9.258) (writing took 0.8878618534654379 seconds)
2022-03-14 18:36:44 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-14 18:36:44 | INFO | train | epoch 177 | loss 3.984 | ppl 15.82 | wps 39854.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 18198 | lr 0.000234416 | gnorm 1.012 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29650
KL Stats: Epoch 177 Divergences: Uniform: 5.488003525728686 Unigram: 4.944019707654846
2022-03-14 18:36:44 | INFO | fairseq.trainer | begin training epoch 178
2022-03-14 18:36:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:36:48 | INFO | train_inner | epoch 178:      2 / 103 loss=3.984, ppl=15.83, wps=40214.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18200, lr=0.000234404, gnorm=1.012, loss_scale=16, train_wall=153, gb_free=20.8, wall=29654
2022-03-14 18:39:26 | INFO | train_inner | epoch 178:    102 / 103 loss=3.985, ppl=15.83, wps=41359.1, ups=0.63, wpb=65530.9, bsz=128, num_updates=18300, lr=0.000233762, gnorm=1.015, loss_scale=16, train_wall=154, gb_free=20.8, wall=29812
2022-03-14 18:39:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:39:31 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 9.262 | ppl 614.05 | wps 66241.9 | wpb 2040.3 | bsz 4 | num_updates 18301 | best_loss 7.537
2022-03-14 18:39:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 18301 updates
2022-03-14 18:39:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:39:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:39:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 178 @ 18301 updates, score 9.262) (writing took 0.8579642893746495 seconds)
2022-03-14 18:39:31 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-14 18:39:31 | INFO | train | epoch 178 | loss 3.983 | ppl 15.81 | wps 40250 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18301 | lr 0.000233756 | gnorm 1.018 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29817
KL Stats: Epoch 178 Divergences: Uniform: 5.489725293478312 Unigram: 4.946233151721008
2022-03-14 18:39:31 | INFO | fairseq.trainer | begin training epoch 179
2022-03-14 18:39:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:42:08 | INFO | train_inner | epoch 179:     99 / 103 loss=3.974, ppl=15.71, wps=40226.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18400, lr=0.000233126, gnorm=1.019, loss_scale=16, train_wall=153, gb_free=20.8, wall=29974
2022-03-14 18:42:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:42:18 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 9.245 | ppl 606.89 | wps 65991.5 | wpb 2040.3 | bsz 4 | num_updates 18404 | best_loss 7.537
2022-03-14 18:42:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 18404 updates
2022-03-14 18:42:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:42:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:42:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 179 @ 18404 updates, score 9.245) (writing took 0.8468500012531877 seconds)
2022-03-14 18:42:19 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-14 18:42:19 | INFO | train | epoch 179 | loss 3.976 | ppl 15.73 | wps 40260.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18404 | lr 0.000233101 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29985
KL Stats: Epoch 179 Divergences: Uniform: 5.492481539362536 Unigram: 4.952907800060635
2022-03-14 18:42:19 | INFO | fairseq.trainer | begin training epoch 180
2022-03-14 18:42:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:44:51 | INFO | train_inner | epoch 180:     96 / 103 loss=3.971, ppl=15.68, wps=40229.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18500, lr=0.000232495, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=30137
2022-03-14 18:45:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:45:05 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 9.273 | ppl 618.5 | wps 66385 | wpb 2040.3 | bsz 4 | num_updates 18507 | best_loss 7.537
2022-03-14 18:45:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 18507 updates
2022-03-14 18:45:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:45:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:45:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 180 @ 18507 updates, score 9.273) (writing took 0.8497480927035213 seconds)
2022-03-14 18:45:06 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-14 18:45:06 | INFO | train | epoch 180 | loss 3.973 | ppl 15.7 | wps 40268 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18507 | lr 0.000232451 | gnorm 1.009 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30152
KL Stats: Epoch 180 Divergences: Uniform: 5.497500819535587 Unigram: 4.955981487542139
2022-03-14 18:45:06 | INFO | fairseq.trainer | begin training epoch 181
2022-03-14 18:45:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:47:33 | INFO | train_inner | epoch 181:     93 / 103 loss=3.968, ppl=15.64, wps=40256.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18600, lr=0.000231869, gnorm=1.015, loss_scale=16, train_wall=153, gb_free=20.8, wall=30299
2022-03-14 18:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:47:52 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 9.268 | ppl 616.62 | wps 66412.1 | wpb 2040.3 | bsz 4 | num_updates 18610 | best_loss 7.537
2022-03-14 18:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 18610 updates
2022-03-14 18:47:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 181 @ 18610 updates, score 9.268) (writing took 0.836912670172751 seconds)
2022-03-14 18:47:53 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-14 18:47:53 | INFO | train | epoch 181 | loss 3.97 | ppl 15.67 | wps 40288.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18610 | lr 0.000231807 | gnorm 1.021 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 30319
KL Stats: Epoch 181 Divergences: Uniform: 5.494886446227129 Unigram: 4.957764958335705
2022-03-14 18:47:53 | INFO | fairseq.trainer | begin training epoch 182
2022-03-14 18:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:48:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:50:17 | INFO | train_inner | epoch 182:     91 / 103 loss=3.964, ppl=15.6, wps=39843.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18700, lr=0.000231249, gnorm=1.029, loss_scale=16, train_wall=155, gb_free=20.8, wall=30463
2022-03-14 18:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:50:39 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 9.277 | ppl 620.54 | wps 65951.9 | wpb 2040.3 | bsz 4 | num_updates 18712 | best_loss 7.537
2022-03-14 18:50:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 18712 updates
2022-03-14 18:50:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:50:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:50:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 182 @ 18712 updates, score 9.277) (writing took 0.8453847086057067 seconds)
2022-03-14 18:50:40 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-14 18:50:40 | INFO | train | epoch 182 | loss 3.965 | ppl 15.62 | wps 39868.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 18712 | lr 0.000231174 | gnorm 1.025 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30486
KL Stats: Epoch 182 Divergences: Uniform: 5.501271998527165 Unigram: 4.96464437531741
2022-03-14 18:50:40 | INFO | fairseq.trainer | begin training epoch 183
2022-03-14 18:50:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:52:59 | INFO | train_inner | epoch 183:     88 / 103 loss=3.961, ppl=15.58, wps=40237.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18800, lr=0.000230633, gnorm=1.011, loss_scale=16, train_wall=153, gb_free=20.8, wall=30625
2022-03-14 18:53:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:53:26 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 9.282 | ppl 622.6 | wps 66419.2 | wpb 2040.3 | bsz 4 | num_updates 18815 | best_loss 7.537
2022-03-14 18:53:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 18815 updates
2022-03-14 18:53:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:53:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 183 @ 18815 updates, score 9.282) (writing took 0.8453526562079787 seconds)
2022-03-14 18:53:27 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-14 18:53:27 | INFO | train | epoch 183 | loss 3.962 | ppl 15.58 | wps 40268.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18815 | lr 0.000230541 | gnorm 1.01 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30653
KL Stats: Epoch 183 Divergences: Uniform: 5.503094968413465 Unigram: 4.967909674453314
2022-03-14 18:53:27 | INFO | fairseq.trainer | begin training epoch 184
2022-03-14 18:53:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:55:41 | INFO | train_inner | epoch 184:     85 / 103 loss=3.957, ppl=15.53, wps=40225.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18900, lr=0.000230022, gnorm=1.028, loss_scale=16, train_wall=153, gb_free=20.8, wall=30787
2022-03-14 18:56:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:56:13 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 9.286 | ppl 624.17 | wps 66556.7 | wpb 2040.3 | bsz 4 | num_updates 18918 | best_loss 7.537
2022-03-14 18:56:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 18918 updates
2022-03-14 18:56:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:56:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:56:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 184 @ 18918 updates, score 9.286) (writing took 0.8892947221174836 seconds)
2022-03-14 18:56:14 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-14 18:56:14 | INFO | train | epoch 184 | loss 3.958 | ppl 15.54 | wps 40246.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18918 | lr 0.000229912 | gnorm 1.031 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30820
KL Stats: Epoch 184 Divergences: Uniform: 5.503240216764819 Unigram: 4.971056486202014
2022-03-14 18:56:14 | INFO | fairseq.trainer | begin training epoch 185
2022-03-14 18:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:58:24 | INFO | train_inner | epoch 185:     82 / 103 loss=3.952, ppl=15.47, wps=40215.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19000, lr=0.000229416, gnorm=1.018, loss_scale=16, train_wall=153, gb_free=20.8, wall=30950
2022-03-14 18:58:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:59:00 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 9.277 | ppl 620.21 | wps 66042 | wpb 2040.3 | bsz 4 | num_updates 19021 | best_loss 7.537
2022-03-14 18:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 19021 updates
2022-03-14 18:59:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 18:59:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 185 @ 19021 updates, score 9.277) (writing took 0.9538393309339881 seconds)
2022-03-14 18:59:01 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-14 18:59:01 | INFO | train | epoch 185 | loss 3.953 | ppl 15.48 | wps 40234.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19021 | lr 0.000229289 | gnorm 1.015 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30987
KL Stats: Epoch 185 Divergences: Uniform: 5.506557859537925 Unigram: 4.975234803876354
2022-03-14 18:59:01 | INFO | fairseq.trainer | begin training epoch 186
2022-03-14 18:59:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:01:06 | INFO | train_inner | epoch 186:     79 / 103 loss=3.95, ppl=15.46, wps=40201.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19100, lr=0.000228814, gnorm=1.016, loss_scale=16, train_wall=153, gb_free=20.8, wall=31112
2022-03-14 19:01:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:01:47 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 9.292 | ppl 626.77 | wps 66199 | wpb 2040.3 | bsz 4 | num_updates 19124 | best_loss 7.537
2022-03-14 19:01:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 19124 updates
2022-03-14 19:01:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:01:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:01:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 186 @ 19124 updates, score 9.292) (writing took 1.0231481557711959 seconds)
2022-03-14 19:01:48 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-14 19:01:48 | INFO | train | epoch 186 | loss 3.95 | ppl 15.45 | wps 40213.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19124 | lr 0.000228671 | gnorm 1.012 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31154
KL Stats: Epoch 186 Divergences: Uniform: 5.508633586859695 Unigram: 4.978345539027077
2022-03-14 19:01:48 | INFO | fairseq.trainer | begin training epoch 187
2022-03-14 19:01:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:02:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:03:50 | INFO | train_inner | epoch 187:     77 / 103 loss=3.946, ppl=15.41, wps=39779.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=19200, lr=0.000228218, gnorm=1.018, loss_scale=16, train_wall=155, gb_free=20.8, wall=31276
2022-03-14 19:04:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:04:35 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 9.296 | ppl 628.81 | wps 66034.2 | wpb 2040.3 | bsz 4 | num_updates 19226 | best_loss 7.537
2022-03-14 19:04:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 19226 updates
2022-03-14 19:04:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:04:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:04:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 187 @ 19226 updates, score 9.296) (writing took 0.9437335636466742 seconds)
2022-03-14 19:04:36 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-14 19:04:36 | INFO | train | epoch 187 | loss 3.947 | ppl 15.42 | wps 39826.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19226 | lr 0.000228063 | gnorm 1.026 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31322
KL Stats: Epoch 187 Divergences: Uniform: 5.5123783098945465 Unigram: 4.982405195976277
2022-03-14 19:04:36 | INFO | fairseq.trainer | begin training epoch 188
2022-03-14 19:04:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:06:33 | INFO | train_inner | epoch 188:     74 / 103 loss=3.943, ppl=15.39, wps=40196.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19300, lr=0.000227626, gnorm=1.022, loss_scale=16, train_wall=153, gb_free=20.8, wall=31439
2022-03-14 19:07:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:07:22 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 9.299 | ppl 629.79 | wps 66442.2 | wpb 2040.3 | bsz 4 | num_updates 19329 | best_loss 7.537
2022-03-14 19:07:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 19329 updates
2022-03-14 19:07:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:07:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 188 @ 19329 updates, score 9.299) (writing took 0.9613297106698155 seconds)
2022-03-14 19:07:23 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-14 19:07:23 | INFO | train | epoch 188 | loss 3.942 | ppl 15.37 | wps 40222.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19329 | lr 0.000227455 | gnorm 1.02 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31489
KL Stats: Epoch 188 Divergences: Uniform: 5.5152358137539705 Unigram: 4.987369985604997
2022-03-14 19:07:23 | INFO | fairseq.trainer | begin training epoch 189
2022-03-14 19:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:09:15 | INFO | train_inner | epoch 189:     71 / 103 loss=3.939, ppl=15.34, wps=40182.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19400, lr=0.000227038, gnorm=1.021, loss_scale=16, train_wall=153, gb_free=20.8, wall=31601
2022-03-14 19:10:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:10:09 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 9.32 | ppl 638.96 | wps 66254.1 | wpb 2040.3 | bsz 4 | num_updates 19432 | best_loss 7.537
2022-03-14 19:10:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 19432 updates
2022-03-14 19:10:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:10:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:10:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 189 @ 19432 updates, score 9.32) (writing took 0.9706403659656644 seconds)
2022-03-14 19:10:10 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-14 19:10:10 | INFO | train | epoch 189 | loss 3.941 | ppl 15.35 | wps 40217.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19432 | lr 0.000226851 | gnorm 1.022 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31656
KL Stats: Epoch 189 Divergences: Uniform: 5.518279561684297 Unigram: 4.990412197905719
2022-03-14 19:10:10 | INFO | fairseq.trainer | begin training epoch 190
2022-03-14 19:10:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:11:58 | INFO | train_inner | epoch 190:     68 / 103 loss=3.938, ppl=15.33, wps=40178.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19500, lr=0.000226455, gnorm=1.02, loss_scale=16, train_wall=153, gb_free=20.8, wall=31764
2022-03-14 19:12:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:12:56 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 9.313 | ppl 636.01 | wps 66445.4 | wpb 2040.3 | bsz 4 | num_updates 19535 | best_loss 7.537
2022-03-14 19:12:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 19535 updates
2022-03-14 19:12:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:12:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:12:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 190 @ 19535 updates, score 9.313) (writing took 0.9324256265535951 seconds)
2022-03-14 19:12:57 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-14 19:12:57 | INFO | train | epoch 190 | loss 3.936 | ppl 15.3 | wps 40224.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19535 | lr 0.000226252 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31823
KL Stats: Epoch 190 Divergences: Uniform: 5.520637888485739 Unigram: 4.994402429048258
2022-03-14 19:12:57 | INFO | fairseq.trainer | begin training epoch 191
2022-03-14 19:12:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:14:40 | INFO | train_inner | epoch 191:     65 / 103 loss=3.932, ppl=15.26, wps=40207.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19600, lr=0.000225877, gnorm=1.017, loss_scale=16, train_wall=153, gb_free=20.8, wall=31926
2022-03-14 19:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:15:44 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 9.308 | ppl 633.84 | wps 66065.3 | wpb 2040.3 | bsz 4 | num_updates 19638 | best_loss 7.537
2022-03-14 19:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 19638 updates
2022-03-14 19:15:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:15:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:15:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 191 @ 19638 updates, score 9.308) (writing took 0.9475568886846304 seconds)
2022-03-14 19:15:45 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-14 19:15:45 | INFO | train | epoch 191 | loss 3.932 | ppl 15.27 | wps 40235.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19638 | lr 0.000225658 | gnorm 1.016 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31991
KL Stats: Epoch 191 Divergences: Uniform: 5.520618256193261 Unigram: 4.998318619147606
2022-03-14 19:15:45 | INFO | fairseq.trainer | begin training epoch 192
2022-03-14 19:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:15:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:17:24 | INFO | train_inner | epoch 192:     63 / 103 loss=3.927, ppl=15.21, wps=39808.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=19700, lr=0.000225303, gnorm=1.015, loss_scale=16, train_wall=155, gb_free=20.8, wall=32090
2022-03-14 19:18:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:18:31 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 9.323 | ppl 640.41 | wps 66269 | wpb 2040.3 | bsz 4 | num_updates 19740 | best_loss 7.537
2022-03-14 19:18:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 19740 updates
2022-03-14 19:18:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:18:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:18:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 192 @ 19740 updates, score 9.323) (writing took 0.9398326221853495 seconds)
2022-03-14 19:18:32 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-14 19:18:32 | INFO | train | epoch 192 | loss 3.928 | ppl 15.22 | wps 39834.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19740 | lr 0.000225075 | gnorm 1.016 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32158
KL Stats: Epoch 192 Divergences: Uniform: 5.525950911151175 Unigram: 5.003180336680383
2022-03-14 19:18:32 | INFO | fairseq.trainer | begin training epoch 193
2022-03-14 19:18:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:20:07 | INFO | train_inner | epoch 193:     60 / 103 loss=3.928, ppl=15.22, wps=40195.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19800, lr=0.000224733, gnorm=1.021, loss_scale=16, train_wall=153, gb_free=20.8, wall=32253
2022-03-14 19:21:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:21:18 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 9.324 | ppl 641.02 | wps 65788.6 | wpb 2040.3 | bsz 4 | num_updates 19843 | best_loss 7.537
2022-03-14 19:21:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 19843 updates
2022-03-14 19:21:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:21:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:21:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 193 @ 19843 updates, score 9.324) (writing took 1.0878089033067226 seconds)
2022-03-14 19:21:19 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-14 19:21:19 | INFO | train | epoch 193 | loss 3.926 | ppl 15.2 | wps 40188 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19843 | lr 0.00022449 | gnorm 1.022 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32325
KL Stats: Epoch 193 Divergences: Uniform: 5.525424955030625 Unigram: 5.004400349399893
2022-03-14 19:21:19 | INFO | fairseq.trainer | begin training epoch 194
2022-03-14 19:21:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:22:50 | INFO | train_inner | epoch 194:     57 / 103 loss=3.923, ppl=15.17, wps=40141.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=19900, lr=0.000224168, gnorm=1.025, loss_scale=16, train_wall=153, gb_free=20.8, wall=32416
2022-03-14 19:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:24:05 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 9.339 | ppl 647.52 | wps 66263.7 | wpb 2040.3 | bsz 4 | num_updates 19946 | best_loss 7.537
2022-03-14 19:24:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 19946 updates
2022-03-14 19:24:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:24:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 194 @ 19946 updates, score 9.339) (writing took 0.9599386006593704 seconds)
2022-03-14 19:24:06 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-14 19:24:06 | INFO | train | epoch 194 | loss 3.922 | ppl 15.16 | wps 40223 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19946 | lr 0.000223909 | gnorm 1.032 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32492
KL Stats: Epoch 194 Divergences: Uniform: 5.52801992564396 Unigram: 5.009425675706769
2022-03-14 19:24:06 | INFO | fairseq.trainer | begin training epoch 195
2022-03-14 19:24:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:25:32 | INFO | train_inner | epoch 195:     54 / 103 loss=3.919, ppl=15.13, wps=40191.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20000, lr=0.000223607, gnorm=1.031, loss_scale=16, train_wall=153, gb_free=20.8, wall=32578
2022-03-14 19:26:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:26:53 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 9.342 | ppl 648.98 | wps 66549.9 | wpb 2040.3 | bsz 4 | num_updates 20049 | best_loss 7.537
2022-03-14 19:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 20049 updates
2022-03-14 19:26:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:26:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:26:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 195 @ 20049 updates, score 9.342) (writing took 0.9783883560448885 seconds)
2022-03-14 19:26:54 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-14 19:26:54 | INFO | train | epoch 195 | loss 3.918 | ppl 15.11 | wps 40224.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20049 | lr 0.000223333 | gnorm 1.024 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32660
KL Stats: Epoch 195 Divergences: Uniform: 5.530925507035138 Unigram: 5.01305828185676
2022-03-14 19:26:54 | INFO | fairseq.trainer | begin training epoch 196
2022-03-14 19:26:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:28:15 | INFO | train_inner | epoch 196:     51 / 103 loss=3.918, ppl=15.11, wps=40191.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20100, lr=0.00022305, gnorm=1.021, loss_scale=16, train_wall=153, gb_free=20.8, wall=32741
2022-03-14 19:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:29:40 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 9.339 | ppl 647.73 | wps 66403.9 | wpb 2040.3 | bsz 4 | num_updates 20152 | best_loss 7.537
2022-03-14 19:29:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 20152 updates
2022-03-14 19:29:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:29:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:29:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 196 @ 20152 updates, score 9.339) (writing took 0.939512268640101 seconds)
2022-03-14 19:29:41 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-14 19:29:41 | INFO | train | epoch 196 | loss 3.915 | ppl 15.09 | wps 40221.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20152 | lr 0.000222762 | gnorm 1.033 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32827
KL Stats: Epoch 196 Divergences: Uniform: 5.531626126344435 Unigram: 5.01509972530588
2022-03-14 19:29:41 | INFO | fairseq.trainer | begin training epoch 197
2022-03-14 19:29:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:29:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:30:59 | INFO | train_inner | epoch 197:     49 / 103 loss=3.911, ppl=15.04, wps=39806.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=20200, lr=0.000222497, gnorm=1.031, loss_scale=16, train_wall=155, gb_free=20.8, wall=32905
2022-03-14 19:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:32:27 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 9.353 | ppl 653.86 | wps 66137.8 | wpb 2040.3 | bsz 4 | num_updates 20254 | best_loss 7.537
2022-03-14 19:32:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 20254 updates
2022-03-14 19:32:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:32:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:32:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 197 @ 20254 updates, score 9.353) (writing took 0.981312339194119 seconds)
2022-03-14 19:32:28 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-14 19:32:28 | INFO | train | epoch 197 | loss 3.91 | ppl 15.03 | wps 39835.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20254 | lr 0.0002222 | gnorm 1.016 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32994
KL Stats: Epoch 197 Divergences: Uniform: 5.53587902121002 Unigram: 5.020415569640732
2022-03-14 19:32:28 | INFO | fairseq.trainer | begin training epoch 198
2022-03-14 19:32:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:33:41 | INFO | train_inner | epoch 198:     46 / 103 loss=3.91, ppl=15.03, wps=40194.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20300, lr=0.000221948, gnorm=1.016, loss_scale=16, train_wall=153, gb_free=20.8, wall=33067
2022-03-14 19:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:35:14 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 9.333 | ppl 644.81 | wps 66447.4 | wpb 2040.3 | bsz 4 | num_updates 20357 | best_loss 7.537
2022-03-14 19:35:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 20357 updates
2022-03-14 19:35:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:35:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:35:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 198 @ 20357 updates, score 9.333) (writing took 0.9929256029427052 seconds)
2022-03-14 19:35:15 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-14 19:35:15 | INFO | train | epoch 198 | loss 3.91 | ppl 15.03 | wps 40222.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20357 | lr 0.000221637 | gnorm 1.034 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33161
KL Stats: Epoch 198 Divergences: Uniform: 5.534644338110432 Unigram: 5.020010279311376
2022-03-14 19:35:15 | INFO | fairseq.trainer | begin training epoch 199
2022-03-14 19:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:36:24 | INFO | train_inner | epoch 199:     43 / 103 loss=3.911, ppl=15.04, wps=40194.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20400, lr=0.000221404, gnorm=1.041, loss_scale=16, train_wall=153, gb_free=20.8, wall=33230
2022-03-14 19:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:38:02 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 9.359 | ppl 656.65 | wps 65782.4 | wpb 2040.3 | bsz 4 | num_updates 20460 | best_loss 7.537
2022-03-14 19:38:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 20460 updates
2022-03-14 19:38:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:38:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:38:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 199 @ 20460 updates, score 9.359) (writing took 0.9169102478772402 seconds)
2022-03-14 19:38:03 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-14 19:38:03 | INFO | train | epoch 199 | loss 3.904 | ppl 14.97 | wps 40245 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20460 | lr 0.000221079 | gnorm 1.029 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33329
KL Stats: Epoch 199 Divergences: Uniform: 5.538492540736197 Unigram: 5.026864876489334
2022-03-14 19:38:03 | INFO | fairseq.trainer | begin training epoch 200
2022-03-14 19:38:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:39:06 | INFO | train_inner | epoch 200:     40 / 103 loss=3.903, ppl=14.95, wps=40202.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=20500, lr=0.000220863, gnorm=1.021, loss_scale=16, train_wall=153, gb_free=20.8, wall=33392
2022-03-14 19:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:40:49 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 9.378 | ppl 665.31 | wps 66412.9 | wpb 2040.3 | bsz 4 | num_updates 20563 | best_loss 7.537
2022-03-14 19:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 20563 updates
2022-03-14 19:40:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:40:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:40:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 200 @ 20563 updates, score 9.378) (writing took 0.9236928131431341 seconds)
2022-03-14 19:40:50 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-14 19:40:50 | INFO | train | epoch 200 | loss 3.902 | ppl 14.95 | wps 40228.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20563 | lr 0.000220524 | gnorm 1.034 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33496
KL Stats: Epoch 200 Divergences: Uniform: 5.540127303364436 Unigram: 5.031059410906136
2022-03-14 19:40:50 | INFO | fairseq.trainer | begin training epoch 201
2022-03-14 19:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:41:49 | INFO | train_inner | epoch 201:     37 / 103 loss=3.9, ppl=14.93, wps=40195.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=20600, lr=0.000220326, gnorm=1.04, loss_scale=16, train_wall=153, gb_free=20.8, wall=33555
2022-03-14 19:43:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:43:36 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 9.356 | ppl 655.43 | wps 66707.6 | wpb 2040.3 | bsz 4 | num_updates 20666 | best_loss 7.537
2022-03-14 19:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 20666 updates
2022-03-14 19:43:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:43:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:43:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 201 @ 20666 updates, score 9.356) (writing took 1.0198015505447984 seconds)
2022-03-14 19:43:37 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-14 19:43:37 | INFO | train | epoch 201 | loss 3.899 | ppl 14.92 | wps 40221.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20666 | lr 0.000219974 | gnorm 1.041 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33663
KL Stats: Epoch 201 Divergences: Uniform: 5.543069377757469 Unigram: 5.033266173570022
2022-03-14 19:43:37 | INFO | fairseq.trainer | begin training epoch 202
2022-03-14 19:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:43:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:44:33 | INFO | train_inner | epoch 202:     35 / 103 loss=3.9, ppl=14.93, wps=39815.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20700, lr=0.000219793, gnorm=1.036, loss_scale=16, train_wall=155, gb_free=20.8, wall=33719
2022-03-14 19:46:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:46:23 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 9.384 | ppl 668.03 | wps 66428.5 | wpb 2040.3 | bsz 4 | num_updates 20768 | best_loss 7.537
2022-03-14 19:46:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 20768 updates
2022-03-14 19:46:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:46:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:46:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 202 @ 20768 updates, score 9.384) (writing took 0.9301279271021485 seconds)
2022-03-14 19:46:24 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-14 19:46:24 | INFO | train | epoch 202 | loss 3.895 | ppl 14.88 | wps 39843.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20768 | lr 0.000219433 | gnorm 1.018 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33830
KL Stats: Epoch 202 Divergences: Uniform: 5.544649231894221 Unigram: 5.038173120238405
2022-03-14 19:46:24 | INFO | fairseq.trainer | begin training epoch 203
2022-03-14 19:46:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:47:15 | INFO | train_inner | epoch 203:     32 / 103 loss=3.893, ppl=14.85, wps=40204.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=20800, lr=0.000219265, gnorm=1.029, loss_scale=16, train_wall=153, gb_free=20.8, wall=33881
2022-03-14 19:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:49:10 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 9.383 | ppl 667.56 | wps 66420.9 | wpb 2040.3 | bsz 4 | num_updates 20871 | best_loss 7.537
2022-03-14 19:49:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 20871 updates
2022-03-14 19:49:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:49:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:49:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 203 @ 20871 updates, score 9.383) (writing took 0.8881074944511056 seconds)
2022-03-14 19:49:11 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-14 19:49:11 | INFO | train | epoch 203 | loss 3.893 | ppl 14.85 | wps 40261 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20871 | lr 0.000218891 | gnorm 1.035 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33997
KL Stats: Epoch 203 Divergences: Uniform: 5.546997754123992 Unigram: 5.038657152709736
2022-03-14 19:49:11 | INFO | fairseq.trainer | begin training epoch 204
2022-03-14 19:49:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:49:57 | INFO | train_inner | epoch 204:     29 / 103 loss=3.895, ppl=14.88, wps=40219.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20900, lr=0.000218739, gnorm=1.03, loss_scale=16, train_wall=153, gb_free=20.8, wall=34043
2022-03-14 19:51:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:51:58 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 9.364 | ppl 658.98 | wps 66369.2 | wpb 2040.3 | bsz 4 | num_updates 20974 | best_loss 7.537
2022-03-14 19:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 20974 updates
2022-03-14 19:51:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:51:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:51:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 204 @ 20974 updates, score 9.364) (writing took 0.9705802062526345 seconds)
2022-03-14 19:51:59 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-14 19:51:59 | INFO | train | epoch 204 | loss 3.89 | ppl 14.82 | wps 40231.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20974 | lr 0.000218353 | gnorm 1.031 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34165
KL Stats: Epoch 204 Divergences: Uniform: 5.5481820929002215 Unigram: 5.042461516340676
2022-03-14 19:51:59 | INFO | fairseq.trainer | begin training epoch 205
2022-03-14 19:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:52:40 | INFO | train_inner | epoch 205:     26 / 103 loss=3.887, ppl=14.8, wps=40202.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=21000, lr=0.000218218, gnorm=1.037, loss_scale=16, train_wall=153, gb_free=20.8, wall=34206
2022-03-14 19:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:54:45 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 9.385 | ppl 668.79 | wps 66427.6 | wpb 2040.3 | bsz 4 | num_updates 21077 | best_loss 7.537
2022-03-14 19:54:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 21077 updates
2022-03-14 19:54:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:54:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:54:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 205 @ 21077 updates, score 9.385) (writing took 0.9505628114566207 seconds)
2022-03-14 19:54:46 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-14 19:54:46 | INFO | train | epoch 205 | loss 3.887 | ppl 14.79 | wps 40224.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21077 | lr 0.000217819 | gnorm 1.048 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34332
KL Stats: Epoch 205 Divergences: Uniform: 5.549460974998797 Unigram: 5.044552896828632
2022-03-14 19:54:46 | INFO | fairseq.trainer | begin training epoch 206
2022-03-14 19:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:55:22 | INFO | train_inner | epoch 206:     23 / 103 loss=3.888, ppl=14.81, wps=40186.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=21100, lr=0.0002177, gnorm=1.044, loss_scale=16, train_wall=153, gb_free=20.8, wall=34368
2022-03-14 19:57:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:57:32 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 9.365 | ppl 659.47 | wps 66292.4 | wpb 2040.3 | bsz 4 | num_updates 21180 | best_loss 7.537
2022-03-14 19:57:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 21180 updates
2022-03-14 19:57:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:57:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 19:57:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 206 @ 21180 updates, score 9.365) (writing took 0.9395507061854005 seconds)
2022-03-14 19:57:33 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-14 19:57:33 | INFO | train | epoch 206 | loss 3.883 | ppl 14.75 | wps 40224.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21180 | lr 0.000217289 | gnorm 1.031 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34499
KL Stats: Epoch 206 Divergences: Uniform: 5.55212095680812 Unigram: 5.0482176542545165
2022-03-14 19:57:33 | INFO | fairseq.trainer | begin training epoch 207
2022-03-14 19:57:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:57:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:58:06 | INFO | train_inner | epoch 207:     21 / 103 loss=3.883, ppl=14.76, wps=39810.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=21200, lr=0.000217186, gnorm=1.034, loss_scale=16, train_wall=155, gb_free=20.8, wall=34532
2022-03-14 20:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:00:19 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 9.394 | ppl 672.73 | wps 66091 | wpb 2040.3 | bsz 4 | num_updates 21282 | best_loss 7.537
2022-03-14 20:00:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 21282 updates
2022-03-14 20:00:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:00:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:00:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 207 @ 21282 updates, score 9.394) (writing took 0.9434785284101963 seconds)
2022-03-14 20:00:20 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-14 20:00:20 | INFO | train | epoch 207 | loss 3.878 | ppl 14.7 | wps 39836.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21282 | lr 0.000216767 | gnorm 1.029 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34666
KL Stats: Epoch 207 Divergences: Uniform: 5.5548236736088565 Unigram: 5.051896294288313
2022-03-14 20:00:20 | INFO | fairseq.trainer | begin training epoch 208
2022-03-14 20:00:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:00:49 | INFO | train_inner | epoch 208:     18 / 103 loss=3.877, ppl=14.7, wps=40190.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21300, lr=0.000216676, gnorm=1.025, loss_scale=16, train_wall=153, gb_free=20.8, wall=34695
2022-03-14 20:03:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:03:07 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 9.382 | ppl 667.43 | wps 66422.5 | wpb 2040.3 | bsz 4 | num_updates 21385 | best_loss 7.537
2022-03-14 20:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 21385 updates
2022-03-14 20:03:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:03:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:03:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 208 @ 21385 updates, score 9.382) (writing took 0.8897970812395215 seconds)
2022-03-14 20:03:07 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-14 20:03:07 | INFO | train | epoch 208 | loss 3.877 | ppl 14.69 | wps 40247.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21385 | lr 0.000216245 | gnorm 1.039 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34833
KL Stats: Epoch 208 Divergences: Uniform: 5.555160657287126 Unigram: 5.055491694793758
2022-03-14 20:03:07 | INFO | fairseq.trainer | begin training epoch 209
2022-03-14 20:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:03:31 | INFO | train_inner | epoch 209:     15 / 103 loss=3.88, ppl=14.72, wps=40218.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21400, lr=0.000216169, gnorm=1.04, loss_scale=16, train_wall=153, gb_free=20.8, wall=34857
2022-03-14 20:05:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:05:54 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 9.395 | ppl 673.04 | wps 66135.8 | wpb 2040.3 | bsz 4 | num_updates 21488 | best_loss 7.537
2022-03-14 20:05:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 21488 updates
2022-03-14 20:05:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:05:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:05:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 209 @ 21488 updates, score 9.395) (writing took 0.8471370497718453 seconds)
2022-03-14 20:05:54 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-14 20:05:54 | INFO | train | epoch 209 | loss 3.875 | ppl 14.67 | wps 40263.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21488 | lr 0.000215726 | gnorm 1.049 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35001
KL Stats: Epoch 209 Divergences: Uniform: 5.558068073492973 Unigram: 5.0582367578908425
2022-03-14 20:05:55 | INFO | fairseq.trainer | begin training epoch 210
2022-03-14 20:05:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:06:14 | INFO | train_inner | epoch 210:     12 / 103 loss=3.874, ppl=14.67, wps=40235, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21500, lr=0.000215666, gnorm=1.051, loss_scale=16, train_wall=153, gb_free=20.8, wall=35020
2022-03-14 20:08:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:08:41 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 9.399 | ppl 675.1 | wps 66065.3 | wpb 2040.3 | bsz 4 | num_updates 21591 | best_loss 7.537
2022-03-14 20:08:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 21591 updates
2022-03-14 20:08:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:08:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:08:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 210 @ 21591 updates, score 9.399) (writing took 0.9064059946686029 seconds)
2022-03-14 20:08:42 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-14 20:08:42 | INFO | train | epoch 210 | loss 3.87 | ppl 14.62 | wps 40248.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21591 | lr 0.000215211 | gnorm 1.036 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35168
KL Stats: Epoch 210 Divergences: Uniform: 5.56059886613897 Unigram: 5.062059564439634
2022-03-14 20:08:42 | INFO | fairseq.trainer | begin training epoch 211
2022-03-14 20:08:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:08:56 | INFO | train_inner | epoch 211:      9 / 103 loss=3.87, ppl=14.63, wps=40212.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21600, lr=0.000215166, gnorm=1.034, loss_scale=16, train_wall=153, gb_free=20.8, wall=35182
2022-03-14 20:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:11:28 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 9.393 | ppl 672.24 | wps 66446.5 | wpb 2040.3 | bsz 4 | num_updates 21694 | best_loss 7.537
2022-03-14 20:11:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 21694 updates
2022-03-14 20:11:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:11:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:11:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 211 @ 21694 updates, score 9.393) (writing took 0.8671965803951025 seconds)
2022-03-14 20:11:29 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-14 20:11:29 | INFO | train | epoch 211 | loss 3.868 | ppl 14.6 | wps 40241.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21694 | lr 0.000214699 | gnorm 1.029 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 35335
KL Stats: Epoch 211 Divergences: Uniform: 5.560814432731311 Unigram: 5.064227600280043
2022-03-14 20:11:29 | INFO | fairseq.trainer | begin training epoch 212
2022-03-14 20:11:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:11:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 20:11:40 | INFO | train_inner | epoch 212:      7 / 103 loss=3.871, ppl=14.63, wps=39824, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21700, lr=0.000214669, gnorm=1.031, loss_scale=16, train_wall=155, gb_free=20.8, wall=35346
2022-03-14 20:14:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:14:15 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 9.418 | ppl 684.01 | wps 65945.6 | wpb 2040.3 | bsz 4 | num_updates 21796 | best_loss 7.537
2022-03-14 20:14:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 21796 updates
2022-03-14 20:14:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:14:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:14:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 212 @ 21796 updates, score 9.418) (writing took 0.859303561039269 seconds)
2022-03-14 20:14:16 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-14 20:14:16 | INFO | train | epoch 212 | loss 3.864 | ppl 14.56 | wps 39863.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21796 | lr 0.000214196 | gnorm 1.037 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35502
KL Stats: Epoch 212 Divergences: Uniform: 5.563987466911044 Unigram: 5.068520727995872
2022-03-14 20:14:16 | INFO | fairseq.trainer | begin training epoch 213
2022-03-14 20:14:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:14:22 | INFO | train_inner | epoch 213:      4 / 103 loss=3.864, ppl=14.57, wps=40220.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21800, lr=0.000214176, gnorm=1.035, loss_scale=16, train_wall=153, gb_free=20.8, wall=35508
2022-03-14 20:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:17:02 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 9.423 | ppl 686.28 | wps 66145 | wpb 2040.3 | bsz 4 | num_updates 21899 | best_loss 7.537
2022-03-14 20:17:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 21899 updates
2022-03-14 20:17:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:17:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:17:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 213 @ 21899 updates, score 9.423) (writing took 0.8861076487228274 seconds)
2022-03-14 20:17:03 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-14 20:17:03 | INFO | train | epoch 213 | loss 3.862 | ppl 14.54 | wps 40264.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21899 | lr 0.000213692 | gnorm 1.042 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35669
KL Stats: Epoch 213 Divergences: Uniform: 5.565336523305059 Unigram: 5.072013746810862
2022-03-14 20:17:03 | INFO | fairseq.trainer | begin training epoch 214
2022-03-14 20:17:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:17:05 | INFO | train_inner | epoch 214:      1 / 103 loss=3.864, ppl=14.57, wps=40227.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21900, lr=0.000213687, gnorm=1.043, loss_scale=16, train_wall=153, gb_free=20.8, wall=35671
2022-03-14 20:19:43 | INFO | train_inner | epoch 214:    101 / 103 loss=3.858, ppl=14.5, wps=41368.6, ups=0.63, wpb=65530.9, bsz=128, num_updates=22000, lr=0.000213201, gnorm=1.043, loss_scale=16, train_wall=153, gb_free=20.8, wall=35829
2022-03-14 20:19:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:19:49 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 9.412 | ppl 681.1 | wps 66066.1 | wpb 2040.3 | bsz 4 | num_updates 22002 | best_loss 7.537
2022-03-14 20:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 22002 updates
2022-03-14 20:19:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:19:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 214 @ 22002 updates, score 9.412) (writing took 0.8918570065870881 seconds)
2022-03-14 20:19:50 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-14 20:19:50 | INFO | train | epoch 214 | loss 3.859 | ppl 14.51 | wps 40240.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22002 | lr 0.000213191 | gnorm 1.045 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35836
KL Stats: Epoch 214 Divergences: Uniform: 5.566553017075073 Unigram: 5.073878159054766
2022-03-14 20:19:50 | INFO | fairseq.trainer | begin training epoch 215
2022-03-14 20:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:22:25 | INFO | train_inner | epoch 215:     98 / 103 loss=3.855, ppl=14.47, wps=40201.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22100, lr=0.000212718, gnorm=1.042, loss_scale=16, train_wall=153, gb_free=20.8, wall=35992
2022-03-14 20:22:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:22:36 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 9.386 | ppl 669.23 | wps 66789.5 | wpb 2040.3 | bsz 4 | num_updates 22105 | best_loss 7.537
2022-03-14 20:22:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 22105 updates
2022-03-14 20:22:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:22:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:22:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 215 @ 22105 updates, score 9.386) (writing took 0.876976634375751 seconds)
2022-03-14 20:22:37 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-14 20:22:37 | INFO | train | epoch 215 | loss 3.857 | ppl 14.49 | wps 40249.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22105 | lr 0.000212694 | gnorm 1.043 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36003
KL Stats: Epoch 215 Divergences: Uniform: 5.56643886124224 Unigram: 5.074894132400182
2022-03-14 20:22:37 | INFO | fairseq.trainer | begin training epoch 216
2022-03-14 20:22:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:25:08 | INFO | train_inner | epoch 216:     95 / 103 loss=3.851, ppl=14.43, wps=40231.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22200, lr=0.000212238, gnorm=1.041, loss_scale=16, train_wall=153, gb_free=20.8, wall=36154
2022-03-14 20:25:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 20:25:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:25:23 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 9.42 | ppl 685.09 | wps 66400.8 | wpb 2040.3 | bsz 4 | num_updates 22207 | best_loss 7.537
2022-03-14 20:25:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 22207 updates
2022-03-14 20:25:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:25:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 216 @ 22207 updates, score 9.42) (writing took 0.8817113069817424 seconds)
2022-03-14 20:25:24 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-14 20:25:24 | INFO | train | epoch 216 | loss 3.852 | ppl 14.44 | wps 39874.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22207 | lr 0.000212205 | gnorm 1.043 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36170
KL Stats: Epoch 216 Divergences: Uniform: 5.570514048035857 Unigram: 5.081505767524834
2022-03-14 20:25:24 | INFO | fairseq.trainer | begin training epoch 217
2022-03-14 20:25:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:27:52 | INFO | train_inner | epoch 217:     93 / 103 loss=3.848, ppl=14.4, wps=39830.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=22300, lr=0.000211762, gnorm=1.04, loss_scale=16, train_wall=155, gb_free=20.8, wall=36318
2022-03-14 20:28:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:28:11 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 9.392 | ppl 671.64 | wps 66082.6 | wpb 2040.3 | bsz 4 | num_updates 22310 | best_loss 7.537
2022-03-14 20:28:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 22310 updates
2022-03-14 20:28:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:28:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:28:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 217 @ 22310 updates, score 9.392) (writing took 0.8472069753333926 seconds)
2022-03-14 20:28:12 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-14 20:28:12 | INFO | train | epoch 217 | loss 3.849 | ppl 14.41 | wps 40247.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22310 | lr 0.000211714 | gnorm 1.038 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36338
KL Stats: Epoch 217 Divergences: Uniform: 5.5714424707118795 Unigram: 5.082471197955352
2022-03-14 20:28:12 | INFO | fairseq.trainer | begin training epoch 218
2022-03-14 20:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:30:34 | INFO | train_inner | epoch 218:     90 / 103 loss=3.844, ppl=14.36, wps=40237.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=22400, lr=0.000211289, gnorm=1.046, loss_scale=16, train_wall=153, gb_free=20.8, wall=36480
2022-03-14 20:30:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:30:58 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 9.411 | ppl 680.71 | wps 66132.7 | wpb 2040.3 | bsz 4 | num_updates 22413 | best_loss 7.537
2022-03-14 20:30:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 22413 updates
2022-03-14 20:30:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 218 @ 22413 updates, score 9.411) (writing took 0.878188943490386 seconds)
2022-03-14 20:30:59 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-14 20:30:59 | INFO | train | epoch 218 | loss 3.847 | ppl 14.39 | wps 40271.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22413 | lr 0.000211227 | gnorm 1.045 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36505
KL Stats: Epoch 218 Divergences: Uniform: 5.5725517107397815 Unigram: 5.085718931736162
2022-03-14 20:30:59 | INFO | fairseq.trainer | begin training epoch 219
2022-03-14 20:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:33:16 | INFO | train_inner | epoch 219:     87 / 103 loss=3.845, ppl=14.37, wps=40245.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=22500, lr=0.000210819, gnorm=1.018, loss_scale=16, train_wall=153, gb_free=20.8, wall=36642
2022-03-14 20:33:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:33:45 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 9.432 | ppl 690.6 | wps 66386 | wpb 2040.3 | bsz 4 | num_updates 22516 | best_loss 7.537
2022-03-14 20:33:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 22516 updates
2022-03-14 20:33:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:33:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:33:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 219 @ 22516 updates, score 9.432) (writing took 0.8854883154854178 seconds)
2022-03-14 20:33:46 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-14 20:33:46 | INFO | train | epoch 219 | loss 3.844 | ppl 14.36 | wps 40275.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22516 | lr 0.000210744 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36672
KL Stats: Epoch 219 Divergences: Uniform: 5.575046633586764 Unigram: 5.090023957687777
2022-03-14 20:33:46 | INFO | fairseq.trainer | begin training epoch 220
2022-03-14 20:33:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:35:59 | INFO | train_inner | epoch 220:     84 / 103 loss=3.84, ppl=14.32, wps=40221.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=22600, lr=0.000210352, gnorm=1.045, loss_scale=16, train_wall=153, gb_free=20.8, wall=36805
2022-03-14 20:36:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:36:32 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 9.422 | ppl 686.08 | wps 66183.8 | wpb 2040.3 | bsz 4 | num_updates 22619 | best_loss 7.537
2022-03-14 20:36:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 22619 updates
2022-03-14 20:36:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:36:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:36:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 220 @ 22619 updates, score 9.422) (writing took 0.8559260135516524 seconds)
2022-03-14 20:36:33 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-14 20:36:33 | INFO | train | epoch 220 | loss 3.843 | ppl 14.35 | wps 40263.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22619 | lr 0.000210263 | gnorm 1.048 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36839
KL Stats: Epoch 220 Divergences: Uniform: 5.576046257257549 Unigram: 5.091414527780828
2022-03-14 20:36:33 | INFO | fairseq.trainer | begin training epoch 221
2022-03-14 20:36:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:38:41 | INFO | train_inner | epoch 221:     81 / 103 loss=3.84, ppl=14.32, wps=40246.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22700, lr=0.000209888, gnorm=1.039, loss_scale=16, train_wall=153, gb_free=20.8, wall=36967
2022-03-14 20:39:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 20:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:39:19 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 9.429 | ppl 689.27 | wps 66586.6 | wpb 2040.3 | bsz 4 | num_updates 22721 | best_loss 7.537
2022-03-14 20:39:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 22721 updates
2022-03-14 20:39:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 221 @ 22721 updates, score 9.429) (writing took 0.87104547675699 seconds)
2022-03-14 20:39:20 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-14 20:39:20 | INFO | train | epoch 221 | loss 3.839 | ppl 14.31 | wps 39888.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22721 | lr 0.000209791 | gnorm 1.037 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37006
KL Stats: Epoch 221 Divergences: Uniform: 5.578283657594479 Unigram: 5.096430990493398
2022-03-14 20:39:20 | INFO | fairseq.trainer | begin training epoch 222
2022-03-14 20:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:41:25 | INFO | train_inner | epoch 222:     79 / 103 loss=3.835, ppl=14.28, wps=39848.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22800, lr=0.000209427, gnorm=1.049, loss_scale=16, train_wall=154, gb_free=20.8, wall=37131
2022-03-14 20:42:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:42:06 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 9.435 | ppl 692.4 | wps 66304.2 | wpb 2040.3 | bsz 4 | num_updates 22824 | best_loss 7.537
2022-03-14 20:42:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 22824 updates
2022-03-14 20:42:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:42:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:42:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 222 @ 22824 updates, score 9.435) (writing took 0.8674568450078368 seconds)
2022-03-14 20:42:07 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-14 20:42:07 | INFO | train | epoch 222 | loss 3.837 | ppl 14.29 | wps 40264.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22824 | lr 0.000209317 | gnorm 1.042 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37173
KL Stats: Epoch 222 Divergences: Uniform: 5.5784062401342585 Unigram: 5.094995652143023
2022-03-14 20:42:07 | INFO | fairseq.trainer | begin training epoch 223
2022-03-14 20:42:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:43:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:44:09 | INFO | train_inner | epoch 223:     77 / 103 loss=3.833, ppl=14.25, wps=39845.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22900, lr=0.000208969, gnorm=1.035, loss_scale=8, train_wall=154, gb_free=20.8, wall=37295
2022-03-14 20:44:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:44:53 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 9.43 | ppl 689.99 | wps 66225.7 | wpb 2040.3 | bsz 4 | num_updates 22926 | best_loss 7.537
2022-03-14 20:44:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 22926 updates
2022-03-14 20:44:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:44:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:44:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 223 @ 22926 updates, score 9.43) (writing took 0.8568995082750916 seconds)
2022-03-14 20:44:54 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-14 20:44:54 | INFO | train | epoch 223 | loss 3.833 | ppl 14.25 | wps 39875.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22926 | lr 0.000208851 | gnorm 1.044 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 37340
KL Stats: Epoch 223 Divergences: Uniform: 5.581438053351371 Unigram: 5.101092045339604
2022-03-14 20:44:54 | INFO | fairseq.trainer | begin training epoch 224
2022-03-14 20:44:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:46:51 | INFO | train_inner | epoch 224:     74 / 103 loss=3.832, ppl=14.24, wps=40211.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23000, lr=0.000208514, gnorm=1.037, loss_scale=8, train_wall=153, gb_free=20.8, wall=37457
2022-03-14 20:47:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:47:40 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 9.433 | ppl 691.29 | wps 66003.4 | wpb 2040.3 | bsz 4 | num_updates 23029 | best_loss 7.537
2022-03-14 20:47:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 23029 updates
2022-03-14 20:47:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:47:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:47:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 224 @ 23029 updates, score 9.433) (writing took 0.8732812209054828 seconds)
2022-03-14 20:47:41 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-14 20:47:41 | INFO | train | epoch 224 | loss 3.832 | ppl 14.24 | wps 40239.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23029 | lr 0.000208383 | gnorm 1.034 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 37507
KL Stats: Epoch 224 Divergences: Uniform: 5.582186962462997 Unigram: 5.100550264679101
2022-03-14 20:47:41 | INFO | fairseq.trainer | begin training epoch 225
2022-03-14 20:47:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:49:33 | INFO | train_inner | epoch 225:     71 / 103 loss=3.83, ppl=14.22, wps=40240.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23100, lr=0.000208063, gnorm=1.042, loss_scale=8, train_wall=153, gb_free=20.8, wall=37619
2022-03-14 20:50:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:50:27 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 9.446 | ppl 697.52 | wps 66322.7 | wpb 2040.3 | bsz 4 | num_updates 23132 | best_loss 7.537
2022-03-14 20:50:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 23132 updates
2022-03-14 20:50:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:50:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 225 @ 23132 updates, score 9.446) (writing took 0.8751855045557022 seconds)
2022-03-14 20:50:28 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-14 20:50:28 | INFO | train | epoch 225 | loss 3.829 | ppl 14.21 | wps 40272.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23132 | lr 0.000207919 | gnorm 1.041 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 37674
KL Stats: Epoch 225 Divergences: Uniform: 5.584380334262771 Unigram: 5.104145478167574
2022-03-14 20:50:28 | INFO | fairseq.trainer | begin training epoch 226
2022-03-14 20:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:52:16 | INFO | train_inner | epoch 226:     68 / 103 loss=3.823, ppl=14.16, wps=40231.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23200, lr=0.000207614, gnorm=1.041, loss_scale=8, train_wall=153, gb_free=20.8, wall=37782
2022-03-14 20:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:53:14 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 9.444 | ppl 696.57 | wps 66398.2 | wpb 2040.3 | bsz 4 | num_updates 23235 | best_loss 7.537
2022-03-14 20:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 23235 updates
2022-03-14 20:53:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:53:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:53:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 226 @ 23235 updates, score 9.444) (writing took 0.9197679413482547 seconds)
2022-03-14 20:53:15 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-14 20:53:15 | INFO | train | epoch 226 | loss 3.826 | ppl 14.18 | wps 40262.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23235 | lr 0.000207457 | gnorm 1.043 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 37841
KL Stats: Epoch 226 Divergences: Uniform: 5.585758129960257 Unigram: 5.108939254735488
2022-03-14 20:53:15 | INFO | fairseq.trainer | begin training epoch 227
2022-03-14 20:53:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:54:58 | INFO | train_inner | epoch 227:     65 / 103 loss=3.826, ppl=14.18, wps=40227.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23300, lr=0.000207168, gnorm=1.034, loss_scale=8, train_wall=153, gb_free=20.8, wall=37944
2022-03-14 20:55:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:56:01 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 9.469 | ppl 708.89 | wps 66426.8 | wpb 2040.3 | bsz 4 | num_updates 23338 | best_loss 7.537
2022-03-14 20:56:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 23338 updates
2022-03-14 20:56:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:56:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:56:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 227 @ 23338 updates, score 9.469) (writing took 0.874693782068789 seconds)
2022-03-14 20:56:02 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-14 20:56:02 | INFO | train | epoch 227 | loss 3.823 | ppl 14.15 | wps 40259.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23338 | lr 0.000206999 | gnorm 1.036 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 38008
KL Stats: Epoch 227 Divergences: Uniform: 5.586493522080046 Unigram: 5.111751277765047
2022-03-14 20:56:02 | INFO | fairseq.trainer | begin training epoch 228
2022-03-14 20:56:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:57:40 | INFO | train_inner | epoch 228:     62 / 103 loss=3.819, ppl=14.12, wps=40234.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23400, lr=0.000206725, gnorm=1.044, loss_scale=16, train_wall=153, gb_free=20.8, wall=38106
2022-03-14 20:58:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:58:48 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 9.464 | ppl 706.29 | wps 66261.2 | wpb 2040.3 | bsz 4 | num_updates 23441 | best_loss 7.537
2022-03-14 20:58:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 23441 updates
2022-03-14 20:58:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:58:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 20:58:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 228 @ 23441 updates, score 9.464) (writing took 0.8787402110174298 seconds)
2022-03-14 20:58:49 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-14 20:58:49 | INFO | train | epoch 228 | loss 3.82 | ppl 14.12 | wps 40269.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23441 | lr 0.000206544 | gnorm 1.038 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38175
KL Stats: Epoch 228 Divergences: Uniform: 5.589915822524715 Unigram: 5.114309067496397
2022-03-14 20:58:49 | INFO | fairseq.trainer | begin training epoch 229
2022-03-14 20:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:00:23 | INFO | train_inner | epoch 229:     59 / 103 loss=3.817, ppl=14.1, wps=40214.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23500, lr=0.000206284, gnorm=1.036, loss_scale=16, train_wall=153, gb_free=20.8, wall=38269
2022-03-14 21:01:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:01:36 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 9.441 | ppl 695.13 | wps 66404.2 | wpb 2040.3 | bsz 4 | num_updates 23544 | best_loss 7.537
2022-03-14 21:01:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 23544 updates
2022-03-14 21:01:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:01:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:01:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 229 @ 23544 updates, score 9.441) (writing took 0.8681004336103797 seconds)
2022-03-14 21:01:36 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-14 21:01:36 | INFO | train | epoch 229 | loss 3.817 | ppl 14.09 | wps 40246.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23544 | lr 0.000206091 | gnorm 1.049 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38342
KL Stats: Epoch 229 Divergences: Uniform: 5.590994203629937 Unigram: 5.116671968707709
2022-03-14 21:01:36 | INFO | fairseq.trainer | begin training epoch 230
2022-03-14 21:01:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:03:05 | INFO | train_inner | epoch 230:     56 / 103 loss=3.816, ppl=14.09, wps=40238.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=23600, lr=0.000205847, gnorm=1.045, loss_scale=16, train_wall=153, gb_free=20.8, wall=38431
2022-03-14 21:04:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:04:23 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 9.446 | ppl 697.31 | wps 66139.5 | wpb 2040.3 | bsz 4 | num_updates 23647 | best_loss 7.537
2022-03-14 21:04:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 23647 updates
2022-03-14 21:04:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:04:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:04:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 230 @ 23647 updates, score 9.446) (writing took 0.8474817499518394 seconds)
2022-03-14 21:04:23 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-14 21:04:23 | INFO | train | epoch 230 | loss 3.814 | ppl 14.07 | wps 40280 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23647 | lr 0.000205642 | gnorm 1.04 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38509
KL Stats: Epoch 230 Divergences: Uniform: 5.591624632088653 Unigram: 5.118413635035042
2022-03-14 21:04:23 | INFO | fairseq.trainer | begin training epoch 231
2022-03-14 21:04:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:05:47 | INFO | train_inner | epoch 231:     53 / 103 loss=3.813, ppl=14.05, wps=40246.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23700, lr=0.000205412, gnorm=1.043, loss_scale=16, train_wall=153, gb_free=20.8, wall=38593
2022-03-14 21:07:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:07:10 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 9.472 | ppl 710.4 | wps 66268.4 | wpb 2040.3 | bsz 4 | num_updates 23750 | best_loss 7.537
2022-03-14 21:07:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 23750 updates
2022-03-14 21:07:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:07:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:07:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 231 @ 23750 updates, score 9.472) (writing took 0.8816194105893373 seconds)
2022-03-14 21:07:10 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-14 21:07:10 | INFO | train | epoch 231 | loss 3.813 | ppl 14.05 | wps 40265 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23750 | lr 0.000205196 | gnorm 1.04 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38677
KL Stats: Epoch 231 Divergences: Uniform: 5.593085032046038 Unigram: 5.121103768595969
2022-03-14 21:07:10 | INFO | fairseq.trainer | begin training epoch 232
2022-03-14 21:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:08:30 | INFO | train_inner | epoch 232:     50 / 103 loss=3.813, ppl=14.06, wps=40226.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=23800, lr=0.00020498, gnorm=1.046, loss_scale=16, train_wall=153, gb_free=20.8, wall=38756
2022-03-14 21:09:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:09:57 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 9.475 | ppl 711.47 | wps 66147.7 | wpb 2040.3 | bsz 4 | num_updates 23853 | best_loss 7.537
2022-03-14 21:09:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 23853 updates
2022-03-14 21:09:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:09:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:09:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 232 @ 23853 updates, score 9.475) (writing took 0.9148665722459555 seconds)
2022-03-14 21:09:58 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-14 21:09:58 | INFO | train | epoch 232 | loss 3.811 | ppl 14.03 | wps 40259.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23853 | lr 0.000204752 | gnorm 1.05 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38844
KL Stats: Epoch 232 Divergences: Uniform: 5.594533236476594 Unigram: 5.122771440108237
2022-03-14 21:09:58 | INFO | fairseq.trainer | begin training epoch 233
2022-03-14 21:09:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:11:12 | INFO | train_inner | epoch 233:     47 / 103 loss=3.81, ppl=14.02, wps=40222.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23900, lr=0.000204551, gnorm=1.046, loss_scale=16, train_wall=153, gb_free=20.8, wall=38918
2022-03-14 21:11:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 21:12:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:12:44 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 9.459 | ppl 703.94 | wps 66204.3 | wpb 2040.3 | bsz 4 | num_updates 23955 | best_loss 7.537
2022-03-14 21:12:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 23955 updates
2022-03-14 21:12:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 233 @ 23955 updates, score 9.459) (writing took 0.8685025181621313 seconds)
2022-03-14 21:12:45 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-14 21:12:45 | INFO | train | epoch 233 | loss 3.807 | ppl 13.99 | wps 39861.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23955 | lr 0.000204316 | gnorm 1.038 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39011
KL Stats: Epoch 233 Divergences: Uniform: 5.5974377817684955 Unigram: 5.129565658372919
2022-03-14 21:12:45 | INFO | fairseq.trainer | begin training epoch 234
2022-03-14 21:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:13:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:13:58 | INFO | train_inner | epoch 234:     46 / 103 loss=3.804, ppl=13.97, wps=39446.3, ups=0.6, wpb=65310.7, bsz=127.6, num_updates=24000, lr=0.000204124, gnorm=1.039, loss_scale=8, train_wall=156, gb_free=20.8, wall=39084
2022-03-14 21:15:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:15:31 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 9.483 | ppl 715.58 | wps 66329.9 | wpb 2040.3 | bsz 4 | num_updates 24057 | best_loss 7.537
2022-03-14 21:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 24057 updates
2022-03-14 21:15:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:15:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 234 @ 24057 updates, score 9.483) (writing took 0.8696715841069818 seconds)
2022-03-14 21:15:32 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-14 21:15:32 | INFO | train | epoch 234 | loss 3.806 | ppl 13.99 | wps 39857.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24057 | lr 0.000203882 | gnorm 1.047 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 39178
KL Stats: Epoch 234 Divergences: Uniform: 5.598172967229621 Unigram: 5.129149565393322
2022-03-14 21:15:32 | INFO | fairseq.trainer | begin training epoch 235
2022-03-14 21:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:16:40 | INFO | train_inner | epoch 235:     43 / 103 loss=3.805, ppl=13.98, wps=40211.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=24100, lr=0.0002037, gnorm=1.044, loss_scale=8, train_wall=153, gb_free=20.8, wall=39246
2022-03-14 21:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:18:18 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 9.458 | ppl 703.39 | wps 65995.3 | wpb 2040.3 | bsz 4 | num_updates 24160 | best_loss 7.537
2022-03-14 21:18:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 24160 updates
2022-03-14 21:18:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 235 @ 24160 updates, score 9.458) (writing took 0.9104166906327009 seconds)
2022-03-14 21:18:19 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-14 21:18:19 | INFO | train | epoch 235 | loss 3.804 | ppl 13.96 | wps 40244.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24160 | lr 0.000203447 | gnorm 1.059 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 39345
KL Stats: Epoch 235 Divergences: Uniform: 5.596745162380229 Unigram: 5.129978426154285
2022-03-14 21:18:19 | INFO | fairseq.trainer | begin training epoch 236
2022-03-14 21:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:19:22 | INFO | train_inner | epoch 236:     40 / 103 loss=3.802, ppl=13.94, wps=40229.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24200, lr=0.000203279, gnorm=1.06, loss_scale=8, train_wall=153, gb_free=20.8, wall=39408
2022-03-14 21:21:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:21:05 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 9.497 | ppl 722.64 | wps 65784.8 | wpb 2040.3 | bsz 4 | num_updates 24263 | best_loss 7.537
2022-03-14 21:21:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 24263 updates
2022-03-14 21:21:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:21:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:21:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 236 @ 24263 updates, score 9.497) (writing took 0.9788483483716846 seconds)
2022-03-14 21:21:06 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-14 21:21:06 | INFO | train | epoch 236 | loss 3.8 | ppl 13.93 | wps 40229.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24263 | lr 0.000203015 | gnorm 1.034 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 39512
KL Stats: Epoch 236 Divergences: Uniform: 5.599964692935473 Unigram: 5.133322326573172
2022-03-14 21:21:06 | INFO | fairseq.trainer | begin training epoch 237
2022-03-14 21:21:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:22:05 | INFO | train_inner | epoch 237:     37 / 103 loss=3.8, ppl=13.93, wps=40194.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=24300, lr=0.00020286, gnorm=1.045, loss_scale=8, train_wall=153, gb_free=20.8, wall=39571
2022-03-14 21:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:23:53 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 9.483 | ppl 715.55 | wps 66421.8 | wpb 2040.3 | bsz 4 | num_updates 24366 | best_loss 7.537
2022-03-14 21:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 24366 updates
2022-03-14 21:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:23:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:23:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 237 @ 24366 updates, score 9.483) (writing took 0.8758800085633993 seconds)
2022-03-14 21:23:53 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-14 21:23:53 | INFO | train | epoch 237 | loss 3.799 | ppl 13.92 | wps 40239.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24366 | lr 0.000202585 | gnorm 1.055 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 39679
KL Stats: Epoch 237 Divergences: Uniform: 5.602056840571817 Unigram: 5.137447887924323
2022-03-14 21:23:53 | INFO | fairseq.trainer | begin training epoch 238
2022-03-14 21:23:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:24:47 | INFO | train_inner | epoch 238:     34 / 103 loss=3.8, ppl=13.93, wps=40198.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24400, lr=0.000202444, gnorm=1.051, loss_scale=8, train_wall=153, gb_free=20.8, wall=39733
2022-03-14 21:26:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:26:40 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 9.463 | ppl 705.74 | wps 66189 | wpb 2040.3 | bsz 4 | num_updates 24469 | best_loss 7.537
2022-03-14 21:26:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 24469 updates
2022-03-14 21:26:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:26:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:26:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 238 @ 24469 updates, score 9.463) (writing took 0.9941833075135946 seconds)
2022-03-14 21:26:41 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-14 21:26:41 | INFO | train | epoch 238 | loss 3.796 | ppl 13.89 | wps 40190.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24469 | lr 0.000202158 | gnorm 1.047 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 39847
KL Stats: Epoch 238 Divergences: Uniform: 5.602724018917666 Unigram: 5.13928983561385
2022-03-14 21:26:41 | INFO | fairseq.trainer | begin training epoch 239
2022-03-14 21:26:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:27:30 | INFO | train_inner | epoch 239:     31 / 103 loss=3.794, ppl=13.87, wps=40155.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24500, lr=0.000202031, gnorm=1.042, loss_scale=16, train_wall=153, gb_free=20.8, wall=39896
2022-03-14 21:29:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:29:27 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 9.496 | ppl 722.18 | wps 66274 | wpb 2040.3 | bsz 4 | num_updates 24572 | best_loss 7.537
2022-03-14 21:29:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 24572 updates
2022-03-14 21:29:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:29:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:29:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 239 @ 24572 updates, score 9.496) (writing took 0.8994756788015366 seconds)
2022-03-14 21:29:28 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-14 21:29:28 | INFO | train | epoch 239 | loss 3.793 | ppl 13.86 | wps 40201.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24572 | lr 0.000201734 | gnorm 1.044 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40014
KL Stats: Epoch 239 Divergences: Uniform: 5.604922193953025 Unigram: 5.141629598911478
2022-03-14 21:29:28 | INFO | fairseq.trainer | begin training epoch 240
2022-03-14 21:29:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:29:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:30:14 | INFO | train_inner | epoch 240:     29 / 103 loss=3.795, ppl=13.88, wps=39786.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24600, lr=0.000201619, gnorm=1.05, loss_scale=8, train_wall=155, gb_free=20.8, wall=40060
2022-03-14 21:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:32:14 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 9.509 | ppl 728.4 | wps 66189.4 | wpb 2040.3 | bsz 4 | num_updates 24674 | best_loss 7.537
2022-03-14 21:32:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 24674 updates
2022-03-14 21:32:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:32:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:32:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 240 @ 24674 updates, score 9.509) (writing took 0.8955208538100123 seconds)
2022-03-14 21:32:15 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-14 21:32:15 | INFO | train | epoch 240 | loss 3.79 | ppl 13.83 | wps 39830 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24674 | lr 0.000201317 | gnorm 1.055 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 40181
KL Stats: Epoch 240 Divergences: Uniform: 5.608496641753219 Unigram: 5.147023753060624
2022-03-14 21:32:15 | INFO | fairseq.trainer | begin training epoch 241
2022-03-14 21:32:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:32:57 | INFO | train_inner | epoch 241:     26 / 103 loss=3.79, ppl=13.83, wps=40187.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24700, lr=0.000201211, gnorm=1.051, loss_scale=8, train_wall=153, gb_free=20.8, wall=40223
2022-03-14 21:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:35:02 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 9.508 | ppl 728.02 | wps 66241.9 | wpb 2040.3 | bsz 4 | num_updates 24777 | best_loss 7.537
2022-03-14 21:35:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 24777 updates
2022-03-14 21:35:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:35:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 241 @ 24777 updates, score 9.508) (writing took 0.9428642662242055 seconds)
2022-03-14 21:35:03 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-14 21:35:03 | INFO | train | epoch 241 | loss 3.789 | ppl 13.82 | wps 40191.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24777 | lr 0.000200898 | gnorm 1.06 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 40349
KL Stats: Epoch 241 Divergences: Uniform: 5.605819486230119 Unigram: 5.147658058719277
2022-03-14 21:35:03 | INFO | fairseq.trainer | begin training epoch 242
2022-03-14 21:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:35:39 | INFO | train_inner | epoch 242:     23 / 103 loss=3.789, ppl=13.82, wps=40149.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24800, lr=0.000200805, gnorm=1.061, loss_scale=8, train_wall=153, gb_free=20.8, wall=40385
2022-03-14 21:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:37:49 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 9.495 | ppl 721.45 | wps 65768.9 | wpb 2040.3 | bsz 4 | num_updates 24880 | best_loss 7.537
2022-03-14 21:37:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 24880 updates
2022-03-14 21:37:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:37:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 242 @ 24880 updates, score 9.495) (writing took 0.903750691562891 seconds)
2022-03-14 21:37:50 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-14 21:37:50 | INFO | train | epoch 242 | loss 3.786 | ppl 13.8 | wps 40185.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24880 | lr 0.000200482 | gnorm 1.065 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 40516
KL Stats: Epoch 242 Divergences: Uniform: 5.607127060632401 Unigram: 5.149303646024513
2022-03-14 21:37:50 | INFO | fairseq.trainer | begin training epoch 243
2022-03-14 21:37:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:38:22 | INFO | train_inner | epoch 243:     20 / 103 loss=3.789, ppl=13.82, wps=40145.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24900, lr=0.000200401, gnorm=1.063, loss_scale=8, train_wall=153, gb_free=20.8, wall=40548
2022-03-14 21:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:40:37 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 9.494 | ppl 721.08 | wps 66071.3 | wpb 2040.3 | bsz 4 | num_updates 24983 | best_loss 7.537
2022-03-14 21:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 24983 updates
2022-03-14 21:40:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 243 @ 24983 updates, score 9.494) (writing took 0.8784270267933607 seconds)
2022-03-14 21:40:38 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-14 21:40:38 | INFO | train | epoch 243 | loss 3.784 | ppl 13.78 | wps 40149.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 24983 | lr 0.000200068 | gnorm 1.05 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 40684
KL Stats: Epoch 243 Divergences: Uniform: 5.6092764441604865 Unigram: 5.151706031386841
2022-03-14 21:40:38 | INFO | fairseq.trainer | begin training epoch 244
2022-03-14 21:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:41:05 | INFO | train_inner | epoch 244:     17 / 103 loss=3.784, ppl=13.77, wps=40111.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=25000, lr=0.0002, gnorm=1.06, loss_scale=8, train_wall=153, gb_free=20.8, wall=40711
2022-03-14 21:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:43:24 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 9.491 | ppl 719.7 | wps 66256.9 | wpb 2040.3 | bsz 4 | num_updates 25086 | best_loss 7.537
2022-03-14 21:43:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 25086 updates
2022-03-14 21:43:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:43:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 244 @ 25086 updates, score 9.491) (writing took 0.8627063753083348 seconds)
2022-03-14 21:43:25 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-14 21:43:25 | INFO | train | epoch 244 | loss 3.781 | ppl 13.74 | wps 40130.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25086 | lr 0.000199657 | gnorm 1.066 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 40851
KL Stats: Epoch 244 Divergences: Uniform: 5.608879760119265 Unigram: 5.151942364298802
2022-03-14 21:43:25 | INFO | fairseq.trainer | begin training epoch 245
2022-03-14 21:43:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:43:48 | INFO | train_inner | epoch 245:     14 / 103 loss=3.781, ppl=13.75, wps=40095.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25100, lr=0.000199601, gnorm=1.062, loss_scale=16, train_wall=153, gb_free=20.8, wall=40874
2022-03-14 21:43:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:46:12 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 9.496 | ppl 721.91 | wps 66460.6 | wpb 2040.3 | bsz 4 | num_updates 25188 | best_loss 7.537
2022-03-14 21:46:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 25188 updates
2022-03-14 21:46:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:46:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:46:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 245 @ 25188 updates, score 9.496) (writing took 0.9214172251522541 seconds)
2022-03-14 21:46:13 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-14 21:46:13 | INFO | train | epoch 245 | loss 3.778 | ppl 13.72 | wps 39761.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 25188 | lr 0.000199252 | gnorm 1.052 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 41019
KL Stats: Epoch 245 Divergences: Uniform: 5.611541735840966 Unigram: 5.156039564238616
2022-03-14 21:46:13 | INFO | fairseq.trainer | begin training epoch 246
2022-03-14 21:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:46:32 | INFO | train_inner | epoch 246:     12 / 103 loss=3.781, ppl=13.74, wps=39737.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=25200, lr=0.000199205, gnorm=1.051, loss_scale=8, train_wall=155, gb_free=20.8, wall=41038
2022-03-14 21:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:48:59 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 9.514 | ppl 730.9 | wps 66624.3 | wpb 2040.3 | bsz 4 | num_updates 25291 | best_loss 7.537
2022-03-14 21:48:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 25291 updates
2022-03-14 21:48:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:49:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:49:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 246 @ 25291 updates, score 9.514) (writing took 0.93012551125139 seconds)
2022-03-14 21:49:00 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-14 21:49:00 | INFO | train | epoch 246 | loss 3.778 | ppl 13.71 | wps 40195.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25291 | lr 0.000198846 | gnorm 1.052 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 41186
KL Stats: Epoch 246 Divergences: Uniform: 5.6144470760602205 Unigram: 5.159349727876136
2022-03-14 21:49:00 | INFO | fairseq.trainer | begin training epoch 247
2022-03-14 21:49:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:49:15 | INFO | train_inner | epoch 247:      9 / 103 loss=3.78, ppl=13.73, wps=40172.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25300, lr=0.000198811, gnorm=1.053, loss_scale=8, train_wall=153, gb_free=20.8, wall=41201
2022-03-14 21:51:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:51:47 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 9.505 | ppl 726.7 | wps 65804.5 | wpb 2040.3 | bsz 4 | num_updates 25394 | best_loss 7.537
2022-03-14 21:51:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 25394 updates
2022-03-14 21:51:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:51:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:51:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 247 @ 25394 updates, score 9.505) (writing took 0.8759045209735632 seconds)
2022-03-14 21:51:48 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-14 21:51:48 | INFO | train | epoch 247 | loss 3.775 | ppl 13.69 | wps 40175.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25394 | lr 0.000198442 | gnorm 1.065 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 41354
KL Stats: Epoch 247 Divergences: Uniform: 5.612946428872067 Unigram: 5.159490782585859
2022-03-14 21:51:48 | INFO | fairseq.trainer | begin training epoch 248
2022-03-14 21:51:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:51:57 | INFO | train_inner | epoch 248:      6 / 103 loss=3.775, ppl=13.69, wps=40136, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25400, lr=0.000198419, gnorm=1.064, loss_scale=8, train_wall=153, gb_free=20.8, wall=41363
2022-03-14 21:54:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:54:34 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 9.517 | ppl 732.43 | wps 66453.3 | wpb 2040.3 | bsz 4 | num_updates 25497 | best_loss 7.537
2022-03-14 21:54:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 25497 updates
2022-03-14 21:54:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 248 @ 25497 updates, score 9.517) (writing took 0.9087532553821802 seconds)
2022-03-14 21:54:35 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-14 21:54:35 | INFO | train | epoch 248 | loss 3.772 | ppl 13.66 | wps 40188.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25497 | lr 0.000198041 | gnorm 1.048 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 41521
KL Stats: Epoch 248 Divergences: Uniform: 5.61470684670227 Unigram: 5.16397462980236
2022-03-14 21:54:35 | INFO | fairseq.trainer | begin training epoch 249
2022-03-14 21:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:54:40 | INFO | train_inner | epoch 249:      3 / 103 loss=3.774, ppl=13.68, wps=40156.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25500, lr=0.00019803, gnorm=1.049, loss_scale=8, train_wall=153, gb_free=20.8, wall=41526
2022-03-14 21:57:18 | INFO | train_inner | epoch 249:    103 / 103 loss=3.772, ppl=13.66, wps=41315.5, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=25600, lr=0.000197642, gnorm=1.041, loss_scale=8, train_wall=153, gb_free=20.8, wall=41684
2022-03-14 21:57:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:57:22 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 9.54 | ppl 744.37 | wps 66262.2 | wpb 2040.3 | bsz 4 | num_updates 25600 | best_loss 7.537
2022-03-14 21:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 25600 updates
2022-03-14 21:57:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:57:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 21:57:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 249 @ 25600 updates, score 9.54) (writing took 0.9782888423651457 seconds)
2022-03-14 21:57:23 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-14 21:57:23 | INFO | train | epoch 249 | loss 3.77 | ppl 13.64 | wps 40165.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25600 | lr 0.000197642 | gnorm 1.041 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 41689
KL Stats: Epoch 249 Divergences: Uniform: 5.616968196014483 Unigram: 5.1673387387168015
2022-03-14 21:57:23 | INFO | fairseq.trainer | begin training epoch 250
2022-03-14 21:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:00:01 | INFO | train_inner | epoch 250:    100 / 103 loss=3.766, ppl=13.61, wps=40123.6, ups=0.61, wpb=65530.9, bsz=128, num_updates=25700, lr=0.000197257, gnorm=1.057, loss_scale=16, train_wall=154, gb_free=20.8, wall=41847
2022-03-14 22:00:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:00:09 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 9.524 | ppl 736.48 | wps 66614.5 | wpb 2040.3 | bsz 4 | num_updates 25703 | best_loss 7.537
2022-03-14 22:00:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 25703 updates
2022-03-14 22:00:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:00:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 250 @ 25703 updates, score 9.524) (writing took 0.8788427710533142 seconds)
2022-03-14 22:00:10 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-14 22:00:10 | INFO | train | epoch 250 | loss 3.768 | ppl 13.62 | wps 40192.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25703 | lr 0.000197246 | gnorm 1.059 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41856
KL Stats: Epoch 250 Divergences: Uniform: 5.617758664983123 Unigram: 5.166934815940282
2022-03-14 22:00:10 | INFO | fairseq.trainer | begin training epoch 251
2022-03-14 22:00:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:02:44 | INFO | train_inner | epoch 251:     97 / 103 loss=3.763, ppl=13.57, wps=40187.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25800, lr=0.000196875, gnorm=1.047, loss_scale=16, train_wall=153, gb_free=20.8, wall=42010
2022-03-14 22:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:02:56 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 9.543 | ppl 745.81 | wps 66234.4 | wpb 2040.3 | bsz 4 | num_updates 25806 | best_loss 7.537
2022-03-14 22:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 25806 updates
2022-03-14 22:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:02:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 251 @ 25806 updates, score 9.543) (writing took 0.8922135969623923 seconds)
2022-03-14 22:02:57 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-14 22:02:57 | INFO | train | epoch 251 | loss 3.764 | ppl 13.59 | wps 40199.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25806 | lr 0.000196852 | gnorm 1.047 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42023
KL Stats: Epoch 251 Divergences: Uniform: 5.620875819249379 Unigram: 5.172997134378089
2022-03-14 22:02:57 | INFO | fairseq.trainer | begin training epoch 252
2022-03-14 22:02:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:05:27 | INFO | train_inner | epoch 252:     94 / 103 loss=3.761, ppl=13.56, wps=40133.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25900, lr=0.000196494, gnorm=1.054, loss_scale=16, train_wall=153, gb_free=20.8, wall=42173
2022-03-14 22:05:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:05:44 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 9.544 | ppl 746.55 | wps 66188.6 | wpb 2040.3 | bsz 4 | num_updates 25909 | best_loss 7.537
2022-03-14 22:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 25909 updates
2022-03-14 22:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:05:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:05:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 252 @ 25909 updates, score 9.544) (writing took 0.9722710810601711 seconds)
2022-03-14 22:05:45 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-14 22:05:45 | INFO | train | epoch 252 | loss 3.763 | ppl 13.57 | wps 40156.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25909 | lr 0.00019646 | gnorm 1.058 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42191
KL Stats: Epoch 252 Divergences: Uniform: 5.621508251581616 Unigram: 5.173766435354499
2022-03-14 22:05:45 | INFO | fairseq.trainer | begin training epoch 253
2022-03-14 22:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:08:09 | INFO | train_inner | epoch 253:     91 / 103 loss=3.758, ppl=13.53, wps=40104.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26000, lr=0.000196116, gnorm=1.058, loss_scale=16, train_wall=153, gb_free=20.8, wall=42335
2022-03-14 22:08:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:08:31 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 9.514 | ppl 731.37 | wps 66056.7 | wpb 2040.3 | bsz 4 | num_updates 26012 | best_loss 7.537
2022-03-14 22:08:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 26012 updates
2022-03-14 22:08:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:08:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:08:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 253 @ 26012 updates, score 9.514) (writing took 0.8915569689124823 seconds)
2022-03-14 22:08:32 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-14 22:08:32 | INFO | train | epoch 253 | loss 3.76 | ppl 13.55 | wps 40154.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26012 | lr 0.000196071 | gnorm 1.057 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42358
KL Stats: Epoch 253 Divergences: Uniform: 5.621890298773937 Unigram: 5.17505372437803
2022-03-14 22:08:32 | INFO | fairseq.trainer | begin training epoch 254
2022-03-14 22:08:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:10:52 | INFO | train_inner | epoch 254:     88 / 103 loss=3.757, ppl=13.52, wps=40144.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26100, lr=0.00019574, gnorm=1.069, loss_scale=16, train_wall=153, gb_free=20.8, wall=42498
2022-03-14 22:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:11:19 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 9.533 | ppl 740.71 | wps 66565.1 | wpb 2040.3 | bsz 4 | num_updates 26115 | best_loss 7.537
2022-03-14 22:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 26115 updates
2022-03-14 22:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:11:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 254 @ 26115 updates, score 9.533) (writing took 0.9078833013772964 seconds)
2022-03-14 22:11:20 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-14 22:11:20 | INFO | train | epoch 254 | loss 3.758 | ppl 13.53 | wps 40186.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26115 | lr 0.000195684 | gnorm 1.067 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42526
KL Stats: Epoch 254 Divergences: Uniform: 5.622450152807877 Unigram: 5.176941709739402
2022-03-14 22:11:20 | INFO | fairseq.trainer | begin training epoch 255
2022-03-14 22:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:11:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:12:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:13:38 | INFO | train_inner | epoch 255:     87 / 103 loss=3.759, ppl=13.54, wps=39391.1, ups=0.6, wpb=65305.6, bsz=127.6, num_updates=26200, lr=0.000195366, gnorm=1.052, loss_scale=8, train_wall=156, gb_free=20.8, wall=42664
2022-03-14 22:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:14:06 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 9.543 | ppl 745.85 | wps 66186.2 | wpb 2040.3 | bsz 4 | num_updates 26216 | best_loss 7.537
2022-03-14 22:14:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 26216 updates
2022-03-14 22:14:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:14:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:14:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 255 @ 26216 updates, score 9.543) (writing took 0.9265226684510708 seconds)
2022-03-14 22:14:07 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-14 22:14:07 | INFO | train | epoch 255 | loss 3.755 | ppl 13.5 | wps 39397.2 | ups 0.6 | wpb 65307.9 | bsz 127.6 | num_updates 26216 | lr 0.000195307 | gnorm 1.047 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 42693
KL Stats: Epoch 255 Divergences: Uniform: 5.625153645455464 Unigram: 5.182159441645946
2022-03-14 22:14:07 | INFO | fairseq.trainer | begin training epoch 256
2022-03-14 22:14:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:16:20 | INFO | train_inner | epoch 256:     84 / 103 loss=3.749, ppl=13.44, wps=40155.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26300, lr=0.000194994, gnorm=1.047, loss_scale=8, train_wall=153, gb_free=20.8, wall=42826
2022-03-14 22:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:16:54 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 9.546 | ppl 747.68 | wps 66233.7 | wpb 2040.3 | bsz 4 | num_updates 26319 | best_loss 7.537
2022-03-14 22:16:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 26319 updates
2022-03-14 22:16:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:16:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 256 @ 26319 updates, score 9.546) (writing took 0.946555782109499 seconds)
2022-03-14 22:16:55 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-14 22:16:55 | INFO | train | epoch 256 | loss 3.754 | ppl 13.49 | wps 40195.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26319 | lr 0.000194924 | gnorm 1.057 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 42861
KL Stats: Epoch 256 Divergences: Uniform: 5.62545556141726 Unigram: 5.183047102549007
2022-03-14 22:16:55 | INFO | fairseq.trainer | begin training epoch 257
2022-03-14 22:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:19:03 | INFO | train_inner | epoch 257:     81 / 103 loss=3.752, ppl=13.48, wps=40172.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=26400, lr=0.000194625, gnorm=1.07, loss_scale=8, train_wall=153, gb_free=20.8, wall=42989
2022-03-14 22:19:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:19:41 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 9.557 | ppl 753.45 | wps 66115.3 | wpb 2040.3 | bsz 4 | num_updates 26422 | best_loss 7.537
2022-03-14 22:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 26422 updates
2022-03-14 22:19:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:19:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:19:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 257 @ 26422 updates, score 9.557) (writing took 0.9130340106785297 seconds)
2022-03-14 22:19:42 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-14 22:19:42 | INFO | train | epoch 257 | loss 3.752 | ppl 13.47 | wps 40196.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26422 | lr 0.000194544 | gnorm 1.066 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43028
KL Stats: Epoch 257 Divergences: Uniform: 5.62714694697614 Unigram: 5.186553060118439
2022-03-14 22:19:42 | INFO | fairseq.trainer | begin training epoch 258
2022-03-14 22:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:21:46 | INFO | train_inner | epoch 258:     78 / 103 loss=3.749, ppl=13.44, wps=40129.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=26500, lr=0.000194257, gnorm=1.056, loss_scale=8, train_wall=153, gb_free=20.8, wall=43152
2022-03-14 22:22:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:22:28 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 9.524 | ppl 736.3 | wps 66046.2 | wpb 2040.3 | bsz 4 | num_updates 26525 | best_loss 7.537
2022-03-14 22:22:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 26525 updates
2022-03-14 22:22:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:22:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:22:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 258 @ 26525 updates, score 9.524) (writing took 0.932512036524713 seconds)
2022-03-14 22:22:29 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-14 22:22:29 | INFO | train | epoch 258 | loss 3.75 | ppl 13.46 | wps 40156.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26525 | lr 0.000194166 | gnorm 1.052 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43195
KL Stats: Epoch 258 Divergences: Uniform: 5.626508793299494 Unigram: 5.185634129430582
2022-03-14 22:22:29 | INFO | fairseq.trainer | begin training epoch 259
2022-03-14 22:22:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:24:28 | INFO | train_inner | epoch 259:     75 / 103 loss=3.748, ppl=13.44, wps=40146.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26600, lr=0.000193892, gnorm=1.054, loss_scale=8, train_wall=153, gb_free=20.8, wall=43314
2022-03-14 22:25:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:25:16 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 9.542 | ppl 745.58 | wps 66248.5 | wpb 2040.3 | bsz 4 | num_updates 26628 | best_loss 7.537
2022-03-14 22:25:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 26628 updates
2022-03-14 22:25:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:25:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:25:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 259 @ 26628 updates, score 9.542) (writing took 0.9047070927917957 seconds)
2022-03-14 22:25:17 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-14 22:25:17 | INFO | train | epoch 259 | loss 3.747 | ppl 13.43 | wps 40213.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26628 | lr 0.00019379 | gnorm 1.061 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43363
KL Stats: Epoch 259 Divergences: Uniform: 5.6285335188624 Unigram: 5.188827872407836
2022-03-14 22:25:17 | INFO | fairseq.trainer | begin training epoch 260
2022-03-14 22:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:27:11 | INFO | train_inner | epoch 260:     72 / 103 loss=3.744, ppl=13.4, wps=40174.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=26700, lr=0.000193528, gnorm=1.05, loss_scale=16, train_wall=153, gb_free=20.8, wall=43477
2022-03-14 22:28:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:28:03 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 9.569 | ppl 759.37 | wps 66042.3 | wpb 2040.3 | bsz 4 | num_updates 26731 | best_loss 7.537
2022-03-14 22:28:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 26731 updates
2022-03-14 22:28:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:28:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:28:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 260 @ 26731 updates, score 9.569) (writing took 0.9157518167048693 seconds)
2022-03-14 22:28:04 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-14 22:28:04 | INFO | train | epoch 260 | loss 3.746 | ppl 13.42 | wps 40181 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26731 | lr 0.000193416 | gnorm 1.042 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43530
KL Stats: Epoch 260 Divergences: Uniform: 5.631243102679405 Unigram: 5.191700263267144
2022-03-14 22:28:04 | INFO | fairseq.trainer | begin training epoch 261
2022-03-14 22:28:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:29:54 | INFO | train_inner | epoch 261:     69 / 103 loss=3.745, ppl=13.41, wps=40128.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=26800, lr=0.000193167, gnorm=1.049, loss_scale=16, train_wall=153, gb_free=20.8, wall=43640
2022-03-14 22:30:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:30:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:30:51 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 9.545 | ppl 747.03 | wps 66365.8 | wpb 2040.3 | bsz 4 | num_updates 26833 | best_loss 7.537
2022-03-14 22:30:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 26833 updates
2022-03-14 22:30:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 261 @ 26833 updates, score 9.545) (writing took 0.910634214989841 seconds)
2022-03-14 22:30:52 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-14 22:30:52 | INFO | train | epoch 261 | loss 3.744 | ppl 13.39 | wps 39773.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 26833 | lr 0.000193048 | gnorm 1.048 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43698
KL Stats: Epoch 261 Divergences: Uniform: 5.6301968298488 Unigram: 5.193322092261811
2022-03-14 22:30:52 | INFO | fairseq.trainer | begin training epoch 262
2022-03-14 22:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:32:38 | INFO | train_inner | epoch 262:     67 / 103 loss=3.741, ppl=13.37, wps=39752, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26900, lr=0.000192807, gnorm=1.05, loss_scale=8, train_wall=155, gb_free=20.8, wall=43804
2022-03-14 22:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:33:38 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 9.57 | ppl 760.13 | wps 66420.5 | wpb 2040.3 | bsz 4 | num_updates 26936 | best_loss 7.537
2022-03-14 22:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 26936 updates
2022-03-14 22:33:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:33:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 262 @ 26936 updates, score 9.57) (writing took 0.8914880333468318 seconds)
2022-03-14 22:33:39 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-14 22:33:39 | INFO | train | epoch 262 | loss 3.741 | ppl 13.37 | wps 40184.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26936 | lr 0.000192679 | gnorm 1.052 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 43865
KL Stats: Epoch 262 Divergences: Uniform: 5.632881346797627 Unigram: 5.197854941502438
2022-03-14 22:33:39 | INFO | fairseq.trainer | begin training epoch 263
2022-03-14 22:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:35:21 | INFO | train_inner | epoch 263:     64 / 103 loss=3.739, ppl=13.36, wps=40148.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27000, lr=0.00019245, gnorm=1.059, loss_scale=8, train_wall=153, gb_free=20.8, wall=43967
2022-03-14 22:36:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:36:26 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 9.572 | ppl 761.24 | wps 66425.7 | wpb 2040.3 | bsz 4 | num_updates 27039 | best_loss 7.537
2022-03-14 22:36:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 27039 updates
2022-03-14 22:36:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:36:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:36:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 263 @ 27039 updates, score 9.572) (writing took 0.8735114606097341 seconds)
2022-03-14 22:36:26 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-14 22:36:26 | INFO | train | epoch 263 | loss 3.74 | ppl 13.36 | wps 40185.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27039 | lr 0.000192311 | gnorm 1.065 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44032
KL Stats: Epoch 263 Divergences: Uniform: 5.633205222311858 Unigram: 5.19921367051804
2022-03-14 22:36:26 | INFO | fairseq.trainer | begin training epoch 264
2022-03-14 22:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:38:03 | INFO | train_inner | epoch 264:     61 / 103 loss=3.737, ppl=13.33, wps=40166.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=27100, lr=0.000192095, gnorm=1.059, loss_scale=8, train_wall=153, gb_free=20.8, wall=44129
2022-03-14 22:39:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:39:13 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 9.576 | ppl 763.03 | wps 65778 | wpb 2040.3 | bsz 4 | num_updates 27142 | best_loss 7.537
2022-03-14 22:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 27142 updates
2022-03-14 22:39:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:39:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:39:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 264 @ 27142 updates, score 9.576) (writing took 0.8664350127801299 seconds)
2022-03-14 22:39:14 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-14 22:39:14 | INFO | train | epoch 264 | loss 3.738 | ppl 13.34 | wps 40197.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27142 | lr 0.000191946 | gnorm 1.057 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44200
KL Stats: Epoch 264 Divergences: Uniform: 5.635197731851435 Unigram: 5.200867951657238
2022-03-14 22:39:14 | INFO | fairseq.trainer | begin training epoch 265
2022-03-14 22:39:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:40:46 | INFO | train_inner | epoch 265:     58 / 103 loss=3.738, ppl=13.34, wps=40174.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27200, lr=0.000191741, gnorm=1.057, loss_scale=8, train_wall=153, gb_free=20.8, wall=44292
2022-03-14 22:41:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:42:00 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 9.568 | ppl 758.9 | wps 66419.2 | wpb 2040.3 | bsz 4 | num_updates 27245 | best_loss 7.537
2022-03-14 22:42:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 27245 updates
2022-03-14 22:42:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:42:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:42:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 265 @ 27245 updates, score 9.568) (writing took 0.9207313228398561 seconds)
2022-03-14 22:42:01 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-14 22:42:01 | INFO | train | epoch 265 | loss 3.735 | ppl 13.32 | wps 40199.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27245 | lr 0.000191583 | gnorm 1.056 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44367
KL Stats: Epoch 265 Divergences: Uniform: 5.633868368498847 Unigram: 5.201567619887728
2022-03-14 22:42:01 | INFO | fairseq.trainer | begin training epoch 266
2022-03-14 22:42:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:43:28 | INFO | train_inner | epoch 266:     55 / 103 loss=3.73, ppl=13.27, wps=40166.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=27300, lr=0.00019139, gnorm=1.044, loss_scale=8, train_wall=153, gb_free=20.8, wall=44454
2022-03-14 22:44:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:44:48 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 9.574 | ppl 762.3 | wps 66055.7 | wpb 2040.3 | bsz 4 | num_updates 27348 | best_loss 7.537
2022-03-14 22:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 27348 updates
2022-03-14 22:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:44:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:44:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 266 @ 27348 updates, score 9.574) (writing took 0.8561280844733119 seconds)
2022-03-14 22:44:48 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-14 22:44:48 | INFO | train | epoch 266 | loss 3.733 | ppl 13.3 | wps 40213.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27348 | lr 0.000191222 | gnorm 1.043 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44534
KL Stats: Epoch 266 Divergences: Uniform: 5.637578353797657 Unigram: 5.20548466608427
2022-03-14 22:44:48 | INFO | fairseq.trainer | begin training epoch 267
2022-03-14 22:44:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:45:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:46:12 | INFO | train_inner | epoch 267:     53 / 103 loss=3.737, ppl=13.33, wps=39798.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27400, lr=0.00019104, gnorm=1.062, loss_scale=8, train_wall=155, gb_free=20.8, wall=44618
2022-03-14 22:47:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:47:35 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 9.572 | ppl 761.22 | wps 66245.8 | wpb 2040.3 | bsz 4 | num_updates 27450 | best_loss 7.537
2022-03-14 22:47:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 27450 updates
2022-03-14 22:47:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:47:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:47:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 267 @ 27450 updates, score 9.572) (writing took 0.8791765328496695 seconds)
2022-03-14 22:47:36 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-14 22:47:36 | INFO | train | epoch 267 | loss 3.73 | ppl 13.27 | wps 39806 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27450 | lr 0.000190866 | gnorm 1.063 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44702
KL Stats: Epoch 267 Divergences: Uniform: 5.638426671899738 Unigram: 5.207738234550473
2022-03-14 22:47:36 | INFO | fairseq.trainer | begin training epoch 268
2022-03-14 22:47:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:48:55 | INFO | train_inner | epoch 268:     50 / 103 loss=3.726, ppl=13.24, wps=40131.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27500, lr=0.000190693, gnorm=1.057, loss_scale=8, train_wall=153, gb_free=20.8, wall=44781
2022-03-14 22:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:50:22 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 9.573 | ppl 761.59 | wps 66060.2 | wpb 2040.3 | bsz 4 | num_updates 27553 | best_loss 7.537
2022-03-14 22:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 27553 updates
2022-03-14 22:50:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:50:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:50:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 268 @ 27553 updates, score 9.573) (writing took 0.8513247305527329 seconds)
2022-03-14 22:50:23 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-14 22:50:23 | INFO | train | epoch 268 | loss 3.73 | ppl 13.27 | wps 40161.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27553 | lr 0.000190509 | gnorm 1.065 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 44869
KL Stats: Epoch 268 Divergences: Uniform: 5.638518386678075 Unigram: 5.208658803986819
2022-03-14 22:50:23 | INFO | fairseq.trainer | begin training epoch 269
2022-03-14 22:50:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:51:38 | INFO | train_inner | epoch 269:     47 / 103 loss=3.729, ppl=13.26, wps=40146.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27600, lr=0.000190347, gnorm=1.07, loss_scale=8, train_wall=153, gb_free=20.8, wall=44944
2022-03-14 22:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:53:10 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 9.565 | ppl 757.36 | wps 66044.4 | wpb 2040.3 | bsz 4 | num_updates 27656 | best_loss 7.537
2022-03-14 22:53:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 27656 updates
2022-03-14 22:53:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:53:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 269 @ 27656 updates, score 9.565) (writing took 0.9115799181163311 seconds)
2022-03-14 22:53:11 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-14 22:53:11 | INFO | train | epoch 269 | loss 3.727 | ppl 13.24 | wps 40172.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27656 | lr 0.000190154 | gnorm 1.069 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 45037
KL Stats: Epoch 269 Divergences: Uniform: 5.6405853815839855 Unigram: 5.210814003981225
2022-03-14 22:53:11 | INFO | fairseq.trainer | begin training epoch 270
2022-03-14 22:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:54:21 | INFO | train_inner | epoch 270:     44 / 103 loss=3.726, ppl=13.23, wps=40145.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=27700, lr=0.000190003, gnorm=1.074, loss_scale=8, train_wall=153, gb_free=20.8, wall=45107
2022-03-14 22:55:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:55:57 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 9.611 | ppl 781.77 | wps 66038.6 | wpb 2040.3 | bsz 4 | num_updates 27759 | best_loss 7.537
2022-03-14 22:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 27759 updates
2022-03-14 22:55:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:55:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:55:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 270 @ 27759 updates, score 9.611) (writing took 0.9323791805654764 seconds)
2022-03-14 22:55:58 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-14 22:55:58 | INFO | train | epoch 270 | loss 3.724 | ppl 13.21 | wps 40155.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27759 | lr 0.000189801 | gnorm 1.066 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 45204
KL Stats: Epoch 270 Divergences: Uniform: 5.642971655146608 Unigram: 5.214958950069382
2022-03-14 22:55:58 | INFO | fairseq.trainer | begin training epoch 271
2022-03-14 22:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:57:03 | INFO | train_inner | epoch 271:     41 / 103 loss=3.723, ppl=13.2, wps=40122.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27800, lr=0.000189661, gnorm=1.057, loss_scale=8, train_wall=153, gb_free=20.8, wall=45269
2022-03-14 22:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:58:45 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 9.594 | ppl 772.71 | wps 65715 | wpb 2040.3 | bsz 4 | num_updates 27862 | best_loss 7.537
2022-03-14 22:58:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 27862 updates
2022-03-14 22:58:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:58:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 22:58:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 271 @ 27862 updates, score 9.594) (writing took 0.9252883838489652 seconds)
2022-03-14 22:58:46 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-14 22:58:46 | INFO | train | epoch 271 | loss 3.723 | ppl 13.21 | wps 40150.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27862 | lr 0.00018945 | gnorm 1.06 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 45372
KL Stats: Epoch 271 Divergences: Uniform: 5.641436230518135 Unigram: 5.21359488672086
2022-03-14 22:58:46 | INFO | fairseq.trainer | begin training epoch 272
2022-03-14 22:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:59:46 | INFO | train_inner | epoch 272:     38 / 103 loss=3.725, ppl=13.22, wps=40113.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=27900, lr=0.000189321, gnorm=1.06, loss_scale=16, train_wall=153, gb_free=20.8, wall=45432
2022-03-14 22:59:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 23:01:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:01:32 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 9.593 | ppl 772.14 | wps 66249.7 | wpb 2040.3 | bsz 4 | num_updates 27964 | best_loss 7.537
2022-03-14 23:01:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 27964 updates
2022-03-14 23:01:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:01:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:01:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 272 @ 27964 updates, score 9.593) (writing took 0.8767317971214652 seconds)
2022-03-14 23:01:33 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-14 23:01:33 | INFO | train | epoch 272 | loss 3.721 | ppl 13.18 | wps 39791.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27964 | lr 0.000189104 | gnorm 1.061 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 45539
KL Stats: Epoch 272 Divergences: Uniform: 5.643476711103433 Unigram: 5.216960810176937
2022-03-14 23:01:33 | INFO | fairseq.trainer | begin training epoch 273
2022-03-14 23:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:02:30 | INFO | train_inner | epoch 273:     36 / 103 loss=3.717, ppl=13.15, wps=39775.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28000, lr=0.000188982, gnorm=1.064, loss_scale=8, train_wall=155, gb_free=20.8, wall=45596
2022-03-14 23:04:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:04:20 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 9.606 | ppl 779.19 | wps 66422 | wpb 2040.3 | bsz 4 | num_updates 28067 | best_loss 7.537
2022-03-14 23:04:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 28067 updates
2022-03-14 23:04:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:04:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:04:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 273 @ 28067 updates, score 9.606) (writing took 0.8920840509235859 seconds)
2022-03-14 23:04:20 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-14 23:04:20 | INFO | train | epoch 273 | loss 3.72 | ppl 13.17 | wps 40210.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28067 | lr 0.000188757 | gnorm 1.05 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 45707
KL Stats: Epoch 273 Divergences: Uniform: 5.645199364272493 Unigram: 5.2197078039822395
2022-03-14 23:04:20 | INFO | fairseq.trainer | begin training epoch 274
2022-03-14 23:04:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:05:13 | INFO | train_inner | epoch 274:     33 / 103 loss=3.721, ppl=13.19, wps=40175.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=28100, lr=0.000188646, gnorm=1.05, loss_scale=8, train_wall=153, gb_free=20.8, wall=45759
2022-03-14 23:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:07:07 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 9.582 | ppl 766.39 | wps 66221.9 | wpb 2040.3 | bsz 4 | num_updates 28170 | best_loss 7.537
2022-03-14 23:07:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 28170 updates
2022-03-14 23:07:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:07:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:07:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 274 @ 28170 updates, score 9.582) (writing took 0.9571656975895166 seconds)
2022-03-14 23:07:08 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-14 23:07:08 | INFO | train | epoch 274 | loss 3.718 | ppl 13.16 | wps 40179 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28170 | lr 0.000188411 | gnorm 1.059 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 45874
KL Stats: Epoch 274 Divergences: Uniform: 5.64397878587224 Unigram: 5.219868483688955
2022-03-14 23:07:08 | INFO | fairseq.trainer | begin training epoch 275
2022-03-14 23:07:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:07:56 | INFO | train_inner | epoch 275:     30 / 103 loss=3.72, ppl=13.17, wps=40139.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28200, lr=0.000188311, gnorm=1.059, loss_scale=8, train_wall=153, gb_free=20.8, wall=45922
2022-03-14 23:09:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:09:55 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 9.585 | ppl 767.78 | wps 65846.8 | wpb 2040.3 | bsz 4 | num_updates 28273 | best_loss 7.537
2022-03-14 23:09:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 28273 updates
2022-03-14 23:09:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 275 @ 28273 updates, score 9.585) (writing took 0.889111403375864 seconds)
2022-03-14 23:09:55 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-14 23:09:55 | INFO | train | epoch 275 | loss 3.716 | ppl 13.14 | wps 40163.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28273 | lr 0.000188068 | gnorm 1.067 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 46041
KL Stats: Epoch 275 Divergences: Uniform: 5.644266993616293 Unigram: 5.220638548236158
2022-03-14 23:09:55 | INFO | fairseq.trainer | begin training epoch 276
2022-03-14 23:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:10:38 | INFO | train_inner | epoch 276:     27 / 103 loss=3.714, ppl=13.13, wps=40123, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28300, lr=0.000187978, gnorm=1.068, loss_scale=8, train_wall=153, gb_free=20.8, wall=46084
2022-03-14 23:12:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:12:42 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 9.589 | ppl 770.18 | wps 65798.4 | wpb 2040.3 | bsz 4 | num_updates 28376 | best_loss 7.537
2022-03-14 23:12:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 28376 updates
2022-03-14 23:12:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:12:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:12:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 276 @ 28376 updates, score 9.589) (writing took 0.9250701144337654 seconds)
2022-03-14 23:12:43 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-14 23:12:43 | INFO | train | epoch 276 | loss 3.713 | ppl 13.11 | wps 40158 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28376 | lr 0.000187726 | gnorm 1.059 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 46209
KL Stats: Epoch 276 Divergences: Uniform: 5.646462560936387 Unigram: 5.224233981992182
2022-03-14 23:12:43 | INFO | fairseq.trainer | begin training epoch 277
2022-03-14 23:12:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:13:21 | INFO | train_inner | epoch 277:     24 / 103 loss=3.714, ppl=13.13, wps=40124.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28400, lr=0.000187647, gnorm=1.056, loss_scale=8, train_wall=153, gb_free=20.8, wall=46247
2022-03-14 23:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:15:30 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 9.6 | ppl 775.87 | wps 66038.1 | wpb 2040.3 | bsz 4 | num_updates 28479 | best_loss 7.537
2022-03-14 23:15:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 28479 updates
2022-03-14 23:15:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:15:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:15:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 277 @ 28479 updates, score 9.6) (writing took 0.9338942337781191 seconds)
2022-03-14 23:15:31 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-14 23:15:31 | INFO | train | epoch 277 | loss 3.712 | ppl 13.11 | wps 40140.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28479 | lr 0.000187386 | gnorm 1.057 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46377
KL Stats: Epoch 277 Divergences: Uniform: 5.648179603456004 Unigram: 5.227209256457336
2022-03-14 23:15:31 | INFO | fairseq.trainer | begin training epoch 278
2022-03-14 23:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:16:04 | INFO | train_inner | epoch 278:     21 / 103 loss=3.714, ppl=13.12, wps=40106.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=28500, lr=0.000187317, gnorm=1.061, loss_scale=16, train_wall=153, gb_free=20.8, wall=46410
2022-03-14 23:18:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:18:17 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 9.597 | ppl 774.39 | wps 65835.2 | wpb 2040.3 | bsz 4 | num_updates 28582 | best_loss 7.537
2022-03-14 23:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 28582 updates
2022-03-14 23:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:18:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 278 @ 28582 updates, score 9.597) (writing took 0.8744976604357362 seconds)
2022-03-14 23:18:18 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-14 23:18:18 | INFO | train | epoch 278 | loss 3.71 | ppl 13.08 | wps 40177 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28582 | lr 0.000187048 | gnorm 1.064 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46544
KL Stats: Epoch 278 Divergences: Uniform: 5.646454122584723 Unigram: 5.227025549391606
2022-03-14 23:18:18 | INFO | fairseq.trainer | begin training epoch 279
2022-03-14 23:18:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:18:47 | INFO | train_inner | epoch 279:     18 / 103 loss=3.709, ppl=13.08, wps=40157.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28600, lr=0.000186989, gnorm=1.062, loss_scale=16, train_wall=153, gb_free=20.8, wall=46573
2022-03-14 23:21:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:21:04 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 9.608 | ppl 780.27 | wps 66404.3 | wpb 2040.3 | bsz 4 | num_updates 28685 | best_loss 7.537
2022-03-14 23:21:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 28685 updates
2022-03-14 23:21:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:21:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:21:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 279 @ 28685 updates, score 9.608) (writing took 0.8887773053720593 seconds)
2022-03-14 23:21:05 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-14 23:21:05 | INFO | train | epoch 279 | loss 3.708 | ppl 13.07 | wps 40187.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28685 | lr 0.000186712 | gnorm 1.059 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46711
KL Stats: Epoch 279 Divergences: Uniform: 5.649327109148503 Unigram: 5.229581813945539
2022-03-14 23:21:05 | INFO | fairseq.trainer | begin training epoch 280
2022-03-14 23:21:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:21:29 | INFO | train_inner | epoch 280:     15 / 103 loss=3.711, ppl=13.1, wps=40146.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=28700, lr=0.000186663, gnorm=1.061, loss_scale=16, train_wall=153, gb_free=20.8, wall=46735
2022-03-14 23:23:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 23:23:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:23:52 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 9.604 | ppl 778.17 | wps 65873.7 | wpb 2040.3 | bsz 4 | num_updates 28787 | best_loss 7.537
2022-03-14 23:23:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 28787 updates
2022-03-14 23:23:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:23:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:23:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 280 @ 28787 updates, score 9.604) (writing took 0.9147515464574099 seconds)
2022-03-14 23:23:53 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-14 23:23:53 | INFO | train | epoch 280 | loss 3.706 | ppl 13.05 | wps 39786.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28787 | lr 0.000186381 | gnorm 1.053 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 46879
KL Stats: Epoch 280 Divergences: Uniform: 5.6497230310920585 Unigram: 5.230259713568903
2022-03-14 23:23:53 | INFO | fairseq.trainer | begin training epoch 281
2022-03-14 23:23:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:24:13 | INFO | train_inner | epoch 281:     13 / 103 loss=3.705, ppl=13.05, wps=39757.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28800, lr=0.000186339, gnorm=1.052, loss_scale=8, train_wall=155, gb_free=20.8, wall=46899
2022-03-14 23:26:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:26:39 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 9.611 | ppl 781.9 | wps 65992.5 | wpb 2040.3 | bsz 4 | num_updates 28890 | best_loss 7.537
2022-03-14 23:26:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 28890 updates
2022-03-14 23:26:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:26:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:26:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 281 @ 28890 updates, score 9.611) (writing took 0.8502298109233379 seconds)
2022-03-14 23:26:40 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-14 23:26:40 | INFO | train | epoch 281 | loss 3.705 | ppl 13.04 | wps 40187.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28890 | lr 0.000186049 | gnorm 1.066 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 47046
KL Stats: Epoch 281 Divergences: Uniform: 5.650779359907997 Unigram: 5.233674090835442
2022-03-14 23:26:40 | INFO | fairseq.trainer | begin training epoch 282
2022-03-14 23:26:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:26:56 | INFO | train_inner | epoch 282:     10 / 103 loss=3.707, ppl=13.06, wps=40151.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28900, lr=0.000186016, gnorm=1.071, loss_scale=8, train_wall=153, gb_free=20.8, wall=47062
2022-03-14 23:29:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:29:27 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 9.624 | ppl 788.8 | wps 66239.2 | wpb 2040.3 | bsz 4 | num_updates 28993 | best_loss 7.537
2022-03-14 23:29:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 28993 updates
2022-03-14 23:29:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:29:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:29:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 282 @ 28993 updates, score 9.624) (writing took 0.8902464639395475 seconds)
2022-03-14 23:29:28 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-14 23:29:28 | INFO | train | epoch 282 | loss 3.703 | ppl 13.02 | wps 40179.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28993 | lr 0.000185718 | gnorm 1.075 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 47214
KL Stats: Epoch 282 Divergences: Uniform: 5.6516786056917 Unigram: 5.23575122639641
2022-03-14 23:29:28 | INFO | fairseq.trainer | begin training epoch 283
2022-03-14 23:29:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:29:39 | INFO | train_inner | epoch 283:      7 / 103 loss=3.705, ppl=13.04, wps=40152.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29000, lr=0.000185695, gnorm=1.071, loss_scale=8, train_wall=153, gb_free=20.8, wall=47225
2022-03-14 23:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:32:14 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 9.61 | ppl 781.25 | wps 66027.5 | wpb 2040.3 | bsz 4 | num_updates 29096 | best_loss 7.537
2022-03-14 23:32:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 29096 updates
2022-03-14 23:32:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:32:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:32:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 283 @ 29096 updates, score 9.61) (writing took 0.8721752595156431 seconds)
2022-03-14 23:32:15 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-14 23:32:15 | INFO | train | epoch 283 | loss 3.701 | ppl 13 | wps 40204.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29096 | lr 0.000185389 | gnorm 1.076 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 47381
KL Stats: Epoch 283 Divergences: Uniform: 5.6531031717663085 Unigram: 5.2381286587422276
2022-03-14 23:32:15 | INFO | fairseq.trainer | begin training epoch 284
2022-03-14 23:32:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:32:21 | INFO | train_inner | epoch 284:      4 / 103 loss=3.703, ppl=13.02, wps=40168, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29100, lr=0.000185376, gnorm=1.078, loss_scale=8, train_wall=153, gb_free=20.8, wall=47387
2022-03-14 23:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:35:01 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 9.623 | ppl 788.56 | wps 66065.4 | wpb 2040.3 | bsz 4 | num_updates 29199 | best_loss 7.537
2022-03-14 23:35:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 29199 updates
2022-03-14 23:35:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:35:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:35:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 284 @ 29199 updates, score 9.623) (writing took 0.9122421629726887 seconds)
2022-03-14 23:35:02 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-14 23:35:02 | INFO | train | epoch 284 | loss 3.699 | ppl 12.99 | wps 40188.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29199 | lr 0.000185061 | gnorm 1.058 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 47548
KL Stats: Epoch 284 Divergences: Uniform: 5.654296013992383 Unigram: 5.241461814383717
2022-03-14 23:35:02 | INFO | fairseq.trainer | begin training epoch 285
2022-03-14 23:35:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:35:04 | INFO | train_inner | epoch 285:      1 / 103 loss=3.7, ppl=12.99, wps=40156.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29200, lr=0.000185058, gnorm=1.058, loss_scale=8, train_wall=153, gb_free=20.8, wall=47550
2022-03-14 23:37:43 | INFO | train_inner | epoch 285:    101 / 103 loss=3.697, ppl=12.97, wps=41313.5, ups=0.63, wpb=65530.9, bsz=128, num_updates=29300, lr=0.000184742, gnorm=1.07, loss_scale=16, train_wall=154, gb_free=20.8, wall=47709
2022-03-14 23:37:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:37:49 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 9.609 | ppl 780.91 | wps 66399.6 | wpb 2040.3 | bsz 4 | num_updates 29302 | best_loss 7.537
2022-03-14 23:37:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 29302 updates
2022-03-14 23:37:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:37:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 285 @ 29302 updates, score 9.609) (writing took 0.8708542492240667 seconds)
2022-03-14 23:37:50 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-14 23:37:50 | INFO | train | epoch 285 | loss 3.697 | ppl 12.97 | wps 40200.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29302 | lr 0.000184736 | gnorm 1.071 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47716
KL Stats: Epoch 285 Divergences: Uniform: 5.654291553644627 Unigram: 5.2396491896365225
2022-03-14 23:37:50 | INFO | fairseq.trainer | begin training epoch 286
2022-03-14 23:37:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:40:25 | INFO | train_inner | epoch 286:     98 / 103 loss=3.692, ppl=12.93, wps=40203, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29400, lr=0.000184428, gnorm=1.067, loss_scale=16, train_wall=153, gb_free=20.8, wall=47871
2022-03-14 23:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:40:36 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 9.605 | ppl 778.5 | wps 66198.6 | wpb 2040.3 | bsz 4 | num_updates 29405 | best_loss 7.537
2022-03-14 23:40:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 29405 updates
2022-03-14 23:40:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:40:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:40:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 286 @ 29405 updates, score 9.605) (writing took 0.8820142652839422 seconds)
2022-03-14 23:40:37 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-14 23:40:37 | INFO | train | epoch 286 | loss 3.694 | ppl 12.95 | wps 40232.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29405 | lr 0.000184412 | gnorm 1.067 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47883
KL Stats: Epoch 286 Divergences: Uniform: 5.656663967748476 Unigram: 5.244892871165021
2022-03-14 23:40:37 | INFO | fairseq.trainer | begin training epoch 287
2022-03-14 23:40:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:43:08 | INFO | train_inner | epoch 287:     95 / 103 loss=3.693, ppl=12.93, wps=40195, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=29500, lr=0.000184115, gnorm=1.062, loss_scale=16, train_wall=153, gb_free=20.8, wall=48034
2022-03-14 23:43:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:43:23 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 9.628 | ppl 791.37 | wps 66128.4 | wpb 2040.3 | bsz 4 | num_updates 29508 | best_loss 7.537
2022-03-14 23:43:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 29508 updates
2022-03-14 23:43:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:43:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:43:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 287 @ 29508 updates, score 9.628) (writing took 0.9016301622614264 seconds)
2022-03-14 23:43:24 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-14 23:43:24 | INFO | train | epoch 287 | loss 3.693 | ppl 12.93 | wps 40219.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29508 | lr 0.00018409 | gnorm 1.064 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48050
KL Stats: Epoch 287 Divergences: Uniform: 5.657923042462914 Unigram: 5.2470057237406955
2022-03-14 23:43:24 | INFO | fairseq.trainer | begin training epoch 288
2022-03-14 23:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:45:50 | INFO | train_inner | epoch 288:     92 / 103 loss=3.689, ppl=12.89, wps=40159.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=29600, lr=0.000183804, gnorm=1.058, loss_scale=16, train_wall=153, gb_free=20.8, wall=48196
2022-03-14 23:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:46:11 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 9.613 | ppl 783.3 | wps 66207.7 | wpb 2040.3 | bsz 4 | num_updates 29611 | best_loss 7.537
2022-03-14 23:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 29611 updates
2022-03-14 23:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:46:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:46:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 288 @ 29611 updates, score 9.613) (writing took 0.9246036326512694 seconds)
2022-03-14 23:46:12 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-14 23:46:12 | INFO | train | epoch 288 | loss 3.691 | ppl 12.91 | wps 40187.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29611 | lr 0.00018377 | gnorm 1.058 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48218
KL Stats: Epoch 288 Divergences: Uniform: 5.658755428486775 Unigram: 5.248734384461684
2022-03-14 23:46:12 | INFO | fairseq.trainer | begin training epoch 289
2022-03-14 23:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:48:33 | INFO | train_inner | epoch 289:     89 / 103 loss=3.688, ppl=12.89, wps=40176.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29700, lr=0.000183494, gnorm=1.058, loss_scale=16, train_wall=153, gb_free=20.8, wall=48359
2022-03-14 23:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:48:58 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 9.627 | ppl 790.51 | wps 66127.8 | wpb 2040.3 | bsz 4 | num_updates 29714 | best_loss 7.537
2022-03-14 23:48:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 29714 updates
2022-03-14 23:48:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:48:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:48:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 289 @ 29714 updates, score 9.627) (writing took 0.8865663139149547 seconds)
2022-03-14 23:48:59 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-14 23:48:59 | INFO | train | epoch 289 | loss 3.69 | ppl 12.91 | wps 40219.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29714 | lr 0.000183451 | gnorm 1.057 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48385
KL Stats: Epoch 289 Divergences: Uniform: 5.657579164270006 Unigram: 5.24801169911392
2022-03-14 23:48:59 | INFO | fairseq.trainer | begin training epoch 290
2022-03-14 23:48:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:50:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 23:51:17 | INFO | train_inner | epoch 290:     87 / 103 loss=3.686, ppl=12.87, wps=39797.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29800, lr=0.000183186, gnorm=1.07, loss_scale=8, train_wall=155, gb_free=20.8, wall=48523
2022-03-14 23:51:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:51:45 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 9.625 | ppl 789.83 | wps 66433.4 | wpb 2040.3 | bsz 4 | num_updates 29816 | best_loss 7.537
2022-03-14 23:51:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 29816 updates
2022-03-14 23:51:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:51:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:51:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 290 @ 29816 updates, score 9.625) (writing took 0.9105685809627175 seconds)
2022-03-14 23:51:46 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-14 23:51:46 | INFO | train | epoch 290 | loss 3.687 | ppl 12.88 | wps 39824.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 29816 | lr 0.000183137 | gnorm 1.071 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 48552
KL Stats: Epoch 290 Divergences: Uniform: 5.659451003388562 Unigram: 5.250822587765591
2022-03-14 23:51:46 | INFO | fairseq.trainer | begin training epoch 291
2022-03-14 23:51:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:53:59 | INFO | train_inner | epoch 291:     84 / 103 loss=3.686, ppl=12.87, wps=40183.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29900, lr=0.000182879, gnorm=1.057, loss_scale=8, train_wall=153, gb_free=20.8, wall=48685
2022-03-14 23:54:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:54:32 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 9.615 | ppl 784.39 | wps 66086.7 | wpb 2040.3 | bsz 4 | num_updates 29919 | best_loss 7.537
2022-03-14 23:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 29919 updates
2022-03-14 23:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:54:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:54:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 291 @ 29919 updates, score 9.615) (writing took 0.8859843434765935 seconds)
2022-03-14 23:54:33 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-14 23:54:33 | INFO | train | epoch 291 | loss 3.686 | ppl 12.87 | wps 40216.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29919 | lr 0.000182821 | gnorm 1.06 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 48719
KL Stats: Epoch 291 Divergences: Uniform: 5.660604312078792 Unigram: 5.251682131235193
2022-03-14 23:54:33 | INFO | fairseq.trainer | begin training epoch 292
2022-03-14 23:54:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:56:42 | INFO | train_inner | epoch 292:     81 / 103 loss=3.685, ppl=12.87, wps=40163, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30000, lr=0.000182574, gnorm=1.077, loss_scale=8, train_wall=153, gb_free=20.8, wall=48848
2022-03-14 23:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:57:20 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 9.65 | ppl 803.28 | wps 66430.6 | wpb 2040.3 | bsz 4 | num_updates 30022 | best_loss 7.537
2022-03-14 23:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 30022 updates
2022-03-14 23:57:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-14 23:57:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 292 @ 30022 updates, score 9.65) (writing took 0.9229140821844339 seconds)
2022-03-14 23:57:21 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-14 23:57:21 | INFO | train | epoch 292 | loss 3.685 | ppl 12.86 | wps 40192.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30022 | lr 0.000182507 | gnorm 1.071 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 48887
KL Stats: Epoch 292 Divergences: Uniform: 5.660991373654892 Unigram: 5.255594419652638
2022-03-14 23:57:21 | INFO | fairseq.trainer | begin training epoch 293
2022-03-14 23:57:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:59:24 | INFO | train_inner | epoch 293:     78 / 103 loss=3.683, ppl=12.85, wps=40175.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30100, lr=0.000182271, gnorm=1.066, loss_scale=8, train_wall=153, gb_free=20.8, wall=49010
2022-03-15 00:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:00:07 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 9.628 | ppl 790.99 | wps 66287.5 | wpb 2040.3 | bsz 4 | num_updates 30125 | best_loss 7.537
2022-03-15 00:00:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 30125 updates
2022-03-15 00:00:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:00:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:00:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 293 @ 30125 updates, score 9.628) (writing took 0.8619355857372284 seconds)
2022-03-15 00:00:08 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-15 00:00:08 | INFO | train | epoch 293 | loss 3.683 | ppl 12.84 | wps 40199.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30125 | lr 0.000182195 | gnorm 1.074 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 49054
KL Stats: Epoch 293 Divergences: Uniform: 5.661297387014026 Unigram: 5.25560379112499
2022-03-15 00:00:08 | INFO | fairseq.trainer | begin training epoch 294
2022-03-15 00:00:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:02:07 | INFO | train_inner | epoch 294:     75 / 103 loss=3.679, ppl=12.81, wps=40151.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=30200, lr=0.000181969, gnorm=1.073, loss_scale=8, train_wall=153, gb_free=20.8, wall=49173
2022-03-15 00:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:02:55 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 9.622 | ppl 788.01 | wps 66052.6 | wpb 2040.3 | bsz 4 | num_updates 30228 | best_loss 7.537
2022-03-15 00:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 30228 updates
2022-03-15 00:02:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 294 @ 30228 updates, score 9.622) (writing took 0.8831898989155889 seconds)
2022-03-15 00:02:55 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-15 00:02:55 | INFO | train | epoch 294 | loss 3.681 | ppl 12.83 | wps 40191.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30228 | lr 0.000181884 | gnorm 1.071 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 49221
KL Stats: Epoch 294 Divergences: Uniform: 5.662937658154908 Unigram: 5.258219947127482
2022-03-15 00:02:55 | INFO | fairseq.trainer | begin training epoch 295
2022-03-15 00:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:04:50 | INFO | train_inner | epoch 295:     72 / 103 loss=3.678, ppl=12.8, wps=40127.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=30300, lr=0.000181668, gnorm=1.069, loss_scale=16, train_wall=153, gb_free=20.8, wall=49336
2022-03-15 00:05:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:05:42 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 9.638 | ppl 796.54 | wps 66159 | wpb 2040.3 | bsz 4 | num_updates 30331 | best_loss 7.537
2022-03-15 00:05:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 30331 updates
2022-03-15 00:05:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:05:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:05:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 295 @ 30331 updates, score 9.638) (writing took 0.9066601376980543 seconds)
2022-03-15 00:05:43 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-15 00:05:43 | INFO | train | epoch 295 | loss 3.679 | ppl 12.8 | wps 40153.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 30331 | lr 0.000181575 | gnorm 1.065 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 49389
KL Stats: Epoch 295 Divergences: Uniform: 5.662777560684075 Unigram: 5.2619725802927695
2022-03-15 00:05:43 | INFO | fairseq.trainer | begin training epoch 296
2022-03-15 00:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:07:33 | INFO | train_inner | epoch 296:     69 / 103 loss=3.677, ppl=12.79, wps=40113.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=30400, lr=0.000181369, gnorm=1.065, loss_scale=16, train_wall=153, gb_free=20.8, wall=49499
2022-03-15 00:08:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:08:30 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 9.634 | ppl 794.51 | wps 66375.6 | wpb 2040.3 | bsz 4 | num_updates 30434 | best_loss 7.537
2022-03-15 00:08:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 30434 updates
2022-03-15 00:08:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:08:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 296 @ 30434 updates, score 9.634) (writing took 0.8739015990868211 seconds)
2022-03-15 00:08:31 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-15 00:08:31 | INFO | train | epoch 296 | loss 3.677 | ppl 12.79 | wps 40141.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 30434 | lr 0.000181268 | gnorm 1.061 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 49557
KL Stats: Epoch 296 Divergences: Uniform: 5.665977584513376 Unigram: 5.262620966379236
2022-03-15 00:08:31 | INFO | fairseq.trainer | begin training epoch 297
2022-03-15 00:08:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:10:15 | INFO | train_inner | epoch 297:     66 / 103 loss=3.676, ppl=12.78, wps=40129.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=30500, lr=0.000181071, gnorm=1.056, loss_scale=16, train_wall=153, gb_free=20.8, wall=49661
2022-03-15 00:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:11:17 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 9.622 | ppl 787.81 | wps 66050.5 | wpb 2040.3 | bsz 4 | num_updates 30537 | best_loss 7.537
2022-03-15 00:11:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 30537 updates
2022-03-15 00:11:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:11:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:11:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 297 @ 30537 updates, score 9.622) (writing took 0.8896943647414446 seconds)
2022-03-15 00:11:18 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-15 00:11:18 | INFO | train | epoch 297 | loss 3.677 | ppl 12.79 | wps 40158.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 30537 | lr 0.000180962 | gnorm 1.06 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 49724
KL Stats: Epoch 297 Divergences: Uniform: 5.663780633436051 Unigram: 5.262104863162951
2022-03-15 00:11:18 | INFO | fairseq.trainer | begin training epoch 298
2022-03-15 00:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:12:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 00:13:00 | INFO | train_inner | epoch 298:     64 / 103 loss=3.676, ppl=12.78, wps=39724.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=30600, lr=0.000180775, gnorm=1.067, loss_scale=8, train_wall=155, gb_free=20.8, wall=49826
2022-03-15 00:14:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:14:05 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 9.638 | ppl 796.75 | wps 66253.4 | wpb 2040.3 | bsz 4 | num_updates 30639 | best_loss 7.537
2022-03-15 00:14:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 30639 updates
2022-03-15 00:14:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:14:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 298 @ 30639 updates, score 9.638) (writing took 0.900873102247715 seconds)
2022-03-15 00:14:06 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-15 00:14:06 | INFO | train | epoch 298 | loss 3.673 | ppl 12.75 | wps 39763.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 30639 | lr 0.00018066 | gnorm 1.061 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 49892
KL Stats: Epoch 298 Divergences: Uniform: 5.666882596396488 Unigram: 5.266229299676467
2022-03-15 00:14:06 | INFO | fairseq.trainer | begin training epoch 299
2022-03-15 00:14:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:15:42 | INFO | train_inner | epoch 299:     61 / 103 loss=3.672, ppl=12.74, wps=40130, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=30700, lr=0.000180481, gnorm=1.062, loss_scale=8, train_wall=153, gb_free=20.8, wall=49989
2022-03-15 00:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:16:52 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 9.649 | ppl 802.76 | wps 66001.6 | wpb 2040.3 | bsz 4 | num_updates 30742 | best_loss 7.537
2022-03-15 00:16:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 30742 updates
2022-03-15 00:16:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:16:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 299 @ 30742 updates, score 9.649) (writing took 0.8620862634852529 seconds)
2022-03-15 00:16:53 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-15 00:16:53 | INFO | train | epoch 299 | loss 3.673 | ppl 12.76 | wps 40167.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30742 | lr 0.000180357 | gnorm 1.072 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 50059
KL Stats: Epoch 299 Divergences: Uniform: 5.665688342914812 Unigram: 5.266501735141498
2022-03-15 00:16:53 | INFO | fairseq.trainer | begin training epoch 300
2022-03-15 00:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:18:25 | INFO | train_inner | epoch 300:     58 / 103 loss=3.672, ppl=12.75, wps=40154, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=30800, lr=0.000180187, gnorm=1.07, loss_scale=8, train_wall=153, gb_free=20.8, wall=50151
2022-03-15 00:19:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:19:39 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 9.645 | ppl 800.55 | wps 65913.1 | wpb 2040.3 | bsz 4 | num_updates 30845 | best_loss 7.537
2022-03-15 00:19:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 30845 updates
2022-03-15 00:19:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 300 @ 30845 updates, score 9.645) (writing took 0.8707518950104713 seconds)
2022-03-15 00:19:40 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-15 00:19:40 | INFO | train | epoch 300 | loss 3.67 | ppl 12.73 | wps 40210 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30845 | lr 0.000180056 | gnorm 1.062 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 50226
KL Stats: Epoch 300 Divergences: Uniform: 5.6667644719596995 Unigram: 5.2686620589519695
2022-03-15 00:19:40 | INFO | fairseq.trainer | begin training epoch 301
2022-03-15 00:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:21:08 | INFO | train_inner | epoch 301:     55 / 103 loss=3.67, ppl=12.73, wps=40171.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=30900, lr=0.000179896, gnorm=1.056, loss_scale=8, train_wall=153, gb_free=20.8, wall=50314
2022-03-15 00:22:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:22:27 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 9.644 | ppl 799.82 | wps 66379.7 | wpb 2040.3 | bsz 4 | num_updates 30948 | best_loss 7.537
2022-03-15 00:22:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 30948 updates
2022-03-15 00:22:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:22:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:22:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 301 @ 30948 updates, score 9.644) (writing took 0.8912198301404715 seconds)
2022-03-15 00:22:28 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-15 00:22:28 | INFO | train | epoch 301 | loss 3.67 | ppl 12.72 | wps 40183.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30948 | lr 0.000179756 | gnorm 1.07 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 50394
KL Stats: Epoch 301 Divergences: Uniform: 5.668279078779259 Unigram: 5.270260331524606
2022-03-15 00:22:28 | INFO | fairseq.trainer | begin training epoch 302
2022-03-15 00:22:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:23:50 | INFO | train_inner | epoch 302:     52 / 103 loss=3.667, ppl=12.7, wps=40153.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=31000, lr=0.000179605, gnorm=1.072, loss_scale=8, train_wall=153, gb_free=20.8, wall=50476
2022-03-15 00:25:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:25:14 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 9.659 | ppl 808.54 | wps 65985.5 | wpb 2040.3 | bsz 4 | num_updates 31051 | best_loss 7.537
2022-03-15 00:25:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 31051 updates
2022-03-15 00:25:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:25:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:25:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 302 @ 31051 updates, score 9.659) (writing took 0.9181462023407221 seconds)
2022-03-15 00:25:15 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-15 00:25:15 | INFO | train | epoch 302 | loss 3.667 | ppl 12.7 | wps 40168 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 31051 | lr 0.000179458 | gnorm 1.064 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 50561
KL Stats: Epoch 302 Divergences: Uniform: 5.668505911986676 Unigram: 5.272643106200319
2022-03-15 00:25:15 | INFO | fairseq.trainer | begin training epoch 303
2022-03-15 00:25:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:26:33 | INFO | train_inner | epoch 303:     49 / 103 loss=3.667, ppl=12.7, wps=40132.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31100, lr=0.000179316, gnorm=1.065, loss_scale=16, train_wall=153, gb_free=20.8, wall=50639
2022-03-15 00:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:28:02 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 9.649 | ppl 802.83 | wps 66064.1 | wpb 2040.3 | bsz 4 | num_updates 31154 | best_loss 7.537
2022-03-15 00:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 31154 updates
2022-03-15 00:28:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:28:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:28:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 303 @ 31154 updates, score 9.649) (writing took 0.9118567649275064 seconds)
2022-03-15 00:28:03 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-15 00:28:03 | INFO | train | epoch 303 | loss 3.666 | ppl 12.69 | wps 40156.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31154 | lr 0.000179161 | gnorm 1.059 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 50729
KL Stats: Epoch 303 Divergences: Uniform: 5.669626501826251 Unigram: 5.273859629783616
2022-03-15 00:28:03 | INFO | fairseq.trainer | begin training epoch 304
2022-03-15 00:28:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:28:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 00:29:18 | INFO | train_inner | epoch 304:     47 / 103 loss=3.664, ppl=12.68, wps=39701.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31200, lr=0.000179029, gnorm=1.06, loss_scale=8, train_wall=155, gb_free=20.8, wall=50804
2022-03-15 00:30:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:30:50 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 9.67 | ppl 814.54 | wps 65844.5 | wpb 2040.3 | bsz 4 | num_updates 31256 | best_loss 7.537
2022-03-15 00:30:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 31256 updates
2022-03-15 00:30:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:30:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:30:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 304 @ 31256 updates, score 9.67) (writing took 0.9182428000494838 seconds)
2022-03-15 00:30:51 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-15 00:30:51 | INFO | train | epoch 304 | loss 3.665 | ppl 12.68 | wps 39712.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 31256 | lr 0.000178868 | gnorm 1.067 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 50897
KL Stats: Epoch 304 Divergences: Uniform: 5.668981004681996 Unigram: 5.275312088674901
2022-03-15 00:30:51 | INFO | fairseq.trainer | begin training epoch 305
2022-03-15 00:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:32:01 | INFO | train_inner | epoch 305:     44 / 103 loss=3.666, ppl=12.7, wps=40070, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=31300, lr=0.000178743, gnorm=1.073, loss_scale=8, train_wall=153, gb_free=20.8, wall=50967
2022-03-15 00:33:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:33:37 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 9.68 | ppl 820.11 | wps 66212.8 | wpb 2040.3 | bsz 4 | num_updates 31359 | best_loss 7.537
2022-03-15 00:33:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 31359 updates
2022-03-15 00:33:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:33:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 305 @ 31359 updates, score 9.68) (writing took 0.924850245937705 seconds)
2022-03-15 00:33:38 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-15 00:33:38 | INFO | train | epoch 305 | loss 3.663 | ppl 12.67 | wps 40101 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31359 | lr 0.000178574 | gnorm 1.069 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 51064
KL Stats: Epoch 305 Divergences: Uniform: 5.670790267893829 Unigram: 5.2776713149957075
2022-03-15 00:33:38 | INFO | fairseq.trainer | begin training epoch 306
2022-03-15 00:33:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:34:44 | INFO | train_inner | epoch 306:     41 / 103 loss=3.661, ppl=12.65, wps=40072.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31400, lr=0.000178458, gnorm=1.068, loss_scale=8, train_wall=153, gb_free=20.8, wall=51130
2022-03-15 00:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:36:25 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 9.697 | ppl 830.21 | wps 66228.6 | wpb 2040.3 | bsz 4 | num_updates 31462 | best_loss 7.537
2022-03-15 00:36:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 31462 updates
2022-03-15 00:36:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:36:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:36:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 306 @ 31462 updates, score 9.697) (writing took 0.9157768348231912 seconds)
2022-03-15 00:36:26 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-15 00:36:26 | INFO | train | epoch 306 | loss 3.66 | ppl 12.64 | wps 40128.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31462 | lr 0.000178282 | gnorm 1.066 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 51232
KL Stats: Epoch 306 Divergences: Uniform: 5.674396925263652 Unigram: 5.281025861492487
2022-03-15 00:36:26 | INFO | fairseq.trainer | begin training epoch 307
2022-03-15 00:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:37:26 | INFO | train_inner | epoch 307:     38 / 103 loss=3.66, ppl=12.64, wps=40104.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31500, lr=0.000178174, gnorm=1.063, loss_scale=8, train_wall=153, gb_free=20.8, wall=51292
2022-03-15 00:39:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:39:13 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 9.65 | ppl 803.36 | wps 66410.2 | wpb 2040.3 | bsz 4 | num_updates 31565 | best_loss 7.537
2022-03-15 00:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 31565 updates
2022-03-15 00:39:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:39:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:39:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 307 @ 31565 updates, score 9.65) (writing took 0.898951499722898 seconds)
2022-03-15 00:39:13 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-15 00:39:13 | INFO | train | epoch 307 | loss 3.658 | ppl 12.62 | wps 40149.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31565 | lr 0.000177991 | gnorm 1.068 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 51400
KL Stats: Epoch 307 Divergences: Uniform: 5.672651012262118 Unigram: 5.281269639237219
2022-03-15 00:39:13 | INFO | fairseq.trainer | begin training epoch 308
2022-03-15 00:39:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:40:09 | INFO | train_inner | epoch 308:     35 / 103 loss=3.659, ppl=12.63, wps=40132.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31600, lr=0.000177892, gnorm=1.068, loss_scale=8, train_wall=153, gb_free=20.8, wall=51455
2022-03-15 00:41:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:42:00 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 9.661 | ppl 809.62 | wps 66354.4 | wpb 2040.3 | bsz 4 | num_updates 31668 | best_loss 7.537
2022-03-15 00:42:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 31668 updates
2022-03-15 00:42:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:42:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:42:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 308 @ 31668 updates, score 9.661) (writing took 0.9020866844803095 seconds)
2022-03-15 00:42:01 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-15 00:42:01 | INFO | train | epoch 308 | loss 3.659 | ppl 12.63 | wps 40176.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 31668 | lr 0.000177701 | gnorm 1.061 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 51567
KL Stats: Epoch 308 Divergences: Uniform: 5.674463206435354 Unigram: 5.280857324828204
2022-03-15 00:42:01 | INFO | fairseq.trainer | begin training epoch 309
2022-03-15 00:42:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:42:52 | INFO | train_inner | epoch 309:     32 / 103 loss=3.657, ppl=12.62, wps=40142.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31700, lr=0.000177611, gnorm=1.077, loss_scale=16, train_wall=153, gb_free=20.8, wall=51618
2022-03-15 00:44:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:44:48 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 9.663 | ppl 810.74 | wps 66123.8 | wpb 2040.3 | bsz 4 | num_updates 31771 | best_loss 7.537
2022-03-15 00:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 31771 updates
2022-03-15 00:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:44:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:44:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 309 @ 31771 updates, score 9.663) (writing took 0.8950538579374552 seconds)
2022-03-15 00:44:49 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-15 00:44:49 | INFO | train | epoch 309 | loss 3.656 | ppl 12.61 | wps 40140.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31771 | lr 0.000177413 | gnorm 1.087 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 51735
KL Stats: Epoch 309 Divergences: Uniform: 5.674426341223428 Unigram: 5.282661110112316
2022-03-15 00:44:49 | INFO | fairseq.trainer | begin training epoch 310
2022-03-15 00:44:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:45:35 | INFO | train_inner | epoch 310:     29 / 103 loss=3.657, ppl=12.62, wps=40100.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=31800, lr=0.000177332, gnorm=1.07, loss_scale=16, train_wall=153, gb_free=20.8, wall=51781
2022-03-15 00:45:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 00:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:47:35 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 9.639 | ppl 797.16 | wps 66236.7 | wpb 2040.3 | bsz 4 | num_updates 31873 | best_loss 7.537
2022-03-15 00:47:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 31873 updates
2022-03-15 00:47:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:47:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:47:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 310 @ 31873 updates, score 9.639) (writing took 0.9301335886120796 seconds)
2022-03-15 00:47:36 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-15 00:47:36 | INFO | train | epoch 310 | loss 3.654 | ppl 12.59 | wps 39745.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 31873 | lr 0.000177129 | gnorm 1.077 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 51902
KL Stats: Epoch 310 Divergences: Uniform: 5.674209821026919 Unigram: 5.283318280244233
2022-03-15 00:47:36 | INFO | fairseq.trainer | begin training epoch 311
2022-03-15 00:47:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:48:19 | INFO | train_inner | epoch 311:     27 / 103 loss=3.653, ppl=12.58, wps=39724.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=31900, lr=0.000177054, gnorm=1.079, loss_scale=8, train_wall=155, gb_free=20.8, wall=51945
2022-03-15 00:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:50:23 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 9.683 | ppl 821.91 | wps 66235 | wpb 2040.3 | bsz 4 | num_updates 31976 | best_loss 7.537
2022-03-15 00:50:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 31976 updates
2022-03-15 00:50:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:50:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 311 @ 31976 updates, score 9.683) (writing took 0.8950122324749827 seconds)
2022-03-15 00:50:24 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-15 00:50:24 | INFO | train | epoch 311 | loss 3.653 | ppl 12.58 | wps 40148.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 31976 | lr 0.000176843 | gnorm 1.073 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 52070
KL Stats: Epoch 311 Divergences: Uniform: 5.675855340989209 Unigram: 5.287080486279368
2022-03-15 00:50:24 | INFO | fairseq.trainer | begin training epoch 312
2022-03-15 00:50:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:51:02 | INFO | train_inner | epoch 312:     24 / 103 loss=3.653, ppl=12.58, wps=40112.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32000, lr=0.000176777, gnorm=1.073, loss_scale=8, train_wall=153, gb_free=20.8, wall=52108
2022-03-15 00:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:53:10 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 9.685 | ppl 823.2 | wps 66246.3 | wpb 2040.3 | bsz 4 | num_updates 32079 | best_loss 7.537
2022-03-15 00:53:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 32079 updates
2022-03-15 00:53:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:53:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 312 @ 32079 updates, score 9.685) (writing took 0.889123123139143 seconds)
2022-03-15 00:53:11 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-15 00:53:11 | INFO | train | epoch 312 | loss 3.651 | ppl 12.56 | wps 40147 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32079 | lr 0.000176559 | gnorm 1.068 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 52237
KL Stats: Epoch 312 Divergences: Uniform: 5.6775090177254715 Unigram: 5.289488876598115
2022-03-15 00:53:11 | INFO | fairseq.trainer | begin training epoch 313
2022-03-15 00:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:53:45 | INFO | train_inner | epoch 313:     21 / 103 loss=3.652, ppl=12.57, wps=40103.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32100, lr=0.000176501, gnorm=1.066, loss_scale=8, train_wall=153, gb_free=20.8, wall=52271
2022-03-15 00:55:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:55:58 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 9.664 | ppl 811.14 | wps 66403.9 | wpb 2040.3 | bsz 4 | num_updates 32182 | best_loss 7.537
2022-03-15 00:55:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 32182 updates
2022-03-15 00:55:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:55:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:55:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 313 @ 32182 updates, score 9.664) (writing took 0.9117990238592029 seconds)
2022-03-15 00:55:59 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-15 00:55:59 | INFO | train | epoch 313 | loss 3.649 | ppl 12.54 | wps 40149.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32182 | lr 0.000176276 | gnorm 1.064 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 52405
KL Stats: Epoch 313 Divergences: Uniform: 5.677486966277975 Unigram: 5.291142111606745
2022-03-15 00:55:59 | INFO | fairseq.trainer | begin training epoch 314
2022-03-15 00:55:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:56:27 | INFO | train_inner | epoch 314:     18 / 103 loss=3.65, ppl=12.55, wps=40123.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32200, lr=0.000176227, gnorm=1.067, loss_scale=8, train_wall=153, gb_free=20.8, wall=52433
2022-03-15 00:58:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:58:46 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 9.706 | ppl 835.03 | wps 66430.3 | wpb 2040.3 | bsz 4 | num_updates 32285 | best_loss 7.537
2022-03-15 00:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 32285 updates
2022-03-15 00:58:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:58:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 00:58:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 314 @ 32285 updates, score 9.706) (writing took 0.9095614980906248 seconds)
2022-03-15 00:58:46 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-15 00:58:46 | INFO | train | epoch 314 | loss 3.648 | ppl 12.54 | wps 40117.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32285 | lr 0.000175995 | gnorm 1.066 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 52573
KL Stats: Epoch 314 Divergences: Uniform: 5.6783930466691555 Unigram: 5.292585432130478
2022-03-15 00:58:46 | INFO | fairseq.trainer | begin training epoch 315
2022-03-15 00:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:59:10 | INFO | train_inner | epoch 315:     15 / 103 loss=3.651, ppl=12.57, wps=40075.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32300, lr=0.000175954, gnorm=1.069, loss_scale=8, train_wall=153, gb_free=20.8, wall=52596
2022-03-15 01:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:01:33 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 9.69 | ppl 825.78 | wps 66239.1 | wpb 2040.3 | bsz 4 | num_updates 32388 | best_loss 7.537
2022-03-15 01:01:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 32388 updates
2022-03-15 01:01:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:01:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:01:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 315 @ 32388 updates, score 9.69) (writing took 0.9023961126804352 seconds)
2022-03-15 01:01:34 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-15 01:01:34 | INFO | train | epoch 315 | loss 3.647 | ppl 12.53 | wps 40132.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32388 | lr 0.000175715 | gnorm 1.076 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 52740
KL Stats: Epoch 315 Divergences: Uniform: 5.680118879828219 Unigram: 5.295262371314365
2022-03-15 01:01:34 | INFO | fairseq.trainer | begin training epoch 316
2022-03-15 01:01:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:01:53 | INFO | train_inner | epoch 316:     12 / 103 loss=3.648, ppl=12.54, wps=40106, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32400, lr=0.000175682, gnorm=1.081, loss_scale=16, train_wall=153, gb_free=20.8, wall=52759
2022-03-15 01:02:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 01:04:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:04:21 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 9.684 | ppl 822.84 | wps 65841.1 | wpb 2040.3 | bsz 4 | num_updates 32490 | best_loss 7.537
2022-03-15 01:04:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 32490 updates
2022-03-15 01:04:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:04:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 316 @ 32490 updates, score 9.684) (writing took 0.9382704952731729 seconds)
2022-03-15 01:04:22 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-15 01:04:22 | INFO | train | epoch 316 | loss 3.645 | ppl 12.51 | wps 39724.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 32490 | lr 0.000175439 | gnorm 1.082 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 52908
KL Stats: Epoch 316 Divergences: Uniform: 5.679424547403777 Unigram: 5.294986310974997
2022-03-15 01:04:22 | INFO | fairseq.trainer | begin training epoch 317
2022-03-15 01:04:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:04:38 | INFO | train_inner | epoch 317:     10 / 103 loss=3.645, ppl=12.51, wps=39695.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32500, lr=0.000175412, gnorm=1.077, loss_scale=8, train_wall=155, gb_free=20.8, wall=52924
2022-03-15 01:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:07:09 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 9.689 | ppl 825.32 | wps 66249.9 | wpb 2040.3 | bsz 4 | num_updates 32593 | best_loss 7.537
2022-03-15 01:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 32593 updates
2022-03-15 01:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:07:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:07:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 317 @ 32593 updates, score 9.689) (writing took 0.9246464874595404 seconds)
2022-03-15 01:07:09 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-15 01:07:09 | INFO | train | epoch 317 | loss 3.644 | ppl 12.5 | wps 40130.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32593 | lr 0.000175161 | gnorm 1.062 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 53075
KL Stats: Epoch 317 Divergences: Uniform: 5.680731696142524 Unigram: 5.29437019001609
2022-03-15 01:07:09 | INFO | fairseq.trainer | begin training epoch 318
2022-03-15 01:07:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:07:21 | INFO | train_inner | epoch 318:      7 / 103 loss=3.646, ppl=12.52, wps=40097.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32600, lr=0.000175142, gnorm=1.063, loss_scale=8, train_wall=153, gb_free=20.8, wall=53087
2022-03-15 01:09:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:09:56 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 9.706 | ppl 835.23 | wps 66059.5 | wpb 2040.3 | bsz 4 | num_updates 32696 | best_loss 7.537
2022-03-15 01:09:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 32696 updates
2022-03-15 01:09:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:09:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:09:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 318 @ 32696 updates, score 9.706) (writing took 0.9129480887204409 seconds)
2022-03-15 01:09:57 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-15 01:09:57 | INFO | train | epoch 318 | loss 3.642 | ppl 12.48 | wps 40122.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32696 | lr 0.000174885 | gnorm 1.073 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 53243
KL Stats: Epoch 318 Divergences: Uniform: 5.681121753497613 Unigram: 5.297460290446532
2022-03-15 01:09:57 | INFO | fairseq.trainer | begin training epoch 319
2022-03-15 01:09:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:10:04 | INFO | train_inner | epoch 319:      4 / 103 loss=3.643, ppl=12.49, wps=40084.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32700, lr=0.000174874, gnorm=1.072, loss_scale=8, train_wall=153, gb_free=20.8, wall=53250
2022-03-15 01:12:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:12:44 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 9.705 | ppl 834.35 | wps 66233.9 | wpb 2040.3 | bsz 4 | num_updates 32799 | best_loss 7.537
2022-03-15 01:12:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 32799 updates
2022-03-15 01:12:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 319 @ 32799 updates, score 9.705) (writing took 0.9051177026703954 seconds)
2022-03-15 01:12:45 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-15 01:12:45 | INFO | train | epoch 319 | loss 3.641 | ppl 12.48 | wps 40142.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 32799 | lr 0.00017461 | gnorm 1.082 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 53411
KL Stats: Epoch 319 Divergences: Uniform: 5.682173265609377 Unigram: 5.300477263523226
2022-03-15 01:12:45 | INFO | fairseq.trainer | begin training epoch 320
2022-03-15 01:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:12:46 | INFO | train_inner | epoch 320:      1 / 103 loss=3.643, ppl=12.49, wps=40111.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=32800, lr=0.000174608, gnorm=1.082, loss_scale=8, train_wall=153, gb_free=20.8, wall=53412
2022-03-15 01:15:25 | INFO | train_inner | epoch 320:    101 / 103 loss=3.638, ppl=12.45, wps=41315, ups=0.63, wpb=65530.9, bsz=128, num_updates=32900, lr=0.000174342, gnorm=1.069, loss_scale=8, train_wall=154, gb_free=20.8, wall=53571
2022-03-15 01:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:15:31 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 9.688 | ppl 824.98 | wps 65927.6 | wpb 2040.3 | bsz 4 | num_updates 32902 | best_loss 7.537
2022-03-15 01:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 32902 updates
2022-03-15 01:15:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:15:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 320 @ 32902 updates, score 9.688) (writing took 0.9632996181026101 seconds)
2022-03-15 01:15:32 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-15 01:15:32 | INFO | train | epoch 320 | loss 3.638 | ppl 12.45 | wps 40179.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 32902 | lr 0.000174337 | gnorm 1.07 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 53578
KL Stats: Epoch 320 Divergences: Uniform: 5.682342928023231 Unigram: 5.30206180816628
2022-03-15 01:15:32 | INFO | fairseq.trainer | begin training epoch 321
2022-03-15 01:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:18:07 | INFO | train_inner | epoch 321:     98 / 103 loss=3.636, ppl=12.43, wps=40198.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=33000, lr=0.000174078, gnorm=1.081, loss_scale=16, train_wall=153, gb_free=20.8, wall=53733
2022-03-15 01:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:18:18 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 9.685 | ppl 823.08 | wps 66287.2 | wpb 2040.3 | bsz 4 | num_updates 33005 | best_loss 7.537
2022-03-15 01:18:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 33005 updates
2022-03-15 01:18:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 321 @ 33005 updates, score 9.685) (writing took 0.9547285735607147 seconds)
2022-03-15 01:18:19 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-15 01:18:19 | INFO | train | epoch 321 | loss 3.637 | ppl 12.44 | wps 40233.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33005 | lr 0.000174064 | gnorm 1.081 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 53745
KL Stats: Epoch 321 Divergences: Uniform: 5.6839107239847015 Unigram: 5.303674063449311
2022-03-15 01:18:19 | INFO | fairseq.trainer | begin training epoch 322
2022-03-15 01:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:18:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 01:20:51 | INFO | train_inner | epoch 322:     96 / 103 loss=3.635, ppl=12.42, wps=39803.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33100, lr=0.000173814, gnorm=1.069, loss_scale=8, train_wall=155, gb_free=20.8, wall=53898
2022-03-15 01:21:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:21:06 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 9.692 | ppl 827.41 | wps 66143.7 | wpb 2040.3 | bsz 4 | num_updates 33107 | best_loss 7.537
2022-03-15 01:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 33107 updates
2022-03-15 01:21:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:21:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:21:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 322 @ 33107 updates, score 9.692) (writing took 1.125100502744317 seconds)
2022-03-15 01:21:07 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-15 01:21:07 | INFO | train | epoch 322 | loss 3.636 | ppl 12.43 | wps 39792 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 33107 | lr 0.000173796 | gnorm 1.071 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 53913
KL Stats: Epoch 322 Divergences: Uniform: 5.6833203438144695 Unigram: 5.306248166868905
2022-03-15 01:21:07 | INFO | fairseq.trainer | begin training epoch 323
2022-03-15 01:21:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:23:34 | INFO | train_inner | epoch 323:     93 / 103 loss=3.634, ppl=12.41, wps=40149.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33200, lr=0.000173553, gnorm=1.078, loss_scale=8, train_wall=153, gb_free=20.8, wall=54060
2022-03-15 01:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:23:53 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 9.694 | ppl 828.36 | wps 66181.8 | wpb 2040.3 | bsz 4 | num_updates 33210 | best_loss 7.537
2022-03-15 01:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 33210 updates
2022-03-15 01:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:23:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:23:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 323 @ 33210 updates, score 9.694) (writing took 0.9508539270609617 seconds)
2022-03-15 01:23:54 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-15 01:23:54 | INFO | train | epoch 323 | loss 3.635 | ppl 12.43 | wps 40220.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33210 | lr 0.000173526 | gnorm 1.077 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 54080
KL Stats: Epoch 323 Divergences: Uniform: 5.683294811017288 Unigram: 5.30548216022521
2022-03-15 01:23:54 | INFO | fairseq.trainer | begin training epoch 324
2022-03-15 01:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:26:17 | INFO | train_inner | epoch 324:     90 / 103 loss=3.631, ppl=12.39, wps=40183.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=33300, lr=0.000173292, gnorm=1.07, loss_scale=8, train_wall=153, gb_free=20.8, wall=54223
2022-03-15 01:26:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:26:40 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 9.714 | ppl 839.6 | wps 66281.6 | wpb 2040.3 | bsz 4 | num_updates 33313 | best_loss 7.537
2022-03-15 01:26:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 33313 updates
2022-03-15 01:26:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:26:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:26:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 324 @ 33313 updates, score 9.714) (writing took 1.0128007642924786 seconds)
2022-03-15 01:26:41 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-15 01:26:41 | INFO | train | epoch 324 | loss 3.632 | ppl 12.4 | wps 40205.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33313 | lr 0.000173258 | gnorm 1.074 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 54247
KL Stats: Epoch 324 Divergences: Uniform: 5.685893332848614 Unigram: 5.30877474293458
2022-03-15 01:26:41 | INFO | fairseq.trainer | begin training epoch 325
2022-03-15 01:26:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:28:59 | INFO | train_inner | epoch 325:     87 / 103 loss=3.631, ppl=12.38, wps=40141.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33400, lr=0.000173032, gnorm=1.081, loss_scale=8, train_wall=153, gb_free=20.8, wall=54385
2022-03-15 01:29:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:29:28 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 9.703 | ppl 833.49 | wps 66226 | wpb 2040.3 | bsz 4 | num_updates 33416 | best_loss 7.537
2022-03-15 01:29:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 33416 updates
2022-03-15 01:29:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:29:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:29:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 325 @ 33416 updates, score 9.703) (writing took 1.1373837990686297 seconds)
2022-03-15 01:29:29 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-15 01:29:29 | INFO | train | epoch 325 | loss 3.632 | ppl 12.4 | wps 40144.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 33416 | lr 0.000172991 | gnorm 1.082 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 54415
KL Stats: Epoch 325 Divergences: Uniform: 5.684614737799344 Unigram: 5.3081735575185975
2022-03-15 01:29:29 | INFO | fairseq.trainer | begin training epoch 326
2022-03-15 01:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:31:42 | INFO | train_inner | epoch 326:     84 / 103 loss=3.628, ppl=12.36, wps=40146.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33500, lr=0.000172774, gnorm=1.066, loss_scale=8, train_wall=153, gb_free=20.8, wall=54548
2022-03-15 01:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:32:15 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 9.718 | ppl 842.08 | wps 66232.1 | wpb 2040.3 | bsz 4 | num_updates 33519 | best_loss 7.537
2022-03-15 01:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 33519 updates
2022-03-15 01:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:32:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:32:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 326 @ 33519 updates, score 9.718) (writing took 0.9696885710582137 seconds)
2022-03-15 01:32:16 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-15 01:32:16 | INFO | train | epoch 326 | loss 3.63 | ppl 12.38 | wps 40224.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33519 | lr 0.000172725 | gnorm 1.065 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 54582
KL Stats: Epoch 326 Divergences: Uniform: 5.686884823315457 Unigram: 5.31070319972261
2022-03-15 01:32:16 | INFO | fairseq.trainer | begin training epoch 327
2022-03-15 01:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:32:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 01:34:26 | INFO | train_inner | epoch 327:     82 / 103 loss=3.628, ppl=12.36, wps=39812.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=33600, lr=0.000172516, gnorm=1.068, loss_scale=8, train_wall=154, gb_free=20.8, wall=54712
2022-03-15 01:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:35:02 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 9.699 | ppl 831.22 | wps 66233.3 | wpb 2040.3 | bsz 4 | num_updates 33621 | best_loss 7.537
2022-03-15 01:35:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 33621 updates
2022-03-15 01:35:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:35:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 327 @ 33621 updates, score 9.699) (writing took 0.9706501066684723 seconds)
2022-03-15 01:35:03 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-15 01:35:03 | INFO | train | epoch 327 | loss 3.627 | ppl 12.36 | wps 39847 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 33621 | lr 0.000172463 | gnorm 1.063 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 54749
KL Stats: Epoch 327 Divergences: Uniform: 5.688127188701847 Unigram: 5.314354818469683
2022-03-15 01:35:03 | INFO | fairseq.trainer | begin training epoch 328
2022-03-15 01:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:37:09 | INFO | train_inner | epoch 328:     79 / 103 loss=3.627, ppl=12.35, wps=40187.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=33700, lr=0.00017226, gnorm=1.074, loss_scale=8, train_wall=153, gb_free=20.8, wall=54875
2022-03-15 01:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:37:50 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 9.716 | ppl 841.21 | wps 66429.9 | wpb 2040.3 | bsz 4 | num_updates 33724 | best_loss 7.537
2022-03-15 01:37:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 33724 updates
2022-03-15 01:37:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:37:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 328 @ 33724 updates, score 9.716) (writing took 1.0043302746489644 seconds)
2022-03-15 01:37:51 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-15 01:37:51 | INFO | train | epoch 328 | loss 3.627 | ppl 12.36 | wps 40211.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33724 | lr 0.000172199 | gnorm 1.078 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 54917
KL Stats: Epoch 328 Divergences: Uniform: 5.687513091608898 Unigram: 5.314442543529245
2022-03-15 01:37:51 | INFO | fairseq.trainer | begin training epoch 329
2022-03-15 01:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:39:51 | INFO | train_inner | epoch 329:     76 / 103 loss=3.623, ppl=12.32, wps=40187.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=33800, lr=0.000172005, gnorm=1.072, loss_scale=8, train_wall=153, gb_free=20.8, wall=55037
2022-03-15 01:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:40:37 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 9.717 | ppl 841.71 | wps 66167.4 | wpb 2040.3 | bsz 4 | num_updates 33827 | best_loss 7.537
2022-03-15 01:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 33827 updates
2022-03-15 01:40:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 329 @ 33827 updates, score 9.717) (writing took 0.9478337224572897 seconds)
2022-03-15 01:40:38 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-15 01:40:38 | INFO | train | epoch 329 | loss 3.626 | ppl 12.34 | wps 40235.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33827 | lr 0.000171937 | gnorm 1.074 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55084
KL Stats: Epoch 329 Divergences: Uniform: 5.68726566717352 Unigram: 5.313336264556627
2022-03-15 01:40:38 | INFO | fairseq.trainer | begin training epoch 330
2022-03-15 01:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:42:34 | INFO | train_inner | epoch 330:     73 / 103 loss=3.626, ppl=12.35, wps=40205.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=33900, lr=0.000171751, gnorm=1.073, loss_scale=8, train_wall=153, gb_free=20.8, wall=55200
2022-03-15 01:43:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:43:24 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 9.716 | ppl 840.89 | wps 66300.3 | wpb 2040.3 | bsz 4 | num_updates 33930 | best_loss 7.537
2022-03-15 01:43:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 33930 updates
2022-03-15 01:43:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:43:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 330 @ 33930 updates, score 9.716) (writing took 0.9759918749332428 seconds)
2022-03-15 01:43:25 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-15 01:43:25 | INFO | train | epoch 330 | loss 3.625 | ppl 12.34 | wps 40227.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 33930 | lr 0.000171675 | gnorm 1.074 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55251
KL Stats: Epoch 330 Divergences: Uniform: 5.687849436511271 Unigram: 5.31682160901164
2022-03-15 01:43:25 | INFO | fairseq.trainer | begin training epoch 331
2022-03-15 01:43:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:45:16 | INFO | train_inner | epoch 331:     70 / 103 loss=3.621, ppl=12.3, wps=40188.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=34000, lr=0.000171499, gnorm=1.077, loss_scale=8, train_wall=153, gb_free=20.8, wall=55362
2022-03-15 01:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:46:11 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 9.712 | ppl 838.57 | wps 66394.3 | wpb 2040.3 | bsz 4 | num_updates 34033 | best_loss 7.537
2022-03-15 01:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 34033 updates
2022-03-15 01:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:46:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 331 @ 34033 updates, score 9.712) (writing took 1.0237076850607991 seconds)
2022-03-15 01:46:12 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-15 01:46:12 | INFO | train | epoch 331 | loss 3.623 | ppl 12.32 | wps 40210.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34033 | lr 0.000171415 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55418
KL Stats: Epoch 331 Divergences: Uniform: 5.689796332148516 Unigram: 5.318306287153103
2022-03-15 01:46:12 | INFO | fairseq.trainer | begin training epoch 332
2022-03-15 01:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:47:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 01:48:00 | INFO | train_inner | epoch 332:     68 / 103 loss=3.625, ppl=12.34, wps=39802.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=34100, lr=0.000171247, gnorm=1.091, loss_scale=8, train_wall=154, gb_free=20.8, wall=55526
2022-03-15 01:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:48:59 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 9.713 | ppl 839.03 | wps 65966.8 | wpb 2040.3 | bsz 4 | num_updates 34135 | best_loss 7.537
2022-03-15 01:48:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 34135 updates
2022-03-15 01:48:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:48:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:48:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 332 @ 34135 updates, score 9.713) (writing took 0.9518001163378358 seconds)
2022-03-15 01:48:59 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-15 01:48:59 | INFO | train | epoch 332 | loss 3.622 | ppl 12.31 | wps 39850.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 34135 | lr 0.000171159 | gnorm 1.087 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55586
KL Stats: Epoch 332 Divergences: Uniform: 5.6892563204328646 Unigram: 5.318958422768506
2022-03-15 01:48:59 | INFO | fairseq.trainer | begin training epoch 333
2022-03-15 01:48:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:50:43 | INFO | train_inner | epoch 333:     65 / 103 loss=3.618, ppl=12.28, wps=40197.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=34200, lr=0.000170996, gnorm=1.075, loss_scale=8, train_wall=153, gb_free=20.8, wall=55689
2022-03-15 01:51:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:51:46 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 9.701 | ppl 832.58 | wps 66478.5 | wpb 2040.3 | bsz 4 | num_updates 34238 | best_loss 7.537
2022-03-15 01:51:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 34238 updates
2022-03-15 01:51:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:51:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:51:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 333 @ 34238 updates, score 9.701) (writing took 0.9683945905417204 seconds)
2022-03-15 01:51:47 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-15 01:51:47 | INFO | train | epoch 333 | loss 3.62 | ppl 12.3 | wps 40228.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34238 | lr 0.000170901 | gnorm 1.071 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55753
KL Stats: Epoch 333 Divergences: Uniform: 5.688231695553274 Unigram: 5.319534353457553
2022-03-15 01:51:47 | INFO | fairseq.trainer | begin training epoch 334
2022-03-15 01:51:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:53:25 | INFO | train_inner | epoch 334:     62 / 103 loss=3.618, ppl=12.28, wps=40207.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=34300, lr=0.000170747, gnorm=1.066, loss_scale=8, train_wall=153, gb_free=20.8, wall=55851
2022-03-15 01:54:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:54:33 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 9.71 | ppl 837.43 | wps 66156.5 | wpb 2040.3 | bsz 4 | num_updates 34341 | best_loss 7.537
2022-03-15 01:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 34341 updates
2022-03-15 01:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 334 @ 34341 updates, score 9.71) (writing took 1.015587130561471 seconds)
2022-03-15 01:54:34 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-15 01:54:34 | INFO | train | epoch 334 | loss 3.618 | ppl 12.28 | wps 40209.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34341 | lr 0.000170645 | gnorm 1.064 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 55920
KL Stats: Epoch 334 Divergences: Uniform: 5.691366678864345 Unigram: 5.322292330827113
2022-03-15 01:54:34 | INFO | fairseq.trainer | begin training epoch 335
2022-03-15 01:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:56:08 | INFO | train_inner | epoch 335:     59 / 103 loss=3.619, ppl=12.29, wps=40156, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=34400, lr=0.000170499, gnorm=1.071, loss_scale=8, train_wall=153, gb_free=20.8, wall=56014
2022-03-15 01:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:57:20 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 9.715 | ppl 840.71 | wps 66047.7 | wpb 2040.3 | bsz 4 | num_updates 34444 | best_loss 7.537
2022-03-15 01:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 34444 updates
2022-03-15 01:57:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 01:57:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 335 @ 34444 updates, score 9.715) (writing took 0.9742526318877935 seconds)
2022-03-15 01:57:21 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-15 01:57:21 | INFO | train | epoch 335 | loss 3.617 | ppl 12.27 | wps 40202.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34444 | lr 0.00017039 | gnorm 1.076 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 56087
KL Stats: Epoch 335 Divergences: Uniform: 5.692975364059331 Unigram: 5.324435482817829
2022-03-15 01:57:21 | INFO | fairseq.trainer | begin training epoch 336
2022-03-15 01:57:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:58:50 | INFO | train_inner | epoch 336:     56 / 103 loss=3.614, ppl=12.25, wps=40174, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=34500, lr=0.000170251, gnorm=1.083, loss_scale=8, train_wall=153, gb_free=20.8, wall=56176
2022-03-15 02:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:00:08 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 9.727 | ppl 847.28 | wps 66442 | wpb 2040.3 | bsz 4 | num_updates 34547 | best_loss 7.537
2022-03-15 02:00:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 34547 updates
2022-03-15 02:00:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:00:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:00:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 336 @ 34547 updates, score 9.727) (writing took 0.9927863953635097 seconds)
2022-03-15 02:00:09 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-15 02:00:09 | INFO | train | epoch 336 | loss 3.616 | ppl 12.26 | wps 40198.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34547 | lr 0.000170135 | gnorm 1.091 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 56255
KL Stats: Epoch 336 Divergences: Uniform: 5.6908011280381094 Unigram: 5.324094664730453
2022-03-15 02:00:09 | INFO | fairseq.trainer | begin training epoch 337
2022-03-15 02:00:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:01:33 | INFO | train_inner | epoch 337:     53 / 103 loss=3.614, ppl=12.24, wps=40154.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=34600, lr=0.000170005, gnorm=1.09, loss_scale=16, train_wall=153, gb_free=20.8, wall=56339
2022-03-15 02:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:02:55 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 9.739 | ppl 854.51 | wps 66428.2 | wpb 2040.3 | bsz 4 | num_updates 34650 | best_loss 7.537
2022-03-15 02:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 34650 updates
2022-03-15 02:02:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:02:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:02:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 337 @ 34650 updates, score 9.739) (writing took 1.0156681360676885 seconds)
2022-03-15 02:02:56 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-15 02:02:56 | INFO | train | epoch 337 | loss 3.613 | ppl 12.24 | wps 40190.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34650 | lr 0.000169882 | gnorm 1.075 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 56422
KL Stats: Epoch 337 Divergences: Uniform: 5.693839759728451 Unigram: 5.326730053597577
2022-03-15 02:02:56 | INFO | fairseq.trainer | begin training epoch 338
2022-03-15 02:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:04:15 | INFO | train_inner | epoch 338:     50 / 103 loss=3.615, ppl=12.25, wps=40163.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=34700, lr=0.00016976, gnorm=1.066, loss_scale=16, train_wall=153, gb_free=20.8, wall=56501
2022-03-15 02:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:05:42 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 9.726 | ppl 846.79 | wps 66293.7 | wpb 2040.3 | bsz 4 | num_updates 34753 | best_loss 7.537
2022-03-15 02:05:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 34753 updates
2022-03-15 02:05:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:05:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:05:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 338 @ 34753 updates, score 9.726) (writing took 0.9107328075915575 seconds)
2022-03-15 02:05:43 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-15 02:05:43 | INFO | train | epoch 338 | loss 3.613 | ppl 12.24 | wps 40237.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34753 | lr 0.00016963 | gnorm 1.078 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 56589
KL Stats: Epoch 338 Divergences: Uniform: 5.69352789524944 Unigram: 5.32936972828199
2022-03-15 02:05:43 | INFO | fairseq.trainer | begin training epoch 339
2022-03-15 02:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 02:06:59 | INFO | train_inner | epoch 339:     48 / 103 loss=3.612, ppl=12.23, wps=39822.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=34800, lr=0.000169516, gnorm=1.074, loss_scale=8, train_wall=155, gb_free=20.8, wall=56665
2022-03-15 02:08:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:08:30 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 9.739 | ppl 854.48 | wps 65722.5 | wpb 2040.3 | bsz 4 | num_updates 34855 | best_loss 7.537
2022-03-15 02:08:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 34855 updates
2022-03-15 02:08:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:08:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 339 @ 34855 updates, score 9.739) (writing took 0.963137966580689 seconds)
2022-03-15 02:08:31 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-15 02:08:31 | INFO | train | epoch 339 | loss 3.613 | ppl 12.23 | wps 39823.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 34855 | lr 0.000169382 | gnorm 1.074 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 56757
KL Stats: Epoch 339 Divergences: Uniform: 5.69440472986208 Unigram: 5.330357692784446
2022-03-15 02:08:31 | INFO | fairseq.trainer | begin training epoch 340
2022-03-15 02:08:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:09:42 | INFO | train_inner | epoch 340:     45 / 103 loss=3.612, ppl=12.22, wps=40177.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=34900, lr=0.000169273, gnorm=1.077, loss_scale=8, train_wall=153, gb_free=20.8, wall=56828
2022-03-15 02:11:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:11:17 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 9.748 | ppl 859.86 | wps 66140.2 | wpb 2040.3 | bsz 4 | num_updates 34958 | best_loss 7.537
2022-03-15 02:11:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 34958 updates
2022-03-15 02:11:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:11:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:11:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 340 @ 34958 updates, score 9.748) (writing took 1.0028053326532245 seconds)
2022-03-15 02:11:18 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-15 02:11:18 | INFO | train | epoch 340 | loss 3.612 | ppl 12.23 | wps 40207.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 34958 | lr 0.000169132 | gnorm 1.078 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 56924
KL Stats: Epoch 340 Divergences: Uniform: 5.695213186692648 Unigram: 5.330206837431391
2022-03-15 02:11:18 | INFO | fairseq.trainer | begin training epoch 341
2022-03-15 02:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:12:24 | INFO | train_inner | epoch 341:     42 / 103 loss=3.612, ppl=12.23, wps=40175.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=35000, lr=0.000169031, gnorm=1.078, loss_scale=8, train_wall=153, gb_free=20.8, wall=56990
2022-03-15 02:14:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:14:04 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 9.739 | ppl 854.52 | wps 66227.5 | wpb 2040.3 | bsz 4 | num_updates 35061 | best_loss 7.537
2022-03-15 02:14:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 35061 updates
2022-03-15 02:14:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:14:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:14:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 341 @ 35061 updates, score 9.739) (writing took 0.9389529014006257 seconds)
2022-03-15 02:14:05 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-15 02:14:05 | INFO | train | epoch 341 | loss 3.61 | ppl 12.21 | wps 40225.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35061 | lr 0.000168884 | gnorm 1.078 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57091
KL Stats: Epoch 341 Divergences: Uniform: 5.69409205361998 Unigram: 5.331295020653071
2022-03-15 02:14:05 | INFO | fairseq.trainer | begin training epoch 342
2022-03-15 02:14:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:15:07 | INFO | train_inner | epoch 342:     39 / 103 loss=3.61, ppl=12.21, wps=40191.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=35100, lr=0.00016879, gnorm=1.077, loss_scale=8, train_wall=153, gb_free=20.8, wall=57153
2022-03-15 02:16:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:16:51 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 9.721 | ppl 843.8 | wps 66127.9 | wpb 2040.3 | bsz 4 | num_updates 35164 | best_loss 7.537
2022-03-15 02:16:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 35164 updates
2022-03-15 02:16:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:16:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:16:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 342 @ 35164 updates, score 9.721) (writing took 0.9925435716286302 seconds)
2022-03-15 02:16:52 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-15 02:16:52 | INFO | train | epoch 342 | loss 3.608 | ppl 12.19 | wps 40211.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35164 | lr 0.000168636 | gnorm 1.068 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57258
KL Stats: Epoch 342 Divergences: Uniform: 5.695116710206874 Unigram: 5.332797487012688
2022-03-15 02:16:52 | INFO | fairseq.trainer | begin training epoch 343
2022-03-15 02:16:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:17:49 | INFO | train_inner | epoch 343:     36 / 103 loss=3.605, ppl=12.17, wps=40178.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=35200, lr=0.00016855, gnorm=1.07, loss_scale=8, train_wall=153, gb_free=20.8, wall=57316
2022-03-15 02:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:19:39 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 9.737 | ppl 853.41 | wps 66131.9 | wpb 2040.3 | bsz 4 | num_updates 35267 | best_loss 7.537
2022-03-15 02:19:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 35267 updates
2022-03-15 02:19:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 343 @ 35267 updates, score 9.737) (writing took 0.9925834145396948 seconds)
2022-03-15 02:19:40 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-15 02:19:40 | INFO | train | epoch 343 | loss 3.607 | ppl 12.18 | wps 40195.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35267 | lr 0.00016839 | gnorm 1.083 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57426
KL Stats: Epoch 343 Divergences: Uniform: 5.696704911221121 Unigram: 5.335646263927868
2022-03-15 02:19:40 | INFO | fairseq.trainer | begin training epoch 344
2022-03-15 02:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:20:32 | INFO | train_inner | epoch 344:     33 / 103 loss=3.608, ppl=12.2, wps=40156.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=35300, lr=0.000168311, gnorm=1.085, loss_scale=8, train_wall=153, gb_free=20.8, wall=57478
2022-03-15 02:21:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 02:22:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:22:26 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 9.722 | ppl 844.67 | wps 66230.9 | wpb 2040.3 | bsz 4 | num_updates 35369 | best_loss 7.537
2022-03-15 02:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 35369 updates
2022-03-15 02:22:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:22:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:22:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 344 @ 35369 updates, score 9.722) (writing took 0.9648590572178364 seconds)
2022-03-15 02:22:27 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-15 02:22:27 | INFO | train | epoch 344 | loss 3.604 | ppl 12.16 | wps 39829.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 35369 | lr 0.000168147 | gnorm 1.077 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57593
KL Stats: Epoch 344 Divergences: Uniform: 5.697223697843338 Unigram: 5.335834821369246
2022-03-15 02:22:27 | INFO | fairseq.trainer | begin training epoch 345
2022-03-15 02:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:23:16 | INFO | train_inner | epoch 345:     31 / 103 loss=3.604, ppl=12.16, wps=39807.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=35400, lr=0.000168073, gnorm=1.078, loss_scale=8, train_wall=155, gb_free=20.8, wall=57642
2022-03-15 02:25:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:25:13 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 9.74 | ppl 854.89 | wps 66256.8 | wpb 2040.3 | bsz 4 | num_updates 35472 | best_loss 7.537
2022-03-15 02:25:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 35472 updates
2022-03-15 02:25:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:25:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:25:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 345 @ 35472 updates, score 9.74) (writing took 0.9792298870161176 seconds)
2022-03-15 02:25:14 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-15 02:25:14 | INFO | train | epoch 345 | loss 3.603 | ppl 12.15 | wps 40204.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35472 | lr 0.000167902 | gnorm 1.083 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57760
KL Stats: Epoch 345 Divergences: Uniform: 5.697118021609723 Unigram: 5.338601674188275
2022-03-15 02:25:14 | INFO | fairseq.trainer | begin training epoch 346
2022-03-15 02:25:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:25:59 | INFO | train_inner | epoch 346:     28 / 103 loss=3.606, ppl=12.17, wps=40178.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=35500, lr=0.000167836, gnorm=1.089, loss_scale=8, train_wall=153, gb_free=20.8, wall=57805
2022-03-15 02:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:28:01 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 9.739 | ppl 854.52 | wps 66600.7 | wpb 2040.3 | bsz 4 | num_updates 35575 | best_loss 7.537
2022-03-15 02:28:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 35575 updates
2022-03-15 02:28:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:28:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:28:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 346 @ 35575 updates, score 9.739) (writing took 0.9916541129350662 seconds)
2022-03-15 02:28:02 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-15 02:28:02 | INFO | train | epoch 346 | loss 3.603 | ppl 12.15 | wps 40221.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35575 | lr 0.000167659 | gnorm 1.088 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 57928
KL Stats: Epoch 346 Divergences: Uniform: 5.7000877593623756 Unigram: 5.3406120394993986
2022-03-15 02:28:02 | INFO | fairseq.trainer | begin training epoch 347
2022-03-15 02:28:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:28:41 | INFO | train_inner | epoch 347:     25 / 103 loss=3.599, ppl=12.12, wps=40189.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=35600, lr=0.0001676, gnorm=1.079, loss_scale=8, train_wall=153, gb_free=20.8, wall=57967
2022-03-15 02:30:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:30:48 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 9.717 | ppl 841.62 | wps 66423.1 | wpb 2040.3 | bsz 4 | num_updates 35678 | best_loss 7.537
2022-03-15 02:30:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 35678 updates
2022-03-15 02:30:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:30:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 347 @ 35678 updates, score 9.717) (writing took 0.9424154926091433 seconds)
2022-03-15 02:30:49 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-15 02:30:49 | INFO | train | epoch 347 | loss 3.601 | ppl 12.14 | wps 40231.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35678 | lr 0.000167417 | gnorm 1.078 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 58095
KL Stats: Epoch 347 Divergences: Uniform: 5.697369937118076 Unigram: 5.340096296708169
2022-03-15 02:30:49 | INFO | fairseq.trainer | begin training epoch 348
2022-03-15 02:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:31:24 | INFO | train_inner | epoch 348:     22 / 103 loss=3.604, ppl=12.16, wps=40190.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=35700, lr=0.000167365, gnorm=1.08, loss_scale=8, train_wall=153, gb_free=20.8, wall=58130
2022-03-15 02:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:33:35 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 9.742 | ppl 856.07 | wps 66228.8 | wpb 2040.3 | bsz 4 | num_updates 35781 | best_loss 7.537
2022-03-15 02:33:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 35781 updates
2022-03-15 02:33:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:33:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 348 @ 35781 updates, score 9.742) (writing took 0.9862700486555696 seconds)
2022-03-15 02:33:36 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-15 02:33:36 | INFO | train | epoch 348 | loss 3.599 | ppl 12.12 | wps 40201.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35781 | lr 0.000167176 | gnorm 1.075 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 58262
KL Stats: Epoch 348 Divergences: Uniform: 5.697282536777778 Unigram: 5.3405080947511205
2022-03-15 02:33:36 | INFO | fairseq.trainer | begin training epoch 349
2022-03-15 02:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:34:06 | INFO | train_inner | epoch 349:     19 / 103 loss=3.6, ppl=12.13, wps=40171.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=35800, lr=0.000167132, gnorm=1.075, loss_scale=8, train_wall=153, gb_free=20.8, wall=58292
2022-03-15 02:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:36:22 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 9.744 | ppl 857.74 | wps 66006.1 | wpb 2040.3 | bsz 4 | num_updates 35884 | best_loss 7.537
2022-03-15 02:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 35884 updates
2022-03-15 02:36:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:36:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:36:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 349 @ 35884 updates, score 9.744) (writing took 0.9768453566357493 seconds)
2022-03-15 02:36:23 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-15 02:36:23 | INFO | train | epoch 349 | loss 3.599 | ppl 12.12 | wps 40217 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 35884 | lr 0.000166936 | gnorm 1.088 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 58429
KL Stats: Epoch 349 Divergences: Uniform: 5.699659973122084 Unigram: 5.342570306133286
2022-03-15 02:36:23 | INFO | fairseq.trainer | begin training epoch 350
2022-03-15 02:36:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:36:49 | INFO | train_inner | epoch 350:     16 / 103 loss=3.598, ppl=12.11, wps=40186.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=35900, lr=0.000166899, gnorm=1.091, loss_scale=16, train_wall=153, gb_free=20.8, wall=58455
2022-03-15 02:37:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 02:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:39:10 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 9.739 | ppl 854.52 | wps 66420.4 | wpb 2040.3 | bsz 4 | num_updates 35986 | best_loss 7.537
2022-03-15 02:39:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 35986 updates
2022-03-15 02:39:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:39:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:39:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 350 @ 35986 updates, score 9.739) (writing took 0.9640934178605676 seconds)
2022-03-15 02:39:11 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-15 02:39:11 | INFO | train | epoch 350 | loss 3.596 | ppl 12.09 | wps 39841.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 35986 | lr 0.000166699 | gnorm 1.083 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 58597
KL Stats: Epoch 350 Divergences: Uniform: 5.7009530533583295 Unigram: 5.34364985192072
2022-03-15 02:39:11 | INFO | fairseq.trainer | begin training epoch 351
2022-03-15 02:39:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:39:33 | INFO | train_inner | epoch 351:     14 / 103 loss=3.599, ppl=12.12, wps=39802.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=36000, lr=0.000166667, gnorm=1.081, loss_scale=8, train_wall=155, gb_free=20.8, wall=58619
2022-03-15 02:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:41:57 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 9.76 | ppl 866.79 | wps 66228.9 | wpb 2040.3 | bsz 4 | num_updates 36089 | best_loss 7.537
2022-03-15 02:41:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 36089 updates
2022-03-15 02:41:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:41:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:41:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 351 @ 36089 updates, score 9.76) (writing took 0.9934419058263302 seconds)
2022-03-15 02:41:58 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-15 02:41:58 | INFO | train | epoch 351 | loss 3.597 | ppl 12.1 | wps 40198.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36089 | lr 0.000166461 | gnorm 1.074 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 58764
KL Stats: Epoch 351 Divergences: Uniform: 5.700485152749289 Unigram: 5.3458712672871584
2022-03-15 02:41:58 | INFO | fairseq.trainer | begin training epoch 352
2022-03-15 02:41:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:42:15 | INFO | train_inner | epoch 352:     11 / 103 loss=3.597, ppl=12.1, wps=40173.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=36100, lr=0.000166436, gnorm=1.072, loss_scale=8, train_wall=153, gb_free=20.8, wall=58781
2022-03-15 02:44:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:44:44 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 9.74 | ppl 855.33 | wps 65940.3 | wpb 2040.3 | bsz 4 | num_updates 36192 | best_loss 7.537
2022-03-15 02:44:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 36192 updates
2022-03-15 02:44:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:44:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:44:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 352 @ 36192 updates, score 9.74) (writing took 0.9891886189579964 seconds)
2022-03-15 02:44:45 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-15 02:44:45 | INFO | train | epoch 352 | loss 3.595 | ppl 12.09 | wps 40204.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36192 | lr 0.000166224 | gnorm 1.068 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 58931
KL Stats: Epoch 352 Divergences: Uniform: 5.700318160904116 Unigram: 5.345998043117825
2022-03-15 02:44:45 | INFO | fairseq.trainer | begin training epoch 353
2022-03-15 02:44:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:44:58 | INFO | train_inner | epoch 353:      8 / 103 loss=3.597, ppl=12.1, wps=40165.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=36200, lr=0.000166206, gnorm=1.073, loss_scale=8, train_wall=153, gb_free=20.8, wall=58944
2022-03-15 02:47:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:47:32 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 9.75 | ppl 860.81 | wps 66246.2 | wpb 2040.3 | bsz 4 | num_updates 36295 | best_loss 7.537
2022-03-15 02:47:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 36295 updates
2022-03-15 02:47:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:47:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 353 @ 36295 updates, score 9.75) (writing took 0.963242307305336 seconds)
2022-03-15 02:47:33 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-15 02:47:33 | INFO | train | epoch 353 | loss 3.593 | ppl 12.06 | wps 40197 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36295 | lr 0.000165988 | gnorm 1.084 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 59099
KL Stats: Epoch 353 Divergences: Uniform: 5.701700087670414 Unigram: 5.347706597971101
2022-03-15 02:47:33 | INFO | fairseq.trainer | begin training epoch 354
2022-03-15 02:47:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:47:41 | INFO | train_inner | epoch 354:      5 / 103 loss=3.594, ppl=12.08, wps=40163.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=36300, lr=0.000165977, gnorm=1.084, loss_scale=8, train_wall=153, gb_free=20.8, wall=59107
2022-03-15 02:50:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:50:19 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 9.758 | ppl 865.92 | wps 65953.9 | wpb 2040.3 | bsz 4 | num_updates 36398 | best_loss 7.537
2022-03-15 02:50:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 36398 updates
2022-03-15 02:50:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:50:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:50:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 354 @ 36398 updates, score 9.758) (writing took 0.9967748364433646 seconds)
2022-03-15 02:50:20 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-15 02:50:20 | INFO | train | epoch 354 | loss 3.592 | ppl 12.06 | wps 40214.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36398 | lr 0.000165753 | gnorm 1.083 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 59266
KL Stats: Epoch 354 Divergences: Uniform: 5.703432194245742 Unigram: 5.350358124593024
2022-03-15 02:50:20 | INFO | fairseq.trainer | begin training epoch 355
2022-03-15 02:50:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:50:23 | INFO | train_inner | epoch 355:      2 / 103 loss=3.594, ppl=12.07, wps=40183.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=36400, lr=0.000165748, gnorm=1.081, loss_scale=8, train_wall=153, gb_free=20.8, wall=59269
2022-03-15 02:53:02 | INFO | train_inner | epoch 355:    102 / 103 loss=3.592, ppl=12.05, wps=41337.7, ups=0.63, wpb=65530.9, bsz=128, num_updates=36500, lr=0.000165521, gnorm=1.081, loss_scale=16, train_wall=154, gb_free=20.8, wall=59428
2022-03-15 02:53:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:53:06 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 9.756 | ppl 864.5 | wps 66210.9 | wpb 2040.3 | bsz 4 | num_updates 36501 | best_loss 7.537
2022-03-15 02:53:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 36501 updates
2022-03-15 02:53:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:53:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:53:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 355 @ 36501 updates, score 9.756) (writing took 1.0126963695511222 seconds)
2022-03-15 02:53:07 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-15 02:53:07 | INFO | train | epoch 355 | loss 3.591 | ppl 12.05 | wps 40189.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36501 | lr 0.000165519 | gnorm 1.082 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 59433
KL Stats: Epoch 355 Divergences: Uniform: 5.701185245941824 Unigram: 5.350362448922059
2022-03-15 02:53:07 | INFO | fairseq.trainer | begin training epoch 356
2022-03-15 02:53:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:55:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 02:55:46 | INFO | train_inner | epoch 356:    100 / 103 loss=3.588, ppl=12.02, wps=39776.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=36600, lr=0.000165295, gnorm=1.081, loss_scale=8, train_wall=155, gb_free=20.8, wall=59592
2022-03-15 02:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:55:54 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 9.752 | ppl 862.07 | wps 66029.9 | wpb 2040.3 | bsz 4 | num_updates 36603 | best_loss 7.537
2022-03-15 02:55:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 36603 updates
2022-03-15 02:55:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:55:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 356 @ 36603 updates, score 9.752) (writing took 0.9623030116781592 seconds)
2022-03-15 02:55:55 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-15 02:55:55 | INFO | train | epoch 356 | loss 3.589 | ppl 12.03 | wps 39816.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 36603 | lr 0.000165288 | gnorm 1.082 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 59601
KL Stats: Epoch 356 Divergences: Uniform: 5.702683168266047 Unigram: 5.351896049468646
2022-03-15 02:55:55 | INFO | fairseq.trainer | begin training epoch 357
2022-03-15 02:55:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:58:28 | INFO | train_inner | epoch 357:     97 / 103 loss=3.587, ppl=12.02, wps=40172.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=36700, lr=0.00016507, gnorm=1.07, loss_scale=8, train_wall=153, gb_free=20.8, wall=59754
2022-03-15 02:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:58:41 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 9.777 | ppl 877.21 | wps 66203.7 | wpb 2040.3 | bsz 4 | num_updates 36706 | best_loss 7.537
2022-03-15 02:58:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 36706 updates
2022-03-15 02:58:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:58:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 02:58:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 357 @ 36706 updates, score 9.777) (writing took 0.9884991282597184 seconds)
2022-03-15 02:58:42 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-15 02:58:42 | INFO | train | epoch 357 | loss 3.588 | ppl 12.03 | wps 40198.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36706 | lr 0.000165056 | gnorm 1.071 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 59768
KL Stats: Epoch 357 Divergences: Uniform: 5.703477230822615 Unigram: 5.353040953338387
2022-03-15 02:58:42 | INFO | fairseq.trainer | begin training epoch 358
2022-03-15 02:58:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:01:11 | INFO | train_inner | epoch 358:     94 / 103 loss=3.587, ppl=12.02, wps=40179, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=36800, lr=0.000164845, gnorm=1.085, loss_scale=8, train_wall=153, gb_free=20.8, wall=59917
2022-03-15 03:01:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:01:28 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 9.78 | ppl 878.98 | wps 66218.4 | wpb 2040.3 | bsz 4 | num_updates 36809 | best_loss 7.537
2022-03-15 03:01:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 36809 updates
2022-03-15 03:01:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:01:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:01:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 358 @ 36809 updates, score 9.78) (writing took 0.9933073800057173 seconds)
2022-03-15 03:01:29 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-15 03:01:29 | INFO | train | epoch 358 | loss 3.588 | ppl 12.02 | wps 40211.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36809 | lr 0.000164825 | gnorm 1.084 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 59935
KL Stats: Epoch 358 Divergences: Uniform: 5.703252737642255 Unigram: 5.354715055751204
2022-03-15 03:01:29 | INFO | fairseq.trainer | begin training epoch 359
2022-03-15 03:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:03:54 | INFO | train_inner | epoch 359:     91 / 103 loss=3.585, ppl=12, wps=40170.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=36900, lr=0.000164622, gnorm=1.093, loss_scale=8, train_wall=153, gb_free=20.8, wall=60080
2022-03-15 03:04:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:04:16 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 9.766 | ppl 870.5 | wps 66378 | wpb 2040.3 | bsz 4 | num_updates 36912 | best_loss 7.537
2022-03-15 03:04:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 36912 updates
2022-03-15 03:04:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:04:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:04:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 359 @ 36912 updates, score 9.766) (writing took 0.9523966507986188 seconds)
2022-03-15 03:04:17 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-15 03:04:17 | INFO | train | epoch 359 | loss 3.586 | ppl 12.01 | wps 40215.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 36912 | lr 0.000164595 | gnorm 1.09 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 60103
KL Stats: Epoch 359 Divergences: Uniform: 5.70498447986419 Unigram: 5.355443066663276
2022-03-15 03:04:17 | INFO | fairseq.trainer | begin training epoch 360
2022-03-15 03:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:06:36 | INFO | train_inner | epoch 360:     88 / 103 loss=3.584, ppl=11.99, wps=40188.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=37000, lr=0.000164399, gnorm=1.08, loss_scale=8, train_wall=153, gb_free=20.8, wall=60242
2022-03-15 03:06:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:07:03 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 9.762 | ppl 868.52 | wps 66619.1 | wpb 2040.3 | bsz 4 | num_updates 37015 | best_loss 7.537
2022-03-15 03:07:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 37015 updates
2022-03-15 03:07:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:07:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:07:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 360 @ 37015 updates, score 9.762) (writing took 0.956898532807827 seconds)
2022-03-15 03:07:04 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-15 03:07:04 | INFO | train | epoch 360 | loss 3.585 | ppl 12 | wps 40226.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37015 | lr 0.000164366 | gnorm 1.086 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 60270
KL Stats: Epoch 360 Divergences: Uniform: 5.705365761311101 Unigram: 5.357963144345159
2022-03-15 03:07:04 | INFO | fairseq.trainer | begin training epoch 361
2022-03-15 03:07:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:09:19 | INFO | train_inner | epoch 361:     85 / 103 loss=3.584, ppl=11.99, wps=40193.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=37100, lr=0.000164177, gnorm=1.085, loss_scale=16, train_wall=153, gb_free=20.8, wall=60405
2022-03-15 03:09:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:09:50 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 9.749 | ppl 860.75 | wps 66203.3 | wpb 2040.3 | bsz 4 | num_updates 37118 | best_loss 7.537
2022-03-15 03:09:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 37118 updates
2022-03-15 03:09:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:09:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:09:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 361 @ 37118 updates, score 9.749) (writing took 0.9727796316146851 seconds)
2022-03-15 03:09:51 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-15 03:09:51 | INFO | train | epoch 361 | loss 3.583 | ppl 11.99 | wps 40222.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37118 | lr 0.000164137 | gnorm 1.08 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 60437
KL Stats: Epoch 361 Divergences: Uniform: 5.704239257498233 Unigram: 5.358129872009569
2022-03-15 03:09:51 | INFO | fairseq.trainer | begin training epoch 362
2022-03-15 03:09:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:11:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 03:12:03 | INFO | train_inner | epoch 362:     83 / 103 loss=3.579, ppl=11.95, wps=39810.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=37200, lr=0.000163956, gnorm=1.08, loss_scale=8, train_wall=155, gb_free=20.8, wall=60569
2022-03-15 03:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:12:37 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 9.772 | ppl 874.22 | wps 66429.2 | wpb 2040.3 | bsz 4 | num_updates 37220 | best_loss 7.537
2022-03-15 03:12:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 37220 updates
2022-03-15 03:12:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:12:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:12:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 362 @ 37220 updates, score 9.772) (writing took 0.9311800533905625 seconds)
2022-03-15 03:12:38 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-15 03:12:38 | INFO | train | epoch 362 | loss 3.58 | ppl 11.96 | wps 39838.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 37220 | lr 0.000163912 | gnorm 1.078 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 60604
KL Stats: Epoch 362 Divergences: Uniform: 5.706411916852742 Unigram: 5.359514496281727
2022-03-15 03:12:38 | INFO | fairseq.trainer | begin training epoch 363
2022-03-15 03:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:14:45 | INFO | train_inner | epoch 363:     80 / 103 loss=3.58, ppl=11.96, wps=40184, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=37300, lr=0.000163737, gnorm=1.076, loss_scale=8, train_wall=153, gb_free=20.8, wall=60731
2022-03-15 03:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:15:25 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 9.768 | ppl 871.67 | wps 66362.4 | wpb 2040.3 | bsz 4 | num_updates 37323 | best_loss 7.537
2022-03-15 03:15:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 37323 updates
2022-03-15 03:15:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:15:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:15:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 363 @ 37323 updates, score 9.768) (writing took 0.9688303833827376 seconds)
2022-03-15 03:15:25 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-15 03:15:25 | INFO | train | epoch 363 | loss 3.581 | ppl 11.96 | wps 40220.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37323 | lr 0.000163686 | gnorm 1.078 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 60772
KL Stats: Epoch 363 Divergences: Uniform: 5.70650417893281 Unigram: 5.360609308995495
2022-03-15 03:15:25 | INFO | fairseq.trainer | begin training epoch 364
2022-03-15 03:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:17:28 | INFO | train_inner | epoch 364:     77 / 103 loss=3.576, ppl=11.93, wps=40189.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=37400, lr=0.000163517, gnorm=1.074, loss_scale=8, train_wall=153, gb_free=20.8, wall=60894
2022-03-15 03:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:18:12 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 9.762 | ppl 868.01 | wps 66606.8 | wpb 2040.3 | bsz 4 | num_updates 37426 | best_loss 7.537
2022-03-15 03:18:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 37426 updates
2022-03-15 03:18:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:18:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:18:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 364 @ 37426 updates, score 9.762) (writing took 0.9918651944026351 seconds)
2022-03-15 03:18:13 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-15 03:18:13 | INFO | train | epoch 364 | loss 3.579 | ppl 11.95 | wps 40221.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37426 | lr 0.000163461 | gnorm 1.077 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 60939
KL Stats: Epoch 364 Divergences: Uniform: 5.707992122154895 Unigram: 5.362758766250077
2022-03-15 03:18:13 | INFO | fairseq.trainer | begin training epoch 365
2022-03-15 03:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:20:10 | INFO | train_inner | epoch 365:     74 / 103 loss=3.581, ppl=11.97, wps=40198.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=37500, lr=0.000163299, gnorm=1.09, loss_scale=8, train_wall=153, gb_free=20.8, wall=61056
2022-03-15 03:20:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:20:59 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 9.76 | ppl 866.89 | wps 66352.4 | wpb 2040.3 | bsz 4 | num_updates 37529 | best_loss 7.537
2022-03-15 03:20:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 37529 updates
2022-03-15 03:20:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:21:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:21:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 365 @ 37529 updates, score 9.76) (writing took 0.9432222424075007 seconds)
2022-03-15 03:21:00 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-15 03:21:00 | INFO | train | epoch 365 | loss 3.579 | ppl 11.95 | wps 40243.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37529 | lr 0.000163236 | gnorm 1.095 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61106
KL Stats: Epoch 365 Divergences: Uniform: 5.707296667067432 Unigram: 5.363541047298632
2022-03-15 03:21:00 | INFO | fairseq.trainer | begin training epoch 366
2022-03-15 03:21:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:22:52 | INFO | train_inner | epoch 366:     71 / 103 loss=3.577, ppl=11.93, wps=40194.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=37600, lr=0.000163082, gnorm=1.092, loss_scale=8, train_wall=153, gb_free=20.8, wall=61219
2022-03-15 03:23:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:23:46 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 9.759 | ppl 866.66 | wps 65990.3 | wpb 2040.3 | bsz 4 | num_updates 37632 | best_loss 7.537
2022-03-15 03:23:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 37632 updates
2022-03-15 03:23:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:23:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:23:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 366 @ 37632 updates, score 9.759) (writing took 0.993892515078187 seconds)
2022-03-15 03:23:47 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-15 03:23:47 | INFO | train | epoch 366 | loss 3.577 | ppl 11.94 | wps 40209.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37632 | lr 0.000163013 | gnorm 1.088 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61273
KL Stats: Epoch 366 Divergences: Uniform: 5.707885030316447 Unigram: 5.364033500163509
2022-03-15 03:23:47 | INFO | fairseq.trainer | begin training epoch 367
2022-03-15 03:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:25:35 | INFO | train_inner | epoch 367:     68 / 103 loss=3.575, ppl=11.91, wps=40178.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=37700, lr=0.000162866, gnorm=1.083, loss_scale=16, train_wall=153, gb_free=20.8, wall=61381
2022-03-15 03:25:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 03:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:26:33 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 9.769 | ppl 872.63 | wps 66243.1 | wpb 2040.3 | bsz 4 | num_updates 37734 | best_loss 7.537
2022-03-15 03:26:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 37734 updates
2022-03-15 03:26:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:26:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:26:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 367 @ 37734 updates, score 9.769) (writing took 0.9819887019693851 seconds)
2022-03-15 03:26:34 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-15 03:26:34 | INFO | train | epoch 367 | loss 3.574 | ppl 11.91 | wps 39826.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 37734 | lr 0.000162792 | gnorm 1.081 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61440
KL Stats: Epoch 367 Divergences: Uniform: 5.709576449406502 Unigram: 5.367305712403511
2022-03-15 03:26:34 | INFO | fairseq.trainer | begin training epoch 368
2022-03-15 03:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:28:19 | INFO | train_inner | epoch 368:     66 / 103 loss=3.572, ppl=11.89, wps=39798.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=37800, lr=0.00016265, gnorm=1.095, loss_scale=8, train_wall=155, gb_free=20.8, wall=61545
2022-03-15 03:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:29:21 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 9.744 | ppl 857.43 | wps 66280.7 | wpb 2040.3 | bsz 4 | num_updates 37837 | best_loss 7.537
2022-03-15 03:29:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 37837 updates
2022-03-15 03:29:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:29:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:29:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 368 @ 37837 updates, score 9.744) (writing took 0.9915060186758637 seconds)
2022-03-15 03:29:22 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-15 03:29:22 | INFO | train | epoch 368 | loss 3.575 | ppl 11.92 | wps 40211 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37837 | lr 0.00016257 | gnorm 1.092 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61608
KL Stats: Epoch 368 Divergences: Uniform: 5.7084006591157115 Unigram: 5.365430752430474
2022-03-15 03:29:22 | INFO | fairseq.trainer | begin training epoch 369
2022-03-15 03:29:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:31:02 | INFO | train_inner | epoch 369:     63 / 103 loss=3.575, ppl=11.91, wps=40168.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=37900, lr=0.000162435, gnorm=1.075, loss_scale=8, train_wall=153, gb_free=20.8, wall=61708
2022-03-15 03:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:32:08 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 9.764 | ppl 869.35 | wps 66591 | wpb 2040.3 | bsz 4 | num_updates 37940 | best_loss 7.537
2022-03-15 03:32:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 37940 updates
2022-03-15 03:32:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:32:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 369 @ 37940 updates, score 9.764) (writing took 1.0150486892089248 seconds)
2022-03-15 03:32:09 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-15 03:32:09 | INFO | train | epoch 369 | loss 3.573 | ppl 11.9 | wps 40201.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 37940 | lr 0.00016235 | gnorm 1.073 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61775
KL Stats: Epoch 369 Divergences: Uniform: 5.709423655839298 Unigram: 5.367322143521016
2022-03-15 03:32:09 | INFO | fairseq.trainer | begin training epoch 370
2022-03-15 03:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:33:44 | INFO | train_inner | epoch 370:     60 / 103 loss=3.572, ppl=11.89, wps=40184.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=38000, lr=0.000162221, gnorm=1.072, loss_scale=8, train_wall=153, gb_free=20.8, wall=61870
2022-03-15 03:34:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:34:55 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 9.783 | ppl 881.13 | wps 66055.7 | wpb 2040.3 | bsz 4 | num_updates 38043 | best_loss 7.537
2022-03-15 03:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 38043 updates
2022-03-15 03:34:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:34:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:34:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 370 @ 38043 updates, score 9.783) (writing took 1.0069333333522081 seconds)
2022-03-15 03:34:56 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-15 03:34:56 | INFO | train | epoch 370 | loss 3.573 | ppl 11.9 | wps 40214.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38043 | lr 0.00016213 | gnorm 1.081 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 61942
KL Stats: Epoch 370 Divergences: Uniform: 5.710187318106704 Unigram: 5.370237572835885
2022-03-15 03:34:56 | INFO | fairseq.trainer | begin training epoch 371
2022-03-15 03:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:36:27 | INFO | train_inner | epoch 371:     57 / 103 loss=3.571, ppl=11.89, wps=40169.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=38100, lr=0.000162008, gnorm=1.086, loss_scale=8, train_wall=153, gb_free=20.8, wall=62033
2022-03-15 03:37:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:37:43 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 9.772 | ppl 874.47 | wps 66048.4 | wpb 2040.3 | bsz 4 | num_updates 38146 | best_loss 7.537
2022-03-15 03:37:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 38146 updates
2022-03-15 03:37:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:37:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:37:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 371 @ 38146 updates, score 9.772) (writing took 0.9631983069702983 seconds)
2022-03-15 03:37:44 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-15 03:37:44 | INFO | train | epoch 371 | loss 3.571 | ppl 11.88 | wps 40209.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38146 | lr 0.000161911 | gnorm 1.079 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 62110
KL Stats: Epoch 371 Divergences: Uniform: 5.710635226559402 Unigram: 5.371090750362821
2022-03-15 03:37:44 | INFO | fairseq.trainer | begin training epoch 372
2022-03-15 03:37:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:39:09 | INFO | train_inner | epoch 372:     54 / 103 loss=3.57, ppl=11.88, wps=40174.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=38200, lr=0.000161796, gnorm=1.083, loss_scale=8, train_wall=153, gb_free=20.8, wall=62195
2022-03-15 03:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:40:30 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 9.774 | ppl 875.33 | wps 66228.4 | wpb 2040.3 | bsz 4 | num_updates 38249 | best_loss 7.537
2022-03-15 03:40:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 38249 updates
2022-03-15 03:40:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 372 @ 38249 updates, score 9.774) (writing took 0.998027672059834 seconds)
2022-03-15 03:40:31 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-15 03:40:31 | INFO | train | epoch 372 | loss 3.57 | ppl 11.87 | wps 40209.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38249 | lr 0.000161693 | gnorm 1.097 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 62277
KL Stats: Epoch 372 Divergences: Uniform: 5.712130899208352 Unigram: 5.372585069418568
2022-03-15 03:40:31 | INFO | fairseq.trainer | begin training epoch 373
2022-03-15 03:40:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:41:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 03:41:53 | INFO | train_inner | epoch 373:     52 / 103 loss=3.571, ppl=11.88, wps=39799.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=38300, lr=0.000161585, gnorm=1.103, loss_scale=8, train_wall=154, gb_free=20.8, wall=62359
2022-03-15 03:43:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:43:17 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 9.793 | ppl 887.27 | wps 66407.2 | wpb 2040.3 | bsz 4 | num_updates 38351 | best_loss 7.537
2022-03-15 03:43:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 38351 updates
2022-03-15 03:43:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:43:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:43:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 373 @ 38351 updates, score 9.793) (writing took 0.9994039814919233 seconds)
2022-03-15 03:43:18 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-15 03:43:18 | INFO | train | epoch 373 | loss 3.568 | ppl 11.86 | wps 39837.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 38351 | lr 0.000161477 | gnorm 1.088 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 62444
KL Stats: Epoch 373 Divergences: Uniform: 5.711052881474441 Unigram: 5.373199389093981
2022-03-15 03:43:18 | INFO | fairseq.trainer | begin training epoch 374
2022-03-15 03:43:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:44:36 | INFO | train_inner | epoch 374:     49 / 103 loss=3.569, ppl=11.87, wps=40180.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=38400, lr=0.000161374, gnorm=1.079, loss_scale=8, train_wall=153, gb_free=20.8, wall=62522
2022-03-15 03:46:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:46:05 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 9.791 | ppl 885.61 | wps 66090 | wpb 2040.3 | bsz 4 | num_updates 38454 | best_loss 7.537
2022-03-15 03:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 38454 updates
2022-03-15 03:46:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:46:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:46:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 374 @ 38454 updates, score 9.791) (writing took 0.9640518566593528 seconds)
2022-03-15 03:46:05 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-15 03:46:05 | INFO | train | epoch 374 | loss 3.567 | ppl 11.85 | wps 40216.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38454 | lr 0.000161261 | gnorm 1.083 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 62612
KL Stats: Epoch 374 Divergences: Uniform: 5.71182031326322 Unigram: 5.376549571908191
2022-03-15 03:46:05 | INFO | fairseq.trainer | begin training epoch 375
2022-03-15 03:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:47:18 | INFO | train_inner | epoch 375:     46 / 103 loss=3.565, ppl=11.83, wps=40203.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=38500, lr=0.000161165, gnorm=1.082, loss_scale=8, train_wall=153, gb_free=20.8, wall=62684
2022-03-15 03:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:48:52 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 9.797 | ppl 889.42 | wps 66033.2 | wpb 2040.3 | bsz 4 | num_updates 38557 | best_loss 7.537
2022-03-15 03:48:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 38557 updates
2022-03-15 03:48:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:48:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:48:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 375 @ 38557 updates, score 9.797) (writing took 1.0001841085031629 seconds)
2022-03-15 03:48:53 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-15 03:48:53 | INFO | train | epoch 375 | loss 3.566 | ppl 11.85 | wps 40208.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38557 | lr 0.000161045 | gnorm 1.081 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 62779
KL Stats: Epoch 375 Divergences: Uniform: 5.71330134766029 Unigram: 5.376192802100903
2022-03-15 03:48:53 | INFO | fairseq.trainer | begin training epoch 376
2022-03-15 03:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:50:01 | INFO | train_inner | epoch 376:     43 / 103 loss=3.565, ppl=11.84, wps=40160.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=38600, lr=0.000160956, gnorm=1.09, loss_scale=8, train_wall=153, gb_free=20.8, wall=62847
2022-03-15 03:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:51:39 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 9.797 | ppl 889.35 | wps 66614.5 | wpb 2040.3 | bsz 4 | num_updates 38660 | best_loss 7.537
2022-03-15 03:51:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 38660 updates
2022-03-15 03:51:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:51:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:51:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 376 @ 38660 updates, score 9.797) (writing took 1.0014103595167398 seconds)
2022-03-15 03:51:40 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-15 03:51:40 | INFO | train | epoch 376 | loss 3.566 | ppl 11.84 | wps 40214.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38660 | lr 0.000160831 | gnorm 1.093 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 62946
KL Stats: Epoch 376 Divergences: Uniform: 5.712983786248687 Unigram: 5.37619892076869
2022-03-15 03:51:40 | INFO | fairseq.trainer | begin training epoch 377
2022-03-15 03:51:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:52:44 | INFO | train_inner | epoch 377:     40 / 103 loss=3.565, ppl=11.84, wps=40187.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=38700, lr=0.000160748, gnorm=1.083, loss_scale=8, train_wall=153, gb_free=20.8, wall=63010
2022-03-15 03:54:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:54:26 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 9.801 | ppl 892.09 | wps 66433.7 | wpb 2040.3 | bsz 4 | num_updates 38763 | best_loss 7.537
2022-03-15 03:54:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 38763 updates
2022-03-15 03:54:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:54:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:54:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 377 @ 38763 updates, score 9.801) (writing took 0.9654678581282496 seconds)
2022-03-15 03:54:27 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-15 03:54:27 | INFO | train | epoch 377 | loss 3.564 | ppl 11.83 | wps 40226.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38763 | lr 0.000160617 | gnorm 1.081 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 63113
KL Stats: Epoch 377 Divergences: Uniform: 5.713176763351457 Unigram: 5.378901675028939
2022-03-15 03:54:27 | INFO | fairseq.trainer | begin training epoch 378
2022-03-15 03:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:55:26 | INFO | train_inner | epoch 378:     37 / 103 loss=3.564, ppl=11.82, wps=40201.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=38800, lr=0.00016054, gnorm=1.086, loss_scale=16, train_wall=153, gb_free=20.8, wall=63172
2022-03-15 03:57:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:57:14 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 9.794 | ppl 888.05 | wps 66599.7 | wpb 2040.3 | bsz 4 | num_updates 38866 | best_loss 7.537
2022-03-15 03:57:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 38866 updates
2022-03-15 03:57:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:57:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 03:57:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 378 @ 38866 updates, score 9.794) (writing took 0.9910238841548562 seconds)
2022-03-15 03:57:15 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-15 03:57:15 | INFO | train | epoch 378 | loss 3.562 | ppl 11.81 | wps 40218.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 38866 | lr 0.000160404 | gnorm 1.084 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 63281
KL Stats: Epoch 378 Divergences: Uniform: 5.714500364953869 Unigram: 5.3792421859342765
2022-03-15 03:57:15 | INFO | fairseq.trainer | begin training epoch 379
2022-03-15 03:57:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:57:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 03:58:10 | INFO | train_inner | epoch 379:     35 / 103 loss=3.564, ppl=11.83, wps=39786.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=38900, lr=0.000160334, gnorm=1.083, loss_scale=8, train_wall=155, gb_free=20.8, wall=63336
2022-03-15 03:59:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:00:01 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 9.788 | ppl 884.36 | wps 66271.4 | wpb 2040.3 | bsz 4 | num_updates 38968 | best_loss 7.537
2022-03-15 04:00:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 38968 updates
2022-03-15 04:00:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:00:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:00:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 379 @ 38968 updates, score 9.788) (writing took 0.9929371625185013 seconds)
2022-03-15 04:00:02 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-15 04:00:02 | INFO | train | epoch 379 | loss 3.561 | ppl 11.8 | wps 39813.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 38968 | lr 0.000160194 | gnorm 1.089 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 63448
KL Stats: Epoch 379 Divergences: Uniform: 5.715981115668782 Unigram: 5.381483153763743
2022-03-15 04:00:02 | INFO | fairseq.trainer | begin training epoch 380
2022-03-15 04:00:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:00:53 | INFO | train_inner | epoch 380:     32 / 103 loss=3.561, ppl=11.8, wps=40180.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=39000, lr=0.000160128, gnorm=1.083, loss_scale=8, train_wall=153, gb_free=20.8, wall=63499
2022-03-15 04:02:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:02:48 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 9.809 | ppl 897.31 | wps 66033.6 | wpb 2040.3 | bsz 4 | num_updates 39071 | best_loss 7.537
2022-03-15 04:02:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 39071 updates
2022-03-15 04:02:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:02:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:02:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 380 @ 39071 updates, score 9.809) (writing took 0.9450239343568683 seconds)
2022-03-15 04:02:49 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-15 04:02:49 | INFO | train | epoch 380 | loss 3.56 | ppl 11.8 | wps 40219.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39071 | lr 0.000159983 | gnorm 1.076 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 63615
KL Stats: Epoch 380 Divergences: Uniform: 5.716552144422738 Unigram: 5.382739287906379
2022-03-15 04:02:49 | INFO | fairseq.trainer | begin training epoch 381
2022-03-15 04:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:03:35 | INFO | train_inner | epoch 381:     29 / 103 loss=3.56, ppl=11.8, wps=40190, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39100, lr=0.000159923, gnorm=1.084, loss_scale=8, train_wall=153, gb_free=20.8, wall=63661
2022-03-15 04:05:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:05:35 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 9.806 | ppl 895 | wps 66052.1 | wpb 2040.3 | bsz 4 | num_updates 39174 | best_loss 7.537
2022-03-15 04:05:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 39174 updates
2022-03-15 04:05:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:05:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:05:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 381 @ 39174 updates, score 9.806) (writing took 1.0188629208132625 seconds)
2022-03-15 04:05:37 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-15 04:05:37 | INFO | train | epoch 381 | loss 3.56 | ppl 11.8 | wps 40199.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39174 | lr 0.000159772 | gnorm 1.087 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 63783
KL Stats: Epoch 381 Divergences: Uniform: 5.71598724710367 Unigram: 5.383720885273638
2022-03-15 04:05:37 | INFO | fairseq.trainer | begin training epoch 382
2022-03-15 04:05:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:06:18 | INFO | train_inner | epoch 382:     26 / 103 loss=3.559, ppl=11.79, wps=40158.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=39200, lr=0.000159719, gnorm=1.088, loss_scale=8, train_wall=153, gb_free=20.8, wall=63824
2022-03-15 04:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:08:23 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 9.798 | ppl 890.47 | wps 65880.5 | wpb 2040.3 | bsz 4 | num_updates 39277 | best_loss 7.537
2022-03-15 04:08:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 39277 updates
2022-03-15 04:08:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:08:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:08:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 382 @ 39277 updates, score 9.798) (writing took 1.0184727646410465 seconds)
2022-03-15 04:08:24 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-15 04:08:24 | INFO | train | epoch 382 | loss 3.558 | ppl 11.78 | wps 40225.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39277 | lr 0.000159563 | gnorm 1.084 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 63950
KL Stats: Epoch 382 Divergences: Uniform: 5.717129800564316 Unigram: 5.384239326412514
2022-03-15 04:08:24 | INFO | fairseq.trainer | begin training epoch 383
2022-03-15 04:08:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:09:00 | INFO | train_inner | epoch 383:     23 / 103 loss=3.56, ppl=11.8, wps=40194.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=39300, lr=0.000159516, gnorm=1.084, loss_scale=8, train_wall=153, gb_free=20.8, wall=63986
2022-03-15 04:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:11:10 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 9.81 | ppl 897.73 | wps 66418.3 | wpb 2040.3 | bsz 4 | num_updates 39380 | best_loss 7.537
2022-03-15 04:11:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 39380 updates
2022-03-15 04:11:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:11:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:11:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 383 @ 39380 updates, score 9.81) (writing took 0.9870021119713783 seconds)
2022-03-15 04:11:11 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-15 04:11:11 | INFO | train | epoch 383 | loss 3.557 | ppl 11.77 | wps 40229.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39380 | lr 0.000159354 | gnorm 1.077 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64117
KL Stats: Epoch 383 Divergences: Uniform: 5.717877920781396 Unigram: 5.385638367967511
2022-03-15 04:11:11 | INFO | fairseq.trainer | begin training epoch 384
2022-03-15 04:11:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:11:43 | INFO | train_inner | epoch 384:     20 / 103 loss=3.557, ppl=11.77, wps=40195.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39400, lr=0.000159313, gnorm=1.077, loss_scale=16, train_wall=153, gb_free=20.8, wall=64149
2022-03-15 04:13:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 04:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:13:57 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 9.818 | ppl 902.68 | wps 65844.8 | wpb 2040.3 | bsz 4 | num_updates 39482 | best_loss 7.537
2022-03-15 04:13:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 39482 updates
2022-03-15 04:13:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:13:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:13:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 384 @ 39482 updates, score 9.818) (writing took 0.9886699235066772 seconds)
2022-03-15 04:13:58 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-15 04:13:58 | INFO | train | epoch 384 | loss 3.555 | ppl 11.75 | wps 39830.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 39482 | lr 0.000159148 | gnorm 1.091 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64284
KL Stats: Epoch 384 Divergences: Uniform: 5.716936395693544 Unigram: 5.3883745014601745
2022-03-15 04:13:58 | INFO | fairseq.trainer | begin training epoch 385
2022-03-15 04:13:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:14:27 | INFO | train_inner | epoch 385:     18 / 103 loss=3.554, ppl=11.74, wps=39799.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=39500, lr=0.000159111, gnorm=1.086, loss_scale=8, train_wall=155, gb_free=20.8, wall=64313
2022-03-15 04:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:16:44 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 9.785 | ppl 881.99 | wps 66024.8 | wpb 2040.3 | bsz 4 | num_updates 39585 | best_loss 7.537
2022-03-15 04:16:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 39585 updates
2022-03-15 04:16:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 385 @ 39585 updates, score 9.785) (writing took 1.0154171157628298 seconds)
2022-03-15 04:16:45 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-15 04:16:45 | INFO | train | epoch 385 | loss 3.555 | ppl 11.75 | wps 40213.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39585 | lr 0.000158941 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64452
KL Stats: Epoch 385 Divergences: Uniform: 5.71690216836091 Unigram: 5.386716415374408
2022-03-15 04:16:46 | INFO | fairseq.trainer | begin training epoch 386
2022-03-15 04:16:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:17:09 | INFO | train_inner | epoch 386:     15 / 103 loss=3.558, ppl=11.77, wps=40177.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39600, lr=0.00015891, gnorm=1.082, loss_scale=8, train_wall=153, gb_free=20.8, wall=64475
2022-03-15 04:19:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:19:32 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 9.805 | ppl 894.35 | wps 66198.3 | wpb 2040.3 | bsz 4 | num_updates 39688 | best_loss 7.537
2022-03-15 04:19:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 39688 updates
2022-03-15 04:19:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:19:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:19:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 386 @ 39688 updates, score 9.805) (writing took 0.9767486993223429 seconds)
2022-03-15 04:19:33 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-15 04:19:33 | INFO | train | epoch 386 | loss 3.554 | ppl 11.74 | wps 40209.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39688 | lr 0.000158734 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64619
KL Stats: Epoch 386 Divergences: Uniform: 5.717867152784712 Unigram: 5.388211008501912
2022-03-15 04:19:33 | INFO | fairseq.trainer | begin training epoch 387
2022-03-15 04:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:19:52 | INFO | train_inner | epoch 387:     12 / 103 loss=3.554, ppl=11.74, wps=40180.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39700, lr=0.00015871, gnorm=1.085, loss_scale=8, train_wall=153, gb_free=20.8, wall=64638
2022-03-15 04:22:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:22:19 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 9.793 | ppl 887.19 | wps 66547.4 | wpb 2040.3 | bsz 4 | num_updates 39791 | best_loss 7.537
2022-03-15 04:22:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 39791 updates
2022-03-15 04:22:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:22:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:22:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 387 @ 39791 updates, score 9.793) (writing took 1.0191719457507133 seconds)
2022-03-15 04:22:20 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-15 04:22:20 | INFO | train | epoch 387 | loss 3.553 | ppl 11.73 | wps 40214.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39791 | lr 0.000158529 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64786
KL Stats: Epoch 387 Divergences: Uniform: 5.717264779817975 Unigram: 5.388799341095857
2022-03-15 04:22:20 | INFO | fairseq.trainer | begin training epoch 388
2022-03-15 04:22:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:22:34 | INFO | train_inner | epoch 388:      9 / 103 loss=3.554, ppl=11.75, wps=40174.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39800, lr=0.000158511, gnorm=1.075, loss_scale=8, train_wall=153, gb_free=20.8, wall=64800
2022-03-15 04:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:25:06 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 9.814 | ppl 900.39 | wps 66220.9 | wpb 2040.3 | bsz 4 | num_updates 39894 | best_loss 7.537
2022-03-15 04:25:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 39894 updates
2022-03-15 04:25:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:25:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 388 @ 39894 updates, score 9.814) (writing took 1.0562034454196692 seconds)
2022-03-15 04:25:07 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-15 04:25:07 | INFO | train | epoch 388 | loss 3.553 | ppl 11.74 | wps 40206.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 39894 | lr 0.000158324 | gnorm 1.078 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 64953
KL Stats: Epoch 388 Divergences: Uniform: 5.717033230219312 Unigram: 5.390570446041061
2022-03-15 04:25:07 | INFO | fairseq.trainer | begin training epoch 389
2022-03-15 04:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:25:17 | INFO | train_inner | epoch 389:      6 / 103 loss=3.555, ppl=11.75, wps=40175.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=39900, lr=0.000158312, gnorm=1.079, loss_scale=8, train_wall=153, gb_free=20.8, wall=64963
2022-03-15 04:27:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 04:27:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:27:54 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 9.816 | ppl 901.09 | wps 66372.6 | wpb 2040.3 | bsz 4 | num_updates 39996 | best_loss 7.537
2022-03-15 04:27:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 39996 updates
2022-03-15 04:27:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:27:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:27:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 389 @ 39996 updates, score 9.816) (writing took 0.9862143388018012 seconds)
2022-03-15 04:27:55 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-15 04:27:55 | INFO | train | epoch 389 | loss 3.551 | ppl 11.72 | wps 39834.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 39996 | lr 0.000158122 | gnorm 1.085 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 65121
KL Stats: Epoch 389 Divergences: Uniform: 5.7183666218024225 Unigram: 5.391988135839745
2022-03-15 04:27:55 | INFO | fairseq.trainer | begin training epoch 390
2022-03-15 04:27:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:28:01 | INFO | train_inner | epoch 390:      4 / 103 loss=3.551, ppl=11.72, wps=39801.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=40000, lr=0.000158114, gnorm=1.087, loss_scale=8, train_wall=155, gb_free=20.8, wall=65127
2022-03-15 04:30:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:30:41 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 9.788 | ppl 884.35 | wps 66070.6 | wpb 2040.3 | bsz 4 | num_updates 40099 | best_loss 7.537
2022-03-15 04:30:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 40099 updates
2022-03-15 04:30:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:30:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:30:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 390 @ 40099 updates, score 9.788) (writing took 0.9896046249195933 seconds)
2022-03-15 04:30:42 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-15 04:30:42 | INFO | train | epoch 390 | loss 3.548 | ppl 11.7 | wps 40204.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40099 | lr 0.000157919 | gnorm 1.078 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 65288
KL Stats: Epoch 390 Divergences: Uniform: 5.719995481961788 Unigram: 5.39337002570772
2022-03-15 04:30:42 | INFO | fairseq.trainer | begin training epoch 391
2022-03-15 04:30:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:30:44 | INFO | train_inner | epoch 391:      1 / 103 loss=3.55, ppl=11.71, wps=40173.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=40100, lr=0.000157917, gnorm=1.078, loss_scale=8, train_wall=153, gb_free=20.8, wall=65290
2022-03-15 04:33:22 | INFO | train_inner | epoch 391:    101 / 103 loss=3.548, ppl=11.7, wps=41359.8, ups=0.63, wpb=65536, bsz=128, num_updates=40200, lr=0.00015772, gnorm=1.085, loss_scale=8, train_wall=154, gb_free=20.8, wall=65448
2022-03-15 04:33:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:33:28 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 9.804 | ppl 894.12 | wps 66789.6 | wpb 2040.3 | bsz 4 | num_updates 40202 | best_loss 7.537
2022-03-15 04:33:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 40202 updates
2022-03-15 04:33:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:33:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:33:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 391 @ 40202 updates, score 9.804) (writing took 1.0690828366205096 seconds)
2022-03-15 04:33:29 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-15 04:33:29 | INFO | train | epoch 391 | loss 3.548 | ppl 11.7 | wps 40198.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40202 | lr 0.000157716 | gnorm 1.087 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 65455
KL Stats: Epoch 391 Divergences: Uniform: 5.721136674674042 Unigram: 5.3930233936793845
2022-03-15 04:33:29 | INFO | fairseq.trainer | begin training epoch 392
2022-03-15 04:33:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:36:05 | INFO | train_inner | epoch 392:     98 / 103 loss=3.546, ppl=11.68, wps=40163.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=40300, lr=0.000157524, gnorm=1.082, loss_scale=8, train_wall=153, gb_free=20.8, wall=65611
2022-03-15 04:36:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:36:16 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 9.796 | ppl 889.16 | wps 66184.2 | wpb 2040.3 | bsz 4 | num_updates 40305 | best_loss 7.537
2022-03-15 04:36:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 40305 updates
2022-03-15 04:36:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:36:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:36:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 392 @ 40305 updates, score 9.796) (writing took 0.9806273821741343 seconds)
2022-03-15 04:36:17 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-15 04:36:17 | INFO | train | epoch 392 | loss 3.547 | ppl 11.69 | wps 40215.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40305 | lr 0.000157514 | gnorm 1.082 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 65623
KL Stats: Epoch 392 Divergences: Uniform: 5.718847865574322 Unigram: 5.394426271888253
2022-03-15 04:36:17 | INFO | fairseq.trainer | begin training epoch 393
2022-03-15 04:36:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:38:47 | INFO | train_inner | epoch 393:     95 / 103 loss=3.545, ppl=11.67, wps=40201.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=40400, lr=0.000157329, gnorm=1.092, loss_scale=8, train_wall=153, gb_free=20.8, wall=65773
2022-03-15 04:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:39:03 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 9.819 | ppl 903.39 | wps 66201.4 | wpb 2040.3 | bsz 4 | num_updates 40408 | best_loss 7.537
2022-03-15 04:39:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 40408 updates
2022-03-15 04:39:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:39:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:39:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 393 @ 40408 updates, score 9.819) (writing took 1.026606141589582 seconds)
2022-03-15 04:39:04 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-15 04:39:04 | INFO | train | epoch 393 | loss 3.546 | ppl 11.68 | wps 40225.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40408 | lr 0.000157314 | gnorm 1.094 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 65790
KL Stats: Epoch 393 Divergences: Uniform: 5.720985386502265 Unigram: 5.396916735790459
2022-03-15 04:39:04 | INFO | fairseq.trainer | begin training epoch 394
2022-03-15 04:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:41:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 04:41:31 | INFO | train_inner | epoch 394:     93 / 103 loss=3.545, ppl=11.67, wps=39800.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=40500, lr=0.000157135, gnorm=1.089, loss_scale=8, train_wall=155, gb_free=20.8, wall=65937
2022-03-15 04:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:41:50 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 9.822 | ppl 905.35 | wps 66013 | wpb 2040.3 | bsz 4 | num_updates 40510 | best_loss 7.537
2022-03-15 04:41:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 40510 updates
2022-03-15 04:41:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:41:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:41:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 394 @ 40510 updates, score 9.822) (writing took 1.0313783437013626 seconds)
2022-03-15 04:41:51 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-15 04:41:51 | INFO | train | epoch 394 | loss 3.545 | ppl 11.67 | wps 39824.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 40510 | lr 0.000157115 | gnorm 1.09 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 65957
KL Stats: Epoch 394 Divergences: Uniform: 5.7200105566801325 Unigram: 5.396885338685406
2022-03-15 04:41:51 | INFO | fairseq.trainer | begin training epoch 395
2022-03-15 04:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:44:14 | INFO | train_inner | epoch 395:     90 / 103 loss=3.541, ppl=11.64, wps=40178.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=40600, lr=0.000156941, gnorm=1.088, loss_scale=8, train_wall=153, gb_free=20.8, wall=66100
2022-03-15 04:44:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:44:37 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 9.806 | ppl 895.44 | wps 66000.2 | wpb 2040.3 | bsz 4 | num_updates 40613 | best_loss 7.537
2022-03-15 04:44:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 40613 updates
2022-03-15 04:44:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:44:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:44:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 395 @ 40613 updates, score 9.806) (writing took 1.0039631398394704 seconds)
2022-03-15 04:44:38 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-15 04:44:38 | INFO | train | epoch 395 | loss 3.544 | ppl 11.66 | wps 40224.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40613 | lr 0.000156916 | gnorm 1.087 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66124
KL Stats: Epoch 395 Divergences: Uniform: 5.721037575601436 Unigram: 5.396846066033327
2022-03-15 04:44:38 | INFO | fairseq.trainer | begin training epoch 396
2022-03-15 04:44:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:46:56 | INFO | train_inner | epoch 396:     87 / 103 loss=3.542, ppl=11.65, wps=40209.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=40700, lr=0.000156748, gnorm=1.083, loss_scale=8, train_wall=153, gb_free=20.8, wall=66262
2022-03-15 04:47:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:47:25 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 9.835 | ppl 913.22 | wps 66231.7 | wpb 2040.3 | bsz 4 | num_updates 40716 | best_loss 7.537
2022-03-15 04:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 40716 updates
2022-03-15 04:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 396 @ 40716 updates, score 9.835) (writing took 1.0060068778693676 seconds)
2022-03-15 04:47:26 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-15 04:47:26 | INFO | train | epoch 396 | loss 3.542 | ppl 11.64 | wps 40238.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40716 | lr 0.000156717 | gnorm 1.083 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 66292
KL Stats: Epoch 396 Divergences: Uniform: 5.722285110400678 Unigram: 5.400965154745334
2022-03-15 04:47:26 | INFO | fairseq.trainer | begin training epoch 397
2022-03-15 04:47:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:49:39 | INFO | train_inner | epoch 397:     84 / 103 loss=3.537, ppl=11.61, wps=40187.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=40800, lr=0.000156556, gnorm=1.081, loss_scale=8, train_wall=153, gb_free=20.8, wall=66425
2022-03-15 04:50:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:50:12 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 9.81 | ppl 897.73 | wps 66407.7 | wpb 2040.3 | bsz 4 | num_updates 40819 | best_loss 7.537
2022-03-15 04:50:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 40819 updates
2022-03-15 04:50:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:50:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:50:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 397 @ 40819 updates, score 9.81) (writing took 1.0080556459724903 seconds)
2022-03-15 04:50:13 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-15 04:50:13 | INFO | train | epoch 397 | loss 3.541 | ppl 11.64 | wps 40229 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40819 | lr 0.00015652 | gnorm 1.077 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66459
KL Stats: Epoch 397 Divergences: Uniform: 5.72112678788786 Unigram: 5.401510020484377
2022-03-15 04:50:13 | INFO | fairseq.trainer | begin training epoch 398
2022-03-15 04:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:52:21 | INFO | train_inner | epoch 398:     81 / 103 loss=3.54, ppl=11.63, wps=40189.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=40900, lr=0.000156365, gnorm=1.077, loss_scale=8, train_wall=153, gb_free=20.8, wall=66587
2022-03-15 04:52:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:52:59 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 9.813 | ppl 899.8 | wps 66294.1 | wpb 2040.3 | bsz 4 | num_updates 40922 | best_loss 7.537
2022-03-15 04:52:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 40922 updates
2022-03-15 04:52:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:53:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:53:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 398 @ 40922 updates, score 9.813) (writing took 1.032151342369616 seconds)
2022-03-15 04:53:00 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-15 04:53:00 | INFO | train | epoch 398 | loss 3.541 | ppl 11.64 | wps 40215.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 40922 | lr 0.000156323 | gnorm 1.081 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66626
KL Stats: Epoch 398 Divergences: Uniform: 5.721504012202901 Unigram: 5.40082582625978
2022-03-15 04:53:00 | INFO | fairseq.trainer | begin training epoch 399
2022-03-15 04:53:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:55:04 | INFO | train_inner | epoch 399:     78 / 103 loss=3.54, ppl=11.63, wps=40186.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41000, lr=0.000156174, gnorm=1.088, loss_scale=8, train_wall=153, gb_free=20.8, wall=66750
2022-03-15 04:55:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 04:55:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:55:46 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 9.821 | ppl 904.65 | wps 65863.9 | wpb 2040.3 | bsz 4 | num_updates 41024 | best_loss 7.537
2022-03-15 04:55:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 41024 updates
2022-03-15 04:55:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:55:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:55:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 399 @ 41024 updates, score 9.821) (writing took 1.0490592066198587 seconds)
2022-03-15 04:55:47 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-15 04:55:47 | INFO | train | epoch 399 | loss 3.538 | ppl 11.62 | wps 39820.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 41024 | lr 0.000156128 | gnorm 1.089 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66793
KL Stats: Epoch 399 Divergences: Uniform: 5.720476686450303 Unigram: 5.404378647223778
2022-03-15 04:55:47 | INFO | fairseq.trainer | begin training epoch 400
2022-03-15 04:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:57:48 | INFO | train_inner | epoch 400:     76 / 103 loss=3.536, ppl=11.6, wps=39797.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=41100, lr=0.000155984, gnorm=1.069, loss_scale=8, train_wall=154, gb_free=20.8, wall=66914
2022-03-15 04:58:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:58:33 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 9.822 | ppl 905.4 | wps 66201.7 | wpb 2040.3 | bsz 4 | num_updates 41127 | best_loss 7.537
2022-03-15 04:58:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 41127 updates
2022-03-15 04:58:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:58:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 04:58:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 400 @ 41127 updates, score 9.822) (writing took 1.0196897024288774 seconds)
2022-03-15 04:58:35 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-15 04:58:35 | INFO | train | epoch 400 | loss 3.538 | ppl 11.62 | wps 40236.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41127 | lr 0.000155932 | gnorm 1.064 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 66961
KL Stats: Epoch 400 Divergences: Uniform: 5.722651077640894 Unigram: 5.4047816350557385
2022-03-15 04:58:35 | INFO | fairseq.trainer | begin training epoch 401
2022-03-15 04:58:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:00:30 | INFO | train_inner | epoch 401:     73 / 103 loss=3.538, ppl=11.62, wps=40197.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41200, lr=0.000155794, gnorm=1.081, loss_scale=8, train_wall=153, gb_free=20.8, wall=67076
2022-03-15 05:01:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:01:21 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 9.819 | ppl 903.37 | wps 66592.5 | wpb 2040.3 | bsz 4 | num_updates 41230 | best_loss 7.537
2022-03-15 05:01:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 41230 updates
2022-03-15 05:01:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:01:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:01:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 401 @ 41230 updates, score 9.819) (writing took 0.9727295031771064 seconds)
2022-03-15 05:01:22 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-15 05:01:22 | INFO | train | epoch 401 | loss 3.538 | ppl 11.62 | wps 40229 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41230 | lr 0.000155738 | gnorm 1.091 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 67128
KL Stats: Epoch 401 Divergences: Uniform: 5.722585406484039 Unigram: 5.4048722088621926
2022-03-15 05:01:22 | INFO | fairseq.trainer | begin training epoch 402
2022-03-15 05:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:03:13 | INFO | train_inner | epoch 402:     70 / 103 loss=3.534, ppl=11.59, wps=40210.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=41300, lr=0.000155606, gnorm=1.092, loss_scale=8, train_wall=153, gb_free=20.8, wall=67239
2022-03-15 05:04:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:04:08 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 9.834 | ppl 912.8 | wps 66342.3 | wpb 2040.3 | bsz 4 | num_updates 41333 | best_loss 7.537
2022-03-15 05:04:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 41333 updates
2022-03-15 05:04:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:04:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:04:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 402 @ 41333 updates, score 9.834) (writing took 1.0119969034567475 seconds)
2022-03-15 05:04:09 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-15 05:04:09 | INFO | train | epoch 402 | loss 3.535 | ppl 11.59 | wps 40243.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41333 | lr 0.000155543 | gnorm 1.081 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 67295
KL Stats: Epoch 402 Divergences: Uniform: 5.723586658591424 Unigram: 5.405831584179826
2022-03-15 05:04:09 | INFO | fairseq.trainer | begin training epoch 403
2022-03-15 05:04:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:05:55 | INFO | train_inner | epoch 403:     67 / 103 loss=3.535, ppl=11.59, wps=40205.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41400, lr=0.000155417, gnorm=1.092, loss_scale=8, train_wall=153, gb_free=20.8, wall=67401
2022-03-15 05:06:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:06:55 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 9.819 | ppl 903.09 | wps 66351.1 | wpb 2040.3 | bsz 4 | num_updates 41436 | best_loss 7.537
2022-03-15 05:06:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 41436 updates
2022-03-15 05:06:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:06:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:06:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 403 @ 41436 updates, score 9.819) (writing took 1.0392924435436726 seconds)
2022-03-15 05:06:56 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-15 05:06:56 | INFO | train | epoch 403 | loss 3.536 | ppl 11.6 | wps 40222.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41436 | lr 0.00015535 | gnorm 1.095 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 67462
KL Stats: Epoch 403 Divergences: Uniform: 5.723833279120392 Unigram: 5.405878399662693
2022-03-15 05:06:56 | INFO | fairseq.trainer | begin training epoch 404
2022-03-15 05:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:08:38 | INFO | train_inner | epoch 404:     64 / 103 loss=3.537, ppl=11.61, wps=40191.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41500, lr=0.00015523, gnorm=1.092, loss_scale=8, train_wall=153, gb_free=20.8, wall=67564
2022-03-15 05:09:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:09:42 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 9.839 | ppl 915.56 | wps 66493.5 | wpb 2040.3 | bsz 4 | num_updates 41539 | best_loss 7.537
2022-03-15 05:09:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 41539 updates
2022-03-15 05:09:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:09:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:09:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 404 @ 41539 updates, score 9.839) (writing took 0.9885558290407062 seconds)
2022-03-15 05:09:43 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-15 05:09:43 | INFO | train | epoch 404 | loss 3.534 | ppl 11.59 | wps 40242.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41539 | lr 0.000155157 | gnorm 1.096 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 67629
KL Stats: Epoch 404 Divergences: Uniform: 5.725736122650449 Unigram: 5.4075088345246005
2022-03-15 05:09:43 | INFO | fairseq.trainer | begin training epoch 405
2022-03-15 05:09:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:11:20 | INFO | train_inner | epoch 405:     61 / 103 loss=3.533, ppl=11.57, wps=40188.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41600, lr=0.000155043, gnorm=1.094, loss_scale=16, train_wall=153, gb_free=20.8, wall=67726
2022-03-15 05:12:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:12:30 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 9.853 | ppl 924.79 | wps 66032.9 | wpb 2040.3 | bsz 4 | num_updates 41642 | best_loss 7.537
2022-03-15 05:12:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 41642 updates
2022-03-15 05:12:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:12:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:12:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 405 @ 41642 updates, score 9.853) (writing took 0.9592807991430163 seconds)
2022-03-15 05:12:31 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-15 05:12:31 | INFO | train | epoch 405 | loss 3.533 | ppl 11.58 | wps 40224.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41642 | lr 0.000154965 | gnorm 1.083 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 67797
KL Stats: Epoch 405 Divergences: Uniform: 5.725274719092371 Unigram: 5.4107227871197905
2022-03-15 05:12:31 | INFO | fairseq.trainer | begin training epoch 406
2022-03-15 05:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:13:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 05:14:04 | INFO | train_inner | epoch 406:     59 / 103 loss=3.532, ppl=11.57, wps=39814.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=41700, lr=0.000154857, gnorm=1.089, loss_scale=8, train_wall=154, gb_free=20.8, wall=67890
2022-03-15 05:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:15:17 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 9.833 | ppl 912.35 | wps 66358 | wpb 2040.3 | bsz 4 | num_updates 41744 | best_loss 7.537
2022-03-15 05:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 41744 updates
2022-03-15 05:15:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 406 @ 41744 updates, score 9.833) (writing took 1.0715007148683071 seconds)
2022-03-15 05:15:18 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-15 05:15:18 | INFO | train | epoch 406 | loss 3.532 | ppl 11.57 | wps 39822.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 41744 | lr 0.000154776 | gnorm 1.1 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 67964
KL Stats: Epoch 406 Divergences: Uniform: 5.725836256138758 Unigram: 5.409877349682352
2022-03-15 05:15:18 | INFO | fairseq.trainer | begin training epoch 407
2022-03-15 05:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:16:47 | INFO | train_inner | epoch 407:     56 / 103 loss=3.53, ppl=11.55, wps=40186.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=41800, lr=0.000154672, gnorm=1.086, loss_scale=8, train_wall=153, gb_free=20.8, wall=68053
2022-03-15 05:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:18:04 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 9.832 | ppl 911.67 | wps 66188.8 | wpb 2040.3 | bsz 4 | num_updates 41847 | best_loss 7.537
2022-03-15 05:18:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 41847 updates
2022-03-15 05:18:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:18:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:18:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 407 @ 41847 updates, score 9.832) (writing took 0.989296268671751 seconds)
2022-03-15 05:18:05 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-15 05:18:05 | INFO | train | epoch 407 | loss 3.531 | ppl 11.56 | wps 40239.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41847 | lr 0.000154585 | gnorm 1.082 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 68131
KL Stats: Epoch 407 Divergences: Uniform: 5.7258463890072875 Unigram: 5.411103228323159
2022-03-15 05:18:05 | INFO | fairseq.trainer | begin training epoch 408
2022-03-15 05:18:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:19:29 | INFO | train_inner | epoch 408:     53 / 103 loss=3.53, ppl=11.55, wps=40198.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=41900, lr=0.000154487, gnorm=1.087, loss_scale=8, train_wall=153, gb_free=20.8, wall=68215
2022-03-15 05:20:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:20:51 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 9.836 | ppl 913.88 | wps 66188.4 | wpb 2040.3 | bsz 4 | num_updates 41950 | best_loss 7.537
2022-03-15 05:20:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 41950 updates
2022-03-15 05:20:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:20:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:20:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 408 @ 41950 updates, score 9.836) (writing took 0.9979460537433624 seconds)
2022-03-15 05:20:52 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-15 05:20:52 | INFO | train | epoch 408 | loss 3.53 | ppl 11.55 | wps 40215.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 41950 | lr 0.000154395 | gnorm 1.09 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 68298
KL Stats: Epoch 408 Divergences: Uniform: 5.725390941371546 Unigram: 5.412667675165623
2022-03-15 05:20:52 | INFO | fairseq.trainer | begin training epoch 409
2022-03-15 05:20:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:22:12 | INFO | train_inner | epoch 409:     50 / 103 loss=3.532, ppl=11.57, wps=40179.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=42000, lr=0.000154303, gnorm=1.09, loss_scale=8, train_wall=153, gb_free=20.8, wall=68378
2022-03-15 05:23:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:23:38 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 9.824 | ppl 906.41 | wps 65964.5 | wpb 2040.3 | bsz 4 | num_updates 42053 | best_loss 7.537
2022-03-15 05:23:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 42053 updates
2022-03-15 05:23:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:23:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:23:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 409 @ 42053 updates, score 9.824) (writing took 1.0266513796523213 seconds)
2022-03-15 05:23:40 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-15 05:23:40 | INFO | train | epoch 409 | loss 3.53 | ppl 11.55 | wps 40230.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42053 | lr 0.000154206 | gnorm 1.09 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 68466
KL Stats: Epoch 409 Divergences: Uniform: 5.726399755249921 Unigram: 5.413481975750434
2022-03-15 05:23:40 | INFO | fairseq.trainer | begin training epoch 410
2022-03-15 05:23:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:24:54 | INFO | train_inner | epoch 410:     47 / 103 loss=3.527, ppl=11.53, wps=40199, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=42100, lr=0.00015412, gnorm=1.091, loss_scale=8, train_wall=153, gb_free=20.8, wall=68540
2022-03-15 05:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:26:26 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 9.824 | ppl 906.49 | wps 66170.3 | wpb 2040.3 | bsz 4 | num_updates 42156 | best_loss 7.537
2022-03-15 05:26:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 42156 updates
2022-03-15 05:26:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:26:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:26:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 410 @ 42156 updates, score 9.824) (writing took 0.9624223094433546 seconds)
2022-03-15 05:26:27 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-15 05:26:27 | INFO | train | epoch 410 | loss 3.528 | ppl 11.54 | wps 40230.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42156 | lr 0.000154018 | gnorm 1.087 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 68633
KL Stats: Epoch 410 Divergences: Uniform: 5.727600329989412 Unigram: 5.414693488176801
2022-03-15 05:26:27 | INFO | fairseq.trainer | begin training epoch 411
2022-03-15 05:26:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:27:36 | INFO | train_inner | epoch 411:     44 / 103 loss=3.529, ppl=11.55, wps=40204.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=42200, lr=0.000153937, gnorm=1.093, loss_scale=8, train_wall=153, gb_free=20.8, wall=68702
2022-03-15 05:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:29:13 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 9.83 | ppl 910.37 | wps 66122.8 | wpb 2040.3 | bsz 4 | num_updates 42259 | best_loss 7.537
2022-03-15 05:29:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 42259 updates
2022-03-15 05:29:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:29:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:29:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 411 @ 42259 updates, score 9.83) (writing took 1.014141010120511 seconds)
2022-03-15 05:29:14 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-15 05:29:14 | INFO | train | epoch 411 | loss 3.526 | ppl 11.52 | wps 40248.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42259 | lr 0.00015383 | gnorm 1.094 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 68800
KL Stats: Epoch 411 Divergences: Uniform: 5.727661578819216 Unigram: 5.416014807063808
2022-03-15 05:29:14 | INFO | fairseq.trainer | begin training epoch 412
2022-03-15 05:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:30:19 | INFO | train_inner | epoch 412:     41 / 103 loss=3.526, ppl=11.52, wps=40220.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=42300, lr=0.000153755, gnorm=1.084, loss_scale=16, train_wall=153, gb_free=20.8, wall=68865
2022-03-15 05:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:32:00 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 9.847 | ppl 920.81 | wps 66616.3 | wpb 2040.3 | bsz 4 | num_updates 42362 | best_loss 7.537
2022-03-15 05:32:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 42362 updates
2022-03-15 05:32:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:32:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:32:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 412 @ 42362 updates, score 9.847) (writing took 1.0049608135595918 seconds)
2022-03-15 05:32:01 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-15 05:32:01 | INFO | train | epoch 412 | loss 3.526 | ppl 11.52 | wps 40231.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42362 | lr 0.000153643 | gnorm 1.084 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 68967
KL Stats: Epoch 412 Divergences: Uniform: 5.728155825251207 Unigram: 5.416549127599079
2022-03-15 05:32:01 | INFO | fairseq.trainer | begin training epoch 413
2022-03-15 05:32:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:33:01 | INFO | train_inner | epoch 413:     38 / 103 loss=3.526, ppl=11.52, wps=40178.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=42400, lr=0.000153574, gnorm=1.088, loss_scale=16, train_wall=153, gb_free=20.8, wall=69027
2022-03-15 05:34:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 05:34:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:34:47 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 9.834 | ppl 912.88 | wps 66238 | wpb 2040.3 | bsz 4 | num_updates 42464 | best_loss 7.537
2022-03-15 05:34:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 42464 updates
2022-03-15 05:34:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:34:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:34:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 413 @ 42464 updates, score 9.834) (writing took 0.9621514100581408 seconds)
2022-03-15 05:34:48 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-15 05:34:48 | INFO | train | epoch 413 | loss 3.524 | ppl 11.5 | wps 39823.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 42464 | lr 0.000153458 | gnorm 1.1 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 69134
KL Stats: Epoch 413 Divergences: Uniform: 5.730545819651866 Unigram: 5.419121401044278
2022-03-15 05:34:48 | INFO | fairseq.trainer | begin training epoch 414
2022-03-15 05:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:35:45 | INFO | train_inner | epoch 414:     36 / 103 loss=3.524, ppl=11.5, wps=39796, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=42500, lr=0.000153393, gnorm=1.099, loss_scale=8, train_wall=155, gb_free=20.8, wall=69191
2022-03-15 05:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:37:35 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 9.843 | ppl 918.37 | wps 66701.4 | wpb 2040.3 | bsz 4 | num_updates 42567 | best_loss 7.537
2022-03-15 05:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 42567 updates
2022-03-15 05:37:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:37:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:37:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 414 @ 42567 updates, score 9.843) (writing took 1.0091590723022819 seconds)
2022-03-15 05:37:36 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-15 05:37:36 | INFO | train | epoch 414 | loss 3.524 | ppl 11.5 | wps 40203.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42567 | lr 0.000153272 | gnorm 1.092 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 69302
KL Stats: Epoch 414 Divergences: Uniform: 5.727864786578084 Unigram: 5.418997031461233
2022-03-15 05:37:36 | INFO | fairseq.trainer | begin training epoch 415
2022-03-15 05:37:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:38:28 | INFO | train_inner | epoch 415:     33 / 103 loss=3.523, ppl=11.5, wps=40166.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=42600, lr=0.000153213, gnorm=1.085, loss_scale=8, train_wall=153, gb_free=20.8, wall=69354
2022-03-15 05:40:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:40:22 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 9.836 | ppl 913.77 | wps 66351.6 | wpb 2040.3 | bsz 4 | num_updates 42670 | best_loss 7.537
2022-03-15 05:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 42670 updates
2022-03-15 05:40:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:40:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:40:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 415 @ 42670 updates, score 9.836) (writing took 0.9907266516238451 seconds)
2022-03-15 05:40:23 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-15 05:40:23 | INFO | train | epoch 415 | loss 3.522 | ppl 11.49 | wps 40193.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42670 | lr 0.000153087 | gnorm 1.079 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 69469
KL Stats: Epoch 415 Divergences: Uniform: 5.728482105048889 Unigram: 5.420642900274009
2022-03-15 05:40:23 | INFO | fairseq.trainer | begin training epoch 416
2022-03-15 05:40:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:41:11 | INFO | train_inner | epoch 416:     30 / 103 loss=3.522, ppl=11.49, wps=40162, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=42700, lr=0.000153033, gnorm=1.085, loss_scale=8, train_wall=153, gb_free=20.8, wall=69517
2022-03-15 05:43:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:43:09 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 9.855 | ppl 926.35 | wps 66186.7 | wpb 2040.3 | bsz 4 | num_updates 42773 | best_loss 7.537
2022-03-15 05:43:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 42773 updates
2022-03-15 05:43:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:43:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:43:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 416 @ 42773 updates, score 9.855) (writing took 0.9464489975944161 seconds)
2022-03-15 05:43:10 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-15 05:43:10 | INFO | train | epoch 416 | loss 3.522 | ppl 11.49 | wps 40208.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42773 | lr 0.000152903 | gnorm 1.098 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 69636
KL Stats: Epoch 416 Divergences: Uniform: 5.7308332807310105 Unigram: 5.4213982332011454
2022-03-15 05:43:10 | INFO | fairseq.trainer | begin training epoch 417
2022-03-15 05:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:43:53 | INFO | train_inner | epoch 417:     27 / 103 loss=3.521, ppl=11.48, wps=40179.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=42800, lr=0.000152854, gnorm=1.098, loss_scale=8, train_wall=153, gb_free=20.8, wall=69679
2022-03-15 05:45:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:45:57 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 9.846 | ppl 920.58 | wps 65733.5 | wpb 2040.3 | bsz 4 | num_updates 42876 | best_loss 7.537
2022-03-15 05:45:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 42876 updates
2022-03-15 05:45:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:45:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:45:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 417 @ 42876 updates, score 9.846) (writing took 0.9631458315998316 seconds)
2022-03-15 05:45:58 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-15 05:45:58 | INFO | train | epoch 417 | loss 3.52 | ppl 11.47 | wps 40217.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42876 | lr 0.000152719 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 69804
KL Stats: Epoch 417 Divergences: Uniform: 5.730587775148685 Unigram: 5.422577387201914
2022-03-15 05:45:58 | INFO | fairseq.trainer | begin training epoch 418
2022-03-15 05:45:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:46:36 | INFO | train_inner | epoch 418:     24 / 103 loss=3.523, ppl=11.49, wps=40190.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=42900, lr=0.000152676, gnorm=1.08, loss_scale=8, train_wall=153, gb_free=20.8, wall=69842
2022-03-15 05:48:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:48:44 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 9.836 | ppl 913.96 | wps 66241.2 | wpb 2040.3 | bsz 4 | num_updates 42979 | best_loss 7.537
2022-03-15 05:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 42979 updates
2022-03-15 05:48:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:48:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:48:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 418 @ 42979 updates, score 9.836) (writing took 0.9573551127687097 seconds)
2022-03-15 05:48:45 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-15 05:48:45 | INFO | train | epoch 418 | loss 3.519 | ppl 11.47 | wps 40242.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 42979 | lr 0.000152536 | gnorm 1.087 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 69971
KL Stats: Epoch 418 Divergences: Uniform: 5.728371158668599 Unigram: 5.423188562522964
2022-03-15 05:48:45 | INFO | fairseq.trainer | begin training epoch 419
2022-03-15 05:48:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:49:18 | INFO | train_inner | epoch 419:     21 / 103 loss=3.518, ppl=11.46, wps=40206.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=43000, lr=0.000152499, gnorm=1.087, loss_scale=16, train_wall=153, gb_free=20.8, wall=70004
2022-03-15 05:51:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:51:31 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 9.851 | ppl 923.81 | wps 66028.3 | wpb 2040.3 | bsz 4 | num_updates 43082 | best_loss 7.537
2022-03-15 05:51:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 43082 updates
2022-03-15 05:51:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:51:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:51:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 419 @ 43082 updates, score 9.851) (writing took 0.9507478158921003 seconds)
2022-03-15 05:51:32 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-15 05:51:32 | INFO | train | epoch 419 | loss 3.52 | ppl 11.47 | wps 40235.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43082 | lr 0.000152353 | gnorm 1.094 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 70138
KL Stats: Epoch 419 Divergences: Uniform: 5.729162785515008 Unigram: 5.421909080160239
2022-03-15 05:51:32 | INFO | fairseq.trainer | begin training epoch 420
2022-03-15 05:51:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:52:01 | INFO | train_inner | epoch 420:     18 / 103 loss=3.522, ppl=11.49, wps=40204.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=43100, lr=0.000152322, gnorm=1.094, loss_scale=16, train_wall=153, gb_free=20.8, wall=70167
2022-03-15 05:54:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:54:18 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 9.849 | ppl 922.02 | wps 66485.3 | wpb 2040.3 | bsz 4 | num_updates 43185 | best_loss 7.537
2022-03-15 05:54:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 43185 updates
2022-03-15 05:54:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:54:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:54:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 420 @ 43185 updates, score 9.849) (writing took 0.973449326120317 seconds)
2022-03-15 05:54:19 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-15 05:54:19 | INFO | train | epoch 420 | loss 3.519 | ppl 11.46 | wps 40237 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43185 | lr 0.000152172 | gnorm 1.09 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 70305
KL Stats: Epoch 420 Divergences: Uniform: 5.729170085770893 Unigram: 5.4238554618164825
2022-03-15 05:54:19 | INFO | fairseq.trainer | begin training epoch 421
2022-03-15 05:54:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:54:43 | INFO | train_inner | epoch 421:     15 / 103 loss=3.519, ppl=11.46, wps=40202.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43200, lr=0.000152145, gnorm=1.096, loss_scale=16, train_wall=153, gb_free=20.8, wall=70329
2022-03-15 05:56:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 05:57:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:57:05 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 9.86 | ppl 929.54 | wps 66422.1 | wpb 2040.3 | bsz 4 | num_updates 43287 | best_loss 7.537
2022-03-15 05:57:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 43287 updates
2022-03-15 05:57:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:57:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:57:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 421 @ 43287 updates, score 9.86) (writing took 0.9583921674638987 seconds)
2022-03-15 05:57:06 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-15 05:57:06 | INFO | train | epoch 421 | loss 3.517 | ppl 11.45 | wps 39856.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 43287 | lr 0.000151992 | gnorm 1.092 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 70472
KL Stats: Epoch 421 Divergences: Uniform: 5.730071040381838 Unigram: 5.425882196864822
2022-03-15 05:57:06 | INFO | fairseq.trainer | begin training epoch 422
2022-03-15 05:57:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:57:27 | INFO | train_inner | epoch 422:     13 / 103 loss=3.517, ppl=11.45, wps=39827.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=43300, lr=0.000151969, gnorm=1.085, loss_scale=8, train_wall=154, gb_free=20.8, wall=70493
2022-03-15 05:59:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:59:53 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 9.862 | ppl 930.71 | wps 65765.4 | wpb 2040.3 | bsz 4 | num_updates 43390 | best_loss 7.537
2022-03-15 05:59:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 43390 updates
2022-03-15 05:59:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:59:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 05:59:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 422 @ 43390 updates, score 9.862) (writing took 0.9555061385035515 seconds)
2022-03-15 05:59:53 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-15 05:59:53 | INFO | train | epoch 422 | loss 3.515 | ppl 11.44 | wps 40239.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43390 | lr 0.000151812 | gnorm 1.08 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 70640
KL Stats: Epoch 422 Divergences: Uniform: 5.7323345993844494 Unigram: 5.429133866349754
2022-03-15 05:59:54 | INFO | fairseq.trainer | begin training epoch 423
2022-03-15 05:59:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:00:09 | INFO | train_inner | epoch 423:     10 / 103 loss=3.517, ppl=11.45, wps=40210.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43400, lr=0.000151794, gnorm=1.082, loss_scale=8, train_wall=153, gb_free=20.8, wall=70655
2022-03-15 06:02:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:02:40 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 9.855 | ppl 925.88 | wps 66540.6 | wpb 2040.3 | bsz 4 | num_updates 43493 | best_loss 7.537
2022-03-15 06:02:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 43493 updates
2022-03-15 06:02:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:02:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:02:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 423 @ 43493 updates, score 9.855) (writing took 0.9472612030804157 seconds)
2022-03-15 06:02:41 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-15 06:02:41 | INFO | train | epoch 423 | loss 3.515 | ppl 11.43 | wps 40253.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43493 | lr 0.000151632 | gnorm 1.101 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 70807
KL Stats: Epoch 423 Divergences: Uniform: 5.731788049229983 Unigram: 5.427885296222874
2022-03-15 06:02:41 | INFO | fairseq.trainer | begin training epoch 424
2022-03-15 06:02:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:02:52 | INFO | train_inner | epoch 424:      7 / 103 loss=3.517, ppl=11.44, wps=40218.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43500, lr=0.00015162, gnorm=1.099, loss_scale=8, train_wall=153, gb_free=20.8, wall=70818
2022-03-15 06:05:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:05:27 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 9.861 | ppl 930.23 | wps 66266.2 | wpb 2040.3 | bsz 4 | num_updates 43596 | best_loss 7.537
2022-03-15 06:05:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 43596 updates
2022-03-15 06:05:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:05:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:05:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 424 @ 43596 updates, score 9.861) (writing took 0.9592677149921656 seconds)
2022-03-15 06:05:28 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-15 06:05:28 | INFO | train | epoch 424 | loss 3.514 | ppl 11.43 | wps 40240.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43596 | lr 0.000151453 | gnorm 1.098 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 70974
KL Stats: Epoch 424 Divergences: Uniform: 5.730882477278041 Unigram: 5.428853384454972
2022-03-15 06:05:28 | INFO | fairseq.trainer | begin training epoch 425
2022-03-15 06:05:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:05:34 | INFO | train_inner | epoch 425:      4 / 103 loss=3.515, ppl=11.43, wps=40205.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43600, lr=0.000151446, gnorm=1.1, loss_scale=8, train_wall=153, gb_free=20.8, wall=70980
2022-03-15 06:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:08:14 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 9.878 | ppl 940.74 | wps 66099 | wpb 2040.3 | bsz 4 | num_updates 43699 | best_loss 7.537
2022-03-15 06:08:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 43699 updates
2022-03-15 06:08:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:08:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:08:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 425 @ 43699 updates, score 9.878) (writing took 0.9400125443935394 seconds)
2022-03-15 06:08:15 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-15 06:08:15 | INFO | train | epoch 425 | loss 3.513 | ppl 11.41 | wps 40256.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43699 | lr 0.000151274 | gnorm 1.092 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 71141
KL Stats: Epoch 425 Divergences: Uniform: 5.731927109466137 Unigram: 5.430232431258117
2022-03-15 06:08:15 | INFO | fairseq.trainer | begin training epoch 426
2022-03-15 06:08:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:08:17 | INFO | train_inner | epoch 426:      1 / 103 loss=3.514, ppl=11.43, wps=40221.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43700, lr=0.000151272, gnorm=1.093, loss_scale=8, train_wall=153, gb_free=20.8, wall=71143
2022-03-15 06:10:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 06:10:57 | INFO | train_inner | epoch 426:    102 / 103 loss=3.512, ppl=11.41, wps=40940, ups=0.62, wpb=65530.9, bsz=128, num_updates=43800, lr=0.000151099, gnorm=1.088, loss_scale=8, train_wall=155, gb_free=20.8, wall=71303
2022-03-15 06:10:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:11:01 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 9.871 | ppl 936.12 | wps 66344.2 | wpb 2040.3 | bsz 4 | num_updates 43801 | best_loss 7.537
2022-03-15 06:11:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 43801 updates
2022-03-15 06:11:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:11:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:11:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 426 @ 43801 updates, score 9.871) (writing took 0.947541581466794 seconds)
2022-03-15 06:11:02 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-15 06:11:02 | INFO | train | epoch 426 | loss 3.511 | ppl 11.4 | wps 39823.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 43801 | lr 0.000151098 | gnorm 1.091 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 71308
KL Stats: Epoch 426 Divergences: Uniform: 5.732463487047797 Unigram: 5.429812087395385
2022-03-15 06:11:02 | INFO | fairseq.trainer | begin training epoch 427
2022-03-15 06:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:13:39 | INFO | train_inner | epoch 427:     99 / 103 loss=3.51, ppl=11.39, wps=40211.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=43900, lr=0.000150927, gnorm=1.092, loss_scale=8, train_wall=153, gb_free=20.8, wall=71465
2022-03-15 06:13:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:13:48 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 9.859 | ppl 928.36 | wps 66288 | wpb 2040.3 | bsz 4 | num_updates 43904 | best_loss 7.537
2022-03-15 06:13:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 43904 updates
2022-03-15 06:13:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:13:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:13:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 427 @ 43904 updates, score 9.859) (writing took 0.9686508858576417 seconds)
2022-03-15 06:13:49 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-15 06:13:49 | INFO | train | epoch 427 | loss 3.511 | ppl 11.4 | wps 40243.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 43904 | lr 0.00015092 | gnorm 1.092 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 71475
KL Stats: Epoch 427 Divergences: Uniform: 5.732758453498215 Unigram: 5.431385006471433
2022-03-15 06:13:49 | INFO | fairseq.trainer | begin training epoch 428
2022-03-15 06:13:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:16:22 | INFO | train_inner | epoch 428:     96 / 103 loss=3.508, ppl=11.38, wps=40191.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=44000, lr=0.000150756, gnorm=1.088, loss_scale=8, train_wall=153, gb_free=20.8, wall=71628
2022-03-15 06:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:16:36 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 9.879 | ppl 941.3 | wps 66272.5 | wpb 2040.3 | bsz 4 | num_updates 44007 | best_loss 7.537
2022-03-15 06:16:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 44007 updates
2022-03-15 06:16:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:16:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:16:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 428 @ 44007 updates, score 9.879) (writing took 0.9381838897243142 seconds)
2022-03-15 06:16:37 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-15 06:16:37 | INFO | train | epoch 428 | loss 3.51 | ppl 11.39 | wps 40234.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 44007 | lr 0.000150744 | gnorm 1.091 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 71643
KL Stats: Epoch 428 Divergences: Uniform: 5.7329918875769685 Unigram: 5.433900053915885
2022-03-15 06:16:37 | INFO | fairseq.trainer | begin training epoch 429
2022-03-15 06:16:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:19:04 | INFO | train_inner | epoch 429:     93 / 103 loss=3.507, ppl=11.37, wps=40218.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=44100, lr=0.000150585, gnorm=1.085, loss_scale=8, train_wall=153, gb_free=20.8, wall=71790
2022-03-15 06:19:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:19:23 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 9.855 | ppl 925.82 | wps 66014.7 | wpb 2040.3 | bsz 4 | num_updates 44110 | best_loss 7.537
2022-03-15 06:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 44110 updates
2022-03-15 06:19:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:19:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt
2022-03-15 06:19:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.055_0.02_0.925_#1/checkpoint_last.pt (epoch 429 @ 44110 updates, score 9.855) (writing took 0.9409146681427956 seconds)
2022-03-15 06:19:24 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-15 06:19:24 | INFO | train | epoch 429 | loss 3.509 | ppl 11.38 | wps 40247.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 44110 | lr 0.000150568 | gnorm 1.084 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 71810
KL Stats: Epoch 429 Divergences: Uniform: 5.733084644206792 Unigram: 5.432120753334217
2022-03-15 06:19:24 | INFO | fairseq.trainer | begin training epoch 430
2022-03-15 06:19:24 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 496, in train_step
    optimizer.backward(loss)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
