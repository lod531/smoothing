Sender: LSF System <lsfadmin@eu-g2-08>
Subject: Job 202625081: <w2_jelinek_0.11_-0.01_0.9_#2> in cluster <euler> Exited

Job <w2_jelinek_0.11_-0.01_0.9_#2> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Jan 31 08:47:48 2022
Job was executed on host(s) <eu-g2-08>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Jan 31 08:48:12 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Jan 31 08:48:12 2022
Terminated at Tue Feb  1 04:48:18 2022
Results reported at Tue Feb  1 04:48:18 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.11, -0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72887.00 sec.
    Max Memory :                                 5565 MB
    Average Memory :                             3094.44 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14435.00 MB
    Max Swap :                                   5 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72006 sec.
    Turnaround time :                            72030 sec.

The output (if any) follows:

2022-01-31 08:48:20 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.11, -0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-31 08:48:20 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-31 08:48:22 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1401/36718 [00:00<00:02, 14008.11it/s]  8%|▊         | 2802/36718 [00:00<00:02, 13400.28it/s] 12%|█▏        | 4301/36718 [00:00<00:02, 14102.41it/s] 16%|█▌        | 5866/36718 [00:00<00:02, 14702.98it/s] 20%|█▉        | 7339/36718 [00:00<00:02, 13880.25it/s] 24%|██▍       | 8736/36718 [00:00<00:02, 13584.23it/s] 28%|██▊       | 10217/36718 [00:00<00:01, 13964.84it/s] 32%|███▏      | 11620/36718 [00:00<00:01, 13790.31it/s] 36%|███▌      | 13086/36718 [00:00<00:01, 14053.09it/s] 40%|███▉      | 14558/36718 [00:01<00:01, 14253.03it/s] 44%|████▎     | 15988/36718 [00:01<00:01, 14266.42it/s] 48%|████▊     | 17445/36718 [00:01<00:01, 14356.97it/s] 51%|█████▏    | 18899/36718 [00:01<00:01, 14411.70it/s] 55%|█████▌    | 20345/36718 [00:01<00:01, 14424.15it/s] 59%|█████▉    | 21789/36718 [00:01<00:01, 14310.57it/s] 63%|██████▎   | 23295/36718 [00:01<00:00, 14533.78it/s] 68%|██████▊   | 24974/36718 [00:01<00:00, 15205.37it/s] 72%|███████▏  | 26496/36718 [00:01<00:00, 14757.08it/s] 76%|███████▌  | 27976/36718 [00:01<00:00, 14137.73it/s] 80%|████████  | 29419/36718 [00:02<00:00, 14216.92it/s] 84%|████████▍ | 30846/36718 [00:02<00:00, 13977.88it/s] 88%|████████▊ | 32248/36718 [00:02<00:00, 13809.05it/s] 92%|█████████▏| 33632/36718 [00:02<00:00, 13751.28it/s] 96%|█████████▌| 35084/36718 [00:02<00:00, 13966.46it/s] 99%|█████████▉| 36492/36718 [00:02<00:00, 13995.00it/s]100%|██████████| 36718/36718 [00:02<00:00, 14156.60it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  7%|▋         | 2627/36718 [00:00<00:01, 26267.77it/s] 15%|█▌        | 5541/36718 [00:00<00:01, 27954.84it/s] 23%|██▎       | 8337/36718 [00:00<00:01, 27200.08it/s] 30%|███       | 11060/36718 [00:00<00:00, 26992.12it/s] 38%|███▊      | 13829/36718 [00:00<00:00, 27239.16it/s] 45%|████▌     | 16562/36718 [00:00<00:00, 27264.42it/s] 53%|█████▎    | 19509/36718 [00:00<00:00, 27976.41it/s] 61%|██████    | 22308/36718 [00:00<00:00, 27880.17it/s] 70%|██████▉   | 25526/36718 [00:00<00:00, 29213.66it/s] 77%|███████▋  | 28449/36718 [00:01<00:00, 28758.37it/s] 85%|████████▌ | 31328/36718 [00:01<00:00, 28312.89it/s] 93%|█████████▎| 34162/36718 [00:01<00:00, 27849.06it/s]100%|██████████| 36718/36718 [00:01<00:00, 27872.30it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.08it/s]2022-01-31 08:48:35 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-31 08:48:35 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-31 08:48:35 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-31 08:48:35 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-31 08:48:35 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-31 08:48:35 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-31 08:48:35 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-31 08:48:36 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-31 08:48:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:48:36 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-31 08:48:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:48:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-31 08:48:36 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-31 08:48:36 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint_last.pt
2022-01-31 08:48:36 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint_last.pt
2022-01-31 08:48:36 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-31 08:48:36 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-31 08:48:36 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-31 08:48:36 | INFO | fairseq.trainer | begin training epoch 1
2022-01-31 08:48:36 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-31 08:53:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-31 08:54:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.719 | ppl 26972.1 | wps 8018.2 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-31 08:54:26 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-31 08:54:26 | INFO | train | epoch 001 | loss 16.136 | ppl 71992.6 | wps 5980.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.202 | train_wall 321 | gb_free 6.1 | wall 350
KL Stats: Epoch 1 Divergences: Uniform: 0.5171106382047024 Unigram: 3.6858789449895797
2022-01-31 08:54:26 | INFO | fairseq.trainer | begin training epoch 2
2022-01-31 08:54:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 08:57:28 | INFO | train_inner | epoch 002:     36 / 64 loss=15.602, ppl=49731.4, wps=6153.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.623, train_wall=503, gb_free=6.1, wall=532
2022-01-31 08:59:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:00:15 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.729 | ppl 13581.3 | wps 8041.9 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-31 09:00:15 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-31 09:00:15 | INFO | train | epoch 002 | loss 14.447 | ppl 22336.3 | wps 5987.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.477 | train_wall 321 | gb_free 6.1 | wall 699
KL Stats: Epoch 2 Divergences: Uniform: 0.533560633236072 Unigram: 2.4169236367086384
2022-01-31 09:00:15 | INFO | fairseq.trainer | begin training epoch 3
2022-01-31 09:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:06:01 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.917 | ppl 7734.78 | wps 8104.9 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-31 09:06:01 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-31 09:06:01 | INFO | train | epoch 003 | loss 13.555 | ppl 12038 | wps 6033.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.19 | train_wall 318 | gb_free 6.1 | wall 1045
KL Stats: Epoch 3 Divergences: Uniform: 0.5162869045801074 Unigram: 1.7356846949496483
2022-01-31 09:06:01 | INFO | fairseq.trainer | begin training epoch 4
2022-01-31 09:06:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:06:41 | INFO | train_inner | epoch 004:      8 / 64 loss=13.687, ppl=13186.1, wps=5894.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.219, train_wall=497, gb_free=6.1, wall=1085
2022-01-31 09:11:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:11:46 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.084 | ppl 4340.64 | wps 8046.8 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-31 09:11:46 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-31 09:11:46 | INFO | train | epoch 004 | loss 12.618 | ppl 6284.38 | wps 6046.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.947 | train_wall 317 | gb_free 6.1 | wall 1391
KL Stats: Epoch 4 Divergences: Uniform: 0.5977791940112988 Unigram: 1.1260147594738896
2022-01-31 09:11:46 | INFO | fairseq.trainer | begin training epoch 5
2022-01-31 09:11:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:15:28 | INFO | train_inner | epoch 005:     44 / 64 loss=12.274, ppl=4951.8, wps=6197.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.834, train_wall=499, gb_free=6.1, wall=1613
2022-01-31 09:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:17:35 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.571 | ppl 3042.87 | wps 8019.7 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-31 09:17:35 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-31 09:17:35 | INFO | train | epoch 005 | loss 11.834 | ppl 3651.25 | wps 5991.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.681 | train_wall 320 | gb_free 6.1 | wall 1739
KL Stats: Epoch 5 Divergences: Uniform: 0.8302719691463222 Unigram: 0.6766878780237157
2022-01-31 09:17:35 | INFO | fairseq.trainer | begin training epoch 6
2022-01-31 09:17:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:22:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:23:24 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.325 | ppl 2565.28 | wps 8022.8 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-31 09:23:24 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-31 09:23:24 | INFO | train | epoch 006 | loss 11.408 | ppl 2718.18 | wps 5992.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.581 | train_wall 320 | gb_free 6.1 | wall 2088
KL Stats: Epoch 6 Divergences: Uniform: 1.1180389069262155 Unigram: 0.4816152227226491
2022-01-31 09:23:24 | INFO | fairseq.trainer | begin training epoch 7
2022-01-31 09:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:24:44 | INFO | train_inner | epoch 007:     16 / 64 loss=11.431, ppl=2760.11, wps=5862.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.579, train_wall=500, gb_free=6.1, wall=2169
2022-01-31 09:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:29:12 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.179 | ppl 2318.3 | wps 8025.9 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-31 09:29:12 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-31 09:29:12 | INFO | train | epoch 007 | loss 11.209 | ppl 2366.67 | wps 5992.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.523 | train_wall 320 | gb_free 6.1 | wall 2436
KL Stats: Epoch 7 Divergences: Uniform: 1.3326223716701977 Unigram: 0.4965568794391444
2022-01-31 09:29:12 | INFO | fairseq.trainer | begin training epoch 8
2022-01-31 09:29:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:33:34 | INFO | train_inner | epoch 008:     52 / 64 loss=11.147, ppl=2267.25, wps=6168.9, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=501, gb_free=6.1, wall=2699
2022-01-31 09:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:35:00 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.072 | ppl 2152.22 | wps 8072.2 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-31 09:35:00 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-31 09:35:00 | INFO | train | epoch 008 | loss 11.094 | ppl 2186.43 | wps 5994.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 320 | gb_free 6.1 | wall 2785
KL Stats: Epoch 8 Divergences: Uniform: 1.441088107761361 Unigram: 0.5781758444816125
2022-01-31 09:35:00 | INFO | fairseq.trainer | begin training epoch 9
2022-01-31 09:35:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:40:50 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.953 | ppl 1981.77 | wps 8032.3 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-31 09:40:50 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-31 09:40:50 | INFO | train | epoch 009 | loss 10.986 | ppl 2027.84 | wps 5982 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 321 | gb_free 6.1 | wall 3134
KL Stats: Epoch 9 Divergences: Uniform: 1.48232923694785 Unigram: 0.6909154184225449
2022-01-31 09:40:50 | INFO | fairseq.trainer | begin training epoch 10
2022-01-31 09:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:42:51 | INFO | train_inner | epoch 010:     24 / 64 loss=10.976, ppl=2014.52, wps=5857, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.487, train_wall=501, gb_free=6.1, wall=3255
2022-01-31 09:46:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:46:38 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.845 | ppl 1839.79 | wps 8036.5 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-31 09:46:38 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-31 09:46:38 | INFO | train | epoch 010 | loss 10.873 | ppl 1875.96 | wps 5990.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.483 | train_wall 321 | gb_free 6.1 | wall 3483
KL Stats: Epoch 10 Divergences: Uniform: 1.5051192626707617 Unigram: 0.815548152644212
2022-01-31 09:46:38 | INFO | fairseq.trainer | begin training epoch 11
2022-01-31 09:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:51:41 | INFO | train_inner | epoch 011:     60 / 64 loss=10.796, ppl=1777.34, wps=6163.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=502, gb_free=6.1, wall=3785
2022-01-31 09:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:52:27 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.736 | ppl 1705.87 | wps 8048.3 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-31 09:52:27 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-31 09:52:27 | INFO | train | epoch 011 | loss 10.755 | ppl 1727.8 | wps 5984.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.498 | train_wall 321 | gb_free 6.1 | wall 3832
KL Stats: Epoch 11 Divergences: Uniform: 1.5223130737470618 Unigram: 0.9408259592847829
2022-01-31 09:52:27 | INFO | fairseq.trainer | begin training epoch 12
2022-01-31 09:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:57:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:58:17 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.625 | ppl 1579.34 | wps 7945.5 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-31 09:58:17 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-31 09:58:17 | INFO | train | epoch 012 | loss 10.636 | ppl 1591.2 | wps 5973.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.482 | train_wall 321 | gb_free 6.1 | wall 4181
KL Stats: Epoch 12 Divergences: Uniform: 1.5328654112733315 Unigram: 1.0622536844536299
2022-01-31 09:58:17 | INFO | fairseq.trainer | begin training epoch 13
2022-01-31 09:58:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:00:59 | INFO | train_inner | epoch 013:     32 / 64 loss=10.612, ppl=1564.61, wps=5842.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.496, train_wall=502, gb_free=6.1, wall=4343
2022-01-31 10:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:04:07 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.535 | ppl 1483.58 | wps 8012.6 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-31 10:04:07 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-31 10:04:07 | INFO | train | epoch 013 | loss 10.52 | ppl 1468.57 | wps 5970.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 322 | gb_free 6.1 | wall 4531
KL Stats: Epoch 13 Divergences: Uniform: 1.557062515511917 Unigram: 1.1693127984424936
2022-01-31 10:04:07 | INFO | fairseq.trainer | begin training epoch 14
2022-01-31 10:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:09:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:09:56 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.439 | ppl 1388.02 | wps 8046.4 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-31 10:09:56 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-31 10:09:56 | INFO | train | epoch 014 | loss 10.409 | ppl 1359.25 | wps 5985.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.56 | train_wall 321 | gb_free 6.1 | wall 4880
KL Stats: Epoch 14 Divergences: Uniform: 1.5836099849189593 Unigram: 1.2676935243543073
2022-01-31 10:09:56 | INFO | fairseq.trainer | begin training epoch 15
2022-01-31 10:09:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:10:16 | INFO | train_inner | epoch 015:      4 / 64 loss=10.431, ppl=1380.83, wps=5852.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.538, train_wall=501, gb_free=6.1, wall=4900
2022-01-31 10:15:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:15:45 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.369 | ppl 1322.21 | wps 8043.2 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-31 10:15:45 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-31 10:15:45 | INFO | train | epoch 015 | loss 10.296 | ppl 1257.56 | wps 5985.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.541 | train_wall 321 | gb_free 6.1 | wall 5229
KL Stats: Epoch 15 Divergences: Uniform: 1.604885217723347 Unigram: 1.3585080924798159
2022-01-31 10:15:45 | INFO | fairseq.trainer | begin training epoch 16
2022-01-31 10:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:19:07 | INFO | train_inner | epoch 016:     40 / 64 loss=10.255, ppl=1221.97, wps=6156.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.56, train_wall=502, gb_free=6.1, wall=5431
2022-01-31 10:21:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:21:34 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.289 | ppl 1250.83 | wps 8006.2 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-31 10:21:34 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-31 10:21:34 | INFO | train | epoch 016 | loss 10.19 | ppl 1167.96 | wps 5973.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.557 | train_wall 321 | gb_free 6.1 | wall 5579
KL Stats: Epoch 16 Divergences: Uniform: 1.6324820278276087 Unigram: 1.4446118608136946
2022-01-31 10:21:34 | INFO | fairseq.trainer | begin training epoch 17
2022-01-31 10:21:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:26:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:27:23 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.194 | ppl 1171.03 | wps 8068.7 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-31 10:27:23 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-31 10:27:23 | INFO | train | epoch 017 | loss 10.083 | ppl 1084.72 | wps 5985.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.548 | train_wall 321 | gb_free 6.1 | wall 5928
KL Stats: Epoch 17 Divergences: Uniform: 1.666492520836899 Unigram: 1.5197929693654648
2022-01-31 10:27:23 | INFO | fairseq.trainer | begin training epoch 18
2022-01-31 10:27:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:28:24 | INFO | train_inner | epoch 018:     12 / 64 loss=10.097, ppl=1095.43, wps=5854.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.551, train_wall=501, gb_free=6.1, wall=5988
2022-01-31 10:32:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:33:09 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.134 | ppl 1123.53 | wps 8208.2 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-31 10:33:09 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-31 10:33:09 | INFO | train | epoch 018 | loss 9.983 | ppl 1011.78 | wps 6042 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.569 | train_wall 318 | gb_free 6.1 | wall 6273
KL Stats: Epoch 18 Divergences: Uniform: 1.6990609249431612 Unigram: 1.594492043593805
2022-01-31 10:33:09 | INFO | fairseq.trainer | begin training epoch 19
2022-01-31 10:33:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:37:08 | INFO | train_inner | epoch 019:     48 / 64 loss=9.933, ppl=977.65, wps=6229.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.54, train_wall=497, gb_free=6.1, wall=6513
2022-01-31 10:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:38:54 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.057 | ppl 1065.24 | wps 8132 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-31 10:38:54 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-31 10:38:54 | INFO | train | epoch 019 | loss 9.879 | ppl 941.9 | wps 6051.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 317 | gb_free 6.1 | wall 6619
KL Stats: Epoch 19 Divergences: Uniform: 1.7271330018494322 Unigram: 1.6682365866592075
2022-01-31 10:38:54 | INFO | fairseq.trainer | begin training epoch 20
2022-01-31 10:38:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:44:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:44:41 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.973 | ppl 1004.87 | wps 8134.9 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-31 10:44:41 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-31 10:44:41 | INFO | train | epoch 020 | loss 9.783 | ppl 880.93 | wps 6019.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.548 | train_wall 319 | gb_free 6.1 | wall 6966
KL Stats: Epoch 20 Divergences: Uniform: 1.7575968569032996 Unigram: 1.7355260210888046
2022-01-31 10:44:41 | INFO | fairseq.trainer | begin training epoch 21
2022-01-31 10:44:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:46:21 | INFO | train_inner | epoch 021:     20 / 64 loss=9.778, ppl=877.87, wps=5893.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.545, train_wall=498, gb_free=6.1, wall=7066
2022-01-31 10:50:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:50:28 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.931 | ppl 976.06 | wps 8080.3 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-31 10:50:28 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-31 10:50:28 | INFO | train | epoch 021 | loss 9.689 | ppl 825.32 | wps 6024.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.53 | train_wall 319 | gb_free 6.1 | wall 7312
KL Stats: Epoch 21 Divergences: Uniform: 1.7872851899185553 Unigram: 1.8023461702925017
2022-01-31 10:50:28 | INFO | fairseq.trainer | begin training epoch 22
2022-01-31 10:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:55:09 | INFO | train_inner | epoch 022:     56 / 64 loss=9.636, ppl=795.86, wps=6196.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.541, train_wall=499, gb_free=6.1, wall=7593
2022-01-31 10:55:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:56:14 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.867 | ppl 933.84 | wps 8132.8 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-31 10:56:14 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-31 10:56:14 | INFO | train | epoch 022 | loss 9.6 | ppl 775.94 | wps 6023.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.55 | train_wall 319 | gb_free 6.1 | wall 7659
KL Stats: Epoch 22 Divergences: Uniform: 1.8113941170615828 Unigram: 1.8674924177854684
2022-01-31 10:56:14 | INFO | fairseq.trainer | begin training epoch 23
2022-01-31 10:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:02:02 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.803 | ppl 893.61 | wps 8134.4 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-31 11:02:02 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-31 11:02:02 | INFO | train | epoch 023 | loss 9.513 | ppl 730.66 | wps 6018.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.516 | train_wall 319 | gb_free 6.1 | wall 8006
KL Stats: Epoch 23 Divergences: Uniform: 1.839375828670175 Unigram: 1.9252475437142296
2022-01-31 11:02:02 | INFO | fairseq.trainer | begin training epoch 24
2022-01-31 11:02:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:04:22 | INFO | train_inner | epoch 024:     28 / 64 loss=9.498, ppl=723.12, wps=5892.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.531, train_wall=498, gb_free=6.1, wall=8146
2022-01-31 11:07:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:07:49 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.745 | ppl 857.85 | wps 8063.9 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-31 11:07:49 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-31 11:07:49 | INFO | train | epoch 024 | loss 9.43 | ppl 689.88 | wps 6018.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.564 | train_wall 319 | gb_free 6.1 | wall 8353
KL Stats: Epoch 24 Divergences: Uniform: 1.8600812712828954 Unigram: 1.978621486976207
2022-01-31 11:07:49 | INFO | fairseq.trainer | begin training epoch 25
2022-01-31 11:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:13:08 | INFO | train_inner | epoch 025:     64 / 64 loss=9.376, ppl=664.63, wps=6199.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.545, train_wall=497, gb_free=6.1, wall=8672
2022-01-31 11:13:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:13:35 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.715 | ppl 840.18 | wps 8135.6 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-31 11:13:35 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-31 11:13:35 | INFO | train | epoch 025 | loss 9.349 | ppl 651.95 | wps 6035.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.53 | train_wall 318 | gb_free 6.1 | wall 8699
KL Stats: Epoch 25 Divergences: Uniform: 1.88861118038125 Unigram: 2.0342098927952903
2022-01-31 11:13:35 | INFO | fairseq.trainer | begin training epoch 26
2022-01-31 11:13:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:18:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:19:20 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.664 | ppl 811.31 | wps 8133.3 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-31 11:19:20 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-31 11:19:20 | INFO | train | epoch 026 | loss 9.268 | ppl 616.35 | wps 6039.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.545 | train_wall 318 | gb_free 6.1 | wall 9045
KL Stats: Epoch 26 Divergences: Uniform: 1.9008871858722096 Unigram: 2.0835399930338516
2022-01-31 11:19:20 | INFO | fairseq.trainer | begin training epoch 27
2022-01-31 11:19:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:22:21 | INFO | train_inner | epoch 027:     36 / 64 loss=9.24, ppl=604.67, wps=5906.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.54, train_wall=498, gb_free=6.1, wall=9226
2022-01-31 11:24:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:25:07 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.631 | ppl 792.98 | wps 8123.4 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-31 11:25:07 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-31 11:25:07 | INFO | train | epoch 027 | loss 9.188 | ppl 583.25 | wps 6020.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.533 | train_wall 319 | gb_free 6.1 | wall 9392
KL Stats: Epoch 27 Divergences: Uniform: 1.9268720136236943 Unigram: 2.1285420285295604
2022-01-31 11:25:07 | INFO | fairseq.trainer | begin training epoch 28
2022-01-31 11:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:30:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:30:54 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.604 | ppl 778.42 | wps 8126.9 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-31 11:30:54 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-31 11:30:54 | INFO | train | epoch 028 | loss 9.11 | ppl 552.5 | wps 6026.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.527 | train_wall 319 | gb_free 6.1 | wall 9738
KL Stats: Epoch 28 Divergences: Uniform: 1.9558787386098861 Unigram: 2.1766612490600235
2022-01-31 11:30:54 | INFO | fairseq.trainer | begin training epoch 29
2022-01-31 11:30:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:31:34 | INFO | train_inner | epoch 029:      8 / 64 loss=9.125, ppl=558.51, wps=5892.9, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.532, train_wall=498, gb_free=6.1, wall=9779
2022-01-31 11:36:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:36:41 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.567 | ppl 758.66 | wps 8116.5 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-31 11:36:41 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-31 11:36:41 | INFO | train | epoch 029 | loss 9.031 | ppl 523.09 | wps 6022.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.525 | train_wall 319 | gb_free 6.1 | wall 10085
KL Stats: Epoch 29 Divergences: Uniform: 1.9760192409918353 Unigram: 2.2196457963808873
2022-01-31 11:36:41 | INFO | fairseq.trainer | begin training epoch 30
2022-01-31 11:36:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:40:21 | INFO | train_inner | epoch 030:     44 / 64 loss=8.998, ppl=511.29, wps=6204.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.516, train_wall=498, gb_free=6.1, wall=10305
2022-01-31 11:42:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:42:27 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.544 | ppl 746.67 | wps 8061.6 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-31 11:42:27 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-31 11:42:27 | INFO | train | epoch 030 | loss 8.954 | ppl 495.79 | wps 6028.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.523 | train_wall 318 | gb_free 6.1 | wall 10432
KL Stats: Epoch 30 Divergences: Uniform: 1.993195625183268 Unigram: 2.2669259936768267
2022-01-31 11:42:27 | INFO | fairseq.trainer | begin training epoch 31
2022-01-31 11:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:48:13 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.494 | ppl 720.96 | wps 8149 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-31 11:48:13 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-31 11:48:13 | INFO | train | epoch 031 | loss 8.874 | ppl 469.22 | wps 6036.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.5 | train_wall 318 | gb_free 6.1 | wall 10778
KL Stats: Epoch 31 Divergences: Uniform: 2.0115572472863126 Unigram: 2.3072716586599338
2022-01-31 11:48:13 | INFO | fairseq.trainer | begin training epoch 32
2022-01-31 11:48:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:49:33 | INFO | train_inner | epoch 032:     16 / 64 loss=8.875, ppl=469.65, wps=5901.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.508, train_wall=497, gb_free=6.1, wall=10858
2022-01-31 11:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:53:59 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.46 | ppl 704.15 | wps 8158.1 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-31 11:53:59 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-31 11:53:59 | INFO | train | epoch 032 | loss 8.801 | ppl 445.89 | wps 6034.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.512 | train_wall 318 | gb_free 6.1 | wall 11124
KL Stats: Epoch 32 Divergences: Uniform: 2.039364226489823 Unigram: 2.349113817485872
2022-01-31 11:53:59 | INFO | fairseq.trainer | begin training epoch 33
2022-01-31 11:53:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:58:20 | INFO | train_inner | epoch 033:     52 / 64 loss=8.764, ppl=434.62, wps=6210.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.515, train_wall=498, gb_free=6.1, wall=11384
2022-01-31 11:59:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:59:45 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.444 | ppl 696.27 | wps 8172.7 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-31 11:59:45 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-31 11:59:45 | INFO | train | epoch 033 | loss 8.726 | ppl 423.47 | wps 6040.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.514 | train_wall 318 | gb_free 6.1 | wall 11470
KL Stats: Epoch 33 Divergences: Uniform: 2.0618618398150814 Unigram: 2.397358807785163
2022-01-31 11:59:45 | INFO | fairseq.trainer | begin training epoch 34
2022-01-31 11:59:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:05:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:05:29 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.424 | ppl 686.89 | wps 8216 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-31 12:05:29 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-31 12:05:29 | INFO | train | epoch 034 | loss 8.65 | ppl 401.83 | wps 6075.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.516 | train_wall 316 | gb_free 6.1 | wall 11813
KL Stats: Epoch 34 Divergences: Uniform: 2.082294738509631 Unigram: 2.4387711432051034
2022-01-31 12:05:29 | INFO | fairseq.trainer | begin training epoch 35
2022-01-31 12:05:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:07:28 | INFO | train_inner | epoch 035:     24 / 64 loss=8.638, ppl=398.25, wps=5941.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.515, train_wall=494, gb_free=6.1, wall=11933
2022-01-31 12:10:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:11:14 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.396 | ppl 673.88 | wps 8146.5 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-31 12:11:14 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-31 12:11:14 | INFO | train | epoch 035 | loss 8.578 | ppl 382.13 | wps 6059.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.509 | train_wall 317 | gb_free 6.1 | wall 12158
KL Stats: Epoch 35 Divergences: Uniform: 2.103809158483506 Unigram: 2.475979529853614
2022-01-31 12:11:14 | INFO | fairseq.trainer | begin training epoch 36
2022-01-31 12:11:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:16:15 | INFO | train_inner | epoch 036:     60 / 64 loss=8.534, ppl=370.75, wps=6207.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.51, train_wall=498, gb_free=6.1, wall=12459
2022-01-31 12:16:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:17:01 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.37 | ppl 661.76 | wps 8043.8 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-31 12:17:01 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-31 12:17:01 | INFO | train | epoch 036 | loss 8.505 | ppl 363.21 | wps 6014.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.51 | train_wall 319 | gb_free 6.1 | wall 12505
KL Stats: Epoch 36 Divergences: Uniform: 2.1246713908365233 Unigram: 2.5216195951606557
2022-01-31 12:17:01 | INFO | fairseq.trainer | begin training epoch 37
2022-01-31 12:17:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:22:47 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.39 | ppl 670.9 | wps 8085.1 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-31 12:22:47 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-31 12:22:47 | INFO | train | epoch 037 | loss 8.435 | ppl 346.1 | wps 6027.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.513 | train_wall 319 | gb_free 6.1 | wall 12852
KL Stats: Epoch 37 Divergences: Uniform: 2.1425923121224177 Unigram: 2.564022273420494
2022-01-31 12:22:47 | INFO | fairseq.trainer | begin training epoch 38
2022-01-31 12:22:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:25:28 | INFO | train_inner | epoch 038:     32 / 64 loss=8.414, ppl=341.01, wps=5890.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.511, train_wall=498, gb_free=6.1, wall=13013
2022-01-31 12:28:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:28:35 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.369 | ppl 661.03 | wps 8104.9 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-31 12:28:35 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-31 12:28:35 | INFO | train | epoch 038 | loss 8.367 | ppl 330.06 | wps 6013 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.512 | train_wall 319 | gb_free 6.1 | wall 13199
KL Stats: Epoch 38 Divergences: Uniform: 2.171568709799728 Unigram: 2.5955388278258518
2022-01-31 12:28:35 | INFO | fairseq.trainer | begin training epoch 39
2022-01-31 12:28:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:33:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:34:22 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.347 | ppl 651.15 | wps 8118.4 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-31 12:34:22 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-31 12:34:22 | INFO | train | epoch 039 | loss 8.298 | ppl 314.65 | wps 6020.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.504 | train_wall 319 | gb_free 6.1 | wall 13546
KL Stats: Epoch 39 Divergences: Uniform: 2.1804200416663146 Unigram: 2.640163408085552
2022-01-31 12:34:22 | INFO | fairseq.trainer | begin training epoch 40
2022-01-31 12:34:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:34:42 | INFO | train_inner | epoch 040:      4 / 64 loss=8.319, ppl=319.43, wps=5888.1, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.508, train_wall=498, gb_free=6.1, wall=13566
2022-01-31 12:39:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:40:07 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.326 | ppl 641.68 | wps 8134.1 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-31 12:40:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-31 12:40:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint40.pt
2022-01-31 12:40:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint40.pt
2022-01-31 12:40:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.326) (writing took 5.3829080406576395 seconds)
2022-01-31 12:40:13 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-31 12:40:13 | INFO | train | epoch 040 | loss 8.229 | ppl 300.03 | wps 5947.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.508 | train_wall 318 | gb_free 6.1 | wall 13897
KL Stats: Epoch 40 Divergences: Uniform: 2.2076651354763066 Unigram: 2.67738658187128
2022-01-31 12:40:13 | INFO | fairseq.trainer | begin training epoch 41
2022-01-31 12:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:43:33 | INFO | train_inner | epoch 041:     40 / 64 loss=8.205, ppl=295.15, wps=6147.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.506, train_wall=498, gb_free=6.1, wall=14098
2022-01-31 12:45:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:46:00 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.317 | ppl 637.77 | wps 8118.9 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.317
2022-01-31 12:46:00 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-31 12:46:00 | INFO | train | epoch 041 | loss 8.165 | ppl 286.96 | wps 6022.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.505 | train_wall 319 | gb_free 6.1 | wall 14244
KL Stats: Epoch 41 Divergences: Uniform: 2.221443738611444 Unigram: 2.712206682521822
2022-01-31 12:46:00 | INFO | fairseq.trainer | begin training epoch 42
2022-01-31 12:46:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:51:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:51:46 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.294 | ppl 627.71 | wps 8081.2 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.294
2022-01-31 12:51:46 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-31 12:51:46 | INFO | train | epoch 042 | loss 8.101 | ppl 274.49 | wps 6021.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.515 | train_wall 319 | gb_free 6.1 | wall 14591
KL Stats: Epoch 42 Divergences: Uniform: 2.237935346230051 Unigram: 2.7540435213223597
2022-01-31 12:51:46 | INFO | fairseq.trainer | begin training epoch 43
2022-01-31 12:51:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:52:47 | INFO | train_inner | epoch 043:     12 / 64 loss=8.107, ppl=275.71, wps=5891.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.514, train_wall=498, gb_free=6.1, wall=14651
2022-01-31 12:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:57:33 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.327 | ppl 642.05 | wps 8117.1 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.326
2022-01-31 12:57:33 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-31 12:57:33 | INFO | train | epoch 043 | loss 8.036 | ppl 262.4 | wps 6032.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.507 | train_wall 318 | gb_free 6.1 | wall 14937
KL Stats: Epoch 43 Divergences: Uniform: 2.261333200701914 Unigram: 2.7913128920147487
2022-01-31 12:57:33 | INFO | fairseq.trainer | begin training epoch 44
2022-01-31 12:57:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:01:33 | INFO | train_inner | epoch 044:     48 / 64 loss=8.002, ppl=256.33, wps=6210.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.513, train_wall=498, gb_free=6.1, wall=15177
2022-01-31 13:02:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:03:19 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.34 | ppl 648.11 | wps 8103.1 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.326
2022-01-31 13:03:19 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-31 13:03:19 | INFO | train | epoch 044 | loss 7.976 | ppl 251.79 | wps 6034.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.513 | train_wall 318 | gb_free 6.1 | wall 15283
KL Stats: Epoch 44 Divergences: Uniform: 2.2775280908431363 Unigram: 2.826799115233034
2022-01-31 13:03:19 | INFO | fairseq.trainer | begin training epoch 45
2022-01-31 13:03:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:08:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:09:05 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.316 | ppl 637.33 | wps 8134 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.316
2022-01-31 13:09:05 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-31 13:09:05 | INFO | train | epoch 045 | loss 7.913 | ppl 241.04 | wps 6025.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.515 | train_wall 319 | gb_free 6.1 | wall 15630
KL Stats: Epoch 45 Divergences: Uniform: 2.294562090570219 Unigram: 2.869581372061677
2022-01-31 13:09:05 | INFO | fairseq.trainer | begin training epoch 46
2022-01-31 13:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:10:46 | INFO | train_inner | epoch 046:     20 / 64 loss=7.913, ppl=240.97, wps=5897, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.514, train_wall=498, gb_free=6.1, wall=15730
2022-01-31 13:14:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:14:52 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.313 | ppl 635.98 | wps 8058.6 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.313
2022-01-31 13:14:52 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-31 13:14:52 | INFO | train | epoch 046 | loss 7.854 | ppl 231.41 | wps 6023.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.523 | train_wall 319 | gb_free 6.1 | wall 15977
KL Stats: Epoch 46 Divergences: Uniform: 2.3092151561208794 Unigram: 2.894159442310697
2022-01-31 13:14:52 | INFO | fairseq.trainer | begin training epoch 47
2022-01-31 13:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:19:33 | INFO | train_inner | epoch 047:     56 / 64 loss=7.823, ppl=226.49, wps=6195.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.51, train_wall=499, gb_free=6.1, wall=16258
2022-01-31 13:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:20:39 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.302 | ppl 631.18 | wps 8116.4 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.302
2022-01-31 13:20:39 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-31 13:20:39 | INFO | train | epoch 047 | loss 7.796 | ppl 222.18 | wps 6019.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.506 | train_wall 319 | gb_free 6.1 | wall 16324
KL Stats: Epoch 47 Divergences: Uniform: 2.3318123438598524 Unigram: 2.925511145136698
2022-01-31 13:20:39 | INFO | fairseq.trainer | begin training epoch 48
2022-01-31 13:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:26:27 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.294 | ppl 627.78 | wps 8083.5 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.294
2022-01-31 13:26:27 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-31 13:26:27 | INFO | train | epoch 048 | loss 7.739 | ppl 213.6 | wps 6002.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.518 | train_wall 320 | gb_free 6.1 | wall 16672
KL Stats: Epoch 48 Divergences: Uniform: 2.347705015858914 Unigram: 2.963357710594926
2022-01-31 13:26:27 | INFO | fairseq.trainer | begin training epoch 49
2022-01-31 13:26:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:28:48 | INFO | train_inner | epoch 049:     28 / 64 loss=7.721, ppl=211.01, wps=5880.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.517, train_wall=499, gb_free=6.1, wall=16812
2022-01-31 13:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:32:13 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.333 | ppl 645.13 | wps 8154.3 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.326
2022-01-31 13:32:13 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-31 13:32:13 | INFO | train | epoch 049 | loss 7.682 | ppl 205.3 | wps 6035.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.518 | train_wall 318 | gb_free 6.1 | wall 17018
KL Stats: Epoch 49 Divergences: Uniform: 2.3515043399411204 Unigram: 2.9950348147804133
2022-01-31 13:32:13 | INFO | fairseq.trainer | begin training epoch 50
2022-01-31 13:32:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:37:31 | INFO | train_inner | epoch 050:     64 / 64 loss=7.657, ppl=201.84, wps=6231.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.529, train_wall=495, gb_free=6.1, wall=17335
2022-01-31 13:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:37:57 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.347 | ppl 651.01 | wps 8199.1 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.326
2022-01-31 13:37:57 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-31 13:37:57 | INFO | train | epoch 050 | loss 7.63 | ppl 198.14 | wps 6066.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.534 | train_wall 317 | gb_free 6.1 | wall 17362
KL Stats: Epoch 50 Divergences: Uniform: 2.3674361136453816 Unigram: 3.0203142879382803
2022-01-31 13:37:57 | INFO | fairseq.trainer | begin training epoch 51
2022-01-31 13:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:43:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:43:43 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.355 | ppl 654.97 | wps 8105.1 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.326
2022-01-31 13:43:43 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-31 13:43:43 | INFO | train | epoch 051 | loss 7.574 | ppl 190.59 | wps 6044 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.519 | train_wall 318 | gb_free 6.1 | wall 17707
KL Stats: Epoch 51 Divergences: Uniform: 2.394050767778345 Unigram: 3.0478396800905134
2022-01-31 13:43:43 | INFO | fairseq.trainer | begin training epoch 52
2022-01-31 13:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:46:44 | INFO | train_inner | epoch 052:     36 / 64 loss=7.55, ppl=187.46, wps=5909.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.52, train_wall=498, gb_free=6.1, wall=17888
2022-01-31 13:49:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:49:30 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.344 | ppl 650.08 | wps 8117.3 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.326
2022-01-31 13:49:30 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-31 13:49:30 | INFO | train | epoch 052 | loss 7.522 | ppl 183.8 | wps 6020.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.525 | train_wall 319 | gb_free 6.1 | wall 18054
KL Stats: Epoch 52 Divergences: Uniform: 2.407123674882871 Unigram: 3.0920985578908637
2022-01-31 13:49:30 | INFO | fairseq.trainer | begin training epoch 53
2022-01-31 13:49:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:54:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:55:17 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.331 | ppl 644.16 | wps 8147.2 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.326
2022-01-31 13:55:17 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-31 13:55:17 | INFO | train | epoch 053 | loss 7.471 | ppl 177.37 | wps 6024.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.518 | train_wall 319 | gb_free 6.1 | wall 18401
KL Stats: Epoch 53 Divergences: Uniform: 2.4222252122360075 Unigram: 3.1153657475525254
2022-01-31 13:55:17 | INFO | fairseq.trainer | begin training epoch 54
2022-01-31 13:55:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:55:57 | INFO | train_inner | epoch 054:      8 / 64 loss=7.483, ppl=178.96, wps=5895.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.525, train_wall=498, gb_free=6.1, wall=18441
2022-01-31 14:00:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:01:03 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.364 | ppl 658.91 | wps 7998.4 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.326
2022-01-31 14:01:03 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-31 14:01:03 | INFO | train | epoch 054 | loss 7.42 | ppl 171.3 | wps 6021.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.526 | train_wall 319 | gb_free 6.1 | wall 18748
KL Stats: Epoch 54 Divergences: Uniform: 2.431386707625916 Unigram: 3.1426068885666076
2022-01-31 14:01:03 | INFO | fairseq.trainer | begin training epoch 55
2022-01-31 14:01:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:04:44 | INFO | train_inner | epoch 055:     44 / 64 loss=7.393, ppl=168.11, wps=6193.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.527, train_wall=499, gb_free=6.1, wall=18969
2022-01-31 14:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:06:51 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.382 | ppl 667.26 | wps 8118 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.326
2022-01-31 14:06:51 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-31 14:06:51 | INFO | train | epoch 055 | loss 7.374 | ppl 165.85 | wps 6016.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.54 | train_wall 319 | gb_free 6.1 | wall 19095
KL Stats: Epoch 55 Divergences: Uniform: 2.4412968343911676 Unigram: 3.177885878313609
2022-01-31 14:06:51 | INFO | fairseq.trainer | begin training epoch 56
2022-01-31 14:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:12:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:12:38 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.465 | ppl 706.55 | wps 8078.2 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.326
2022-01-31 14:12:38 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-31 14:12:38 | INFO | train | epoch 056 | loss 7.324 | ppl 160.22 | wps 6012.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.529 | train_wall 319 | gb_free 6.1 | wall 19442
KL Stats: Epoch 56 Divergences: Uniform: 2.4449243932843365 Unigram: 3.1982874194093136
2022-01-31 14:12:38 | INFO | fairseq.trainer | begin training epoch 57
2022-01-31 14:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:13:58 | INFO | train_inner | epoch 057:     16 / 64 loss=7.328, ppl=160.69, wps=5888.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.537, train_wall=498, gb_free=6.1, wall=19523
2022-01-31 14:17:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:18:24 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.471 | ppl 709.45 | wps 8148.6 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.326
2022-01-31 14:18:24 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-31 14:18:24 | INFO | train | epoch 057 | loss 7.277 | ppl 155.09 | wps 6031 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.541 | train_wall 319 | gb_free 6.1 | wall 19789
KL Stats: Epoch 57 Divergences: Uniform: 2.4738395278632668 Unigram: 3.235402570953911
2022-01-31 14:18:24 | INFO | fairseq.trainer | begin training epoch 58
2022-01-31 14:18:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:22:45 | INFO | train_inner | epoch 058:     52 / 64 loss=7.252, ppl=152.45, wps=6196.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.536, train_wall=499, gb_free=6.1, wall=20050
2022-01-31 14:23:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:24:11 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.49 | ppl 719.27 | wps 8088.9 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.326
2022-01-31 14:24:11 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-31 14:24:11 | INFO | train | epoch 058 | loss 7.232 | ppl 150.32 | wps 6016.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.539 | train_wall 319 | gb_free 6.1 | wall 20136
KL Stats: Epoch 58 Divergences: Uniform: 2.482570292629034 Unigram: 3.261137688260474
2022-01-31 14:24:11 | INFO | fairseq.trainer | begin training epoch 59
2022-01-31 14:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:29:58 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.54 | ppl 744.53 | wps 8111 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.326
2022-01-31 14:29:58 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-31 14:29:58 | INFO | train | epoch 059 | loss 7.186 | ppl 145.64 | wps 6027.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.538 | train_wall 319 | gb_free 6.1 | wall 20482
KL Stats: Epoch 59 Divergences: Uniform: 2.4963397731052948 Unigram: 3.288185482177531
2022-01-31 14:29:58 | INFO | fairseq.trainer | begin training epoch 60
2022-01-31 14:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:31:58 | INFO | train_inner | epoch 060:     24 / 64 loss=7.18, ppl=145.01, wps=5898.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.541, train_wall=497, gb_free=6.1, wall=20603
2022-01-31 14:35:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:35:45 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.494 | ppl 720.97 | wps 8011.8 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.326
2022-01-31 14:35:45 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-31 14:35:45 | INFO | train | epoch 060 | loss 7.141 | ppl 141.18 | wps 6015.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.55 | train_wall 319 | gb_free 6.1 | wall 20830
KL Stats: Epoch 60 Divergences: Uniform: 2.5131464301878434 Unigram: 3.3220301948543978
2022-01-31 14:35:45 | INFO | fairseq.trainer | begin training epoch 61
2022-01-31 14:35:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:40:47 | INFO | train_inner | epoch 061:     60 / 64 loss=7.122, ppl=139.32, wps=6183.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.552, train_wall=500, gb_free=6.1, wall=21131
2022-01-31 14:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:41:33 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.549 | ppl 748.88 | wps 8081.2 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.326
2022-01-31 14:41:33 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-31 14:41:33 | INFO | train | epoch 061 | loss 7.099 | ppl 137.1 | wps 6013.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.553 | train_wall 319 | gb_free 6.1 | wall 21177
KL Stats: Epoch 61 Divergences: Uniform: 2.525891462538542 Unigram: 3.3346169889105512
2022-01-31 14:41:33 | INFO | fairseq.trainer | begin training epoch 62
2022-01-31 14:41:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:46:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:47:19 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.514 | ppl 731.26 | wps 8125.8 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.326
2022-01-31 14:47:19 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-31 14:47:19 | INFO | train | epoch 062 | loss 7.058 | ppl 133.27 | wps 6026.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.557 | train_wall 319 | gb_free 6.1 | wall 21524
KL Stats: Epoch 62 Divergences: Uniform: 2.528594754930607 Unigram: 3.373237554412178
2022-01-31 14:47:19 | INFO | fairseq.trainer | begin training epoch 63
2022-01-31 14:47:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:50:00 | INFO | train_inner | epoch 063:     32 / 64 loss=7.032, ppl=130.88, wps=5893.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.554, train_wall=498, gb_free=6.1, wall=21684
2022-01-31 14:52:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:53:06 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.547 | ppl 748.13 | wps 8132.2 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.326
2022-01-31 14:53:06 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-31 14:53:06 | INFO | train | epoch 063 | loss 7.014 | ppl 129.21 | wps 6020.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.551 | train_wall 319 | gb_free 6.1 | wall 21870
KL Stats: Epoch 63 Divergences: Uniform: 2.549045492901148 Unigram: 3.4021279169515246
2022-01-31 14:53:06 | INFO | fairseq.trainer | begin training epoch 64
2022-01-31 14:53:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:58:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:58:53 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.615 | ppl 784.25 | wps 8124.2 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.326
2022-01-31 14:58:53 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-31 14:58:53 | INFO | train | epoch 064 | loss 6.972 | ppl 125.53 | wps 6013.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.564 | train_wall 319 | gb_free 6.1 | wall 22218
KL Stats: Epoch 64 Divergences: Uniform: 2.5551295953489017 Unigram: 3.4205264833520586
2022-01-31 14:58:53 | INFO | fairseq.trainer | begin training epoch 65
2022-01-31 14:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:59:14 | INFO | train_inner | epoch 065:      4 / 64 loss=6.998, ppl=127.86, wps=5887.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.562, train_wall=498, gb_free=6.1, wall=22238
2022-01-31 15:04:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:04:39 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.627 | ppl 790.78 | wps 8181.2 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.326
2022-01-31 15:04:39 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-31 15:04:39 | INFO | train | epoch 065 | loss 6.928 | ppl 121.77 | wps 6044.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.562 | train_wall 318 | gb_free 6.1 | wall 22563
KL Stats: Epoch 65 Divergences: Uniform: 2.563942976226502 Unigram: 3.445737368680613
2022-01-31 15:04:39 | INFO | fairseq.trainer | begin training epoch 66
2022-01-31 15:04:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:07:58 | INFO | train_inner | epoch 066:     40 / 64 loss=6.904, ppl=119.75, wps=6229, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.567, train_wall=497, gb_free=6.1, wall=22763
2022-01-31 15:09:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:10:24 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.639 | ppl 797.29 | wps 8094.7 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.326
2022-01-31 15:10:24 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-31 15:10:24 | INFO | train | epoch 066 | loss 6.888 | ppl 118.46 | wps 6056.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.563 | train_wall 317 | gb_free 6.1 | wall 22908
KL Stats: Epoch 66 Divergences: Uniform: 2.5772898308287924 Unigram: 3.471961225872827
2022-01-31 15:10:24 | INFO | fairseq.trainer | begin training epoch 67
2022-01-31 15:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:15:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:16:10 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.638 | ppl 796.8 | wps 8107.5 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.326
2022-01-31 15:16:10 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-31 15:16:10 | INFO | train | epoch 067 | loss 6.847 | ppl 115.1 | wps 6031.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.569 | train_wall 318 | gb_free 6.1 | wall 23254
KL Stats: Epoch 67 Divergences: Uniform: 2.5950305911630087 Unigram: 3.507518799528248
2022-01-31 15:16:10 | INFO | fairseq.trainer | begin training epoch 68
2022-01-31 15:16:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:17:10 | INFO | train_inner | epoch 068:     12 / 64 loss=6.856, ppl=115.81, wps=5907.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.563, train_wall=496, gb_free=6.1, wall=23314
2022-01-31 15:21:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:21:56 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.681 | ppl 820.87 | wps 8118.6 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.326
2022-01-31 15:21:56 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-31 15:21:56 | INFO | train | epoch 068 | loss 6.81 | ppl 112.18 | wps 6033.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.582 | train_wall 318 | gb_free 6.1 | wall 23601
KL Stats: Epoch 68 Divergences: Uniform: 2.6060593442497813 Unigram: 3.5349998447665416
2022-01-31 15:21:56 | INFO | fairseq.trainer | begin training epoch 69
2022-01-31 15:21:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:25:57 | INFO | train_inner | epoch 069:     48 / 64 loss=6.792, ppl=110.8, wps=6201.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.581, train_wall=499, gb_free=6.1, wall=23841
2022-01-31 15:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:27:43 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.681 | ppl 820.85 | wps 8109.1 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.326
2022-01-31 15:27:43 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-31 15:27:43 | INFO | train | epoch 069 | loss 6.772 | ppl 109.27 | wps 6025.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.582 | train_wall 319 | gb_free 6.1 | wall 23947
KL Stats: Epoch 69 Divergences: Uniform: 2.618332367180402 Unigram: 3.5546142788288915
2022-01-31 15:27:43 | INFO | fairseq.trainer | begin training epoch 70
2022-01-31 15:27:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:33:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:33:30 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.785 | ppl 882.26 | wps 8077.7 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.326
2022-01-31 15:33:30 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-31 15:33:30 | INFO | train | epoch 070 | loss 6.736 | ppl 106.58 | wps 6015.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.575 | train_wall 319 | gb_free 6.1 | wall 24294
KL Stats: Epoch 70 Divergences: Uniform: 2.6226714181201594 Unigram: 3.571775430475295
2022-01-31 15:33:30 | INFO | fairseq.trainer | begin training epoch 71
2022-01-31 15:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:35:11 | INFO | train_inner | epoch 071:     20 / 64 loss=6.73, ppl=106.18, wps=5887.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.58, train_wall=498, gb_free=6.1, wall=24395
2022-01-31 15:38:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:39:17 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.776 | ppl 876.47 | wps 8142.7 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.326
2022-01-31 15:39:17 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-31 15:39:17 | INFO | train | epoch 071 | loss 6.701 | ppl 104.07 | wps 6021.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.588 | train_wall 319 | gb_free 6.1 | wall 24641
KL Stats: Epoch 71 Divergences: Uniform: 2.635696134088942 Unigram: 3.5959790520174897
2022-01-31 15:39:17 | INFO | fairseq.trainer | begin training epoch 72
2022-01-31 15:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:43:58 | INFO | train_inner | epoch 072:     56 / 64 loss=6.686, ppl=102.96, wps=6198, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.584, train_wall=499, gb_free=6.1, wall=24922
2022-01-31 15:44:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:45:04 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.668 | ppl 813.59 | wps 8052.2 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.326
2022-01-31 15:45:04 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-31 15:45:04 | INFO | train | epoch 072 | loss 6.666 | ppl 101.56 | wps 6015.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.583 | train_wall 319 | gb_free 6.1 | wall 24989
KL Stats: Epoch 72 Divergences: Uniform: 2.6509674567939228 Unigram: 3.627942886767364
2022-01-31 15:45:04 | INFO | fairseq.trainer | begin training epoch 73
2022-01-31 15:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:50:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:50:51 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.777 | ppl 877.34 | wps 8134.4 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.326
2022-01-31 15:50:51 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-31 15:50:51 | INFO | train | epoch 073 | loss 6.634 | ppl 99.29 | wps 6025.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.582 | train_wall 319 | gb_free 6.1 | wall 25335
KL Stats: Epoch 73 Divergences: Uniform: 2.6515154245954804 Unigram: 3.641509598538551
2022-01-31 15:50:51 | INFO | fairseq.trainer | begin training epoch 74
2022-01-31 15:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:53:11 | INFO | train_inner | epoch 074:     28 / 64 loss=6.622, ppl=98.52, wps=5893.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.584, train_wall=498, gb_free=6.1, wall=25476
2022-01-31 15:56:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:56:37 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.728 | ppl 847.88 | wps 8109.6 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.326
2022-01-31 15:56:37 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-31 15:56:37 | INFO | train | epoch 074 | loss 6.6 | ppl 97.02 | wps 6024.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.585 | train_wall 319 | gb_free 6.1 | wall 25682
KL Stats: Epoch 74 Divergences: Uniform: 2.6599145195931793 Unigram: 3.6727161269901174
2022-01-31 15:56:37 | INFO | fairseq.trainer | begin training epoch 75
2022-01-31 15:56:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:01:57 | INFO | train_inner | epoch 075:     64 / 64 loss=6.592, ppl=96.45, wps=6195.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.592, train_wall=498, gb_free=6.1, wall=26002
2022-01-31 16:01:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:02:24 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.859 | ppl 928.85 | wps 8136.5 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.326
2022-01-31 16:02:24 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-31 16:02:24 | INFO | train | epoch 075 | loss 6.572 | ppl 95.13 | wps 6024 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.597 | train_wall 319 | gb_free 6.1 | wall 26029
KL Stats: Epoch 75 Divergences: Uniform: 2.6677873147311764 Unigram: 3.6916189951416234
2022-01-31 16:02:24 | INFO | fairseq.trainer | begin training epoch 76
2022-01-31 16:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:07:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:08:11 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.804 | ppl 893.85 | wps 8092.7 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.326
2022-01-31 16:08:11 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-31 16:08:11 | INFO | train | epoch 076 | loss 6.541 | ppl 93.14 | wps 6020.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.607 | train_wall 319 | gb_free 6.1 | wall 26375
KL Stats: Epoch 76 Divergences: Uniform: 2.676770203705105 Unigram: 3.7220396256901878
2022-01-31 16:08:11 | INFO | fairseq.trainer | begin training epoch 77
2022-01-31 16:08:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:11:12 | INFO | train_inner | epoch 077:     36 / 64 loss=6.516, ppl=91.54, wps=5891.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.606, train_wall=499, gb_free=6.1, wall=26556
2022-01-31 16:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:13:58 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.758 | ppl 865.93 | wps 8095 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.326
2022-01-31 16:13:58 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-31 16:13:58 | INFO | train | epoch 077 | loss 6.511 | ppl 91.23 | wps 6017 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.616 | train_wall 319 | gb_free 6.1 | wall 26723
KL Stats: Epoch 77 Divergences: Uniform: 2.6854287922990836 Unigram: 3.751392547575252
2022-01-31 16:13:58 | INFO | fairseq.trainer | begin training epoch 78
2022-01-31 16:13:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:19:45 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.805 | ppl 894.51 | wps 7986.8 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.326
2022-01-31 16:19:45 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-31 16:19:45 | INFO | train | epoch 078 | loss 6.483 | ppl 89.43 | wps 6017.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.613 | train_wall 319 | gb_free 6.1 | wall 27070
KL Stats: Epoch 78 Divergences: Uniform: 2.691453206607939 Unigram: 3.766316553036266
2022-01-31 16:19:45 | INFO | fairseq.trainer | begin training epoch 79
2022-01-31 16:19:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:20:26 | INFO | train_inner | epoch 079:      8 / 64 loss=6.497, ppl=90.33, wps=5884.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.617, train_wall=498, gb_free=6.1, wall=27110
2022-01-31 16:25:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:25:33 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.889 | ppl 948.02 | wps 8104.5 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.326
2022-01-31 16:25:33 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-31 16:25:33 | INFO | train | epoch 079 | loss 6.451 | ppl 87.51 | wps 6009.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.601 | train_wall 320 | gb_free 6.1 | wall 27417
KL Stats: Epoch 79 Divergences: Uniform: 2.6939372343324948 Unigram: 3.78126672993646
2022-01-31 16:25:33 | INFO | fairseq.trainer | begin training epoch 80
2022-01-31 16:25:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:29:14 | INFO | train_inner | epoch 080:     44 / 64 loss=6.435, ppl=86.53, wps=6192.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.601, train_wall=499, gb_free=6.1, wall=27638
2022-01-31 16:30:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:31:20 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.808 | ppl 896.48 | wps 8084.2 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.326
2022-01-31 16:31:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-31 16:31:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint80.pt
2022-01-31 16:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint80.pt
2022-01-31 16:31:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.808) (writing took 3.7053578067570925 seconds)
2022-01-31 16:31:24 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-31 16:31:24 | INFO | train | epoch 080 | loss 6.427 | ppl 86.02 | wps 5950.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.609 | train_wall 319 | gb_free 6.1 | wall 27768
KL Stats: Epoch 80 Divergences: Uniform: 2.7024125311039207 Unigram: 3.807613960436276
2022-01-31 16:31:24 | INFO | fairseq.trainer | begin training epoch 81
2022-01-31 16:31:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:36:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:37:08 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.903 | ppl 957.55 | wps 8185.4 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.326
2022-01-31 16:37:08 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-31 16:37:08 | INFO | train | epoch 081 | loss 6.401 | ppl 84.53 | wps 6063.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.622 | train_wall 317 | gb_free 6.1 | wall 28113
KL Stats: Epoch 81 Divergences: Uniform: 2.7187858859645067 Unigram: 3.8318851558145184
2022-01-31 16:37:08 | INFO | fairseq.trainer | begin training epoch 82
2022-01-31 16:37:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:38:28 | INFO | train_inner | epoch 082:     16 / 64 loss=6.408, ppl=84.92, wps=5880.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.625, train_wall=495, gb_free=6.1, wall=28193
2022-01-31 16:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:42:53 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.839 | ppl 915.94 | wps 8144.9 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.326
2022-01-31 16:42:53 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-31 16:42:53 | INFO | train | epoch 082 | loss 6.374 | ppl 82.95 | wps 6055.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.617 | train_wall 317 | gb_free 6.1 | wall 28458
KL Stats: Epoch 82 Divergences: Uniform: 2.723287194768852 Unigram: 3.8658415518810205
2022-01-31 16:42:53 | INFO | fairseq.trainer | begin training epoch 83
2022-01-31 16:42:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:47:14 | INFO | train_inner | epoch 083:     52 / 64 loss=6.36, ppl=82.13, wps=6214, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.627, train_wall=498, gb_free=6.1, wall=28718
2022-01-31 16:48:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:48:40 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.775 | ppl 876.01 | wps 8090.6 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.326
2022-01-31 16:48:40 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-31 16:48:40 | INFO | train | epoch 083 | loss 6.35 | ppl 81.55 | wps 6024.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.639 | train_wall 319 | gb_free 6.1 | wall 28804
KL Stats: Epoch 83 Divergences: Uniform: 2.733066352271949 Unigram: 3.8812998243823773
2022-01-31 16:48:40 | INFO | fairseq.trainer | begin training epoch 84
2022-01-31 16:48:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:54:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:54:27 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.843 | ppl 918.37 | wps 8031.1 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.326
2022-01-31 16:54:27 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-31 16:54:27 | INFO | train | epoch 084 | loss 6.323 | ppl 80.07 | wps 6020.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.625 | train_wall 319 | gb_free 6.1 | wall 29151
KL Stats: Epoch 84 Divergences: Uniform: 2.7399716252387494 Unigram: 3.8974870511599766
2022-01-31 16:54:27 | INFO | fairseq.trainer | begin training epoch 85
2022-01-31 16:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:56:28 | INFO | train_inner | epoch 085:     24 / 64 loss=6.312, ppl=79.48, wps=5888.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.626, train_wall=498, gb_free=6.1, wall=29272
2022-01-31 16:59:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:00:14 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.882 | ppl 943.79 | wps 8125.2 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.326
2022-01-31 17:00:14 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-31 17:00:14 | INFO | train | epoch 085 | loss 6.3 | ppl 78.79 | wps 6020.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.635 | train_wall 319 | gb_free 6.1 | wall 29498
KL Stats: Epoch 85 Divergences: Uniform: 2.7499357247638323 Unigram: 3.920821769577209
2022-01-31 17:00:14 | INFO | fairseq.trainer | begin training epoch 86
2022-01-31 17:00:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:05:14 | INFO | train_inner | epoch 086:     60 / 64 loss=6.297, ppl=78.64, wps=6205.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.638, train_wall=498, gb_free=6.1, wall=29799
2022-01-31 17:05:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:06:00 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.933 | ppl 977.34 | wps 8129.9 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.326
2022-01-31 17:06:00 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-31 17:06:00 | INFO | train | epoch 086 | loss 6.276 | ppl 77.47 | wps 6034 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.639 | train_wall 318 | gb_free 6.1 | wall 29844
KL Stats: Epoch 86 Divergences: Uniform: 2.749816638440277 Unigram: 3.9447428747330355
2022-01-31 17:06:00 | INFO | fairseq.trainer | begin training epoch 87
2022-01-31 17:06:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:11:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:11:47 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.93 | ppl 975.62 | wps 8099.2 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.326
2022-01-31 17:11:47 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-31 17:11:47 | INFO | train | epoch 087 | loss 6.254 | ppl 76.3 | wps 6022.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.656 | train_wall 319 | gb_free 6.1 | wall 30191
KL Stats: Epoch 87 Divergences: Uniform: 2.7570176675909104 Unigram: 3.9567084475405947
2022-01-31 17:11:47 | INFO | fairseq.trainer | begin training epoch 88
2022-01-31 17:11:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:14:28 | INFO | train_inner | epoch 088:     32 / 64 loss=6.24, ppl=75.6, wps=5890.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.653, train_wall=498, gb_free=6.1, wall=30352
2022-01-31 17:17:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:17:34 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.901 | ppl 955.9 | wps 8118.2 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.326
2022-01-31 17:17:34 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-31 17:17:34 | INFO | train | epoch 088 | loss 6.231 | ppl 75.1 | wps 6015.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.651 | train_wall 319 | gb_free 6.1 | wall 30538
KL Stats: Epoch 88 Divergences: Uniform: 2.763481384587193 Unigram: 3.9818362478568616
2022-01-31 17:17:34 | INFO | fairseq.trainer | begin training epoch 89
2022-01-31 17:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:23:20 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.911 | ppl 962.89 | wps 8123.9 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.326
2022-01-31 17:23:20 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-31 17:23:20 | INFO | train | epoch 089 | loss 6.213 | ppl 74.2 | wps 6031.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.674 | train_wall 319 | gb_free 6.1 | wall 30885
KL Stats: Epoch 89 Divergences: Uniform: 2.772029917556553 Unigram: 3.9957191701788295
2022-01-31 17:23:20 | INFO | fairseq.trainer | begin training epoch 90
2022-01-31 17:23:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:23:40 | INFO | train_inner | epoch 090:      4 / 64 loss=6.224, ppl=74.73, wps=5898.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.667, train_wall=497, gb_free=6.1, wall=30905
2022-01-31 17:28:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:29:07 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.974 | ppl 1005.38 | wps 8035.5 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.326
2022-01-31 17:29:07 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-31 17:29:07 | INFO | train | epoch 090 | loss 6.188 | ppl 72.91 | wps 6021.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.655 | train_wall 319 | gb_free 6.1 | wall 31231
KL Stats: Epoch 90 Divergences: Uniform: 2.7743925227094532 Unigram: 4.011171219457905
2022-01-31 17:29:07 | INFO | fairseq.trainer | begin training epoch 91
2022-01-31 17:29:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:32:28 | INFO | train_inner | epoch 091:     40 / 64 loss=6.17, ppl=71.99, wps=6192.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.653, train_wall=499, gb_free=6.1, wall=31432
2022-01-31 17:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:34:54 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.945 | ppl 985.5 | wps 8130.4 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.326
2022-01-31 17:34:54 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-31 17:34:54 | INFO | train | epoch 091 | loss 6.166 | ppl 71.78 | wps 6021.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.657 | train_wall 319 | gb_free 6.1 | wall 31578
KL Stats: Epoch 91 Divergences: Uniform: 2.7827876296722778 Unigram: 4.044986030868144
2022-01-31 17:34:54 | INFO | fairseq.trainer | begin training epoch 92
2022-01-31 17:34:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:40:41 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.98 | ppl 1010.04 | wps 8111.5 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.326
2022-01-31 17:40:41 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-31 17:40:41 | INFO | train | epoch 092 | loss 6.147 | ppl 70.88 | wps 6008.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.681 | train_wall 320 | gb_free 6.1 | wall 31926
KL Stats: Epoch 92 Divergences: Uniform: 2.789062773022607 Unigram: 4.062267832792022
2022-01-31 17:40:41 | INFO | fairseq.trainer | begin training epoch 93
2022-01-31 17:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:41:42 | INFO | train_inner | epoch 093:     12 / 64 loss=6.156, ppl=71.32, wps=5886.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.674, train_wall=499, gb_free=6.1, wall=31986
2022-01-31 17:46:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:46:29 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.911 | ppl 962.51 | wps 8093.7 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.326
2022-01-31 17:46:29 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-31 17:46:29 | INFO | train | epoch 093 | loss 6.129 | ppl 70 | wps 6016.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.677 | train_wall 319 | gb_free 6.1 | wall 32273
KL Stats: Epoch 93 Divergences: Uniform: 2.7930974417456613 Unigram: 4.082826242518859
2022-01-31 17:46:29 | INFO | fairseq.trainer | begin training epoch 94
2022-01-31 17:46:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:50:30 | INFO | train_inner | epoch 094:     48 / 64 loss=6.115, ppl=69.29, wps=6187.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.68, train_wall=500, gb_free=6.1, wall=32514
2022-01-31 17:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:52:16 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 10.009 | ppl 1030.45 | wps 8123.6 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.326
2022-01-31 17:52:16 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-31 17:52:16 | INFO | train | epoch 094 | loss 6.108 | ppl 68.96 | wps 6016.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.679 | train_wall 319 | gb_free 6.1 | wall 32620
KL Stats: Epoch 94 Divergences: Uniform: 2.794718596335257 Unigram: 4.100380602911532
2022-01-31 17:52:16 | INFO | fairseq.trainer | begin training epoch 95
2022-01-31 17:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:58:02 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 10.034 | ppl 1048.51 | wps 8083.5 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.326
2022-01-31 17:58:02 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-31 17:58:02 | INFO | train | epoch 095 | loss 6.088 | ppl 68.01 | wps 6035.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.671 | train_wall 318 | gb_free 6.1 | wall 32966
KL Stats: Epoch 95 Divergences: Uniform: 2.798401115843311 Unigram: 4.116616116594432
2022-01-31 17:58:02 | INFO | fairseq.trainer | begin training epoch 96
2022-01-31 17:58:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:59:42 | INFO | train_inner | epoch 096:     20 / 64 loss=6.087, ppl=67.98, wps=5902, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.679, train_wall=497, gb_free=6.1, wall=33067
2022-01-31 18:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:03:48 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.938 | ppl 981.04 | wps 8118.2 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.326
2022-01-31 18:03:48 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-31 18:03:48 | INFO | train | epoch 096 | loss 6.071 | ppl 67.21 | wps 6032.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.698 | train_wall 318 | gb_free 6.1 | wall 33313
KL Stats: Epoch 96 Divergences: Uniform: 2.8145845751205765 Unigram: 4.132888318801318
2022-01-31 18:03:48 | INFO | fairseq.trainer | begin training epoch 97
2022-01-31 18:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:08:28 | INFO | train_inner | epoch 097:     56 / 64 loss=6.065, ppl=66.94, wps=6217.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.693, train_wall=497, gb_free=6.1, wall=33592
2022-01-31 18:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:09:33 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 10.029 | ppl 1044.88 | wps 8180.3 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.326
2022-01-31 18:09:33 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-31 18:09:33 | INFO | train | epoch 097 | loss 6.054 | ppl 66.42 | wps 6052.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.694 | train_wall 317 | gb_free 6.1 | wall 33658
KL Stats: Epoch 97 Divergences: Uniform: 2.8203055707285576 Unigram: 4.15749548320711
2022-01-31 18:09:33 | INFO | fairseq.trainer | begin training epoch 98
2022-01-31 18:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:15:19 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.983 | ppl 1012.16 | wps 8118.8 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.326
2022-01-31 18:15:19 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-31 18:15:19 | INFO | train | epoch 098 | loss 6.034 | ppl 65.54 | wps 6037.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.722 | train_wall 318 | gb_free 6.1 | wall 34004
KL Stats: Epoch 98 Divergences: Uniform: 2.8204585626503125 Unigram: 4.162579997613385
2022-01-31 18:15:19 | INFO | fairseq.trainer | begin training epoch 99
2022-01-31 18:15:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:17:40 | INFO | train_inner | epoch 099:     28 / 64 loss=6.025, ppl=65.13, wps=5906.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.724, train_wall=497, gb_free=6.1, wall=34144
2022-01-31 18:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:21:06 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 10.008 | ppl 1029.95 | wps 8184.9 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.326
2022-01-31 18:21:06 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-31 18:21:06 | INFO | train | epoch 099 | loss 6.016 | ppl 64.72 | wps 6026.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.722 | train_wall 319 | gb_free 6.1 | wall 34350
KL Stats: Epoch 99 Divergences: Uniform: 2.826178525640231 Unigram: 4.1873297947436185
2022-01-31 18:21:06 | INFO | fairseq.trainer | begin training epoch 100
2022-01-31 18:21:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:26:25 | INFO | train_inner | epoch 100:     64 / 64 loss=6.019, ppl=64.83, wps=6203.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.723, train_wall=497, gb_free=6.1, wall=34670
2022-01-31 18:26:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:26:52 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 10.007 | ppl 1028.75 | wps 8152.4 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.326
2022-01-31 18:26:52 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-31 18:26:52 | INFO | train | epoch 100 | loss 6.001 | ppl 64.04 | wps 6029 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.727 | train_wall 319 | gb_free 6.1 | wall 34697
KL Stats: Epoch 100 Divergences: Uniform: 2.824272446985833 Unigram: 4.195015192349328
2022-01-31 18:26:52 | INFO | fairseq.trainer | begin training epoch 101
2022-01-31 18:26:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:32:38 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 10.07 | ppl 1075.1 | wps 8144.3 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.326
2022-01-31 18:32:38 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-31 18:32:38 | INFO | train | epoch 101 | loss 5.983 | ppl 63.23 | wps 6034.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.731 | train_wall 318 | gb_free 6.1 | wall 35043
KL Stats: Epoch 101 Divergences: Uniform: 2.8393487423407042 Unigram: 4.218693767713537
2022-01-31 18:32:38 | INFO | fairseq.trainer | begin training epoch 102
2022-01-31 18:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:35:39 | INFO | train_inner | epoch 102:     36 / 64 loss=5.968, ppl=62.61, wps=5907.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.731, train_wall=498, gb_free=6.1, wall=35223
2022-01-31 18:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:38:25 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 10.079 | ppl 1081.82 | wps 8052.9 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.326
2022-01-31 18:38:25 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-31 18:38:25 | INFO | train | epoch 102 | loss 5.968 | ppl 62.57 | wps 6021.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.729 | train_wall 319 | gb_free 6.1 | wall 35390
KL Stats: Epoch 102 Divergences: Uniform: 2.839530661642631 Unigram: 4.2357347550203786
2022-01-31 18:38:25 | INFO | fairseq.trainer | begin training epoch 103
2022-01-31 18:38:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:43:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:44:11 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 10.091 | ppl 1090.82 | wps 8092.7 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.326
2022-01-31 18:44:11 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-31 18:44:11 | INFO | train | epoch 103 | loss 5.949 | ppl 61.78 | wps 6031.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.721 | train_wall 318 | gb_free 6.1 | wall 35736
KL Stats: Epoch 103 Divergences: Uniform: 2.8518920019897314 Unigram: 4.2535451524161365
2022-01-31 18:44:11 | INFO | fairseq.trainer | begin training epoch 104
2022-01-31 18:44:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:44:52 | INFO | train_inner | epoch 104:      8 / 64 loss=5.957, ppl=62.11, wps=5892.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.722, train_wall=498, gb_free=6.1, wall=35776
2022-01-31 18:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:49:59 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 10.078 | ppl 1080.67 | wps 8134.2 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.326
2022-01-31 18:49:59 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-31 18:49:59 | INFO | train | epoch 104 | loss 5.936 | ppl 61.23 | wps 6012.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.735 | train_wall 320 | gb_free 6.1 | wall 36083
KL Stats: Epoch 104 Divergences: Uniform: 2.846316067525878 Unigram: 4.271676171900059
2022-01-31 18:49:59 | INFO | fairseq.trainer | begin training epoch 105
2022-01-31 18:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:53:39 | INFO | train_inner | epoch 105:     44 / 64 loss=5.924, ppl=60.72, wps=6196, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.741, train_wall=499, gb_free=6.1, wall=36304
2022-01-31 18:55:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:55:45 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 10.029 | ppl 1044.78 | wps 8114.1 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.326
2022-01-31 18:55:45 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-31 18:55:45 | INFO | train | epoch 105 | loss 5.921 | ppl 60.57 | wps 6035.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.745 | train_wall 318 | gb_free 6.1 | wall 36429
KL Stats: Epoch 105 Divergences: Uniform: 2.853214934408744 Unigram: 4.285304926894688
2022-01-31 18:55:45 | INFO | fairseq.trainer | begin training epoch 106
2022-01-31 18:55:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:01:31 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 10.108 | ppl 1103.91 | wps 8126.8 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.326
2022-01-31 19:01:31 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-31 19:01:31 | INFO | train | epoch 106 | loss 5.903 | ppl 59.84 | wps 6028.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.729 | train_wall 319 | gb_free 6.1 | wall 36776
KL Stats: Epoch 106 Divergences: Uniform: 2.8544577686616277 Unigram: 4.292459220183567
2022-01-31 19:01:31 | INFO | fairseq.trainer | begin training epoch 107
2022-01-31 19:01:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:02:51 | INFO | train_inner | epoch 107:     16 / 64 loss=5.907, ppl=60, wps=5903.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.737, train_wall=497, gb_free=6.1, wall=36856
2022-01-31 19:06:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:07:17 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 10.11 | ppl 1105.39 | wps 8130.3 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.326
2022-01-31 19:07:17 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-31 19:07:17 | INFO | train | epoch 107 | loss 5.887 | ppl 59.19 | wps 6037.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.745 | train_wall 318 | gb_free 6.1 | wall 37122
KL Stats: Epoch 107 Divergences: Uniform: 2.8634388464797724 Unigram: 4.313897806964236
2022-01-31 19:07:17 | INFO | fairseq.trainer | begin training epoch 108
2022-01-31 19:07:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:11:37 | INFO | train_inner | epoch 108:     52 / 64 loss=5.883, ppl=59, wps=6213.3, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.756, train_wall=498, gb_free=6.1, wall=37382
2022-01-31 19:12:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:13:03 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 10.112 | ppl 1106.8 | wps 8108.3 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.326
2022-01-31 19:13:03 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-31 19:13:03 | INFO | train | epoch 108 | loss 5.876 | ppl 58.74 | wps 6034.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.777 | train_wall 318 | gb_free 6.1 | wall 37468
KL Stats: Epoch 108 Divergences: Uniform: 2.867727607078569 Unigram: 4.324856370171599
2022-01-31 19:13:03 | INFO | fairseq.trainer | begin training epoch 109
2022-01-31 19:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:18:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:18:51 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.121 | ppl 1113.86 | wps 8128.1 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.326
2022-01-31 19:18:51 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-31 19:18:51 | INFO | train | epoch 109 | loss 5.86 | ppl 58.09 | wps 6015.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.763 | train_wall 319 | gb_free 6.1 | wall 37815
KL Stats: Epoch 109 Divergences: Uniform: 2.8681110768544635 Unigram: 4.346300518147637
2022-01-31 19:18:51 | INFO | fairseq.trainer | begin training epoch 110
2022-01-31 19:18:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:20:51 | INFO | train_inner | epoch 110:     24 / 64 loss=5.854, ppl=57.86, wps=5889, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.769, train_wall=498, gb_free=6.1, wall=37935
2022-01-31 19:24:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:24:37 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.166 | ppl 1148.73 | wps 8118 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.326
2022-01-31 19:24:37 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-31 19:24:37 | INFO | train | epoch 110 | loss 5.847 | ppl 57.54 | wps 6022.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.769 | train_wall 319 | gb_free 6.1 | wall 38162
KL Stats: Epoch 110 Divergences: Uniform: 2.8757373250647222 Unigram: 4.360464246337592
2022-01-31 19:24:37 | INFO | fairseq.trainer | begin training epoch 111
2022-01-31 19:24:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:29:38 | INFO | train_inner | epoch 111:     60 / 64 loss=5.846, ppl=57.51, wps=6199.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.778, train_wall=499, gb_free=6.1, wall=38463
2022-01-31 19:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:30:23 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.132 | ppl 1121.93 | wps 8198 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.326
2022-01-31 19:30:23 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-31 19:30:23 | INFO | train | epoch 111 | loss 5.833 | ppl 57 | wps 6036.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.783 | train_wall 318 | gb_free 6.1 | wall 38508
KL Stats: Epoch 111 Divergences: Uniform: 2.8757006983412037 Unigram: 4.379962283666537
2022-01-31 19:30:23 | INFO | fairseq.trainer | begin training epoch 112
2022-01-31 19:30:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:35:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:36:06 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.18 | ppl 1159.82 | wps 8218.7 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.326
2022-01-31 19:36:06 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-31 19:36:06 | INFO | train | epoch 112 | loss 5.818 | ppl 56.42 | wps 6087.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.779 | train_wall 316 | gb_free 6.1 | wall 38851
KL Stats: Epoch 112 Divergences: Uniform: 2.879814677591912 Unigram: 4.395338171490341
2022-01-31 19:36:06 | INFO | fairseq.trainer | begin training epoch 113
2022-01-31 19:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:38:45 | INFO | train_inner | epoch 113:     32 / 64 loss=5.806, ppl=55.96, wps=5957.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.778, train_wall=493, gb_free=6.1, wall=39010
2022-01-31 19:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:41:51 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.134 | ppl 1123.32 | wps 8125 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.326
2022-01-31 19:41:51 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-31 19:41:51 | INFO | train | epoch 113 | loss 5.803 | ppl 55.84 | wps 6055.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.773 | train_wall 317 | gb_free 6.1 | wall 39196
KL Stats: Epoch 113 Divergences: Uniform: 2.887484484654345 Unigram: 4.408567771877758
2022-01-31 19:41:51 | INFO | fairseq.trainer | begin training epoch 114
2022-01-31 19:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:47:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:47:39 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.158 | ppl 1142.84 | wps 8112.9 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.326
2022-01-31 19:47:39 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-31 19:47:39 | INFO | train | epoch 114 | loss 5.791 | ppl 55.37 | wps 6012.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.791 | train_wall 319 | gb_free 6.1 | wall 39543
KL Stats: Epoch 114 Divergences: Uniform: 2.888618008486176 Unigram: 4.419617988774367
2022-01-31 19:47:39 | INFO | fairseq.trainer | begin training epoch 115
2022-01-31 19:47:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:47:59 | INFO | train_inner | epoch 115:      4 / 64 loss=5.803, ppl=55.84, wps=5887.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.789, train_wall=498, gb_free=6.1, wall=39563
2022-01-31 19:52:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:53:25 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.163 | ppl 1146.61 | wps 8121.2 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.326
2022-01-31 19:53:25 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-31 19:53:25 | INFO | train | epoch 115 | loss 5.779 | ppl 54.9 | wps 6024.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.8 | train_wall 319 | gb_free 6.1 | wall 39890
KL Stats: Epoch 115 Divergences: Uniform: 2.893427841725796 Unigram: 4.43073827533578
2022-01-31 19:53:25 | INFO | fairseq.trainer | begin training epoch 116
2022-01-31 19:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:56:46 | INFO | train_inner | epoch 116:     40 / 64 loss=5.764, ppl=54.35, wps=6198, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.791, train_wall=499, gb_free=6.1, wall=40091
2022-01-31 19:58:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:59:12 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.127 | ppl 1118.07 | wps 8088.8 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.326
2022-01-31 19:59:12 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-31 19:59:12 | INFO | train | epoch 116 | loss 5.765 | ppl 54.38 | wps 6021.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.788 | train_wall 319 | gb_free 6.1 | wall 40237
KL Stats: Epoch 116 Divergences: Uniform: 2.8974294330192256 Unigram: 4.437428403736695
2022-01-31 19:59:12 | INFO | fairseq.trainer | begin training epoch 117
2022-01-31 19:59:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:04:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:04:59 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.225 | ppl 1196.82 | wps 8145 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.326
2022-01-31 20:04:59 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-31 20:04:59 | INFO | train | epoch 117 | loss 5.754 | ppl 53.98 | wps 6024.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.801 | train_wall 319 | gb_free 6.1 | wall 40583
KL Stats: Epoch 117 Divergences: Uniform: 2.896982778298606 Unigram: 4.461594135032143
2022-01-31 20:04:59 | INFO | fairseq.trainer | begin training epoch 118
2022-01-31 20:04:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:05:59 | INFO | train_inner | epoch 118:     12 / 64 loss=5.76, ppl=54.18, wps=5895.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.808, train_wall=498, gb_free=6.1, wall=40644
2022-01-31 20:10:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:10:46 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.171 | ppl 1153.16 | wps 8104.7 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.326
2022-01-31 20:10:46 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-31 20:10:46 | INFO | train | epoch 118 | loss 5.742 | ppl 53.5 | wps 6024.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.812 | train_wall 319 | gb_free 6.1 | wall 40930
KL Stats: Epoch 118 Divergences: Uniform: 2.90852886467471 Unigram: 4.4740443212743655
2022-01-31 20:10:46 | INFO | fairseq.trainer | begin training epoch 119
2022-01-31 20:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:14:47 | INFO | train_inner | epoch 119:     48 / 64 loss=5.73, ppl=53.08, wps=6193.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.795, train_wall=499, gb_free=6.1, wall=41171
2022-01-31 20:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:16:33 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.157 | ppl 1141.33 | wps 8117.6 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.326
2022-01-31 20:16:33 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-31 20:16:33 | INFO | train | epoch 119 | loss 5.727 | ppl 52.97 | wps 6014.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.795 | train_wall 319 | gb_free 6.1 | wall 41277
KL Stats: Epoch 119 Divergences: Uniform: 2.9090011743138326 Unigram: 4.493895493027797
2022-01-31 20:16:33 | INFO | fairseq.trainer | begin training epoch 120
2022-01-31 20:16:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:21:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:22:20 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.224 | ppl 1196.03 | wps 8119.6 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.326
2022-01-31 20:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-31 20:22:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint120.pt
2022-01-31 20:22:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint120.pt
2022-01-31 20:22:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.224) (writing took 3.455343583598733 seconds)
2022-01-31 20:22:23 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-31 20:22:23 | INFO | train | epoch 120 | loss 5.718 | ppl 52.65 | wps 5959.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.841 | train_wall 319 | gb_free 6.1 | wall 41628
KL Stats: Epoch 120 Divergences: Uniform: 2.913523930948785 Unigram: 4.500055369619682
2022-01-31 20:22:23 | INFO | fairseq.trainer | begin training epoch 121
2022-01-31 20:22:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:24:04 | INFO | train_inner | epoch 121:     20 / 64 loss=5.72, ppl=52.72, wps=5848.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.843, train_wall=499, gb_free=6.1, wall=41729
2022-01-31 20:27:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:28:10 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.202 | ppl 1178.1 | wps 8116.8 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.326
2022-01-31 20:28:10 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-31 20:28:10 | INFO | train | epoch 121 | loss 5.708 | ppl 52.27 | wps 6020.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.832 | train_wall 319 | gb_free 6.1 | wall 41975
KL Stats: Epoch 121 Divergences: Uniform: 2.9143809572728645 Unigram: 4.514382908834228
2022-01-31 20:28:10 | INFO | fairseq.trainer | begin training epoch 122
2022-01-31 20:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:32:52 | INFO | train_inner | epoch 122:     56 / 64 loss=5.704, ppl=52.12, wps=6197.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.825, train_wall=499, gb_free=6.1, wall=42256
2022-01-31 20:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:33:58 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.184 | ppl 1163.16 | wps 8117.9 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.326
2022-01-31 20:33:58 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-31 20:33:58 | INFO | train | epoch 122 | loss 5.696 | ppl 51.83 | wps 6015.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.833 | train_wall 319 | gb_free 6.1 | wall 42322
KL Stats: Epoch 122 Divergences: Uniform: 2.91664986985025 Unigram: 4.526332197218961
2022-01-31 20:33:58 | INFO | fairseq.trainer | begin training epoch 123
2022-01-31 20:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:39:44 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.226 | ppl 1197.87 | wps 8097.6 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.326
2022-01-31 20:39:44 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-31 20:39:44 | INFO | train | epoch 123 | loss 5.682 | ppl 51.35 | wps 6035.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.835 | train_wall 318 | gb_free 6.1 | wall 42668
KL Stats: Epoch 123 Divergences: Uniform: 2.9160364511221504 Unigram: 4.544041454553922
2022-01-31 20:39:44 | INFO | fairseq.trainer | begin training epoch 124
2022-01-31 20:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:42:04 | INFO | train_inner | epoch 124:     28 / 64 loss=5.675, ppl=51.1, wps=5901.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.827, train_wall=497, gb_free=6.1, wall=42809
2022-01-31 20:45:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:45:30 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.217 | ppl 1190.37 | wps 8133.8 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.326
2022-01-31 20:45:30 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-31 20:45:30 | INFO | train | epoch 124 | loss 5.67 | ppl 50.93 | wps 6026.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.824 | train_wall 319 | gb_free 6.1 | wall 43015
KL Stats: Epoch 124 Divergences: Uniform: 2.915198025362681 Unigram: 4.5475545003580296
2022-01-31 20:45:30 | INFO | fairseq.trainer | begin training epoch 125
2022-01-31 20:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:50:49 | INFO | train_inner | epoch 125:     64 / 64 loss=5.675, ppl=51.09, wps=6207.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.834, train_wall=497, gb_free=6.1, wall=43334
2022-01-31 20:50:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:51:16 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.261 | ppl 1227.09 | wps 8117 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.326
2022-01-31 20:51:16 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-31 20:51:16 | INFO | train | epoch 125 | loss 5.661 | ppl 50.59 | wps 6037.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.831 | train_wall 318 | gb_free 6.1 | wall 43361
KL Stats: Epoch 125 Divergences: Uniform: 2.9228282789627396 Unigram: 4.566401216859982
2022-01-31 20:51:16 | INFO | fairseq.trainer | begin training epoch 126
2022-01-31 20:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:57:00 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.196 | ppl 1173.32 | wps 8193.5 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.326
2022-01-31 20:57:00 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-31 20:57:00 | INFO | train | epoch 126 | loss 5.65 | ppl 50.21 | wps 6073.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.825 | train_wall 316 | gb_free 6.1 | wall 43705
KL Stats: Epoch 126 Divergences: Uniform: 2.931145260506506 Unigram: 4.583903470570598
2022-01-31 20:57:00 | INFO | fairseq.trainer | begin training epoch 127
2022-01-31 20:57:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:00:00 | INFO | train_inner | epoch 127:     36 / 64 loss=5.638, ppl=49.81, wps=5938.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.851, train_wall=495, gb_free=6.1, wall=43884
2022-01-31 21:02:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:02:45 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.195 | ppl 1172.5 | wps 8113 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.326
2022-01-31 21:02:45 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-31 21:02:45 | INFO | train | epoch 127 | loss 5.641 | ppl 49.91 | wps 6059.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.877 | train_wall 317 | gb_free 6.1 | wall 44049
KL Stats: Epoch 127 Divergences: Uniform: 2.9329548366748117 Unigram: 4.585434422617852
2022-01-31 21:02:45 | INFO | fairseq.trainer | begin training epoch 128
2022-01-31 21:02:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:08:32 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.228 | ppl 1198.91 | wps 8121.9 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.326
2022-01-31 21:08:32 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-31 21:08:32 | INFO | train | epoch 128 | loss 5.629 | ppl 49.48 | wps 6021.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.868 | train_wall 319 | gb_free 6.1 | wall 44396
KL Stats: Epoch 128 Divergences: Uniform: 2.923145826054424 Unigram: 4.595537100375836
2022-01-31 21:08:32 | INFO | fairseq.trainer | begin training epoch 129
2022-01-31 21:08:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:09:12 | INFO | train_inner | epoch 129:      8 / 64 loss=5.636, ppl=49.74, wps=5902.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.866, train_wall=497, gb_free=6.1, wall=44436
2022-01-31 21:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:14:18 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.189 | ppl 1167.42 | wps 8099.2 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.326
2022-01-31 21:14:18 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-31 21:14:18 | INFO | train | epoch 129 | loss 5.622 | ppl 49.25 | wps 6023.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.888 | train_wall 319 | gb_free 6.1 | wall 44743
KL Stats: Epoch 129 Divergences: Uniform: 2.929744821625501 Unigram: 4.607004362268021
2022-01-31 21:14:18 | INFO | fairseq.trainer | begin training epoch 130
2022-01-31 21:14:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:17:59 | INFO | train_inner | epoch 130:     44 / 64 loss=5.609, ppl=48.82, wps=6196.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.875, train_wall=499, gb_free=6.1, wall=44964
2022-01-31 21:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:20:05 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.288 | ppl 1250.45 | wps 8135 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.326
2022-01-31 21:20:05 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-31 21:20:05 | INFO | train | epoch 130 | loss 5.608 | ppl 48.79 | wps 6023.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.865 | train_wall 319 | gb_free 6.1 | wall 45090
KL Stats: Epoch 130 Divergences: Uniform: 2.9330096932659666 Unigram: 4.628320513647819
2022-01-31 21:20:05 | INFO | fairseq.trainer | begin training epoch 131
2022-01-31 21:20:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:25:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:25:53 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.251 | ppl 1218.75 | wps 8086 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.326
2022-01-31 21:25:53 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-31 21:25:53 | INFO | train | epoch 131 | loss 5.601 | ppl 48.52 | wps 6010.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.894 | train_wall 320 | gb_free 6.1 | wall 45437
KL Stats: Epoch 131 Divergences: Uniform: 2.934985056698084 Unigram: 4.629325769765611
2022-01-31 21:25:53 | INFO | fairseq.trainer | begin training epoch 132
2022-01-31 21:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:27:13 | INFO | train_inner | epoch 132:     16 / 64 loss=5.603, ppl=48.6, wps=5889, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.882, train_wall=498, gb_free=6.1, wall=45517
2022-01-31 21:31:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:31:39 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.265 | ppl 1230.66 | wps 8076 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.326
2022-01-31 21:31:39 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-31 21:31:39 | INFO | train | epoch 132 | loss 5.589 | ppl 48.14 | wps 6023.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.885 | train_wall 319 | gb_free 6.1 | wall 45784
KL Stats: Epoch 132 Divergences: Uniform: 2.9356706579473353 Unigram: 4.653152776304161
2022-01-31 21:31:39 | INFO | fairseq.trainer | begin training epoch 133
2022-01-31 21:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:36:00 | INFO | train_inner | epoch 133:     52 / 64 loss=5.584, ppl=47.97, wps=6196.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.904, train_wall=499, gb_free=6.1, wall=46045
2022-01-31 21:36:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:37:26 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.282 | ppl 1245.27 | wps 8121.6 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.326
2022-01-31 21:37:26 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-31 21:37:26 | INFO | train | epoch 133 | loss 5.58 | ppl 47.84 | wps 6026 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.912 | train_wall 319 | gb_free 6.1 | wall 46130
KL Stats: Epoch 133 Divergences: Uniform: 2.947139322413797 Unigram: 4.658479379644619
2022-01-31 21:37:26 | INFO | fairseq.trainer | begin training epoch 134
2022-01-31 21:37:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:42:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:43:12 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.317 | ppl 1275.84 | wps 8106.6 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.326
2022-01-31 21:43:12 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-31 21:43:12 | INFO | train | epoch 134 | loss 5.571 | ppl 47.55 | wps 6027 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.926 | train_wall 319 | gb_free 6.1 | wall 46477
KL Stats: Epoch 134 Divergences: Uniform: 2.9411135552673406 Unigram: 4.677324379702118
2022-01-31 21:43:12 | INFO | fairseq.trainer | begin training epoch 135
2022-01-31 21:43:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:45:13 | INFO | train_inner | epoch 135:     24 / 64 loss=5.571, ppl=47.53, wps=5899.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.924, train_wall=497, gb_free=6.1, wall=46597
2022-01-31 21:48:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:48:59 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.251 | ppl 1218.18 | wps 8099.6 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.326
2022-01-31 21:48:59 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-31 21:48:59 | INFO | train | epoch 135 | loss 5.56 | ppl 47.19 | wps 6034.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.884 | train_wall 318 | gb_free 6.1 | wall 46823
KL Stats: Epoch 135 Divergences: Uniform: 2.950843291657266 Unigram: 4.686307114280704
2022-01-31 21:48:59 | INFO | fairseq.trainer | begin training epoch 136
2022-01-31 21:48:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:54:00 | INFO | train_inner | epoch 136:     60 / 64 loss=5.562, ppl=47.24, wps=6204.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.901, train_wall=498, gb_free=6.1, wall=47124
2022-01-31 21:54:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:54:45 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.327 | ppl 1284.9 | wps 8131.2 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.326
2022-01-31 21:54:45 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-31 21:54:45 | INFO | train | epoch 136 | loss 5.554 | ppl 46.97 | wps 6022.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.924 | train_wall 319 | gb_free 6.1 | wall 47170
KL Stats: Epoch 136 Divergences: Uniform: 2.944617387616682 Unigram: 4.688226809884727
2022-01-31 21:54:45 | INFO | fairseq.trainer | begin training epoch 137
2022-01-31 21:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:00:33 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.411 | ppl 1361.73 | wps 8061.7 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.326
2022-01-31 22:00:33 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-31 22:00:33 | INFO | train | epoch 137 | loss 5.543 | ppl 46.62 | wps 6010.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.913 | train_wall 319 | gb_free 6.1 | wall 47517
KL Stats: Epoch 137 Divergences: Uniform: 2.946300688395223 Unigram: 4.705965392175802
2022-01-31 22:00:33 | INFO | fairseq.trainer | begin training epoch 138
2022-01-31 22:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:03:14 | INFO | train_inner | epoch 138:     32 / 64 loss=5.534, ppl=46.34, wps=5881.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.913, train_wall=499, gb_free=6.1, wall=47678
2022-01-31 22:05:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:06:20 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.385 | ppl 1337.12 | wps 8083.6 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.326
2022-01-31 22:06:20 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-31 22:06:20 | INFO | train | epoch 138 | loss 5.534 | ppl 46.32 | wps 6013 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.932 | train_wall 319 | gb_free 6.1 | wall 47865
KL Stats: Epoch 138 Divergences: Uniform: 2.9470303372917734 Unigram: 4.708562935610321
2022-01-31 22:06:20 | INFO | fairseq.trainer | begin training epoch 139
2022-01-31 22:06:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:11:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:12:07 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.315 | ppl 1274.14 | wps 8104 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.326
2022-01-31 22:12:07 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-31 22:12:07 | INFO | train | epoch 139 | loss 5.525 | ppl 46.04 | wps 6017.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.94 | train_wall 319 | gb_free 6.1 | wall 48212
KL Stats: Epoch 139 Divergences: Uniform: 2.951840734883938 Unigram: 4.724573653060703
2022-01-31 22:12:07 | INFO | fairseq.trainer | begin training epoch 140
2022-01-31 22:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:12:27 | INFO | train_inner | epoch 140:      4 / 64 loss=5.533, ppl=46.29, wps=5887.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.946, train_wall=498, gb_free=6.1, wall=48232
2022-01-31 22:17:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:17:52 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.317 | ppl 1275.93 | wps 8221.8 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.326
2022-01-31 22:17:52 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-31 22:17:52 | INFO | train | epoch 140 | loss 5.518 | ppl 45.83 | wps 6054.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.956 | train_wall 317 | gb_free 6.1 | wall 48557
KL Stats: Epoch 140 Divergences: Uniform: 2.951970174690379 Unigram: 4.729392544407343
2022-01-31 22:17:52 | INFO | fairseq.trainer | begin training epoch 141
2022-01-31 22:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:21:11 | INFO | train_inner | epoch 141:     40 / 64 loss=5.509, ppl=45.54, wps=6242.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.949, train_wall=496, gb_free=6.1, wall=48755
2022-01-31 22:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:23:36 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.319 | ppl 1277.59 | wps 8218.6 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.326
2022-01-31 22:23:36 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-31 22:23:36 | INFO | train | epoch 141 | loss 5.508 | ppl 45.5 | wps 6083.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.936 | train_wall 316 | gb_free 6.1 | wall 48900
KL Stats: Epoch 141 Divergences: Uniform: 2.9578667965350127 Unigram: 4.747178242992836
2022-01-31 22:23:36 | INFO | fairseq.trainer | begin training epoch 142
2022-01-31 22:23:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:29:21 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.308 | ppl 1267.72 | wps 8115.9 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.326
2022-01-31 22:29:21 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-31 22:29:21 | INFO | train | epoch 142 | loss 5.499 | ppl 45.22 | wps 6050.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.949 | train_wall 317 | gb_free 6.1 | wall 49245
KL Stats: Epoch 142 Divergences: Uniform: 2.9559981076917383 Unigram: 4.753810440652697
2022-01-31 22:29:21 | INFO | fairseq.trainer | begin training epoch 143
2022-01-31 22:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:30:21 | INFO | train_inner | epoch 143:     12 / 64 loss=5.501, ppl=45.28, wps=5925.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.945, train_wall=495, gb_free=6.1, wall=49306
2022-01-31 22:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:35:07 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.365 | ppl 1318.93 | wps 8144.6 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.326
2022-01-31 22:35:07 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-31 22:35:07 | INFO | train | epoch 143 | loss 5.494 | ppl 45.06 | wps 6032.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.967 | train_wall 318 | gb_free 6.1 | wall 49592
KL Stats: Epoch 143 Divergences: Uniform: 2.9670587138393114 Unigram: 4.763425698769235
2022-01-31 22:35:07 | INFO | fairseq.trainer | begin training epoch 144
2022-01-31 22:35:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:39:08 | INFO | train_inner | epoch 144:     48 / 64 loss=5.489, ppl=44.92, wps=6207.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.967, train_wall=498, gb_free=6.1, wall=49832
2022-01-31 22:40:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:40:53 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.39 | ppl 1342.29 | wps 8121.7 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.326
2022-01-31 22:40:53 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-31 22:40:53 | INFO | train | epoch 144 | loss 5.485 | ppl 44.8 | wps 6029.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.965 | train_wall 319 | gb_free 6.1 | wall 49938
KL Stats: Epoch 144 Divergences: Uniform: 2.9577879231609985 Unigram: 4.7651672522015325
2022-01-31 22:40:53 | INFO | fairseq.trainer | begin training epoch 145
2022-01-31 22:40:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:46:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:46:40 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.422 | ppl 1371.71 | wps 8099 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.326
2022-01-31 22:46:40 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-31 22:46:40 | INFO | train | epoch 145 | loss 5.476 | ppl 44.51 | wps 6022 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.951 | train_wall 319 | gb_free 6.1 | wall 50285
KL Stats: Epoch 145 Divergences: Uniform: 2.967391096111726 Unigram: 4.781376787889179
2022-01-31 22:46:40 | INFO | fairseq.trainer | begin training epoch 146
2022-01-31 22:46:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:48:21 | INFO | train_inner | epoch 146:     20 / 64 loss=5.473, ppl=44.43, wps=5895.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.961, train_wall=498, gb_free=6.1, wall=50385
2022-01-31 22:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:52:27 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.347 | ppl 1302.37 | wps 8116.1 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.326
2022-01-31 22:52:27 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-31 22:52:27 | INFO | train | epoch 146 | loss 5.468 | ppl 44.26 | wps 6024.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.988 | train_wall 319 | gb_free 6.1 | wall 50631
KL Stats: Epoch 146 Divergences: Uniform: 2.963370392600854 Unigram: 4.788961304699745
2022-01-31 22:52:27 | INFO | fairseq.trainer | begin training epoch 147
2022-01-31 22:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:57:08 | INFO | train_inner | epoch 147:     56 / 64 loss=5.47, ppl=44.31, wps=6195.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.992, train_wall=499, gb_free=6.1, wall=50912
2022-01-31 22:57:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:58:14 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.319 | ppl 1277.7 | wps 8121.9 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.326
2022-01-31 22:58:14 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-31 22:58:14 | INFO | train | epoch 147 | loss 5.461 | ppl 44.03 | wps 6023.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.998 | train_wall 319 | gb_free 6.1 | wall 50978
KL Stats: Epoch 147 Divergences: Uniform: 2.968024547503252 Unigram: 4.795234353395235
2022-01-31 22:58:14 | INFO | fairseq.trainer | begin training epoch 148
2022-01-31 22:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:03:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:04:00 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.344 | ppl 1300.1 | wps 8127.9 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.326
2022-01-31 23:04:00 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-31 23:04:00 | INFO | train | epoch 148 | loss 5.451 | ppl 43.74 | wps 6033.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.981 | train_wall 318 | gb_free 6.1 | wall 51324
KL Stats: Epoch 148 Divergences: Uniform: 2.970875453483355 Unigram: 4.814836934678458
2022-01-31 23:04:00 | INFO | fairseq.trainer | begin training epoch 149
2022-01-31 23:04:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:06:20 | INFO | train_inner | epoch 149:     28 / 64 loss=5.447, ppl=43.62, wps=5901.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.99, train_wall=497, gb_free=6.1, wall=51465
2022-01-31 23:09:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:09:47 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.364 | ppl 1317.92 | wps 8112.4 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.326
2022-01-31 23:09:47 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-31 23:09:47 | INFO | train | epoch 149 | loss 5.447 | ppl 43.63 | wps 6024.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 1.03 | train_wall 319 | gb_free 6.1 | wall 51671
KL Stats: Epoch 149 Divergences: Uniform: 2.9728071771089204 Unigram: 4.820278068674547
2022-01-31 23:09:47 | INFO | fairseq.trainer | begin training epoch 150
2022-01-31 23:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:15:06 | INFO | train_inner | epoch 150:     64 / 64 loss=5.449, ppl=43.67, wps=6208, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=1.017, train_wall=497, gb_free=6.1, wall=51990
2022-01-31 23:15:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:15:33 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.406 | ppl 1356.62 | wps 8085.1 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.326
2022-01-31 23:15:33 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-31 23:15:33 | INFO | train | epoch 150 | loss 5.437 | ppl 43.32 | wps 6036.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.999 | train_wall 318 | gb_free 6.1 | wall 52017
KL Stats: Epoch 150 Divergences: Uniform: 2.973089248087477 Unigram: 4.815940756613659
2022-01-31 23:15:33 | INFO | fairseq.trainer | begin training epoch 151
2022-01-31 23:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:21:19 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.395 | ppl 1346.83 | wps 8114.9 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.326
2022-01-31 23:21:19 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-31 23:21:19 | INFO | train | epoch 151 | loss 5.429 | ppl 43.07 | wps 6022.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.012 | train_wall 319 | gb_free 6.1 | wall 52364
KL Stats: Epoch 151 Divergences: Uniform: 2.9696210993696095 Unigram: 4.833747653182327
2022-01-31 23:21:19 | INFO | fairseq.trainer | begin training epoch 152
2022-01-31 23:21:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:24:20 | INFO | train_inner | epoch 152:     36 / 64 loss=5.416, ppl=42.7, wps=5893.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.018, train_wall=499, gb_free=6.1, wall=52544
2022-01-31 23:26:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:27:06 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.405 | ppl 1355.57 | wps 8149.5 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.326
2022-01-31 23:27:06 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-31 23:27:06 | INFO | train | epoch 152 | loss 5.422 | ppl 42.86 | wps 6028 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.016 | train_wall 319 | gb_free 6.1 | wall 52710
KL Stats: Epoch 152 Divergences: Uniform: 2.9755798518472494 Unigram: 4.846741600138211
2022-01-31 23:27:06 | INFO | fairseq.trainer | begin training epoch 153
2022-01-31 23:27:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:32:51 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.447 | ppl 1396.14 | wps 8219.4 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.326
2022-01-31 23:32:51 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-31 23:32:51 | INFO | train | epoch 153 | loss 5.413 | ppl 42.61 | wps 6053.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.992 | train_wall 318 | gb_free 6.1 | wall 53055
KL Stats: Epoch 153 Divergences: Uniform: 2.976073612597483 Unigram: 4.856112391695784
2022-01-31 23:32:51 | INFO | fairseq.trainer | begin training epoch 154
2022-01-31 23:32:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:33:31 | INFO | train_inner | epoch 154:      8 / 64 loss=5.421, ppl=42.85, wps=5920.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.998, train_wall=496, gb_free=6.1, wall=53095
2022-01-31 23:38:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:38:34 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.436 | ppl 1385.55 | wps 8208.3 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.326
2022-01-31 23:38:34 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-31 23:38:34 | INFO | train | epoch 154 | loss 5.408 | ppl 42.46 | wps 6091.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.035 | train_wall 315 | gb_free 6.1 | wall 53398
KL Stats: Epoch 154 Divergences: Uniform: 2.9810862469239283 Unigram: 4.857268663601933
2022-01-31 23:38:34 | INFO | fairseq.trainer | begin training epoch 155
2022-01-31 23:38:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:42:12 | INFO | train_inner | epoch 155:     44 / 64 loss=5.399, ppl=42.2, wps=6272.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.036, train_wall=493, gb_free=6.1, wall=53616
2022-01-31 23:43:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:44:16 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.385 | ppl 1336.99 | wps 8236 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.326
2022-01-31 23:44:16 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-31 23:44:16 | INFO | train | epoch 155 | loss 5.401 | ppl 42.25 | wps 6104.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.044 | train_wall 315 | gb_free 6.1 | wall 53740
KL Stats: Epoch 155 Divergences: Uniform: 2.9841395142974716 Unigram: 4.877648546174004
2022-01-31 23:44:16 | INFO | fairseq.trainer | begin training epoch 156
2022-01-31 23:44:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:49:58 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.458 | ppl 1406.57 | wps 8231.3 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.326
2022-01-31 23:49:58 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-31 23:49:58 | INFO | train | epoch 156 | loss 5.394 | ppl 42.05 | wps 6101.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.054 | train_wall 315 | gb_free 6.1 | wall 54083
KL Stats: Epoch 156 Divergences: Uniform: 2.9802092739702912 Unigram: 4.878030227757643
2022-01-31 23:49:58 | INFO | fairseq.trainer | begin training epoch 157
2022-01-31 23:49:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:51:18 | INFO | train_inner | epoch 157:     16 / 64 loss=5.399, ppl=42.21, wps=5970.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.046, train_wall=492, gb_free=6.1, wall=54162
2022-01-31 23:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:55:41 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.442 | ppl 1391.18 | wps 8243.1 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.326
2022-01-31 23:55:41 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-01-31 23:55:41 | INFO | train | epoch 157 | loss 5.386 | ppl 41.82 | wps 6086 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.024 | train_wall 316 | gb_free 6.1 | wall 54426
KL Stats: Epoch 157 Divergences: Uniform: 2.984939463234879 Unigram: 4.8915829757981655
2022-01-31 23:55:41 | INFO | fairseq.trainer | begin training epoch 158
2022-01-31 23:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:59:59 | INFO | train_inner | epoch 158:     52 / 64 loss=5.38, ppl=41.65, wps=6269.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.047, train_wall=493, gb_free=6.1, wall=54683
2022-02-01 00:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:01:24 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.44 | ppl 1389.46 | wps 8234.2 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.326
2022-02-01 00:01:24 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-01 00:01:24 | INFO | train | epoch 158 | loss 5.382 | ppl 41.69 | wps 6101.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.068 | train_wall 315 | gb_free 6.1 | wall 54768
KL Stats: Epoch 158 Divergences: Uniform: 2.981100016469909 Unigram: 4.895714819510672
2022-02-01 00:01:24 | INFO | fairseq.trainer | begin training epoch 159
2022-02-01 00:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:06:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:07:06 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.457 | ppl 1405.15 | wps 8227.4 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.326
2022-02-01 00:07:06 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-01 00:07:06 | INFO | train | epoch 159 | loss 5.373 | ppl 41.44 | wps 6106.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.075 | train_wall 315 | gb_free 6.1 | wall 55110
KL Stats: Epoch 159 Divergences: Uniform: 2.9847001847403876 Unigram: 4.912320133637599
2022-02-01 00:07:06 | INFO | fairseq.trainer | begin training epoch 160
2022-02-01 00:07:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:09:05 | INFO | train_inner | epoch 160:     24 / 64 loss=5.372, ppl=41.43, wps=5973.8, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.076, train_wall=491, gb_free=6.1, wall=55229
2022-02-01 00:12:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:12:48 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.473 | ppl 1421.17 | wps 8243.3 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.326
2022-02-01 00:12:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-01 00:12:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint160.pt
2022-02-01 00:12:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint160.pt
2022-02-01 00:12:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.473) (writing took 3.7004612926393747 seconds)
2022-02-01 00:12:52 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-01 00:12:52 | INFO | train | epoch 160 | loss 5.367 | ppl 41.26 | wps 6040.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.041 | train_wall 315 | gb_free 6.1 | wall 55456
KL Stats: Epoch 160 Divergences: Uniform: 2.9856770664016987 Unigram: 4.922376669516735
2022-02-01 00:12:52 | INFO | fairseq.trainer | begin training epoch 161
2022-02-01 00:12:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:17:48 | INFO | train_inner | epoch 161:     60 / 64 loss=5.368, ppl=41.3, wps=6247, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.051, train_wall=492, gb_free=6.1, wall=55752
2022-02-01 00:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:18:33 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.374 | ppl 1327.43 | wps 8276.1 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.326
2022-02-01 00:18:33 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-01 00:18:33 | INFO | train | epoch 161 | loss 5.361 | ppl 41.09 | wps 6122.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.066 | train_wall 314 | gb_free 6.1 | wall 55797
KL Stats: Epoch 161 Divergences: Uniform: 2.988834571372759 Unigram: 4.92429793933948
2022-02-01 00:18:33 | INFO | fairseq.trainer | begin training epoch 162
2022-02-01 00:18:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:24:15 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.457 | ppl 1405.7 | wps 8253.8 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.326
2022-02-01 00:24:15 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-01 00:24:15 | INFO | train | epoch 162 | loss 5.352 | ppl 40.86 | wps 6099.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.046 | train_wall 315 | gb_free 6.1 | wall 56140
KL Stats: Epoch 162 Divergences: Uniform: 2.9962826371986604 Unigram: 4.934040904521307
2022-02-01 00:24:15 | INFO | fairseq.trainer | begin training epoch 163
2022-02-01 00:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:26:54 | INFO | train_inner | epoch 163:     32 / 64 loss=5.34, ppl=40.5, wps=5967.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.057, train_wall=492, gb_free=6.1, wall=56299
2022-02-01 00:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:29:57 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.522 | ppl 1470.1 | wps 8272.8 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.326
2022-02-01 00:29:57 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-01 00:29:57 | INFO | train | epoch 163 | loss 5.35 | ppl 40.78 | wps 6101.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.093 | train_wall 315 | gb_free 6.1 | wall 56482
KL Stats: Epoch 163 Divergences: Uniform: 2.9887244471750205 Unigram: 4.947805474506079
2022-02-01 00:29:57 | INFO | fairseq.trainer | begin training epoch 164
2022-02-01 00:29:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:35:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:35:40 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.417 | ppl 1367.5 | wps 8267.6 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.326
2022-02-01 00:35:40 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-01 00:35:40 | INFO | train | epoch 164 | loss 5.341 | ppl 40.54 | wps 6099.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.1 | train_wall 315 | gb_free 6.1 | wall 56824
KL Stats: Epoch 164 Divergences: Uniform: 2.9881662757355425 Unigram: 4.949558263771067
2022-02-01 00:35:40 | INFO | fairseq.trainer | begin training epoch 165
2022-02-01 00:35:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:36:00 | INFO | train_inner | epoch 165:      4 / 64 loss=5.356, ppl=40.97, wps=5972.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.1, train_wall=491, gb_free=6.1, wall=56844
2022-02-01 00:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:41:21 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.468 | ppl 1416.63 | wps 8244.3 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.326
2022-02-01 00:41:21 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-01 00:41:21 | INFO | train | epoch 165 | loss 5.333 | ppl 40.31 | wps 6121.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.079 | train_wall 314 | gb_free 6.1 | wall 57166
KL Stats: Epoch 165 Divergences: Uniform: 2.994881500628489 Unigram: 4.9666141733507345
2022-02-01 00:41:21 | INFO | fairseq.trainer | begin training epoch 166
2022-02-01 00:41:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:44:39 | INFO | train_inner | epoch 166:     40 / 64 loss=5.327, ppl=40.14, wps=6292.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.102, train_wall=492, gb_free=6.1, wall=57364
2022-02-01 00:46:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:47:03 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.363 | ppl 1317.33 | wps 8270.2 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.326
2022-02-01 00:47:03 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-01 00:47:03 | INFO | train | epoch 166 | loss 5.33 | ppl 40.23 | wps 6107.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.122 | train_wall 315 | gb_free 6.1 | wall 57508
KL Stats: Epoch 166 Divergences: Uniform: 2.9992728981504 Unigram: 4.971394016326823
2022-02-01 00:47:03 | INFO | fairseq.trainer | begin training epoch 167
2022-02-01 00:47:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:52:44 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.359 | ppl 1313.38 | wps 8284.7 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.326
2022-02-01 00:52:44 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-01 00:52:44 | INFO | train | epoch 167 | loss 5.323 | ppl 40.03 | wps 6124 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.121 | train_wall 314 | gb_free 6.1 | wall 57849
KL Stats: Epoch 167 Divergences: Uniform: 2.9950113051000087 Unigram: 4.9742442550947015
2022-02-01 00:52:44 | INFO | fairseq.trainer | begin training epoch 168
2022-02-01 00:52:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:53:43 | INFO | train_inner | epoch 168:     12 / 64 loss=5.325, ppl=40.09, wps=5990.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.117, train_wall=490, gb_free=6.1, wall=57908
2022-02-01 00:58:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:58:27 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.485 | ppl 1432.75 | wps 8149.8 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.326
2022-02-01 00:58:27 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-01 00:58:27 | INFO | train | epoch 168 | loss 5.318 | ppl 39.89 | wps 6094.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.128 | train_wall 315 | gb_free 6.1 | wall 58191
KL Stats: Epoch 168 Divergences: Uniform: 3.000312554799235 Unigram: 4.978208199639454
2022-02-01 00:58:27 | INFO | fairseq.trainer | begin training epoch 169
2022-02-01 00:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:02:24 | INFO | train_inner | epoch 169:     48 / 64 loss=5.317, ppl=39.86, wps=6277.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.124, train_wall=492, gb_free=6.1, wall=58428
2022-02-01 01:03:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:04:08 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.442 | ppl 1390.67 | wps 8244.4 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.326
2022-02-01 01:04:08 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-01 01:04:08 | INFO | train | epoch 169 | loss 5.312 | ppl 39.71 | wps 6117.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.118 | train_wall 314 | gb_free 6.1 | wall 58533
KL Stats: Epoch 169 Divergences: Uniform: 2.9983674913737386 Unigram: 4.990433999394714
2022-02-01 01:04:08 | INFO | fairseq.trainer | begin training epoch 170
2022-02-01 01:04:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:09:50 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.483 | ppl 1431.53 | wps 8214.1 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.326
2022-02-01 01:09:50 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-01 01:09:50 | INFO | train | epoch 170 | loss 5.306 | ppl 39.55 | wps 6109.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.128 | train_wall 314 | gb_free 6.1 | wall 58875
KL Stats: Epoch 170 Divergences: Uniform: 3.0005937742223963 Unigram: 4.998865152537638
2022-02-01 01:09:50 | INFO | fairseq.trainer | begin training epoch 171
2022-02-01 01:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:11:29 | INFO | train_inner | epoch 171:     20 / 64 loss=5.3, ppl=39.4, wps=5980.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.137, train_wall=491, gb_free=6.1, wall=58974
2022-02-01 01:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:15:31 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.471 | ppl 1419.8 | wps 8266.1 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.326
2022-02-01 01:15:31 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-01 01:15:31 | INFO | train | epoch 171 | loss 5.3 | ppl 39.4 | wps 6119.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.181 | train_wall 314 | gb_free 6.1 | wall 59216
KL Stats: Epoch 171 Divergences: Uniform: 3.000937250419241 Unigram: 5.008228403168469
2022-02-01 01:15:31 | INFO | fairseq.trainer | begin training epoch 172
2022-02-01 01:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:20:09 | INFO | train_inner | epoch 172:     56 / 64 loss=5.303, ppl=39.48, wps=6290.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.167, train_wall=492, gb_free=6.1, wall=59493
2022-02-01 01:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:21:14 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.458 | ppl 1406.26 | wps 8250.8 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.326
2022-02-01 01:21:14 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-01 01:21:14 | INFO | train | epoch 172 | loss 5.294 | ppl 39.23 | wps 6103.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.164 | train_wall 315 | gb_free 6.1 | wall 59558
KL Stats: Epoch 172 Divergences: Uniform: 3.0039760474887784 Unigram: 5.011681364315963
2022-02-01 01:21:14 | INFO | fairseq.trainer | begin training epoch 173
2022-02-01 01:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:26:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:26:55 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.395 | ppl 1346.09 | wps 8252.2 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.326
2022-02-01 01:26:55 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-01 01:26:55 | INFO | train | epoch 173 | loss 5.287 | ppl 39.05 | wps 6112.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.175 | train_wall 314 | gb_free 6.1 | wall 59900
KL Stats: Epoch 173 Divergences: Uniform: 3.00334954737982 Unigram: 5.0166818895606635
2022-02-01 01:26:55 | INFO | fairseq.trainer | begin training epoch 174
2022-02-01 01:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:29:14 | INFO | train_inner | epoch 174:     28 / 64 loss=5.281, ppl=38.88, wps=5981.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.163, train_wall=491, gb_free=6.1, wall=60038
2022-02-01 01:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:32:38 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.473 | ppl 1421.64 | wps 8138.6 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.326
2022-02-01 01:32:38 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-01 01:32:38 | INFO | train | epoch 174 | loss 5.283 | ppl 38.93 | wps 6098.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.165 | train_wall 315 | gb_free 6.1 | wall 60242
KL Stats: Epoch 174 Divergences: Uniform: 3.0051567015836254 Unigram: 5.029634433378922
2022-02-01 01:32:38 | INFO | fairseq.trainer | begin training epoch 175
2022-02-01 01:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:37:53 | INFO | train_inner | epoch 175:     64 / 64 loss=5.287, ppl=39.03, wps=6275.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.177, train_wall=491, gb_free=6.1, wall=60558
2022-02-01 01:37:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:38:20 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.534 | ppl 1482.38 | wps 8247.9 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.326
2022-02-01 01:38:20 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-01 01:38:20 | INFO | train | epoch 175 | loss 5.275 | ppl 38.73 | wps 6111 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.165 | train_wall 314 | gb_free 6.1 | wall 60584
KL Stats: Epoch 175 Divergences: Uniform: 3.015325232606118 Unigram: 5.039678662076189
2022-02-01 01:38:20 | INFO | fairseq.trainer | begin training epoch 176
2022-02-01 01:38:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:44:02 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.52 | ppl 1468.83 | wps 8192.7 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.326
2022-02-01 01:44:02 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-01 01:44:02 | INFO | train | epoch 176 | loss 5.271 | ppl 38.62 | wps 6103.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.18 | train_wall 315 | gb_free 6.1 | wall 60926
KL Stats: Epoch 176 Divergences: Uniform: 3.0099425586763084 Unigram: 5.046631055147024
2022-02-01 01:44:02 | INFO | fairseq.trainer | begin training epoch 177
2022-02-01 01:44:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:47:00 | INFO | train_inner | epoch 177:     36 / 64 loss=5.258, ppl=38.27, wps=5975.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.187, train_wall=492, gb_free=6.1, wall=61105
2022-02-01 01:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:49:43 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.424 | ppl 1373.76 | wps 8293 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.326
2022-02-01 01:49:43 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-01 01:49:43 | INFO | train | epoch 177 | loss 5.265 | ppl 38.45 | wps 6112.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.217 | train_wall 314 | gb_free 6.1 | wall 61268
KL Stats: Epoch 177 Divergences: Uniform: 3.0112642756156056 Unigram: 5.050980110777996
2022-02-01 01:49:43 | INFO | fairseq.trainer | begin training epoch 178
2022-02-01 01:49:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:55:25 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.498 | ppl 1446.53 | wps 8218.7 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.326
2022-02-01 01:55:25 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-01 01:55:25 | INFO | train | epoch 178 | loss 5.262 | ppl 38.38 | wps 6113 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.203 | train_wall 314 | gb_free 6.1 | wall 61610
KL Stats: Epoch 178 Divergences: Uniform: 3.0118346679914385 Unigram: 5.055410763553868
2022-02-01 01:55:25 | INFO | fairseq.trainer | begin training epoch 179
2022-02-01 01:55:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:56:05 | INFO | train_inner | epoch 179:      8 / 64 loss=5.269, ppl=38.57, wps=5982.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.21, train_wall=491, gb_free=6.1, wall=61649
2022-02-01 02:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:01:07 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.44 | ppl 1388.73 | wps 8287.9 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.326
2022-02-01 02:01:07 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-01 02:01:07 | INFO | train | epoch 179 | loss 5.255 | ppl 38.19 | wps 6117.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.198 | train_wall 314 | gb_free 6.1 | wall 61951
KL Stats: Epoch 179 Divergences: Uniform: 3.0139144278609695 Unigram: 5.063057981593525
2022-02-01 02:01:07 | INFO | fairseq.trainer | begin training epoch 180
2022-02-01 02:01:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:04:44 | INFO | train_inner | epoch 180:     44 / 64 loss=5.25, ppl=38.06, wps=6296, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.203, train_wall=491, gb_free=6.1, wall=62168
2022-02-01 02:06:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:06:49 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.422 | ppl 1372.27 | wps 8225.1 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.326
2022-02-01 02:06:49 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-01 02:06:49 | INFO | train | epoch 180 | loss 5.251 | ppl 38.09 | wps 6098.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.222 | train_wall 315 | gb_free 6.1 | wall 62293
KL Stats: Epoch 180 Divergences: Uniform: 3.015776991050507 Unigram: 5.070970856979377
2022-02-01 02:06:49 | INFO | fairseq.trainer | begin training epoch 181
2022-02-01 02:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:12:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:12:31 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.488 | ppl 1436.01 | wps 8255.7 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.326
2022-02-01 02:12:31 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-01 02:12:31 | INFO | train | epoch 181 | loss 5.243 | ppl 37.87 | wps 6115.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.216 | train_wall 314 | gb_free 6.1 | wall 62635
KL Stats: Epoch 181 Divergences: Uniform: 3.0187921644685747 Unigram: 5.081654839657489
2022-02-01 02:12:31 | INFO | fairseq.trainer | begin training epoch 182
2022-02-01 02:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:13:50 | INFO | train_inner | epoch 182:     16 / 64 loss=5.244, ppl=37.91, wps=5973.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.23, train_wall=491, gb_free=6.1, wall=62714
2022-02-01 02:17:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:18:13 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.41 | ppl 1360.67 | wps 8232.5 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.326
2022-02-01 02:18:13 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-01 02:18:13 | INFO | train | epoch 182 | loss 5.241 | ppl 37.82 | wps 6107.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.241 | train_wall 315 | gb_free 6.1 | wall 62977
KL Stats: Epoch 182 Divergences: Uniform: 3.019154154032112 Unigram: 5.0797379849701
2022-02-01 02:18:13 | INFO | fairseq.trainer | begin training epoch 183
2022-02-01 02:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:22:30 | INFO | train_inner | epoch 183:     52 / 64 loss=5.239, ppl=37.77, wps=6283.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.262, train_wall=492, gb_free=6.1, wall=63234
2022-02-01 02:23:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:23:54 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.437 | ppl 1386.39 | wps 8245.7 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.326
2022-02-01 02:23:54 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-01 02:23:54 | INFO | train | epoch 183 | loss 5.236 | ppl 37.68 | wps 6109.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.274 | train_wall 314 | gb_free 6.1 | wall 63319
KL Stats: Epoch 183 Divergences: Uniform: 3.019949897151495 Unigram: 5.095525725492096
2022-02-01 02:23:54 | INFO | fairseq.trainer | begin training epoch 184
2022-02-01 02:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:29:36 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.43 | ppl 1379.62 | wps 8222.4 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.326
2022-02-01 02:29:36 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-01 02:29:36 | INFO | train | epoch 184 | loss 5.231 | ppl 37.55 | wps 6113.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.235 | train_wall 314 | gb_free 6.1 | wall 63660
KL Stats: Epoch 184 Divergences: Uniform: 3.0190379417477002 Unigram: 5.096809579381083
2022-02-01 02:29:36 | INFO | fairseq.trainer | begin training epoch 185
2022-02-01 02:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:31:35 | INFO | train_inner | epoch 185:     24 / 64 loss=5.231, ppl=37.54, wps=5979.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.241, train_wall=491, gb_free=6.1, wall=63780
2022-02-01 02:34:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:35:18 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.48 | ppl 1427.78 | wps 8295.4 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.326
2022-02-01 02:35:18 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-01 02:35:18 | INFO | train | epoch 185 | loss 5.226 | ppl 37.44 | wps 6108.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.283 | train_wall 315 | gb_free 6.1 | wall 64002
KL Stats: Epoch 185 Divergences: Uniform: 3.016914206825253 Unigram: 5.106786464195065
2022-02-01 02:35:18 | INFO | fairseq.trainer | begin training epoch 186
2022-02-01 02:35:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:40:15 | INFO | train_inner | epoch 186:     60 / 64 loss=5.227, ppl=37.46, wps=6286.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.292, train_wall=492, gb_free=6.1, wall=64299
2022-02-01 02:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:41:00 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.411 | ppl 1361.39 | wps 8221.8 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.326
2022-02-01 02:41:00 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-01 02:41:00 | INFO | train | epoch 186 | loss 5.223 | ppl 37.34 | wps 6103.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.29 | train_wall 315 | gb_free 6.1 | wall 64345
KL Stats: Epoch 186 Divergences: Uniform: 3.017672078005219 Unigram: 5.110796530723995
2022-02-01 02:41:00 | INFO | fairseq.trainer | begin training epoch 187
2022-02-01 02:41:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:46:42 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.482 | ppl 1430.5 | wps 8266.6 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.326
2022-02-01 02:46:42 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-01 02:46:42 | INFO | train | epoch 187 | loss 5.217 | ppl 37.2 | wps 6107 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.263 | train_wall 315 | gb_free 6.1 | wall 64687
KL Stats: Epoch 187 Divergences: Uniform: 3.020967771358295 Unigram: 5.118241081542562
2022-02-01 02:46:42 | INFO | fairseq.trainer | begin training epoch 188
2022-02-01 02:46:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:49:20 | INFO | train_inner | epoch 188:     32 / 64 loss=5.21, ppl=37.01, wps=5978.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.272, train_wall=491, gb_free=6.1, wall=64845
2022-02-01 02:51:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:52:24 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.476 | ppl 1424.66 | wps 8196.4 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.326
2022-02-01 02:52:24 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-01 02:52:24 | INFO | train | epoch 188 | loss 5.209 | ppl 37 | wps 6116.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.279 | train_wall 314 | gb_free 6.1 | wall 65028
KL Stats: Epoch 188 Divergences: Uniform: 3.019819845583933 Unigram: 5.126205599260394
2022-02-01 02:52:24 | INFO | fairseq.trainer | begin training epoch 189
2022-02-01 02:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:57:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:58:06 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.441 | ppl 1390.09 | wps 8283 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.326
2022-02-01 02:58:06 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-01 02:58:06 | INFO | train | epoch 189 | loss 5.207 | ppl 36.95 | wps 6101.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.335 | train_wall 315 | gb_free 6.1 | wall 65370
KL Stats: Epoch 189 Divergences: Uniform: 3.0199039292451917 Unigram: 5.1277280512038095
2022-02-01 02:58:06 | INFO | fairseq.trainer | begin training epoch 190
2022-02-01 02:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:58:26 | INFO | train_inner | epoch 190:      4 / 64 loss=5.213, ppl=37.08, wps=5975.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.313, train_wall=491, gb_free=6.1, wall=65390
2022-02-01 03:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:03:47 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.454 | ppl 1403.15 | wps 8206 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.326
2022-02-01 03:03:47 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-01 03:03:47 | INFO | train | epoch 190 | loss 5.201 | ppl 36.78 | wps 6120.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.3 | train_wall 314 | gb_free 6.1 | wall 65712
KL Stats: Epoch 190 Divergences: Uniform: 3.0226450112466012 Unigram: 5.1327704773761935
2022-02-01 03:03:47 | INFO | fairseq.trainer | begin training epoch 191
2022-02-01 03:03:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:07:06 | INFO | train_inner | epoch 191:     40 / 64 loss=5.19, ppl=36.5, wps=6283.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.293, train_wall=492, gb_free=6.1, wall=65910
2022-02-01 03:09:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:09:30 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.454 | ppl 1402.27 | wps 8249.9 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.326
2022-02-01 03:09:30 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-01 03:09:30 | INFO | train | epoch 191 | loss 5.196 | ppl 36.66 | wps 6097.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.277 | train_wall 315 | gb_free 6.1 | wall 66054
KL Stats: Epoch 191 Divergences: Uniform: 3.023339571446987 Unigram: 5.142581513866657
2022-02-01 03:09:30 | INFO | fairseq.trainer | begin training epoch 192
2022-02-01 03:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:14:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:15:12 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.476 | ppl 1424.34 | wps 8233.2 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.326
2022-02-01 03:15:12 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-01 03:15:12 | INFO | train | epoch 192 | loss 5.193 | ppl 36.58 | wps 6097 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.338 | train_wall 315 | gb_free 6.1 | wall 66397
KL Stats: Epoch 192 Divergences: Uniform: 3.0228202068906227 Unigram: 5.143725730237356
2022-02-01 03:15:12 | INFO | fairseq.trainer | begin training epoch 193
2022-02-01 03:15:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:16:12 | INFO | train_inner | epoch 193:     12 / 64 loss=5.199, ppl=36.74, wps=5968.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.328, train_wall=492, gb_free=6.1, wall=66456
2022-02-01 03:20:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:20:54 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.466 | ppl 1414.78 | wps 8292.9 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.326
2022-02-01 03:20:54 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-01 03:20:54 | INFO | train | epoch 193 | loss 5.19 | ppl 36.5 | wps 6104.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.343 | train_wall 315 | gb_free 6.1 | wall 66739
KL Stats: Epoch 193 Divergences: Uniform: 3.026802161403407 Unigram: 5.153601186729461
2022-02-01 03:20:54 | INFO | fairseq.trainer | begin training epoch 194
2022-02-01 03:20:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:24:51 | INFO | train_inner | epoch 194:     48 / 64 loss=5.186, ppl=36.39, wps=6292.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.348, train_wall=492, gb_free=6.1, wall=66976
2022-02-01 03:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:26:36 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.435 | ppl 1384.71 | wps 8233.1 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.326
2022-02-01 03:26:36 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-01 03:26:36 | INFO | train | epoch 194 | loss 5.184 | ppl 36.36 | wps 6118.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.369 | train_wall 314 | gb_free 6.1 | wall 67080
KL Stats: Epoch 194 Divergences: Uniform: 3.0267364787251165 Unigram: 5.155686279005651
2022-02-01 03:26:36 | INFO | fairseq.trainer | begin training epoch 195
2022-02-01 03:26:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:32:18 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.464 | ppl 1412.64 | wps 8269.3 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.326
2022-02-01 03:32:18 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-01 03:32:18 | INFO | train | epoch 195 | loss 5.18 | ppl 36.25 | wps 6100.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.361 | train_wall 315 | gb_free 6.1 | wall 67423
KL Stats: Epoch 195 Divergences: Uniform: 3.0246999717742877 Unigram: 5.161739679955399
2022-02-01 03:32:18 | INFO | fairseq.trainer | begin training epoch 196
2022-02-01 03:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:33:57 | INFO | train_inner | epoch 196:     20 / 64 loss=5.178, ppl=36.2, wps=5975, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.356, train_wall=491, gb_free=6.1, wall=67521
2022-02-01 03:37:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:38:00 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.431 | ppl 1380.96 | wps 8268.5 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.326
2022-02-01 03:38:00 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-01 03:38:00 | INFO | train | epoch 196 | loss 5.176 | ppl 36.15 | wps 6117.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.352 | train_wall 314 | gb_free 6.1 | wall 67764
KL Stats: Epoch 196 Divergences: Uniform: 3.0263476945324257 Unigram: 5.169377428131848
2022-02-01 03:38:00 | INFO | fairseq.trainer | begin training epoch 197
2022-02-01 03:38:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:42:37 | INFO | train_inner | epoch 197:     56 / 64 loss=5.176, ppl=36.16, wps=6285.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.379, train_wall=492, gb_free=6.1, wall=68041
2022-02-01 03:43:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:43:42 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.515 | ppl 1462.97 | wps 8246.2 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.326
2022-02-01 03:43:42 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-01 03:43:42 | INFO | train | epoch 197 | loss 5.171 | ppl 36.04 | wps 6104.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.395 | train_wall 315 | gb_free 6.1 | wall 68106
KL Stats: Epoch 197 Divergences: Uniform: 3.0288804799675466 Unigram: 5.171969335448514
2022-02-01 03:43:42 | INFO | fairseq.trainer | begin training epoch 198
2022-02-01 03:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:49:24 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.461 | ppl 1409.24 | wps 8264.4 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.326
2022-02-01 03:49:24 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-01 03:49:24 | INFO | train | epoch 198 | loss 5.167 | ppl 35.94 | wps 6110.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.414 | train_wall 314 | gb_free 6.1 | wall 68448
KL Stats: Epoch 198 Divergences: Uniform: 3.030845318695624 Unigram: 5.185619835106468
2022-02-01 03:49:24 | INFO | fairseq.trainer | begin training epoch 199
2022-02-01 03:49:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:51:42 | INFO | train_inner | epoch 199:     28 / 64 loss=5.162, ppl=35.79, wps=5980.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.397, train_wall=491, gb_free=6.1, wall=68587
2022-02-01 03:54:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:55:06 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.437 | ppl 1386.43 | wps 8259.7 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.326
2022-02-01 03:55:06 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-01 03:55:06 | INFO | train | epoch 199 | loss 5.16 | ppl 35.76 | wps 6105.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.355 | train_wall 315 | gb_free 6.1 | wall 68790
KL Stats: Epoch 199 Divergences: Uniform: 3.0302740565628885 Unigram: 5.193646351813847
2022-02-01 03:55:06 | INFO | fairseq.trainer | begin training epoch 200
2022-02-01 03:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:00:20 | INFO | train_inner | epoch 200:     64 / 64 loss=5.17, ppl=35.99, wps=6288.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.39, train_wall=491, gb_free=6.1, wall=69105
2022-02-01 04:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:00:47 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.491 | ppl 1438.71 | wps 8242.3 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.326
2022-02-01 04:00:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-01 04:00:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint200.pt
2022-02-01 04:00:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint200.pt
2022-02-01 04:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.491) (writing took 3.4844263773411512 seconds)
2022-02-01 04:00:50 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-01 04:00:50 | INFO | train | epoch 200 | loss 5.158 | ppl 35.7 | wps 6057 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.404 | train_wall 314 | gb_free 6.1 | wall 69135
KL Stats: Epoch 200 Divergences: Uniform: 3.0285782648942443 Unigram: 5.1993120202370555
2022-02-01 04:00:50 | INFO | fairseq.trainer | begin training epoch 201
2022-02-01 04:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:06:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:06:33 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.494 | ppl 1441.79 | wps 8286.2 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.326
2022-02-01 04:06:33 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-01 04:06:33 | INFO | train | epoch 201 | loss 5.155 | ppl 35.63 | wps 6102.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.418 | train_wall 315 | gb_free 6.1 | wall 69477
KL Stats: Epoch 201 Divergences: Uniform: 3.027663156396804 Unigram: 5.1950693989773615
2022-02-01 04:06:33 | INFO | fairseq.trainer | begin training epoch 202
2022-02-01 04:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:09:30 | INFO | train_inner | epoch 202:     36 / 64 loss=5.14, ppl=35.27, wps=5940.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.419, train_wall=492, gb_free=6.1, wall=69655
2022-02-01 04:11:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:12:14 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.484 | ppl 1432.59 | wps 8260.7 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.326
2022-02-01 04:12:14 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-01 04:12:14 | INFO | train | epoch 202 | loss 5.148 | ppl 35.46 | wps 6120.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.405 | train_wall 314 | gb_free 6.1 | wall 69818
KL Stats: Epoch 202 Divergences: Uniform: 3.028541582190509 Unigram: 5.210616738014204
2022-02-01 04:12:14 | INFO | fairseq.trainer | begin training epoch 203
2022-02-01 04:12:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:17:56 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.443 | ppl 1391.83 | wps 8291.8 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.326
2022-02-01 04:17:56 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-01 04:17:56 | INFO | train | epoch 203 | loss 5.145 | ppl 35.37 | wps 6103.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.455 | train_wall 315 | gb_free 6.1 | wall 70161
KL Stats: Epoch 203 Divergences: Uniform: 3.0285699207730894 Unigram: 5.2168153046609245
2022-02-01 04:17:56 | INFO | fairseq.trainer | begin training epoch 204
2022-02-01 04:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:18:36 | INFO | train_inner | epoch 204:      8 / 64 loss=5.153, ppl=35.58, wps=5978.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.431, train_wall=491, gb_free=6.1, wall=70200
2022-02-01 04:23:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:23:38 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.483 | ppl 1431.1 | wps 8264.8 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.326
2022-02-01 04:23:38 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-01 04:23:38 | INFO | train | epoch 204 | loss 5.139 | ppl 35.25 | wps 6108.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.438 | train_wall 315 | gb_free 6.1 | wall 70503
KL Stats: Epoch 204 Divergences: Uniform: 3.035448135083059 Unigram: 5.221081664283911
2022-02-01 04:23:38 | INFO | fairseq.trainer | begin training epoch 205
2022-02-01 04:23:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:27:16 | INFO | train_inner | epoch 205:     44 / 64 loss=5.135, ppl=35.13, wps=6284.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.448, train_wall=492, gb_free=6.1, wall=70720
2022-02-01 04:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:29:20 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.495 | ppl 1443.33 | wps 8260.5 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.326
2022-02-01 04:29:20 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-01 04:29:20 | INFO | train | epoch 205 | loss 5.135 | ppl 35.14 | wps 6105 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.457 | train_wall 315 | gb_free 6.1 | wall 70845
KL Stats: Epoch 205 Divergences: Uniform: 3.0338626720616406 Unigram: 5.231691087027735
2022-02-01 04:29:20 | INFO | fairseq.trainer | begin training epoch 206
2022-02-01 04:29:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:34:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:35:02 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.496 | ppl 1444.49 | wps 8281.3 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.326
2022-02-01 04:35:02 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-01 04:35:02 | INFO | train | epoch 206 | loss 5.132 | ppl 35.06 | wps 6116.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.43 | train_wall 314 | gb_free 6.1 | wall 71186
KL Stats: Epoch 206 Divergences: Uniform: 3.031974173840871 Unigram: 5.23500968824743
2022-02-01 04:35:02 | INFO | fairseq.trainer | begin training epoch 207
2022-02-01 04:35:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:36:21 | INFO | train_inner | epoch 207:     16 / 64 loss=5.133, ppl=35.1, wps=5981.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.439, train_wall=491, gb_free=6.1, wall=71265
2022-02-01 04:40:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:40:44 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.515 | ppl 1463.37 | wps 8250.7 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.326
2022-02-01 04:40:44 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-02-01 04:40:44 | INFO | train | epoch 207 | loss 5.129 | ppl 35 | wps 6098.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.482 | train_wall 315 | gb_free 6.1 | wall 71529
KL Stats: Epoch 207 Divergences: Uniform: 3.033549174593652 Unigram: 5.23813205520894
2022-02-01 04:40:44 | INFO | fairseq.trainer | begin training epoch 208
2022-02-01 04:40:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:45:01 | INFO | train_inner | epoch 208:     52 / 64 loss=5.127, ppl=34.93, wps=6283.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.486, train_wall=492, gb_free=6.1, wall=71785
2022-02-01 04:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:46:25 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 10.511 | ppl 1458.84 | wps 8263.6 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.326
2022-02-01 04:46:25 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-02-01 04:46:25 | INFO | train | epoch 208 | loss 5.124 | ppl 34.87 | wps 6119.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.482 | train_wall 314 | gb_free 6.1 | wall 71870
KL Stats: Epoch 208 Divergences: Uniform: 3.0362536561155764 Unigram: 5.249248391620011
2022-02-01 04:46:25 | INFO | fairseq.trainer | begin training epoch 209
2022-02-01 04:46:25 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
Sender: LSF System <lsfadmin@eu-g2-08>
Subject: Job 202993293: <w2_jelinek_0.11_-0.01_0.9_#2> in cluster <euler> Exited

Job <w2_jelinek_0.11_-0.01_0.9_#2> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:06:01 2022
Job was executed on host(s) <eu-g2-08>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:06:34 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:06:34 2022
Terminated at Thu Feb  3 02:06:38 2022
Results reported at Thu Feb  3 02:06:38 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.11, -0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 202 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72864.17 sec.
    Max Memory :                                 5069 MB
    Average Memory :                             2689.26 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14931.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72003 sec.
    Turnaround time :                            72037 sec.

The output (if any) follows:

2022-02-02 06:06:39 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 202, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 202, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.11, -0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:06:39 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:06:40 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1390/36718 [00:00<00:02, 13883.53it/s]  8%|▊         | 2779/36718 [00:00<00:02, 13383.96it/s] 12%|█▏        | 4317/36718 [00:00<00:02, 14267.26it/s] 16%|█▌        | 5927/36718 [00:00<00:02, 14978.61it/s] 20%|██        | 7428/36718 [00:00<00:02, 14239.86it/s] 24%|██▍       | 8860/36718 [00:00<00:01, 14006.85it/s] 28%|██▊       | 10307/36718 [00:00<00:01, 14151.75it/s] 32%|███▏      | 11726/36718 [00:00<00:01, 13841.09it/s] 36%|███▌      | 13177/36718 [00:00<00:01, 14037.28it/s] 40%|███▉      | 14602/36718 [00:01<00:01, 14100.06it/s] 44%|████▎     | 16015/36718 [00:01<00:01, 13944.58it/s] 48%|████▊     | 17457/36718 [00:01<00:01, 14082.42it/s] 51%|█████▏    | 18886/36718 [00:01<00:01, 14143.78it/s] 55%|█████▌    | 20314/36718 [00:01<00:01, 14179.69it/s] 59%|█████▉    | 21733/36718 [00:01<00:01, 14044.05it/s] 63%|██████▎   | 23218/36718 [00:01<00:00, 14272.63it/s] 68%|██████▊   | 24883/36718 [00:01<00:00, 14977.89it/s] 72%|███████▏  | 26382/36718 [00:01<00:00, 14503.01it/s] 76%|███████▌  | 27837/36718 [00:01<00:00, 14031.16it/s] 80%|███████▉  | 29309/36718 [00:02<00:00, 14217.21it/s] 84%|████████▎ | 30736/36718 [00:02<00:00, 13877.59it/s] 87%|████████▋ | 32128/36718 [00:02<00:00, 13627.67it/s] 91%|█████████ | 33494/36718 [00:02<00:00, 13557.25it/s] 95%|█████████▌| 34955/36718 [00:02<00:00, 13858.39it/s] 99%|█████████▉| 36344/36718 [00:02<00:00, 13813.63it/s]100%|██████████| 36718/36718 [00:02<00:00, 14052.21it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  7%|▋         | 2699/36718 [00:00<00:01, 26981.86it/s] 16%|█▌        | 5794/36718 [00:00<00:01, 29313.11it/s] 24%|██▍       | 8726/36718 [00:00<00:01, 27843.01it/s] 31%|███▏      | 11519/36718 [00:00<00:00, 27869.54it/s] 39%|███▉      | 14344/36718 [00:00<00:00, 27993.87it/s] 47%|████▋     | 17147/36718 [00:00<00:00, 27778.55it/s] 55%|█████▍    | 20063/36718 [00:00<00:00, 28216.34it/s] 62%|██████▏   | 22887/36718 [00:00<00:00, 27991.05it/s] 71%|███████   | 25911/36718 [00:00<00:00, 28676.60it/s] 78%|███████▊  | 28781/36718 [00:01<00:00, 28350.49it/s] 86%|████████▌ | 31618/36718 [00:01<00:00, 27844.32it/s] 94%|█████████▎| 34406/36718 [00:01<00:00, 27436.51it/s]100%|██████████| 36718/36718 [00:01<00:00, 27953.94it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 208.60it/s]2022-02-02 06:06:49 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:06:49 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:06:49 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:06:49 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:06:49 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:06:49 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:06:49 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:06:49 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:06:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:06:49 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-02-02 06:06:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:06:49 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:06:49 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:06:49 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint_last.pt
2022-02-02 06:06:49 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint_last.pt
2022-02-02 06:06:49 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:06:49 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:06:49 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:06:49 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:06:49 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:12:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:12:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.748 | ppl 27508.5 | wps 8072.4 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:12:38 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:12:38 | INFO | train | epoch 001 | loss 16.014 | ppl 66166.1 | wps 6003.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.136 | train_wall 320 | gb_free 6.1 | wall 349
KL Stats: Epoch 1 Divergences: Uniform: 0.5279059260356072 Unigram: 3.6091869227684077
2022-02-02 06:12:38 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:15:39 | INFO | train_inner | epoch 002:     36 / 64 loss=15.514, ppl=46796.1, wps=6173, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.579, train_wall=501, gb_free=6.1, wall=531
2022-02-02 06:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:18:26 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.703 | ppl 13337.6 | wps 8099.7 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:18:26 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:18:26 | INFO | train | epoch 002 | loss 14.41 | ppl 21769.6 | wps 5989.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.494 | train_wall 321 | gb_free 6.1 | wall 698
KL Stats: Epoch 2 Divergences: Uniform: 0.5317900062295209 Unigram: 2.390907032035797
2022-02-02 06:18:27 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:23:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:24:14 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.877 | ppl 7522.57 | wps 8082.1 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:24:14 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:24:14 | INFO | train | epoch 003 | loss 13.518 | ppl 11732.8 | wps 6006 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.228 | train_wall 320 | gb_free 6.1 | wall 1046
KL Stats: Epoch 3 Divergences: Uniform: 0.5127929902531759 Unigram: 1.708478491199424
2022-02-02 06:24:14 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:24:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:24:55 | INFO | train_inner | epoch 004:      8 / 64 loss=13.647, ppl=12831.8, wps=5871, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.257, train_wall=500, gb_free=6.1, wall=1086
2022-02-02 06:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:30:03 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.079 | ppl 4326.68 | wps 8069.1 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:30:03 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:30:03 | INFO | train | epoch 004 | loss 12.581 | ppl 6127.26 | wps 5995 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.95 | train_wall 320 | gb_free 6.1 | wall 1394
KL Stats: Epoch 4 Divergences: Uniform: 0.6016739755802772 Unigram: 1.0936494938701828
2022-02-02 06:30:03 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:33:44 | INFO | train_inner | epoch 005:     44 / 64 loss=12.244, ppl=4849.42, wps=6174.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.825, train_wall=501, gb_free=6.1, wall=1615
2022-02-02 06:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:35:51 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.56 | ppl 3018.4 | wps 8072.1 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:35:51 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:35:51 | INFO | train | epoch 005 | loss 11.817 | ppl 3608.22 | wps 6002.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.672 | train_wall 320 | gb_free 6.1 | wall 1742
KL Stats: Epoch 5 Divergences: Uniform: 0.8343163313888943 Unigram: 0.6340081426920596
2022-02-02 06:35:51 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:41:39 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.342 | ppl 2595.12 | wps 8089.7 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:41:39 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:41:39 | INFO | train | epoch 006 | loss 11.409 | ppl 2719.16 | wps 5997.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.59 | train_wall 320 | gb_free 6.1 | wall 2090
KL Stats: Epoch 6 Divergences: Uniform: 1.1322518684469325 Unigram: 0.43630940592452994
2022-02-02 06:41:39 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:41:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:43:00 | INFO | train_inner | epoch 007:     16 / 64 loss=11.432, ppl=2763.14, wps=5868.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.601, train_wall=500, gb_free=6.1, wall=2171
2022-02-02 06:47:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:47:27 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.19 | ppl 2336.33 | wps 8067.4 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:47:27 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:47:27 | INFO | train | epoch 007 | loss 11.219 | ppl 2384.28 | wps 5996.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.555 | train_wall 320 | gb_free 6.1 | wall 2438
KL Stats: Epoch 7 Divergences: Uniform: 1.3401658770459206 Unigram: 0.4646066417442234
2022-02-02 06:47:27 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:51:49 | INFO | train_inner | epoch 008:     52 / 64 loss=11.154, ppl=2278.63, wps=6166.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.502, train_wall=502, gb_free=6.1, wall=2701
2022-02-02 06:52:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:53:16 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.075 | ppl 2156.91 | wps 8067.1 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:53:16 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:53:16 | INFO | train | epoch 008 | loss 11.098 | ppl 2191.28 | wps 5991.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.468 | train_wall 321 | gb_free 6.1 | wall 2787
KL Stats: Epoch 8 Divergences: Uniform: 1.4433857009932565 Unigram: 0.5540367504569408
2022-02-02 06:53:16 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:59:03 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.968 | ppl 2002.74 | wps 8082 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 06:59:03 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 06:59:03 | INFO | train | epoch 009 | loss 10.99 | ppl 2033.44 | wps 6008.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.49 | train_wall 320 | gb_free 6.1 | wall 3135
KL Stats: Epoch 9 Divergences: Uniform: 1.489850095786151 Unigram: 0.6668601679209334
2022-02-02 06:59:03 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 06:59:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:01:05 | INFO | train_inner | epoch 010:     24 / 64 loss=10.978, ppl=2016.62, wps=5873.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.497, train_wall=500, gb_free=6.1, wall=3256
2022-02-02 07:04:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:04:52 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.854 | ppl 1851.21 | wps 8055 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:04:52 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:04:52 | INFO | train | epoch 010 | loss 10.873 | ppl 1875.71 | wps 5986 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.515 | train_wall 321 | gb_free 6.1 | wall 3484
KL Stats: Epoch 10 Divergences: Uniform: 1.5086112479554035 Unigram: 0.7959024950603988
2022-02-02 07:04:52 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:09:54 | INFO | train_inner | epoch 011:     60 / 64 loss=10.795, ppl=1777.28, wps=6167.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.493, train_wall=501, gb_free=6.1, wall=3786
2022-02-02 07:10:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:10:40 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.741 | ppl 1710.93 | wps 8039.7 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:10:40 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:10:40 | INFO | train | epoch 011 | loss 10.754 | ppl 1726.46 | wps 5998.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.487 | train_wall 320 | gb_free 6.1 | wall 3832
KL Stats: Epoch 11 Divergences: Uniform: 1.5233365782514658 Unigram: 0.924527356902917
2022-02-02 07:10:40 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:10:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:16:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:16:30 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.635 | ppl 1590.33 | wps 8080.1 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:16:30 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:16:30 | INFO | train | epoch 012 | loss 10.631 | ppl 1586.07 | wps 5982.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.471 | train_wall 321 | gb_free 6.1 | wall 4181
KL Stats: Epoch 12 Divergences: Uniform: 1.5432113389465156 Unigram: 1.0474763204931843
2022-02-02 07:16:30 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:16:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:19:10 | INFO | train_inner | epoch 013:     32 / 64 loss=10.599, ppl=1550.86, wps=5862.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.475, train_wall=500, gb_free=6.1, wall=4342
2022-02-02 07:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:22:17 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.525 | ppl 1473.64 | wps 8039.1 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:22:17 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:22:17 | INFO | train | epoch 013 | loss 10.515 | ppl 1463.26 | wps 6007.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.503 | train_wall 320 | gb_free 6.1 | wall 4529
KL Stats: Epoch 13 Divergences: Uniform: 1.5611915543404251 Unigram: 1.1577483409254274
2022-02-02 07:22:17 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:22:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:27:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:28:06 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.434 | ppl 1383.04 | wps 8078.4 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:28:06 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:28:06 | INFO | train | epoch 014 | loss 10.401 | ppl 1351.94 | wps 5985.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.504 | train_wall 321 | gb_free 6.1 | wall 4877
KL Stats: Epoch 14 Divergences: Uniform: 1.5876081866578848 Unigram: 1.252906567511747
2022-02-02 07:28:06 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:28:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:28:26 | INFO | train_inner | epoch 015:      4 / 64 loss=10.431, ppl=1380.53, wps=5864.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.513, train_wall=500, gb_free=6.1, wall=4898
2022-02-02 07:33:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:33:54 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.347 | ppl 1302.39 | wps 8071.3 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:33:54 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:33:54 | INFO | train | epoch 015 | loss 10.288 | ppl 1250.12 | wps 6003.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.53 | train_wall 320 | gb_free 6.1 | wall 5225
KL Stats: Epoch 15 Divergences: Uniform: 1.6115145974830156 Unigram: 1.3487161807996983
2022-02-02 07:33:54 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:33:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:37:16 | INFO | train_inner | epoch 016:     40 / 64 loss=10.25, ppl=1217.54, wps=6171, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.533, train_wall=501, gb_free=6.1, wall=5427
2022-02-02 07:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:39:43 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.274 | ppl 1237.92 | wps 8058.8 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:39:43 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:39:43 | INFO | train | epoch 016 | loss 10.179 | ppl 1158.88 | wps 5992.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.535 | train_wall 321 | gb_free 6.1 | wall 5574
KL Stats: Epoch 16 Divergences: Uniform: 1.6394231698272814 Unigram: 1.4300742511266715
2022-02-02 07:39:43 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:39:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:45:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:45:31 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.191 | ppl 1168.68 | wps 8071.5 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:45:31 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:45:31 | INFO | train | epoch 017 | loss 10.071 | ppl 1075.35 | wps 5990.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.521 | train_wall 321 | gb_free 6.1 | wall 5923
KL Stats: Epoch 17 Divergences: Uniform: 1.6717880988089286 Unigram: 1.5099513677824776
2022-02-02 07:45:31 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:45:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:46:32 | INFO | train_inner | epoch 018:     12 / 64 loss=10.079, ppl=1081.51, wps=5864.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.516, train_wall=500, gb_free=6.1, wall=5983
2022-02-02 07:50:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:51:20 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.099 | ppl 1096.42 | wps 8083.5 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 07:51:20 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 07:51:20 | INFO | train | epoch 018 | loss 9.966 | ppl 1000.21 | wps 5993.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.522 | train_wall 321 | gb_free 6.1 | wall 6271
KL Stats: Epoch 18 Divergences: Uniform: 1.7001348415904716 Unigram: 1.5873168980445642
2022-02-02 07:51:20 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 07:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:55:21 | INFO | train_inner | epoch 019:     48 / 64 loss=9.915, ppl=965.57, wps=6174.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.537, train_wall=501, gb_free=6.1, wall=6512
2022-02-02 07:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:57:07 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.042 | ppl 1054.36 | wps 8057.8 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 07:57:07 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 07:57:07 | INFO | train | epoch 019 | loss 9.866 | ppl 933.47 | wps 6007.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.554 | train_wall 320 | gb_free 6.1 | wall 6619
KL Stats: Epoch 19 Divergences: Uniform: 1.736227645378773 Unigram: 1.6592006097091763
2022-02-02 07:57:07 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 07:57:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:02:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:02:56 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.966 | ppl 999.96 | wps 8084.7 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 08:02:56 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 08:02:56 | INFO | train | epoch 020 | loss 9.768 | ppl 872.02 | wps 5988.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.528 | train_wall 321 | gb_free 6.1 | wall 6967
KL Stats: Epoch 20 Divergences: Uniform: 1.7524617222008365 Unigram: 1.729352924488303
2022-02-02 08:02:56 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 08:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:04:37 | INFO | train_inner | epoch 021:     20 / 64 loss=9.769, ppl=872.29, wps=5864.8, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.54, train_wall=500, gb_free=6.1, wall=7068
2022-02-02 08:08:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:08:44 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.924 | ppl 971.36 | wps 8040.8 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:08:44 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:08:44 | INFO | train | epoch 021 | loss 9.676 | ppl 817.76 | wps 6002.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.534 | train_wall 320 | gb_free 6.1 | wall 7315
KL Stats: Epoch 21 Divergences: Uniform: 1.7881511874692047 Unigram: 1.796497387511435
2022-02-02 08:08:44 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:08:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:13:27 | INFO | train_inner | epoch 022:     56 / 64 loss=9.625, ppl=789.56, wps=6169.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.555, train_wall=501, gb_free=6.1, wall=7598
2022-02-02 08:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:14:33 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.865 | ppl 932.84 | wps 8082.2 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:14:33 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:14:33 | INFO | train | epoch 022 | loss 9.586 | ppl 768.65 | wps 5992.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.569 | train_wall 321 | gb_free 6.1 | wall 7664
KL Stats: Epoch 22 Divergences: Uniform: 1.8161640056122477 Unigram: 1.8607282443836006
2022-02-02 08:14:33 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:19:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:20:21 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.802 | ppl 892.72 | wps 8075.4 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:20:21 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:20:21 | INFO | train | epoch 023 | loss 9.499 | ppl 723.57 | wps 5997.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.534 | train_wall 320 | gb_free 6.1 | wall 8012
KL Stats: Epoch 23 Divergences: Uniform: 1.831613566787625 Unigram: 1.9245904876135003
2022-02-02 08:20:21 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:20:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:22:42 | INFO | train_inner | epoch 024:     28 / 64 loss=9.484, ppl=715.99, wps=5868.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.547, train_wall=500, gb_free=6.1, wall=8153
2022-02-02 08:25:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:26:10 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.764 | ppl 869.4 | wps 8074.8 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:26:10 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:26:10 | INFO | train | epoch 024 | loss 9.418 | ppl 684.3 | wps 5988.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.574 | train_wall 321 | gb_free 6.1 | wall 8361
KL Stats: Epoch 24 Divergences: Uniform: 1.861200565769045 Unigram: 1.9772171159347216
2022-02-02 08:26:10 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:26:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:31:31 | INFO | train_inner | epoch 025:     64 / 64 loss=9.361, ppl=657.39, wps=6169.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.541, train_wall=500, gb_free=6.1, wall=8682
2022-02-02 08:31:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:31:58 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.74 | ppl 855.2 | wps 8096.5 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:31:58 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:31:58 | INFO | train | epoch 025 | loss 9.333 | ppl 645.01 | wps 6004.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.523 | train_wall 320 | gb_free 6.1 | wall 8709
KL Stats: Epoch 25 Divergences: Uniform: 1.8883291541657024 Unigram: 2.031519260927142
2022-02-02 08:31:58 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:31:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:37:47 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.689 | ppl 825.28 | wps 8044.3 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:37:47 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:37:47 | INFO | train | epoch 026 | loss 9.252 | ppl 609.83 | wps 5975.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.528 | train_wall 321 | gb_free 6.1 | wall 9058
KL Stats: Epoch 26 Divergences: Uniform: 1.9144877614945346 Unigram: 2.086753418749298
2022-02-02 08:37:47 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:37:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:40:48 | INFO | train_inner | epoch 027:     36 / 64 loss=9.222, ppl=597.27, wps=5859, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.529, train_wall=502, gb_free=6.1, wall=9240
2022-02-02 08:43:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:43:35 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.623 | ppl 788.78 | wps 8069.8 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:43:35 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:43:35 | INFO | train | epoch 027 | loss 9.172 | ppl 577.02 | wps 6002.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.524 | train_wall 320 | gb_free 6.1 | wall 9406
KL Stats: Epoch 27 Divergences: Uniform: 1.9319397517431591 Unigram: 2.1328346513400223
2022-02-02 08:43:35 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:49:24 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.601 | ppl 776.47 | wps 8069.6 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 08:49:24 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 08:49:24 | INFO | train | epoch 028 | loss 9.094 | ppl 546.45 | wps 5986.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.522 | train_wall 321 | gb_free 6.1 | wall 9755
KL Stats: Epoch 28 Divergences: Uniform: 1.9570755910936908 Unigram: 2.1808375845577683
2022-02-02 08:49:24 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 08:49:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:50:04 | INFO | train_inner | epoch 029:      8 / 64 loss=9.111, ppl=553.01, wps=5863.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.526, train_wall=500, gb_free=6.1, wall=9796
2022-02-02 08:54:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:55:12 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.579 | ppl 765.05 | wps 8094.5 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 08:55:12 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 08:55:12 | INFO | train | epoch 029 | loss 9.018 | ppl 518.46 | wps 6006.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.54 | train_wall 320 | gb_free 6.1 | wall 10103
KL Stats: Epoch 29 Divergences: Uniform: 1.9768267988999897 Unigram: 2.223532757651155
2022-02-02 08:55:12 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 08:55:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:58:54 | INFO | train_inner | epoch 030:     44 / 64 loss=8.985, ppl=506.55, wps=6167.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.531, train_wall=501, gb_free=6.1, wall=10325
2022-02-02 09:00:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:01:01 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.513 | ppl 730.59 | wps 8068.6 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 09:01:01 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 09:01:01 | INFO | train | epoch 030 | loss 8.939 | ppl 490.79 | wps 5983.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.521 | train_wall 321 | gb_free 6.1 | wall 10452
KL Stats: Epoch 30 Divergences: Uniform: 1.9930478564591287 Unigram: 2.2680695145806364
2022-02-02 09:01:01 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 09:01:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:06:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:06:49 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.491 | ppl 719.47 | wps 8059.1 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 09:06:49 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 09:06:49 | INFO | train | epoch 031 | loss 8.865 | ppl 466.35 | wps 6004.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.529 | train_wall 320 | gb_free 6.1 | wall 10800
KL Stats: Epoch 31 Divergences: Uniform: 2.018492416546073 Unigram: 2.311413203987396
2022-02-02 09:06:49 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 09:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:08:09 | INFO | train_inner | epoch 032:     16 / 64 loss=8.864, ppl=466, wps=5871.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.523, train_wall=500, gb_free=6.1, wall=10881
2022-02-02 09:12:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:12:38 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.461 | ppl 704.73 | wps 8055.1 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:12:38 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:12:38 | INFO | train | epoch 032 | loss 8.79 | ppl 442.69 | wps 5978.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.53 | train_wall 321 | gb_free 6.1 | wall 11149
KL Stats: Epoch 32 Divergences: Uniform: 2.040346245420704 Unigram: 2.352815789219754
2022-02-02 09:12:38 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:17:00 | INFO | train_inner | epoch 033:     52 / 64 loss=8.753, ppl=431.42, wps=6158.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.525, train_wall=502, gb_free=6.1, wall=11411
2022-02-02 09:17:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:18:26 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.447 | ppl 697.82 | wps 8066.9 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:18:26 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:18:26 | INFO | train | epoch 033 | loss 8.714 | ppl 419.83 | wps 5998.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.517 | train_wall 320 | gb_free 6.1 | wall 11497
KL Stats: Epoch 33 Divergences: Uniform: 2.0624580388591918 Unigram: 2.396850367307769
2022-02-02 09:18:26 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:18:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:23:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:24:15 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.411 | ppl 680.64 | wps 8096.1 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:24:15 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:24:15 | INFO | train | epoch 034 | loss 8.643 | ppl 399.77 | wps 5994.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.527 | train_wall 321 | gb_free 6.1 | wall 11846
KL Stats: Epoch 34 Divergences: Uniform: 2.081474244726852 Unigram: 2.4377324049916207
2022-02-02 09:24:15 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:26:16 | INFO | train_inner | epoch 035:     24 / 64 loss=8.631, ppl=396.51, wps=5867.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.522, train_wall=500, gb_free=6.1, wall=11967
2022-02-02 09:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:30:03 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.382 | ppl 667.08 | wps 8085.7 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:30:03 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:30:03 | INFO | train | epoch 035 | loss 8.569 | ppl 379.85 | wps 6002.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.51 | train_wall 320 | gb_free 6.1 | wall 12194
KL Stats: Epoch 35 Divergences: Uniform: 2.102212789690447 Unigram: 2.476778015791973
2022-02-02 09:30:03 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:35:05 | INFO | train_inner | epoch 036:     60 / 64 loss=8.53, ppl=369.74, wps=6168.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.514, train_wall=502, gb_free=6.1, wall=12497
2022-02-02 09:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:35:51 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.376 | ppl 664.37 | wps 8087 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:35:51 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:35:51 | INFO | train | epoch 036 | loss 8.499 | ppl 361.75 | wps 5989.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.515 | train_wall 321 | gb_free 6.1 | wall 12543
KL Stats: Epoch 36 Divergences: Uniform: 2.1252139073925127 Unigram: 2.5199811331600386
2022-02-02 09:35:51 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:41:39 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.35 | ppl 652.37 | wps 8010.8 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:41:39 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:41:39 | INFO | train | epoch 037 | loss 8.431 | ppl 345.09 | wps 6000.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.513 | train_wall 320 | gb_free 6.1 | wall 12891
KL Stats: Epoch 37 Divergences: Uniform: 2.140597071057153 Unigram: 2.5601006771160453
2022-02-02 09:41:39 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:41:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:44:21 | INFO | train_inner | epoch 038:     32 / 64 loss=8.407, ppl=339.45, wps=5867.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.512, train_wall=500, gb_free=6.1, wall=13052
2022-02-02 09:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:47:28 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.339 | ppl 647.76 | wps 8061.4 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 09:47:28 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 09:47:28 | INFO | train | epoch 038 | loss 8.362 | ppl 328.94 | wps 5991.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.513 | train_wall 321 | gb_free 6.1 | wall 13239
KL Stats: Epoch 38 Divergences: Uniform: 2.1632191949667425 Unigram: 2.6017369128733914
2022-02-02 09:47:28 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 09:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:52:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:53:16 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.326 | ppl 641.65 | wps 8077.9 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 09:53:16 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 09:53:16 | INFO | train | epoch 039 | loss 8.294 | ppl 313.76 | wps 5994 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.509 | train_wall 320 | gb_free 6.1 | wall 13588
KL Stats: Epoch 39 Divergences: Uniform: 2.1839237183504405 Unigram: 2.636028460486963
2022-02-02 09:53:16 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 09:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:53:37 | INFO | train_inner | epoch 040:      4 / 64 loss=8.314, ppl=318.34, wps=5865.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.511, train_wall=500, gb_free=6.1, wall=13608
2022-02-02 09:58:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:59:05 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.319 | ppl 638.88 | wps 8080.3 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 09:59:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 09:59:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint40.pt
2022-02-02 09:59:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint40.pt
2022-02-02 09:59:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.319) (writing took 4.945087596774101 seconds)
2022-02-02 09:59:10 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 09:59:10 | INFO | train | epoch 040 | loss 8.226 | ppl 299.51 | wps 5903.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.504 | train_wall 321 | gb_free 6.1 | wall 13941
KL Stats: Epoch 40 Divergences: Uniform: 2.210585611637994 Unigram: 2.6804367916032676
2022-02-02 09:59:10 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 09:59:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:02:32 | INFO | train_inner | epoch 041:     40 / 64 loss=8.2, ppl=294.06, wps=6107.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.503, train_wall=502, gb_free=6.1, wall=14143
2022-02-02 10:04:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:04:58 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.296 | ppl 628.4 | wps 8068.9 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.296
2022-02-02 10:04:58 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 10:04:58 | INFO | train | epoch 041 | loss 8.163 | ppl 286.68 | wps 5999.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.513 | train_wall 320 | gb_free 6.1 | wall 14290
KL Stats: Epoch 41 Divergences: Uniform: 2.2246425376169108 Unigram: 2.711394650429236
2022-02-02 10:04:58 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 10:04:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:10:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:10:47 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.308 | ppl 633.89 | wps 8093.4 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.308
2022-02-02 10:10:47 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 10:10:47 | INFO | train | epoch 042 | loss 8.097 | ppl 273.87 | wps 5995.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.501 | train_wall 321 | gb_free 6.1 | wall 14638
KL Stats: Epoch 42 Divergences: Uniform: 2.242858874866606 Unigram: 2.7492915378694156
2022-02-02 10:10:47 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 10:10:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:11:47 | INFO | train_inner | epoch 043:     12 / 64 loss=8.108, ppl=275.87, wps=5868.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.51, train_wall=500, gb_free=6.1, wall=14698
2022-02-02 10:16:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:16:35 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.28 | ppl 621.72 | wps 8109.6 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.28
2022-02-02 10:16:35 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:16:35 | INFO | train | epoch 043 | loss 8.036 | ppl 262.5 | wps 6000.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.51 | train_wall 320 | gb_free 6.1 | wall 14986
KL Stats: Epoch 43 Divergences: Uniform: 2.2629011583180096 Unigram: 2.7851832959581047
2022-02-02 10:16:35 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:20:37 | INFO | train_inner | epoch 044:     48 / 64 loss=7.999, ppl=255.9, wps=6166.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.504, train_wall=502, gb_free=6.1, wall=15228
2022-02-02 10:21:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:22:23 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.296 | ppl 628.51 | wps 8091.6 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.296
2022-02-02 10:22:23 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:22:23 | INFO | train | epoch 044 | loss 7.973 | ppl 251.22 | wps 5990.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.51 | train_wall 321 | gb_free 6.1 | wall 15335
KL Stats: Epoch 44 Divergences: Uniform: 2.27473311534311 Unigram: 2.821812116247889
2022-02-02 10:22:23 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:22:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:27:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:28:12 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.327 | ppl 642.09 | wps 8072.6 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.319
2022-02-02 10:28:12 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:28:12 | INFO | train | epoch 045 | loss 7.914 | ppl 241.18 | wps 5995.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.514 | train_wall 320 | gb_free 6.1 | wall 15683
KL Stats: Epoch 45 Divergences: Uniform: 2.2908783882816683 Unigram: 2.8561435922537175
2022-02-02 10:28:12 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:29:53 | INFO | train_inner | epoch 046:     20 / 64 loss=7.912, ppl=240.91, wps=5867.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.516, train_wall=500, gb_free=6.1, wall=15784
2022-02-02 10:33:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:34:00 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.316 | ppl 637.19 | wps 8097 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.316
2022-02-02 10:34:00 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:34:00 | INFO | train | epoch 046 | loss 7.854 | ppl 231.34 | wps 5991.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.519 | train_wall 321 | gb_free 6.1 | wall 16032
KL Stats: Epoch 46 Divergences: Uniform: 2.3078997969045356 Unigram: 2.886937697622652
2022-02-02 10:34:00 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:34:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:38:42 | INFO | train_inner | epoch 047:     56 / 64 loss=7.823, ppl=226.39, wps=6171, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.516, train_wall=501, gb_free=6.1, wall=16314
2022-02-02 10:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:39:48 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.326 | ppl 641.97 | wps 8072.4 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.319
2022-02-02 10:39:48 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:39:48 | INFO | train | epoch 047 | loss 7.795 | ppl 222.14 | wps 6001.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.511 | train_wall 320 | gb_free 6.1 | wall 16380
KL Stats: Epoch 47 Divergences: Uniform: 2.329695825094231 Unigram: 2.9214779538045814
2022-02-02 10:39:48 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:45:37 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.276 | ppl 619.87 | wps 8129.9 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.276
2022-02-02 10:45:37 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 10:45:37 | INFO | train | epoch 048 | loss 7.739 | ppl 213.65 | wps 5993.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.515 | train_wall 321 | gb_free 6.1 | wall 16728
KL Stats: Epoch 48 Divergences: Uniform: 2.340703410039835 Unigram: 2.951959172831712
2022-02-02 10:45:37 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 10:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:47:57 | INFO | train_inner | epoch 049:     28 / 64 loss=7.725, ppl=211.63, wps=5876.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.518, train_wall=499, gb_free=6.1, wall=16868
2022-02-02 10:50:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:51:23 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.295 | ppl 628.19 | wps 8140.4 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.295
2022-02-02 10:51:23 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 10:51:23 | INFO | train | epoch 049 | loss 7.682 | ppl 205.41 | wps 6038.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.522 | train_wall 318 | gb_free 6.1 | wall 17074
KL Stats: Epoch 49 Divergences: Uniform: 2.3541598255455467 Unigram: 2.9817111838197263
2022-02-02 10:51:23 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 10:51:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:56:42 | INFO | train_inner | epoch 050:     64 / 64 loss=7.653, ppl=201.31, wps=6209.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.526, train_wall=497, gb_free=6.1, wall=17393
2022-02-02 10:56:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:57:09 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.318 | ppl 638.21 | wps 8131.2 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.318
2022-02-02 10:57:09 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 10:57:09 | INFO | train | epoch 050 | loss 7.629 | ppl 197.97 | wps 6033.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.528 | train_wall 318 | gb_free 6.1 | wall 17420
KL Stats: Epoch 50 Divergences: Uniform: 2.372061206031999 Unigram: 3.0115687364585866
2022-02-02 10:57:09 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 10:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:02:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:02:55 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.347 | ppl 651.02 | wps 8142.7 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.319
2022-02-02 11:02:55 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 11:02:55 | INFO | train | epoch 051 | loss 7.574 | ppl 190.52 | wps 6034.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.522 | train_wall 318 | gb_free 6.1 | wall 17766
KL Stats: Epoch 51 Divergences: Uniform: 2.386253866999085 Unigram: 3.0404571303779475
2022-02-02 11:02:55 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 11:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:05:56 | INFO | train_inner | epoch 052:     36 / 64 loss=7.544, ppl=186.68, wps=5901.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.52, train_wall=499, gb_free=6.1, wall=17947
2022-02-02 11:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:08:42 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.425 | ppl 687.47 | wps 8118.7 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.319
2022-02-02 11:08:42 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 11:08:42 | INFO | train | epoch 052 | loss 7.519 | ppl 183.47 | wps 6024.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.522 | train_wall 319 | gb_free 6.1 | wall 18113
KL Stats: Epoch 52 Divergences: Uniform: 2.391604919090728 Unigram: 3.06876492299242
2022-02-02 11:08:42 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 11:08:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:14:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:14:28 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.434 | ppl 691.53 | wps 8110.5 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.319
2022-02-02 11:14:28 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 11:14:28 | INFO | train | epoch 053 | loss 7.469 | ppl 177.2 | wps 6038.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.529 | train_wall 318 | gb_free 6.1 | wall 18459
KL Stats: Epoch 53 Divergences: Uniform: 2.407661137028477 Unigram: 3.1036020332688605
2022-02-02 11:14:28 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 11:14:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:15:08 | INFO | train_inner | epoch 054:      8 / 64 loss=7.488, ppl=179.48, wps=5904.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.529, train_wall=497, gb_free=6.1, wall=18499
2022-02-02 11:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:20:14 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.467 | ppl 707.84 | wps 8118.2 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.319
2022-02-02 11:20:14 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:20:14 | INFO | train | epoch 054 | loss 7.418 | ppl 171.05 | wps 6023.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.526 | train_wall 319 | gb_free 6.1 | wall 18806
KL Stats: Epoch 54 Divergences: Uniform: 2.419325798286949 Unigram: 3.1405919769632513
2022-02-02 11:20:14 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:20:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:23:55 | INFO | train_inner | epoch 055:     44 / 64 loss=7.389, ppl=167.67, wps=6204.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.527, train_wall=499, gb_free=6.1, wall=19026
2022-02-02 11:25:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:26:00 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.401 | ppl 676.13 | wps 8154.6 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.319
2022-02-02 11:26:00 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:26:00 | INFO | train | epoch 055 | loss 7.367 | ppl 165.12 | wps 6038 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.538 | train_wall 318 | gb_free 6.1 | wall 19152
KL Stats: Epoch 55 Divergences: Uniform: 2.4537439610870266 Unigram: 3.1674105098815795
2022-02-02 11:26:00 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:26:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:31:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:31:47 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.519 | ppl 733.68 | wps 8122.8 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.319
2022-02-02 11:31:47 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:31:47 | INFO | train | epoch 056 | loss 7.321 | ppl 159.87 | wps 6025.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.542 | train_wall 319 | gb_free 6.1 | wall 19498
KL Stats: Epoch 56 Divergences: Uniform: 2.4487009193439033 Unigram: 3.1894286409040267
2022-02-02 11:31:47 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:31:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:33:07 | INFO | train_inner | epoch 057:     16 / 64 loss=7.323, ppl=160.13, wps=5902.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.543, train_wall=497, gb_free=6.1, wall=19578
2022-02-02 11:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:37:33 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.431 | ppl 690.14 | wps 8136.8 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.319
2022-02-02 11:37:33 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:37:33 | INFO | train | epoch 057 | loss 7.273 | ppl 154.64 | wps 6038.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.541 | train_wall 318 | gb_free 6.1 | wall 19844
KL Stats: Epoch 57 Divergences: Uniform: 2.4660711095854806 Unigram: 3.2203924853802786
2022-02-02 11:37:33 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:37:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:41:54 | INFO | train_inner | epoch 058:     52 / 64 loss=7.248, ppl=151.96, wps=6204.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.545, train_wall=499, gb_free=6.1, wall=20105
2022-02-02 11:42:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:43:19 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.436 | ppl 692.65 | wps 8130 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.319
2022-02-02 11:43:19 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 11:43:19 | INFO | train | epoch 058 | loss 7.228 | ppl 149.9 | wps 6025 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.553 | train_wall 319 | gb_free 6.1 | wall 20191
KL Stats: Epoch 58 Divergences: Uniform: 2.4811736309840526 Unigram: 3.243876530443675
2022-02-02 11:43:19 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 11:43:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:49:05 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.53 | ppl 739.24 | wps 8116.3 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.319
2022-02-02 11:49:05 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 11:49:05 | INFO | train | epoch 059 | loss 7.181 | ppl 145.15 | wps 6038.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.545 | train_wall 318 | gb_free 6.1 | wall 20537
KL Stats: Epoch 59 Divergences: Uniform: 2.4896715719118894 Unigram: 3.2694383310943618
2022-02-02 11:49:05 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 11:49:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:51:06 | INFO | train_inner | epoch 060:     24 / 64 loss=7.176, ppl=144.63, wps=5903.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.552, train_wall=497, gb_free=6.1, wall=20657
2022-02-02 11:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:54:53 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.571 | ppl 760.49 | wps 8121.8 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.319
2022-02-02 11:54:53 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 11:54:53 | INFO | train | epoch 060 | loss 7.136 | ppl 140.69 | wps 6015.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.546 | train_wall 319 | gb_free 6.1 | wall 20884
KL Stats: Epoch 60 Divergences: Uniform: 2.5013500550985865 Unigram: 3.3026199373625356
2022-02-02 11:54:53 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 11:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:59:53 | INFO | train_inner | epoch 061:     60 / 64 loss=7.118, ppl=138.96, wps=6203.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.547, train_wall=499, gb_free=6.1, wall=21184
2022-02-02 12:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:00:38 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.513 | ppl 730.68 | wps 8138.7 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.319
2022-02-02 12:00:38 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 12:00:38 | INFO | train | epoch 061 | loss 7.094 | ppl 136.61 | wps 6041.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.555 | train_wall 318 | gb_free 6.1 | wall 21230
KL Stats: Epoch 61 Divergences: Uniform: 2.524737303171272 Unigram: 3.3360698964931252
2022-02-02 12:00:38 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 12:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:05:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:06:25 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.569 | ppl 759.58 | wps 8148.5 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.319
2022-02-02 12:06:25 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 12:06:25 | INFO | train | epoch 062 | loss 7.052 | ppl 132.73 | wps 6029.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.555 | train_wall 319 | gb_free 6.1 | wall 21576
KL Stats: Epoch 62 Divergences: Uniform: 2.537928280489634 Unigram: 3.3565847155151505
2022-02-02 12:06:25 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 12:06:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:09:05 | INFO | train_inner | epoch 063:     32 / 64 loss=7.028, ppl=130.49, wps=5906.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.554, train_wall=497, gb_free=6.1, wall=21736
2022-02-02 12:11:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:12:10 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.599 | ppl 775.4 | wps 8134.9 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.319
2022-02-02 12:12:10 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 12:12:10 | INFO | train | epoch 063 | loss 7.009 | ppl 128.79 | wps 6043.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.556 | train_wall 318 | gb_free 6.1 | wall 21922
KL Stats: Epoch 63 Divergences: Uniform: 2.5430315483743438 Unigram: 3.385424434265665
2022-02-02 12:12:10 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 12:12:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:17:57 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.609 | ppl 780.83 | wps 8143.6 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.319
2022-02-02 12:17:57 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 12:17:57 | INFO | train | epoch 064 | loss 6.966 | ppl 125.05 | wps 6027.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.566 | train_wall 319 | gb_free 6.1 | wall 22268
KL Stats: Epoch 64 Divergences: Uniform: 2.5551599868921717 Unigram: 3.4070354678394845
2022-02-02 12:17:57 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 12:17:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:18:17 | INFO | train_inner | epoch 065:      4 / 64 loss=6.988, ppl=126.95, wps=5903, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.566, train_wall=497, gb_free=6.1, wall=22288
2022-02-02 12:23:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:23:42 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.633 | ppl 794.27 | wps 8127.5 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.319
2022-02-02 12:23:42 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:23:42 | INFO | train | epoch 065 | loss 6.923 | ppl 121.37 | wps 6042.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.558 | train_wall 318 | gb_free 6.1 | wall 22614
KL Stats: Epoch 65 Divergences: Uniform: 2.5730606925471644 Unigram: 3.436636804423224
2022-02-02 12:23:42 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:27:03 | INFO | train_inner | epoch 066:     40 / 64 loss=6.9, ppl=119.41, wps=6211.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.558, train_wall=498, gb_free=6.1, wall=22814
2022-02-02 12:29:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:29:29 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.624 | ppl 789.04 | wps 8136.4 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.319
2022-02-02 12:29:29 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:29:29 | INFO | train | epoch 066 | loss 6.883 | ppl 118.01 | wps 6032.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.561 | train_wall 319 | gb_free 6.1 | wall 22960
KL Stats: Epoch 66 Divergences: Uniform: 2.58302287519957 Unigram: 3.4666112566650362
2022-02-02 12:29:29 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:34:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:35:15 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.693 | ppl 827.54 | wps 8102.1 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.319
2022-02-02 12:35:15 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:35:15 | INFO | train | epoch 067 | loss 6.841 | ppl 114.66 | wps 6029.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.56 | train_wall 319 | gb_free 6.1 | wall 23306
KL Stats: Epoch 67 Divergences: Uniform: 2.5806935827201913 Unigram: 3.4935432441277974
2022-02-02 12:35:15 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:36:15 | INFO | train_inner | epoch 068:     12 / 64 loss=6.852, ppl=115.52, wps=5902.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.563, train_wall=497, gb_free=6.1, wall=23367
2022-02-02 12:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:41:02 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.605 | ppl 778.66 | wps 8087.1 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.319
2022-02-02 12:41:02 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 12:41:02 | INFO | train | epoch 068 | loss 6.802 | ppl 111.62 | wps 6015.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.573 | train_wall 319 | gb_free 6.1 | wall 23654
KL Stats: Epoch 68 Divergences: Uniform: 2.6139199501982384 Unigram: 3.522116418314467
2022-02-02 12:41:02 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 12:41:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:45:03 | INFO | train_inner | epoch 069:     48 / 64 loss=6.782, ppl=110.08, wps=6191.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.583, train_wall=500, gb_free=6.1, wall=23894
2022-02-02 12:46:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:46:49 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.695 | ppl 829.05 | wps 8114.1 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.319
2022-02-02 12:46:49 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 12:46:49 | INFO | train | epoch 069 | loss 6.765 | ppl 108.78 | wps 6024.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.59 | train_wall 319 | gb_free 6.1 | wall 24000
KL Stats: Epoch 69 Divergences: Uniform: 2.607344170649529 Unigram: 3.546151277598835
2022-02-02 12:46:49 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 12:46:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:52:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:52:36 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.764 | ppl 869.36 | wps 8101.6 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.319
2022-02-02 12:52:37 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 12:52:37 | INFO | train | epoch 070 | loss 6.728 | ppl 106.03 | wps 6010.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.574 | train_wall 320 | gb_free 6.1 | wall 24348
KL Stats: Epoch 70 Divergences: Uniform: 2.625297804065032 Unigram: 3.569649369781196
2022-02-02 12:52:37 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 12:52:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:54:17 | INFO | train_inner | epoch 071:     20 / 64 loss=6.725, ppl=105.81, wps=5887, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.581, train_wall=498, gb_free=6.1, wall=24448
2022-02-02 12:57:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:58:23 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.8 | ppl 891.37 | wps 8096.3 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.319
2022-02-02 12:58:23 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 12:58:23 | INFO | train | epoch 071 | loss 6.692 | ppl 103.42 | wps 6023.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.582 | train_wall 319 | gb_free 6.1 | wall 24695
KL Stats: Epoch 71 Divergences: Uniform: 2.6262016666766224 Unigram: 3.5962528253310637
2022-02-02 12:58:23 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 12:58:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:03:05 | INFO | train_inner | epoch 072:     56 / 64 loss=6.68, ppl=102.51, wps=6192.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.572, train_wall=499, gb_free=6.1, wall=24976
2022-02-02 13:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:04:10 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.824 | ppl 906.5 | wps 8109.1 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.319
2022-02-02 13:04:10 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 13:04:10 | INFO | train | epoch 072 | loss 6.658 | ppl 100.99 | wps 6016.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.573 | train_wall 319 | gb_free 6.1 | wall 25042
KL Stats: Epoch 72 Divergences: Uniform: 2.6394357761699676 Unigram: 3.6166169625412237
2022-02-02 13:04:10 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 13:04:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:09:57 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.77 | ppl 873.27 | wps 8128 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.319
2022-02-02 13:09:57 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 13:09:57 | INFO | train | epoch 073 | loss 6.624 | ppl 98.67 | wps 6029.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.594 | train_wall 319 | gb_free 6.1 | wall 25388
KL Stats: Epoch 73 Divergences: Uniform: 2.6559467640549568 Unigram: 3.6549925774507823
2022-02-02 13:09:57 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 13:09:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:12:17 | INFO | train_inner | epoch 074:     28 / 64 loss=6.606, ppl=97.4, wps=5898.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.589, train_wall=497, gb_free=6.1, wall=25529
2022-02-02 13:15:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:15:44 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.831 | ppl 910.9 | wps 8108.9 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.319
2022-02-02 13:15:44 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 13:15:44 | INFO | train | epoch 074 | loss 6.592 | ppl 96.48 | wps 6011.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.59 | train_wall 320 | gb_free 6.1 | wall 25736
KL Stats: Epoch 74 Divergences: Uniform: 2.6562193744827045 Unigram: 3.666898378413675
2022-02-02 13:15:44 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 13:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:21:04 | INFO | train_inner | epoch 075:     64 / 64 loss=6.586, ppl=96.05, wps=6193.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.592, train_wall=498, gb_free=6.1, wall=26055
2022-02-02 13:21:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:21:31 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.79 | ppl 885.15 | wps 8107.2 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.319
2022-02-02 13:21:31 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 13:21:31 | INFO | train | epoch 075 | loss 6.56 | ppl 94.34 | wps 6029.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.585 | train_wall 319 | gb_free 6.1 | wall 26082
KL Stats: Epoch 75 Divergences: Uniform: 2.6673938577248157 Unigram: 3.7011169032737303
2022-02-02 13:21:31 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 13:21:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:26:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:27:18 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.747 | ppl 859.31 | wps 8116.9 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.319
2022-02-02 13:27:18 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:27:18 | INFO | train | epoch 076 | loss 6.53 | ppl 92.43 | wps 6012.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.599 | train_wall 320 | gb_free 6.1 | wall 26429
KL Stats: Epoch 76 Divergences: Uniform: 2.688622625996894 Unigram: 3.716771787185432
2022-02-02 13:27:18 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:27:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:30:19 | INFO | train_inner | epoch 077:     36 / 64 loss=6.508, ppl=90.99, wps=5889.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.606, train_wall=500, gb_free=6.1, wall=26610
2022-02-02 13:32:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:33:05 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.867 | ppl 933.68 | wps 8103 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.319
2022-02-02 13:33:05 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:33:05 | INFO | train | epoch 077 | loss 6.501 | ppl 90.56 | wps 6026.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.61 | train_wall 319 | gb_free 6.1 | wall 26776
KL Stats: Epoch 77 Divergences: Uniform: 2.681893007733057 Unigram: 3.737095291435692
2022-02-02 13:33:05 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:38:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:38:52 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.869 | ppl 935.29 | wps 8068.9 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.319
2022-02-02 13:38:52 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 13:38:52 | INFO | train | epoch 078 | loss 6.473 | ppl 88.82 | wps 6012 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.611 | train_wall 319 | gb_free 6.1 | wall 27123
KL Stats: Epoch 78 Divergences: Uniform: 2.697925560219363 Unigram: 3.764763065512531
2022-02-02 13:38:52 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 13:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:39:32 | INFO | train_inner | epoch 079:      8 / 64 loss=6.484, ppl=89.51, wps=5887.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.608, train_wall=498, gb_free=6.1, wall=27163
2022-02-02 13:44:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:44:39 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.83 | ppl 909.98 | wps 8105.5 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.319
2022-02-02 13:44:39 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 13:44:39 | INFO | train | epoch 079 | loss 6.443 | ppl 87.01 | wps 6024.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.615 | train_wall 319 | gb_free 6.1 | wall 27470
KL Stats: Epoch 79 Divergences: Uniform: 2.702805380899537 Unigram: 3.7903317954346596
2022-02-02 13:44:39 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 13:44:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:48:20 | INFO | train_inner | epoch 080:     44 / 64 loss=6.429, ppl=86.16, wps=6195.9, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.614, train_wall=499, gb_free=6.1, wall=27691
2022-02-02 13:49:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:50:26 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.845 | ppl 919.79 | wps 8133.4 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.319
2022-02-02 13:50:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 13:50:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint80.pt
2022-02-02 13:50:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint80.pt
2022-02-02 13:50:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.845) (writing took 3.5963580403476954 seconds)
2022-02-02 13:50:30 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 13:50:30 | INFO | train | epoch 080 | loss 6.416 | ppl 85.39 | wps 5950.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.617 | train_wall 320 | gb_free 6.1 | wall 27821
KL Stats: Epoch 80 Divergences: Uniform: 2.6983273502354934 Unigram: 3.8044726225306498
2022-02-02 13:50:30 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 13:50:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:55:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:56:16 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.891 | ppl 949.36 | wps 8141.1 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.319
2022-02-02 13:56:16 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 13:56:16 | INFO | train | epoch 081 | loss 6.388 | ppl 83.77 | wps 6027.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.617 | train_wall 319 | gb_free 6.1 | wall 28167
KL Stats: Epoch 81 Divergences: Uniform: 2.716269486542019 Unigram: 3.832984966857138
2022-02-02 13:56:16 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 13:56:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:57:36 | INFO | train_inner | epoch 082:     16 / 64 loss=6.386, ppl=83.65, wps=5854.3, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.621, train_wall=498, gb_free=6.1, wall=28248
2022-02-02 14:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:02:04 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.867 | ppl 933.59 | wps 8111.9 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.319
2022-02-02 14:02:04 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 14:02:04 | INFO | train | epoch 082 | loss 6.363 | ppl 82.3 | wps 6013.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.621 | train_wall 320 | gb_free 6.1 | wall 28515
KL Stats: Epoch 82 Divergences: Uniform: 2.7302996586335273 Unigram: 3.8534681920840166
2022-02-02 14:02:04 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 14:02:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:06:24 | INFO | train_inner | epoch 083:     52 / 64 loss=6.357, ppl=81.96, wps=6192.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.631, train_wall=500, gb_free=6.1, wall=28776
2022-02-02 14:07:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:07:50 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.947 | ppl 986.93 | wps 8115.1 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.319
2022-02-02 14:07:50 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 14:07:50 | INFO | train | epoch 083 | loss 6.341 | ppl 81.05 | wps 6027 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.642 | train_wall 319 | gb_free 6.1 | wall 28861
KL Stats: Epoch 83 Divergences: Uniform: 2.7299982849566398 Unigram: 3.8660869689396207
2022-02-02 14:07:50 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 14:07:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:13:38 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.832 | ppl 911.36 | wps 8112.8 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.319
2022-02-02 14:13:38 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 14:13:38 | INFO | train | epoch 084 | loss 6.314 | ppl 79.55 | wps 6008.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.641 | train_wall 320 | gb_free 6.1 | wall 29209
KL Stats: Epoch 84 Divergences: Uniform: 2.7417917984938334 Unigram: 3.8938646003293083
2022-02-02 14:13:38 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 14:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:15:38 | INFO | train_inner | epoch 085:     24 / 64 loss=6.309, ppl=79.29, wps=5886.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.635, train_wall=499, gb_free=6.1, wall=29329
2022-02-02 14:18:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:19:25 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 10 | ppl 1023.79 | wps 8106.9 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.319
2022-02-02 14:19:25 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 14:19:25 | INFO | train | epoch 085 | loss 6.289 | ppl 78.18 | wps 6017.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.626 | train_wall 319 | gb_free 6.1 | wall 29556
KL Stats: Epoch 85 Divergences: Uniform: 2.736456097468661 Unigram: 3.9122794651212662
2022-02-02 14:19:25 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 14:19:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:24:26 | INFO | train_inner | epoch 086:     60 / 64 loss=6.282, ppl=77.83, wps=6188.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.644, train_wall=500, gb_free=6.1, wall=29857
2022-02-02 14:24:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:25:12 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 10.029 | ppl 1045.01 | wps 8084.7 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.319
2022-02-02 14:25:12 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 14:25:12 | INFO | train | epoch 086 | loss 6.266 | ppl 76.98 | wps 6012.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.651 | train_wall 319 | gb_free 6.1 | wall 29903
KL Stats: Epoch 86 Divergences: Uniform: 2.744921057159722 Unigram: 3.932407303804617
2022-02-02 14:25:12 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 14:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:30:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:30:59 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.974 | ppl 1005.78 | wps 8097.4 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.319
2022-02-02 14:30:59 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:30:59 | INFO | train | epoch 087 | loss 6.244 | ppl 75.81 | wps 6027.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.649 | train_wall 319 | gb_free 6.1 | wall 30250
KL Stats: Epoch 87 Divergences: Uniform: 2.7584156678932485 Unigram: 3.950272296197775
2022-02-02 14:30:59 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:33:39 | INFO | train_inner | epoch 088:     32 / 64 loss=6.226, ppl=74.83, wps=5894.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.65, train_wall=498, gb_free=6.1, wall=30410
2022-02-02 14:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:36:46 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.929 | ppl 974.82 | wps 8085 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.319
2022-02-02 14:36:46 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 14:36:46 | INFO | train | epoch 088 | loss 6.22 | ppl 74.56 | wps 6017.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.641 | train_wall 319 | gb_free 6.1 | wall 30597
KL Stats: Epoch 88 Divergences: Uniform: 2.768326192340267 Unigram: 3.972972903313025
2022-02-02 14:36:46 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 14:36:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:42:32 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.987 | ppl 1014.88 | wps 8118.1 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.319
2022-02-02 14:42:32 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 14:42:32 | INFO | train | epoch 089 | loss 6.203 | ppl 73.68 | wps 6029.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.691 | train_wall 319 | gb_free 6.1 | wall 30943
KL Stats: Epoch 89 Divergences: Uniform: 2.7661866570280966 Unigram: 3.9876580871162126
2022-02-02 14:42:32 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 14:42:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:42:52 | INFO | train_inner | epoch 090:      4 / 64 loss=6.22, ppl=74.54, wps=5894.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.673, train_wall=498, gb_free=6.1, wall=30964
2022-02-02 14:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:48:19 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 10.051 | ppl 1061.14 | wps 8095.8 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.319
2022-02-02 14:48:19 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 14:48:19 | INFO | train | epoch 090 | loss 6.177 | ppl 72.35 | wps 6018.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.652 | train_wall 319 | gb_free 6.1 | wall 31290
KL Stats: Epoch 90 Divergences: Uniform: 2.776102445308653 Unigram: 4.015969526169832
2022-02-02 14:48:19 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 14:48:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:51:40 | INFO | train_inner | epoch 091:     40 / 64 loss=6.161, ppl=71.55, wps=6196.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.659, train_wall=499, gb_free=6.1, wall=31491
2022-02-02 14:53:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:54:06 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.952 | ppl 990.55 | wps 8116.4 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.319
2022-02-02 14:54:06 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 14:54:06 | INFO | train | epoch 091 | loss 6.157 | ppl 71.37 | wps 6028.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.666 | train_wall 319 | gb_free 6.1 | wall 31637
KL Stats: Epoch 91 Divergences: Uniform: 2.787661145223388 Unigram: 4.034548955655764
2022-02-02 14:54:06 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 14:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:59:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:59:53 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.954 | ppl 991.79 | wps 8079.1 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.319
2022-02-02 14:59:53 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 14:59:53 | INFO | train | epoch 092 | loss 6.138 | ppl 70.42 | wps 6011.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.673 | train_wall 320 | gb_free 6.1 | wall 31984
KL Stats: Epoch 92 Divergences: Uniform: 2.7876440612041202 Unigram: 4.053438906663267
2022-02-02 14:59:53 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 14:59:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:00:53 | INFO | train_inner | epoch 093:     12 / 64 loss=6.141, ppl=70.57, wps=5888.2, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.664, train_wall=498, gb_free=6.1, wall=32045
2022-02-02 15:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:05:39 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.952 | ppl 990.63 | wps 8143.3 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.319
2022-02-02 15:05:39 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 15:05:39 | INFO | train | epoch 093 | loss 6.117 | ppl 69.41 | wps 6030.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.675 | train_wall 319 | gb_free 6.1 | wall 32331
KL Stats: Epoch 93 Divergences: Uniform: 2.7996632353337776 Unigram: 4.067518613944834
2022-02-02 15:05:39 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 15:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:09:40 | INFO | train_inner | epoch 094:     48 / 64 loss=6.108, ppl=68.97, wps=6199.8, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.684, train_wall=499, gb_free=6.1, wall=32572
2022-02-02 15:11:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:11:27 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 10.035 | ppl 1049.34 | wps 8121.1 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.319
2022-02-02 15:11:27 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 15:11:27 | INFO | train | epoch 094 | loss 6.1 | ppl 68.57 | wps 6016.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.695 | train_wall 319 | gb_free 6.1 | wall 32678
KL Stats: Epoch 94 Divergences: Uniform: 2.8012962251359284 Unigram: 4.085686084698213
2022-02-02 15:11:27 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 15:11:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:16:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:17:13 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 10.134 | ppl 1123.95 | wps 8108.4 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.319
2022-02-02 15:17:13 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 15:17:13 | INFO | train | epoch 095 | loss 6.081 | ppl 67.68 | wps 6023.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.692 | train_wall 319 | gb_free 6.1 | wall 33025
KL Stats: Epoch 95 Divergences: Uniform: 2.8016363936321396 Unigram: 4.1062229550577936
2022-02-02 15:17:13 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 15:17:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:18:54 | INFO | train_inner | epoch 096:     20 / 64 loss=6.08, ppl=67.63, wps=5892.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.695, train_wall=498, gb_free=6.1, wall=33125
2022-02-02 15:22:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:23:00 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 10.039 | ppl 1051.84 | wps 8136.2 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.319
2022-02-02 15:23:00 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 15:23:00 | INFO | train | epoch 096 | loss 6.06 | ppl 66.73 | wps 6015.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.691 | train_wall 320 | gb_free 6.1 | wall 33372
KL Stats: Epoch 96 Divergences: Uniform: 2.8096322856688043 Unigram: 4.118868814697808
2022-02-02 15:23:00 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 15:23:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:27:41 | INFO | train_inner | epoch 097:     56 / 64 loss=6.054, ppl=66.45, wps=6193.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.693, train_wall=500, gb_free=6.1, wall=33653
2022-02-02 15:28:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:28:47 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 10.032 | ppl 1047.05 | wps 8139.6 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.319
2022-02-02 15:28:47 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 15:28:47 | INFO | train | epoch 097 | loss 6.041 | ppl 65.83 | wps 6027.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.695 | train_wall 319 | gb_free 6.1 | wall 33718
KL Stats: Epoch 97 Divergences: Uniform: 2.816451391007601 Unigram: 4.136176332811541
2022-02-02 15:28:47 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 15:28:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:34:34 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.975 | ppl 1006.52 | wps 8145.1 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.319
2022-02-02 15:34:34 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 15:34:34 | INFO | train | epoch 098 | loss 6.024 | ppl 65.08 | wps 6018.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.696 | train_wall 319 | gb_free 6.1 | wall 34065
KL Stats: Epoch 98 Divergences: Uniform: 2.829433249517171 Unigram: 4.159331261185715
2022-02-02 15:34:34 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 15:34:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:36:54 | INFO | train_inner | epoch 099:     28 / 64 loss=6.013, ppl=64.56, wps=5895, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.696, train_wall=498, gb_free=6.1, wall=34206
2022-02-02 15:39:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:40:20 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.974 | ppl 1005.83 | wps 8082.1 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.319
2022-02-02 15:40:20 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 15:40:20 | INFO | train | epoch 099 | loss 6.007 | ppl 64.33 | wps 6029.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.699 | train_wall 319 | gb_free 6.1 | wall 34412
KL Stats: Epoch 99 Divergences: Uniform: 2.8304014174185803 Unigram: 4.1780897046109065
2022-02-02 15:40:20 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 15:40:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:45:41 | INFO | train_inner | epoch 100:     64 / 64 loss=6.009, ppl=64.41, wps=6193.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.711, train_wall=498, gb_free=6.1, wall=34732
2022-02-02 15:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:46:08 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 10.015 | ppl 1034.93 | wps 8128 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.319
2022-02-02 15:46:08 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 15:46:08 | INFO | train | epoch 100 | loss 5.991 | ppl 63.62 | wps 6016.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.717 | train_wall 319 | gb_free 6.1 | wall 34759
KL Stats: Epoch 100 Divergences: Uniform: 2.841715326745194 Unigram: 4.190577668504508
2022-02-02 15:46:08 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 15:46:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:51:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:51:54 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.994 | ppl 1019.48 | wps 8119.5 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.319
2022-02-02 15:51:54 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 15:51:54 | INFO | train | epoch 101 | loss 5.974 | ppl 62.84 | wps 6027.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.716 | train_wall 319 | gb_free 6.1 | wall 35105
KL Stats: Epoch 101 Divergences: Uniform: 2.8462690377944426 Unigram: 4.211199425825583
2022-02-02 15:51:54 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 15:51:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:54:55 | INFO | train_inner | epoch 102:     36 / 64 loss=5.957, ppl=62.1, wps=5898, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.714, train_wall=499, gb_free=6.1, wall=35286
2022-02-02 15:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:57:41 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.965 | ppl 999.69 | wps 8123.1 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.319
2022-02-02 15:57:41 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 15:57:41 | INFO | train | epoch 102 | loss 5.956 | ppl 62.08 | wps 6017.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.716 | train_wall 319 | gb_free 6.1 | wall 35452
KL Stats: Epoch 102 Divergences: Uniform: 2.849301752385911 Unigram: 4.226703849094897
2022-02-02 15:57:41 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 15:57:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:03:28 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 10.029 | ppl 1044.63 | wps 8117 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.319
2022-02-02 16:03:28 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 16:03:28 | INFO | train | epoch 103 | loss 5.943 | ppl 61.5 | wps 6026.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.735 | train_wall 319 | gb_free 6.1 | wall 35799
KL Stats: Epoch 103 Divergences: Uniform: 2.854133320658989 Unigram: 4.245222604068395
2022-02-02 16:03:28 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 16:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:04:08 | INFO | train_inner | epoch 104:      8 / 64 loss=5.951, ppl=61.88, wps=5893.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.733, train_wall=498, gb_free=6.1, wall=35839
2022-02-02 16:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:09:15 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 10.031 | ppl 1046 | wps 8097.1 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.319
2022-02-02 16:09:15 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 16:09:15 | INFO | train | epoch 104 | loss 5.924 | ppl 60.71 | wps 6012.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.726 | train_wall 320 | gb_free 6.1 | wall 36146
KL Stats: Epoch 104 Divergences: Uniform: 2.854280405133447 Unigram: 4.2580248343378395
2022-02-02 16:09:15 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 16:09:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:12:56 | INFO | train_inner | epoch 105:     44 / 64 loss=5.911, ppl=60.16, wps=6189.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.728, train_wall=500, gb_free=6.1, wall=36367
2022-02-02 16:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:15:02 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 10.206 | ppl 1181.43 | wps 8110.5 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.319
2022-02-02 16:15:02 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 16:15:02 | INFO | train | epoch 105 | loss 5.909 | ppl 60.1 | wps 6022.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.74 | train_wall 319 | gb_free 6.1 | wall 36493
KL Stats: Epoch 105 Divergences: Uniform: 2.852439865767559 Unigram: 4.273958156863372
2022-02-02 16:15:02 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 16:15:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:20:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:20:49 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 10.028 | ppl 1044.27 | wps 8120.5 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.319
2022-02-02 16:20:49 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 16:20:49 | INFO | train | epoch 106 | loss 5.893 | ppl 59.42 | wps 6011.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.736 | train_wall 320 | gb_free 6.1 | wall 36841
KL Stats: Epoch 106 Divergences: Uniform: 2.8690346503226003 Unigram: 4.2983646333561545
2022-02-02 16:20:49 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 16:20:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:22:10 | INFO | train_inner | epoch 107:     16 / 64 loss=5.896, ppl=59.56, wps=5886.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.739, train_wall=499, gb_free=6.1, wall=36921
2022-02-02 16:26:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:26:37 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 10.128 | ppl 1119.38 | wps 8108.9 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.319
2022-02-02 16:26:37 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 16:26:37 | INFO | train | epoch 107 | loss 5.878 | ppl 58.82 | wps 6013.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.746 | train_wall 320 | gb_free 6.1 | wall 37188
KL Stats: Epoch 107 Divergences: Uniform: 2.865924790124601 Unigram: 4.308643140424584
2022-02-02 16:26:37 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 16:26:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:30:58 | INFO | train_inner | epoch 108:     52 / 64 loss=5.875, ppl=58.7, wps=6184.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.755, train_wall=500, gb_free=6.1, wall=37449
2022-02-02 16:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:32:24 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 10.066 | ppl 1071.92 | wps 8098.8 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.319
2022-02-02 16:32:24 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 16:32:24 | INFO | train | epoch 108 | loss 5.864 | ppl 58.24 | wps 6012 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.762 | train_wall 320 | gb_free 6.1 | wall 37535
KL Stats: Epoch 108 Divergences: Uniform: 2.8708663384648783 Unigram: 4.32109211266861
2022-02-02 16:32:24 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 16:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:38:11 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.05 | ppl 1060.36 | wps 8117.2 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.319
2022-02-02 16:38:11 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 16:38:11 | INFO | train | epoch 109 | loss 5.85 | ppl 57.66 | wps 6026.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.773 | train_wall 319 | gb_free 6.1 | wall 37882
KL Stats: Epoch 109 Divergences: Uniform: 2.880201000030761 Unigram: 4.342722418040527
2022-02-02 16:38:11 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 16:38:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:40:11 | INFO | train_inner | epoch 110:     24 / 64 loss=5.843, ppl=57.39, wps=5894.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.769, train_wall=498, gb_free=6.1, wall=38002
2022-02-02 16:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:43:58 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.072 | ppl 1076.68 | wps 8113.6 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.319
2022-02-02 16:43:58 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 16:43:58 | INFO | train | epoch 110 | loss 5.837 | ppl 57.16 | wps 6010.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.758 | train_wall 320 | gb_free 6.1 | wall 38229
KL Stats: Epoch 110 Divergences: Uniform: 2.8796272955097413 Unigram: 4.351494890501697
2022-02-02 16:43:58 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 16:43:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:48:59 | INFO | train_inner | epoch 111:     60 / 64 loss=5.835, ppl=57.08, wps=6192.8, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.77, train_wall=500, gb_free=6.1, wall=38530
2022-02-02 16:49:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:49:45 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.109 | ppl 1104.23 | wps 8099.8 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.319
2022-02-02 16:49:45 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 16:49:45 | INFO | train | epoch 111 | loss 5.823 | ppl 56.6 | wps 6025.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.777 | train_wall 319 | gb_free 6.1 | wall 38576
KL Stats: Epoch 111 Divergences: Uniform: 2.8842749723687575 Unigram: 4.364750398618086
2022-02-02 16:49:45 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 16:49:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:55:32 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.185 | ppl 1164.34 | wps 8105.3 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.319
2022-02-02 16:55:32 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 16:55:32 | INFO | train | epoch 112 | loss 5.807 | ppl 56 | wps 6010.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.768 | train_wall 320 | gb_free 6.1 | wall 38924
KL Stats: Epoch 112 Divergences: Uniform: 2.88077216099698 Unigram: 4.379516085570937
2022-02-02 16:55:32 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 16:55:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:58:13 | INFO | train_inner | epoch 113:     32 / 64 loss=5.797, ppl=55.58, wps=5887.2, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.78, train_wall=498, gb_free=6.1, wall=39084
2022-02-02 17:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:01:19 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.121 | ppl 1113.38 | wps 8124.7 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.319
2022-02-02 17:01:19 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 17:01:19 | INFO | train | epoch 113 | loss 5.796 | ppl 55.55 | wps 6032.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.794 | train_wall 318 | gb_free 6.1 | wall 39270
KL Stats: Epoch 113 Divergences: Uniform: 2.886028662290882 Unigram: 4.395279029290834
2022-02-02 17:01:19 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 17:01:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:07:05 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.046 | ppl 1057.37 | wps 8121.5 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.319
2022-02-02 17:07:05 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 17:07:05 | INFO | train | epoch 114 | loss 5.781 | ppl 54.99 | wps 6029.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.78 | train_wall 319 | gb_free 6.1 | wall 39616
KL Stats: Epoch 114 Divergences: Uniform: 2.885311136550497 Unigram: 4.408099652606542
2022-02-02 17:07:05 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 17:07:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:07:25 | INFO | train_inner | epoch 115:      4 / 64 loss=5.79, ppl=55.34, wps=5902.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.78, train_wall=497, gb_free=6.1, wall=39636
2022-02-02 17:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:12:51 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.081 | ppl 1082.99 | wps 8127.7 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.319
2022-02-02 17:12:51 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 17:12:51 | INFO | train | epoch 115 | loss 5.771 | ppl 54.6 | wps 6037.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.791 | train_wall 318 | gb_free 6.1 | wall 39962
KL Stats: Epoch 115 Divergences: Uniform: 2.8944902449674306 Unigram: 4.420541484145339
2022-02-02 17:12:51 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 17:12:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:16:11 | INFO | train_inner | epoch 116:     40 / 64 loss=5.756, ppl=54.05, wps=6208.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.793, train_wall=498, gb_free=6.1, wall=40163
2022-02-02 17:18:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:18:37 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.133 | ppl 1122.66 | wps 8144.1 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.319
2022-02-02 17:18:37 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 17:18:37 | INFO | train | epoch 116 | loss 5.756 | ppl 54.04 | wps 6027.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.791 | train_wall 319 | gb_free 6.1 | wall 40309
KL Stats: Epoch 116 Divergences: Uniform: 2.8953536349405358 Unigram: 4.430213458793088
2022-02-02 17:18:37 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 17:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:23:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:24:23 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.16 | ppl 1144.47 | wps 8120.7 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.319
2022-02-02 17:24:23 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 17:24:23 | INFO | train | epoch 117 | loss 5.748 | ppl 53.75 | wps 6040.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.824 | train_wall 318 | gb_free 6.1 | wall 40654
KL Stats: Epoch 117 Divergences: Uniform: 2.8949238105821333 Unigram: 4.437996143454506
2022-02-02 17:24:23 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 17:24:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:25:23 | INFO | train_inner | epoch 118:     12 / 64 loss=5.755, ppl=53.99, wps=5906.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.815, train_wall=497, gb_free=6.1, wall=40715
2022-02-02 17:29:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:30:10 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.087 | ppl 1087.42 | wps 8092.8 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.319
2022-02-02 17:30:10 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 17:30:10 | INFO | train | epoch 118 | loss 5.732 | ppl 53.15 | wps 6027.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.811 | train_wall 319 | gb_free 6.1 | wall 41001
KL Stats: Epoch 118 Divergences: Uniform: 2.904412509598205 Unigram: 4.466796308636824
2022-02-02 17:30:10 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 17:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:34:10 | INFO | train_inner | epoch 119:     48 / 64 loss=5.723, ppl=52.84, wps=6203.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.813, train_wall=499, gb_free=6.1, wall=41241
2022-02-02 17:35:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:35:56 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.088 | ppl 1088.3 | wps 8101.2 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.319
2022-02-02 17:35:56 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 17:35:56 | INFO | train | epoch 119 | loss 5.721 | ppl 52.75 | wps 6028.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.825 | train_wall 319 | gb_free 6.1 | wall 41347
KL Stats: Epoch 119 Divergences: Uniform: 2.909744045335454 Unigram: 4.474067700687007
2022-02-02 17:35:56 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 17:35:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:41:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:41:44 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.216 | ppl 1189.28 | wps 8071.5 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.319
2022-02-02 17:41:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 17:41:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint120.pt
2022-02-02 17:41:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint120.pt
2022-02-02 17:41:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.216) (writing took 3.691919267177582 seconds)
2022-02-02 17:41:47 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 17:41:47 | INFO | train | epoch 120 | loss 5.709 | ppl 52.32 | wps 5949.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.811 | train_wall 319 | gb_free 6.1 | wall 41698
KL Stats: Epoch 120 Divergences: Uniform: 2.908893733674349 Unigram: 4.486101260779965
2022-02-02 17:41:47 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 17:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:43:28 | INFO | train_inner | epoch 121:     20 / 64 loss=5.709, ppl=52.32, wps=5847.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.811, train_wall=498, gb_free=6.1, wall=41799
2022-02-02 17:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:47:34 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.21 | ppl 1184.35 | wps 8122.7 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.319
2022-02-02 17:47:34 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 17:47:34 | INFO | train | epoch 121 | loss 5.697 | ppl 51.88 | wps 6023.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.821 | train_wall 319 | gb_free 6.1 | wall 42045
KL Stats: Epoch 121 Divergences: Uniform: 2.91064372276445 Unigram: 4.499518125680516
2022-02-02 17:47:34 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 17:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:52:15 | INFO | train_inner | epoch 122:     56 / 64 loss=5.699, ppl=51.94, wps=6191.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.838, train_wall=500, gb_free=6.1, wall=42327
2022-02-02 17:52:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:53:22 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.282 | ppl 1245.26 | wps 8057.2 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.319
2022-02-02 17:53:22 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 17:53:22 | INFO | train | epoch 122 | loss 5.688 | ppl 51.54 | wps 6008.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.839 | train_wall 320 | gb_free 6.1 | wall 42393
KL Stats: Epoch 122 Divergences: Uniform: 2.9094173430973194 Unigram: 4.507252636243648
2022-02-02 17:53:22 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 17:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:58:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:59:09 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.181 | ppl 1160.62 | wps 8137.4 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.319
2022-02-02 17:59:09 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 17:59:09 | INFO | train | epoch 123 | loss 5.675 | ppl 51.09 | wps 6020.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.832 | train_wall 319 | gb_free 6.1 | wall 42740
KL Stats: Epoch 123 Divergences: Uniform: 2.917487739722992 Unigram: 4.529780358248058
2022-02-02 17:59:09 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 17:59:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:01:29 | INFO | train_inner | epoch 124:     28 / 64 loss=5.666, ppl=50.78, wps=5890.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.831, train_wall=498, gb_free=6.1, wall=42880
2022-02-02 18:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:04:56 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.185 | ppl 1163.71 | wps 8042.7 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.319
2022-02-02 18:04:56 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 18:04:56 | INFO | train | epoch 124 | loss 5.663 | ppl 50.66 | wps 6013.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.833 | train_wall 319 | gb_free 6.1 | wall 43087
KL Stats: Epoch 124 Divergences: Uniform: 2.9217321259997657 Unigram: 4.535057388302278
2022-02-02 18:04:56 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 18:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:10:16 | INFO | train_inner | epoch 125:     64 / 64 loss=5.667, ppl=50.8, wps=6190, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.856, train_wall=498, gb_free=6.1, wall=43407
2022-02-02 18:10:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:10:42 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.167 | ppl 1149.34 | wps 8116.4 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.319
2022-02-02 18:10:42 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 18:10:42 | INFO | train | epoch 125 | loss 5.655 | ppl 50.37 | wps 6026 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.869 | train_wall 319 | gb_free 6.1 | wall 43434
KL Stats: Epoch 125 Divergences: Uniform: 2.925103263118454 Unigram: 4.5508212645319475
2022-02-02 18:10:42 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 18:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:16:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:16:30 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.286 | ppl 1248.72 | wps 8086.3 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.319
2022-02-02 18:16:30 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 18:16:30 | INFO | train | epoch 126 | loss 5.643 | ppl 49.96 | wps 6016.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.846 | train_wall 319 | gb_free 6.1 | wall 43781
KL Stats: Epoch 126 Divergences: Uniform: 2.9269252321850283 Unigram: 4.557244908687966
2022-02-02 18:16:30 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 18:16:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:19:30 | INFO | train_inner | epoch 127:     36 / 64 loss=5.626, ppl=49.39, wps=5898.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.848, train_wall=499, gb_free=6.1, wall=43961
2022-02-02 18:21:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:22:15 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.159 | ppl 1142.98 | wps 8144.9 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.319
2022-02-02 18:22:15 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 18:22:15 | INFO | train | epoch 127 | loss 5.63 | ppl 49.52 | wps 6045.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.847 | train_wall 318 | gb_free 6.1 | wall 44126
KL Stats: Epoch 127 Divergences: Uniform: 2.9267745813792194 Unigram: 4.575804502552369
2022-02-02 18:22:15 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 18:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:27:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:28:01 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.172 | ppl 1154.01 | wps 8122.1 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.319
2022-02-02 18:28:01 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 18:28:01 | INFO | train | epoch 128 | loss 5.623 | ppl 49.27 | wps 6033.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.856 | train_wall 318 | gb_free 6.1 | wall 44473
KL Stats: Epoch 128 Divergences: Uniform: 2.931046185999302 Unigram: 4.591500354881981
2022-02-02 18:28:01 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 18:28:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:28:41 | INFO | train_inner | epoch 129:      8 / 64 loss=5.632, ppl=49.6, wps=5908.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.858, train_wall=497, gb_free=6.1, wall=44513
2022-02-02 18:33:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:33:47 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.249 | ppl 1216.52 | wps 8146.1 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.319
2022-02-02 18:33:47 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 18:33:47 | INFO | train | epoch 129 | loss 5.611 | ppl 48.89 | wps 6042 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.857 | train_wall 318 | gb_free 6.1 | wall 44818
KL Stats: Epoch 129 Divergences: Uniform: 2.9294363674565096 Unigram: 4.593809825390961
2022-02-02 18:33:47 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 18:33:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:37:27 | INFO | train_inner | epoch 130:     44 / 64 loss=5.597, ppl=48.41, wps=6212.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.853, train_wall=498, gb_free=6.1, wall=45039
2022-02-02 18:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:39:33 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.221 | ppl 1193.93 | wps 8129.4 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.319
2022-02-02 18:39:33 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 18:39:33 | INFO | train | epoch 130 | loss 5.603 | ppl 48.59 | wps 6030.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.881 | train_wall 319 | gb_free 6.1 | wall 45165
KL Stats: Epoch 130 Divergences: Uniform: 2.9365828256314983 Unigram: 4.607514848298514
2022-02-02 18:39:33 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 18:39:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:45:19 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.231 | ppl 1202.12 | wps 8129.6 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.319
2022-02-02 18:45:19 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 18:45:19 | INFO | train | epoch 131 | loss 5.592 | ppl 48.24 | wps 6037.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.877 | train_wall 318 | gb_free 6.1 | wall 45511
KL Stats: Epoch 131 Divergences: Uniform: 2.9370092535040087 Unigram: 4.62390765580822
2022-02-02 18:45:19 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 18:45:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:46:39 | INFO | train_inner | epoch 132:     16 / 64 loss=5.596, ppl=48.36, wps=5907.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.885, train_wall=497, gb_free=6.1, wall=45591
2022-02-02 18:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:51:06 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.241 | ppl 1210.41 | wps 8086.1 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.319
2022-02-02 18:51:06 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 18:51:06 | INFO | train | epoch 132 | loss 5.582 | ppl 47.89 | wps 6029.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.882 | train_wall 319 | gb_free 6.1 | wall 45857
KL Stats: Epoch 132 Divergences: Uniform: 2.9422560377328386 Unigram: 4.629657887798704
2022-02-02 18:51:06 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 18:51:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:55:26 | INFO | train_inner | epoch 133:     52 / 64 loss=5.582, ppl=47.9, wps=6206.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.888, train_wall=498, gb_free=6.1, wall=46117
2022-02-02 18:56:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:56:51 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.25 | ppl 1218.03 | wps 8139.1 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.319
2022-02-02 18:56:51 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 18:56:51 | INFO | train | epoch 133 | loss 5.573 | ppl 47.59 | wps 6040.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.888 | train_wall 318 | gb_free 6.1 | wall 46203
KL Stats: Epoch 133 Divergences: Uniform: 2.9396026051949247 Unigram: 4.647105402804669
2022-02-02 18:56:51 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 18:56:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:02:38 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.263 | ppl 1228.56 | wps 8105.7 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.319
2022-02-02 19:02:38 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 19:02:38 | INFO | train | epoch 134 | loss 5.563 | ppl 47.28 | wps 6032.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.9 | train_wall 318 | gb_free 6.1 | wall 46549
KL Stats: Epoch 134 Divergences: Uniform: 2.9411813660404493 Unigram: 4.659683131452036
2022-02-02 19:02:38 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 19:02:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:04:38 | INFO | train_inner | epoch 135:     24 / 64 loss=5.554, ppl=46.97, wps=5905.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.894, train_wall=497, gb_free=6.1, wall=46669
2022-02-02 19:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:08:24 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.26 | ppl 1225.88 | wps 8125.5 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.319
2022-02-02 19:08:24 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 19:08:24 | INFO | train | epoch 135 | loss 5.554 | ppl 46.98 | wps 6036.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.9 | train_wall 318 | gb_free 6.1 | wall 46895
KL Stats: Epoch 135 Divergences: Uniform: 2.949419989355183 Unigram: 4.672875257899271
2022-02-02 19:08:24 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 19:08:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:13:24 | INFO | train_inner | epoch 136:     60 / 64 loss=5.563, ppl=47.29, wps=6209.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.921, train_wall=498, gb_free=6.1, wall=47195
2022-02-02 19:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:14:10 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.231 | ppl 1201.52 | wps 8092.9 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.319
2022-02-02 19:14:10 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 19:14:10 | INFO | train | epoch 136 | loss 5.546 | ppl 46.71 | wps 6030.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.926 | train_wall 319 | gb_free 6.1 | wall 47241
KL Stats: Epoch 136 Divergences: Uniform: 2.946122058804068 Unigram: 4.6733075166034315
2022-02-02 19:14:10 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 19:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:19:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:19:58 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.213 | ppl 1187 | wps 8037.7 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.319
2022-02-02 19:19:58 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 19:19:58 | INFO | train | epoch 137 | loss 5.535 | ppl 46.36 | wps 5997.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.902 | train_wall 320 | gb_free 6.1 | wall 47589
KL Stats: Epoch 137 Divergences: Uniform: 2.947417103762739 Unigram: 4.69013423492154
2022-02-02 19:19:58 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 19:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:22:40 | INFO | train_inner | epoch 138:     32 / 64 loss=5.521, ppl=45.93, wps=5866.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.903, train_wall=500, gb_free=6.1, wall=47751
2022-02-02 19:25:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:25:48 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.23 | ppl 1201.37 | wps 7972.6 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.319
2022-02-02 19:25:48 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 19:25:48 | INFO | train | epoch 138 | loss 5.528 | ppl 46.15 | wps 5972 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.916 | train_wall 321 | gb_free 6.1 | wall 47939
KL Stats: Epoch 138 Divergences: Uniform: 2.9487997538451878 Unigram: 4.692136032656464
2022-02-02 19:25:48 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 19:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:31:37 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.297 | ppl 1258.34 | wps 8035.4 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.319
2022-02-02 19:31:37 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 19:31:37 | INFO | train | epoch 139 | loss 5.518 | ppl 45.83 | wps 5982.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.934 | train_wall 321 | gb_free 6.1 | wall 48288
KL Stats: Epoch 139 Divergences: Uniform: 2.950894625198561 Unigram: 4.7099355423762646
2022-02-02 19:31:37 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 19:31:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:31:57 | INFO | train_inner | epoch 140:      4 / 64 loss=5.53, ppl=46.2, wps=5847.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.932, train_wall=502, gb_free=6.1, wall=48309
2022-02-02 19:36:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:37:27 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.281 | ppl 1243.87 | wps 8012.7 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.319
2022-02-02 19:37:27 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 19:37:27 | INFO | train | epoch 140 | loss 5.512 | ppl 45.64 | wps 5975.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.94 | train_wall 321 | gb_free 6.1 | wall 48638
KL Stats: Epoch 140 Divergences: Uniform: 2.96272214740528 Unigram: 4.725075531259834
2022-02-02 19:37:27 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 19:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:40:48 | INFO | train_inner | epoch 141:     40 / 64 loss=5.501, ppl=45.28, wps=6152.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.945, train_wall=503, gb_free=6.1, wall=48840
2022-02-02 19:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:43:15 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.242 | ppl 1210.96 | wps 8082.3 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.319
2022-02-02 19:43:15 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 19:43:15 | INFO | train | epoch 141 | loss 5.502 | ppl 45.33 | wps 5988.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.94 | train_wall 321 | gb_free 6.1 | wall 48987
KL Stats: Epoch 141 Divergences: Uniform: 2.9556387358647265 Unigram: 4.728038598630781
2022-02-02 19:43:15 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 19:43:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:49:05 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.275 | ppl 1239.43 | wps 7994.7 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.319
2022-02-02 19:49:05 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 19:49:05 | INFO | train | epoch 142 | loss 5.494 | ppl 45.07 | wps 5971.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.937 | train_wall 322 | gb_free 6.1 | wall 49336
KL Stats: Epoch 142 Divergences: Uniform: 2.9564729928441222 Unigram: 4.739350389386621
2022-02-02 19:49:05 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 19:49:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:50:06 | INFO | train_inner | epoch 143:     12 / 64 loss=5.501, ppl=45.28, wps=5849.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.936, train_wall=502, gb_free=6.1, wall=49397
2022-02-02 19:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:54:54 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.333 | ppl 1289.96 | wps 8022.8 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.319
2022-02-02 19:54:54 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 19:54:54 | INFO | train | epoch 143 | loss 5.486 | ppl 44.82 | wps 5981.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.959 | train_wall 321 | gb_free 6.1 | wall 49686
KL Stats: Epoch 143 Divergences: Uniform: 2.954136866333746 Unigram: 4.7510881288497115
2022-02-02 19:54:54 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 19:54:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:58:57 | INFO | train_inner | epoch 144:     48 / 64 loss=5.478, ppl=44.57, wps=6151.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.948, train_wall=503, gb_free=6.1, wall=49928
2022-02-02 20:00:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:00:44 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.299 | ppl 1259.9 | wps 7960.9 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.319
2022-02-02 20:00:44 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 20:00:44 | INFO | train | epoch 144 | loss 5.477 | ppl 44.53 | wps 5964.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.955 | train_wall 322 | gb_free 6.1 | wall 50036
KL Stats: Epoch 144 Divergences: Uniform: 2.9594138031581534 Unigram: 4.759092144472992
2022-02-02 20:00:44 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 20:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:06:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:06:34 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.334 | ppl 1290.38 | wps 7989.4 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.319
2022-02-02 20:06:34 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 20:06:34 | INFO | train | epoch 145 | loss 5.468 | ppl 44.28 | wps 5972 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.959 | train_wall 322 | gb_free 6.1 | wall 50385
KL Stats: Epoch 145 Divergences: Uniform: 2.9622813991795525 Unigram: 4.774307268754779
2022-02-02 20:06:34 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 20:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:08:15 | INFO | train_inner | epoch 146:     20 / 64 loss=5.468, ppl=44.25, wps=5841.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.963, train_wall=502, gb_free=6.1, wall=50486
2022-02-02 20:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:12:23 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.35 | ppl 1305.4 | wps 7981.3 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.319
2022-02-02 20:12:23 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 20:12:23 | INFO | train | epoch 146 | loss 5.462 | ppl 44.07 | wps 5980.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.984 | train_wall 321 | gb_free 6.1 | wall 50735
KL Stats: Epoch 146 Divergences: Uniform: 2.96459437157385 Unigram: 4.77553259993044
2022-02-02 20:12:23 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 20:12:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:17:06 | INFO | train_inner | epoch 147:     56 / 64 loss=5.46, ppl=44.03, wps=6151.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.986, train_wall=503, gb_free=6.1, wall=51018
2022-02-02 20:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:18:13 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.344 | ppl 1299.39 | wps 8050.8 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.319
2022-02-02 20:18:13 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 20:18:13 | INFO | train | epoch 147 | loss 5.453 | ppl 43.82 | wps 5981 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.979 | train_wall 321 | gb_free 6.1 | wall 51084
KL Stats: Epoch 147 Divergences: Uniform: 2.9618580731824933 Unigram: 4.785147269884322
2022-02-02 20:18:13 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 20:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:23:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:24:02 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.264 | ppl 1229.58 | wps 8052 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.319
2022-02-02 20:24:02 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 20:24:02 | INFO | train | epoch 148 | loss 5.446 | ppl 43.6 | wps 5978 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.986 | train_wall 321 | gb_free 6.1 | wall 51433
KL Stats: Epoch 148 Divergences: Uniform: 2.969901013998683 Unigram: 4.798222808059036
2022-02-02 20:24:02 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 20:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:26:24 | INFO | train_inner | epoch 149:     28 / 64 loss=5.44, ppl=43.42, wps=5847.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.998, train_wall=502, gb_free=6.1, wall=51575
2022-02-02 20:29:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:29:52 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.306 | ppl 1265.7 | wps 8027.5 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.319
2022-02-02 20:29:52 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 20:29:52 | INFO | train | epoch 149 | loss 5.439 | ppl 43.39 | wps 5972.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 1.023 | train_wall 322 | gb_free 6.1 | wall 51783
KL Stats: Epoch 149 Divergences: Uniform: 2.9685616986358956 Unigram: 4.802337523306734
2022-02-02 20:29:52 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 20:29:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:35:14 | INFO | train_inner | epoch 150:     64 / 64 loss=5.444, ppl=43.53, wps=6144.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.995, train_wall=502, gb_free=6.1, wall=52106
2022-02-02 20:35:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:35:42 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.228 | ppl 1199.5 | wps 7983.5 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.319
2022-02-02 20:35:42 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 20:35:42 | INFO | train | epoch 150 | loss 5.432 | ppl 43.17 | wps 5964.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.98 | train_wall 322 | gb_free 6.1 | wall 52133
KL Stats: Epoch 150 Divergences: Uniform: 2.972564406041511 Unigram: 4.8115513450666585
2022-02-02 20:35:42 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 20:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:41:32 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.294 | ppl 1255.45 | wps 8031.7 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.319
2022-02-02 20:41:32 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 20:41:32 | INFO | train | epoch 151 | loss 5.423 | ppl 42.9 | wps 5965.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.017 | train_wall 322 | gb_free 6.1 | wall 52483
KL Stats: Epoch 151 Divergences: Uniform: 2.9731047370409467 Unigram: 4.82104667091285
2022-02-02 20:41:32 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 20:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:44:34 | INFO | train_inner | epoch 152:     36 / 64 loss=5.411, ppl=42.54, wps=5838.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.007, train_wall=504, gb_free=6.1, wall=52666
2022-02-02 20:46:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:47:23 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.315 | ppl 1273.74 | wps 7953.2 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.319
2022-02-02 20:47:23 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 20:47:23 | INFO | train | epoch 152 | loss 5.417 | ppl 42.72 | wps 5956.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.016 | train_wall 322 | gb_free 6.1 | wall 52834
KL Stats: Epoch 152 Divergences: Uniform: 2.9779804337040563 Unigram: 4.83219524219308
2022-02-02 20:47:23 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 20:47:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:52:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:53:12 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.297 | ppl 1257.87 | wps 8040.9 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.319
2022-02-02 20:53:12 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 20:53:12 | INFO | train | epoch 153 | loss 5.409 | ppl 42.48 | wps 5974.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 1.026 | train_wall 322 | gb_free 6.1 | wall 53183
KL Stats: Epoch 153 Divergences: Uniform: 2.977961936739885 Unigram: 4.8410951154686
2022-02-02 20:53:12 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 20:53:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:53:53 | INFO | train_inner | epoch 154:      8 / 64 loss=5.416, ppl=42.71, wps=5837.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=1.034, train_wall=502, gb_free=6.1, wall=53224
2022-02-02 20:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:59:02 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.279 | ppl 1242.36 | wps 8009.2 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.319
2022-02-02 20:59:02 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 20:59:02 | INFO | train | epoch 154 | loss 5.4 | ppl 42.22 | wps 5965 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.011 | train_wall 322 | gb_free 6.1 | wall 53534
KL Stats: Epoch 154 Divergences: Uniform: 2.9803803107815745 Unigram: 4.854195770030016
2022-02-02 20:59:02 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 20:59:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:02:45 | INFO | train_inner | epoch 155:     44 / 64 loss=5.392, ppl=41.98, wps=6141.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.012, train_wall=503, gb_free=6.1, wall=53756
2022-02-02 21:04:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:04:52 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.301 | ppl 1261.72 | wps 8093.1 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.319
2022-02-02 21:04:52 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 21:04:52 | INFO | train | epoch 155 | loss 5.395 | ppl 42.07 | wps 5979.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.022 | train_wall 321 | gb_free 6.1 | wall 53883
KL Stats: Epoch 155 Divergences: Uniform: 2.9829548379870134 Unigram: 4.853592300330381
2022-02-02 21:04:52 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 21:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:10:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:10:42 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.298 | ppl 1258.58 | wps 8028.6 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.319
2022-02-02 21:10:42 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 21:10:42 | INFO | train | epoch 156 | loss 5.389 | ppl 41.89 | wps 5960.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.055 | train_wall 322 | gb_free 6.1 | wall 54233
KL Stats: Epoch 156 Divergences: Uniform: 2.9814671392817527 Unigram: 4.867415194293419
2022-02-02 21:10:42 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 21:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:12:03 | INFO | train_inner | epoch 157:     16 / 64 loss=5.391, ppl=41.96, wps=5840.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.047, train_wall=503, gb_free=6.1, wall=54314
2022-02-02 21:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:16:31 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.354 | ppl 1308.41 | wps 8005.4 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.319
2022-02-02 21:16:31 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 21:16:31 | INFO | train | epoch 157 | loss 5.38 | ppl 41.65 | wps 5978.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.035 | train_wall 321 | gb_free 6.1 | wall 54583
KL Stats: Epoch 157 Divergences: Uniform: 2.980874368470349 Unigram: 4.87796986457564
2022-02-02 21:16:31 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 21:16:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:20:55 | INFO | train_inner | epoch 158:     52 / 64 loss=5.377, ppl=41.55, wps=6144.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.045, train_wall=503, gb_free=6.1, wall=54846
2022-02-02 21:21:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:22:22 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.442 | ppl 1390.97 | wps 7954.1 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.319
2022-02-02 21:22:22 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 21:22:22 | INFO | train | epoch 158 | loss 5.375 | ppl 41.5 | wps 5957.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.064 | train_wall 322 | gb_free 6.1 | wall 54933
KL Stats: Epoch 158 Divergences: Uniform: 2.982518955913058 Unigram: 4.883524444967812
2022-02-02 21:22:22 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 21:22:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:27:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:28:11 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.375 | ppl 1327.78 | wps 7989.3 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.319
2022-02-02 21:28:11 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 21:28:11 | INFO | train | epoch 159 | loss 5.367 | ppl 41.28 | wps 5982.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.04 | train_wall 321 | gb_free 6.1 | wall 55282
KL Stats: Epoch 159 Divergences: Uniform: 2.982746079292924 Unigram: 4.893036314079193
2022-02-02 21:28:11 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 21:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:30:13 | INFO | train_inner | epoch 160:     24 / 64 loss=5.364, ppl=41.18, wps=5844.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.052, train_wall=502, gb_free=6.1, wall=55404
2022-02-02 21:33:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:34:01 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.379 | ppl 1331.71 | wps 8026.5 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.319
2022-02-02 21:34:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 21:34:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint160.pt
2022-02-02 21:34:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint160.pt
2022-02-02 21:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.379) (writing took 3.6415340714156628 seconds)
2022-02-02 21:34:05 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 21:34:05 | INFO | train | epoch 160 | loss 5.361 | ppl 41.09 | wps 5906.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.074 | train_wall 322 | gb_free 6.1 | wall 55636
KL Stats: Epoch 160 Divergences: Uniform: 2.981351547753393 Unigram: 4.899642410142867
2022-02-02 21:34:05 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 21:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:39:08 | INFO | train_inner | epoch 161:     60 / 64 loss=5.367, ppl=41.26, wps=6105.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.084, train_wall=503, gb_free=6.1, wall=55939
2022-02-02 21:39:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:39:54 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.432 | ppl 1381.13 | wps 8050.4 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.319
2022-02-02 21:39:54 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 21:39:54 | INFO | train | epoch 161 | loss 5.357 | ppl 40.99 | wps 5981.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.087 | train_wall 321 | gb_free 6.1 | wall 55985
KL Stats: Epoch 161 Divergences: Uniform: 2.9837335822744153 Unigram: 4.911020748360232
2022-02-02 21:39:54 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 21:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:45:43 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.374 | ppl 1327.04 | wps 8043.2 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.319
2022-02-02 21:45:43 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 21:45:43 | INFO | train | epoch 162 | loss 5.351 | ppl 40.83 | wps 5978.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.087 | train_wall 321 | gb_free 6.1 | wall 56335
KL Stats: Epoch 162 Divergences: Uniform: 2.9943090964570027 Unigram: 4.912877974063621
2022-02-02 21:45:43 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 21:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:48:25 | INFO | train_inner | epoch 163:     32 / 64 loss=5.342, ppl=40.57, wps=5851.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.094, train_wall=501, gb_free=6.1, wall=56496
2022-02-02 21:51:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:51:32 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.438 | ppl 1387.09 | wps 8033.3 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.319
2022-02-02 21:51:32 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 21:51:32 | INFO | train | epoch 163 | loss 5.344 | ppl 40.61 | wps 5985.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.108 | train_wall 321 | gb_free 6.1 | wall 56684
KL Stats: Epoch 163 Divergences: Uniform: 2.9865048180354523 Unigram: 4.918735589655145
2022-02-02 21:51:32 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 21:51:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:56:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:57:22 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.431 | ppl 1380.07 | wps 8010.8 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.319
2022-02-02 21:57:22 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 21:57:22 | INFO | train | epoch 164 | loss 5.336 | ppl 40.38 | wps 5966.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.098 | train_wall 322 | gb_free 6.1 | wall 57034
KL Stats: Epoch 164 Divergences: Uniform: 2.990474509494441 Unigram: 4.9321073615916085
2022-02-02 21:57:22 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 21:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:57:43 | INFO | train_inner | epoch 165:      4 / 64 loss=5.347, ppl=40.69, wps=5846.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.102, train_wall=502, gb_free=6.1, wall=57054
2022-02-02 22:02:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:03:11 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.394 | ppl 1345.47 | wps 8041.8 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.319
2022-02-02 22:03:11 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 22:03:11 | INFO | train | epoch 165 | loss 5.331 | ppl 40.26 | wps 5986 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.122 | train_wall 321 | gb_free 6.1 | wall 57383
KL Stats: Epoch 165 Divergences: Uniform: 2.9886864768204773 Unigram: 4.943556517005443
2022-02-02 22:03:11 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 22:03:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:06:34 | INFO | train_inner | epoch 166:     40 / 64 loss=5.318, ppl=39.89, wps=6155.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.116, train_wall=502, gb_free=6.1, wall=57585
2022-02-02 22:08:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:09:01 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.353 | ppl 1308 | wps 7932.8 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.319
2022-02-02 22:09:01 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 22:09:01 | INFO | train | epoch 166 | loss 5.324 | ppl 40.07 | wps 5970.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.109 | train_wall 321 | gb_free 6.1 | wall 57732
KL Stats: Epoch 166 Divergences: Uniform: 2.9939736583420187 Unigram: 4.943103495461116
2022-02-02 22:09:01 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 22:09:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:14:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:14:50 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.373 | ppl 1325.68 | wps 8049.5 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.319
2022-02-02 22:14:50 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 22:14:50 | INFO | train | epoch 167 | loss 5.319 | ppl 39.93 | wps 5981.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.106 | train_wall 321 | gb_free 6.1 | wall 58082
KL Stats: Epoch 167 Divergences: Uniform: 2.997636443924174 Unigram: 4.959167938046174
2022-02-02 22:14:50 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 22:14:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:15:51 | INFO | train_inner | epoch 168:     12 / 64 loss=5.326, ppl=40.11, wps=5848.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.11, train_wall=501, gb_free=6.1, wall=58142
2022-02-02 22:20:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:20:40 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.431 | ppl 1380.74 | wps 8023.9 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.319
2022-02-02 22:20:40 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 22:20:40 | INFO | train | epoch 168 | loss 5.314 | ppl 39.78 | wps 5974.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.141 | train_wall 321 | gb_free 6.1 | wall 58431
KL Stats: Epoch 168 Divergences: Uniform: 2.9929278456683273 Unigram: 4.964504108395092
2022-02-02 22:20:40 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 22:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:24:42 | INFO | train_inner | epoch 169:     48 / 64 loss=5.309, ppl=39.64, wps=6154.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.148, train_wall=502, gb_free=6.1, wall=58673
2022-02-02 22:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:26:28 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.397 | ppl 1348.49 | wps 8074.1 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.319
2022-02-02 22:26:28 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 22:26:28 | INFO | train | epoch 169 | loss 5.308 | ppl 39.6 | wps 5993.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.143 | train_wall 321 | gb_free 6.1 | wall 58780
KL Stats: Epoch 169 Divergences: Uniform: 2.9968294421143917 Unigram: 4.974798827291964
2022-02-02 22:26:28 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 22:26:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:32:18 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.477 | ppl 1424.99 | wps 8014.5 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.319
2022-02-02 22:32:18 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 22:32:18 | INFO | train | epoch 170 | loss 5.302 | ppl 39.44 | wps 5978.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.148 | train_wall 321 | gb_free 6.1 | wall 59129
KL Stats: Epoch 170 Divergences: Uniform: 2.99458965141933 Unigram: 4.970310661774765
2022-02-02 22:32:18 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 22:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:33:59 | INFO | train_inner | epoch 171:     20 / 64 loss=5.302, ppl=39.45, wps=5853.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.142, train_wall=501, gb_free=6.1, wall=59230
2022-02-02 22:37:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:38:07 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.397 | ppl 1348.38 | wps 8039.3 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.319
2022-02-02 22:38:07 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 22:38:07 | INFO | train | epoch 171 | loss 5.297 | ppl 39.32 | wps 5976.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.146 | train_wall 321 | gb_free 6.1 | wall 59478
KL Stats: Epoch 171 Divergences: Uniform: 2.9970873809633285 Unigram: 4.983003888932324
2022-02-02 22:38:07 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 22:38:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:42:51 | INFO | train_inner | epoch 172:     56 / 64 loss=5.297, ppl=39.3, wps=6142.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.164, train_wall=504, gb_free=6.1, wall=59762
2022-02-02 22:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:43:58 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.439 | ppl 1388.47 | wps 7967.3 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.319
2022-02-02 22:43:58 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 22:43:58 | INFO | train | epoch 172 | loss 5.292 | ppl 39.18 | wps 5960.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.184 | train_wall 322 | gb_free 6.1 | wall 59829
KL Stats: Epoch 172 Divergences: Uniform: 2.9963750159851563 Unigram: 4.991981392059123
2022-02-02 22:43:58 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 22:43:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:49:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:49:47 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.459 | ppl 1407.82 | wps 8012.5 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.319
2022-02-02 22:49:47 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 22:49:47 | INFO | train | epoch 173 | loss 5.286 | ppl 39.01 | wps 5977 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.17 | train_wall 321 | gb_free 6.1 | wall 60178
KL Stats: Epoch 173 Divergences: Uniform: 3.0042911939921506 Unigram: 5.001641176564927
2022-02-02 22:49:47 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 22:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:52:08 | INFO | train_inner | epoch 174:     28 / 64 loss=5.279, ppl=38.83, wps=5846.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.18, train_wall=502, gb_free=6.1, wall=60320
2022-02-02 22:55:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:55:37 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.422 | ppl 1371.51 | wps 7956.3 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.319
2022-02-02 22:55:37 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 22:55:37 | INFO | train | epoch 174 | loss 5.278 | ppl 38.8 | wps 5968.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.194 | train_wall 322 | gb_free 6.1 | wall 60528
KL Stats: Epoch 174 Divergences: Uniform: 3.0045021351739347 Unigram: 5.004860672906299
2022-02-02 22:55:37 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 22:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:00:59 | INFO | train_inner | epoch 175:     64 / 64 loss=5.286, ppl=39.01, wps=6143.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.188, train_wall=502, gb_free=6.1, wall=60850
2022-02-02 23:00:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:01:26 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.429 | ppl 1379.04 | wps 8030.2 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.319
2022-02-02 23:01:26 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 23:01:26 | INFO | train | epoch 175 | loss 5.274 | ppl 38.69 | wps 5978.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.179 | train_wall 321 | gb_free 6.1 | wall 60878
KL Stats: Epoch 175 Divergences: Uniform: 3.0039290473877034 Unigram: 5.017830687208383
2022-02-02 23:01:26 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 23:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:06:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:07:16 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.419 | ppl 1369.53 | wps 8003.5 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.319
2022-02-02 23:07:16 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 23:07:16 | INFO | train | epoch 176 | loss 5.271 | ppl 38.6 | wps 5971.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.227 | train_wall 322 | gb_free 6.1 | wall 61227
KL Stats: Epoch 176 Divergences: Uniform: 3.0053094663040087 Unigram: 5.0201924815476335
2022-02-02 23:07:16 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 23:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:10:19 | INFO | train_inner | epoch 177:     36 / 64 loss=5.259, ppl=38.29, wps=5842.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.207, train_wall=503, gb_free=6.1, wall=61410
2022-02-02 23:12:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:13:06 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.427 | ppl 1376.3 | wps 8064.9 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.319
2022-02-02 23:13:06 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 23:13:06 | INFO | train | epoch 177 | loss 5.262 | ppl 38.36 | wps 5973.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.178 | train_wall 322 | gb_free 6.1 | wall 61577
KL Stats: Epoch 177 Divergences: Uniform: 3.0061142936686225 Unigram: 5.030010547841119
2022-02-02 23:13:06 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 23:13:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:18:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:18:55 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.415 | ppl 1365.63 | wps 8017.8 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.319
2022-02-02 23:18:55 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-02 23:18:55 | INFO | train | epoch 178 | loss 5.259 | ppl 38.3 | wps 5986.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.209 | train_wall 321 | gb_free 6.1 | wall 61926
KL Stats: Epoch 178 Divergences: Uniform: 3.0090617174791117 Unigram: 5.033596484543639
2022-02-02 23:18:55 | INFO | fairseq.trainer | begin training epoch 179
2022-02-02 23:18:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:19:35 | INFO | train_inner | epoch 179:      8 / 64 loss=5.262, ppl=38.37, wps=5855.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.206, train_wall=501, gb_free=6.1, wall=61967
2022-02-02 23:24:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:24:44 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.458 | ppl 1406.77 | wps 8053.2 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.319
2022-02-02 23:24:44 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-02 23:24:44 | INFO | train | epoch 179 | loss 5.253 | ppl 38.12 | wps 5976.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.212 | train_wall 321 | gb_free 6.1 | wall 62275
KL Stats: Epoch 179 Divergences: Uniform: 3.0086503134692344 Unigram: 5.045467088447906
2022-02-02 23:24:44 | INFO | fairseq.trainer | begin training epoch 180
2022-02-02 23:24:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:28:26 | INFO | train_inner | epoch 180:     44 / 64 loss=5.249, ppl=38.02, wps=6156.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.201, train_wall=502, gb_free=6.1, wall=62497
2022-02-02 23:30:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:30:33 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.455 | ppl 1403.28 | wps 7923.1 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.319
2022-02-02 23:30:33 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-02 23:30:33 | INFO | train | epoch 180 | loss 5.249 | ppl 38.03 | wps 5980 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.203 | train_wall 321 | gb_free 6.1 | wall 62625
KL Stats: Epoch 180 Divergences: Uniform: 3.0038610747058394 Unigram: 5.055832299030573
2022-02-02 23:30:33 | INFO | fairseq.trainer | begin training epoch 181
2022-02-02 23:30:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:35:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:36:23 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.399 | ppl 1349.87 | wps 8041.8 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.319
2022-02-02 23:36:23 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-02 23:36:23 | INFO | train | epoch 181 | loss 5.246 | ppl 37.94 | wps 5976.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.214 | train_wall 321 | gb_free 6.1 | wall 62974
KL Stats: Epoch 181 Divergences: Uniform: 3.007816443800979 Unigram: 5.054445791604304
2022-02-02 23:36:23 | INFO | fairseq.trainer | begin training epoch 182
2022-02-02 23:36:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:37:44 | INFO | train_inner | epoch 182:     16 / 64 loss=5.244, ppl=37.91, wps=5847.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.216, train_wall=501, gb_free=6.1, wall=63055
2022-02-02 23:41:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:42:10 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.44 | ppl 1389.34 | wps 8091.8 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.319
2022-02-02 23:42:10 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-02 23:42:10 | INFO | train | epoch 182 | loss 5.238 | ppl 37.75 | wps 6008.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.258 | train_wall 320 | gb_free 6.1 | wall 63322
KL Stats: Epoch 182 Divergences: Uniform: 3.0071501509644856 Unigram: 5.062461721383885
2022-02-02 23:42:10 | INFO | fairseq.trainer | begin training epoch 183
2022-02-02 23:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:46:31 | INFO | train_inner | epoch 183:     52 / 64 loss=5.239, ppl=37.77, wps=6197.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.251, train_wall=499, gb_free=6.1, wall=63582
2022-02-02 23:47:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:47:57 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.434 | ppl 1383.63 | wps 8105.5 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.319
2022-02-02 23:47:57 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-02 23:47:57 | INFO | train | epoch 183 | loss 5.235 | ppl 37.66 | wps 6033.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.236 | train_wall 318 | gb_free 6.1 | wall 63668
KL Stats: Epoch 183 Divergences: Uniform: 3.0106058471000727 Unigram: 5.0662707660233135
2022-02-02 23:47:57 | INFO | fairseq.trainer | begin training epoch 184
2022-02-02 23:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:53:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:53:43 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.451 | ppl 1399.93 | wps 8087.2 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.319
2022-02-02 23:53:43 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-02 23:53:43 | INFO | train | epoch 184 | loss 5.228 | ppl 37.47 | wps 6033.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.242 | train_wall 318 | gb_free 6.1 | wall 64014
KL Stats: Epoch 184 Divergences: Uniform: 3.0134677631930145 Unigram: 5.078189443917577
2022-02-02 23:53:43 | INFO | fairseq.trainer | begin training epoch 185
2022-02-02 23:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:55:43 | INFO | train_inner | epoch 185:     24 / 64 loss=5.222, ppl=37.33, wps=5902.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.25, train_wall=497, gb_free=6.1, wall=64134
2022-02-02 23:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:59:29 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.466 | ppl 1414.68 | wps 8154.3 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.319
2022-02-02 23:59:29 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-02 23:59:29 | INFO | train | epoch 185 | loss 5.224 | ppl 37.37 | wps 6039.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.271 | train_wall 318 | gb_free 6.1 | wall 64360
KL Stats: Epoch 185 Divergences: Uniform: 3.016447332558291 Unigram: 5.084798702387295
2022-02-02 23:59:29 | INFO | fairseq.trainer | begin training epoch 186
2022-02-02 23:59:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:04:29 | INFO | train_inner | epoch 186:     60 / 64 loss=5.23, ppl=37.54, wps=6211.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.276, train_wall=498, gb_free=6.1, wall=64661
2022-02-03 00:04:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:05:15 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.435 | ppl 1384.41 | wps 8102.9 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.319
2022-02-03 00:05:15 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-03 00:05:15 | INFO | train | epoch 186 | loss 5.218 | ppl 37.21 | wps 6029.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.283 | train_wall 319 | gb_free 6.1 | wall 64706
KL Stats: Epoch 186 Divergences: Uniform: 3.0140366202928837 Unigram: 5.091119032248994
2022-02-03 00:05:15 | INFO | fairseq.trainer | begin training epoch 187
2022-02-03 00:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:11:01 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.446 | ppl 1395.08 | wps 8137.8 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.319
2022-02-03 00:11:01 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-03 00:11:01 | INFO | train | epoch 187 | loss 5.212 | ppl 37.07 | wps 6034.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.299 | train_wall 318 | gb_free 6.1 | wall 65052
KL Stats: Epoch 187 Divergences: Uniform: 3.015406655566829 Unigram: 5.1014137919934335
2022-02-03 00:11:01 | INFO | fairseq.trainer | begin training epoch 188
2022-02-03 00:11:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:13:41 | INFO | train_inner | epoch 188:     32 / 64 loss=5.201, ppl=36.79, wps=5905.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.302, train_wall=497, gb_free=6.1, wall=65213
2022-02-03 00:16:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:16:48 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.438 | ppl 1387.66 | wps 8078.7 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.319
2022-02-03 00:16:48 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-03 00:16:48 | INFO | train | epoch 188 | loss 5.208 | ppl 36.95 | wps 6029 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.301 | train_wall 319 | gb_free 6.1 | wall 65399
KL Stats: Epoch 188 Divergences: Uniform: 3.01422970209236 Unigram: 5.102168983107295
2022-02-03 00:16:48 | INFO | fairseq.trainer | begin training epoch 189
2022-02-03 00:16:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:22:34 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.459 | ppl 1407.57 | wps 8127.4 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.319
2022-02-03 00:22:34 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-03 00:22:34 | INFO | train | epoch 189 | loss 5.204 | ppl 36.85 | wps 6037.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.303 | train_wall 318 | gb_free 6.1 | wall 65745
KL Stats: Epoch 189 Divergences: Uniform: 3.018216293544913 Unigram: 5.111089856689155
2022-02-03 00:22:34 | INFO | fairseq.trainer | begin training epoch 190
2022-02-03 00:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:22:54 | INFO | train_inner | epoch 190:      4 / 64 loss=5.214, ppl=37.12, wps=5902.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.297, train_wall=497, gb_free=6.1, wall=65765
2022-02-03 00:27:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:28:20 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.506 | ppl 1454.58 | wps 8116.2 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.319
2022-02-03 00:28:20 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-03 00:28:20 | INFO | train | epoch 190 | loss 5.199 | ppl 36.74 | wps 6033.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.297 | train_wall 318 | gb_free 6.1 | wall 66091
KL Stats: Epoch 190 Divergences: Uniform: 3.0218545786285738 Unigram: 5.11552614283149
2022-02-03 00:28:20 | INFO | fairseq.trainer | begin training epoch 191
2022-02-03 00:28:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:31:40 | INFO | train_inner | epoch 191:     40 / 64 loss=5.19, ppl=36.52, wps=6208, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.321, train_wall=498, gb_free=6.1, wall=66291
2022-02-03 00:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:34:06 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.435 | ppl 1384.16 | wps 8109.6 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.319
2022-02-03 00:34:06 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-03 00:34:06 | INFO | train | epoch 191 | loss 5.196 | ppl 36.65 | wps 6034.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.342 | train_wall 318 | gb_free 6.1 | wall 66437
KL Stats: Epoch 191 Divergences: Uniform: 3.016230248262022 Unigram: 5.12353180738433
2022-02-03 00:34:06 | INFO | fairseq.trainer | begin training epoch 192
2022-02-03 00:34:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:39:52 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.461 | ppl 1409.09 | wps 8105.1 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.319
2022-02-03 00:39:52 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-03 00:39:52 | INFO | train | epoch 192 | loss 5.191 | ppl 36.54 | wps 6031.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.347 | train_wall 318 | gb_free 6.1 | wall 66783
KL Stats: Epoch 192 Divergences: Uniform: 3.0205619437822593 Unigram: 5.122784228733366
2022-02-03 00:39:52 | INFO | fairseq.trainer | begin training epoch 193
2022-02-03 00:39:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:40:52 | INFO | train_inner | epoch 193:     12 / 64 loss=5.196, ppl=36.65, wps=5901.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.344, train_wall=497, gb_free=6.1, wall=66844
2022-02-03 00:45:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:45:38 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.47 | ppl 1418.83 | wps 8134 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.319
2022-02-03 00:45:38 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-03 00:45:38 | INFO | train | epoch 193 | loss 5.186 | ppl 36.41 | wps 6033.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.322 | train_wall 318 | gb_free 6.1 | wall 67130
KL Stats: Epoch 193 Divergences: Uniform: 3.016349978093513 Unigram: 5.1349984599493155
2022-02-03 00:45:38 | INFO | fairseq.trainer | begin training epoch 194
2022-02-03 00:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:49:39 | INFO | train_inner | epoch 194:     48 / 64 loss=5.183, ppl=36.33, wps=6210.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.343, train_wall=498, gb_free=6.1, wall=67370
2022-02-03 00:50:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:51:25 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.51 | ppl 1457.93 | wps 8096.1 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.319
2022-02-03 00:51:25 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-03 00:51:25 | INFO | train | epoch 194 | loss 5.183 | ppl 36.34 | wps 6031.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.363 | train_wall 318 | gb_free 6.1 | wall 67476
KL Stats: Epoch 194 Divergences: Uniform: 3.021478785444142 Unigram: 5.140869455976693
2022-02-03 00:51:25 | INFO | fairseq.trainer | begin training epoch 195
2022-02-03 00:51:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:56:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:57:11 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.493 | ppl 1440.98 | wps 8150.4 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.319
2022-02-03 00:57:11 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-03 00:57:11 | INFO | train | epoch 195 | loss 5.178 | ppl 36.2 | wps 6030 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.358 | train_wall 319 | gb_free 6.1 | wall 67822
KL Stats: Epoch 195 Divergences: Uniform: 3.0170324054020434 Unigram: 5.15032978815552
2022-02-03 00:57:11 | INFO | fairseq.trainer | begin training epoch 196
2022-02-03 00:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:58:51 | INFO | train_inner | epoch 196:     20 / 64 loss=5.174, ppl=36.1, wps=5900.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.37, train_wall=497, gb_free=6.1, wall=67922
2022-02-03 01:02:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:02:58 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.491 | ppl 1439.06 | wps 8054.8 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.319
2022-02-03 01:02:58 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 01:02:58 | INFO | train | epoch 196 | loss 5.175 | ppl 36.13 | wps 6024.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.366 | train_wall 319 | gb_free 6.1 | wall 68169
KL Stats: Epoch 196 Divergences: Uniform: 3.026011588993572 Unigram: 5.151857901614241
2022-02-03 01:02:58 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 01:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:07:38 | INFO | train_inner | epoch 197:     56 / 64 loss=5.179, ppl=36.24, wps=6203.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.338, train_wall=498, gb_free=6.1, wall=68449
2022-02-03 01:08:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:08:44 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.512 | ppl 1460.26 | wps 8141.5 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.319
2022-02-03 01:08:44 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 01:08:44 | INFO | train | epoch 197 | loss 5.168 | ppl 35.96 | wps 6039.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.347 | train_wall 318 | gb_free 6.1 | wall 68515
KL Stats: Epoch 197 Divergences: Uniform: 3.020698522918234 Unigram: 5.157730848800855
2022-02-03 01:08:44 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 01:08:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:14:30 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.511 | ppl 1459.38 | wps 8078 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.319
2022-02-03 01:14:30 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 01:14:30 | INFO | train | epoch 198 | loss 5.167 | ppl 35.94 | wps 6028.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.405 | train_wall 319 | gb_free 6.1 | wall 68861
KL Stats: Epoch 198 Divergences: Uniform: 3.0212976270075433 Unigram: 5.169052834940444
2022-02-03 01:14:30 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 01:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:16:50 | INFO | train_inner | epoch 199:     28 / 64 loss=5.16, ppl=35.76, wps=5900.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.397, train_wall=497, gb_free=6.1, wall=69002
2022-02-03 01:19:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:20:16 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.473 | ppl 1420.84 | wps 8132.3 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.319
2022-02-03 01:20:16 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 01:20:16 | INFO | train | epoch 199 | loss 5.159 | ppl 35.72 | wps 6034.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.381 | train_wall 318 | gb_free 6.1 | wall 69207
KL Stats: Epoch 199 Divergences: Uniform: 3.023608568346453 Unigram: 5.176286654212027
2022-02-03 01:20:16 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 01:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:25:35 | INFO | train_inner | epoch 200:     64 / 64 loss=5.165, ppl=35.88, wps=6211.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.393, train_wall=497, gb_free=6.1, wall=69527
2022-02-03 01:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:26:02 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.508 | ppl 1456.5 | wps 8121 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.319
2022-02-03 01:26:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-03 01:26:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint200.pt
2022-02-03 01:26:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint200.pt
2022-02-03 01:26:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#2/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.508) (writing took 3.5037462562322617 seconds)
2022-02-03 01:26:06 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-03 01:26:06 | INFO | train | epoch 200 | loss 5.156 | ppl 35.66 | wps 5974.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.401 | train_wall 318 | gb_free 6.1 | wall 69557
KL Stats: Epoch 200 Divergences: Uniform: 3.023843701870982 Unigram: 5.178759381657858
2022-02-03 01:26:06 | INFO | fairseq.trainer | begin training epoch 201
2022-02-03 01:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:31:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:31:51 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.451 | ppl 1399.51 | wps 8141.9 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.319
2022-02-03 01:31:51 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-03 01:31:51 | INFO | train | epoch 201 | loss 5.154 | ppl 35.6 | wps 6043.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.438 | train_wall 318 | gb_free 6.1 | wall 69903
KL Stats: Epoch 201 Divergences: Uniform: 3.0261271451771443 Unigram: 5.1827052349627305
2022-02-03 01:31:51 | INFO | fairseq.trainer | begin training epoch 202
2022-02-03 01:31:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:34:52 | INFO | train_inner | epoch 202:     36 / 64 loss=5.142, ppl=35.3, wps=5874.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.437, train_wall=498, gb_free=6.1, wall=70083
2022-02-03 01:37:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:37:38 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.513 | ppl 1460.88 | wps 8117.4 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.319
2022-02-03 01:37:38 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-03 01:37:38 | INFO | train | epoch 202 | loss 5.149 | ppl 35.49 | wps 6032.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.442 | train_wall 318 | gb_free 6.1 | wall 70249
KL Stats: Epoch 202 Divergences: Uniform: 3.025448709713106 Unigram: 5.189985180663046
2022-02-03 01:37:38 | INFO | fairseq.trainer | begin training epoch 203
2022-02-03 01:37:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:43:24 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.513 | ppl 1460.86 | wps 8114.9 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.319
2022-02-03 01:43:24 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-03 01:43:24 | INFO | train | epoch 203 | loss 5.148 | ppl 35.45 | wps 6031.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.45 | train_wall 318 | gb_free 6.1 | wall 70595
KL Stats: Epoch 203 Divergences: Uniform: 3.02564750456355 Unigram: 5.193157018897695
2022-02-03 01:43:24 | INFO | fairseq.trainer | begin training epoch 204
2022-02-03 01:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:44:04 | INFO | train_inner | epoch 204:      8 / 64 loss=5.153, ppl=35.59, wps=5902, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.456, train_wall=497, gb_free=6.1, wall=70635
2022-02-03 01:48:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:49:10 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.504 | ppl 1452.46 | wps 8079.4 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.319
2022-02-03 01:49:10 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-03 01:49:10 | INFO | train | epoch 204 | loss 5.142 | ppl 35.31 | wps 6029.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.47 | train_wall 318 | gb_free 6.1 | wall 70941
KL Stats: Epoch 204 Divergences: Uniform: 3.029994250190454 Unigram: 5.191567918961174
2022-02-03 01:49:10 | INFO | fairseq.trainer | begin training epoch 205
2022-02-03 01:49:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:52:51 | INFO | train_inner | epoch 205:     44 / 64 loss=5.139, ppl=35.23, wps=6203.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.45, train_wall=498, gb_free=6.1, wall=71162
2022-02-03 01:54:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:54:56 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.454 | ppl 1402.78 | wps 8124.2 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.319
2022-02-03 01:54:56 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-03 01:54:56 | INFO | train | epoch 205 | loss 5.135 | ppl 35.13 | wps 6032.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.459 | train_wall 318 | gb_free 6.1 | wall 71288
KL Stats: Epoch 205 Divergences: Uniform: 3.0294705728292994 Unigram: 5.20214938778799
2022-02-03 01:54:56 | INFO | fairseq.trainer | begin training epoch 206
2022-02-03 01:54:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:00:42 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.514 | ppl 1462.67 | wps 8112.6 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.319
2022-02-03 02:00:42 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-03 02:00:42 | INFO | train | epoch 206 | loss 5.13 | ppl 35.03 | wps 6038.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.442 | train_wall 318 | gb_free 6.1 | wall 71634
KL Stats: Epoch 206 Divergences: Uniform: 3.0323718283052608 Unigram: 5.209332116910526
2022-02-03 02:00:42 | INFO | fairseq.trainer | begin training epoch 207
2022-02-03 02:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:02:03 | INFO | train_inner | epoch 207:     16 / 64 loss=5.127, ppl=34.95, wps=5908, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.458, train_wall=497, gb_free=6.1, wall=71714
2022-02-03 02:06:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:06:28 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.523 | ppl 1471.65 | wps 8122.4 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.319
2022-02-03 02:06:28 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-02-03 02:06:28 | INFO | train | epoch 207 | loss 5.128 | ppl 34.98 | wps 6036.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.451 | train_wall 318 | gb_free 6.1 | wall 71980
KL Stats: Epoch 207 Divergences: Uniform: 3.0309108053902443 Unigram: 5.217926195553552
2022-02-03 02:06:28 | INFO | fairseq.trainer | begin training epoch 208
2022-02-03 02:06:28 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
